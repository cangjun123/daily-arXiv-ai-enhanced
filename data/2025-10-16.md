<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 77]
- [cs.CL](#cs.CL) [Total: 62]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.HC](#cs.HC) [Total: 7]
- [cs.LG](#cs.LG) [Total: 64]
- [cs.AI](#cs.AI) [Total: 9]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound Interpretation](https://arxiv.org/abs/2510.12953)
*Xiao He,Huangxuan Zhao,Guojia Wan,Wei Zhou,Yanxing Liu,Juhua Liu,Yongchao Xu,Yong Luo,Dacheng Tao,Bo Du*

Main category: cs.CV

TL;DR: 研究引入了针对胎儿超声的FetalMind系统，提出显著认知解耦方法（SED），并开发了大规模数据集FetalSigma-1M。实验结果显示，模型在各个孕期阶段均表现优异，关键病症诊断准确率提升显著。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的医学视觉语言模型在胎儿超声中表现不佳。为了解决这一问题，研究引入了FetalMind系统，旨在提高胎儿超声的报告生成和诊断能力。

Method: 提出了一种显著的认知解耦方法（SED），通过引入专家策划的二分图，结合强化学习，引导模型沿着临床步骤进行推理。

Result: 实验结果表明，FetalMind在所有孕期阶段的表现均优于现有的基线模型，平均提升14%，在关键病症上准确性提高61.2%。

Conclusion: FetalMind显著优于现有的开源和闭源模型，在所有孕期阶段的性能都有提升，特别是在关键病症上的准确性提高了61.2%。

Abstract: Recent medical vision-language models have shown promise on tasks such as
VQA, report generation, and anomaly detection. However, most are adapted to
structured adult imaging and underperform in fetal ultrasound, which poses
challenges of multi-view image reasoning, numerous diseases, and image
diversity. To bridge this gap, we introduce FetalMind, a medical AI system
tailored to fetal ultrasound for both report generation and diagnosis. Guided
by clinical workflow, we propose Salient Epistemic Disentanglement (SED), which
injects an expert-curated bipartite graph into the model to decouple
view-disease associations and to steer preference selection along clinically
faithful steps via reinforcement learning. This design mitigates variability
across diseases and heterogeneity across views, reducing learning bottlenecks
while aligning the model's inference with obstetric practice. To train
FetalMind at scale, we curate FetalSigma-1M dataset, the first large-scale
fetal ultrasound report corpus, comprising 20K reports from twelve medical
centers, addressing the scarcity of domain data. Extensive experiments show
that FetalMind outperforms open- and closed-source baselines across all
gestational stages, achieving +14% average gains and +61.2% higher accuracy on
critical conditions while remaining efficient, stable, and scalable. Project
Page: https://hexiao0275.github.io/FetalMind.

</details>


### [2] [SimULi: Real-Time LiDAR and Camera Simulation with Unscented Transforms](https://arxiv.org/abs/2510.12901)
*Haithem Turki,Qi Wu,Xin Kang,Janick Martinez Esturo,Shengyu Huang,Ruilong Li,Zan Gojcic,Riccardo de Lutio*

Main category: cs.CV

TL;DR: SimULi是一种新的方法，可以实时渲染不同类型的相机和LiDAR数据，解决了交叉传感器不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 由于高保真模拟在自动驾驶汽车测试中的必要性和现有方法的速度或模型局限，需要一种能够快速且支持复杂传感器模型的渲染方法。

Method: 该方法延伸于3DGUT，并设计了一个因子化的3D高斯表现和锚定策略，来减少交叉传感器不一致。提高渲染速度通过自动化平铺策略和基于光线的淘汰实现。

Result: 该研究提出了一种名为SimULi的方法，能够实时渲染任意相机模型和LiDAR数据。此方法通过自动化平铺策略和基于光线的淘汰为任意旋转LiDAR模型扩展了复杂相机模型的支持。

Conclusion: SimULi方法在两种广泛使用的自动驾驶数据集上进行评估时，其性能与现有的最先进方法相当或更佳。该方法减少了相机和深度误差，并提高了渲染速度。

Abstract: Rigorous testing of autonomous robots, such as self-driving vehicles, is
essential to ensure their safety in real-world deployments. This requires
building high-fidelity simulators to test scenarios beyond those that can be
safely or exhaustively collected in the real-world. Existing neural rendering
methods based on NeRF and 3DGS hold promise but suffer from low rendering
speeds or can only render pinhole camera models, hindering their suitability to
applications that commonly require high-distortion lenses and LiDAR data.
Multi-sensor simulation poses additional challenges as existing methods handle
cross-sensor inconsistencies by favoring the quality of one modality at the
expense of others. To overcome these limitations, we propose SimULi, the first
method capable of rendering arbitrary camera models and LiDAR data in
real-time. Our method extends 3DGUT, which natively supports complex camera
models, with LiDAR support, via an automated tiling strategy for arbitrary
spinning LiDAR models and ray-based culling. To address cross-sensor
inconsistencies, we design a factorized 3D Gaussian representation and
anchoring strategy that reduces mean camera and depth error by up to 40%
compared to existing methods. SimULi renders 10-20x faster than ray tracing
approaches and 1.5-10x faster than prior rasterization-based work (and handles
a wider range of camera models). When evaluated on two widely benchmarked
autonomous driving datasets, SimULi matches or exceeds the fidelity of existing
state-of-the-art methods across numerous camera and LiDAR metrics.

</details>


### [3] [OS-HGAdapter: Open Semantic Hypergraph Adapter for Large Language Models Assisted Entropy-Enhanced Image-Text Alignment](https://arxiv.org/abs/2510.13131)
*Rongjun Chen,Chengsi Yao,Jinchang Ren,Xianxian Zeng,Peixian Wang,Jun Yuan,Jiawen Li,Huimin Zhao,Xu Lu*

Main category: cs.CV

TL;DR: 本文提出利用大语言模型和超图适配器来解决文本与图像跨模态对齐中信息熵不平衡的问题，并获得了显著的检索性能提升。


<details>
  <summary>Details</summary>
Motivation: 文本与图像的对齐是多媒体内容理解中的基础性挑战，由于文本和图像之间信息熵的固有差异，传统方法在两种模态的互相检索中往往存在失衡。为了弥合这一差距并模拟人类在这些任务中的对齐能力，本文提出利用大型语言模型的开放语义知识来解决这一特定挑战。

Method: 为了实现文本与图像的对齐，提出了一种新的两步流程：首先，设计新的提示模板，不依赖任务领域的显性知识，利用大语言模型（LLM）增强文本模态的多义性描述，提高其相对视觉模态的信息熵；其次，使用超图适配器构建文本和图像模态之间的多边连接，纠正同一嵌入空间内同义语义的正负匹配错误，并通过将降维映射回原维度减少开放语义熵带来的噪声。

Result: 在Flickr30K和MS-COCO基准测试中的综合评估显示，OS-HGAdapter在文本到图像和图像到文本的跨模态检索中分别获得了16.8%和40.1%的提升。

Conclusion: 改进后的开放语义超图适配器（OS-HGAdapter）在文本到图像和图像到文本的跨模态检索任务上展示了显著的性能提升，刷新了语义对齐任务的现有最新水平。

Abstract: Text-image alignment constitutes a foundational challenge in multimedia
content understanding, where effective modeling of cross-modal semantic
correspondences critically enhances retrieval system performance through joint
embedding space optimization. Given the inherent difference in information
entropy between texts and images, conventional approaches often show an
imbalance in the mutual retrieval of these two modalities. To address this
particular challenge, we propose to use the open semantic knowledge of Large
Language Model (LLM) to fill for the entropy gap and reproduce the alignment
ability of humans in these tasks. Our entropy-enhancing alignment is achieved
through a two-step process: 1) a new prompt template that does not rely on
explicit knowledge in the task domain is designed to use LLM to enhance the
polysemy description of the text modality. By analogy, the information entropy
of the text modality relative to the visual modality is increased; 2) A
hypergraph adapter is used to construct multilateral connections between the
text and image modalities, which can correct the positive and negative matching
errors for synonymous semantics in the same fixed embedding space, whilst
reducing the noise caused by open semantic entropy by mapping the reduced
dimensions back to the original dimensions. Comprehensive evaluations on the
Flickr30K and MS-COCO benchmarks validate the superiority of our Open Semantic
Hypergraph Adapter (OS-HGAdapter), showcasing 16.8\% (text-to-image) and 40.1\%
(image-to-text) cross-modal retrieval gains over existing methods while
establishing new state-of-the-art performance in semantic alignment tasks.

</details>


### [4] [Robust Plant Disease Diagnosis with Few Target-Domain Samples](https://arxiv.org/abs/2510.12909)
*Takafumi Nogami,Satoshi Kagiwada,Hitoshi Iyatomi*

Main category: cs.CV

TL;DR: 提出了一个新框架TMPS，利用有限的目标域样本提高植物病害诊断模型的鲁棒性，显示出显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在图像诊断时难以泛化到不同的拍摄环境，其性能下降源于疾病症状的微小变化和图像环境的差异。训练数据的有限多样性使得模型在未见域中表现不佳。

Method: 使用了目标感知的度量学习框架（TMPS），通过优先采样来提升诊断鲁棒性。

Result: TMPS在大型自动化植物疾病诊断任务中表现优越，通过在训练中结合每种疾病10个目标域样本，获得了显著提升的宏F1分数。相比于基线和传统度量学习，分别提高了18.7和17.1分。

Conclusion: 提出了一种新的学习框架TMPS，可以有效提高植物疾病诊断模型在不同条件下的鲁棒性。

Abstract: Various deep learning-based systems have been proposed for accurate and
convenient plant disease diagnosis, achieving impressive performance. However,
recent studies show that these systems often fail to maintain diagnostic
accuracy on images captured under different conditions from the training
environment -- an essential criterion for model robustness. Many deep learning
methods have shown high accuracy in plant disease diagnosis. However, they
often struggle to generalize to images taken in conditions that differ from the
training setting. This drop in performance stems from the subtle variability of
disease symptoms and domain gaps -- differences in image context and
environment. The root cause is the limited diversity of training data relative
to task complexity, making even advanced models vulnerable in unseen domains.
To tackle this challenge, we propose a simple yet highly adaptable learning
framework called Target-Aware Metric Learning with Prioritized Sampling (TMPS),
grounded in metric learning. TMPS operates under the assumption of access to a
limited number of labeled samples from the target (deployment) domain and
leverages these samples effectively to improve diagnostic robustness. We assess
TMPS on a large-scale automated plant disease diagnostic task using a dataset
comprising 223,073 leaf images sourced from 23 agricultural fields, spanning 21
diseases and healthy instances across three crop species. By incorporating just
10 target domain samples per disease into training, TMPS surpasses models
trained using the same combined source and target samples, and those fine-tuned
with these target samples after pre-training on source data. It achieves
average macro F1 score improvements of 7.3 and 3.6 points, respectively, and a
remarkable 18.7 and 17.1 point improvement over the baseline and conventional
metric learning.

</details>


### [5] [Unifying Vision-Language Latents for Zero-label Image Caption Enhancement](https://arxiv.org/abs/2510.12931)
*Sanghyun Byun,Jung Ick Guack,Mohanad Odema,Baisub Lee,Jacob Song,Woo Seong Chung*

Main category: cs.CV

TL;DR: ViZer enhances image captioning by allowing zero-label learning, aligning vision and language features without needing text labels, and improving caption quality in VLMs like SmolVLM-Base and Qwen2-VL.


<details>
  <summary>Details</summary>
Motivation: The motivation is to overcome the scalability limitations of vision-language models due to their reliance on labeled image datasets and to utilize the vast amounts of unlabeled image data more effectively.

Method: ViZer is an enhancement training framework that aligns vision and language representation features during training, enabling zero-label learning in image captioning.

Result: ViZer shows consistent qualitative improvements in producing more grounded and descriptive captions when applied to models such as SmolVLM-Base and Qwen2-VL.

Conclusion: ViZer demonstrates its effectiveness by improving qualitative performance in image captioning, even when automated metrics may penalize it. It allows existing VLMs to generate better captions without relying on text labels or requiring full retraining.

Abstract: Vision-language models (VLMs) achieve remarkable performance through
large-scale image-text pretraining. However, their reliance on labeled image
datasets limits scalability and leaves vast amounts of unlabeled image data
underutilized. To address this, we propose Unified Vision-Language Alignment
for Zero-Label Enhancement (ViZer), an enhancement training framework that
enables zero-label learning in image captioning, providing a practical starting
point for broader zero-label adaptation in vision-language tasks. Unlike prior
approaches that rely on human or synthetically annotated datasets, ViZer
actively aligns vision and language representation features during training,
enabling existing VLMs to generate improved captions without requiring text
labels or full retraining. We demonstrate ViZer's advantage in qualitative
evaluation, as automated caption metrics such as CIDEr and BERTScore often
penalize details that are absent in reference captions. Applying ViZer on
SmolVLM-Base and Qwen2-VL, we observe consistent qualitative improvements,
producing captions that are more grounded and descriptive than their baseline.

</details>


### [6] [CADE 2.5 - ZeResFDG: Frequency-Decoupled, Rescaled and Zero-Projected Guidance for SD/SDXL Latent Diffusion Models](https://arxiv.org/abs/2510.12954)
*Denis Rychkovskiy,GPT-5*

Main category: cs.CV

TL;DR: CADE 2.5 enhances image clarity and detail in SD/SDXL models using ZeResFDG and QSilk stabilizer, improving output quality without retraining.


<details>
  <summary>Details</summary>
Motivation: To enhance image quality in SD/SDXL latent diffusion models by improving sharpness, adherence to prompts, and artifact control without necessitating retraining.

Method: The method involves the use of ZeResFDG which incorporates frequency-decoupled guidance, energy rescaling, and zero-projection, along with a spectral EMA with hysteresis for adaptability during sampling. It also utilizes QSilk Micrograin Stabilizer to improve robustness during inference time.

Result: The proposed system, CADE 2.5, demonstrated improvements in image quality regarding sharpness and adherence to instructions, while maintaining low artifact levels across different samplers in SD/SDXL models.

Conclusion: CADE 2.5, particularly its central module ZeResFDG, along with the QSilk Micrograin Stabilizer, effectively enhances image sharpness, prompt adherence, and artifact control in SD/SDXL latent diffusion models without the need for retraining.

Abstract: We introduce CADE 2.5 (Comfy Adaptive Detail Enhancer), a sampler-level
guidance stack for SD/SDXL latent diffusion models. The central module,
ZeResFDG, unifies (i) frequency-decoupled guidance that reweights low- and
high-frequency components of the guidance signal, (ii) energy rescaling that
matches the per-sample magnitude of the guided prediction to the positive
branch, and (iii) zero-projection that removes the component parallel to the
unconditional direction. A lightweight spectral EMA with hysteresis switches
between a conservative and a detail-seeking mode as structure crystallizes
during sampling. Across SD/SDXL samplers, ZeResFDG improves sharpness, prompt
adherence, and artifact control at moderate guidance scales without any
retraining. In addition, we employ a training-free inference-time stabilizer,
QSilk Micrograin Stabilizer (quantile clamp + depth/edge-gated micro-detail
injection), which improves robustness and yields natural high-frequency
micro-texture at high resolutions with negligible overhead. For completeness we
note that the same rule is compatible with alternative parameterizations (e.g.,
velocity), which we briefly discuss in the Appendix; however, this paper
focuses on SD/SDXL latent diffusion models.

</details>


### [7] [Scope: Selective Cross-modal Orchestration of Visual Perception Experts](https://arxiv.org/abs/2510.12974)
*Tianyu Zhang,Suyuchen Wang,Chao Wang,Juan Rodriguez,Ahmed Masry,Xiangru Jian,Yoshua Bengio,Perouz Taslakian*

Main category: cs.CV

TL;DR: SCOPE框架通过智能选择专用编码器，提高了多编码器视觉语言模型的性能，节省计算资源。


<details>
  <summary>Details</summary>
Motivation: 解决多视觉编码器带来的推理成本增加和回报递减的问题。

Method: 提出了一种称为SCOPE的编码器混合框架，通过实例级路由选择每个图文对的专用编码器，使用文本提示和共享视觉特征之间的交叉注意力来选择最优编码器。

Result: SCOPE使用一个共享和一个路由编码器的配置超越了同时使用四个额外编码器的模型，并将计算量减少了24-49%。

Conclusion: 智能编码器选择优于蛮力聚合，在多编码器视觉语言模型中提供了一种更有效的框架。

Abstract: Vision-language models (VLMs) benefit from multiple vision encoders, but
naively stacking them yields diminishing returns while multiplying inference
costs. We propose SCOPE, a Mixture-of-Encoders (MoEnc) framework that
dynamically selects one specialized encoder per image-text pair via
instance-level routing, unlike token-level routing in traditional MoE. SCOPE
maintains a shared encoder and a pool of routed encoders. A lightweight router
uses cross-attention between text prompts and shared visual features to select
the optimal encoder from the routed encoders. To train this router, we
introduce dual entropy regularization with auxiliary losses to balance
dataset-level load distribution with instance-level routing confidence.
Remarkably, SCOPE with one shared plus one routed encoder outperforms models
using all four extra encoders simultaneously, while reducing compute by
24-49\%. This demonstrates that intelligent encoder selection beats brute-force
aggregation, challenging the prevailing paradigm in multi-encoder VLMs.

</details>


### [8] [SVAG-Bench: A Large-Scale Benchmark for Multi-Instance Spatio-temporal Video Action Grounding](https://arxiv.org/abs/2510.13016)
*Tanveer Hannan,Shuaicong Wu,Mark Weber,Suprosanna Shit,Jindong Gu,Rajat Koner,Aljoša Ošep,Laura Leal-Taixé,Thomas Seidl*

Main category: cs.CV

TL;DR: 论文提出了一种新的任务和基准库来解决微细动作识别与定位问题，并展示了现有模型在这一任务上的不足。


<details>
  <summary>Details</summary>
Motivation: 推动下一代AI系统在视频理解领域的发展，通过解决现有方法在动作和对象识别与定位上的不足。

Method: 作者提出了Spatio-temporal Video Action Grounding (SVAG)任务，并构建了SVAG-Bench基准库和SVAGFormer基线框架，使用标准化评估工具SVAGEval进行性能检验。

Result: 本文旨在解决视频理解中的微细动作识别与定位问题，提出了一种名为SVAG的创新任务，以及支持这一任务的大规模基准库SVAG-Bench。通过将现有视觉语言模型进行改进，作者提出了SVAGFormer基线框架，并引入了标准化评估工具SVAGEval，以促进公平和可重复的基准测试。实证结果显示，现有模型在SVAG任务上表现不佳，尤其是在密集或复杂场景中，这凸显了在长视频中进行细粒度的对象动作交互推理的需求。

Conclusion: 现有视频理解模型在微细动作识别与定位任务上表现有限，特别是对于复杂场景，需进一步研究来提高模型的推理能力。

Abstract: Understanding fine-grained actions and accurately localizing their
corresponding actors in space and time are fundamental capabilities for
advancing next-generation AI systems, including embodied agents, autonomous
platforms, and human-AI interaction frameworks. Despite recent progress in
video understanding, existing methods predominantly address either
coarse-grained action recognition or generic object tracking, thereby
overlooking the challenge of jointly detecting and tracking multiple objects
according to their actions while grounding them temporally. To address this
gap, we introduce Spatio-temporal Video Action Grounding (SVAG), a novel task
that requires models to simultaneously detect, track, and temporally localize
all referent objects in videos based on natural language descriptions of their
actions. To support this task, we construct SVAG-Bench, a large-scale benchmark
comprising 688 videos, 19,590 annotated records, and 903 unique verbs, covering
a diverse range of objects, actions, and real-world scenes. We further propose
SVAGFormer, a baseline framework that adapts state of the art vision language
models for joint spatial and temporal grounding, and introduce SVAGEval, a
standardized evaluation toolkit for fair and reproducible benchmarking.
Empirical results show that existing models perform poorly on SVAG,
particularly in dense or complex scenes, underscoring the need for more
advanced reasoning over fine-grained object-action interactions in long videos.

</details>


### [9] [SeqBench: Benchmarking Sequential Narrative Generation in Text-to-Video Models](https://arxiv.org/abs/2510.13042)
*Zhengxu Tang,Zizheng Wang,Luning Wang,Zitao Shuai,Chenhao Zhang,Siyu Qian,Yirui Wu,Bohao Wang,Haosong Rao,Zhenyu Yang,Chenwei Wu*

Main category: cs.CV

TL;DR: SeqBench 是一个用于评估 T2V 生成中叙述连贯性的基准，显示当前模型在保持对象状态一致性和时序关系上存在问题。


<details>
  <summary>Details</summary>
Motivation: 尽管T2V生成模型在生成视觉上吸引人的视频方面取得了显著进展，但在通过多个事件生成连贯的顺序叙事方面仍存在困难。现有基准主要关注视觉质量指标，而未能评估延长序列的叙述连贯性。为弥补这一差距，作者提出了SeqBench。

Method: 作者创建了SeqBench基准，其中包含320个不同叙事复杂性提示的数据集，以及从8个先进T2V模型中生成的2,560段人工注释视频。此外，设计了一种基于动态时间图（DTG）的自动评估指标，以高效捕捉长距离依赖和时间排序。

Result: SeqBench提出了一种新的基准，用于评估文字生成视频(T2V)模型中的连续叙述连贯性。它包含一个精心设计的数据集和基于动态时间图(DTG)的自动评估指标。这项研究揭示了当前T2V模型在多动作序列中保持连续性、处理多物体场景中的物理可行性以及保持动作时序关系方面的关键限制。

Conclusion: SeqBench为T2V生成的叙述连贯性提供了第一个系统性框架，并提出了改进未来模型序列推理能力的具体见解。

Abstract: Text-to-video (T2V) generation models have made significant progress in
creating visually appealing videos. However, they struggle with generating
coherent sequential narratives that require logical progression through
multiple events. Existing T2V benchmarks primarily focus on visual quality
metrics but fail to evaluate narrative coherence over extended sequences. To
bridge this gap, we present SeqBench, a comprehensive benchmark for evaluating
sequential narrative coherence in T2V generation. SeqBench includes a carefully
designed dataset of 320 prompts spanning various narrative complexities, with
2,560 human-annotated videos generated from 8 state-of-the-art T2V models.
Additionally, we design a Dynamic Temporal Graphs (DTG)-based automatic
evaluation metric, which can efficiently capture long-range dependencies and
temporal ordering while maintaining computational efficiency. Our DTG-based
metric demonstrates a strong correlation with human annotations. Through
systematic evaluation using SeqBench, we reveal critical limitations in current
T2V models: failure to maintain consistent object states across multi-action
sequences, physically implausible results in multi-object scenarios, and
difficulties in preserving realistic timing and ordering relationships between
sequential actions. SeqBench provides the first systematic framework for
evaluating narrative coherence in T2V generation and offers concrete insights
for improving sequential reasoning capabilities in future models. Please refer
to https://videobench.github.io/SeqBench.github.io/ for more details.

</details>


### [10] [True Self-Supervised Novel View Synthesis is Transferable](https://arxiv.org/abs/2510.13063)
*Thomas W. Mitchel,Hyunwoo Ryu,Vincent Sitzmann*

Main category: cs.CV

TL;DR: 该研究提出了一个名为XFactor的模型，以实现几何无关的自监督新视点合成。


<details>
  <summary>Details</summary>
Motivation: 作者意识到现有的自监督NVS模型的姿态预测在不同场景中的转移能力欠缺，希望通过新的模型设计实现更好的视点合成能力。

Method: XFactor结合了成对的姿态估计和对输入输出的简单增强方案，能够在不借助3D归纳偏置或多视图几何概念的情况下，实现真实的新视点合成。

Result: 该论文的研究目标是确定哪些模型能够实现真实的新视点合成（NVS），其中关键标准是可转移性。之前的研究发现，所预测的姿势在不同的3D场景中并不具备可转移性。为此，论文介绍了一种名为XFactor的新模型。

Conclusion: XFactor通过大规模实验证明显著优于之前的无姿态NVS模型，并且其潜在姿态与真实世界姿态高度相关。

Abstract: In this paper, we identify that the key criterion for determining whether a
model is truly capable of novel view synthesis (NVS) is transferability:
Whether any pose representation extracted from one video sequence can be used
to re-render the same camera trajectory in another. We analyze prior work on
self-supervised NVS and find that their predicted poses do not transfer: The
same set of poses lead to different camera trajectories in different 3D scenes.
Here, we present XFactor, the first geometry-free self-supervised model capable
of true NVS. XFactor combines pair-wise pose estimation with a simple
augmentation scheme of the inputs and outputs that jointly enables
disentangling camera pose from scene content and facilitates geometric
reasoning. Remarkably, we show that XFactor achieves transferability with
unconstrained latent pose variables, without any 3D inductive biases or
concepts from multi-view geometry -- such as an explicit parameterization of
poses as elements of SE(3). We introduce a new metric to quantify
transferability, and through large-scale experiments, we demonstrate that
XFactor significantly outperforms prior pose-free NVS transformers, and show
that latent poses are highly correlated with real-world poses through probing
experiments.

</details>


### [11] [Direction-aware multi-scale gradient loss for infrared and visible image fusion](https://arxiv.org/abs/2510.13067)
*Kaixuan Yang,Wei Xiang,Zhenshuai Chen,Tong Jin,Yunpeng Liu*

Main category: cs.CV

TL;DR: 提出了方向感知的多尺度梯度损失，改善了图像融合中的边缘清晰度和纹理保留。


<details>
  <summary>Details</summary>
Motivation: 红外和可见光图像融合旨在整合共配准源图像中的互补信息，产生单一的信息丰富的结果。大多数基于学习的方法通过结构相似性损失、强度重建损失和梯度幅值项进行训练，但传统方法忽略了梯度的方向性。

Method: 本文提出了一种方向感知的多尺度梯度损失方法，以单独监督水平和垂直分量，并在多个尺度上保留其符号。

Result: 实验表明，在多个公共基准上，我们的方法有效地促进了更清晰、对齐的边缘和更丰富的纹理保留，而无需改变模型架构或训练协议。

Conclusion: 在不改变模型架构或训练方法的情况下，结合方向信息的多尺度梯度损失能够显著提升融合图像的质量。

Abstract: Infrared and visible image fusion aims to integrate complementary information
from co-registered source images to produce a single, informative result. Most
learning-based approaches train with a combination of structural similarity
loss, intensity reconstruction loss, and a gradient-magnitude term. However,
collapsing gradients to their magnitude removes directional information,
yielding ambiguous supervision and suboptimal edge fidelity. We introduce a
direction-aware, multi-scale gradient loss that supervises horizontal and
vertical components separately and preserves their sign across scales. This
axis-wise, sign-preserving objective provides clear directional guidance at
both fine and coarse resolutions, promoting sharper, better-aligned edges and
richer texture preservation without changing model architectures or training
protocols. Experiments on open-source model and multiple public benchmarks
demonstrate effectiveness of our approach.

</details>


### [12] [Counting Hallucinations in Diffusion Models](https://arxiv.org/abs/2510.13080)
*Shuai Fu,Jian Zhou,Qi Chen,Huang Jing,Huy Anh Nguyen,Xiaohan Liu,Zhixiong Zeng,Lin Ma,Quanshi Zhang,Qi Wu*

Main category: cs.CV

TL;DR: 该研究定义并量化了扩散模型中一种特定的幻觉现象——计数幻觉，建立了评估协议，并发现常用图像质量指标未能有效检测此类幻觉。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散概率模型在生成任务中取得了显著进展，但它们仍常常生成与现实世界知识冲突的幻觉样本，缺乏系统量化此类幻觉的方法阻碍了生成模型在事实约束下的设计进展。因此，研究者欲通过量化一种特定的幻觉，称为计数幻觉，来填补这一研究空白。

Method: 研究人员构建了CountHalluSet数据集套件，并开发了一个标准化的评估协议，系统地研究了不同采样条件如何影响扩散模型中的计数幻觉水平。此外，还分析了这些条件与常用评价指标（如FID）的相关性。

Result: 研究发现常用的图像质量评价指标（如FID）未能一致地捕捉计数幻觉，并揭示了不同采样条件对计数幻觉水平的系统影响。

Conclusion: 该研究首次系统地量化了扩散模型中的幻觉现象，尤其是计数幻觉，并为图像生成中的幻觉现象提供了新洞察。

Abstract: Diffusion probabilistic models (DPMs) have demonstrated remarkable progress
in generative tasks, such as image and video synthesis. However, they still
often produce hallucinated samples (hallucinations) that conflict with
real-world knowledge, such as generating an implausible duplicate cup floating
beside another cup. Despite their prevalence, the lack of feasible
methodologies for systematically quantifying such hallucinations hinders
progress in addressing this challenge and obscures potential pathways for
designing next-generation generative models under factual constraints. In this
work, we bridge this gap by focusing on a specific form of hallucination, which
we term counting hallucination, referring to the generation of an incorrect
number of instances or structured objects, such as a hand image with six
fingers, despite such patterns being absent from the training data. To this
end, we construct a dataset suite CountHalluSet, with well-defined counting
criteria, comprising ToyShape, SimObject, and RealHand. Using these datasets,
we develop a standardized evaluation protocol for quantifying counting
hallucinations, and systematically examine how different sampling conditions in
DPMs, including solver type, ODE solver order, sampling steps, and initial
noise, affect counting hallucination levels. Furthermore, we analyze their
correlation with common evaluation metrics such as FID, revealing that this
widely used image quality metric fails to capture counting hallucinations
consistently. This work aims to take the first step toward systematically
quantifying hallucinations in diffusion models and offer new insights into the
investigation of hallucination phenomena in image generation.

</details>


### [13] [Edit-Your-Interest: Efficient Video Editing via Feature Most-Similar Propagation](https://arxiv.org/abs/2510.13084)
*Yi Zuo,Zitao Wang,Lingling Li,Xu Liu,Fang Liu,Licheng Jiao*

Main category: cs.CV

TL;DR: 该论文提出了一种名为Edit-Your-Interest的轻量级、基于文本驱动的零样本视频编辑方法，采用了时空特征记忆和相似特征传播等方法来提高效率和视觉一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的视频编辑方法虽然取得了一定进展，但其高计算开销和内存消耗限制了实用性，且常常在视觉保真度上做出妥协，导致时间不一致和伪影。

Method: 提出了时空特征记忆(SFM)和特征最相似传播(FMP)的方法，并使用跨注意力图自动提取目标实例的掩码，以实现高精度的对象编辑和背景保真。

Result: Edit-Your-Interest能够在效率和视觉保真度方面优于现有方法，验证其卓越的有效性和实用性。

Conclusion: Edit-Your-Interest方法有效减少了计算和内存消耗，并在编辑精度和背景保真度上实现了提升。

Abstract: Text-to-image (T2I) diffusion models have recently demonstrated significant
progress in video editing.
  However, existing video editing methods are severely limited by their high
computational overhead and memory consumption.
  Furthermore, these approaches often sacrifice visual fidelity, leading to
undesirable temporal inconsistencies and artifacts such as blurring and
pronounced mosaic-like patterns.
  We propose Edit-Your-Interest, a lightweight, text-driven, zero-shot video
editing method.
  Edit-Your-Interest introduces a spatio-temporal feature memory to cache
features from previous frames, significantly reducing computational overhead
compared to full-sequence spatio-temporal modeling approaches.
  Specifically, we first introduce a Spatio-Temporal Feature Memory bank (SFM),
which is designed to efficiently cache and retain the crucial image tokens
processed by spatial attention.
  Second, we propose the Feature Most-Similar Propagation (FMP) method. FMP
propagates the most relevant tokens from previous frames to subsequent ones,
preserving temporal consistency.
  Finally, we introduce an SFM update algorithm that continuously refreshes the
cached features, ensuring their long-term relevance and effectiveness
throughout the video sequence.
  Furthermore, we leverage cross-attention maps to automatically extract masks
for the instances of interest.
  These masks are seamlessly integrated into the diffusion denoising process,
enabling fine-grained control over target objects and allowing
Edit-Your-Interest to perform highly accurate edits while robustly preserving
the background integrity.
  Extensive experiments decisively demonstrate that the proposed
Edit-Your-Interest outperforms state-of-the-art methods in both efficiency and
visual fidelity, validating its superior effectiveness and practicality.

</details>


### [14] [EgoSocial: Benchmarking Proactive Intervention Ability of Omnimodal LLMs via Egocentric Social Interaction Perception](https://arxiv.org/abs/2510.13105)
*Xijun Wang,Tanay Sharma,Achin Kulshrestha,Abhimitra Meka,Aveek Purohit,Dinesh Manocha*

Main category: cs.CV

TL;DR: 引入EgoSocial数据集和EgoSoD方法以增强AI助手的社交互动感知和干预能力，显著提升了现有模型的干预时机和社交互动检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型(LLM)缺乏社交意识，无法在合适的时机作为AI助手进行干预，导致打断自然对话并影响用户注意力。

Method: 提出了一种新的方法EgoSoD，该方法通过整合多种模态上下文线索，如音频和视觉线索，构建一个社交思维图，动态建模参与者和互动，准确判断干预时机。

Result: 实验结果显示，现有的omnimodal LLMs在检测干预时机上依旧存在困难。EgoSoD方法在干预时机性能上改善了Phi-4 45.6%和Gemini 2.5 Pro 9.9%，在整体社交互动性能上提升了Phi-4 20.4%和Gemini 2.5 Pro 6.9%。

Conclusion: EgoSoD方法在社交互动感知与干预方面取得了显著效果，提高了现有模型在干预时机和社交互动上的性能，即将发布相关数据集和代码。

Abstract: As AR/VR technologies become integral to daily life, there's a growing need
for AI that understands human social dynamics from an egocentric perspective.
However, current LLMs often lack the social awareness to discern when to
intervene as AI assistant. This leads to constant, socially unaware responses
that may disrupt natural conversation and negatively impact user focus. To
address these limitations, we introduce EgoSocial, a large-scale egocentric
dataset with 13,500 social video-question pairs, specifically designed to
benchmark intervention in social interaction perception. We also present an
in-depth analysis of current omnimodal LLMs (OLLMs) to assess their
effectiveness in detecting diverse social contextual cues. Experiments show
that OLLMs still struggle to detect the intervention timing (14.4% for Gemini
2.5 Pro). We also propose EgoSoD (EgoSocial Detection), an end-to-end method
for robustly discerning social dynamics. Informed by our OLLM analysis, EgoSoD
integrates multimodal contextual cues (e.g., audio and visual cues) into a
social thinking graph, dynamically modeling participants and interactions. Our
method proactively detects intervention timing and social interactions,
precisely determining when to intervene. Our EgoSoD improves Phi-4 by 45.6% and
Gemini 2.5 Pro by 9.9% on Intervention Timing performance, and improves Phi-4
by 20.4% and Gemini 2.5 Pro by 6.9% on overall Social Interaction performance.
We will release the dataset and code soon.

</details>


### [15] [DriveCritic: Towards Context-Aware, Human-Aligned Evaluation for Autonomous Driving with Vision-Language Models](https://arxiv.org/abs/2510.13108)
*Jingyu Song,Zhenxin Li,Shiyi Lan,Xinglong Sun,Nadine Chang,Maying Shen,Joshua Chen,Katherine A. Skinner,Jose M. Alvarez*

Main category: cs.CV

TL;DR: DriveCritic通过两阶段监督和强化学习流程来评估轨迹对，显著提升了匹配人类偏好的能力，并展示了强烈的上下文意识。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶评估标准缺乏在复杂场景下的上下文意识，为了解决这一问题，提出了DriveCritic框架，以更好地模拟和匹配人类判断。

Method: DriveCritic使用视觉-语言模型（VLM）评估器，通过一个两阶段的监督和强化学习流程，整合视觉和符号上下文，来学习评判轨迹对之间的差异。

Result: DriveCritic显著优于现有的度量标准和基线，在匹配人类偏好方面表现出色，并且展示了强烈的上下文意识。总体而言，该工作为评估自动驾驶系统提供了一个更加可靠和符合人类的基础。

Conclusion: 通过引入DriveCritic框架，该研究提供了一种更可靠、更符合人类判断标准的自动驾驶系统评估基础。

Abstract: Benchmarking autonomous driving planners to align with human judgment remains
a critical challenge, as state-of-the-art metrics like the Extended Predictive
Driver Model Score (EPDMS) lack context awareness in nuanced scenarios. To
address this, we introduce DriveCritic, a novel framework featuring two key
contributions: the DriveCritic dataset, a curated collection of challenging
scenarios where context is critical for correct judgment and annotated with
pairwise human preferences, and the DriveCritic model, a Vision-Language Model
(VLM) based evaluator. Fine-tuned using a two-stage supervised and
reinforcement learning pipeline, the DriveCritic model learns to adjudicate
between trajectory pairs by integrating visual and symbolic context.
Experiments show DriveCritic significantly outperforms existing metrics and
baselines in matching human preferences and demonstrates strong context
awareness. Overall, our work provides a more reliable, human-aligned foundation
to evaluating autonomous driving systems.

</details>


### [16] [VPREG: An Optimal Control Formulation for Diffeomorphic Image Registration Based on the Variational Principle Grid Generation Method](https://arxiv.org/abs/2510.13109)
*Zicong Zhou,Baihan Zhao,Andreas Mang,Guojun Liao*

Main category: cs.CV

TL;DR: VPreg, a new image registration method, improves accuracy and inverse consistency over existing methods using a unique grid generation approach, showing superior results in brain scan registration tests.


<details>
  <summary>Details</summary>
Motivation: To improve registration accuracy and the quality of registration transformations in neuroimaging workflows while ensuring a positive Jacobian determinant and providing accurate inverse approximations of the registration.

Method: The paper introduces VPreg, a novel diffeomorphic image registration method utilizing a grid generation approach called Variational Principle (VP) for constructing non-folding grids with prescribed Jacobian determinant and curl to ensure accurate inverse transformations and diffeomorphic mappings.

Result: VPreg achieves better registration accuracy and superior regularity properties of computed transformations compared to conventional methods, validated through performance analysis using Dice scores on brain scan registrations from the OASIS-1 dataset.

Conclusion: VPreg outperforms state-of-the-art methods such as ANTs-SyN, Freesurfer-Easyreg, and FSL-Fnirt in terms of registration accuracy, Dice scores, and the quality of the computed spatial transformations.

Abstract: This paper introduces VPreg, a novel diffeomorphic image registration method.
This work provides several improvements to our past work on mesh generation and
diffeomorphic image registration. VPreg aims to achieve excellent registration
accuracy while controlling the quality of the registration transformations. It
ensures a positive Jacobian determinant of the spatial transformation and
provides an accurate approximation of the inverse of the registration, a
crucial property for many neuroimaging workflows. Unlike conventional methods,
VPreg generates this inverse transformation within the group of diffeomorphisms
rather than operating on the image space. The core of VPreg is a grid
generation approach, referred to as \emph{Variational Principle} (VP), which
constructs non-folding grids with prescribed Jacobian determinant and curl.
These VP-generated grids guarantee diffeomorphic spatial transformations
essential for computational anatomy and morphometry, and provide a more
accurate inverse than existing methods. To assess the potential of the proposed
approach, we conduct a performance analysis for 150 registrations of brain
scans from the OASIS-1 dataset. Performance evaluation based on Dice scores for
35 regions of interest, along with an empirical analysis of the properties of
the computed spatial transformations, demonstrates that VPreg outperforms
state-of-the-art methods in terms of Dice scores, regularity properties of the
computed transformation, and accuracy and consistency of the provided inverse
map. We compare our results to ANTs-SyN, Freesurfer-Easyreg, and FSL-Fnirt.

</details>


### [17] [Foveation Improves Payload Capacity in Steganography](https://arxiv.org/abs/2510.13151)
*Lifeng Qiu Lin,Henry Kam,Qi Sun,Kaan Akşit*

Main category: cs.CV

TL;DR: 通过新的感知设计，研究显著提高了隐写术的容量和视觉质量，结果表现为500位容量和卓越的视觉准确性。


<details>
  <summary>Details</summary>
Motivation: 隐写术在视觉媒体中的应用需要更高的容量和准确性，以满足元数据提供和水印的需求。

Method: 支持高效潜在表示和中央渲染，通过训练模型提高现有容量极限。

Result: 提高了容量极限，从100位到500位；测试时200K位中仅出现1位失败；比较好的视觉质量为31.47 dB PSNR和0.13 LPIPS。

Conclusion: 本研究通过新的感知设计，在隐写术中创建了多模态潜在表示，显著提高了视觉质量和容量。

Abstract: Steganography finds its use in visual medium such as providing metadata and
watermarking. With support of efficient latent representations and foveated
rendering, we trained models that improve existing capacity limits from 100 to
500 bits, while achieving better accuracy of up to 1 failure bit out of 2000,
at 200K test bits. Finally, we achieve a comparable visual quality of 31.47 dB
PSNR and 0.13 LPIPS, showing the effectiveness of novel perceptual design in
creating multi-modal latent representations in steganography.

</details>


### [18] [DP-TTA: Test-time Adaptation for Transient Electromagnetic Signal Denoising via Dictionary-driven Prior Regularization](https://arxiv.org/abs/2510.13160)
*Meng Yang,Kecheng Chen,Wei Luo,Xianjie Chen,Yong Jia,Mingyue Wang,Fanqiang Lin*

Main category: cs.CV

TL;DR: 提出了一种提高TEM信号去噪性能的方法，通过字典学习和自监督损失动态调整模型，提高了新环境中的去噪效果。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习去噪模型主要在模拟或单一真实场景数据上训练，未考虑不同地理区域噪声特性差异，导致在不同环境中去噪性能下降。

Method: 提出了一种字典驱动的先验正则化测试时间适应(DP-TTA)方法，结合字典学习编码的先验知识和自监督损失来动态调整模型参数。

Result: 实验结果显示，该方法在TEM去噪方面的性能远优于现有方法和TTA方法。

Conclusion: 所提出的DP-TTA方法通过利用基于字典的先验知识在新的地质环境中显著提高了TEM信号的去噪性能。

Abstract: Transient Electromagnetic (TEM) method is widely used in various geophysical
applications, providing valuable insights into subsurface properties. However,
time-domain TEM signals are often submerged in various types of noise. While
recent deep learning-based denoising models have shown strong performance,
these models are mostly trained on simulated or single real-world scenario
data, overlooking the significant differences in noise characteristics from
different geographical regions. Intuitively, models trained in one environment
often struggle to perform well in new settings due to differences in geological
conditions, equipment, and external interference, leading to reduced denoising
performance. To this end, we propose the Dictionary-driven Prior Regularization
Test-time Adaptation (DP-TTA). Our key insight is that TEM signals possess
intrinsic physical characteristics, such as exponential decay and smoothness,
which remain consistent across different regions regardless of external
conditions. These intrinsic characteristics serve as ideal prior knowledge for
guiding the TTA strategy, which helps the pre-trained model dynamically adjust
parameters by utilizing self-supervised losses, improving denoising performance
in new scenarios. To implement this, we customized a network, named DTEMDNet.
Specifically, we first use dictionary learning to encode these intrinsic
characteristics as a dictionary-driven prior, which is integrated into the
model during training. At the testing stage, this prior guides the model to
adapt dynamically to new environments by minimizing self-supervised losses
derived from the dictionary-driven consistency and the signal one-order
variation. Extensive experimental results demonstrate that the proposed method
achieves much better performance than existing TEM denoising methods and TTA
methods.

</details>


### [19] [STT-GS: Sample-Then-Transmit Edge Gaussian Splatting with Joint Client Selection and Power Control](https://arxiv.org/abs/2510.13186)
*Zhen Li,Xibin Jin,Guoliang Li,Shuai Wang,Miaowen Wen,Huseyin Arslan,Derrick Wing Kwan Ng,Chengzhong Xu*

Main category: cs.CV

TL;DR: 提出了一种新的策略，解决了如何在边缘服务器端有效聚合多客户端数据以训练GS模型的问题，实验验证了该策略的优越性和在通信与资源限制下的高效性。


<details>
  <summary>Details</summary>
Motivation: 传统的边缘资源管理方法强调通信吞吐量或通用学习性能，而无法有效提高GS模型的质量。因此，需要一种新方法来评估客户端对GS模型的贡献，从而优化场景重建。这推动了定义一个新的GS导向目标函数，用于区别不同客户端的异构视图贡献。评估该目标函数需要使用客户端的图像数据，这导致因果关系悖论。因此提出新的方法来解决这一问题。

Method: 论文提出了一个名为样本后传输 EGS（STT-GS）的策略。首先，从每个客户端抽取子集数据作为预测损失的试点数据，并根据初步评估结果优先分配通信资源给更有价值的客户端。此外，采用特征域聚类（FDC）方案进行有效采样，并通过试点传输时间最小化（PTTM）策略减少试点通讯开销。之后构建了一个联合客户端选择与功率控制框架（JCSPC），在通信资源受限条件下最大化GS导向函数，并使用惩罚交替主要化方法（PAMM）算法提出低复杂度解决方案。

Result: 实验结果表明，GS导向的目标可以通过低采样率（例如10%）准确预测，此方法具有显著优于现有基准的性能，并在视图贡献与通信开销之间取得了良好的平衡。

Conclusion: 提出的方案在处理通信约束下GS模型的训练问题时，相较于现有基准显著更优。在实验中，即使仅采用低采样率，该方法也能有效预测GS目标，并在视图贡献与通信成本之间取得了良好的平衡。

Abstract: Edge Gaussian splatting (EGS), which aggregates data from distributed clients
and trains a global GS model at the edge server, is an emerging paradigm for
scene reconstruction. Unlike traditional edge resource management methods that
emphasize communication throughput or general-purpose learning performance, EGS
explicitly aims to maximize the GS qualities, rendering existing approaches
inapplicable. To address this problem, this paper formulates a novel
GS-oriented objective function that distinguishes the heterogeneous view
contributions of different clients. However, evaluating this function in turn
requires clients' images, leading to a causality dilemma. To this end, this
paper further proposes a sample-then-transmit EGS (or STT-GS for short)
strategy, which first samples a subset of images as pilot data from each client
for loss prediction. Based on the first-stage evaluation, communication
resources are then prioritized towards more valuable clients. To achieve
efficient sampling, a feature-domain clustering (FDC) scheme is proposed to
select the most representative data and pilot transmission time minimization
(PTTM) is adopted to reduce the pilot overhead.Subsequently, we develop a joint
client selection and power control (JCSPC) framework to maximize the
GS-oriented function under communication resource constraints. Despite the
nonconvexity of the problem, we propose a low-complexity efficient solution
based on the penalty alternating majorization minimization (PAMM) algorithm.
Experiments unveil that the proposed scheme significantly outperforms existing
benchmarks on real-world datasets. It is found that the GS-oriented objective
can be accurately predicted with low sampling ratios (e.g.,10%), and our method
achieves an excellent tradeoff between view contributions and communication
costs.

</details>


### [20] [Complementary Information Guided Occupancy Prediction via Multi-Level Representation Fusion](https://arxiv.org/abs/2510.13198)
*Rongtao Xu,Jinzhou Lin,Jialei Zhou,Jiahua Dong,Changwei Wang,Ruisheng Wang,Li Guo,Shibiao Xu,Xiaodan Liang*

Main category: cs.CV

TL;DR: CIGOcc通过多层次表示融合机制，提高了占用预测的性能，且无需增加训练成本。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法对2D图像特征利用不足的问题，提出一种基于多层次表示融合的双阶段占用预测框架。

Method: 提出了CIGOcc框架，通过多层次表示融合机制，结合来自SAM的知识蒸馏，从输入图像中提取分割、图形和深度特征，并融合这些特征以增强预测精度。

Result: CIGOcc不增加训练成本的情况下，在SemanticKITTI基准上实现了最先进的性能。代码在补充材料中提供并将在GitHub上发布。

Conclusion: CIGOcc框架有效融合了2D图像的多层次特征，提升了3D场景几何和语义的预测性能。

Abstract: Camera-based occupancy prediction is a mainstream approach for 3D perception
in autonomous driving, aiming to infer complete 3D scene geometry and semantics
from 2D images. Almost existing methods focus on improving performance through
structural modifications, such as lightweight backbones and complex cascaded
frameworks, with good yet limited performance. Few studies explore from the
perspective of representation fusion, leaving the rich diversity of features in
2D images underutilized. Motivated by this, we propose \textbf{CIGOcc, a
two-stage occupancy prediction framework based on multi-level representation
fusion. \textbf{CIGOcc extracts segmentation, graphics, and depth features from
an input image and introduces a deformable multi-level fusion mechanism to fuse
these three multi-level features. Additionally, CIGOcc incorporates knowledge
distilled from SAM to further enhance prediction accuracy. Without increasing
training costs, CIGOcc achieves state-of-the-art performance on the
SemanticKITTI benchmark. The code is provided in the supplementary material and
will be released https://github.com/VitaLemonTea1/CIGOcc

</details>


### [21] [Paper Copilot: Tracking the Evolution of Peer Review in AI Conferences](https://arxiv.org/abs/2510.13201)
*Jing Yang,Qiyao Wei,Jiaxin Pei*

Main category: cs.CV

TL;DR: Paper Copilot 系统通过创建和释放同行评审的数字档案和数据集，支持对评审过程演变的研究，旨在提升评审的透明度和信誉度。


<details>
  <summary>Details</summary>
Motivation: 随着AI会议的快速增长，同行评审体系面临压力，如审稿人工作负担过重、专业技能不匹配、评估标准不一等问题，为了维护评审标准，需要一种系统性的方法来追踪和改进评审流程。

Method: Paper Copilot 系统创建了耐用的数字档案和开放数据集，并进行大规模的实证分析，特别是针对多年ICLR评审的分析。

Result: Paper Copilot释放了基础设施和数据集，支持同行评审演变的研究，并帮助社区追踪变化，诊断问题，促进基于证据的改进。

Conclusion: Paper Copilot 提供了一种系统方法，通过创建持久的数字档案和开放数据集来研究同行评审过程，支持可重复的研究，以推动更强大、透明和可靠的评审体系演变。

Abstract: The rapid growth of AI conferences is straining an already fragile
peer-review system, leading to heavy reviewer workloads, expertise mismatches,
inconsistent evaluation standards, superficial or templated reviews, and
limited accountability under compressed timelines. In response, conference
organizers have introduced new policies and interventions to preserve review
standards. Yet these ad-hoc changes often create further concerns and confusion
about the review process, leaving how papers are ultimately accepted - and how
practices evolve across years - largely opaque. We present Paper Copilot, a
system that creates durable digital archives of peer reviews across a wide
range of computer-science venues, an open dataset that enables researchers to
study peer review at scale, and a large-scale empirical analysis of ICLR
reviews spanning multiple years. By releasing both the infrastructure and the
dataset, Paper Copilot supports reproducible research on the evolution of peer
review. We hope these resources help the community track changes, diagnose
failure modes, and inform evidence-based improvements toward a more robust,
transparent, and reliable peer-review system.

</details>


### [22] [Prompt-based Adaptation in Large-scale Vision Models: A Survey](https://arxiv.org/abs/2510.13219)
*Xi Xiao,Yunbei Zhang,Lin Zhao,Yiyang Liu,Xiaoying Liao,Zheda Mai,Xingjian Li,Xiao Wang,Hao Xu,Jihun Hamm,Xue Lin,Min Xu,Qifan Wang,Tianyang Wang,Cheng Han*

Main category: cs.CV

TL;DR: The paper surveys Visual Prompting and Visual Prompt Tuning, unifies them under Prompt-based Adaptation framework, categorizes techniques, explores applications, and identifies research directions.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the blurred conceptual boundaries between Visual Prompting (VP) and Visual Prompt Tuning (VPT), which are often used interchangeably, by creating a systematic distinction and unifying them under the framework of Prompt-based Adaptation (PA).

Method: The paper revisits Visual Prompting (VP) and Visual Prompt Tuning (VPT) techniques from first principles and conceptualizes them within a unified framework called Prompt-based Adaptation (PA). It provides a taxonomy categorizing these methods into learnable, generative, and non-learnable prompts, further organized by injection granularity such as pixel-level and token-level. The paper explores PA's applications in various domains and summarizes current benchmarks, challenges, and future directions.

Result: The paper presents a comprehensive survey of Prompt-based Adaptation (PA), categorizing existing methods, exploring their applications across various domains, and identifying challenges and future research directions. It aims to clarify these techniques and provide guidance for researchers and practitioners.

Conclusion: The survey is the first comprehensive review of Prompt-based Adaptation methodologies and applications. It provides a taxonomy and systematic understanding of these techniques, aiming to support researchers and practitioners in navigating the evolving research landscape.

Abstract: In computer vision, Visual Prompting (VP) and Visual Prompt Tuning (VPT) have
recently emerged as lightweight and effective alternatives to full fine-tuning
for adapting large-scale vision models within the ``pretrain-then-finetune''
paradigm. However, despite rapid progress, their conceptual boundaries remain
blurred, as VP and VPT are frequently used interchangeably in current research,
reflecting a lack of systematic distinction between these techniques and their
respective applications. In this survey, we revisit the designs of VP and VPT
from first principles, and conceptualize them within a unified framework termed
Prompt-based Adaptation (PA). We provide a taxonomy that categorizes existing
methods into learnable, generative, and non-learnable prompts, and further
organizes them by injection granularity -- pixel-level and token-level. Beyond
the core methodologies, we examine PA's integrations across diverse domains,
including medical imaging, 3D point clouds, and vision-language tasks, as well
as its role in test-time adaptation and trustworthy AI. We also summarize
current benchmarks and identify key challenges and future directions. To the
best of our knowledge, we are the first comprehensive survey dedicated to PA's
methodologies and applications in light of their distinct characteristics. Our
survey aims to provide a clear roadmap for researchers and practitioners in all
area to understand and explore the evolving landscape of PA-related research.

</details>


### [23] [Sample-Centric Multi-Task Learning for Detection and Segmentation of Industrial Surface Defects](https://arxiv.org/abs/2510.13226)
*Hang-Cheng Dong,Yibo Jiao,Fupeng Wei,Guodong Liu,Dong Ye,Bingguo Liu*

Main category: cs.CV

TL;DR: 本文提出了一种样本为中心的多任务学习框架和评估套件，用于解决工业表面缺陷检测中的样本级别决策和缺陷空间定位问题。通过实验验证，该方法有效提高了样本级别决策的可靠性和缺陷定位的完整性。


<details>
  <summary>Details</summary>
Motivation: 在实际生产线中，由于前景背景极度不平衡、缺陷稀疏且规模分布长尾以及对比度低等问题，传统的像素级训练和评估方法难以关注小型或低对比度缺陷，造成模型在样本级别的稳定性不足。因此，解决优化目标和质检决策粒度之间的不匹配问题迫在眉睫。

Method: 文章提出了一种基于共享编码器架构的样本为中心多任务学习框架，并设计了决策关联Metrics（Seg_mIoU和Seg_Recall）。该方法在联合学习样本级缺陷分类和像素级掩膜定位的同时，通过样本级监督调节特征分布，并不断提升小型及低对比度缺陷的召回率。

Result: 通过在两个基准数据集上的实验表明，所提出的方法显著提高了样本级决策的可靠性和缺陷定位的完整性。

Conclusion: 提出的样本为中心的多任务框架和评估方法能够有效解决工业表面缺陷检测中的挑战，特别是在处理小型或低对比度缺陷时提高了模型的性能。

Abstract: Industrial surface defect inspection for sample-wise quality control (QC)
must simultaneously decide whether a given sample contains defects and localize
those defects spatially. In real production lines, extreme
foreground-background imbalance, defect sparsity with a long-tailed scale
distribution, and low contrast are common. As a result, pixel-centric training
and evaluation are easily dominated by large homogeneous regions, making it
difficult to drive models to attend to small or low-contrast defects-one of the
main bottlenecks for deployment. Empirically, existing models achieve strong
pixel-overlap metrics (e.g., mIoU) but exhibit insufficient stability at the
sample level, especially for sparse or slender defects. The root cause is a
mismatch between the optimization objective and the granularity of QC
decisions. To address this, we propose a sample-centric multi-task learning
framework and evaluation suite. Built on a shared-encoder architecture, the
method jointly learns sample-level defect classification and pixel-level mask
localization. Sample-level supervision modulates the feature distribution and,
at the gradient level, continually boosts recall for small and low-contrast
defects, while the segmentation branch preserves boundary and shape details to
enhance per-sample decision stability and reduce misses. For evaluation, we
propose decision-linked metrics, Seg_mIoU and Seg_Recall, which remove the bias
of classical mIoU caused by empty or true-negative samples and tightly couple
localization quality with sample-level decisions. Experiments on two benchmark
datasets demonstrate that our approach substantially improves the reliability
of sample-level decisions and the completeness of defect localization.

</details>


### [24] [What "Not" to Detect: Negation-Aware VLMs via Structured Reasoning and Token Merging](https://arxiv.org/abs/2510.13232)
*Inha Kang,Youngsun Lim,Seonho Lee,Jiho Choi,Junsuk Choe,Hyunjung Shim*

Main category: cs.CV

TL;DR: 该研究提出一种新数据集和适应性方法来改善视觉语言模型的否定理解能力，显著提升了否定基准上的模型表现。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在理解否定时存在困难，尤其是在描述性对象检测任务中。为了解决这一问题，研究旨在通过创建一个新的数据集和适应性方法来改善模型的否定理解能力。

Method: 研究中引入了CoVAND数据集，采用系统化的思维链和VQA（视觉问答）为基础的管道生成高质量、实例化对象的否定数据。同时，提出了一种新的文本令牌合并模块NegToMe，通过在输入级维持正确的极性来解决结构性否定线索丢失的问题，并采用参数高效的LoRA微调方法进行模型集成。

Result: 实验结果表明，该方法显著降低了假阳性率，使NMS-AP在OVDEval上提升最高达+10.8点，同时表现出良好的泛化能力，适用于当前最先进的视觉语言模型。

Conclusion: 该研究通过提出两个主要贡献：新数据集管道CoVAND和轻量级适应性方案NegToMe，有效改善了当前视觉语言模型在理解否定方面的不足。实验结果表明，上述方法显著提升了模型在挑战性否定基准上的表现，有助于解决现实世界检测应用中的否定理解问题。

Abstract: State-of-the-art vision-language models (VLMs) suffer from a critical failure
in understanding negation, often referred to as affirmative bias. This
limitation is particularly severe in described object detection (DOD) tasks. To
address this, we propose two primary contributions: (1) a new dataset pipeline
and (2) a novel, lightweight adaptation recipe. First, we introduce CoVAND, a
dataset constructed with a systematic chain-of-thought (CoT) and VQA-based
pipeline to generate high-quality, instance-grounded negation data. Second, we
propose NegToMe, a novel text token merging module that directly tackles the
architectural cause of affirmative bias. NegToMe fundamentally addresses the
structural loss of negation cues in tokenization, grouping them with attributes
into coherent semantic phrases. It maintains correct polarity at the input
level, enabling robust negation understanding even with limited data. For
instance, to prevent a model from treating the fragmented tokens "not" and
"girl" as simply "girl", NegToMe binds them into a single token whose meaning
is correctly distinguished from that of "girl" alone. This module is integrated
with a parameter-efficient and strategic LoRA fine-tuning approach. Our method
significantly improves performance on challenging negation benchmarks with a
lowered false positive rate, boosting NMS-AP by up to +10.8 points on OVDEval
and demonstrating generalization to SoTA VLMs. This work marks a crucial step
forward in addressing negation understanding for real-world detection
applications.

</details>


### [25] [UniVector: Unified Vector Extraction via Instance-Geometry Interaction](https://arxiv.org/abs/2510.13234)
*Yinglong Yan,Jun Yue,Shaobo Xia,Hanmeng Sun,Tianxu Ying,Chengcheng Wu,Sifan Lan,Min He,Pedram Ghamisi,Leyuan Fang*

Main category: cs.CV

TL;DR: UniVector提出一个利用实例和几何交互的统一矢量提取框架，能够在单个模型中提取多种矢量类型，并在多结构矢量任务中达到新的技术标准。


<details>
  <summary>Details</summary>
Motivation: 现有的矢量提取方法通常针对单一类型的矢量结构，导致在处理复杂结构时的局限性，而人脑在视觉感知中同时利用语义和空间交互的能力启发了统一矢量提取框架的提出。

Method: UniVector将矢量编码为包含实例和几何信息的结构化查询，并通过交互模块进行跨层次信息交换，以提炼全局结构和关键点，通过引入动态形状约束来进一步优化矢量提取。

Result: 实验显示，UniVector在单一和多结构矢量提取任务中均设立了新的技术标准。

Conclusion: UniVector通过实例-几何交互，实现对不同矢量类型的有效提取，在复杂结构场景下展示了其优越性能。

Abstract: Vector extraction retrieves structured vector geometry from raster images,
offering high-fidelity representation and broad applicability. Existing
methods, however, are usually tailored to a single vector type (e.g., polygons,
polylines, line segments), requiring separate models for different structures.
This stems from treating instance attributes (category, structure) and
geometric attributes (point coordinates, connections) independently, limiting
the ability to capture complex structures. Inspired by the human brain's
simultaneous use of semantic and spatial interactions in visual perception, we
propose UniVector, a unified VE framework that leverages instance-geometry
interaction to extract multiple vector types within a single model. UniVector
encodes vectors as structured queries containing both instance- and
geometry-level information, and iteratively updates them through an interaction
module for cross-level context exchange. A dynamic shape constraint further
refines global structures and key points. To benchmark multi-structure
scenarios, we introduce the Multi-Vector dataset with diverse polygons,
polylines, and line segments. Experiments show UniVector sets a new state of
the art on both single- and multi-structure VE tasks. Code and dataset will be
released at https://github.com/yyyyll0ss/UniVector.

</details>


### [26] [EPIPTrack: Rethinking Prompt Modeling with Explicit and Implicit Prompts for Multi-Object Tracking](https://arxiv.org/abs/2510.13235)
*Yukuan Zhang,Jiarui Zhao,Shangqing Nie,Jin Kuang,Shengsheng Wang*

Main category: cs.CV

TL;DR: EPIPTrack, a new multimodal tracking framework, adapts to real-time target changes using explicit and implicit prompts, outperforming current methods on various datasets.


<details>
  <summary>Details</summary>
Motivation: Existing tracking methods relying on static textual descriptions from large language models lack adaptability to real-time target state changes and are prone to hallucinations.

Method: EPIPTrack leverages explicit and implicit prompts for dynamic target modeling and semantic alignment. Explicit prompts turn spatial motion information into natural language for guidance, while implicit prompts use pseudo-words with learnable descriptors for individualized knowledge representation. These undergo dynamic adjustment via CLIP text encoder. A Discriminative Feature Augmentor is designed to enhance visual and cross-modal representations.

Result: Experiments on datasets like MOT17, MOT20, and DanceTrack show that EPIPTrack outperforms existing methods, demonstrating robust adaptability and superior performance.

Conclusion: EPIPTrack outperforms existing trackers in diverse scenarios, showing robust adaptability and superior performance.

Abstract: Multimodal semantic cues, such as textual descriptions, have shown strong
potential in enhancing target perception for tracking. However, existing
methods rely on static textual descriptions from large language models, which
lack adaptability to real-time target state changes and prone to
hallucinations. To address these challenges, we propose a unified multimodal
vision-language tracking framework, named EPIPTrack, which leverages explicit
and implicit prompts for dynamic target modeling and semantic alignment.
Specifically, explicit prompts transform spatial motion information into
natural language descriptions to provide spatiotemporal guidance. Implicit
prompts combine pseudo-words with learnable descriptors to construct
individualized knowledge representations capturing appearance attributes. Both
prompts undergo dynamic adjustment via the CLIP text encoder to respond to
changes in target state. Furthermore, we design a Discriminative Feature
Augmentor to enhance visual and cross-modal representations. Extensive
experiments on MOT17, MOT20, and DanceTrack demonstrate that EPIPTrack
outperforms existing trackers in diverse scenarios, exhibiting robust
adaptability and superior performance.

</details>


### [27] [Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models](https://arxiv.org/abs/2510.13237)
*Haochuan Xu,Yun Sing Koh,Shuhuai Huang,Zirun Zhou,Di Wang,Jun Sakuma,Jingfeng Zhang*

Main category: cs.CV

TL;DR: 本文引入EDPA对抗攻击及其防御策略，测试表明其能扰乱视觉信息解释，但防御策略有效应对这一挑战。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在处理自然语言指令进行机器人任务时取得了巨大进展，但其对抗鲁棒性研究不足。本文旨在探索这一领域，提出针对VLA模型的对抗攻击和防御策略。

Method: EDPA通过破坏视觉和文本潜在表示之间的语义对齐以及最大化对抗和清洁视觉输入之间潜在表示差异，来生成对抗性贴图。防御策略通过视觉编码器细调来缓解攻击影响。

Result: EDPA攻击成功增加了最先进VLA模型任务失败率，而所提出的防御措施有效缓解了这种下降。

Conclusion: 研究表明，尽管EDPA对先进VLA模型具有显著影响，设计适宜的防御策略能够有效改善模型在对抗条件下的鲁棒性。

Abstract: Vision-Language-Action (VLA) models have achieved revolutionary progress in
robot learning, enabling robots to execute complex physical robot tasks from
natural language instructions. Despite this progress, their adversarial
robustness remains underexplored. In this work, we propose both adversarial
patch attack and corresponding defense strategies for VLA models. We first
introduce the Embedding Disruption Patch Attack (EDPA), a model-agnostic
adversarial attack that generates patches directly placeable within the
camera's view. In comparison to prior methods, EDPA can be readily applied to
different VLA models without requiring prior knowledge of the model
architecture, or the controlled robotic manipulator. EDPA constructs these
patches by (i) disrupting the semantic alignment between visual and textual
latent representations, and (ii) maximizing the discrepancy of latent
representations between adversarial and corresponding clean visual inputs.
Through the optimization of these objectives, EDPA distorts the VLA's
interpretation of visual information, causing the model to repeatedly generate
incorrect actions and ultimately result in failure to complete the given
robotic task. To counter this, we propose an adversarial fine-tuning scheme for
the visual encoder, in which the encoder is optimized to produce similar latent
representations for both clean and adversarially perturbed visual inputs.
Extensive evaluations on the widely recognized LIBERO robotic simulation
benchmark demonstrate that EDPA substantially increases the task failure rate
of cutting-edge VLA models, while our proposed defense effectively mitigates
this degradation. The codebase is accessible via the homepage at
https://edpa-attack.github.io/.

</details>


### [28] [FlyAwareV2: A Multimodal Cross-Domain UAV Dataset for Urban Scene Understanding](https://arxiv.org/abs/2510.13243)
*Francesco Barbato,Matteo Caligiuri,Pietro Zanuttigh*

Main category: cs.CV

TL;DR: FlyAwareV2是一个新的多模态数据集，用于城市场景理解，特别是无人机应用，包含真实和合成图像，以及各种环境下的标注。


<details>
  <summary>Details</summary>
Motivation: 城市环境中用于无人机(UAV)应用的计算机视觉算法的开发高度依赖于具有精确标注的大规模数据集。然而，收集和标注真实世界的无人机数据极其具有挑战性且成本高昂。

Method: 提出了FlyAwareV2，一个包含真实和合成的无人机影像的多模态数据集，并对其进行了详细的环境多样性标注和领域适应研究。

Result: FlyAwareV2数据集提供了多模态的数据，包括RGB、深度、语义标签，并支持不同的环境条件如天气变化和昼夜变化下的任务。

Conclusion: FlyAwareV2数据集为无人机基础的三维城市场景理解研究提供了重要的资源，特别是在处理合成到真实领域适应的问题时。

Abstract: The development of computer vision algorithms for Unmanned Aerial Vehicle
(UAV) applications in urban environments heavily relies on the availability of
large-scale datasets with accurate annotations. However, collecting and
annotating real-world UAV data is extremely challenging and costly. To address
this limitation, we present FlyAwareV2, a novel multimodal dataset encompassing
both real and synthetic UAV imagery tailored for urban scene understanding
tasks. Building upon the recently introduced SynDrone and FlyAware datasets,
FlyAwareV2 introduces several new key contributions: 1) Multimodal data (RGB,
depth, semantic labels) across diverse environmental conditions including
varying weather and daytime; 2) Depth maps for real samples computed via
state-of-the-art monocular depth estimation; 3) Benchmarks for RGB and
multimodal semantic segmentation on standard architectures; 4) Studies on
synthetic-to-real domain adaptation to assess the generalization capabilities
of models trained on the synthetic data. With its rich set of annotations and
environmental diversity, FlyAwareV2 provides a valuable resource for research
on UAV-based 3D urban scene understanding.

</details>


### [29] [CymbaDiff: Structured Spatial Diffusion for Sketch-based 3D Semantic Urban Scene Generation](https://arxiv.org/abs/2510.13245)
*Li Liang,Bo Miao,Xinyu Wang,Naveed Akhtar,Jordan Vice,Ajmal Mian*

Main category: cs.CV

TL;DR: 该研究介绍了SketchSem3D，首个基于抽象手绘草图和卫星图像的伪标注的大规模3D户外语义场景生成基准，并推出了大幅提升空间一致性的Cylinder Mamba Diffusion (CymbaDiff)方法。


<details>
  <summary>Details</summary>
Motivation: 生成户外3D语义场景以提高城市模拟和自动驾驶等应用领域的现实性和语义丰富度。

Method: 提出了Cylinder Mamba Diffusion (CymbaDiff)方法，利用结构化空间排序来增强场景的空间一致性，同时捕捉柱状连续性和垂直层次结构，并保留物理邻域关系和全局上下文。

Result: 实验表明，CymbaDiff在语义一致性、空间现实性和跨数据集泛化能力上表现优异。

Conclusion: 该研究提供了一个新的大规模基准和方法，提升了户外3D场景生成的质量和实用性。

Abstract: Outdoor 3D semantic scene generation produces realistic and semantically rich
environments for applications such as urban simulation and autonomous driving.
However, advances in this direction are constrained by the absence of publicly
available, well-annotated datasets. We introduce SketchSem3D, the first
large-scale benchmark for generating 3D outdoor semantic scenes from abstract
freehand sketches and pseudo-labeled annotations of satellite images.
SketchSem3D includes two subsets, Sketch-based SemanticKITTI and Sketch-based
KITTI-360 (containing LiDAR voxels along with their corresponding sketches and
annotated satellite images), to enable standardized, rigorous, and diverse
evaluations. We also propose Cylinder Mamba Diffusion (CymbaDiff) that
significantly enhances spatial coherence in outdoor 3D scene generation.
CymbaDiff imposes structured spatial ordering, explicitly captures cylindrical
continuity and vertical hierarchy, and preserves both physical neighborhood
relationships and global context within the generated scenes. Extensive
experiments on SketchSem3D demonstrate that CymbaDiff achieves superior
semantic consistency, spatial realism, and cross-dataset generalization. The
code and dataset will be available at
https://github.com/Lillian-research-hub/CymbaDiff

</details>


### [30] [Map the Flow: Revealing Hidden Pathways of Information in VideoLLMs](https://arxiv.org/abs/2510.13251)
*Minji Kim,Taekyung Kim,Bohyung Han*

Main category: cs.CV

TL;DR: 论文解析了VideoLLMs在VideoQA任务中的信息流动机制，展示了模型在时空推理中的表现及其潜在的效率提升路径。


<details>
  <summary>Details</summary>
Motivation: 尽管VideoLLMs在时空输入的处理上取得了一定进展，但其如何提取和传播视频和文本信息的内部机制仍需深度探讨。

Method: 该研究采用机制解释技术来分析VideoLLMs的内部信息流动，以理解其在视频问答（VideoQA）任务中的时空推理能力。

Result: 分析揭示了VideoLLMs在不同VideoQA任务中的一致模式，包括：1）时序推理在模型的早中层通过积极的跨帧交互开始；2）在中层进行视频和语言的逐步整合；3）整合完成后，中后层即可生成正确答案；4）通过选择有效的信息路径并抑制大量不必要的注意力边（如LLaVA-NeXT-7B-Video-FT模型中抑制了58%的注意力边），VideoLLMs可以保持其视频问答性能。

Conclusion: 该研究为VideoLLMs在时空推理上的表现提供了详细的解释，并为提高模型可解释性和下游泛化性能提供了实际见解。

Abstract: Video Large Language Models (VideoLLMs) extend the capabilities of
vision-language models to spatiotemporal inputs, enabling tasks such as video
question answering (VideoQA). Despite recent advances in VideoLLMs, their
internal mechanisms on where and how they extract and propagate video and
textual information remain less explored. In this study, we investigate the
internal information flow of VideoLLMs using mechanistic interpretability
techniques. Our analysis reveals consistent patterns across diverse VideoQA
tasks: (1) temporal reasoning in VideoLLMs initiates with active cross-frame
interactions in early-to-middle layers, (2) followed by progressive
video-language integration in middle layers. This is facilitated by alignment
between video representations and linguistic embeddings containing temporal
concepts. (3) Upon completion of this integration, the model is ready to
generate correct answers in middle-to-late layers. (4) Based on our analysis,
we show that VideoLLMs can retain their VideoQA performance by selecting these
effective information pathways while suppressing a substantial amount of
attention edges, e.g., 58% in LLaVA-NeXT-7B-Video-FT. These findings provide a
blueprint on how VideoLLMs perform temporal reasoning and offer practical
insights for improving model interpretability and downstream generalization.
Our project page with the source code is available at
https://map-the-flow.github.io

</details>


### [31] [End-to-End Multi-Modal Diffusion Mamba](https://arxiv.org/abs/2510.13253)
*Chunhao Lu,Qiang Lu,Meichen Dong,Jake Luo*

Main category: cs.CV

TL;DR: MDM是一种创新的多模态架构，通过统一的变分自编码器改善了多模态信息的处理和生成，在多个任务上表现优异并具有较高的计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态模型在处理输入输出信息时使用不同的编码器和解码器，这种分离阻碍了多模态联合表示学习。因此，为了统一多模态处理，提出了MDM架构。

Method: MDM利用基于Mamba的多步选择扩散模型，通过统一的变分自编码器逐步生成和改进特定模态信息，使得编码和解码更加统一化。

Result: 在图像生成、图像字幕生成、视觉问答、文本理解和推理任务等领域的评估中，MDM显著超越现有的端到端模型，并能有效与最新的最先进模型相竞争。

Conclusion: MDM在统一多模态处理中表现出色，并且能够与最先进的模型竞争，尽管在计算效率上保持优化的基础。

Abstract: Current end-to-end multi-modal models utilize different encoders and decoders
to process input and output information. This separation hinders the joint
representation learning of various modalities. To unify multi-modal processing,
we propose a novel architecture called MDM (Multi-modal Diffusion Mamba). MDM
utilizes a Mamba-based multi-step selection diffusion model to progressively
generate and refine modality-specific information through a unified variational
autoencoder for both encoding and decoding. This innovative approach allows MDM
to achieve superior performance when processing high-dimensional data,
particularly in generating high-resolution images and extended text sequences
simultaneously. Our evaluations in areas such as image generation, image
captioning, visual question answering, text comprehension, and reasoning tasks
demonstrate that MDM significantly outperforms existing end-to-end models
(MonoFormer, LlamaGen, and Chameleon etc.) and competes effectively with SOTA
models like GPT-4V, Gemini Pro, and Mistral. Our results validate MDM's
effectiveness in unifying multi-modal processes while maintaining computational
efficiency, establishing a new direction for end-to-end multi-modal
architectures.

</details>


### [32] [MMLongCite: A Benchmark for Evaluating Fidelity of Long-Context Vision-Language Models](https://arxiv.org/abs/2510.13276)
*Keyan Zhou,Zecheng Tang,Lingfeng Ming,Guanghao Zhou,Qiguang Chen,Dan Qiao,Zheming Yang,Libo Qin,Minghui Qiu,Juntao Li,Min Zhang*

Main category: cs.CV

TL;DR: 研究为评估大型视觉语言模型（LVLMs）在长上下文情境下的表现提出了MMLongCite基准测试，通过分析揭示了LVLMs在多模态长上下文处理中的局限性。


<details>
  <summary>Details</summary>
Motivation: 致力于解决长上下文窗口下上下文利用效率不足的问题，并弥补多模态评价局限于短上下文的不足。

Method: 引入了MMLongCite基准测试集，通过8个独特任务和6个上下文长度区间来评估LVLMs在长上下文情境下的可信度。

Result: 对LVLMs进行的评价显示，它们在处理长多模态上下文的可信度有限，并深入分析了上下文长度及关键内容位置对模型可信度的影响。

Conclusion: 当前主流的LVLMs在处理长多模态上下文时的可信度有限。

Abstract: The rapid advancement of large vision language models (LVLMs) has led to a
significant expansion of their context windows. However, an extended context
window does not guarantee the effective utilization of the context, posing a
critical challenge for real-world applications. Current evaluations of such
long-context faithfulness are predominantly focused on the text-only domain,
while multimodal assessments remain limited to short contexts. To bridge this
gap, we introduce MMLongCite, a comprehensive benchmark designed to evaluate
the fidelity of LVLMs in long-context scenarios. MMLongCite comprises 8
distinct tasks spanning 6 context length intervals and incorporates diverse
modalities, including text, images, and videos. Our evaluation of
state-of-the-art LVLMs reveals their limited faithfulness in handling long
multimodal contexts. Furthermore, we provide an in-depth analysis of how
context length and the position of crucial content affect the faithfulness of
these models.

</details>


### [33] [Automated document processing system for government agencies using DBNET++ and BART models](https://arxiv.org/abs/2510.13303)
*Aya Kaysan Bahjat*

Main category: cs.CV

TL;DR: 该自动文档分类系统有效应对复杂成像场景，以92.88%的准确率进行文本检测与分类。


<details>
  <summary>Details</summary>
Motivation: 为了检测图像中的文本内容并将文档分类为发票、报告、信件和表格四种预定义类别。

Method: 该系统的管道包括四个阶段：图像捕获和预处理、使用DBNet++进行文本检测、使用BART进行文本分类，最终集成至Python和PyQt5实现的用户界面中。

Result: 系统在模拟各种高难度场景的Total-Text数据集中，文本检测的准确率达到了约92.88%。

Conclusion: 该系统在各种成像条件下有效地对混合来源文档进行分类。

Abstract: An automatic document classification system is presented that detects textual
content in images and classifies documents into four predefined categories
(Invoice, Report, Letter, and Form). The system supports both offline images
(e.g., files on flash drives, HDDs, microSD) and real-time capture via
connected cameras, and is designed to mitigate practical challenges such as
variable illumination, arbitrary orientation, curved or partially occluded
text, low resolution, and distant text. The pipeline comprises four stages:
image capture and preprocessing, text detection [1] using a DBNet++
(Differentiable Binarization Network Plus) detector, and text classification
[2] using a BART (Bidirectional and Auto-Regressive Transformers) classifier,
all integrated within a user interface implemented in Python with PyQt5. The
achieved results by the system for text detection in images were good at about
92.88% through 10 hours on Total-Text dataset that involve high resolution
images simulate a various and very difficult challenges. The results indicate
the proposed approach is effective for practical, mixed-source document
categorization in unconstrained imaging scenarios.

</details>


### [34] [Novel Class Discovery for Point Cloud Segmentation via Joint Learning of Causal Representation and Reasoning](https://arxiv.org/abs/2510.13307)
*Yang Li,Aming Wu,Zihao Zhang,Yahong Han*

Main category: cs.CV

TL;DR: 本文提出了针对3D点云分割的新类发现任务，通过因果结构模型和联合学习方法提升了新类分割的准确性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决3D点云分割中新类发现的问题，希望通过有标签的基本类3D数据，学习能够对无标签（新类）3D数据进行分割的模型。

Method: 通过结构因果模型分析基本类表示中的隐性混杂因素，并消除这些因素，以获取基本类的因果表示。然后，通过图结构模型基本类和新类之间的因果关系，进行因果推理，实现对新类的分割。

Result: 本文提出了一种对因果表示和因果推理进行联合学习的新方法，并通过实验验证展示了这种方法在3D和2D新类发现语义分割中的优越性。

Conclusion: 本文提出的结构因果模型和联合学习方法能够有效解决3D新类点云分割的问题，促进基本类和新类之间的因果关系建模，从而提高分割性能。

Abstract: In this paper, we focus on Novel Class Discovery for Point Cloud Segmentation
(3D-NCD), aiming to learn a model that can segment unlabeled (novel) 3D classes
using only the supervision from labeled (base) 3D classes. The key to this task
is to setup the exact correlations between the point representations and their
base class labels, as well as the representation correlations between the
points from base and novel classes. A coarse or statistical correlation
learning may lead to the confusion in novel class inference. lf we impose a
causal relationship as a strong correlated constraint upon the learning
process, the essential point cloud representations that accurately correspond
to the classes should be uncovered. To this end, we introduce a structural
causal model (SCM) to re-formalize the 3D-NCD problem and propose a new method,
i.e., Joint Learning of Causal Representation and Reasoning. Specifically, we
first analyze hidden confounders in the base class representations and the
causal relationships between the base and novel classes through SCM. We devise
a causal representation prototype that eliminates confounders to capture the
causal representations of base classes. A graph structure is then used to model
the causal relationships between the base classes' causal representation
prototypes and the novel class prototypes, enabling causal reasoning from base
to novel classes. Extensive experiments and visualization results on 3D and 2D
NCD semantic segmentation demonstrate the superiorities of our method.

</details>


### [35] [InstantSfM: Fully Sparse and Parallel Structure-from-Motion](https://arxiv.org/abs/2510.13310)
*Jiankun Zhong,Zitong Zhan,Quankai Gao,Ziyu Chen,Haozhe Lou,Jiageng Mao,Ulrich Neumann,Yue Wang*

Main category: cs.CV

TL;DR: 该论文利用GPU并行计算加速SfM，取得约40倍速度提升，并保持或提升了重建精度。


<details>
  <summary>Details</summary>
Motivation: 传统的SfM方法在处理大规模场景时存在计算开销大、速度与准确性之间存在权衡的问题。

Method: 基于稀疏感知的束调整优化，将其拓展为一个统一的全球SfM框架，加速SfM管线中的BA和GP。

Result: 通过GPU并行计算加速SfM管线的关键阶段，并在大规模图像数据集上实现了高达40倍的速度提升，同时保持或提升了重建精度。

Conclusion: 使用GPU并行计算可以显著加速大规模SfM场景的处理，并且能够在提升速度的同时保持甚至提高框架的灵活性和重建精度。

Abstract: Structure-from-Motion (SfM), a method that recovers camera poses and scene
geometry from uncalibrated images, is a central component in robotic
reconstruction and simulation. Despite the state-of-the-art performance of
traditional SfM methods such as COLMAP and its follow-up work, GLOMAP, naive
CPU-specialized implementations of bundle adjustment (BA) or global positioning
(GP) introduce significant computational overhead when handling large-scale
scenarios, leading to a trade-off between accuracy and speed in SfM. Moreover,
the blessing of efficient C++-based implementations in COLMAP and GLOMAP comes
with the curse of limited flexibility, as they lack support for various
external optimization options. On the other hand, while deep learning based SfM
pipelines like VGGSfM and VGGT enable feed-forward 3D reconstruction, they are
unable to scale to thousands of input views at once as GPU memory consumption
increases sharply as the number of input views grows. In this paper, we unleash
the full potential of GPU parallel computation to accelerate each critical
stage of the standard SfM pipeline. Building upon recent advances in
sparse-aware bundle adjustment optimization, our design extends these
techniques to accelerate both BA and GP within a unified global SfM framework.
Through extensive experiments on datasets of varying scales (e.g. 5000 images
where VGGSfM and VGGT run out of memory), our method demonstrates up to about
40 times speedup over COLMAP while achieving consistently comparable or even
improved reconstruction accuracy. Our project page can be found at
https://cre185.github.io/InstantSfM/.

</details>


### [36] [Self-Augmented Visual Contrastive Decoding](https://arxiv.org/abs/2510.13315)
*Eun Woo Im,Muhammad Kashif Ali,Vivek Gupta*

Main category: cs.CV

TL;DR: 本文提出一种新的无训练解码策略，通过自增强提示策略和自适应阈值算法，有效增强了LVLMs的生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型（LVLMs）在多模态能力上表现出色，但其基础语言模型有产生幻觉的倾向。现有的视觉对比解码方法所使用的视觉增强往往与文本查询的具体上下文无关，导致效果有限。

Method: 1. 自增强提示策略：利用模型的内在知识动态对齐查询与视觉增强之间的语义。2. 自适应阈值算法：基于输出稀疏性动态调整下一个token候选集的大小，利用完全的信息对logit分布进行调整。

Result: 在四个大型视觉语言模型和七个基准测试中进行了广泛实验，证明所提出的解码方法在事实一致性方面优于先进的解码方法。

Conclusion: 整合查询相关的增强和考虑熵的解码对于提高大型视觉语言模型有效生成能力至关重要。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated remarkable multimodal
capabilities, but they inherit the tendency to hallucinate from their
underlying language models. While visual contrastive decoding has been proposed
to mitigate this issue, existing methods often apply generic visual
augmentations that disregard the specific context provided by the text query,
limiting their effectiveness. This study introduces a novel training-free
decoding strategy that addresses these limitations, featuring two key
contributions. First, a self-augmentation prompting strategy that leverages the
intrinsic knowledge of the model to dynamically align semantics between the
query and the visual augmentation. Second, an adaptive thresholding algorithm
that adaptively adjusts next token candidate size based on the output sparsity,
utilizing full information from the logit distribution. Extensive experiments
across four LVLMs and seven benchmarks demonstrate that the proposed decoding
significantly enhances factual consistency compared to state-of-the-art
decoding methods. This work highlights the importance of integrating
query-dependent augmentation and entropy-aware decoding for improving effective
generation of LVLMs.

</details>


### [37] [Visual Interestingness Decoded: How GPT-4o Mirrors Human Interests](https://arxiv.org/abs/2510.13316)
*Fitim Abdullahu,Helmut Grabner*

Main category: cs.CV

TL;DR: 研究探讨了大型多模态模型在视觉有趣性方面的潜力，发现GPT-4o与人类评价存在部分对齐，并在该领域表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 探讨大型多模态模型（LMMs）在理解视觉有趣性概念方面的潜力，并研究人类评估与领先的LMM（GPT-4o）的预测之间的对齐情况。

Method: 通过比较分析，人类评估与GPT-4o的预测进行对比，检查它们之间的对齐程度。

Result: 研究表明，人类和GPT-4o之间存在部分对齐。GPT-4o在捕捉视觉有趣性的概念上表现优于当前最先进的方法。

Conclusion: 我们的研究揭示了人类和GPT-4o之间的部分对齐情况。GPT-4o在视觉有趣性的概念捕捉上表现得比当前最先进的方法更好。这使得根据图像的有趣性进行有效标注成为可能，并将这些标注用作训练数据以提炼出学习排序模型的知识。

Abstract: Our daily life is highly influenced by what we consume and see. Attracting
and holding one's attention -- the definition of (visual) interestingness -- is
essential. The rise of Large Multimodal Models (LMMs) trained on large-scale
visual and textual data has demonstrated impressive capabilities. We explore
these models' potential to understand to what extent the concepts of visual
interestingness are captured and examine the alignment between human
assessments and GPT-4o's, a leading LMM, predictions through comparative
analysis. Our studies reveal partial alignment between humans and GPT-4o. It
already captures the concept as best compared to state-of-the-art methods.
Hence, this allows for the effective labeling of image pairs according to their
(commonly) interestingness, which are used as training data to distill the
knowledge into a learning-to-rank model. The insights pave the way for a deeper
understanding of human interest.

</details>


### [38] [DEF-YOLO: Leveraging YOLO for Concealed Weapon Detection in Thermal Imagin](https://arxiv.org/abs/2510.13326)
*Divya Bhardwaj,Arnav Ramamoorthy,Poonam Goyal*

Main category: cs.CV

TL;DR: 通过改进YOLO架构和建立新的热成像数据集，实现高效的隐藏武器检测。


<details>
  <summary>Details</summary>
Motivation: 开发一种低成本、保护隐私的实时监测解决方案，解决其他成像技术的局限性。

Method: 提出了一种新颖的方法和数据集，通过热成像进行隐藏武器检测。

Result: 建立了针对热成像隐藏武器检测的新基准，并通过大量实验验证了提出方法的有效性。

Conclusion: DEF-YOLO在热成像下的隐藏武器检测中表现出色，为进一步研究提供了新方向。

Abstract: Concealed weapon detection aims at detecting weapons hidden beneath a
person's clothing or luggage. Various imaging modalities like Millimeter Wave,
Microwave, Terahertz, Infrared, etc., are exploited for the concealed weapon
detection task. These imaging modalities have their own limitations, such as
poor resolution in microwave imaging, privacy concerns in millimeter wave
imaging, etc. To provide a real-time, 24 x 7 surveillance, low-cost, and
privacy-preserved solution, we opted for thermal imaging in spite of the lack
of availability of a benchmark dataset. We propose a novel approach and a
dataset for concealed weapon detection in thermal imagery. Our YOLO-based
architecture, DEF-YOLO, is built with key enhancements in YOLOv8 tailored to
the unique challenges of concealed weapon detection in thermal vision. We adopt
deformable convolutions at the SPPF layer to exploit multi-scale features;
backbone and neck layers to extract low, mid, and high-level features, enabling
DEF-YOLO to adaptively focus on localization around the objects in thermal
homogeneous regions, without sacrificing much of the speed and throughput. In
addition to these simple yet effective key architectural changes, we introduce
a new, large-scale Thermal Imaging Concealed Weapon dataset, TICW, featuring a
diverse set of concealed weapons and capturing a wide range of scenarios. To
the best of our knowledge, this is the first large-scale contributed dataset
for this task. We also incorporate focal loss to address the significant class
imbalance inherent in the concealed weapon detection task. The efficacy of the
proposed work establishes a new benchmark through extensive experimentation for
concealed weapon detection in thermal imagery.

</details>


### [39] [Group-Wise Optimization for Self-Extensible Codebooks in Vector Quantized Models](https://arxiv.org/abs/2510.13331)
*Hong-Kai Zheng,Piji Li*

Main category: cs.CV

TL;DR: 提出了一种名为Group-VQ的方法，通过组内优化和代码书重采样提高了代码书的利用率和图像重建性能。


<details>
  <summary>Details</summary>
Motivation: 解决VQ-VAEs中的代码书崩溃问题和代码书学习能力受限问题，从而提高重建质量。

Method: 提出Group-VQ方法，通过组内独立优化和组内联合优化提高代码书的学习能力，同时引入无训练代码书重采样方法进行代码书大小调整。

Result: Group-VQ在多种图像重建实验中表现出改进的重建性能，并通过训练后代码书采样方法实现了代码书大小调整的灵活性。

Conclusion: Group-VQ方法通过独立的组内优化和组间联合优化提高了代码书利用率与重建性能，并引入了一种无须训练的代码书重采样方法，使代码书大小可以灵活调整。

Abstract: Vector Quantized Variational Autoencoders (VQ-VAEs) leverage self-supervised
learning through reconstruction tasks to represent continuous vectors using the
closest vectors in a codebook. However, issues such as codebook collapse
persist in the VQ model. To address these issues, existing approaches employ
implicit static codebooks or jointly optimize the entire codebook, but these
methods constrain the codebook's learning capability, leading to reduced
reconstruction quality. In this paper, we propose Group-VQ, which performs
group-wise optimization on the codebook. Each group is optimized independently,
with joint optimization performed within groups. This approach improves the
trade-off between codebook utilization and reconstruction performance.
Additionally, we introduce a training-free codebook resampling method, allowing
post-training adjustment of the codebook size. In image reconstruction
experiments under various settings, Group-VQ demonstrates improved performance
on reconstruction metrics. And the post-training codebook sampling method
achieves the desired flexibility in adjusting the codebook size.

</details>


### [40] [No-Reference Rendered Video Quality Assessment: Dataset and Metrics](https://arxiv.org/abs/2510.13349)
*Sipeng Yang,Jiayu Ji,Qingchuan Zhu,Zhiyao Yang,Xiaogang Jin*

Main category: cs.CV

TL;DR: 针对渲染视频质量评价的需求，提出了新的数据集和NR-VQA指标，提升了渲染视频的质量评价准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的无参考视频质量评价（NR-VQA）方法和数据集主要关注摄像机捕获的视频，直接应用于渲染视频会导致偏差，因为渲染视频更容易出现时间伪影。

Method: 创建了一个包含主观质量注释的渲染取向视频数据集，并设计了特定于渲染视频的NR-VQA指标。

Result: 提出的NR-VQA指标在渲染视频上的表现优于现有指标，并且可以用于基准测试超采样方法和评估实时渲染中的帧生成策略。

Conclusion: 提出了一个面向渲染视频的大型数据集和相应的无参考视频质量评价（NR-VQA）指标，这一指标在渲染视频上的表现优于现有的NR-VQA指标。

Abstract: Quality assessment of videos is crucial for many computer graphics
applications, including video games, virtual reality, and augmented reality,
where visual performance has a significant impact on user experience. When test
videos cannot be perfectly aligned with references or when references are
unavailable, the significance of no-reference video quality assessment (NR-VQA)
methods is undeniable. However, existing NR-VQA datasets and metrics are
primarily focused on camera-captured videos; applying them directly to rendered
videos would result in biased predictions, as rendered videos are more prone to
temporal artifacts. To address this, we present a large rendering-oriented
video dataset with subjective quality annotations, as well as a designed NR-VQA
metric specific to rendered videos. The proposed dataset includes a wide range
of 3D scenes and rendering settings, with quality scores annotated for various
display types to better reflect real-world application scenarios. Building on
this dataset, we calibrate our NR-VQA metric to assess rendered video quality
by looking at both image quality and temporal stability. We compare our metric
to existing NR-VQA metrics, demonstrating its superior performance on rendered
videos. Finally, we demonstrate that our metric can be used to benchmark
supersampling methods and assess frame generation strategies in real-time
rendering.

</details>


### [41] [Language as a Label: Zero-Shot Multimodal Classification of Everyday Postures under Data Scarcity](https://arxiv.org/abs/2510.13364)
*MingZe Tang,Jubal Chandy Jacob*

Main category: cs.CV

TL;DR: 简单提示在高性能视觉语言模型中的效果最佳，过多描述细节反而导致性能下降；在低性能模型中，增加描述有助于处理模糊类别。


<details>
  <summary>Details</summary>
Motivation: 探讨提示设计对于识别视觉上相似的类别（如人类姿势）的影响，特别是在数据稀缺的情况下，提示具体性对零样本分类的影响尚不明确。

Method: 评估了一组现代视觉语言模型（VLMs），包括OpenCLIP、MetaCLIP 2和SigLip，采用三层级的提示设计，系统地增加语言细节。在一个小型、由COCO派生出的285张图片数据集上，调查了提示具体性如何影响坐、立、走/跑的零样本分类。

Result: 在最高性能模型（MetaCLIP 2和OpenCLIP）中，简单的提示取得了最好的结果，而添加描述细节显著降低了性能。而在较低性能的SigLip模型中，增加描述性提示在处理模糊类别时提高了分类能力。

Conclusion: 在视觉语言模型的最优表现中，最简单的提示能够取得最佳效果，增加描述细节反而会导致性能下降，即“提示过拟合”。但较低表现的模型在添加更多描述性提示时，对模糊类别的分类性能有所提升。

Abstract: Recent Vision-Language Models (VLMs) enable zero-shot classification by
aligning images and text in a shared space, a promising approach for
data-scarce conditions. However, the influence of prompt design on recognizing
visually similar categories, such as human postures, is not well understood.
This study investigates how prompt specificity affects the zero-shot
classification of sitting, standing, and walking/running on a small, 285-image
COCO-derived dataset. A suite of modern VLMs, including OpenCLIP, MetaCLIP 2,
and SigLip, were evaluated using a three-tiered prompt design that
systematically increases linguistic detail. Our findings reveal a compelling,
counter-intuitive trend: for the highest-performing models (MetaCLIP 2 and
OpenCLIP), the simplest, most basic prompts consistently achieve the best
results. Adding descriptive detail significantly degrades performance for
instance, MetaCLIP 2's multi-class accuracy drops from 68.8\% to 55.1\% a
phenomenon we term "prompt overfitting". Conversely, the lower-performing
SigLip model shows improved classification on ambiguous classes when given more
descriptive, body-cue-based prompts.

</details>


### [42] [DepthVLA: Enhancing Vision-Language-Action Models with Depth-Aware Spatial Reasoning](https://arxiv.org/abs/2510.13375)
*Tianyuan Yuan,Yicheng Liu,Chenhao Lu,Zhuoguang Chen,Tao Jiang,Hang Zhao*

Main category: cs.CV

TL;DR: DepthVLA improves spatial reasoning in vision-language-action tasks with a novel architecture incorporating depth prediction, outperforming existing models in various environments.


<details>
  <summary>Details</summary>
Motivation: The performance of current VLA models is limited in tasks requiring precise spatial reasoning due to inadequate spatial reasoning capabilities inherited from VLMs. There is a need for a VLA model that can achieve better spatial understanding without extensive action-data pretraining.

Method: The paper introduces DepthVLA, which incorporates spatial awareness through a pretrained depth prediction module and uses a mixture-of-transformers design, unifying a Vision-Language Model (VLM), a depth transformer, and an action expert with shared attentions.

Result: DepthVLA achieves significant performance improvements in both real-world and simulated environments, with higher progress rates than existing state-of-the-art approaches.

Conclusion: DepthVLA demonstrates superior performance in tasks requiring spatial reasoning, outperforming state-of-the-art VLA models.

Abstract: Vision-Language-Action (VLA) models have recently shown impressive
generalization and language-guided manipulation capabilities. However, their
performance degrades on tasks requiring precise spatial reasoning due to
limited spatial reasoning inherited from Vision-Language Models (VLMs).
Existing VLAs rely on extensive action-data pretraining to ground VLMs in 3D
space, which reduces training efficiency and is still insufficient for accurate
spatial understanding. In this work, we present DepthVLA, a simple yet
effective VLA architecture that explicitly incorporates spatial awareness
through a pretrained depth prediction module. DepthVLA adopts a
mixture-of-transformers design that unifies a VLM, a depth transformer, and an
action expert with fully shared attentions, forming an end-to-end model with
enhanced spatial reasoning. Extensive evaluations in both real-world and
simulated environments show that DepthVLA outperforms state-of-the-art
approaches, achieving 78.5% vs. 65.0% progress in real-world tasks, 94.9% vs.
93.6% in the LIBERO simulator, and 74.8% vs. 58.8% in the Simpler simulator.
Our code will be made publicly available.

</details>


### [43] [Generalizing WiFi Gesture Recognition via Large-Model-Aware Semantic Distillation and Alignment](https://arxiv.org/abs/2510.13390)
*Feng-Qi Cui,Yu-Tong Guo,Tianyue Zheng,Jinyang Huang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为GLSDA的新框架，解决了WiFi手势识别中的泛化和语义表达问题，通过大模型的语义先验提升表示学习，并在实验中展示了卓越的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的WiFi手势识别方法在通道状态信息的领域敏感性和高层次手势抽象的不足上表现出有限的泛化能力和语义表达性，为此，需要一种能够在不同领域下增强手势表示学习的框架。

Method: 本研究设计了一种双路径CSI编码管道，结合多尺度语义编码器和跨模式注意力机制进行手势表示学习，并引入语义感知的软监督和双重蒸馏策略来提升分类和模型压缩效率。

Result: 提出的GLSDA框架在Widar3.0基准上实现了在域内和跨域手势识别任务中优于当前最先进方法的性能，同时显著减少了模型大小和推理延迟。

Conclusion: GLSDA方法为实际AIoT应用中的通用射频手势接口提供了一种可扩展和易于部署的解决方案，在提高手势识别性能的同时，减少了模型复杂性。

Abstract: WiFi-based gesture recognition has emerged as a promising RF sensing paradigm
for enabling non-contact and privacy-preserving human-computer interaction in
AIoT environments. However, existing methods often suffer from limited
generalization and semantic expressiveness due to the domain-sensitive nature
of Channel State Information and the lack of high-level gesture abstraction. To
address these challenges, we propose a novel generalization framework, termed
Large-Model-Aware Semantic Distillation and Alignment (GLSDA), which leverages
the semantic prior of pre-trained large foundation models to enhance gesture
representation learning in both in-domain and cross-domain scenarios.
Specifically, we first design a dual-path CSI encoding pipeline that captures
geometric and dynamic gesture patterns via CSI-Ratio phase sequences and
Doppler spectrograms. These representations are then fed into a Multiscale
Semantic Encoder, which learns robust temporal embeddings and aligns them with
gesture semantics through cross-modal attention mechanisms. To further enhance
category discrimination, we introduce a Semantic-Aware Soft Supervision scheme
that encodes inter-class correlations and reduces label ambiguity, especially
for semantically similar gestures. Finally, we develop a Robust
Dual-Distillation strategy to compress the aligned model into a lightweight
student network, jointly distilling intermediate features and semantic-informed
soft labels from the teacher model. Extensive experiments on the Widar3.0
benchmark show that GLSDA consistently outperforms state-of-the-art methods in
both in-domain and cross-domain gesture recognition tasks, while significantly
reducing model size and inference latency. Our method offers a scalable and
deployable solution for generalized RF-based gesture interfaces in real-world
AIoT applications.

</details>


### [44] [Spatial-DISE: A Unified Benchmark for Evaluating Spatial Reasoning in Vision-Language Models](https://arxiv.org/abs/2510.13394)
*Xinmiao Huang,Qisong He,Zhenglin Huang,Boxuan Wang,Zhuoyun Li,Guangliang Cheng,Yi Dong,Xiaowei Huang*

Main category: cs.CV

TL;DR: 论文提出了Spatial-DISE，一个用于评估视觉语言模型空间推理能力的基准和数据集，揭示了现有模型与人类能力的差距，并为未来研究提供了方向。


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估空间推理能力方面不足，尤其是在评价人的固有动态空间推理能力方面匮乏。因此，作者提出了基于认知分类的统一基准Spatial-DISE以填补这一空白。

Method: 提出了一个统一基准Spatial-DISE，并开发了一个可扩展的自动化流程来生成多样化和可验证的空间推理问题，产生新的Spatial-DISE数据集，其中包括Spatial-DISE Bench和Spatial-DISE-12K，为不同的VLMs进行评估。

Result: 通过对28个最先进的视觉语言模型的综合评估表明，这些模型在空间推理任务上与人类能力仍有显著差距。

Conclusion: 当前的视觉语言模型在空间推理方面与人类能力有显著差距，特别是在多步骤、多视角的空间推理上。通过Spatial-DISE，我们为未来朝着类人空间智能的研究提供了一个稳健的框架、有价值的数据集和明确的方向。

Abstract: Spatial reasoning ability is crucial for Vision Language Models (VLMs) to
support real-world applications in diverse domains including robotics,
augmented reality, and autonomous navigation. Unfortunately, existing
benchmarks are inadequate in assessing spatial reasoning ability, especially
the \emph{intrinsic-dynamic} spatial reasoning which is a fundamental aspect of
human spatial cognition. In this paper, we propose a unified benchmark,
\textbf{Spatial-DISE}, based on a cognitively grounded taxonomy that
categorizes tasks into four fundamental quadrants:
\textbf{I}ntrinsic-\textbf{S}tatic, Intrinsic-\textbf{D}ynamic,
\textbf{E}xtrinsic-Static, and Extrinsic-Dynamic spatial reasoning. Moreover,
to address the issue of data scarcity, we develop a scalable and automated
pipeline to generate diverse and verifiable spatial reasoning questions,
resulting in a new \textbf{Spatial-DISE} dataset that includes Spatial-DISE
Bench (559 evaluation VQA pairs) and Spatial-DISE-12K (12K+ training VQA
pairs). Our comprehensive evaluation across 28 state-of-the-art VLMs reveals
that, current VLMs have a large and consistent gap to human competence,
especially on multi-step multi-view spatial reasoning. Spatial-DISE offers a
robust framework, valuable dataset, and clear direction for future research
toward human-like spatial intelligence. Benchmark, dataset, and code will be
publicly released.

</details>


### [45] [Reinforcement Learning Meets Masked Generative Models: Mask-GRPO for Text-to-Image Generation](https://arxiv.org/abs/2510.13418)
*Yifu Luo,Xinhao Hu,Keyu Fan,Haoyuan Sun,Zeyu Chen,Bo Xia,Tiantian Zhang,Yongzhe Chang,Xueqian Wang*

Main category: cs.CV

TL;DR: 提出了 Mask-GRPO 方法，将强化学习应用于掩码生成模型，取得了优于现有技术的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法多针对扩散模型或自回归模型，未充分利用掩码生成模型这一选项。本文旨在填补这一空缺。

Method: 通过重新定义转移概率和将解掩码过程建模为多步决策问题，并采用移除 KL 约束、应用减少策略和筛选低质量样本等策略，提升模型性能。

Result: 提出了 Mask-GRPO 方法，将群体相对策略优化（GRPO）强化学习融入掩码生成模型中，并在标准的文本到图像生成基准测试和偏好匹配上取得了显著改进。

Conclusion: Mask-GRPO 方法填补了强化学习在掩码生成模型领域的空白，且在实验中显示出优于当前技术的性能。

Abstract: Reinforcement learning (RL) has garnered increasing attention in
text-to-image (T2I) generation. However, most existing RL approaches are
tailored to either diffusion models or autoregressive models, overlooking an
important alternative: masked generative models. In this work, we propose
Mask-GRPO, the first method to incorporate Group Relative Policy Optimization
(GRPO)-based RL into this overlooked paradigm. Our core insight is to redefine
the transition probability, which is different from current approaches, and
formulate the unmasking process as a multi-step decision-making problem. To
further enhance our method, we explore several useful strategies, including
removing the KL constraint, applying the reduction strategy, and filtering out
low-quality samples. Using Mask-GRPO, we improve a base model, Show-o, with
substantial improvements on standard T2I benchmarks and preference alignment,
outperforming existing state-of-the-art approaches. The code is available on
https://github.com/xingzhejun/Mask-GRPO

</details>


### [46] [Ultra High-Resolution Image Inpainting with Patch-Based Content Consistency Adapter](https://arxiv.org/abs/2510.13419)
*Jianhui Zhang,Sheng Cheng,Qirui Sun,Jia Liu,Wang Luyang,Chaoyu Feng,Chen Fang,Lei Lei,Jue Wang,Shuaicheng Liu*

Main category: cs.CV

TL;DR: Patch-Adapter是一种用于高分辨率文本指导图像修复的有效框架，能够在4K+分辨率下实现精确的内容一致性和提示对齐。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于低分辨率，对于高分辨率和复杂纹理的图像修复在内容一致性和提示对齐方面的挑战加剧。因此，需要一种能够在高分辨率下实现精确修复的框架。

Method: Patch-Adapter采用两阶段适配器架构：第一阶段为双重上下文适配器，用于在降低分辨率下学习掩膜和非掩膜区域的一致性，建立整体结构一致性；第二阶段为参考补丁适配器，使用补丁级注意力机制进行全分辨率修复，通过自适应特征融合保持局部细节的逼真性。

Result: 实验表明，Patch-Adapter不仅解决了大规模修复中常见的伪影问题，还在OpenImages和Photo-Concept-Bucket数据集上的表现优于现有方法，实现了感知质量和文本提示遵从性的顶级性能。

Conclusion: Patch-Adapter框架能够在4K+的分辨率下实现精确的内容一致性和提示对齐，相较于现有方法，在感知质量和文本提示遵从性上取得了卓越的表现。

Abstract: In this work, we present Patch-Adapter, an effective framework for
high-resolution text-guided image inpainting. Unlike existing methods limited
to lower resolutions, our approach achieves 4K+ resolution while maintaining
precise content consistency and prompt alignment, two critical challenges in
image inpainting that intensify with increasing resolution and texture
complexity. Patch-Adapter leverages a two-stage adapter architecture to scale
the diffusion model's resolution from 1K to 4K+ without requiring structural
overhauls: (1) Dual Context Adapter learns coherence between masked and
unmasked regions at reduced resolutions to establish global structural
consistency; and (2) Reference Patch Adapter implements a patch-level attention
mechanism for full-resolution inpainting, preserving local detail fidelity
through adaptive feature fusion. This dual-stage architecture uniquely
addresses the scalability gap in high-resolution inpainting by decoupling
global semantics from localized refinement. Experiments demonstrate that
Patch-Adapter not only resolves artifacts common in large-scale inpainting but
also achieves state-of-the-art performance on the OpenImages and
Photo-Concept-Bucket datasets, outperforming existing methods in both
perceptual quality and text-prompt adherence.

</details>


### [47] [CoDS: Enhancing Collaborative Perception in Heterogeneous Scenarios via Domain Separation](https://arxiv.org/abs/2510.13432)
*Yushan Han,Hui Zhang,Honglei Zhang,Chuntao Ding,Yuanzhouhan Cao,Yidong Li*

Main category: cs.CV

TL;DR: CoDS是一种新型协同感知方法，通过领域分离实现异构场景中的高效特征对齐，提升了推理效率和检测精度。


<details>
  <summary>Details</summary>
Motivation: 大多数协同感知方法假设所有智能体具有相同的编码器，但在实际应用中，这一假设通常不成立。因此，现有方法通常将邻居特征与自我车辆对齐，但容易受领域差距的噪声影响，未能有效解决特征差异。此外，基于变压器的域适应模块在移动设备上推理效率低下。

Method: 提出了一种名为CoDS的协同感知方法，通过领域分离解决异构场景中的特征差异。CoDS采用两个特征对齐模块，即轻量空间通道调整器（LSCR）和通过领域分离的分布对齐（DADS）。此外，利用领域对齐互信息（DAMI）损失确保有效的特征对齐。LSCR使用轻量卷积层调整邻居特征的空间和通道维度。DADS通过编码器特定和编码器无关的领域分离模块缓解特征分布差异。

Result: 实验表明，CoDS能够有效缓解异构场景中的特征差异，并在检测精度和推理效率之间实现权衡。

Conclusion: CoDS提供了一种高效的协同感知解决方案，能够在异构场景中有效对齐特征，改善检测精度并提高推理效率。

Abstract: Collaborative perception has been proven to improve individual perception in
autonomous driving through multi-agent interaction. Nevertheless, most methods
often assume identical encoders for all agents, which does not hold true when
these models are deployed in real-world applications. To realize collaborative
perception in actual heterogeneous scenarios, existing methods usually align
neighbor features to those of the ego vehicle, which is vulnerable to noise
from domain gaps and thus fails to address feature discrepancies effectively.
Moreover, they adopt transformer-based modules for domain adaptation, which
causes the model inference inefficiency on mobile devices. To tackle these
issues, we propose CoDS, a Collaborative perception method that leverages
Domain Separation to address feature discrepancies in heterogeneous scenarios.
The CoDS employs two feature alignment modules, i.e., Lightweight
Spatial-Channel Resizer (LSCR) and Distribution Alignment via Domain Separation
(DADS). Besides, it utilizes the Domain Alignment Mutual Information (DAMI)
loss to ensure effective feature alignment. Specifically, the LSCR aligns the
neighbor feature across spatial and channel dimensions using a lightweight
convolutional layer. Subsequently, the DADS mitigates feature distribution
discrepancy with encoder-specific and encoder-agnostic domain separation
modules. The former removes domain-dependent information and the latter
captures task-related information. During training, the DAMI loss maximizes the
mutual information between aligned heterogeneous features to enhance the domain
separation process. The CoDS employs a fully convolutional architecture, which
ensures high inference efficiency. Extensive experiments demonstrate that the
CoDS effectively mitigates feature discrepancies in heterogeneous scenarios and
achieves a trade-off between detection accuracy and inference efficiency.

</details>


### [48] [Beyond Pixels: A Differentiable Pipeline for Probing Neuronal Selectivity in 3D](https://arxiv.org/abs/2510.13433)
*Pavithra Elumalai,Mohammad Bashiri,Goirik Chakrabarty,Suhas Shrinivasan,Fabian H. Sinz*

Main category: cs.CV

TL;DR: 提出了一种通过优化可变形网格的3D渲染方法，帮助研究神经元对物理可解释3D因素的选择性，尤其在猴子V4区域模型上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 为了理解视觉感官神经元如何实现稳健的感知，研究其对3D场景物理可解释因素的选择性是至关重要的。

Method: 方法采用可微的渲染管道，参数化网格变形，通过径向基函数学习偏移和尺度，从而最大化神经元响应，同时确保几何规律性。

Result: 提出了一种可微分的渲染管道，优化可变形网格，直接在3D中获得最大效应图（MEIs）。

Conclusion: 将逆向图形与系统神经科学相结合，该方法提供了一种超越传统像素方法的手段，帮助以物理基础设定、基于3D的刺激去探测神经选择性。

Abstract: Visual perception relies on inference of 3D scene properties such as shape,
pose, and lighting. To understand how visual sensory neurons enable robust
perception, it is crucial to characterize their selectivity to such physically
interpretable factors. However, current approaches mainly operate on 2D pixels,
making it difficult to isolate selectivity for physical scene properties. To
address this limitation, we introduce a differentiable rendering pipeline that
optimizes deformable meshes to obtain MEIs directly in 3D. The method
parameterizes mesh deformations with radial basis functions and learns offsets
and scales that maximize neuronal responses while enforcing geometric
regularity. Applied to models of monkey area V4, our approach enables probing
neuronal selectivity to interpretable 3D factors such as pose and lighting.
This approach bridges inverse graphics with systems neuroscience, offering a
way to probe neural selectivity with physically grounded, 3D stimuli beyond
conventional pixel-based methods.

</details>


### [49] [VIST3A: Text-to-3D by Stitching a Multi-view Reconstruction Network to a Video Generator](https://arxiv.org/abs/2510.13454)
*Hyojun Go,Dominik Narnhofer,Goutam Bhat,Prune Truong,Federico Tombari,Konrad Schindler*

Main category: cs.CV

TL;DR: 提出的VIST3A框架通过结合文本到视频生成和3D重建技术实现更优质的文本到3D生成。


<details>
  <summary>Details</summary>
Motivation: 结合视觉内容生成和3D重建的预训练模型，以实现高质量的文本到3D生成。

Method: VIST3A框架结合现代潜在文本到视频模型作为“生成器”与新的3D重建系统作为“解码器”来生成3D场景。在匹配两个组件的潜在表示后进行模型拼接，然后通过直接奖励微调进行对齐。

Result: 测试表明，与以前生成高斯斑点的文本到3D模型相比，所有的框架组合均有显著改进。选择合适的3D基础模型后，还可实现高质量的文本到点地图生成。

Conclusion: VIST3A展示了如何将现代视频生成和3D重建技术相结合，以提升文本到3D生成的质量，并引入新的适应技术以确保3D场景的一致性和逼真性。

Abstract: The rapid progress of large, pretrained models for both visual content
generation and 3D reconstruction opens up new possibilities for text-to-3D
generation. Intuitively, one could obtain a formidable 3D scene generator if
one were able to combine the power of a modern latent text-to-video model as
"generator" with the geometric abilities of a recent (feedforward) 3D
reconstruction system as "decoder". We introduce VIST3A, a general framework
that does just that, addressing two main challenges. First, the two components
must be joined in a way that preserves the rich knowledge encoded in their
weights. We revisit model stitching, i.e., we identify the layer in the 3D
decoder that best matches the latent representation produced by the
text-to-video generator and stitch the two parts together. That operation
requires only a small dataset and no labels. Second, the text-to-video
generator must be aligned with the stitched 3D decoder, to ensure that the
generated latents are decodable into consistent, perceptually convincing 3D
scene geometry. To that end, we adapt direct reward finetuning, a popular
technique for human preference alignment. We evaluate the proposed VIST3A
approach with different video generators and 3D reconstruction models. All
tested pairings markedly improve over prior text-to-3D models that output
Gaussian splats. Moreover, by choosing a suitable 3D base model, VIST3A also
enables high-quality text-to-pointmap generation.

</details>


### [50] [Through the Lens of Doubt: Robust and Efficient Uncertainty Estimation for Visual Place Recognition](https://arxiv.org/abs/2510.13464)
*Emily Miller,Michael Milford,Muhammad Burhan Hafez,SD Ramchurn,Shoaib Ehsan*

Main category: cs.CV

TL;DR: 研究提出了无需训练的三种不确定性度量指标，可以有效提升视觉位置识别的准确性，且支持实时应用。


<details>
  <summary>Details</summary>
Motivation: 视觉位置识别（VPR）在变化的视觉环境、光照条件、季节变化和视角变化中面临巨大挑战，特别是对于SLAM等需要稳健地方匹配不确定性估计的应用。

Method: 提出三种无训练的不确定性度量指标，通过分析现有VPR方法相似性得分中的统计模式估计预测信心。

Result: 实验表明，这些指标在多个VPR方法和基准数据集中表现突出，并且在计算上几乎没有开销。它们成功地在正确和错误的VPR匹配之间进行了区分，并始终优于现有方法。

Conclusion: 该研究提出的三个无训练不确定性指标有效区分了正确和错误的VPR匹配，表现优于现有方法，并能在不同环境下以较高的查准-查全性能用在实时机器人应用中。

Abstract: Visual Place Recognition (VPR) enables robots and autonomous vehicles to
identify previously visited locations by matching current observations against
a database of known places. However, VPR systems face significant challenges
when deployed across varying visual environments, lighting conditions, seasonal
changes, and viewpoints changes. Failure-critical VPR applications, such as
loop closure detection in simultaneous localization and mapping (SLAM)
pipelines, require robust estimation of place matching uncertainty. We propose
three training-free uncertainty metrics that estimate prediction confidence by
analyzing inherent statistical patterns in similarity scores from any existing
VPR method. Similarity Distribution (SD) quantifies match distinctiveness by
measuring score separation between candidates; Ratio Spread (RS) evaluates
competitive ambiguity among top-scoring locations; and Statistical Uncertainty
(SU) is a combination of SD and RS that provides a unified metric that
generalizes across datasets and VPR methods without requiring validation data
to select the optimal metric. All three metrics operate without additional
model training, architectural modifications, or computationally expensive
geometric verification. Comprehensive evaluation across nine state-of-the-art
VPR methods and six benchmark datasets confirms that our metrics excel at
discriminating between correct and incorrect VPR matches, and consistently
outperform existing approaches while maintaining negligible computational
overhead, making it deployable for real-time robotic applications across varied
environmental conditions with improved precision-recall performance.

</details>


### [51] [UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning](https://arxiv.org/abs/2510.13515)
*Tiancheng Gu,Kaicheng Yang,Kaichen Zhang,Xiang An,Ziyong Feng,Yueyi Zhang,Weidong Cai,Jiankang Deng,Lidong Bing*

Main category: cs.CV

TL;DR: 本文提出了一个增强的通用多模态嵌入模型UniME-V2，通过全局检索和多语言理解模型提升了模型在困难负例挖掘和语义区分能力上的表现，并取得了领先的实验结果。


<details>
  <summary>Details</summary>
Motivation: 现有的通用多模态嵌入模型在捕捉候选者间的细微语义差异和生成多样化负样本上存在不足，并且在区分虚假与困难负例时辨别能力有限。

Method: 本文的方法首先通过全局检索构建一个潜在的困难负例集，然后引入多语言理解模型作为判别机制（MLLM-as-a-Judge）来评估查询-候选对的语义对齐，并生成软语义匹配分数。这些分数用于困难负例挖掘，并作为软标签来缓解一对一映射的限制。最后，通过联合成对和列表优化训练的重排序模型UniME-V2-Reranker提升性能。

Result: 通过在MMEB基准和多个检索任务上的综合实验表明，本文的方法在所有任务上达到了先进的性能。

Conclusion: 本文提出了一个新的通用多模态嵌入模型UniME-V2，通过利用多语言理解模型（MLLMs）的能力来增强表示学习，改进了在捕捉候选者间细微语义差异和区分虚假与困难负例能力上的不足，并实现了多个任务上的先进性能。

Abstract: Universal multimodal embedding models are foundational to various tasks.
Existing approaches typically employ in-batch negative mining by measuring the
similarity of query-candidate pairs. However, these methods often struggle to
capture subtle semantic differences among candidates and lack diversity in
negative samples. Moreover, the embeddings exhibit limited discriminative
ability in distinguishing false and hard negatives. In this paper, we leverage
the advanced understanding capabilities of MLLMs to enhance representation
learning and present a novel Universal Multimodal Embedding (UniME-V2) model.
Our approach first constructs a potential hard negative set through global
retrieval. We then introduce the MLLM-as-a-Judge mechanism, which utilizes
MLLMs to assess the semantic alignment of query-candidate pairs and generate
soft semantic matching scores. These scores serve as a foundation for hard
negative mining, mitigating the impact of false negatives and enabling the
identification of diverse, high-quality hard negatives. Furthermore, the
semantic matching scores are used as soft labels to mitigate the rigid
one-to-one mapping constraint. By aligning the similarity matrix with the soft
semantic matching score matrix, the model learns semantic distinctions among
candidates, significantly enhancing its discriminative capacity. To further
improve performance, we propose UniME-V2-Reranker, a reranking model trained on
our mined hard negatives through a joint pairwise and listwise optimization
approach. We conduct comprehensive experiments on the MMEB benchmark and
multiple retrieval tasks, demonstrating that our method achieves
state-of-the-art performance on average across all tasks.

</details>


### [52] [High Semantic Features for the Continual Learning of Complex Emotions: a Lightweight Solution](https://arxiv.org/abs/2510.13534)
*Thibault Geoffroy,gauthier Gerspacher,Lionel Prevost*

Main category: cs.CV

TL;DR: 研究表明，动作单元作为面部肌肉动作的高语义特征在复杂情感识别中具有优越性，并达到了领先的准确率，同时保持了模型的轻量级特性。


<details>
  <summary>Details</summary>
Motivation: 在增量学习中，学习新任务时会出现灾难性遗忘旧任务的现象。为解决这一问题，本研究聚焦于复杂情感识别，希望通过学习基本情感后逐步进展至复杂情感识别。

Method: 本研究首先学习基本情感，然后逐步学习复杂情感，通过使用动作单元作为高语义特征来提高情感识别的性能。

Result: 通过使用描述面部肌肉动作的动作单元，我们的方法在逐步学习复杂、复合情感时，实现了在CFEE数据集上的0.75准确率，与最先进的结果对比也表现优良。此外，该方法提供了轻量级模型，并具有较小的内存占用。

Conclusion: 使用动作单元作为高语义特征可以有效地实现复杂情感的逐步学习，避免灾难性遗忘，同时保持模型的轻量级和高效性。

Abstract: Incremental learning is a complex process due to potential catastrophic
forgetting of old tasks when learning new ones. This is mainly due to transient
features that do not fit from task to task. In this paper, we focus on complex
emotion recognition. First, we learn basic emotions and then, incrementally,
like humans, complex emotions. We show that Action Units, describing facial
muscle movements, are non-transient, highly semantical features that outperform
those extracted by both shallow and deep convolutional neural networks. Thanks
to this ability, our approach achieves interesting results when learning
incrementally complex, compound emotions with an accuracy of 0.75 on the CFEE
dataset and can be favorably compared to state-of-the-art results. Moreover, it
results in a lightweight model with a small memory footprint.

</details>


### [53] [Accelerated Feature Detectors for Visual SLAM: A Comparative Study of FPGA vs GPU](https://arxiv.org/abs/2510.13546)
*Ruiqi Ye,Mikel Luján*

Main category: cs.CV

TL;DR: 本文比较了GPU与FPGA加速在视觉SLAM中特征检测的性能，发现不同类型的检测器在不同平台上的表现各异。


<details>
  <summary>Details</summary>
Motivation: 由于SLAM的特征检测模块常常耗时且目标平台电力有限，研究在GPU和FPGA上的加速实现以提高运行性能和能效。

Method: 本文研究了硬件加速特征检测器在视觉SLAM管道中的表现。比较了在现代SoC平台上，GPU加速的FAST、Harris和SuperPoint实现与FPGA加速的对应实现。

Result: 评估表明，对于非学习型的特征检测器如FAST和Harris，GPU实现优于FPGA实现。而对于学习型检测器如SuperPoint，FPGA实现比GPU实现表现更好，在某些数据集上具有更高的FPS。总体来说，GPU加速的V-SLAM在精度上更胜一筹。

Conclusion: 硬件加速特征检测可提高V-SLAM管道的性能，并通过减少全局调整模块的频率来改善效果。

Abstract: Feature detection is a common yet time-consuming module in Simultaneous
Localization and Mapping (SLAM) implementations, which are increasingly
deployed on power-constrained platforms, such as drones. Graphics Processing
Units (GPUs) have been a popular accelerator for computer vision in general,
and feature detection and SLAM in particular.
  On the other hand, System-on-Chips (SoCs) with integrated Field Programmable
Gate Array (FPGA) are also widely available. This paper presents the first
study of hardware-accelerated feature detectors considering a Visual SLAM
(V-SLAM) pipeline. We offer new insights by comparing the best GPU-accelerated
FAST, Harris, and SuperPoint implementations against the FPGA-accelerated
counterparts on modern SoCs (Nvidia Jetson Orin and AMD Versal).
  The evaluation shows that when using a non-learning-based feature detector
such as FAST and Harris, their GPU implementations, and the GPU-accelerated
V-SLAM can achieve better run-time performance and energy efficiency than the
FAST and Harris FPGA implementations as well as the FPGA-accelerated V-SLAM.
However, when considering a learning-based detector such as SuperPoint, its
FPGA implementation can achieve better run-time performance and energy
efficiency (up to 3.1$\times$ and 1.4$\times$ improvements, respectively) than
the GPU implementation. The FPGA-accelerated V-SLAM can also achieve comparable
run-time performance compared to the GPU-accelerated V-SLAM, with better FPS in
2 out of 5 dataset sequences. When considering the accuracy, the results show
that the GPU-accelerated V-SLAM is more accurate than the FPGA-accelerated
V-SLAM in general. Last but not least, the use of hardware acceleration for
feature detection could further improve the performance of the V-SLAM pipeline
by having the global bundle adjustment module invoked less frequently without
sacrificing accuracy.

</details>


### [54] [XD-RCDepth: Lightweight Radar-Camera Depth Estimation with Explainability-Aligned and Distribution-Aware Distillation](https://arxiv.org/abs/2510.13565)
*Huawei Sun,Zixu Wang,Xiangyuan Peng,Julius Ott,Georg Stettinger,Lorenzo Servadei,Robert Wille*

Main category: cs.CV

TL;DR: 本文提出了一种通过雷达摄像头融合进行深度估计的轻量级架构，通过知识蒸馏策略在减小模型参数的同时保持了良好的性能表现。


<details>
  <summary>Details</summary>
Motivation: 在不良环境下维持自动驾驶的深度估计需要融合雷达和摄像头提供的互补几何线索。

Method: 采用两种知识蒸馏策略：一是解释性对齐蒸馏，将教师的显著性结构转移给学生，二是深度分布蒸馏，将深度回归重新设定为离散箱的软分类。

Result: 该研究重点关注自动驾驶中的深度估计问题，通过雷达摄像头融合提供在不良条件下的几何线索。提出了一种轻量级架构XD-RCDepth，旨在减少参数同时保持准确性。

Conclusion: 通过引入知识蒸馏策略，减小了参数量（29.7%），减少了MAE（7.97%），并且实现了实时高效的准确性。

Abstract: Depth estimation remains central to autonomous driving, and radar-camera
fusion offers robustness in adverse conditions by providing complementary
geometric cues. In this paper, we present XD-RCDepth, a lightweight
architecture that reduces the parameters by 29.7% relative to the
state-of-the-art lightweight baseline while maintaining comparable accuracy. To
preserve performance under compression and enhance interpretability, we
introduce two knowledge-distillation strategies: an explainability-aligned
distillation that transfers the teacher's saliency structure to the student,
and a depth-distribution distillation that recasts depth regression as soft
classification over discretized bins. Together, these components reduce the MAE
compared with direct training with 7.97% and deliver competitive accuracy with
real-time efficiency on nuScenes and ZJU-4DRadarCam datasets.

</details>


### [55] [Fusion Meets Diverse Conditions: A High-diversity Benchmark and Baseline for UAV-based Multimodal Object Detection with Condition Cues](https://arxiv.org/abs/2510.13620)
*Chen Chen,Kangcheng Bin,Ting Hu,Jiahao Qi,Xingyue Liu,Tianpeng Liu,Zhen Liu,Yongxiang Liu,Ping Zhong*

Main category: cs.CV

TL;DR: 本文引入了一个高度多样化的数据集ATR-UMOD，并提出了提示引导的条件感知动态融合方法（PCDF），有效提高了复杂条件下的目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的数据集难以全面反映真实世界在有限成像条件下的复杂性。为了应对这一挑战，研究旨在开发一种方法，能够在复杂多变的成像条件下实现稳健的目标检测。

Method: 本文提出了一种新颖的提示引导条件感知动态融合方法（PCDF），通过利用已标注的条件线索自适应地重新分配多模态贡献。该方法将成像条件编码为文本提示，并通过特定任务的软门控转换有效建模条件与多模态贡献之间的关系。此外，引入了一种提示引导的条件解耦模块，以确保在无条件注释的情况下的适用性。

Result: 在ATR-UMOD数据集上的实验结果表明，所提出的PCDF方法表现出色，能够有效提高目标检测性能。

Conclusion: 提出的新方法（PCDF）在面对复杂的成像条件时能够有效地调整多媒体贡献，提高了目标检测的性能。

Abstract: Unmanned aerial vehicles (UAV)-based object detection with visible (RGB) and
infrared (IR) images facilitates robust around-the-clock detection, driven by
advancements in deep learning techniques and the availability of high-quality
dataset. However, the existing dataset struggles to fully capture real-world
complexity for limited imaging conditions. To this end, we introduce a
high-diversity dataset ATR-UMOD covering varying scenarios, spanning altitudes
from 80m to 300m, angles from 0{\deg} to 75{\deg}, and all-day, all-year time
variations in rich weather and illumination conditions. Moreover, each RGB-IR
image pair is annotated with 6 condition attributes, offering valuable
high-level contextual information. To meet the challenge raised by such diverse
conditions, we propose a novel prompt-guided condition-aware dynamic fusion
(PCDF) to adaptively reassign multimodal contributions by leveraging annotated
condition cues. By encoding imaging conditions as text prompts, PCDF
effectively models the relationship between conditions and multimodal
contributions through a task-specific soft-gating transformation. A
prompt-guided condition-decoupling module further ensures the availability in
practice without condition annotations. Experiments on ATR-UMOD dataset reveal
the effectiveness of PCDF.

</details>


### [56] [Local-Global Context-Aware and Structure-Preserving Image Super-Resolution](https://arxiv.org/abs/2510.13649)
*Sanchar Palit,Subhasis Chaudhuri,Biplab Banerjee*

Main category: cs.CV

TL;DR: 本文提出了一种上下文精确的图像超分辨率框架，通过本地-全局上下文感知注意力机制和分布与感知对齐的条件机制，提高感知保真度，实验结果显示方法有效。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像处理任务中取得了显著成功，尤其是在超分辨率和感知质量增强方面。然而，一些现有方法在处理多样化且高度降解的图像时表现不佳，会导致噪声放大或内容生成错误，因此需要一种改进的框架来解决这些限制。

Method: 本文提出了一个框架，使用本地-全局上下文感知注意力机制来维护像素关系，并引入分布与感知对齐的条件机制来捕获像素级别的细粒度表示，逐步保留和优化结构信息，从而在推断过程中生成高质量图像。

Result: 所提出的方法在多个超分辨率基准测试中表现出色，生成的图像在高保真度和感知精度方面达到了高水平重构效果。

Conclusion: 通过使用本地-全局上下文感知注意力和在像素空间中引入分布与感知对齐的条件机制，本文的方法在保持高保真度和感知准确性方面取得了显著的效果，特别是在生成结构一致的高质量图像方面。

Abstract: Diffusion models have recently achieved significant success in various image
manipulation tasks, including image super-resolution and perceptual quality
enhancement. Pretrained text-to-image models, such as Stable Diffusion, have
exhibited strong capabilities in synthesizing realistic image content, which
makes them particularly attractive for addressing super-resolution tasks. While
some existing approaches leverage these models to achieve state-of-the-art
results, they often struggle when applied to diverse and highly degraded
images, leading to noise amplification or incorrect content generation. To
address these limitations, we propose a contextually precise image
super-resolution framework that effectively maintains both local and global
pixel relationships through Local-Global Context-Aware Attention, enabling the
generation of high-quality images. Furthermore, we propose a distribution- and
perceptual-aligned conditioning mechanism in the pixel space to enhance
perceptual fidelity. This mechanism captures fine-grained pixel-level
representations while progressively preserving and refining structural
information, transitioning from local content details to the global structural
composition. During inference, our method generates high-quality images that
are structurally consistent with the original content, mitigating artifacts and
ensuring realistic detail restoration. Extensive experiments on multiple
super-resolution benchmarks demonstrate the effectiveness of our approach in
producing high-fidelity, perceptually accurate reconstructions.

</details>


### [57] [EditCast3D: Single-Frame-Guided 3D Editing with Video Propagation and View Selection](https://arxiv.org/abs/2510.13652)
*Huaizhi Qu,Ruichen Zhang,Shuqing Luo,Luchao Qi,Zhihao Zhang,Xiaoming Liu,Roni Sengupta,Tianlong Chen*

Main category: cs.CV

TL;DR: EditCast3D通过视频生成模型实现单帧编辑传播至所有视图，优化3D重建过程，提高编辑效率和质量。


<details>
  <summary>Details</summary>
Motivation: 基础模型的最新进展在图像编辑方面取得了显著进步，但在3D编辑的扩展尚未得到充分探索。

Method: EditCast3D管道利用视频生成基础模型，在重建之前将编辑从单个首帧传播到整个数据集，同时引入视图选择策略以识别一致且适合重建的视图。

Result: EditCast3D在常用的3D编辑数据集上进行了评估，与最先进的3D编辑基线进行比较，显示出优越的编辑质量和高效率。

Conclusion: EditCast3D被确立为将基础模型集成到3D编辑管道中的可扩展且通用的范式。

Abstract: Recent advances in foundation models have driven remarkable progress in image
editing, yet their extension to 3D editing remains underexplored. A natural
approach is to replace the image editing modules in existing workflows with
foundation models. However, their heavy computational demands and the
restrictions and costs of closed-source APIs make plugging these models into
existing iterative editing strategies impractical. To address this limitation,
we propose EditCast3D, a pipeline that employs video generation foundation
models to propagate edits from a single first frame across the entire dataset
prior to reconstruction. While editing propagation enables dataset-level
editing via video models, its consistency remains suboptimal for 3D
reconstruction, where multi-view alignment is essential. To overcome this,
EditCast3D introduces a view selection strategy that explicitly identifies
consistent and reconstruction-friendly views and adopts feedforward
reconstruction without requiring costly refinement. In combination, the
pipeline both minimizes reliance on expensive image editing and mitigates
prompt ambiguities that arise when applying foundation models independently
across images. We evaluate EditCast3D on commonly used 3D editing datasets and
compare it against state-of-the-art 3D editing baselines, demonstrating
superior editing quality and high efficiency. These results establish
EditCast3D as a scalable and general paradigm for integrating foundation models
into 3D editing pipelines. The code is available at
https://github.com/UNITES-Lab/EditCast3D

</details>


### [58] [OmniGaze: Reward-inspired Generalizable Gaze Estimation In The Wild](https://arxiv.org/abs/2510.13660)
*Hongyu Qu,Jianan Wei,Xiangbo Shu,Yazhou Yao,Wenguan Wang,Jinhui Tang*

Main category: cs.CV

TL;DR: OmniGaze is a semi-supervised 3D gaze estimation framework that generalizes well across diverse domains by utilizing large-scale unlabeled data to mitigate domain bias, showing state-of-the-art performance and robust zero-shot generalization.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this work is the struggle of current 3D gaze estimation methods to generalize across diverse data domains, primarily due to the scarcity of annotated datasets and insufficient diversity in labeled data.

Method: The method involves building a diverse collection of unlabeled facial images and applying a semi-supervised framework called OmniGaze, which uses pseudo-labeling. A reward model assesses the reliability of pseudo labels by incorporating visual embeddings and semantic cues, which are used to compute confidence scores. These scores help in selecting and weighting pseudo labels for loss computation.

Result: Extensive experiments show that OmniGaze achieves state-of-the-art performance on five datasets in both in-domain and cross-domain settings, and demonstrates robust zero-shot generalization on four unseen datasets.

Conclusion: OmniGaze significantly improves 3D gaze estimation by utilizing large-scale unlabeled data to mitigate domain bias and offers robust generalization in both in-domain and cross-domain settings with state-of-the-art performance.

Abstract: Current 3D gaze estimation methods struggle to generalize across diverse data
domains, primarily due to i) the scarcity of annotated datasets, and ii) the
insufficient diversity of labeled data. In this work, we present OmniGaze, a
semi-supervised framework for 3D gaze estimation, which utilizes large-scale
unlabeled data collected from diverse and unconstrained real-world environments
to mitigate domain bias and generalize gaze estimation in the wild. First, we
build a diverse collection of unlabeled facial images, varying in facial
appearances, background environments, illumination conditions, head poses, and
eye occlusions. In order to leverage unlabeled data spanning a broader
distribution, OmniGaze adopts a standard pseudo-labeling strategy and devises a
reward model to assess the reliability of pseudo labels. Beyond pseudo labels
as 3D direction vectors, the reward model also incorporates visual embeddings
extracted by an off-the-shelf visual encoder and semantic cues from gaze
perspective generated by prompting a Multimodal Large Language Model to compute
confidence scores. Then, these scores are utilized to select high-quality
pseudo labels and weight them for loss computation. Extensive experiments
demonstrate that OmniGaze achieves state-of-the-art performance on five
datasets under both in-domain and cross-domain settings. Furthermore, we also
evaluate the efficacy of OmniGaze as a scalable data engine for gaze
estimation, which exhibits robust zero-shot generalization on four unseen
datasets.

</details>


### [59] [CanvasMAR: Improving Masked Autoregressive Video Generation With Canvas](https://arxiv.org/abs/2510.13669)
*Zian Li,Muhan Zhang*

Main category: cs.CV

TL;DR: CanvasMAR引入了画布机制和无分类器引导，解决了视频生成中的慢启动和错误积累问题。


<details>
  <summary>Details</summary>
Motivation: 解决视频生成慢启动和错误积累的问题，改进视频生成模型的性能。

Method: CanvasMAR模型采用画布机制为每一帧提供模糊的整体预测，并引入空间和时间条件的无分类器引导。通过噪音增强画布以提高生成鲁棒性。

Result: 在BAIR和Kinetics-600基准测试中，CanvasMAR模型通过较少的自回归步骤生成高质量视频，表现优于同类自回归模型，并与扩散方法相媲美。

Conclusion: CanvasMAR能有效提高视频生成的质量和效率，在当前基准测试中表现优秀。

Abstract: Masked autoregressive models (MAR) have recently emerged as a powerful
paradigm for image and video generation, combining the flexibility of masked
modeling with the potential of continuous tokenizer. However, video MAR models
suffer from two major limitations: the slow-start problem, caused by the lack
of a structured global prior at early sampling stages, and error accumulation
across the autoregression in both spatial and temporal dimensions. In this
work, we propose CanvasMAR, a novel video MAR model that mitigates these issues
by introducing a canvas mechanism--a blurred, global prediction of the next
frame, used as the starting point for masked generation. The canvas provides
global structure early in sampling, enabling faster and more coherent frame
synthesis. Furthermore, we introduce compositional classifier-free guidance
that jointly enlarges spatial (canvas) and temporal conditioning, and employ
noise-based canvas augmentation to enhance robustness. Experiments on the BAIR
and Kinetics-600 benchmarks demonstrate that CanvasMAR produces high-quality
videos with fewer autoregressive steps. Our approach achieves remarkable
performance among autoregressive models on Kinetics-600 dataset and rivals
diffusion-based methods.

</details>


### [60] [Seeing and Knowing in the Wild: Open-domain Visual Entity Recognition with Large-scale Knowledge Graphs via Contrastive Learning](https://arxiv.org/abs/2510.13675)
*Hongkuan Zhou,Lavdim Halilaj,Sebastian Monka,Stefan Schmid,Yuqicheng Zhu,Jingcheng Wu,Nadeem Nazer,Steffen Staab*

Main category: cs.CV

TL;DR: KnowCoL框架通过结合视觉和文本信息及Wikidata知识，提高开放域视觉实体识别的准确性，尤其在稀有和未见实体方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 由于有限的监督、高度的视觉模糊性和语义消歧的需求，开放域视觉实体识别是一项挑战性任务。

Method: 提出了一种名为KnowCoL的知识引导对比学习框架，将图像和文本描述结合到由Wikidata结构化信息支撑的共享语义空间中。

Result: 实验表明，通过结合视觉、文本和结构化知识，KnowCoL在识别稀有和未见实体方面的准确性提高，最小模型在识别未见实体的准确度上提高了10.5%。

Conclusion: KnowCoL框架通过将视觉和文本描述结合为共享语义空间，显著提高了稀有和未见实体的识别准确性。

Abstract: Open-domain visual entity recognition aims to identify and link entities
depicted in images to a vast and evolving set of real-world concepts, such as
those found in Wikidata. Unlike conventional classification tasks with fixed
label sets, it operates under open-set conditions, where most target entities
are unseen during training and exhibit long-tail distributions. This makes the
task inherently challenging due to limited supervision, high visual ambiguity,
and the need for semantic disambiguation. In this work, we propose a
Knowledge-guided Contrastive Learning (KnowCoL) framework that combines both
images and text descriptions into a shared semantic space grounded by
structured information from Wikidata. By abstracting visual and textual inputs
to a conceptual level, the model leverages entity descriptions, type
hierarchies, and relational context to support zero-shot entity recognition. We
evaluate our approach on the OVEN benchmark, a large-scale open-domain visual
recognition dataset with Wikidata IDs as the label space. Our experiments show
that using visual, textual, and structured knowledge greatly improves accuracy,
especially for rare and unseen entities. Our smallest model improves the
accuracy on unseen entities by 10.5% compared to the state-of-the-art, despite
being 35 times smaller.

</details>


### [61] [FlashWorld: High-quality 3D Scene Generation within Seconds](https://arxiv.org/abs/2510.13678)
*Xinyang Li,Tengfei Wang,Zixiao Gu,Shengchuan Zhang,Chunchao Guo,Liujuan Cao*

Main category: cs.CV

TL;DR: FlashWorld advances 3D scene generation by being 10-100 times faster and offering superior rendering quality through a novel approach combining dual-mode pre-training and cross-mode post-training.


<details>
  <summary>Details</summary>
Motivation: The motivation is to overcome the limitations of conventional multi-view-oriented models that are slower and produce lower quality renderings, by developing a faster and higher-quality 3D scene generation model.

Method: The method involves shifting from a multi-view-oriented approach to a 3D-oriented approach, incorporating a dual-mode pre-training phase and a cross-mode post-training distillation. It uses a video diffusion model and a proposed strategy for enhancing model generalization.

Result: FlashWorld achieves 10-100 times faster generation of 3D scenes while maintaining or surpassing the rendering quality of previous models. It successfully bridges the quality gap in 3D-oriented generation and enhances generalization to diverse inputs.

Conclusion: FlashWorld demonstrates a significant improvement in generating 3D scenes from single images or texts, providing superior rendering quality and speed compared to previous models.

Abstract: We propose FlashWorld, a generative model that produces 3D scenes from a
single image or text prompt in seconds, 10~100$\times$ faster than previous
works while possessing superior rendering quality. Our approach shifts from the
conventional multi-view-oriented (MV-oriented) paradigm, which generates
multi-view images for subsequent 3D reconstruction, to a 3D-oriented approach
where the model directly produces 3D Gaussian representations during multi-view
generation. While ensuring 3D consistency, 3D-oriented method typically suffers
poor visual quality. FlashWorld includes a dual-mode pre-training phase
followed by a cross-mode post-training phase, effectively integrating the
strengths of both paradigms. Specifically, leveraging the prior from a video
diffusion model, we first pre-train a dual-mode multi-view diffusion model,
which jointly supports MV-oriented and 3D-oriented generation modes. To bridge
the quality gap in 3D-oriented generation, we further propose a cross-mode
post-training distillation by matching distribution from consistent 3D-oriented
mode to high-quality MV-oriented mode. This not only enhances visual quality
while maintaining 3D consistency, but also reduces the required denoising steps
for inference. Also, we propose a strategy to leverage massive single-view
images and text prompts during this process to enhance the model's
generalization to out-of-distribution inputs. Extensive experiments demonstrate
the superiority and efficiency of our method.

</details>


### [62] [Generating healthy counterfactuals with denoising diffusion bridge models](https://arxiv.org/abs/2510.13684)
*Ana Lawry Aguila,Peirong Liu,Marina Crespo Aguirre,Juan Eugenio Iglesias*

Main category: cs.CV

TL;DR: 首次提出了去噪扩散桥模型(DDBM)用于医学图像生成，优于以往方法。


<details>
  <summary>Details</summary>
Motivation: 生成健康对照图像在医学成像中具有重要意义，能够有效检测异常或应用于为健康扫描设计的分析工具。然而，如何在去除异常的同时保留个体特异性特征是个挑战。

Method: 我们提出了一种新的去噪扩散桥模型(DDBM)应用，其条件不仅基于初始健康图像，还基于最终合成生成的病理图像，通过将病理图像作为结构性信息的先验来指导扩散过程。

Result: 实验结果表明，DDBM模型在分割和异常检测任务中的表现优于之前的扩散模型和完全监督的方法。

Conclusion: 我们的DDBM模型在分割和异常检测任务中表现优于先前提出的扩散模型和完全监督的方法。

Abstract: Generating healthy counterfactuals from pathological images holds significant
promise in medical imaging, e.g., in anomaly detection or for application of
analysis tools that are designed for healthy scans. These counterfactuals
should represent what a patient's scan would plausibly look like in the absence
of pathology, preserving individual anatomical characteristics while modifying
only the pathological regions. Denoising diffusion probabilistic models (DDPMs)
have become popular methods for generating healthy counterfactuals of pathology
data. Typically, this involves training on solely healthy data with the
assumption that a partial denoising process will be unable to model disease
regions and will instead reconstruct a closely matched healthy counterpart.
More recent methods have incorporated synthetic pathological images to better
guide the diffusion process. However, it remains challenging to guide the
generative process in a way that effectively balances the removal of anomalies
with the retention of subject-specific features. To solve this problem, we
propose a novel application of denoising diffusion bridge models (DDBMs) -
which, unlike DDPMs, condition the diffusion process not only on the initial
point (i.e., the healthy image), but also on the final point (i.e., a
corresponding synthetically generated pathological image). Treating the
pathological image as a structurally informative prior enables us to generate
counterfactuals that closely match the patient's anatomy while selectively
removing pathology. The results show that our DDBM outperforms previously
proposed diffusion models and fully supervised approaches at segmentation and
anomaly detection tasks.

</details>


### [63] [Risk-adaptive Activation Steering for Safe Multimodal Large Language Models](https://arxiv.org/abs/2510.13698)
*Jonghyun Park,Minhyuk Seo,Jonghyun Choi*

Main category: cs.CV

TL;DR: RAS方法通过增强跨模态注意力来实现安全对齐，减少了攻击成功率并提高了推理速度。


<details>
  <summary>Details</summary>
Motivation: 现代AI模型面临的主要挑战之一是确保能够对良性查询提供有帮助的回答，同时拒绝恶意查询。

Method: 提出了查询重构以增强对安全关键图像区域的跨模态注意力，从而实现风险自适应激活引导（RAS），以在查询层面对风险进行准确评估并自适应地引导激活生成安全且有帮助的响应。

Result: 通过在多个以多模态安全性和效用为基准的实验中证实，RAS显著减少了攻击成功率，保持了一般任务性能，并提高了推理速度。

Conclusion: RAS在不牺牲推理速度和减少误拒绝良性查询的情况下，有效提高了模型的安全对齐性。

Abstract: One of the key challenges of modern AI models is ensuring that they provide
helpful responses to benign queries while refusing malicious ones. But often,
the models are vulnerable to multimodal queries with harmful intent embedded in
images. One approach for safety alignment is training with extensive safety
datasets at the significant costs in both dataset curation and training.
Inference-time alignment mitigates these costs, but introduces two drawbacks:
excessive refusals from misclassified benign queries and slower inference speed
due to iterative output adjustments. To overcome these limitations, we propose
to reformulate queries to strengthen cross-modal attention to safety-critical
image regions, enabling accurate risk assessment at the query level. Using the
assessed risk, it adaptively steers activations to generate responses that are
safe and helpful without overhead from iterative output adjustments. We call
this Risk-adaptive Activation Steering (RAS). Extensive experiments across
multiple benchmarks on multimodal safety and utility demonstrate that the RAS
significantly reduces attack success rates, preserves general task performance,
and improves inference speed over prior inference-time defenses.

</details>


### [64] [MVCustom: Multi-View Customized Diffusion via Geometric Latent Rendering and Completion](https://arxiv.org/abs/2510.13702)
*Minjung Shin,Hyunin Cho,Sooyeon Go,Jin-Hwa Kim,Youngjung Uh*

Main category: cs.CV

TL;DR: 论文提出了一种名为MVCustom的框架，能在实现多视图摄像机姿态控制的同时，进行定制化生成。


<details>
  <summary>Details</summary>
Motivation: 现有多视图生成模型不支持具有几何一致性的定制，而定制模型缺乏明确的视点控制机制。现有模型难以泛化到多样化的提示。

Method: MVCustom是一个基于扩散的框架，使用特征场表示学习主体的身份和几何形态，并通过密集时空注意增强的文本转视频扩散骨干，加强时序一致性以实现多视图一致性。在推理阶段，引入深度感知特征渲染和一致性感知潜在完成技术。

Result: MVCustom是唯一同时实现真实多视图生成和定制化的框架。

Conclusion: 通过实验验证，MVCustom框架能够同时实现多视图生成和定制化，并保持几何和透视一致性。

Abstract: Multi-view generation with camera pose control and prompt-based customization
are both essential elements for achieving controllable generative models.
However, existing multi-view generation models do not support customization
with geometric consistency, whereas customization models lack explicit
viewpoint control, making them challenging to unify. Motivated by these gaps,
we introduce a novel task, multi-view customization, which aims to jointly
achieve multi-view camera pose control and customization. Due to the scarcity
of training data in customization, existing multi-view generation models, which
inherently rely on large-scale datasets, struggle to generalize to diverse
prompts. To address this, we propose MVCustom, a novel diffusion-based
framework explicitly designed to achieve both multi-view consistency and
customization fidelity. In the training stage, MVCustom learns the subject's
identity and geometry using a feature-field representation, incorporating the
text-to-video diffusion backbone enhanced with dense spatio-temporal attention,
which leverages temporal coherence for multi-view consistency. In the inference
stage, we introduce two novel techniques: depth-aware feature rendering
explicitly enforces geometric consistency, and consistent-aware latent
completion ensures accurate perspective alignment of the customized subject and
surrounding backgrounds. Extensive experiments demonstrate that MVCustom is the
only framework that simultaneously achieves faithful multi-view generation and
customization.

</details>


### [65] [Circle of Willis Centerline Graphs: A Dataset and Baseline Algorithm](https://arxiv.org/abs/2510.13720)
*Fabio Musio,Norman Juchler,Kaiyuan Yang,Suprosanna Shit,Chinmay Prabhakar,Bjoern Menze,Sven Hirsch*

Main category: cs.CV

TL;DR: 研究开发了一种基于瘦化和U-Net的中心线提取算法，有效提高了Willis环复杂结构的中心线提取的准确性和特征稳健性。


<details>
  <summary>Details</summary>
Motivation: 现有的骨架化技术难以从复杂几何结构的Willis环中提取可靠的中心线，且公开的中心线数据集较少。

Method: 使用了一个基于瘦化的骨架化算法，从TopCoW数据集提取和策划中心线图和形态特征，结合U-Net的骨架化方法与A*图连接开发了一种基准算法。

Result: 基准算法在图拓扑重构中表现出高准确性（F1 = 1），特征如段半径、长度和分叉比率表现出良好的稳健性，且平均相对误差低于5%。

Conclusion: 学习型骨架化结合图连接的方法能够实现具有解剖学合理性的中心线提取。

Abstract: The Circle of Willis (CoW) is a critical network of arteries in the brain,
often implicated in cerebrovascular pathologies. Voxel-level segmentation is an
important first step toward an automated CoW assessment, but a full
quantitative analysis requires centerline representations. However,
conventional skeletonization techniques often struggle to extract reliable
centerlines due to the CoW's complex geometry, and publicly available
centerline datasets remain scarce. To address these challenges, we used a
thinning-based skeletonization algorithm to extract and curate centerline
graphs and morphometric features from the TopCoW dataset, which includes 200
stroke patients, each imaged with MRA and CTA. The curated graphs were used to
develop a baseline algorithm for centerline and feature extraction, combining
U-Net-based skeletonization with A* graph connection. Performance was evaluated
on a held-out test set, focusing on anatomical accuracy and feature robustness.
Further, we used the extracted features to predict the frequency of fetal PCA
variants, confirm theoretical bifurcation optimality relations, and detect
subtle modality differences. The baseline algorithm consistently reconstructed
graph topology with high accuracy (F1 = 1), and the average Euclidean node
distance between reference and predicted graphs was below one voxel. Features
such as segment radius, length, and bifurcation ratios showed strong
robustness, with median relative errors below 5% and Pearson correlations above
0.95. Our results demonstrate the utility of learning-based skeletonization
combined with graph connection for anatomically plausible centerline
extraction. We emphasize the importance of going beyond simple voxel-based
measures by evaluating anatomical accuracy and feature robustness. The dataset
and baseline algorithm have been released to support further method development
and clinical research.

</details>


### [66] [LiFMCR: Dataset and Benchmark for Light Field Multi-Camera Registration](https://arxiv.org/abs/2510.13729)
*Aymeric Fleith,Julian Zirbel,Daniel Cremers,Niclas Zeller*

Main category: cs.CV

TL;DR: LiFMCR数据集通过提供多相机同步图像和精准的姿态数据，支持多视图光场处理的可靠评估。


<details>
  <summary>Details</summary>
Motivation: 现有光场数据集通常仅限于单相机设置，缺乏外部的真实数据，难以有效进行多相机光场注册方法的评估。

Method: 基于RANSAC的跨视点云3D变换估计和从单光场图像估算外部6自由度姿态的全光学PnP算法，这两种方法显式整合了全光学相机模型，实现了准确可扩展的多相机注册。

Result: LiFMCR数据集提供了从两个高分辨率Raytrix R32全光学相机同步的图像序列，并结合由Vicon运动捕捉系统记录的高精度6自由度姿态。这种独特的组合使多相机光场注册方法的严格评估成为可能。

Conclusion: 通过实验验证了两种注册方法的强力与真实数据的对齐，证明了使用LiFMCR数据集进行多相机光场注册是有效和可靠的。

Abstract: We present LiFMCR, a novel dataset for the registration of multiple micro
lens array (MLA)-based light field cameras. While existing light field datasets
are limited to single-camera setups and typically lack external ground truth,
LiFMCR provides synchronized image sequences from two high-resolution Raytrix
R32 plenoptic cameras, together with high-precision 6-degrees of freedom (DoF)
poses recorded by a Vicon motion capture system. This unique combination
enables rigorous evaluation of multi-camera light field registration methods.
  As a baseline, we provide two complementary registration approaches: a robust
3D transformation estimation via a RANSAC-based method using cross-view point
clouds, and a plenoptic PnP algorithm estimating extrinsic 6-DoF poses from
single light field images. Both explicitly integrate the plenoptic camera
model, enabling accurate and scalable multi-camera registration. Experiments
show strong alignment with the ground truth, supporting reliable multi-view
light field processing.
  Project page: https://lifmcr.github.io/

</details>


### [67] [UniCalli: A Unified Diffusion Framework for Column-Level Generation and Recognition of Chinese Calligraphy](https://arxiv.org/abs/2510.13745)
*Tianshuo Xu,Kai Wang,Zhifei Chen,Leyi Wu,Tianshui Wen,Fei Chao,Ying-Cong Chen*

Main category: cs.CV

TL;DR: UniCalli是一种用于汉字书法的统一扩散框架，能够改善字符识别和生成质量，在数据有限的情况下尤其有效。


<details>
  <summary>Details</summary>
Motivation: 当前的计算复制方法要么专注于单独的高质量字符，忽略了页级美学，例如连字和间距；要么尝试组合页，但在书法正确性上有欠缺。

Method: 单元扩散框架，用于柱级识别和生成，同时训练两个任务，以保持字符结构，并提供样式和布局先验。

Result: 模型在生成质量上达到最先进水平，具备卓越的连字连续性和布局保真度，并且识别能力更强。

Conclusion: 该框架成功扩展至其他古代脚本，包括甲骨文和埃及象形文字。

Abstract: Computational replication of Chinese calligraphy remains challenging.
Existing methods falter, either creating high-quality isolated characters while
ignoring page-level aesthetics like ligatures and spacing, or attempting page
synthesis at the expense of calligraphic correctness. We introduce
\textbf{UniCalli}, a unified diffusion framework for column-level recognition
and generation. Training both tasks jointly is deliberate: recognition
constrains the generator to preserve character structure, while generation
provides style and layout priors. This synergy fosters concept-level
abstractions that improve both tasks, especially in limited-data regimes. We
curated a dataset of over 8,000 digitized pieces, with ~4,000 densely
annotated. UniCalli employs asymmetric noising and a rasterized box map for
spatial priors, trained on a mix of synthetic, labeled, and unlabeled data. The
model achieves state-of-the-art generative quality with superior ligature
continuity and layout fidelity, alongside stronger recognition. The framework
successfully extends to other ancient scripts, including Oracle bone
inscriptions and Egyptian hieroglyphs. Code and data can be viewed in
\href{https://github.com/EnVision-Research/UniCalli}{this URL}.

</details>


### [68] [InteractiveOmni: A Unified Omni-modal Model for Audio-Visual Multi-turn Dialogue](https://arxiv.org/abs/2510.13747)
*Wenwen Tong,Hewei Guo,Dongchuan Ran,Jiangnan Chen,Jiefan Lu,Kaibin Wang,Keqiang Li,Xiaoxu Zhu,Jiakui Li,Kehan Li,Xueheng Li,Lumin Li,Chenxu Guo,Jiasheng Zhou,Jiandong Chen,Xianye Wu,Jiahao Wang,Silei Wu,Lei Chen,Hanming Deng,Yuxuan Song,Dinghao Zhou,Guiping Zhong,Ken Zheng,Shiyin Kang,Lewei Lu*

Main category: cs.CV

TL;DR: InteractiveOmni是一个开源轻量级多模态大模型，在音视频多轮交互中表现出色，特别是在长时记忆能力上大幅领先，并提供下一代智能交互系统的基础。


<details>
  <summary>Details</summary>
Motivation: 设计一个轻量级大模型以实现全面的多模态理解和语音生成能力，特别是在音视频多轮交互领域提供领先的性能表现。

Method: 整合视觉编码器、音频编码器、大规模语言模型和语音解码器形成统一模型，采用多阶段训练策略，包括全模态理解的预训练和语音会话与视听交互的后训练。评估中构建了多模态多轮记忆基准和多轮语音交互基准。

Result: 实验表明InteractiveOmni显著优于其他开源模型，特别是在多轮交互中的长时记忆能力上。InteractiveOmni-4B与更大模型Qwen2.5-Omni-7B在通用基准上相当，并在达到InteractiveOmni-8B 97%性能的情况下仅使用一半的模型规模。

Conclusion: InteractiveOmni在多模态多轮交互领域表现优异，尤其是在长时记忆能力方面超出其他开源模型，成为下一代智能交互系统的基础。

Abstract: We introduce InteractiveOmni, a unified and open-source omni-modal large
language model for audio-visual multi-turn interaction, ranging from 4B to 8B
parameters, designed to lead the field of lightweight models by offering
comprehensive omni-modal understanding and speech generation capabilities. To
achieve this, we integrate the vision encoder, audio encoder, large language
model, and speech decoder into a unified model for understanding and generation
tasks. We design a multi-stage training strategy to ensure robust cross-modal
capabilities, including pre-training for omni-modal understanding, followed by
post-training with speech conversation and audio-visual interaction. To enable
human-like long-term conversational ability, we meticulously curate a
multi-turn training dataset that enhances the model's ability to handle complex
and multi-turn interactions. To effectively evaluate the multi-turn memory and
speech interaction capabilities, we construct the multi-modal multi-turn memory
benchmark and the multi-turn speech interaction benchmark. Experiments
demonstrate that InteractiveOmni significantly outperforms leading open-source
models and provides a more intelligent multi-turn audio-visual experience,
particularly in its long-term memory capabilities. Notably, InteractiveOmni-4B
is comparable to the much larger model like Qwen2.5-Omni-7B on general
benchmarks, and it can retain 97% of the performance of the InteractiveOmni-8B
while utilizing only 50% of the model size. Achieving state-of-the-art results
against similarly sized models across image, audio, video understanding, and
speech generation tasks, InteractiveOmni is an accessible, open-source
foundation for next-generation intelligent interactive systems.

</details>


### [69] [Generative Universal Verifier as Multimodal Meta-Reasoner](https://arxiv.org/abs/2510.13804)
*Xinchen Zhang,Xiaoying Zhang,Youbin Wu,Yanbin Cao,Renrui Zhang,Ruihang Chu,Ling Yang,Yujiu Yang*

Main category: cs.CV

TL;DR: 提出了Generative Universal Verifier，开发了一整套视觉验证和生成的综合框架，其通过ViVerBench等测试验证了在多个关键任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 通过引入一个新概念和插件，即Generative Universal Verifier，以解决视觉-语言模型和统一多模态模型在视觉推理和生成过程中对视觉结果进行反思和改进的能力不足的问题。

Method: 创建了ViVerBench基准测试及两个自动化构建大规模验证数据的流程，进而训练出OmniVerifier-7B；并提出了顺序测试时缩放范式OmniVerifier-TTS，用于优化图像生成和编辑。

Result: 构建了ViVerBench基准测试，评估现有视觉-语言模型在多模态推理中的表现，并发现其在可靠性和验证能力上存在差距。通过构建两个自动化流程，训练得到了OmniVerifier-7B，实现了大规模的视觉验证数据生成，并在ViVerBench上取得了显著提升。提出了一种顺序测试时缩放范式OmniVerifier-TTS，在跨模型生成能力上表现出色。

Conclusion: 通过赋予多模态推理系统可靠的视觉验证能力，OmniVerifier在生成过程中实现了可靠的反思，标志着向更值得信赖和可控的下一代推理系统迈出了重要一步。

Abstract: We introduce Generative Universal Verifier, a novel concept and plugin
designed for next-generation multimodal reasoning in vision-language models and
unified multimodal models, providing the fundamental capability of reflection
and refinement on visual outcomes during the reasoning and generation process.
This work makes three main contributions: (1) We build ViVerBench, a
comprehensive benchmark spanning 16 categories of critical tasks for evaluating
visual outcomes in multimodal reasoning. Results show that existing VLMs
consistently underperform across these tasks, underscoring a substantial gap
from human-level capability in reliable visual verification. (2) We design two
automated pipelines to construct large-scale visual verification data and train
OmniVerifier-7B, the first omni-capable generative verifier trained for
universal visual verification and achieves notable gains on ViVerBench(+8.3).
Through training, we identify three atomic capabilities in visual verification
and demonstrate how they generalize and interact synergistically. (3) We
propose OmniVerifier-TTS, a sequential test-time scaling paradigm that
leverages the universal verifier to bridge image generation and editing within
unified models, enhancing the upper bound of generative ability through
iterative fine-grained optimization. Beyond generation, we extend universal
verifier to broader world-modeling interleaved reasoning scenarios.
Empirically, OmniVerifier-TTS achieves improvements on T2I-ReasonBench(+3.7),
and GenEval++(+4.3), outperforming existing parallel test-time scaling methods,
such as Best-of-N. By endowing multimodal reasoning with reliable visual
verification, OmniVerifier advances both reliable reflection during generation
and scalable test-time refinement, marking a step toward more trustworthy and
controllable next-generation reasoning systems.

</details>


### [70] [RECODE: Reasoning Through Code Generation for Visual Question Answering](https://arxiv.org/abs/2510.13756)
*Junhong Shen,Mu Cai,Bo Hu,Ameet Talwalkar,David A Ross,Cordelia Schmid,Alireza Fathi*

Main category: cs.CV

TL;DR: 提出了一种通过反向工程视觉为可执行代码的新方法，实现更精确和可验证的多模态推理。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大型语言模型在处理结构化视觉内容（如图表和图示）时缺乏精确推理的问题。

Method: 提出了一种名为RECODE的框架，通过生成多个候选程序来复现输入图像，再利用评论对最忠实的重建进行选择，并迭代改进代码。

Result: RECODE在CharXiv、ChartQA和Geometry3K等多种视觉推理测试中明显优于不利用代码或仅使用代码画辅助线或裁剪的方法。

Conclusion: 通过将视觉感知基础与可执行代码相结合，RECODE为实现更精确和可验证的多模态推理提供了一条新路径。

Abstract: Multimodal Large Language Models (MLLMs) struggle with precise reasoning for
structured visuals like charts and diagrams, as pixel-based perception lacks a
mechanism for verification. To address this, we propose to leverage derendering
-- the process of reverse-engineering visuals into executable code -- as a new
modality for verifiable visual reasoning. Specifically, we propose RECODE, an
agentic framework that first generates multiple candidate programs to reproduce
the input image. It then uses a critic to select the most faithful
reconstruction and iteratively refines the code. This process not only
transforms an ambiguous perceptual task into a verifiable, symbolic problem,
but also enables precise calculations and logical inferences later on. On
various visual reasoning benchmarks such as CharXiv, ChartQA, and Geometry3K,
RECODE significantly outperforms methods that do not leverage code or only use
code for drawing auxiliary lines or cropping. Our work demonstrates that
grounding visual perception in executable code provides a new path toward more
accurate and verifiable multimodal reasoning.

</details>


### [71] [Uni-MMMU: A Massive Multi-discipline Multimodal Unified Benchmark](https://arxiv.org/abs/2510.13759)
*Kai Zou,Ziqi Huang,Yuhao Dong,Shulin Tian,Dian Zheng,Hongbo Liu,Jingwen He,Bin Liu,Yu Qiao,Ziwei Liu*

Main category: cs.CV

TL;DR: Uni-MMMU是一个旨在同时考察视觉理解和生成能力的综合基准，通过八个推理领域衡量模型的双向协同能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准未能有效评估多模态模型的综合能力，Uni-MMMU填补了这一空白，系统揭示生成与理解的双向协同。

Method: Uni-MMMU通过在八个推理领域进行评估，采用可验证的中间推理步骤、独特的真实值和可复现的评分协议。

Result: 评估显示现有模型在生成和理解能力上有显著的性能差异，并存在跨模态的依赖关系。

Conclusion: Uni-MMMU为推动统一模式的发展提供了可靠的基础，揭示了性能差异和跨模态依赖性。

Abstract: Unified multimodal models aim to jointly enable visual understanding and
generation, yet current benchmarks rarely examine their true integration.
Existing evaluations either treat the two abilities in isolation or overlook
tasks that inherently couple them. To address this gap, we present Uni-MMMU, a
comprehensive and discipline-aware benchmark that systematically unfolds the
bidirectional synergy between generation and understanding across eight
reasoning-centric domains, including science, coding, mathematics, and puzzles.
Each task is bidirectionally coupled, demanding models to (i) leverage
conceptual understanding to guide precise visual synthesis, or (ii) utilize
generation as a cognitive scaffold for analytical reasoning. Uni-MMMU
incorporates verifiable intermediate reasoning steps, unique ground truths, and
a reproducible scoring protocol for both textual and visual outputs. Through
extensive evaluation of state-of-the-art unified, generation-only, and
understanding-only models, we reveal substantial performance disparities and
cross-modal dependencies, offering new insights into when and how these
abilities reinforce one another, and establishing a reliable foundation for
advancing unified models.

</details>


### [72] [Scaling Vision Transformers for Functional MRI with Flat Maps](https://arxiv.org/abs/2510.13768)
*Connor Lane,Daniel Z. Kaplan,Tanishq Mathew Abraham,Paul S. Scotti*

Main category: cs.CV

TL;DR: 研究将fMRI数据转换为2D视频，并利用Vision Transformers进行建模，取得了在大型数据集上的优异表现，支持多种分类任务。


<details>
  <summary>Details</summary>
Motivation: 为了解决fMRI数据与自然图像之间的模态差异，我们探索如何将fMRI数据以合适的方式输入模型，并检验其在深度学习架构中的适应性。

Method: 我们将4D体积fMRI数据转换为2D活动平面图的视频，并在此基础上使用时空掩码自编码器(MAE)框架训练Vision Transformers模型。

Result: 我们的实验发现，随着数据集大小的增加，掩码fMRI建模性能显著提升。我们的模型在下游分类基准测试中取得优异成绩，能够支持跨受试者的细粒度状态解码和跨脑状态变化的特定受试者特质解码。

Conclusion: 我们的方法证明了Vision Transformers在处理fMRI数据方面的有效性，尤其是在大型数据集上。我们的模型能够学习丰富的表示，对于跨受试者的状态解码以及特定受试者的特质解码都表现出色。

Abstract: A key question for adapting modern deep learning architectures to functional
MRI (fMRI) is how to represent the data for model input. To bridge the modality
gap between fMRI and natural images, we transform the 4D volumetric fMRI data
into videos of 2D fMRI activity flat maps. We train Vision Transformers on 2.3K
hours of fMRI flat map videos from the Human Connectome Project using the
spatiotemporal masked autoencoder (MAE) framework. We observe that masked fMRI
modeling performance improves with dataset size according to a strict power
scaling law. Downstream classification benchmarks show that our model learns
rich representations supporting both fine-grained state decoding across
subjects, as well as subject-specific trait decoding across changes in brain
state. This work is part of an ongoing open science project to build foundation
models for fMRI data. Our code and datasets are available at
https://github.com/MedARC-AI/fmri-fm.

</details>


### [73] [Adaptive Visual Conditioning for Semantic Consistency in Diffusion-Based Story Continuation](https://arxiv.org/abs/2510.13787)
*Seyed Mohammad Mousavi,Morteza Analoui*

Main category: cs.CV

TL;DR: AVC 框架通过自适应视觉调节和改进的数据生成方法，实现了高效的故事续写，增强了语义一致性和视觉连贯性。


<details>
  <summary>Details</summary>
Motivation: 故事续写任务旨在生成与当前文本描述和先前图像序列保持一致的下一个图像。关键挑战在于有效利用先前的视觉上下文，同时确保与当前文本输入的语义对齐。

Method: 本研究提出了一种名为 AVC（Adaptive Visual Conditioning）的框架，使用 CLIP 模型从先前帧中检索与语义最相关的图像，并在无相关图像时自适应限制先前视觉的影响。同时通过大规模语言模型重修标注数据集以提高数据质量和文本监督。

Result: 实验结果和人类评估表明，与强基线模型相比，AVC 在保持连贯性、语义一致性和视觉保真度方面表现出色，特别是在先前视觉与当前输入相冲突的困难情况下。

Conclusion: AVC 框架通过自适应限制先前视觉的影响，并改进数据质量，成功应对了先前视觉与当前输入不一致的挑战，为故事续写任务提供了更优的解决方案。

Abstract: Story continuation focuses on generating the next image in a narrative
sequence so that it remains coherent with both the ongoing text description and
the previously observed images. A central challenge in this setting lies in
utilizing prior visual context effectively, while ensuring semantic alignment
with the current textual input. In this work, we introduce AVC (Adaptive Visual
Conditioning), a framework for diffusion-based story continuation. AVC employs
the CLIP model to retrieve the most semantically aligned image from previous
frames. Crucially, when no sufficiently relevant image is found, AVC adaptively
restricts the influence of prior visuals to only the early stages of the
diffusion process. This enables the model to exploit visual context when
beneficial, while avoiding the injection of misleading or irrelevant
information. Furthermore, we improve data quality by re-captioning a noisy
dataset using large language models, thereby strengthening textual supervision
and semantic alignment. Quantitative results and human evaluations demonstrate
that AVC achieves superior coherence, semantic consistency, and visual fidelity
compared to strong baselines, particularly in challenging cases where prior
visuals conflict with the current input.

</details>


### [74] [NoisePrints: Distortion-Free Watermarks for Authorship in Private Diffusion Models](https://arxiv.org/abs/2510.13793)
*Nir Goren,Oren Katzir,Abhinav Nakarmi,Eyal Ronen,Mahmood Sharif,Or Patashnik*

Main category: cs.CV

TL;DR: 提出了一种利用随机种子进行水印嵌入的轻量级方案，以便验证视觉内容生成的作者身份。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型在视觉内容生成中的快速采用，证明作者身份和保护版权变得至关重要，特别是在模型所有者将其模型设为私有并可能不愿或无法处理作者身份问题的情况下。

Method: 利用初始化扩散过程的随机种子作为作者身份证明嵌入水印，不改变生成过程，通过哈希函数保证种子的不可恢复性，使用加密零知识证明证明所有权。

Result: 提出了一种轻量级水印方案，通过随机种子来证明作者身份而无需修改生成过程，验证了该方案在各种操作下的鲁棒性和有效性。

Conclusion: 通过将哈希函数整合到噪声采样过程中，确保从内容中恢复有效种子是不可行的，并且展示了使用加密零知识证明在不泄露种子的情况下证明所有权的可能性。

Abstract: With the rapid adoption of diffusion models for visual content generation,
proving authorship and protecting copyright have become critical. This
challenge is particularly important when model owners keep their models private
and may be unwilling or unable to handle authorship issues, making third-party
verification essential. A natural solution is to embed watermarks for later
verification. However, existing methods require access to model weights and
rely on computationally heavy procedures, rendering them impractical and
non-scalable. To address these challenges, we propose , a lightweight
watermarking scheme that utilizes the random seed used to initialize the
diffusion process as a proof of authorship without modifying the generation
process. Our key observation is that the initial noise derived from a seed is
highly correlated with the generated visual content. By incorporating a hash
function into the noise sampling process, we further ensure that recovering a
valid seed from the content is infeasible. We also show that sampling an
alternative seed that passes verification is infeasible, and demonstrate the
robustness of our method under various manipulations. Finally, we show how to
use cryptographic zero-knowledge proofs to prove ownership without revealing
the seed. By keeping the seed secret, we increase the difficulty of watermark
removal. In our experiments, we validate NoisePrints on multiple
state-of-the-art diffusion models for images and videos, demonstrating
efficient verification using only the seed and output, without requiring access
to model weights.

</details>


### [75] [Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs](https://arxiv.org/abs/2510.13795)
*Yi Zhang,Bolin Ni,Xin-Sheng Chen,Heng-Rui Zhang,Yongming Rao,Houwen Peng,Qinglin Lu,Han Hu,Meng-Hao Guo,Shi-Min Hu*

Main category: cs.CV

TL;DR: 我们通过引入高质量的数据集和数据整理流程，大幅提升了开放MLLMs的性能。


<details>
  <summary>Details</summary>
Motivation: 目前完全开放的多模态模型在数据质量上落后于专有模型，我们的目标是通过提高数据质量来缩小这一差距。

Method: 我们引入了一个新的数据集Honey-Data-15M，引入了HoneyPipe数据整理流程和其基础框架DataStudio，并在此数据集上训练了Bee-8B模型。

Result: Bee-8B模型在Honey-Data-15M数据集上的表现达到SOTA，并且在某些情况下超过了近期的半开放模型。

Conclusion: 我们的工作表明，通过专注于数据质量，完全开放的MLLMs可以与半开放模型竞争。

Abstract: Fully open multimodal large language models (MLLMs) currently lag behind
proprietary counterparts, primarily due to a significant gap in data quality
for supervised fine-tuning (SFT). Existing open-source datasets are often
plagued by widespread noise and a critical deficit in complex reasoning data,
such as Chain-of-Thought (CoT), which hinders the development of advanced model
capabilities. Addressing these challenges, our work makes three primary
contributions. First, we introduce Honey-Data-15M, a new SFT dataset comprising
approximately 15 million QA pairs, processed through multiple cleaning
techniques and enhanced with a novel dual-level (short and long) CoT enrichment
strategy. Second, we introduce HoneyPipe, the data curation pipeline, and its
underlying framework DataStudio, providing the community with a transparent and
adaptable methodology for data curation that moves beyond static dataset
releases. Finally, to validate our dataset and pipeline, we train Bee-8B, an 8B
model on Honey-Data-15M. Experiments show that Bee-8B establishes a new
state-of-the-art (SOTA) for fully open MLLMs, achieving performance that is
competitive with, and in some cases surpasses, recent semi-open models such as
InternVL3.5-8B. Our work delivers to the community a suite of foundational
resources, including: the Honey-Data-15M corpus; the full-stack suite
comprising HoneyPipe and DataStudio; training recipes; an evaluation harness;
and the model weights. This effort demonstrates that a principled focus on data
quality is a key pathway to developing fully open MLLMs that are highly
competitive with their semi-open counterparts.

</details>


### [76] [Reasoning in Space via Grounding in the World](https://arxiv.org/abs/2510.13800)
*Yiming Chen,Zekun Qi,Wenyao Zhang,Xin Jin,Li Zhang,Peidong Liu*

Main category: cs.CV

TL;DR: 提出了一种名为GS-Reasoner的3D视觉定位方法，旨在改进空间推理中的3D表示问题。通过引入一种双路径池化机制和Grounded Chain-of-Thought数据集，GS-Reasoner在不依赖外部模块的情况下实现了良好的自动回归定位，实验结果表明其在3D视觉定位和空间推理中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的3D语言模型缺乏统一的3D表示，这限制了语义和几何信息的整合，从而影响定位和空间推理表现。研究旨在解决这一问题，实现有效的3D视觉定位和空间推理结合。

Method: 采用了一种简单而有效的双路径池化机制，将几何特征与语义和位置线索对齐，构建基于图像区域的3D表示。同时，引入Grounded Chain-of-Thought数据集，用于整合3D视觉定位和空间推理。

Result: 通过实验，GS-Reasoner在3D视觉定位中表现出色，并显著提升了其空间推理能力，达到先进水平。

Conclusion: GS-Reasoner在3D视觉定位和空间推理中表现优异，通过不依赖外部模块实现了先进的性能。提出的方法能够有效地统一几何、语义和位置特征，为全面的3D空间推理提供了基础。

Abstract: In this paper, we claim that 3D visual grounding is the cornerstone of
spatial reasoning and introduce the Grounded-Spatial Reasoner (GS-Reasoner) to
explore the effective spatial representations that bridge the gap between them.
Existing 3D LLMs suffer from the absence of a unified 3D representation capable
of jointly capturing semantic and geometric information. This deficiency is
manifested either in poor performance on grounding or in an excessive reliance
on external modules, ultimately hindering the seamless integration of grounding
and spatial reasoning. To address this, we propose a simple yet effective
dual-path pooling mechanism that tightly aligns geometric features with both
semantic and positional cues, constructing a unified image patch-based 3D
representation that encapsulates all essential information without increasing
the number of input tokens. Leveraging this holistic representation,
GS-Reasoner is the first 3D LLM that achieves autoregressive grounding entirely
without external modules while delivering performance comparable to
state-of-the-art models, establishing a unified and self-contained framework
for 3D spatial reasoning. To further bridge grounding and spatial reasoning, we
introduce the Grounded Chain-of-Thought (GCoT) dataset. This dataset is
meticulously curated to include both 3D bounding box annotations for objects
referenced in reasoning questions and step-by-step reasoning paths that
integrate grounding as a core component of the problem-solving process.
Extensive experiments demonstrate that GS-Reasoner achieves impressive results
on 3D visual grounding, which in turn significantly enhances its spatial
reasoning capabilities, leading to state-of-the-art performance.

</details>


### [77] [VisCoP: Visual Probing for Video Domain Adaptation of Vision Language Models](https://arxiv.org/abs/2510.13808)
*Dominick Reilly,Manish Kumar Govind,Le Xue,Srijan Das*

Main category: cs.CV

TL;DR: VisCoP通过增加视觉探针实现视觉语言模型的域适应，提高新领域性能并保留原有领域知识。


<details>
  <summary>Details</summary>
Motivation: 传统的域适应方法在视觉语言模型中经常导致性能下降或遗忘之前的能力。VisCoP旨在解决这些问题，通过一种高效的域适应机制来提高模型在新领域的表现。

Method: VisCoP在视觉编码器中加入了少量可学习的视觉探针，以最小化预训练参数的修改来实现高效域适应。

Result: 本文介绍了一种针对视觉语言模型的新型域适应方法——VisCoP。该方法通过在视觉编码器上增加可学习的视觉探针，以实现对新领域的高效适应。实验表明，VisCoP在多种复杂的域适应环境中优于现有策略，并有效保留源域知识。

Conclusion: VisCoP在域适应任务中表现出色，不仅提高了目标领域的性能，还有效避免了遗忘源领域知识的问题。

Abstract: Large Vision-Language Models (VLMs) excel at general visual reasoning tasks
but exhibit sharp performance degradation when applied to novel domains with
substantial distribution shifts from pretraining data. Existing domain
adaptation approaches finetune different VLM components, but this often results
in limited domain-specific feature learning or catastrophic forgetting of prior
capabilities. To address these issues, we introduce Vision Contextualized
Probing (VisCoP), which augments the VLM's vision encoder with a compact set of
learnable visual probes. These probes enable efficient domain-specific
adaptation with minimal modification to pretrained parameters. We evaluate
VisCoP across three challenging domain adaptation settings-cross-view
(exocentric to egocentric), cross-modal (RGB to depth), and cross-task (human
understanding to robot control). Experiments show that VisCoP consistently
outperforms existing adaptation strategies, achieving superior performance on
target domains while effectively retaining source-domain knowledge.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [78] [Benchmarking Open-Source Large Language Models for Persian in Zero-Shot and Few-Shot Learning](https://arxiv.org/abs/2510.12807)
*Mahdi Cherakhloo,Arash Abbasi,Mohammad Saeid Sarafraz,Bijan Vosoughi Vahdat*

Main category: cs.CL

TL;DR: 本研究评估了多种大型语言模型在波斯语自然语言处理任务中的表现，发现Gemma 2在大多数任务中表现突出，但面临命名实体识别等具体挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在许多语言中展现了卓越的能力，但其在低资源语言如波斯语中的有效性需要深入研究。

Method: 使用零样本和少样本学习范式，对多个开放源代码的LLMs进行评估，任务涵盖情感分析、命名实体识别、阅读理解和问答等。采用的性能评估指标包括准确率、F1分数、BLEU和ROUGE。

Result: 结果表明，Gemma 2在几乎所有任务中均优于其他模型，尤其是在复杂推理任务中表现出色。然而，大多数模型在处理诸如命名实体识别等标记级理解任务时表现不佳，突显出波斯语处理中的具体挑战。

Conclusion: 这项研究为多语言大型语言模型在低资源语言环境中的表现提供了新的见解，并为未来模型的开发提供了基准。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
numerous languages; however, their effectiveness in low-resource languages like
Persian requires thorough investigation. This paper presents a comprehensive
benchmark of several open-source LLMs for Persian Natural Language Processing
(NLP) tasks, utilizing both zero-shot and few-shot learning paradigms. We
evaluate models across a range of tasks including sentiment analysis, named
entity recognition, reading comprehension, and question answering, using
established Persian datasets such as ParsiNLU and ArmanEmo. Our methodology
encompasses rigorous experimental setups for both zero-shot and few-shot
scenarios, employing metrics such as Accuracy, F1-score, BLEU, and ROUGE for
performance evaluation. The results reveal that Gemma 2 consistently
outperforms other models across nearly all tasks in both learning paradigms,
with particularly strong performance in complex reasoning tasks. However, most
models struggle with token-level understanding tasks like Named Entity
Recognition, highlighting specific challenges in Persian language processing.
This study contributes to the growing body of research on multilingual LLMs,
providing valuable insights into their performance in Persian and offering a
benchmark for future model development.

</details>


### [79] [Cancer Diagnosis Categorization in Electronic Health Records Using Large Language Models and BioBERT: Model Performance Evaluation Study](https://arxiv.org/abs/2510.12813)
*Soheil Hashtarkhani,Rezaur Rashid,Christopher L Brett,Lokesh Chinthala,Fekede Asefa Kumsa,Janet A Zink,Robert L Davis,David L Schwartz,Arash Shaban-Nejad*

Main category: cs.CL

TL;DR: 研究评估了多个大语言模型在分类癌症诊断方面的表现，发现BioBERT在ICD代码分类中性能最佳，而GPT-4o在自由文本诊断中表现优越。尽管这些模型在行政和研究用途上表现足够，但临床应用仍需标准化的文档和人类监督。


<details>
  <summary>Details</summary>
Motivation: 由于电子健康记录中数据结构不一致或为自由文本，需要高效的预处理以支持预测性医疗模型，而人工智能驱动的自然语言处理工具在自动化诊断分类显示出希望，因此其性能和临床可靠性需要系统评估。

Method: 研究评估了5种大语言模型在从结构化和非结构化电子健康记录数据中分类癌症诊断的表现。具体分析了3456名癌症患者的762个独特诊断，测试模型将诊断分类到14个预定义类别的能力，分类结果由两名肿瘤学专家验证。

Result: BioBERT在ICD代码的加权宏F1得分中最高（84.2），并与GPT-4o在ICD代码准确性上持平（90.8）。在自由文本诊断中，GPT-4o的加权宏F1得分（71.8）优于BioBERT（61.5），且准确性略高（81.9 vs 81.6）。GPT-3.5、Gemini和Llama在两种格式上的整体表现较低。常见的误分类模式包括对转移和中枢神经系统肿瘤的混淆，以及涉及模糊或重叠的临床术语的错误。

Conclusion: 当前大语言模型在癌症诊断分类中的表现足以满足行政和研究用途，但在高风险的临床应用中仍需标准化的文档实践和稳健的人类监督。

Abstract: Electronic health records contain inconsistently structured or free-text
data, requiring efficient preprocessing to enable predictive health care
models. Although artificial intelligence-driven natural language processing
tools show promise for automating diagnosis classification, their comparative
performance and clinical reliability require systematic evaluation. The aim of
this study is to evaluate the performance of 4 large language models (GPT-3.5,
GPT-4o, Llama 3.2, and Gemini 1.5) and BioBERT in classifying cancer diagnoses
from structured and unstructured electronic health records data. We analyzed
762 unique diagnoses (326 International Classification of Diseases (ICD) code
descriptions, 436free-text entries) from 3456 records of patients with cancer.
Models were tested on their ability to categorize diagnoses into 14predefined
categories. Two oncology experts validated classifications. BioBERT achieved
the highest weighted macro F1-score for ICD codes (84.2) and matched GPT-4o in
ICD code accuracy (90.8). For free-text diagnoses, GPT-4o outperformed BioBERT
in weighted macro F1-score (71.8 vs 61.5) and achieved slightly higher accuracy
(81.9 vs 81.6). GPT-3.5, Gemini, and Llama showed lower overall performance on
both formats. Common misclassification patterns included confusion between
metastasis and central nervous system tumors, as well as errors involving
ambiguous or overlapping clinical terminology. Although current performance
levels appear sufficient for administrative and research use, reliable clinical
applications will require standardized documentation practices alongside robust
human oversight for high-stakes decision-making.

</details>


### [80] [NExT-OMNI: Towards Any-to-Any Omnimodal Foundation Models with Discrete Flow Matching](https://arxiv.org/abs/2510.13721)
*Run Luo,Xiaobo Xia,Lu Wang,Longze Chen,Renke Shan,Jing Luo,Min Yang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: NExT-OMNI是一个开放源码的全模态基础模型，通过离散流范式实现任意到任意的理解和生成。相比之前的统一模型，其在多回合多模态交互和跨模态检索方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的多模态模型因自回归架构的固有限制，无法平衡理解和生成能力。本研究旨在通过NExT-OMNI模型克服这一问题，实现统一的多模态建模。

Method: 该研究引入NExT-OMNI模型，通过度量诱导概率路径和运动最优速度进行建模，支持任意到任意的理解和生成。模型训练使用了大规模的文本、图像、视频和音频数据。

Result: NExT-OMNI在多模态生成和理解基准测试中表现竞争力，并在多回合多模态交互和跨模态检索中优于之前的统一模型。研究提供了训练细节、数据协议，并开源了代码和模型检查点。

Conclusion: NExT-OMNI模型通过采用离散流范式和统一的表示实现了更高效的响应，适应更广泛的应用场景。相较于以往的统一模型，在多回合多模态交互和跨模态检索方面拥有显著的架构优势。

Abstract: Next-generation multimodal foundation models capable of any-to-any
cross-modal generation and multi-turn interaction will serve as core components
of artificial general intelligence systems, playing a pivotal role in
human-machine interaction. However, most existing multimodal models remain
constrained by autoregressive architectures, whose inherent limitations prevent
a balanced integration of understanding and generation capabilities. Although
hybrid and decoupling strategies have been explored to address these tasks
within unified frameworks separately, their redundant, non-integrated designs
limit their applicability to broader scenarios, such as cross-modal
retrieval.In this work, we introduce NExT-OMNI, an open-source omnimodal
foundation model that achieves unified modeling through discrete flow
paradigms. By leveraging metric-induced probability paths and kinetic optimal
velocities, NExT-OMNI natively supports any-to-any understanding and generation
with enhanced response efficiency, while enabling broader application scenarios
through concise unified representations rather than task-decoupled designs.
Trained on large-scale interleaved text, image, video, and audio data,
NExT-OMNI delivers competitive performance on multimodal generation and
understanding benchmarks, while outperforming prior unified models in
multi-turn multimodal interaction and cross-modal retrieval, highlighting its
architectural advantages as a next-generation multimodal foundation model. To
advance further research, we release training details, data protocols, and
open-source both the code and model checkpoints.

</details>


### [81] [From Noise to Signal to Selbstzweck: Reframing Human Label Variation in the Era of Post-training in NLP](https://arxiv.org/abs/2510.12817)
*Shanshan Xu,Santosh T. Y. S. S,Barbara Plank*

Main category: cs.CL

TL;DR: The paper argues for incorporating and preserving Human Label Variation (HLV) in AI systems to better reflect human diversity and improve model alignment with human values.


<details>
  <summary>Details</summary>
Motivation: The motivation for this paper comes from the increasing importance of Human Label Variation (HLV) as large language models (LLMs) seek to align more closely with human values, where HLV's role has become significant.

Method: The paper outlines actionable steps for incorporating Human Label Variation (HLV) into preference datasets used for training AI.

Result: The paper highlights the problematic nature of aggregating annotations in preference-learning datasets, which currently leads to the erasure of diverse human perspectives.

Conclusion: This paper argues for treating the preservation of Human Label Variation (HLV) as a goal in AI system design, emphasizing the need to reflect human pluralism.

Abstract: Human Label Variation (HLV) refers to legitimate disagreement in annotation
that reflects the genuine diversity of human perspectives rather than mere
error. For decades, HLV in NLP was dismissed as noise to be discarded, and only
slowly over the last decade has it been reframed as a signal for improving
model robustness. With the rise of large language models (LLMs), where
post-training on human feedback has become central to model alignment, the role
of HLV has become increasingly consequential. Yet current preference-learning
datasets routinely aggregate multiple annotations into a single label, thereby
flattening diverse perspectives into a false universal agreement and erasing
precisely the pluralism of human values that alignment aims to preserve. In
this position paper, we argue that preserving HLV as an embodiment of human
pluralism must be treated as a Selbstzweck - a goal it self when designing AI
systems. We call for proactively incorporating HLV into preference datasets and
outline actionable steps towards it.

</details>


### [82] [MEDEQUALQA: Evaluating Biases in LLMs with Counterfactual Reasoning](https://arxiv.org/abs/2510.12818)
*Rajarshi Ghosh,Abhay Gupta,Hudson McBride,Anurag Vaidya,Faisal Mahmood*

Main category: cs.CL

TL;DR: 研究引入MEDEQUALQA基准测试，通过对患者代词的对比分析评估LLMs在临床决策中的推理稳定性，并揭示了潜在的临床偏差。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在临床决策支持中的应用越来越广泛，研究者们发现人口统计学线索的微妙变化可能影响其推理能力。因此，有必要了解在控制人口统计变化下，LLMs的内在推理如何发生变化。

Method: 研究通过引入MEDEQUALQA反事实基准测试，针对每个临床小插曲进行单一CSC消融，生成大约69,000项数据集，使用GPT-4.1模型评估推理稳定性，并通过计算语义文本相似度（STS）来度量在代词变体间的稳定性。

Result: 研究中使用MEDEQUALQA基准测试，通过改变患者代词而保持关键症状和条件（CSC）不变，从而评估GPT-4.1模型的推理稳定性。结果显示，在代词变体之间的推理轨迹整体上具有较高的相似性，但在引用的风险因素、指导锚点和差异排序上存在局部差异，并进行了错误分析。

Conclusion: MEDEQUALQA为审计医学人工智能中的推理稳定性提供了一个受控的诊断设置，尽管最终诊断未改变，但仍存在推理上的局部差异，可能导致不平等的医疗服务。

Abstract: Large language models (LLMs) are increasingly deployed in clinical decision
support, yet subtle demographic cues can influence their reasoning. Prior work
has documented disparities in outputs across patient groups, but little is
known about how internal reasoning shifts under controlled demographic changes.
We introduce MEDEQUALQA, a counterfactual benchmark that perturbs only patient
pronouns (he/him, she/her, they/them) while holding critical symptoms and
conditions (CSCs) constant. Each clinical vignette is expanded into single-CSC
ablations, producing three parallel datasets of approximately 23,000 items each
(69,000 total). We evaluate a GPT-4.1 model and compute Semantic Textual
Similarity (STS) between reasoning traces to measure stability across pronoun
variants. Our results show overall high similarity (mean STS >0.80), but reveal
consistent localized divergences in cited risk factors, guideline anchors, and
differential ordering, even when final diagnoses remain unchanged. Our error
analysis highlights certain cases in which the reasoning shifts, underscoring
clinically relevant bias loci that may cascade into inequitable care.
MEDEQUALQA offers a controlled diagnostic setting for auditing reasoning
stability in medical AI.

</details>


### [83] [Mathematics with large language models as provers and verifiers](https://arxiv.org/abs/2510.12829)
*Hieu Le Duc,Leo Liberti*

Main category: cs.CL

TL;DR: ChatGPT使用合作协议解决了复杂的数学问题，并通过lean证明助手验证了结果。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在处理复杂数学问题和定理证明中的能力，特别是解决国际数学奥赛问题和验证数学猜想。

Method: 使用不同的gpt-5模型实例协作进行定理证明，并通过lean证明助手和人类验证确保证明不受幻觉影响。

Result: 成功解决了2025年国际数学奥赛的六个问题中的五个，并解决了66个数论猜想中的三分之一。

Conclusion: 本文介绍了一项由ChatGPT实现的定理证明能力，通过一种协议使不同的gpt-5模型合作来完成定理的证明。最终的证明通过lean证明助手进行了形式验证，并由人类检验lean代码的前提和结论的符合性。

Abstract: During 2024 and 2025 the discussion about the theorem-proving capabilities of
large language models started reporting interesting success stories, mostly to
do with difficult exercises (such as problems from the International
Mathematical Olympiad), but also with conjectures [Feldman & Karbasi,
arXiv:2509.18383v1] formulated for the purpose of verifying whether the
artificial intelligence could prove it. In this paper we report a theorem
proving feat achieved by ChatGPT by using a protocol involving different prover
and verifier instances of the gpt-5 model working collaboratively. To make sure
that the produced proofs do not suffer from hallucinations, the final proof is
formally verified by the lean proof assistant, and the conformance of premises
and conclusion of the lean code is verified by a human. Our methodology was
able to solve five out of six 2025 IMO problems, and close a third of the
sixty-six number theory conjectures in [Cohen, Journal of Integer Sequences,
2025].

</details>


### [84] [MTSQL-R1: Towards Long-Horizon Multi-Turn Text-to-SQL via Agentic Training](https://arxiv.org/abs/2510.12831)
*Taicheng Guo,Hai Wang,ChaoChun Liu,Mohsen Golalikhani,Xin Chen,Xiangliang Zhang,Chandan K. Reddy*

Main category: cs.CL

TL;DR: 提出了一个名为MTSQL-R1的框架，通过与数据库和对话记忆库交互，改进多轮Text-to-SQL的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有多轮Text-to-SQL系统常忽视对话的连贯性和SQL的可执行性，导致输出不连贯或无法执行。为解决这一问题，提出新的框架MTSQL-R1，以实现长视野的对话连贯和SQL执行准确性。

Method: MTSQL-R1使用马尔可夫决策过程(MDP)，通过“执行->验证->改进”的循环，与数据库和对话记忆库交互，确保SQL查询的可执行性和对话的连贯性。

Result: MTSQL-R1框架在长视野多轮Text-to-SQL任务上展现了其优势。通过将任务视为马尔可夫决策过程(MDP)，MTSQL-R1与数据库和对话记忆库交互，进行执行反馈和连贯性验证。该方法在COSQL和SPARC数据集上优于现有基线，强调了环境驱动的验证和记忆引导的改进的重要性。

Conclusion: MTSQL-R1框架通过与数据库和对话记忆库的交互，改进了多轮Text-to-SQL任务的执行准确性及连贯性，与现有基线相比有显著提升。

Abstract: Multi-turn Text-to-SQL aims to translate a user's conversational utterances
into executable SQL while preserving dialogue coherence and grounding to the
target schema. However, most existing systems only regard this task as a simple
text translation task and follow a short-horizon paradigm, generating a query
per turn without execution, explicit verification, and refinement, which leads
to non-executable or incoherent outputs. We present MTSQL-R1, an agentic
training framework for long-horizon multi-turn Text-to-SQL. We cast the task as
a Markov Decision Process (MDP) in which an agent interacts with (i) a database
for execution feedback and (ii) a persistent dialogue memory for coherence
verification, performing an iterative propose to execute -> verify -> refine
cycle until all checks pass. Experiments on COSQL and SPARC demonstrate that
MTSQL-R1 consistently outperforms strong baselines, highlighting the importance
of environment-driven verification and memory-guided refinement for
conversational semantic parsing. Full recipes (including code, trained models,
logs, reasoning trajectories, etc.) will be released after the internal review
to contribute to community research.

</details>


### [85] [Repurposing Annotation Guidelines to Instruct LLM Annotators: A Case Study](https://arxiv.org/abs/2510.12835)
*Kon Woo Kim,Rezarta Islamaj,Jin-Dong Kim,Florian Boudin,Akiko Aizawa*

Main category: cs.CL

TL;DR: 研究如何将人类注释者使用的注释指南转化为可用于大语言模型的指令，提出了一种面向调控的指南转换方法，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 探讨如何将现有的注释指南重新用于指导大语言模型（LLM）进行文本注释任务。传统指南适用于经过培训的人类注释者，而大模型需要明确的、结构化的指令。

Method: 提出了一种面向调控的指南重新设计方法，通过LLM调控过程将指南转变为明确的指令，以指导大语言模型进行文本注释。

Result: 实验结果显示，经过重新设计的指南可以有效指导LLM注释者，并揭示了一些实际挑战。

Conclusion: 这些结果突显了该工作流程在支持注释指南的可扩展性和成本效益上的潜力，以及自动化注释的潜力。

Abstract: This study investigates how existing annotation guidelines can be repurposed
to instruct large language model (LLM) annotators for text annotation tasks.
Traditional guidelines are written for human annotators who internalize
training, while LLMs require explicit, structured instructions. We propose a
moderation-oriented guideline repurposing method that transforms guidelines
into clear directives for LLMs through an LLM moderation process. Using the
NCBI Disease Corpus as a case study, our experiments show that repurposed
guidelines can effectively guide LLM annotators, while revealing several
practical challenges. The results highlight the potential of this workflow to
support scalable and cost-effective refinement of annotation guidelines and
automated annotation.

</details>


### [86] [FaStFACT: Faster, Stronger Long-Form Factuality Evaluations in LLMs](https://arxiv.org/abs/2510.12839)
*Yingjia Wan,Haochen Tan,Xiao Zhu,Xinyu Zhou,Zhiwei Li,Qingsong Lv,Changxuan Sun,Jiaqi Zeng,Yi Xu,Jianqiao Lu,Yinhong Liu,Zhijiang Guo*

Main category: cs.CL

TL;DR: 提出了一个名为\name的框架，通过块级声明提取和文档级证据收集，高效评估长文本生成的事实性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在评估长文本生成的事实性时效率低下和证据收集不足的问题。

Method: 
ame 框架采用块级别的声明提取，并结合基于置信度的预验证方法，收集来自网页的文档级证据并在验证过程中选择性提取这些证据。

Result: 实验表明，
ame 框架在评估长文本LLM生成的事实性方面既高效又有效，并且与人为评估高度一致。

Conclusion: 
ame 是一种快速且高效的评价框架，在评估长文本LLM生成的事实性方面表现出色。

Abstract: Evaluating the factuality of long-form generations from Large Language Models
(LLMs) remains challenging due to accuracy issues and costly human assessment.
Prior efforts attempt this by decomposing text into claims, searching for
evidence, and verifying claims, but suffer from critical drawbacks: (1)
inefficiency due to complex pipeline components unsuitable for long LLM
outputs, and (2) ineffectiveness stemming from inaccurate claim sets and
insufficient evidence collection of one-line snippets.
  To address these limitations, we propose \name, a fast and strong evaluation
framework that achieves the highest alignment with human evaluation and
efficiency among existing baselines. \name first employs chunk-level claim
extraction integrated with confidence-based pre-verification, significantly
reducing the cost of web searching and inference calling while ensuring
reliability. For searching and verification, it collects document-level
evidence from crawled webpages and selectively retrieves it during
verification, addressing the evidence insufficiency problem in previous
pipelines.
  Extensive experiments based on an aggregated and manually annotated benchmark
demonstrate the reliability of \name in both efficiently and effectively
evaluating the factuality of long-form LLM generations. Code and benchmark data
is available at https://github.com/Yingjia-Wan/FastFact.

</details>


### [87] [EduDial: Constructing a Large-scale Multi-turn Teacher-Student Dialogue Corpus](https://arxiv.org/abs/2510.12899)
*Shouang Wei,Min Zhang,Xin Lin,Bo Jiang,Zhongxiang Dai,Kun Kuang*

Main category: cs.CL

TL;DR: 本文介绍了一个名为 EduDial 的多轮师生对话数据集及相关模型 EduDial-LLM 的开发，通过实验验证模型在各项教学指标上优于现有基准。


<details>
  <summary>Details</summary>
Motivation: 大语言模型被认为是推动智能教育发展的关键技术之一，因此构建专门的师生对话基准尤为重要，这可以帮助更好地评估和提升模型的教学能力。

Method: 本文提出了一个名为 EduDial 的多轮师生对话数据集，以布鲁姆教育目标分类法为指导设计，结合十种提问策略，包含 34,250 个对话会话。此外，开发了一个 11 维的评价框架，用于系统地评估大语言模型的教学能力。基于 EduDial 数据集进行训练，推出了 EduDial-LLM 32B。

Result: EduDial-LLM 在所有指标上均优于基准模型，特别是在以学生为中心的教学场景中表现出显著的提升。

Conclusion: 实验表明，大多数现有的主流大语言模型在以学生为中心的教学场景中表现不佳，而 EduDial-LLM 在所有指标上均优于基准模型，展现了其有效性和优势。

Abstract: Recently, several multi-turn dialogue benchmarks have been proposed to
evaluate the conversational abilities of large language models (LLMs). As LLMs
are increasingly recognized as a key technology for advancing intelligent
education, owing to their ability to deeply understand instructional contexts
and provide personalized guidance, the construction of dedicated
teacher-student dialogue benchmarks has become particularly important. To this
end, we present EduDial, a comprehensive multi-turn teacher-student dialogue
dataset. EduDial covers 345 core knowledge points and consists of 34,250
dialogue sessions generated through interactions between teacher and student
agents. Its design is guided by Bloom's taxonomy of educational objectives and
incorporates ten questioning strategies, including situational questioning,
zone of proximal development (ZPD) questioning, and metacognitive
questioning-thus better capturing authentic classroom interactions.
Furthermore, we design differentiated teaching strategies for students at
different cognitive levels, thereby providing more targeted teaching guidance.
Building on EduDial, we further develop EduDial-LLM 32B via training and
propose an 11-dimensional evaluation framework that systematically measures the
teaching abilities of LLMs, encompassing both overall teaching quality and
content quality. Experiments on 17 mainstream LLMs reveal that most models
struggle in student-centered teaching scenarios, whereas our EduDial-LLM
achieves significant gains, consistently outperforming all baselines across all
metrics. The code is available at
https://github.com/Mind-Lab-ECNU/EduDial/tree/main.

</details>


### [88] [Who's Asking? Evaluating LLM Robustness to Inquiry Personas in Factual Question Answering](https://arxiv.org/abs/2510.12925)
*Nil-Jana Akpinar,Chia-Jung Lee,Vanessa Murdock,Pietro Perona*

Main category: cs.CL

TL;DR: 该研究首次系统性地评估了大语言模型在面对用户背景信息的鲁棒性，发现用户背景信息会影响问答准确性并引发潜在失败模式。


<details>
  <summary>Details</summary>
Motivation: 确保大语言模型（LLMs）在回答事实性问题时，能够以客观知识为基础，如实回答，而不受用户上下文（如自我披露的个人信息或系统个性化）的影响。

Method: 通过评估用户在真实交互中自我披露的合理背景信息，以对大语言模型的问答准确性和鲁棒性进行测试。

Result: 研究发现，用户自我披露的背景信息（如身份、专业或信仰等）会显著影响问答准确性，并引发失败模式，如答复拒绝、虚构限制和角色混淆。

Conclusion: 考察用户背景信息作为鲁棒性测试工具时，大语言模型对用户框架的敏感性会影响其事实可靠性，因此用户背景信息的测试是评估鲁棒性的有效方法。

Abstract: Large Language Models (LLMs) should answer factual questions truthfully,
grounded in objective knowledge, regardless of user context such as
self-disclosed personal information, or system personalization. In this paper,
we present the first systematic evaluation of LLM robustness to inquiry
personas, i.e. user profiles that convey attributes like identity, expertise,
or belief. While prior work has primarily focused on adversarial inputs or
distractors for robustness testing, we evaluate plausible, human-centered
inquiry persona cues that users disclose in real-world interactions. We find
that such cues can meaningfully alter QA accuracy and trigger failure modes
such as refusals, hallucinated limitations, and role confusion. These effects
highlight how model sensitivity to user framing can compromise factual
reliability, and position inquiry persona testing as an effective tool for
robustness evaluation.

</details>


### [89] [The Curious Case of Curiosity across Human Cultures and LLMs](https://arxiv.org/abs/2510.12943)
*Angana Borah,Rada Mihalcea*

Main category: cs.CL

TL;DR: 研究探讨LLM在跨文化背景下的好奇心表现，提出了评估框架CUEST，发现LLM更符合西方好奇心表达，可以通过微调策略改善。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM在不同文化背景下的好奇心表现及其重要性。

Method: 使用Yahoo! Answers多国数据集进行跨文化好奇心研究，并提出CUEST框架进行评估。

Result: 该研究探讨了大型语言模型(LLM)在跨文化背景下的好奇心表现。通过分析Yahoo! Answers的多国数据集，作者提出了CUEST框架，用于评估LLM在表达好奇心方面与人类的对齐程度。从开放和封闭源的模型来看，结果表明LLM更倾向于以西方国家的方式表达好奇心，但可以通过微调策略缩小与人类的表达差异。研究表明好奇心对于LLM的跨文化适应性具有重要意义，为未来的自然语言处理研究提供了参考。

Conclusion: 好奇心对于LLM的跨文化适应性至关重要，LLM当前更倾向于西方国家的好奇心表达，但可以通过微调缩小与不同文化的差异。

Abstract: Recent advances in Large Language Models (LLMs) have expanded their role in
human interaction, yet curiosity -- a central driver of inquiry -- remains
underexplored in these systems, particularly across cultural contexts. In this
work, we investigate cultural variation in curiosity using Yahoo! Answers, a
real-world multi-country dataset spanning diverse topics. We introduce CUEST
(CUriosity Evaluation across SocieTies), an evaluation framework that measures
human-model alignment in curiosity through linguistic (style), topic preference
(content) analysis and grounding insights in social science constructs. Across
open- and closed-source models, we find that LLMs flatten cross-cultural
diversity, aligning more closely with how curiosity is expressed in Western
countries. We then explore fine-tuning strategies to induce curiosity in LLMs,
narrowing the human-model alignment gap by up to 50\%. Finally, we demonstrate
the practical value of curiosity for LLM adaptability across cultures, showing
its importance for future NLP research.

</details>


### [90] [3-Model Speculative Decoding](https://arxiv.org/abs/2510.12966)
*Sanghyun Byun,Mohanad Odema,Jung Ick Guack,Baisub Lee,Jacob Song,Woo Seong Chung*

Main category: cs.CL

TL;DR: 该论文介绍了一种名为PyramidSD的推测解码方法，通过在草稿模型和目标模型之间插入一个中间验证模型，以更小的草稿模型加速推理。


<details>
  <summary>Details</summary>
Motivation: 解决推测解码中，草稿模型大小和令牌接受率之间的权衡问题，提升推理效率。

Method: 提出了层次化解码策略，引入中间验证模型，并使用模糊接受标准，以支持每个阶段的放宽分歧阈值。

Result: 实验证明，PyramidSD在消费级GPU上达到的生成速度是标准SD的1.91倍，能够在小内存环境下实现更高的吞吐量，同时只需很少牺牲目标模型的质量。

Conclusion: PyramidSD是一种改进的推测解码方法，通过引入中间验证模型提高草稿模型与目标模型之间的一致性，允许更小的草稿模型使用而不影响性能，并实现更高的吞吐量。

Abstract: Speculative Decoding (SD) accelerates inference in large language models by
using a smaller draft model to propose tokens, which are then verified by a
larger target model. However, the throughput gains of SD are fundamentally
limited by a trade-off between draft model size and token acceptance: smaller
draft models generate tokens more quickly but exhibit greater divergence from
the target model, resulting in lower acceptance rates and reduced speedups. We
introduce Pyramid Speculative Decoding (PyramidSD), an extension of SD that
inserts an intermediate qualifier model between the draft and target to bridge
the distributional gap in output predictions, allowing smaller model to be used
for drafting. This hierarchical decoding strategy improves alignment across
models, enabling higher acceptance rates and allowing the use of significantly
smaller draft models without sacrificing overall performance. PyramidSD builds
on fuzzy acceptance criteria to support relaxed divergence thresholds at each
stage, improving throughput. In experiments, PyramidSD achieves up to 1.91x
generation speed over standard SD, reaching 124 tokens per second on a consumer
GPU (RTX 4090). In small-memory settings with a 1B-parameter draft model and an
8B target model, PyramidSD minimally trades target model quality for improved
throughput. Overall, PyramidSD offers a practical approach to enhancing
speculative decoding efficiency and can be readily applied to existing
inference pipelines.

</details>


### [91] [A Multilingual, Large-Scale Study of the Interplay between LLM Safeguards, Personalisation, and Disinformation](https://arxiv.org/abs/2510.12993)
*João A. Leite,Arnav Arora,Silvia Gargova,João Luz,Gustavo Sampaio,Ian Roberts,Carolina Scarton,Kalina Bontcheva*

Main category: cs.CL

TL;DR: 大型语言模型在生成个性化虚假信息方面存在漏洞，需加强其安全机制。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs生成个性化、说服性虚假信息的能力，以及其潜在的误用风险。

Method: 采用红队策略，系统评估LLMs针对个人身份提示的安全机制。生成并分析一个由8种先进LLMs产生的160万文本的新数据集AI-TRAITS。

Result: 该研究探讨大型语言模型（LLMs）生成个性化虚假信息的能力及其潜在的误用风险。通过研究，发现LLMs的安全机制对涉及个人信息的提示不够强健，产生了一个新数据集AI-TRAITS，揭示了当前模型的漏洞。

Conclusion: 研究揭示当前最先进的LLMs在面对个性化提示时的关键漏洞，并为改善其安全对齐和检测策略提供了基础。

Abstract: The human-like proficiency of Large Language Models (LLMs) has brought
concerns about their potential misuse for generating persuasive and
personalised disinformation at scale. While prior work has demonstrated that
LLMs can generate disinformation, specific questions around persuasiveness and
personalisation (generation of disinformation tailored to specific demographic
attributes) remain largely unstudied. This paper presents the first
large-scale, multilingual empirical study on persona-targeted disinformation
generation by LLMs. Employing a red teaming methodology, we systematically
evaluate the robustness of LLM safety mechanisms to persona-targeted prompts. A
key novel result is AI-TRAITS (AI-generaTed peRsonAlIsed disinformaTion
dataSet), a new dataset of around 1.6 million texts generated by eight
state-of-the-art LLMs. AI-TRAITS is seeded by prompts that combine 324
disinformation narratives and 150 distinct persona profiles, covering four
major languages (English, Russian, Portuguese, Hindi) and key demographic
dimensions (country, generation, political orientation). The resulting
personalised narratives are then assessed quantitatively and compared along the
dimensions of models, languages, jailbreaking rate, and personalisation
attributes. Our findings demonstrate that the use of even simple
personalisation strategies in the prompts significantly increases the
likelihood of jailbreaks for all studied LLMs. Furthermore, personalised
prompts result in altered linguistic and rhetorical patterns and amplify the
persuasiveness of the LLM-generated false narratives. These insights expose
critical vulnerabilities in current state-of-the-art LLMs and offer a
foundation for improving safety alignment and detection strategies in
multilingual and cross-demographic contexts.

</details>


### [92] [OPLoRA: Orthogonal Projection LoRA Prevents Catastrophic Forgetting during Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2510.13003)
*Yifeng Xiong,Xiaohui Xie*

Main category: cs.CL

TL;DR: OPLoRA通过正交投影解决LoRA的灾难性遗忘问题，实现了知识保留和任务性能的兼顾。


<details>
  <summary>Details</summary>
Motivation: LoRA在高效微调大语言模型时，存在灾难性遗忘的问题，更新信息可能干扰了编码基础预训练知识的主导奇异方向。

Method: OPLoRA通过分解预训练权重并使用双侧正交投影，确保LoRA更新在正交补空间，同时提出误码干扰度量指标来评估更新干扰。

Result: OPLoRA通过双侧正交投影防止干扰，确保LoRA的更新位于正交补空间，实现了知识保留，且在广泛实验中显著减少遗忘。

Conclusion: 正交投影被证明是知识保留的有效机制，在一系列任务上取得竞争性表现。

Abstract: Low-Rank Adaptation (LoRA) enables efficient fine-tuning of large language
models but suffers from catastrophic forgetting when learned updates interfere
with the dominant singular directions that encode essential pre-trained
knowledge. We propose Orthogonal Projection LoRA (OPLoRA), a theoretically
grounded approach that prevents this interference through double-sided
orthogonal projections. By decomposing frozen weights via SVD, OPLoRA
constrains LoRA updates to lie entirely within the orthogonal complement of the
top-$k$ singular subspace using projections $P_L = I - U_k U_k^\top$ and $P_R =
I - V_k V_k^\top$. We prove that this construction exactly preserves the
top-$k$ singular triples, providing mathematical guarantees for knowledge
retention. To quantify subspace interference, we introduce $\rho_k$, a metric
measuring update alignment with dominant directions. Extensive experiments
across commonsense reasoning, mathematics, and code generation demonstrate that
OPLoRA significantly reduces forgetting while maintaining competitive
task-specific performance on LLaMA-2 7B and Qwen2.5 7B, establishing orthogonal
projection as an effective mechanism for knowledge preservation in
parameter-efficient fine-tuning.

</details>


### [93] [CurLL: A Developmental Framework to Evaluate Continual Learning in Language Models](https://arxiv.org/abs/2510.13008)
*Pavan Kalyan,Shubhra Mishra,Satya Lokam,Navin Goyal*

Main category: cs.CL

TL;DR: 本文介绍了一种基于人类发展轨迹的持续学习数据集和评估体系CurlL，以评估语言模型在技能学习上的表现，展示了技能保持与传递效率的权衡。


<details>
  <summary>Details</summary>
Motivation: 随着科技的发展，研究人员致力于开发机器学习模型，使其能够模仿人类的学习方式，以提高模型的学习能力和灵活性。本文旨在推动语言模型的持续学习评估，为其提供一种基于人类年龄发展轨迹的全面数据集和基准测试。通过对模型的技能获取能力进行系统性和细粒度的评估，来探索模型在持续学习中的表现。

Method: 作者通过创建一个名为CurlL的数据集，该数据集基于儿童在5至10岁之间的发展轨迹，划分为五个发展阶段。通过技能图谱将广泛的技能分解为更小的能力、具体目标及可测量的指标，同时捕捉能力之间的依赖关系。生成了一个23.4B字词的合成数据集，控制技能进展、词汇复杂性及格式多样性，包括段落、理解型问答、技能测试问答以及指令-响应对。使用一个135M参数的转换器模型，通过独立、联合和连续（持续）设置训练，对遗忘、前向传递及后向传递进行精确分析。

Result: 通过实验验证，作者展示了技能保持与传递效率之间的权衡。实验结果表明，利用CurlL数据集进行评估，能够有效地模拟人类学习模式，揭示语言模型在连续学习中的表现。

Conclusion: 这项研究通过模拟人类的学习模式，并提供对技能依赖的细粒度控制，推进了语言模型的持续学习评估。通过对技能保留与传递效率进行权衡分析，为未来语言模型的开发提供了实用的洞察。

Abstract: We introduce a comprehensive continual learning dataset and benchmark (CurlL)
grounded in human developmental trajectories from ages 5-10, enabling
systematic and fine-grained assessment of models' ability to progressively
acquire new skills. CurlL spans five developmental stages (0-4) covering ages
5-10, supported by a skill graph that breaks down broad skills into smaller
abilities, concrete goals, and measurable indicators, while also capturing
which abilities build on others. We generate a 23.4B-token synthetic dataset
with controlled skill progression, vocabulary complexity, and format diversity,
comprising paragraphs, comprehension-based QA (CQA), skill-testing QA (CSQA),
and instruction-response (IR) pairs. Stage-wise token counts range from 2.12B
to 6.78B tokens, supporting precise analysis of forgetting, forward transfer,
and backward transfer. Using a 135M-parameter transformer trained under
independent, joint, and sequential (continual) setups, we show trade-offs in
skill retention and transfer efficiency. By mirroring human learning patterns
and providing fine-grained control over skill dependencies, this work advances
continual learning evaluations for language models.

</details>


### [94] [On the Role of Preference Variance in Preference Optimization](https://arxiv.org/abs/2510.13022)
*Jiacheng Guo,Zihao Li,Jiahao Qiu,Yue Wu,Mengdi Wang*

Main category: cs.CL

TL;DR: 研究了偏好方差(PVar)对直接偏好优化(DPO)训练效率的影响，发现高PVar的提示更有助于学习。


<details>
  <summary>Details</summary>
Motivation: 人类偏好数据的收集成本高，因此有必要寻找减少所需标注的方法，偏好方差(PVar)可能影响DPO训练效率。

Method: 通过理论分析建立了DPO梯度范数的上界，并通过实验验证了高PVar的提示的训练效果。

Result: 实验表明使用高PVar的提示进行训练比使用随机或低PVar的提示效果更佳，尤其是在较小的奖励模型中也表现出稳健性。在使用UltraFeedback数据集的人类标注进行的单独实验中，仅训练拥有最高PVar的前10%的提示效果优于完整数据集。

Conclusion: 通过实验验证了偏好方差(PVar)在选择训练样本时的重要性，高PVar的提示比随机选择或低PVar的提示在训练效果上更好。

Abstract: Direct Preference Optimization (DPO) has emerged as an important approach for
learning from human preferences in aligning large language models (LLMs).
However, collecting human preference data is costly and inefficient, motivating
methods to reduce the required annotations. In this work, we investigate the
impact of \emph{preference variance} (PVar), which measures the variance in
model preferences when comparing pairs of responses, on the effectiveness of
DPO training. We provide a theoretical insight by establishing an upper bound
on the DPO gradient norm for any given prompt, showing it is controlled by the
PVar of that prompt. This implies that prompts with low PVar can only produce
small gradient updates, making them less valuable for learning. We validate
this finding by fine-tuning LLMs with preferences generated by a reward model,
evaluating on two benchmarks (AlpacaEval 2.0 and Arena-Hard). Experimental
results demonstrate that prompts with higher PVar outperform randomly selected
prompts or those with lower PVar. We also show that our PVar-based selection
method is robust, when using smaller reward models (1B, 3B) for selection.
Notably, in a separate experiment using the original human annotations from the
UltraFeedback dataset, we found that training on only the top 10\% of prompts
with the highest PVar yields better evaluation performance than training on the
full dataset, highlighting the importance of preference variance in identifying
informative examples for efficient LLM alignment.

</details>


### [95] [GatePro: Parameter-Free Expert Selection Optimization for Mixture-of-Experts Models](https://arxiv.org/abs/2510.13079)
*Chen Zheng,Yuhang Cai,Deyi Liu,Jin Ma,Yiyuan Ma,Yuan Yang,Jing Liu,Yutao Zeng,Xun Zhou,Siyuan Qiao*

Main category: cs.CL

TL;DR: GatePro enhances MoE model effectiveness by promoting expert diversity, avoiding similar expert co-activation, and can be implemented without extra parameters.


<details>
  <summary>Details</summary>
Motivation: Address the issue of redundant computation in MoE models caused by simultaneous selection of functionally similar experts, which limits model capacity.

Method: GatePro identifies similar expert pairs and introduces localized competition to promote diversity, preventing redundant co-activation while preserving specialization.

Result: Evaluation results show that GatePro effectively enhances expert diversity, leading to more distinct and complementary expert capabilities, and can be implemented during any training phase.

Conclusion: GatePro provides a practical solution to improve expert selection diversity in MoE architectures, enhancing model effectiveness without requiring additional parameters.

Abstract: Modern large language models leverage Mixture-of-Experts (MoE) architectures
for efficient scaling, but face a critical challenge: functionally similar
experts are often selected simultaneously, creating redundant computation and
limiting effective model capacity. Existing auxiliary balance loss methods
improve token distribution but fail to address the underlying expert diversity
problem. We introduce GatePro, a novel parameter-free method that directly
promotes expert selection diversity. GatePro identifies the most similar expert
pairs and introduces localized competition mechanisms, preventing redundant
expert co-activation while maintaining natural expert specialization. Our
comprehensive evaluation demonstrates GatePro's effectiveness across model
scales and benchmarks. Analysis demonstrates GatePro's ability to achieve
enhanced expert diversity, where experts develop more distinct and
complementary capabilities, avoiding functional redundancy. This approach can
be deployed hot-swappable during any training phase without additional
learnable parameters, offering a practical solution for improving MoE
effectiveness.

</details>


### [96] [ESI: Epistemic Uncertainty Quantification via Semantic-preserving Intervention for Large Language Models](https://arxiv.org/abs/2510.13103)
*Mingda Li,Xinyu Li,Weinan Zhang,Longxuan Ma*

Main category: cs.CL

TL;DR: 研究提出了一种通过语义保持干预来量化大型语言模型不确定性的新方法，并证明其有效性和效率。


<details>
  <summary>Details</summary>
Motivation: 不确定性量化（UQ）能够提升模型的可靠性，而对大型语言模型（LLMs）进行不确定性量化并非易事。

Method: 提出了一种新颖的灰盒不确定性量化方法，通过语义保持干预前后模型输出的变动来测量不确定性。

Result: 通过理论证明表明，该方法有效估计了认识不确定性。同时，在多种LLMs及问答数据集上进行的大量实验显示，该方法不仅在效果上表现出色，而且在计算效率上也表现优异。

Conclusion: 研究建立了LLMs的不确定性与其语义保持干预不变性之间的联系，进而提出了有效的灰盒不确定性量化方法。

Abstract: Uncertainty Quantification (UQ) is a promising approach to improve model
reliability, yet quantifying the uncertainty of Large Language Models (LLMs) is
non-trivial. In this work, we establish a connection between the uncertainty of
LLMs and their invariance under semantic-preserving intervention from a causal
perspective. Building on this foundation, we propose a novel grey-box
uncertainty quantification method that measures the variation in model outputs
before and after the semantic-preserving intervention. Through theoretical
justification, we show that our method provides an effective estimate of
epistemic uncertainty. Our extensive experiments, conducted across various LLMs
and a variety of question-answering (QA) datasets, demonstrate that our method
excels not only in terms of effectiveness but also in computational efficiency.

</details>


### [97] [Multi-Label Clinical Text Eligibility Classification and Summarization System](https://arxiv.org/abs/2510.13115)
*Surya Tejaswi Yerramsetty,Almas Fathimah*

Main category: cs.CL

TL;DR: 提出了一种利用NLP与LLMs的系统进行临床文本资格分类与总结，使用多种特征提取及分类技术，评估显示方法有效，潜在提升研究效率。


<details>
  <summary>Details</summary>
Motivation: 临床试验在医学进步中至关重要，因为它们有助于提高对人类健康和医疗体系的理解。因此，有必要设计系统以自动化多标签的临床文本资格分类和总结，以改善研究效率。

Method: 系统利用自然语言处理（NLP）和大型语言模型（LLMs）结合特征提取方法，如词嵌入（Word2Vec）和命名实体识别，以识别相关医学概念，还使用计数矢量化和TF-IDF（词频-逆文档频率）等传统矢量化技术。然后应用随机森林与SVM模型进行多标签分类，基于资格标准对文档进行分类。还评估了文本总结技术，包括TextRank、Luhn和GPT-3，以简洁总结资格要求。

Result: 通过ROUGE分数进行的评估表明，所提出的方法是有效的。

Conclusion: 该系统展示了通过数据驱动的方法自动化临床试验资格评估的潜力，从而提高研究效率。

Abstract: Clinical trials are central to medical progress because they help improve
understanding of human health and the healthcare system. They play a key role
in discovering new ways to detect, prevent, or treat diseases, and it is
essential that clinical trials include participants with appropriate and
diverse medical backgrounds. In this paper, we propose a system that leverages
Natural Language Processing (NLP) and Large Language Models (LLMs) to automate
multi-label clinical text eligibility classification and summarization. The
system combines feature extraction methods such as word embeddings (Word2Vec)
and named entity recognition to identify relevant medical concepts, along with
traditional vectorization techniques such as count vectorization and TF-IDF
(Term Frequency-Inverse Document Frequency). We further explore weighted TF-IDF
word embeddings that integrate both count-based and embedding-based strengths
to capture term importance effectively. Multi-label classification using Random
Forest and SVM models is applied to categorize documents based on eligibility
criteria. Summarization techniques including TextRank, Luhn, and GPT-3 are
evaluated to concisely summarize eligibility requirements. Evaluation with
ROUGE scores demonstrates the effectiveness of the proposed methods. This
system shows potential for automating clinical trial eligibility assessment
using data-driven approaches, thereby improving research efficiency.

</details>


### [98] [Stable LLM Ensemble: Interaction between Example Representativeness and Diversity](https://arxiv.org/abs/2510.13143)
*Junichiro Niimi*

Main category: cs.CL

TL;DR: 该研究表明，通过选择代表性样本并增加温度，可以显著提高一次性LLM集成的效果。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过样本选择与输出多样性控制来提高一次性LLM预测的准确性和鲁棒性。

Method: 研究比较了两种一次性策略：基于质心的代表性样本和随机抽样样本，同时通过变化采样温度分析其对LLM集成性能的影响。

Result: 该研究探讨了一次性大型语言模型（LLM）预测的准确性和鲁棒性，重点分析了样本代表性和输出多样性对LLM集成性能的影响。通过比较基于质心的代表性样本（提出的方法）与随机抽样样本（基线）的效果，并变化采样温度进行实验。结果表明，在较高温度设置下，提出方法在宏F1分数上优于随机选择策略7.6%，在RMSE上降低10.5%。而且，提出模型在宏F1得分上超越5次提示21.1%，在RMSE上降低24%。

Conclusion: 结合代表性样本选择与增加温度设置能够为LLM集成提供适当的多样性水平，从而显著提高其性能。

Abstract: Large language models (LLMs) have achieved remarkable results in wide range
of domains. However, the accuracy and robustness of one-shot LLM predictions
remain highly sensitive to the examples and the diversity among ensemble
members. This study systematically investigates the effects of example
representativeness (one-shot strategy) and output diversity (sampling
temperature) on LLM ensemble performance. Two one-shot strategies are compared:
centroid-based representative examples (proposed) and randomly sampled examples
(baseline) and sampling temperature also is varied. The proposed approach with
higher temperature setting significantly outperforms random selection by +7.6%
(macro-F1) and -10.5% (RMSE). Furthermore, the proposed model exceeds 5-shot
prompting by +21.1% (macro-F1) and -24.0% (RMSE). Our findings demonstrate that
combining representative example selection with increased temperature provides
the appropriate level of diversity to the ensemble. This work highlights the
practical importance of both example selection and controlled diversity in
designing effective one-shot LLM ensembles.

</details>


### [99] [I Am Aligned, But With Whom? MENA Values Benchmark for Evaluating Cultural Alignment and Multilingual Bias in LLMs](https://arxiv.org/abs/2510.13154)
*Pardis Sadat Zahraei,Ehsaneddin Asgari*

Main category: cs.CL

TL;DR: MENAValues 是一个用于评估大型语言模型与中东北非文化对齐和多语言偏见的新基准。


<details>
  <summary>Details</summary>
Motivation: 当前的AI评估工作中，中东和北非地区的信仰和价值观往往没有被充分代表。因此，我们设计MENAValues这一新基准，以评估大型语言模型在文化对齐和多语言偏见方面的表现。

Method: 我们从大规模、权威的人类调查中提取数据，形成一个结构化数据集，以人口水平的响应分布来捕捉中东北非地区的社会文化景观。通过交叉三种视角框架（中立、个性化和第三人称/文化观察者）与两种语言模式（英语和当地本土语言：阿拉伯语、波斯语、土耳其语）来评估不同模型的行为。

Result: 分析揭示了三个关键现象："跨语言价值转变"，即相同问题因语言不同而产生显著不同的回答；"推理导致的退化"，即要求模型解释其推理过程时，文化对齐性变差；以及"Logit泄漏"，即模型拒绝敏感问题，而内部概率却透露出强烈的隐性偏好。

Conclusion: MENAValues 提供了一个可扩展的框架，用于诊断文化不对齐问题，并为开发更加文化包容的AI提供了实证见解和方法工具。

Abstract: We introduce MENAValues, a novel benchmark designed to evaluate the cultural
alignment and multilingual biases of large language models (LLMs) with respect
to the beliefs and values of the Middle East and North Africa (MENA) region, an
underrepresented area in current AI evaluation efforts. Drawing from
large-scale, authoritative human surveys, we curate a structured dataset that
captures the sociocultural landscape of MENA with population-level response
distributions from 16 countries. To probe LLM behavior, we evaluate diverse
models across multiple conditions formed by crossing three perspective framings
(neutral, personalized, and third-person/cultural observer) with two language
modes (English and localized native languages: Arabic, Persian, Turkish). Our
analysis reveals three critical phenomena: "Cross-Lingual Value Shifts" where
identical questions yield drastically different responses based on language,
"Reasoning-Induced Degradation" where prompting models to explain their
reasoning worsens cultural alignment, and "Logit Leakage" where models refuse
sensitive questions while internal probabilities reveal strong hidden
preferences. We further demonstrate that models collapse into simplistic
linguistic categories when operating in native languages, treating diverse
nations as monolithic entities. MENAValues offers a scalable framework for
diagnosing cultural misalignment, providing both empirical insights and
methodological tools for developing more culturally inclusive AI.

</details>


### [100] [Mirror Speculative Decoding: Breaking the Serial Barrier in LLM Inference](https://arxiv.org/abs/2510.13161)
*Nikhil Bhendawade,Kumari Nishu,Arnav Kundu,Chris Bartels,Minsik Cho,Irina Belousova*

Main category: cs.CL

TL;DR: Mirror-SD enhances LLM inference by parallel execution and multi-token streaming, achieving up to 5.8x speedups and a 30% improvement over existing methods.


<details>
  <summary>Details</summary>
Motivation: The motivation is to overcome the limitations of previous speculative decoding methods, which are constrained by draft generation costs, leading to a tradeoff between accelerating inference speed and maintaining high acceptance rates.

Method: The paper introduces Mirror Speculative Decoding (Mirror-SD), an inference algorithm that breaks latency-acceptance tradeoff by utilizing parallel heterogeneous execution across devices and speculative streaming to emit multiple tokens per step.

Result: Mirror-SD achieves 2.8x-5.8x speedups on end-to-end tasks and provides a 30% average relative improvement over the strongest baseline, EAGLE3, on server-scale models ranging from 14B to 66B parameters.

Conclusion: Mirror Speculative Decoding (Mirror-SD) significantly improves the efficiency of large language model inference.

Abstract: Speculative decoding accelerates LLM inference by using a draft model to look
ahead, but gains are capped by the cost of autoregressive draft generation:
increasing draft size elevates acceptance rates but introduces additional
latency overhead exacerbating the speed-accuracy tradeoff. Prior methods
(Medusa, Hydra, EAGLE) partially reduce draft cost but either degrade
acceptance or introduce overheads that limit scaling. We present Mirror
Speculative Decoding (Mirror-SD), an inference algorithm that breaks the
latency-acceptance tradeoff. Mirror-SD launches branch-complete rollouts from
early-exit signals in parallel with the target model's suffix and explicitly
maps computation across heterogeneous accelerators (GPU and NPU) to exploit
cross-device parallelism. The draft speculates forward continuations for the
target to verify, while the target simultaneously speculates correction paths
for the draft, converting speculation into two complementary execution
pipelines. To further cut draft latency without weakening acceptance semantics,
we add speculative streaming so the draft emits multiple tokens per step. This
dual strategy of parallel heterogeneous execution plus multi-token speculative
streaming pushes speculative decoding toward its ideal regime of high
acceptance with low overhead. On SpecBench with server-scale models from 14B to
66B parameters, Mirror-SD delivers consistent end-to-end gains, achieving
2.8x-5.8x wall-time speedups across diverse tasks and a 30% average relative
improvement over the strongest baseline, EAGLE3.

</details>


### [101] [CoT-Evo: Evolutionary Distillation of Chain-of-Thought for Scientific Reasoning](https://arxiv.org/abs/2510.13166)
*Kehua Feng,Keyan Ding,Zhihui Zhu,Lei Liang,Qiang Zhang,Huajun Chen*

Main category: cs.CL

TL;DR: 提出了一种名为CoT-Evo的进化推理蒸馏框架，通过改进和精炼推理路径，增强科学领域的小模型能力，实现了在科学推理基准中的领先表现。


<details>
  <summary>Details</summary>
Motivation: 虽然从先进的大型语言模型（LLMs）中进行推理路径（CoT）蒸馏在一般推理任务中效果显著，但在科学领域中，由于其复杂性和专业知识要求，即使是高级模型也会产生错误或肤浅的推理。直接从这些有缺陷的输出中进行蒸馏会导致低质量的训练数据，限制了较小学生模型的性能。

Method: 研究者开发了一个名为CoT-Evo的进化推理蒸馏框架，通过构建不同的推理路径池，自动增加领域知识，并且进行基于新颖性驱动的选择、反射性重组和变异的迭代精炼。采用一个评价函数来评估答案的正确性、一致性和有效知识利用来指导精炼过程。

Result: 通过使用进化后的数据集，对紧凑模型进行了微调，在科学推理基准测试中达到了最先进的性能。

Conclusion: 研究通过提出CoT-Evo进化推理蒸馏框架，有效地提升了在科学推理领域的小模型的表现。

Abstract: While chain-of-thought (CoT) distillation from advanced large language models
(LLMs) has proven effective in general reasoning tasks, it struggles in
scientific domains where even advanced models often produce incorrect or
superficial reasoning due to high complexity and specialized knowledge
requirements. Directly distilling from such flawed outputs results in
low-quality training data and limits the performance of smaller student models.
To overcome this, we propose CoT-Evo, an evolutionary CoT distillation
framework. It begins by constructing a diverse pool of reasoning trajectories
from multiple LLM thinkers, enriches them with automatically retrieved domain
knowledge, and iteratively refines the trajectories using novelty-driven
selection, reflective recombination and mutation. The refinement is guided by a
fitness function that evaluates answer correctness, coherence, and effective
knowledge utilization. This results in a high-quality CoT dataset tailored for
scientific reasoning. We employ this evolved dataset to fine-tune a compact
model, which achieves state-of-the-art performance on scientific reasoning
benchmarks. Our work establishes a scalable approach to synthesizing
high-fidelity scientific reasoning data from diverse and fallible LLMs.

</details>


### [102] [Putting on the Thinking Hats: A Survey on Chain of Thought Fine-tuning from the Perspective of Human Reasoning Mechanism](https://arxiv.org/abs/2510.13170)
*Xiaoshu Chen,Sihang Zhou,Ke Liang,Duanyang Yuan,Haoyuan Chen,Xiaoyu Sun,Linyuan Meng,Xinwang Liu*

Main category: cs.CL

TL;DR: 该文通过人类推理理论研究CoT微调，首次从六种思考帽子框架出发进行分类和检验，并提供未来研究方向指导及实时GitHub跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有的关于连锁思维（CoT）微调的研究主要集中在技术方面，缺乏从人类推理机制的角度进行系统分析。考虑到CoT微调的最终目标是使大语言模型（LLM）的推理方式更接近人类，因此从人类认知的角度来研究这一技术尤为重要。

Method: 该论文首次从以人为基础的推理理论出发，通过受著名的六种思考帽子框架的启发，将其系统地应用于CoT微调方法的分类和检验。

Result: 通过对CoT微调方法进行分类和检验，该论文为未来的研究提供了理论基础，并总结了现有数据集和模型性能的全面概况。

Conclusion: 该论文提供了一个全面的CoT微调调查，基于人类推理理论。它为未来的研究方向提供了指导，并维持一个实时更新的GitHub仓库以追踪该领域的最新进展。

Abstract: Chain of thought (CoT) fine-tuning aims to endow large language models (LLMs)
with reasoning capabilities by training them on curated reasoning traces. It
leverages both supervised and reinforced fine-tuning to cultivate human-like
reasoning skills in LLMs, including detailed planning, divergent thinking,
intuitive judgment, timely reflection, internal thinking, and fact perception,
etc. As CoT fine-tuning has advanced, LLMs have demonstrated substantial
improvements in tasks such as mathematical reasoning and code generation.
However, existing surveys about CoT fine-tuning primarily focus on technical
aspects and overlook a systematic analysis from the perspective of human
reasoning mechanisms. Given that the ultimate goal of CoT fine-tuning is to
enable LLMs to reason like humans, it is crucial to investigate this technique
through the lens of human cognition. To fill this gap, we present the first
comprehensive survey of CoT fine-tuning grounded in human reasoning theory.
Specifically, inspired by the well-known Six Thinking Hats framework, which
systematically characterizes common human thinking modes using six metaphorical
hats, we classify and examine CoT fine-tuning methods through this lens.
Furthermore, building upon this theory, we outline potential directions for
future research in CoT fine-tuning. In addition, we compile a comprehensive
overview of existing datasets and model performances, and a real-time GitHub
repository \footnote{https://github.com/AI-Chen/Awesome-CoT-Finetuning} that
continuously tracks recent advances in this area is maintained. We hope this
survey will serve as a valuable resource to inspire innovation and foster
progress in this rapidly evolving field.

</details>


### [103] [DSCD: Large Language Model Detoxification with Self-Constrained Decoding](https://arxiv.org/abs/2510.13183)
*Ming Dong,Jinkui Zhang,Bolong Zheng,Xinhui Tu,Po Hu,Tingting He*

Main category: cs.CL

TL;DR: 本文提出了一种名为“自约束解码的去毒化（DSCD）”的新方法，不需要参数微调，该方法可以在保持生成流畅性的同时，提高生成内容的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的去毒化解码方法依赖外部约束，导致需要额外的资源开销并降低生成流畅性。因此，研究了一种无需参数微调的自约束去毒化解决方案。

Method: 通过在生成输出期间增强安全层的下一个令牌分布，同时减弱幻觉和有害层的下一个令牌分布，从而实现去毒化。

Result: DSCD在开放源码的大型语言模型和公共数据集上的大量实验验证了其有效性，表现出在去毒化和生成流畅性方面的最新技术表现，并且与现有方法相比具有效率优势。

Conclusion: DSCD被证明为一种轻量级、高兼容性、即插即用的解决方案，可与现有去毒化方法集成以进一步提高性能，被视为更安全的语言模型部署的实用且可扩展的解决方案。

Abstract: Detoxification in large language models (LLMs) remains a significant research
challenge. Existing decoding detoxification methods are all based on external
constraints, which require additional resource overhead and lose generation
fluency. This work proposes Detoxification with Self-Constrained Decoding
(DSCD), a novel method for LLM detoxification without parameter fine-tuning.
DSCD strengthens the inner next-token distribution of the safety layer while
weakening that of hallucination and toxic layers during output generation. This
effectively diminishes toxicity and enhances output safety. DSCD offers
lightweight, high compatibility, and plug-and-play capabilities, readily
integrating with existing detoxification methods for further performance
improvement. Extensive experiments on representative open-source LLMs and
public datasets validate DSCD's effectiveness, demonstrating state-of-the-art
(SOTA) performance in both detoxification and generation fluency, with superior
efficiency compared to existing methods. These results highlight DSCD's
potential as a practical and scalable solution for safer LLM deployments.

</details>


### [104] [SHIELD: Classifier-Guided Prompting for Robust and Safer LVLMs](https://arxiv.org/abs/2510.13190)
*Juan Ren,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: SHIELD是一种安全框架，可减少对大型视觉语言模型的攻击风险，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在多模态推理中表现良好，但容易受到恶意输入的攻击，因而需要一个有效的安全措施。

Method: SHIELD通过细粒度的安全分类结合类别特定的指导和明确的动作（如阻止、重构、转发）来实现。

Result: 这篇论文提出了一种名为SHIELD的轻量级模型无关预处理框架，用于增强大型视觉语言模型（LVLMs）的安全性。

Conclusion: SHIELD能够显著降低LVLMs的攻击风险，同时保持模型的实用性和可扩展性。

Abstract: Large Vision-Language Models (LVLMs) unlock powerful multimodal reasoning but
also expand the attack surface, particularly through adversarial inputs that
conceal harmful goals in benign prompts. We propose SHIELD, a lightweight,
model-agnostic preprocessing framework that couples fine-grained safety
classification with category-specific guidance and explicit actions (Block,
Reframe, Forward). Unlike binary moderators, SHIELD composes tailored safety
prompts that enforce nuanced refusals or safe redirection without retraining.
Across five benchmarks and five representative LVLMs, SHIELD consistently
lowers jailbreak and non-following rates while preserving utility. Our method
is plug-and-play, incurs negligible overhead, and is easily extendable to new
attack types -- serving as a practical safety patch for both weakly and
strongly aligned LVLMs.

</details>


### [105] [Grounding Long-Context Reasoning with Contextual Normalization for Retrieval-Augmented Generation](https://arxiv.org/abs/2510.13191)
*Jiamin Chen,Yuchen Li,Xinyu Ma,Xinran Chen,Xiaokun Zhang,Shuaiqiang Wang,Chen Ma,Dawei Yin*

Main category: cs.CL

TL;DR: 研究发现RAG的表现受上下文格式的显著影响，并提出Contextual Normalization策略来改善长上下文推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管先前的研究主要专注于检索质量和提示策略，但在检索到的文档如何被构建上，即上下文格式的影响仍未得到充分探索。

Method: 设计控制实验以改变上下文的密度、分隔符样式和位置放置，以揭示导致性能差异的潜在因素。同时，引入一种称为Contextual Normalization的策略，用于在生成之前标准化上下文表示。

Result: 实验证明，Contextual Normalization策略在多种RAG基准测试中提高了对顺序变化的鲁棒性，并增强了长上下文的利用能力。

Conclusion: 这项研究表明，RAG的性能不仅依赖于检索的内容，还依赖于这些内容的呈现方式。

Abstract: Retrieval-Augmented Generation (RAG) has become an essential approach for
extending the reasoning and knowledge capacity of large language models (LLMs).
While prior research has primarily focused on retrieval quality and prompting
strategies, the influence of how the retrieved documents are framed, i.e.,
context format, remains underexplored. We show that seemingly superficial
choices, such as delimiters or structural markers in key-value extraction, can
induce substantial shifts in accuracy and stability, even when semantic content
is identical. To systematically investigate this effect, we design controlled
experiments that vary context density, delimiter styles, and positional
placement, revealing the underlying factors that govern performance
differences. Building on these insights, we introduce Contextual Normalization,
a lightweight strategy that adaptively standardizes context representations
before generation. Extensive experiments on both controlled and real-world RAG
benchmarks across diverse settings demonstrate that the proposed strategy
consistently improves robustness to order variation and strengthens
long-context utilization. These findings underscore that reliable RAG depends
not only on retrieving the right content, but also on how that content is
presented, offering both new empirical evidence and a practical technique for
better long-context reasoning.

</details>


### [106] [StressTransfer: Stress-Aware Speech-to-Speech Translation with Emphasis Preservation](https://arxiv.org/abs/2510.13194)
*Xi Chen,Yuchen Song,Satoshi Nakamura*

Main category: cs.CL

TL;DR: 研究提出了一种语音到语音翻译系统，能够识别并翻译语音中的重读，并通过大语言模型进行跨语种重读转换。


<details>
  <summary>Details</summary>
Motivation: 解决现有语音翻译中无法保持词重读这一缺陷，并利用大语言模型来改善跨语言的重读转换。

Method: 该方法通过翻译源语中的重音到目标语言标签，并利用可控TTS模型进行合成。此外，为克服数据匮乏，研究开发了一条自动生成对齐训练数据的流程，并引入'LLM-as-Judge'进行评估。

Result: 实验显示，该方法在保持翻译重音方面显著优于基线，同时保持了可比较的翻译质量、说话者意图和自然度。

Conclusion: 该研究表明，重音在翻译中的重要性，并提供了一种有效的数据节约方案，以在语音到语音的翻译中保留副语言提示。

Abstract: We propose a stress-aware speech-to-speech translation (S2ST) system that
preserves word-level emphasis by leveraging LLMs for cross-lingual emphasis
conversion. Our method translates source-language stress into target-language
tags that guide a controllable TTS model. To overcome data scarcity, we
developed a pipeline to automatically generate aligned training data and
introduce the "LLM-as-Judge" for evaluation. Experiments show our approach
substantially outperforms baselines in preserving emphasis while maintaining
comparable translation quality, speaker intent, and naturalness. Our work
highlights the importance of prosody in translation and provides an effective,
data-efficient solution for preserving paralinguistic cues in S2ST.

</details>


### [107] [Text Anomaly Detection with Simplified Isolation Kernel](https://arxiv.org/abs/2510.13197)
*Yang Cao,Sikun Yang,Yujiu Yang,Lianyong Qi,Ming Liu*

Main category: cs.CL

TL;DR: SIK通过简化隔离内核，降低大型语言模型嵌入的复杂性，提升异常检测性能并减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型提取的高维密集嵌入因内存需求大和计算时间长而带来的挑战。

Method: 引入简化隔离内核（SIK），将高维密集嵌入映射为低维稀疏表示，保留异常特征，具有线性时间复杂度并减少空间复杂度。

Result: 在7个数据集上的实验表明，SIK在检测性能方面优于11种最新的异常检测算法，同时保持计算效率和低内存消耗。

Conclusion: SIK方法在降低计算复杂性和内存需求方面表现优异，同时在多数据集上表现出色的异常检测性能。

Abstract: Two-step approaches combining pre-trained large language model embeddings and
anomaly detectors demonstrate strong performance in text anomaly detection by
leveraging rich semantic representations. However, high-dimensional dense
embeddings extracted by large language models pose challenges due to
substantial memory requirements and high computation time. To address this
challenge, we introduce the Simplified Isolation Kernel (SIK), which maps
high-dimensional dense embeddings to lower-dimensional sparse representations
while preserving crucial anomaly characteristics. SIK has linear time
complexity and significantly reduces space complexity through its innovative
boundary-focused feature mapping. Experiments across 7 datasets demonstrate
that SIK achieves better detection performance than 11 state-of-the-art (SOTA)
anomaly detection algorithms while maintaining computational efficiency and low
memory cost. All code and demonstrations are available at
https://github.com/charles-cao/SIK.

</details>


### [108] [LLM-Guided Synthetic Augmentation (LGSA) for Mitigating Bias in AI Systems](https://arxiv.org/abs/2510.13202)
*Sai Suhruth Reddy Karri,Yashwanth Sai Nallapuneni,Laxmi Narasimha Reddy Mallireddy,Gopichand G*

Main category: cs.CL

TL;DR: 本研究提出了一种新方法LGSA，利用大语言模型生成反事实示例，以减少AI系统中的性别偏见，同时保持高准确率。


<details>
  <summary>Details</summary>
Motivation: AI系统中的偏见，特别是依赖自然语言数据的系统，会引发伦理和实际问题。某些群体的代表性不足往往导致不同人口统计之间的性能不均衡。

Method: 提出了一种名为LLM引导合成增强（LGSA）的新方法，使用大型语言模型生成反事实示例，以提高代表性不足群体的数据覆盖，同时保持标签完整性。在一个受控的数据集中，通过结构化提示生成性别转换的复述，并进行语义相似性检查、属性验证、毒性筛选和人工检查。

Result: 通过使用LGSA增强的数据集进行训练，模型在保持高准确率的同时减少了性别偏差。对比基线模型和简单替换增强方法，LGSA在减少偏差方面表现出色，同时提高了女性标记示例的表现。

Conclusion: LGSA是一个有效的策略，能够在保持任务高准确率和标签完整性的同时，减少偏见并增强子群体平衡。

Abstract: Bias in AI systems, especially those relying on natural language data, raises
ethical and practical concerns. Underrepresentation of certain groups often
leads to uneven performance across demographics. Traditional fairness methods,
such as pre-processing, in-processing, and post-processing, depend on
protected-attribute labels, involve accuracy-fairness trade-offs, and may not
generalize across datasets. To address these challenges, we propose LLM-Guided
Synthetic Augmentation (LGSA), which uses large language models to generate
counterfactual examples for underrepresented groups while preserving label
integrity. We evaluated LGSA on a controlled dataset of short English sentences
with gendered pronouns, professions, and binary classification labels.
Structured prompts were used to produce gender-swapped paraphrases, followed by
quality control including semantic similarity checks, attribute verification,
toxicity screening, and human spot checks. The augmented dataset expanded
training coverage and was used to train a classifier under consistent
conditions. Results show that LGSA reduces performance disparities without
compromising accuracy. The baseline model achieved 96.7 percent accuracy with a
7.2 percent gender bias gap. Simple swap augmentation reduced the gap to 0.7
percent but lowered accuracy to 95.6 percent. LGSA achieved 99.1 percent
accuracy with a 1.9 percent bias gap, improving performance on female-labeled
examples. These findings demonstrate that LGSA is an effective strategy for
bias mitigation, enhancing subgroup balance while maintaining high task
accuracy and label fidelity.

</details>


### [109] [A fully automated and scalable Parallel Data Augmentation for Low Resource Languages using Image and Text Analytics](https://arxiv.org/abs/2510.13211)
*Prawaal Sharma,Navneet Goyal,Poonam Goyal,Vishnupriyan R*

Main category: cs.CL

TL;DR: 文章介绍了一种从报纸文章中提取双语平行语料库的新方法，并在机器翻译中提高了性能。


<details>
  <summary>Details</summary>
Motivation: 全球语言多样性导致高质量数字语言资源的差异，限制了大多数人群获得技术利益的机会。低资源语言缺乏数据资源，难以进行NLP任务。

Method: 提出了一种新颖可扩展的全自动方法，结合图像和文本分析技术，从报纸文章中提取双语平行语料库。

Result: 通过两个不同语言组合构建了平行数据语料库，并在机器翻译的下游任务中验证了数据集的价值，相比当前基线提高了近3个BLEU点。

Conclusion: 通过新的可扩展自动化方法，可以从报纸文章中提取双语平行语料库，改善低资源语言的NLP任务表现。

Abstract: Linguistic diversity across the world creates a disparity with the
availability of good quality digital language resources thereby restricting the
technological benefits to majority of human population. The lack or absence of
data resources makes it difficult to perform NLP tasks for low-resource
languages. This paper presents a novel scalable and fully automated methodology
to extract bilingual parallel corpora from newspaper articles using image and
text analytics. We validate our approach by building parallel data corpus for
two different language combinations and demonstrate the value of this dataset
through a downstream task of machine translation and improve over the current
baseline by close to 3 BLEU points.

</details>


### [110] [Hierarchical Frequency Tagging Probe (HFTP): A Unified Approach to Investigate Syntactic Structure Representations in Large Language Models and the Human Brain](https://arxiv.org/abs/2510.13255)
*Jingmin An,Yilong Song,Ruolin Yang,Nai Ding,Lingxi Lu,Yuxuan Wang,Wei Wang,Chu Zhuang,Qian Wang,Fang Fang*

Main category: cs.CL

TL;DR: 该研究引入了层级频率标记探针（HFTP），用于探测大型语言模型（LLM）和人脑中的句法结构编码。研究发现，LLM和人脑在处理句法时的层级存在差异，尤其是左脑与LLM的表示更为一致。此外，不同升级版本的模型与人脑的相似性不同。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型的行为能力是否来源于类似于人类大脑的机制，以及识别负责这些能力的具体计算模块。

Method: 研究引入了层级频率标记探针（HFTP），利用频域分析识别大型语言模型的神经元成分和人脑皮层区域的句法结构编码。

Result: 结果显示，GPT-2、Gemma 系列和Llama系列模型在类似层级处理中，而人脑在不同句法水平上依赖不同皮层区域。不同模型更新版本与大脑相似性存在差异：Gemma 2与大脑的相似性优于Gemma，而Llama 3.1与大脑的一致性不如Llama 2。

Conclusion: 研究表明，大型语言模型在处理句法结构时，与人类大脑有部分相似性，尤其是与语言处理主导的左半球表现出更强的一致性。然而，不同模型版本与人脑的一致性有差异，这提示LLM的行为改进可能受到与人类相似或不相似的机制驱动。

Abstract: Large Language Models (LLMs) demonstrate human-level or even superior
language abilities, effectively modeling syntactic structures, yet the specific
computational modules responsible remain unclear. A key question is whether LLM
behavioral capabilities stem from mechanisms akin to those in the human brain.
To address these questions, we introduce the Hierarchical Frequency Tagging
Probe (HFTP), a tool that utilizes frequency-domain analysis to identify
neuron-wise components of LLMs (e.g., individual Multilayer Perceptron (MLP)
neurons) and cortical regions (via intracranial recordings) encoding syntactic
structures. Our results show that models such as GPT-2, Gemma, Gemma 2, Llama
2, Llama 3.1, and GLM-4 process syntax in analogous layers, while the human
brain relies on distinct cortical regions for different syntactic levels.
Representational similarity analysis reveals a stronger alignment between LLM
representations and the left hemisphere of the brain (dominant in language
processing). Notably, upgraded models exhibit divergent trends: Gemma 2 shows
greater brain similarity than Gemma, while Llama 3.1 shows less alignment with
the brain compared to Llama 2. These findings offer new insights into the
interpretability of LLM behavioral improvements, raising questions about
whether these advancements are driven by human-like or non-human-like
mechanisms, and establish HFTP as a valuable tool bridging computational
linguistics and cognitive neuroscience. This project is available at
https://github.com/LilTiger/HFTP.

</details>


### [111] [Do You Get the Hint? Benchmarking LLMs on the Board Game Concept](https://arxiv.org/abs/2510.13271)
*Ine Gevers,Walter Daelemans*

Main category: cs.CL

TL;DR: 大型语言模型在评估中显示出与人类完成任务的能力差距，并且在低资源语言中的表现更差。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在抽象推理任务中的弱点，尤其是那些与其训练数据不同的表示形式。

Method: 使用概念猜词游戏作为衡量大型语言模型在自然语言中进行溯因推理的基准。

Result: 人类在概念猜词游戏中的成功率超过90%，而大型语言模型的成功率不超过40%。此外，在低资源语言中的表现比英语还要低。

Conclusion: 概念猜词游戏揭示了大型语言模型在自然语言中的溯因推理挑战，这表明需要进一步改进其处理抽象推理任务的能力。

Abstract: Large language models (LLMs) have achieved striking successes on many
benchmarks, yet recent studies continue to expose fundamental weaknesses. In
particular, tasks that require abstract reasoning remain challenging, often
because they use representations such as grids, symbols, or visual patterns
that differ from the natural language data LLMs are trained on. In this paper,
we introduce Concept, a simple word-guessing board game, as a benchmark for
probing abductive reasoning in a representation that is much closer to LLM
pre-training data: natural language. Our results show that this game, easily
solved by humans (with a success rate of over 90\%), is still very challenging
for state-of-the-art LLMs (no model exceeds 40\% success rate). Specifically,
we observe that LLMs struggle with interpreting other players' strategic
intents, and with correcting initial hypotheses given sequential information
updates. In addition, we extend the evaluation across multiple languages, and
find that the LLM performance drops further in lower-resource languages (Dutch,
French, and Spanish) compared to English.

</details>


### [112] [Beyond Correctness: Rewarding Faithful Reasoning in Retrieval-Augmented Generation](https://arxiv.org/abs/2510.13272)
*Zhichao Xu,Zongyu Wu,Yun Zhou,Aosong Feng,Kang Zhou,Sangmin Woo,Kiran Ramnath,Yijun Tian,Xuan Qi,Weikang Qiu,Lin Lee Cheong,Haibo Ding*

Main category: cs.CL

TL;DR: The paper presents VERITAS, a framework enhancing reasoning faithfulness in LLMs trained with RL for search engine use, maintaining performance across benchmarks.


<details>
  <summary>Details</summary>
Motivation: Current RL-based methods for training LLMs with search engines tend to prioritize final answer correctness, overlooking the faithfulness of intermediate reasoning steps. This can lead to chain-of-thought unfaithfulness, necessitating a focus on improving reasoning faithfulness.

Method: The paper introduces VERITAS, a framework that integrates fine-grained faithfulness rewards into the reinforcement learning process to improve reasoning faithfulness of search agents.

Result: Models trained with VERITAS show a significant improvement in reasoning faithfulness and maintain comparable task performance across various QA benchmarks.

Conclusion: VERITAS significantly improves reasoning faithfulness in RL-based search agents without compromising task performance across QA benchmarks.

Abstract: Inspired by the success of reinforcement learning (RL) in Large Language
Model (LLM) training for domains like math and code, recent works have begun
exploring how to train LLMs to use search engines more effectively as tools for
retrieval-augmented generation. Although these methods achieve performance
improvement across QA benchmarks, many prioritize final answer correctness
while overlooking the quality of intermediate reasoning steps, which may lead
to chain-of-thought unfaithfulness. In this paper, we first introduce a
comprehensive evaluation framework for evaluating RL-based search agents,
covering three distinct faithfulness metrics: information-think faithfulness,
think-answer faithfulness, and think-search faithfulness. Our evaluations
reveal that a prototypical RL-based search agent, Search-R1, has significant
room for improvement in this regard. To foster faithful reasoning, we introduce
VERITAS (Verifying Entailed Reasoning through Intermediate Traceability in
Agentic Search), a novel framework that integrates fine-grained faithfulness
rewards into the reinforcement learning process. Our experiments show that
models trained with VERITAS not only significantly improve reasoning
faithfulness, but also achieve comparable task performance across seven QA
benchmarks.

</details>


### [113] [In-Distribution Steering: Balancing Control and Coherence in Language Model Generation](https://arxiv.org/abs/2510.13285)
*Arthur Vogels,Benjamin Wong,Yann Choho,Annabelle Blangero,Milan Bhan*

Main category: cs.CL

TL;DR: 论文提出了一种动态调整控制强度的方法，提升大型语言模型的文本生成表现。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数激活控制方法依赖于固定的控制强度，可能导致控制不足或适应性不佳的问题，因此需要一种能够根据输入自适应调整的控制方法。

Method: 采用了一种称为“分布内控制”（IDS）的方法，根据输入在表示空间的分布位置，动态地调整干预强度，从而在文本生成过程中实现适应性干预和稳定性。

Result: 这篇论文引入了一种称为“分布内控制”的新方法，旨在通过基于输入数据分布动态调整控制强度，改进大型语言模型在推理时的行为控制。

Conclusion: 实验表明，IDS在分类任务中取得了高准确性，同时生成的文本连贯且稳定，适用于真实世界的应用。

Abstract: Activation steering methods control large language model (LLM) behavior by
modifying internal activations at inference time. However, most existing
activation steering methods rely on a fixed steering strength, leading to
either insufficient control or unadapted intervention that degrades text
plausibility and coherence. We introduce In-Distribution Steering (IDS), a
novel method that adapts steering strength based on the input data distribution
in representation space. IDS dynamically adjusts interventions according to how
far a given input lies within the distribution, enabling adaptive intervention
and generation stability during text generation. Experiments demonstrate that
IDS achieves strong accuracy on classification tasks while producing coherent
text without collapse, making IDS particularly well suited for real-world
applications.

</details>


### [114] [Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models](https://arxiv.org/abs/2510.13293)
*Yizhou Peng,Yukun Ma,Chong Zhang,Yi-Wen Chao,Chongjia Ni,Bin Ma*

Main category: cs.CL

TL;DR: 提出了自适应CFG以解决AR TTS模型中风格与内容的冲突问题。


<details>
  <summary>Details</summary>
Motivation: 解决文本与语音风格冲突导致语音不自然的问题。

Method: 通过检测到的风格与内容不匹配程度，自适应调整不使用分类器的引导（CFG）方案。

Result: 自适应CFG方案在改善AR TTS模型的情感表达性时，同时保持了音频质量和可懂度。

Conclusion: 通过对不使用分类器的引导进行自适应调整，实现了改善情感表达与音频质量的双重效果。

Abstract: While Text-to-Speech (TTS) systems can achieve fine-grained control over
emotional expression via natural language prompts, a significant challenge
emerges when the desired emotion (style prompt) conflicts with the semantic
content of the text. This mismatch often results in unnatural-sounding speech,
undermining the goal of achieving fine-grained emotional control.
Classifier-Free Guidance (CFG) is a key technique for enhancing prompt
alignment; however, its application to auto-regressive (AR) TTS models remains
underexplored, which can lead to degraded audio quality. This paper directly
addresses the challenge of style-content mismatch in AR TTS models by proposing
an adaptive CFG scheme that adjusts to different levels of the detected
mismatch, as measured using large language models or natural language inference
models. This solution is based on a comprehensive analysis of CFG's impact on
emotional expressiveness in state-of-the-art AR TTS models. Our results
demonstrate that the proposed adaptive CFG scheme improves the emotional
expressiveness of the AR TTS model while maintaining audio quality and
intelligibility.

</details>


### [115] [LLM one-shot style transfer for Authorship Attribution and Verification](https://arxiv.org/abs/2510.13302)
*Pablo Miralles-González,Javier Huertas-Tato,Alejandro Martín,David Camacho*

Main category: cs.CL

TL;DR: 提出了一种利用LLM预训练和上下文学习的无监督方法，改进了写作风格分析的准确性，同时在成本和精度之间提供灵活的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法常常混淆风格与主题，CLM预训练的现代LLM在作者身份问题中尚未得到充分利用。

Method: 我们提出了一种基于LLM大规模预训练和其上下文学习能力的无监督方法，使用LLM的对数概率衡量文本间的风格可迁移性。

Result: 我们的方法在控制主题相关性时具有更高的准确性，并且性能随着基础模型的规模相对一致地扩展。对于作者身份验证，还包括一种在测试时增加计算的机制，提高了灵活性的计算成本与准确性之间的权衡。

Conclusion: 我们的无监督方法在控制主题相关性时显著优于对比学习的基线，并在可比规模的LLM提示方法中表现更佳。

Abstract: Computational stylometry analyzes writing style through quantitative patterns
in text, supporting applications from forensic tasks such as identity linking
and plagiarism detection to literary attribution in the humanities. Supervised
and contrastive approaches rely on data with spurious correlations and often
confuse style with topic. Despite their natural use in AI-generated text
detection, the CLM pre-training of modern LLMs has been scarcely leveraged for
general authorship problems. We propose a novel unsupervised approach based on
this extensive pre-training and the in-context learning capabilities of LLMs,
employing the log-probabilities of an LLM to measure style transferability from
one text to another. Our method significantly outperforms LLM prompting
approaches of comparable scale and achieves higher accuracy than contrastively
trained baselines when controlling for topical correlations. Moreover,
performance scales fairly consistently with the size of the base model and, in
the case of authorship verification, with an additional mechanism that
increases test-time computation; enabling flexible trade-offs between
computational cost and accuracy.

</details>


### [116] [ChatR1: Reinforcement Learning for Conversational Reasoning and Retrieval Augmented Question Answering](https://arxiv.org/abs/2510.13312)
*Simon Lupart,Mohammad Aliannejadi,Evangelos Kanoulas*

Main category: cs.CL

TL;DR: ChatR1是一个基于强化学习的推理框架，通过动态的搜索和推理机制提升会话问答的效果，并在多个数据集上超越了现有模型。


<details>
  <summary>Details</summary>
Motivation: 在会话问答中，用户意图随着对话轮次不断变化，且发言通常欠缺具体描述，因此需要基于上下文进行解释、查询重构以及动态协调信息检索和生成。这些问题推动了ChatR1框架的提出。

Method: 该论文通过强化学习（RL）来构建ChatR1框架，在会话问答中进行推理。具体方法包括在对话轮次中交替进行搜索和推理，并通过一个意图感知奖励机制解决RL中稀疏和延迟奖励的问题。

Result: ChatR1在3B和7B模型架构上都展现出了强劲的性能，在五个CQA数据集上的表现优于竞争模型。同时，消融研究确认了意图感知奖励的有效性，分析揭示了多样的推理路径和工具使用的效果。ChatR1还在跨领域中表现出强大的泛化能力。

Conclusion: ChatR1通过引入基于强化学习的推理架构，为会话问答提供了一种有效的解决方案，能够在多个数据集上超越竞争对手。

Abstract: We present ChatR1, a reasoning framework based on reinforcement learning (RL)
for conversational question answering (CQA). Reasoning plays an important role
in CQA, where user intent evolves across dialogue turns, and utterances are
often underspecified, requiring contextual interpretation, query reformulation,
and dynamic coordination between retrieval and generation. Unlike static
`rewrite, retrieve, and generate' pipelines, ChatR1 interleaves search and
reasoning across turns, enabling exploratory and adaptive behaviors learned
through RL. To address the challenge of sparse and delayed rewards in RL, we
propose an intent-aware reward that provides turn-level feedback by aligning
retrieval and reasoning with evolving user goals. Our proposed ChatR1
demonstrates strong performance on both 3B and 7B model backbones,
outperforming competitive models on five CQA datasets, measured by different
metrics (F1, BERTScore, and LLM-as-judge). We include a diverse set of CQA
datasets to cover topic shifts, evolving intents, mixed-initiative dialogues,
and multi-document grounding, testing ChatR1's performance from various
aspects. Ablation studies confirm the effectiveness of the intent-aware reward.
Our analyses further reveal diverse reasoning trajectories and effective use of
the search tool. ChatR1 also generalizes robustly across domains, demonstrating
that RL-based reasoning enables more flexible and context-sensitive behavior
than static CQA pipelines.

</details>


### [117] [Embedding-Based Context-Aware Reranker](https://arxiv.org/abs/2510.13329)
*Ye Yuan,Mohammad Amin Shabani,Siqi Liu*

Main category: cs.CL

TL;DR: EBCAR是一种新的轻量级重排序框架，能够有效提升跨段信息检索的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 目前许多先进的重排序方法尽管使用了功能强大的预训练语言模型，但依然忽视了需要进行跨段推理的问题。为解决这一问题，提出了一种新的重排序框架。

Method: 提出了一种名为EBCAR的重排序框架，通过增强对段落的结构化信息理解和混合注意力机制，在嵌入的基础上实现对检索到的段落更好的跨段理解。

Result: 在ConTEB基准上，EBCAR相比于现有的重排序方法显示出更高的有效性。

Conclusion: EBCAR在需要跨段推理的信息检索中表现出色，并在准确性和效率上均具优势。

Abstract: Retrieval-Augmented Generation (RAG) systems rely on retrieving relevant
evidence from a corpus to support downstream generation. The common practice of
splitting a long document into multiple shorter passages enables finer-grained
and targeted information retrieval. However, it also introduces challenges when
a correct retrieval would require inference across passages, such as resolving
coreference, disambiguating entities, and aggregating evidence scattered across
multiple sources. Many state-of-the-art (SOTA) reranking methods, despite
utilizing powerful large pretrained language models with potentially high
inference costs, still neglect the aforementioned challenges. Therefore, we
propose Embedding-Based Context-Aware Reranker (EBCAR), a lightweight reranking
framework operating directly on embeddings of retrieved passages with enhanced
cross-passage understandings through the structural information of the passages
and a hybrid attention mechanism, which captures both high-level interactions
across documents and low-level relationships within each document. We evaluate
EBCAR against SOTA rerankers on the ConTEB benchmark, demonstrating its
effectiveness for information retrieval requiring cross-passage inference and
its advantages in both accuracy and efficiency.

</details>


### [118] [Taming the Fragility of KV Cache Eviction in LLM Inference](https://arxiv.org/abs/2510.13334)
*Yuan Feng,Haoyu Guo,JunLin Lv,S. Kevin Zhou,Xike Xie*

Main category: cs.CL

TL;DR: 语言模型的键值缓存导致大量开销，本文提出了新的策略和方法优化缓存淘汰，将生成质量损失最小化。


<details>
  <summary>Details</summary>
Motivation: 缓解Transformer键值缓存的内存和运行时开销问题。

Method: 提出了一种双步骤、线性时间的防御性聚合策略，设计了新的缓存淘汰方法DefensiveKV及其扩展Layer-DefensiveKV。

Result: 我们的方法在七个任务领域（18个数据集）中，将生成质量损失分别减小2.3倍和4.3倍，在20%的缓存大小下与最强基线相比。

Conclusion: 设定了新的性能标准，并通过最坏情况下的风险管理，为优化缓存淘汰开辟了新方向。

Abstract: Large language models have revolutionized natural language processing, yet
their deployment remains hampered by the substantial memory and runtime
overhead of the transformer's Key-Value cache. To mitigate this, recent methods
employ a scoring-aggregation framework to evict unimportant cache entries,
based on the stability assumption-that a fixed subset of entries remains
consistently important during generation. However, prior work has largely
focused on refining importance indicators for scoring, while defaulting to mean
aggregation due to a faithful trust in the stability assumption. In this work,
we argue that this underlying assumption is inherently fragile, making mean
aggregation highly vulnerable in extreme cases. To counter this, we propose a
simple yet elegant defensive aggregation strategy: a two-step, linear-time
approach that controls worst-case risk, thereby defending against extreme cases
with negligible computational overhead. Embodying this strategy, we propose a
novel cache eviction method, DefensiveKV and its extension, Layer-DefensiveKV,
which incorporates layer-wise budget allocation. Across seven task domains (18
datasets), our methods reduce generation quality loss by 2.3x and 4.3x
respectively, versus the strongest baseline under a 20% cache size. These
results set new performance benchmarks and pioneer a promising direction for
optimizing cache eviction against underlying fragility through worst-case risk
management. Our code is available at https://github.com/FFY0/DefensiveKV.

</details>


### [119] [Are Proverbs the New Pythian Oracles? Exploring Sentiment in Greek Sayings](https://arxiv.org/abs/2510.13341)
*Katerina Korre,John Pavlopoulos*

Main category: cs.CL

TL;DR: 本研究利用自然语言处理技术分析希腊谚语情感，扩展包含方言的数据，并提供情感分布图，发现希腊多数地区谚语情感偏负面。


<details>
  <summary>Details</summary>
Motivation: 鉴于谚语是一种跨越文化和语言界限的语言现象，该研究旨在探索全球谚语的情感分析，并利用自然语言处理技术扩展希腊谚语数据库，以包含本地方言，并进行情感映射。

Method: 通过利用大型语言模型（LLMs）执行谚语情感分类，扩展已注释的希腊谚语数据集以包括本地方言，并进行地理位置、方言和主题方面的组合分析。

Result: 研究利用大型语言模型（LLMs）成功进行谚语的情感分类，提供希腊情感分布概览，以及地理位置、方言和主题的组合分析，发现希腊大部分地区的谚语情感呈负面。

Conclusion: 大型语言模型能够准确分析希腊谚语的情感，尤其是在非传统情感极性任务中，发现希腊多数地区负面情感更为普遍。

Abstract: Proverbs are among the most fascinating linguistic phenomena that transcend
cultural and linguistic boundaries. Yet, much of the global landscape of
proverbs remains underexplored, as many cultures preserve their traditional
wisdom within their own communities due to the oral tradition of the
phenomenon. Taking advantage of the current advances in Natural Language
Processing (NLP), we focus on Greek proverbs, analyzing their sentiment.
Departing from an annotated dataset of Greek proverbs, we expand it to include
local dialects, effectively mapping the annotated sentiment. We present (1) a
way to exploit LLMs in order to perform sentiment classification of proverbs,
(2) a map of Greece that provides an overview of the distribution of sentiment,
(3) a combinatory analysis in terms of the geographic position, dialect, and
topic of proverbs. Our findings show that LLMs can provide us with an accurate
enough picture of the sentiment of proverbs, especially when approached as a
non-conventional sentiment polarity task. Moreover, in most areas of Greece
negative sentiment is more prevalent.

</details>


### [120] [Protect: Towards Robust Guardrailing Stack for Trustworthy Enterprise LLM Systems](https://arxiv.org/abs/2510.13351)
*Karthik Avinash,Nikhil Pareek,Rishav Hada*

Main category: cs.CL

TL;DR: 本文介绍了Protect，这是一种本地多模式的安全保护模型，专为企业级部署而设计，能够跨文本、图像和音频模式无缝运行，并在所有安全维度上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型安全保护系统在实时监督、多模式数据处理和可解释性方面存在困难，限制了它们在监管环境中的采用。大多数保护措施仅专注于文本，这使它们在多模式、生产规模的环境中不足。

Method: Protect集成了通过低秩适应(Low-Rank Adaptation, LoRA)在广泛的多模式数据集上训练的微调、类别特定的适配器。这些适配器覆盖了四个安全维度：毒性、性别歧视、数据隐私和提示注入。

Result: 实验结果表明，Protect在所有安全维度上均表现出色，超越了现有的开放和专有模型，如WildGuard、LlamaGuard-4和GPT-4.1。

Conclusion: Protect通过在所有安全维度上实现最先进的性能，奠定了可靠、可审计且适合生产的安全系统的基础，能够跨文本、图像和音频模式运行。

Abstract: The increasing deployment of Large Language Models (LLMs) across enterprise
and mission-critical domains has underscored the urgent need for robust
guardrailing systems that ensure safety, reliability, and compliance. Existing
solutions often struggle with real-time oversight, multi-modal data handling,
and explainability -- limitations that hinder their adoption in regulated
environments. Existing guardrails largely operate in isolation, focused on text
alone making them inadequate for multi-modal, production-scale environments. We
introduce Protect, natively multi-modal guardrailing model designed to operate
seamlessly across text, image, and audio inputs, designed for enterprise-grade
deployment. Protect integrates fine-tuned, category-specific adapters trained
via Low-Rank Adaptation (LoRA) on an extensive, multi-modal dataset covering
four safety dimensions: toxicity, sexism, data privacy, and prompt injection.
Our teacher-assisted annotation pipeline leverages reasoning and explanation
traces to generate high-fidelity, context-aware labels across modalities.
Experimental results demonstrate state-of-the-art performance across all safety
dimensions, surpassing existing open and proprietary models such as WildGuard,
LlamaGuard-4, and GPT-4.1. Protect establishes a strong foundation for
trustworthy, auditable, and production-ready safety systems capable of
operating across text, image, and audio modalities.

</details>


### [121] [Personal Attribute Leakage in Federated Speech Models](https://arxiv.org/abs/2510.13357)
*Hamdan Al-Ali,Ali Reza Ghavamipour,Tommaso Caselli,Fatih Turkmen,Zeerak Talat,Hanan Aldarmaki*

Main category: cs.CL

TL;DR: 研究分析了在联邦学习中ASR模型对属性推断攻击的脆弱性，展示了特定属性信息可以被可靠地推断，这暴露了ASR模型的安全隐患。


<details>
  <summary>Details</summary>
Motivation: 为了揭示联邦学习环境下ASR模型在属性推断攻击中的潜在脆弱性以及提升其安全性。

Method: 在被动威胁模型下，测试了一个非参数白盒攻击方法，分析ASR模型Weight不同ials。

Result: 在不同ASR模型中，特别是对于口音信息的推断攻击表现出很高的可靠性，特别是对于未在预训练数据中充分表示的属性，如口音，更易受到推断攻击。

Conclusion: 该研究揭示了联邦学习环境下ASR模型在属性推断攻击中的脆弱性，特别是对未在预训练数据中充分表示的属性更为敏感。

Abstract: Federated learning is a common method for privacy-preserving training of
machine learning models. In this paper, we analyze the vulnerability of ASR
models to attribute inference attacks in the federated setting. We test a
non-parametric white-box attack method under a passive threat model on three
ASR models: Wav2Vec2, HuBERT, and Whisper. The attack operates solely on weight
differentials without access to raw speech from target speakers. We demonstrate
attack feasibility on sensitive demographic and clinical attributes: gender,
age, accent, emotion, and dysarthria. Our findings indicate that attributes
that are underrepresented or absent in the pre-training data are more
vulnerable to such inference attacks. In particular, information about accents
can be reliably inferred from all models. Our findings expose previously
undocumented vulnerabilities in federated ASR models and offer insights towards
improved security.

</details>


### [122] [Make an Offer They Can't Refuse: Grounding Bayesian Persuasion in Real-World Dialogues without Pre-Commitment](https://arxiv.org/abs/2510.13387)
*Buwei He,Yang Liu,Zhaowei Zhang,Zixia Jia,Huijia Wu,Zhaofeng He,Zilong Zheng,Yipeng Kang*

Main category: cs.CL

TL;DR: 该研究应用贝叶斯劝说框架于自然语言对话中，提高大型语言模型在说服任务中的表现，实验显示其成功率优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前研究往往忽略了信息不对称战略性使用在消息设计中的作用，或过分依赖于承诺方面的强假设。因此，我们探讨贝叶斯劝说在自然语言中的应用，以增强LLMs的战略说服能力。

Method: 提出了一种新的框架，将贝叶斯劝说（BP）应用于自然语言，在单轮对话中提高大型语言模型（LLMs）的战略劝说能力。该框架纳入了承诺-沟通机制，明确说明信息结构通过叙述潜在类型（如诚实或不诚实）的方式引导说服对象进行贝叶斯信念更新。

Result: 实验结果显示：（1）采用BP策略指导的LLMs在说服成功率上稳定超越非BP基线；（2）半正式自然语言（SFNL）在可信度和逻辑一致性上表现更优，而纯自然语言（FNL）在情感共鸣和自然对话中表现更强；（3）通过监督微调，小型模型可达到与大型模型相媲美的BP表现。

Conclusion: 研究证明，通过贝叶斯劝说框架增强战略性说服，语言模型在各种说服任务中表现出色，并提供了在自然语言中的不同执行策略（SFNL与FNL），同时指出可通过微调提升小模型的性能。

Abstract: Persuasion, a fundamental social capability for humans, remains a challenge
for AI systems such as large language models (LLMs). Current studies often
overlook the strategic use of information asymmetry in message design or rely
on strong assumptions regarding pre-commitment. In this work, we explore the
application of Bayesian Persuasion (BP) in natural language within single-turn
dialogue settings, to enhance the strategic persuasion capabilities of LLMs.
Our framework incorporates a commitment-communication mechanism, where the
persuader explicitly outlines an information schema by narrating their
potential types (e.g., honest or dishonest), thereby guiding the persuadee in
performing the intended Bayesian belief update. We evaluate two variants of our
approach: Semi-Formal-Natural-Language (SFNL) BP and Fully-Natural-Language
(FNL) BP, benchmarking them against both naive and strong non-BP (NBP)
baselines within a comprehensive evaluation framework. This framework covers a
diverse set of persuadees -- including LLM instances with varying prompts and
fine-tuning and human participants -- across tasks ranging from specially
designed persuasion scenarios to general everyday situations. Experimental
results on LLM-based agents reveal three main findings: (1) LLMs guided by BP
strategies consistently achieve higher persuasion success rates than NBP
baselines; (2) SFNL exhibits greater credibility and logical coherence, while
FNL shows stronger emotional resonance and robustness in naturalistic
conversations; (3) with supervised fine-tuning, smaller models can attain BP
performance comparable to that of larger models.

</details>


### [123] [Investigating Lexical Change through Cross-Linguistic Colexification Patterns](https://arxiv.org/abs/2510.13407)
*Kim Gfeller,Sabine Stoll,Chundra Cathcart,Paul Widmer*

Main category: cs.CL

TL;DR: 该研究通过对三种语言家族的比较分析研究了不同概念共用词形的现象及其演化动力学，发现频繁和易借用的概念对变化更快且不常共同词汇化，而更紧密相关的概念对变化较慢且更常共同词汇化，地域和文化因素可能也是影响因素。


<details>
  <summary>Details</summary>
Motivation: 探讨语言意义变化的动因，重点研究不同概念共用同一个词形现象（共同词汇化）的动态。

Method: 研究应用系统发生比较模型分析了来自南岛语系、印欧语系和乌拉尔语系的字典数据，以揭示概念对的共同词汇化的进化动力学。评估了三个预测因素的影响：关联性、借用性和使用频率。

Result: 更紧密相关的概念对跨越更大范围的家族树表现出共同词汇化并变化较慢，而更频繁和易借用的概念对变化更快且共同词汇化较少。不同语言家族之间存在显著差异，表明地域和文化因素可能作用于此。

Conclusion: 与更紧密相关的概念对在更大范围的家族树中具有共同的词汇化，并表现出较慢的变化速度，而更频繁和易借用的概念对则更容易快速变化，并且不常共同词汇化。语言演化可能与地域和文化因素相关。

Abstract: One of the most intriguing features of language is its constant change, with
ongoing shifts in how meaning is expressed. Despite decades of research, the
factors that determine how and why meanings evolve remain only partly
understood. Colexification -- the phenomenon of expressing multiple distinct
concepts using the same word form -- serves as a valuable window onto the
dynamics of meaning change across languages. Here, we apply phylogenetic
comparative models to dictionary data from three language families,
Austronesian, Indo-European, and Uralic, in order to shed light on the
evolutionary dynamics underlying the colexification of concept pairs. We assess
the effects of three predictors: associativity, borrowability, and usage
frequency. Our results show that more closely related concept pairs are
colexified across a larger portion of the family tree and exhibit slower rates
of change. In contrast, concept pairs that are more frequent and more prone to
borrowing tend to change more rapidly and are less often colexified. We also
find considerable differences between the language families under study,
suggesting that areal and cultural factors may play a role.

</details>


### [124] [Evaluating Arabic Large Language Models: A Survey of Benchmarks, Methods, and Gaps](https://arxiv.org/abs/2510.13430)
*Ahmed Alzubaidi,Shaikha Alsuwaidi,Basma El Amel Boussaha,Leen AlQadi,Omar Alkaabi,Mohammed Alyafeai,Hamza Alobeidli,Hakim Hacid*

Main category: cs.CL

TL;DR: 综述了阿拉伯LLM基准测试的现状，提出分类系统并分析基准多样性进展及存在的关键问题。


<details>
  <summary>Details</summary>
Motivation: 提供阿拉伯语言模型基准测试的系统综述，以帮助研究者了解基准方法、再现性标准和评估指标，并为将来的发展提供建议。

Method: 对40多个评估基准进行了分析，并将这些基准分类为知识、自然语言处理任务、文化和方言及目标特定评估四类。同时研究了本土收集、翻译和合成生成三种主要方法及其在真实性、规模和成本方面的权衡。

Result: 分析表明，虽然在基准多样性上取得了显著进展，但在时间性评估、多回合对话评估及翻译数据集的文化不一致性等方面仍存在重要差距。

Conclusion: 本文为阿拉伯语言模型（LLM）基准测试提供了一个系统的综述，揭示了基准多样性方面的显著进展，同时指出了时间性评估、对话评估的不足以及翻译数据集中存在的文化不一致等关键问题。

Abstract: This survey provides the first systematic review of Arabic LLM benchmarks,
analyzing 40+ evaluation benchmarks across NLP tasks, knowledge domains,
cultural understanding, and specialized capabilities. We propose a taxonomy
organizing benchmarks into four categories: Knowledge, NLP Tasks, Culture and
Dialects, and Target-Specific evaluations. Our analysis reveals significant
progress in benchmark diversity while identifying critical gaps: limited
temporal evaluation, insufficient multi-turn dialogue assessment, and cultural
misalignment in translated datasets. We examine three primary approaches:
native collection, translation, and synthetic generation discussing their
trade-offs regarding authenticity, scale, and cost. This work serves as a
comprehensive reference for Arabic NLP researchers, providing insights into
benchmark methodologies, reproducibility standards, and evaluation metrics
while offering recommendations for future development.

</details>


### [125] [Beyond Single-Reward: Multi-Pair, Multi-Perspective Preference Optimization for Machine Translation](https://arxiv.org/abs/2510.13434)
*Hao Wang,Linlong Xu,Heng Liu,Yangyang Liu,Xiaohu Zhao,Bo Zeng,Liangying Shao,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.CL

TL;DR: M^2PO通过多视角奖励引擎和多对构建策略优化大型语言模型的翻译质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法因质量评估模型提供的奖励信号不完善和低效的数据利用而受到限制。本研究旨在通过改进奖励信号和数据利用方式提升翻译质量。

Method: 引入多视角奖励引擎，包括一种新的幻觉惩罚和创新的动态质量评分，并采用多对构建策略，从翻译候选集中系统性创建完整的偏好对集合。

Result: 本文提出了M^2PO框架，旨在解决现有大型语言模型在机器翻译中的两个问题：1) 质量评估模型提供的奖励信号不完善，未能识别关键错误如翻译幻觉；2) 数据利用效率低，仅选择单一胜负对导致有价值的学习信号被丢弃。

Conclusion: 在WMT21-22基准测试中，M^2PO显著优于现有方法，并与领先的专有大型语言模型表现相当。

Abstract: Direct Preference Optimization (DPO) is a powerful paradigm for aligning
Large Language Models (LLMs) to human preferences in Machine Translation (MT),
but current methods are hindered by two fundamental challenges: (1) flawed
reward signals from Quality Estimation (QE) models that overlook critical
errors like translation hallucination, and (2) inefficient data utilization
that discards valuable learning signals by selecting only a single win-loss
pair. To address these limitations, we introduce M^2PO: Multi-Pair,
Multi-Perspective Preference Optimization. Our framework integrates a
multi-perspective reward engine that creates a more robust signal by combining
two key viewpoints: a new hallucination penalty for factuality, and an
innovative dynamic quality score that adaptively fuses external evaluations
with the model's own evolving judgment. This is synergistically paired with a
multi-pair construction strategy that systematically creates a comprehensive
set of preference pairs from the entire pool of translation candidates. This
synergistic approach ensures the model learns from a richer spectrum of quality
trade-offs, leading to more robust and faithful translations. On challenging
WMT21-22 benchmarks, M^2PO substantially outperforms existing preference
optimization methods and demonstrates highly competitive performance against
leading proprietary LLMs.

</details>


### [126] [LiteraryQA: Towards Effective Evaluation of Long-document Narrative QA](https://arxiv.org/abs/2510.13494)
*Tommaso Bonomo,Luca Gioffré,Roberto Navigli*

Main category: cs.CL

TL;DR: 推出了针对文学作品的高质量QA数据集LiteraryQA，通过验证和优化提高了QA评估的准确性，并在该数据集上对长上下文LLM进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: NarrativeQA作为该领域最常用的基准面临文档噪音和QA对不完善的问题。针对这一问题，引入一个更高质量的子集以提升系统评估的准确性和可靠性。

Method: 引入了LiteraryQA数据集，使用人工和大型语言模型验证的方法来识别和纠正低质量的QA样本，并通过去除不必要文本来提高源文件的质量。

Result: LLM-as-a-Judge评估法与人类判断的排名高度一致，而传统的n-gram评价指标在人类判断方面的系统级相关性较低。

Conclusion: 旨在改进QA系统在文学作品上的性能，并提供了一个改进后的高质量数据集。

Abstract: Question Answering (QA) on narrative text poses a unique challenge to current
systems, requiring a deep understanding of long, complex documents. However,
the reliability of NarrativeQA, the most widely used benchmark in this domain,
is hindered by noisy documents and flawed QA pairs. In this work, we introduce
LiteraryQA, a high-quality subset of NarrativeQA focused on literary works.
Using a human- and LLM-validated pipeline, we identify and correct low-quality
QA samples while removing extraneous text from source documents. We then carry
out a meta-evaluation of automatic metrics to clarify how systems should be
evaluated on LiteraryQA. This analysis reveals that all n-gram-based metrics
have a low system-level correlation to human judgment, while LLM-as-a-Judge
evaluations, even with small open-weight models, can strongly agree with the
ranking identified by humans. Finally, we benchmark a set of long-context LLMs
on LiteraryQA. We release our code and data at
https://github.com/SapienzaNLP/LiteraryQA.

</details>


### [127] [ConsintBench: Evaluating Language Models on Real-World Consumer Intent Understanding](https://arxiv.org/abs/2510.13499)
*Xiaozhe Li,TianYi Lyu,Siyi Yang,Yuxi Gong,Yizhao Yang,Jinxuan Huang,Ligao Zhang,Zhuoyi Huang,Qingwen Liu*

Main category: cs.CL

TL;DR: 引入了ench基准来评估大型语言模型对复杂公共意图的理解。


<details>
  <summary>Details</summary>
Motivation: 为了填补当前缺乏评估LLMs对现实世界人类意图理解的基准这个空白。

Method: 引入了一个动态实时评估基准ench，专门用于意图理解，特别是在消费者领域。

Result: 开发了一个名为ench的新基准，其特点是支持实时更新，并通过自动策展管道防止数据污染。

Conclusion: ench是首个设计用于意图理解的动态实时评估基准，具有大规模和多样性的特点，解决了现有数据收集和评估困难的问题。

Abstract: Understanding human intent is a complex, high-level task for large language
models (LLMs), requiring analytical reasoning, contextual interpretation,
dynamic information aggregation, and decision-making under uncertainty.
Real-world public discussions, such as consumer product discussions, are rarely
linear or involve a single user. Instead, they are characterized by interwoven
and often conflicting perspectives, divergent concerns, goals, emotional
tendencies, as well as implicit assumptions and background knowledge about
usage scenarios. To accurately understand such explicit public intent, an LLM
must go beyond parsing individual sentences; it must integrate multi-source
signals, reason over inconsistencies, and adapt to evolving discourse, similar
to how experts in fields like politics, economics, or finance approach complex,
uncertain environments. Despite the importance of this capability, no
large-scale benchmark currently exists for evaluating LLMs on real-world human
intent understanding, primarily due to the challenges of collecting real-world
public discussion data and constructing a robust evaluation pipeline. To bridge
this gap, we introduce \bench, the first dynamic, live evaluation benchmark
specifically designed for intent understanding, particularly in the consumer
domain. \bench is the largest and most diverse benchmark of its kind,
supporting real-time updates while preventing data contamination through an
automated curation pipeline.

</details>


### [128] [MedREK: Retrieval-Based Editing for Medical LLMs with Key-Aware Prompts](https://arxiv.org/abs/2510.13500)
*Shujun Xia,Haokun Lin,Yichen Wu,Yinan Zhou,Zixuan Li,Zhongwei Wan,Xingrun Xing,Yefeng Zheng,Xiang Li,Caifeng Shan,Zhenan Sun,Quanzheng Li*

Main category: cs.CL

TL;DR: 该研究开发了MedREK检索编辑框架，通过解决检索重叠和批量编辑问题，改善了医疗领域LLMs的准确性和实用性。


<details>
  <summary>Details</summary>
Motivation: 由于医疗知识的快速发展和训练数据中存在错误，大型语言模型（LLMs）在临床实践中可能生成过时或不准确的信息，因此需要一种无需完全重新训练的模型编辑解决方案。

Method: 研究采用了检索编辑的方法，其中包括一个共享查询密钥模块和注意力提示编码器，以提高匹配精度和提供信息指导。

Result: 在多个医疗基准上进行实验后，MedREK表现出优良的性能，尤其是在批量编辑方面取得了突破性进展。

Conclusion: 该研究提出了一种名为MedREK的检索编辑框架，并在新的MedVersa基准上进行了验证，以解决医疗领域的检索编辑挑战。实验表明，MedREK在不同核心指标上表现优异，是医疗LLMs领域首个经过验证的批量编辑解决方案。

Abstract: LLMs hold great promise for healthcare applications, but the rapid evolution
of medical knowledge and errors in training data often cause them to generate
outdated or inaccurate information, limiting their applicability in high-stakes
clinical practice. Model editing has emerged as a potential remedy without full
retraining. While parameter-based editing often compromises locality and is
thus ill-suited for the medical domain, retrieval-based editing offers a more
viable alternative. However, it still faces two critical challenges: (1)
representation overlap within the medical knowledge space often causes
inaccurate retrieval and reduces editing accuracy; (2) existing methods are
restricted to single-sample edits, while batch-editing remains largely
unexplored despite its importance for real-world medical applications. To
address these challenges, we first construct MedVersa, \hk{an enhanced
benchmark with broader coverage of medical subjects, designed to evaluate both
single and batch edits under strict locality constraints}. We then propose
MedREK, a retrieval-based editing framework that integrates a shared query-key
module for precise matching with an attention-based prompt encoder for
informative guidance. Experimental results on various medical benchmarks
demonstrate that our MedREK achieves superior performance across different core
metrics and provides the first validated solution for batch-editing in medical
LLMs. Our code and dataset are available at
https://github.com/mylittleriver/MedREK.

</details>


### [129] [Attention Illuminates LLM Reasoning: The Preplan-and-Anchor Rhythm Enables Fine-Grained Policy Optimization](https://arxiv.org/abs/2510.13554)
*Yang Li,Zhichen Dong,Yuhan Sun,Weixun Wang,Shaopan Xiong,Yijia Luo,Jiashun Liu,Han Lu,Jiamang Wang,Wenbo Su,Bo Zheng,Junchi Yan*

Main category: cs.CL

TL;DR: 通过分析LLM中的注意力机制，提出了新的强化学习策略，从而在推理任务中获得性能提升。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型（LLM）的推理模式并改善强化学习（RL）的信用分配。

Method: 将注意力视为一种特权子状态，揭示LLM的内部逻辑。

Result: 引入三种新的强化学习策略，针对关键节点进行动态目标分配，在多个推理任务中表现出一致的性能提升。

Conclusion: 通过对注意力机制的分析，我们旨在将不透明的优化过程转变为可操作的结构感知过程，以实现更透明和有效的LLM推理优化。

Abstract: The reasoning pattern of Large language models (LLMs) remains opaque, and
Reinforcement learning (RL) typically applies uniform credit across an entire
generation, blurring the distinction between pivotal and routine steps. This
work positions attention as a privileged substrate that renders the internal
logic of LLMs legible, not merely as a byproduct of computation, but as a
mechanistic blueprint of reasoning itself. We first distinguish attention heads
between locally and globally focused information processing and reveal that
locally focused heads produce a sawtooth pattern near the diagonal indicating
phrasal chunks, while globally focused heads expose tokens that exert broad
downstream influence over future tokens. We formalize these with two metrics:
1) Windowed Average Attention Distance, which measures the extent of backward
attention within a clipped window; 2) Future Attention Influence, which
quantifies a token's global importance as the average attention it receives
from subsequent tokens. Taken together, these signals reveal a recurring
preplan-and-anchor mechanism, where the model first performs a long-range
contextual reference to generate an introductory token, which is immediately
followed by or coincides with a semantic anchor token that organizes subsequent
reasoning. Leveraging these insights, we introduce three novel RL strategies
that dynamically perform targeted credit assignment to critical nodes (preplan
tokens, anchor tokens, and their temporal coupling) and show consistent
performance gains across various reasoning tasks. By aligning optimization with
the model's intrinsic reasoning rhythm, we aim to transform opaque optimization
into an actionable structure-aware process, hoping to offer a potential step
toward more transparent and effective optimization of LLM reasoning.

</details>


### [130] [FreshTab: Sourcing Fresh Data for Table-to-Text Generation Evaluation](https://arxiv.org/abs/2510.13598)
*Kristýna Onderková,Ondřej Plátek,Zdeněk Kasner,Ondřej Dušek*

Main category: cs.CL

TL;DR: 提出了FreshTab基准以改善表到文本任务的自动评估，解决领域不平衡问题，尽管自动指标评分低，但实际评估效果并未受损。


<details>
  <summary>Details</summary>
Motivation: 现有的表到文本生成任务面临大语言模型训练数据污染和领域不平衡的影响。为了克服这些挑战，本文提出FreshTab基准以实现更精准的评估。

Method: 本文通过从维基百科中动态生成表文本基准的方式，来应对大语言模型的数据污染问题，并实现领域敏感的评估。FreshTab可以根据需要收集不同语言（包括德语、俄语、法语和英语）的数据集。

Result: 研究表明，虽然通过FreshTab方法收集的最新表格生成的洞察在自动评估中表现较差，但大语言模型和人工评估没有显示明显劣势。同时，领域平衡的基准评估更具挑战性。

Conclusion: 本文提出了一个名为FreshTab的新型动态表文本生成基准，以应对大语言模型训练数据污染及领域不平衡问题。研究发现，虽然自动评估指标显示最新表格生成的洞察质量较差，但这种差异在大语言模型和人工评估中并未明显表现出来。同时，所有评估中都能看到领域效应，说明领域平衡的基准更具挑战性。

Abstract: Table-to-text generation (insight generation from tables) is a challenging
task that requires precision in analyzing the data. In addition, the evaluation
of existing benchmarks is affected by contamination of Large Language Model
(LLM) training data as well as domain imbalance. We introduce FreshTab, an
on-the-fly table-to-text benchmark generation from Wikipedia, to combat the LLM
data contamination problem and enable domain-sensitive evaluation. While
non-English table-to-text datasets are limited, FreshTab collects datasets in
different languages on demand (we experiment with German, Russian and French in
addition to English). We find that insights generated by LLMs from recent
tables collected by our method appear clearly worse by automatic metrics, but
this does not translate into LLM and human evaluations. Domain effects are
visible in all evaluations, showing that a~domain-balanced benchmark is more
challenging.

</details>


### [131] [NOSA: Native and Offloadable Sparse Attention](https://arxiv.org/abs/2510.13602)
*Yuxiang Huang,Chaojun Xiao,Xu Han,Zhiyuan Liu*

Main category: cs.CL

TL;DR: 提出NOSA框架，通过KV缓存卸载实现2.3倍解码吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意方法在长上下文处理过程中无法减少KV缓存大小，影响解码吞吐量。为了解决这个问题，提出了NOSA框架。

Method: NOSA通过将标记选择分解为查询感知和查询无关组件，引入显式局部性约束，减少KV传输的同时保持训练时注意力计算不变。

Result: 该论文提出了NOSA，这是一种可训练的稀疏注意机制框架，旨在支持KV缓存卸载，用于提高长上下文处理中的解码效率。通过引入显式局部性约束，NOSA在不改变训练时使用的注意力计算的情况下减少了KV传输，从而在批量推理过程中提高解码吞吐量。

Conclusion: NOSA在长上下文处理的稀疏注意机制中提高了解码效率，实现了KV缓存卸载，并在保持性能损失最小化的情况下提升了解码吞吐量。

Abstract: Trainable sparse attention has emerged as a promising solution to address the
decoding efficiency bottleneck of LLMs in long-context processing,
significantly saving memory accesses while minimally impacting task
performance. However, existing sparse attention methods leave a crucial
limitation unresolved: the size of the key-value (KV) cache remains unreduced,
which constrains on-GPU batch sizes and throttles decoding throughput,
especially in large-scale batched inference. In this paper, we show that
trainable sparse attention naturally exhibits strong locality in token
selection across adjacent decoding steps, thereby enabling KV cache offloading
without altering the underlying attention computation. However, the inherent
locality remains insufficient to achieve efficient offloading, as the transfer
of selected KV pairs between the CPU and GPU continues to dominate the overall
decoding cost. Building on this insight, we present NOSA, a trainable sparse
attention framework designed to natively support KV cache offloading. NOSA
introduces explicit locality constraints by decomposing token selection into
query-aware and query-agnostic components, thereby reducing KV transfers while
preserving the same attention computation as used during training. We pretrain
a 1B-parameter model with NOSA and conduct extensive benchmarks, showing that
it preserves near-lossless performance while achieving up to a 2.3x improvement
in decoding throughput compared with the vanilla trainable sparse attention
baseline (InfLLM-V2).

</details>


### [132] [MemoTime: Memory-Augmented Temporal Knowledge Graph Enhanced Large Language Model Reasoning](https://arxiv.org/abs/2510.13614)
*Xingyu Tan,Xiaoyang Wang,Xiwei Xu,Xin Yuan,Liming Zhu,Wenjie Zhang*

Main category: cs.CL

TL;DR: MemoTime框架通过结构化支撑、递归推理和经验学习，显著提升了大语言模型在时间性推理上的表现，并在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了应对现有时间性知识图谱推理方法在时间忠实性、多实体时间同步性、检索适应性及推理经验复用方面的挑战，提出MemoTime来提高大型语言模型的时间理解能力。

Method: 提出了MemoTime，一个记忆增强的时间性知识图谱框架。MemoTime将复杂的时间问题分解为时间树，通过递归推理和连续经验学习，形成结构化支持。同时，动态证据检索层适应性地选择操作符特定的检索策略，自我进化的经验记忆存储已验证的推理轨迹、工具选择和子问题嵌入，以供跨类型重用。

Result: MemoTime在多个时间性问答基准上实现了最高的结果，相比强基线提高了24.0%。此外，它还使得某些较小的模型（如Qwen3-4B）在推理性能上接近于GPT-4-Turbo。

Conclusion: 通过引入MemoTime框架，增强了大型语言模型在处理复杂时间问题时的推理能力。在多个时间性问答基准上的实验表明，该方法实现了整体上最先进的结果，显著优于基线。此外，该框架使得较小模型的推理表现达到与更大模型（如GPT-4-Turbo）相当的水平。

Abstract: Large Language Models (LLMs) have achieved impressive reasoning abilities,
but struggle with temporal understanding, especially when questions involve
multiple entities, compound operators, and evolving event sequences. Temporal
Knowledge Graphs (TKGs), which capture vast amounts of temporal facts in a
structured format, offer a reliable source for temporal reasoning. However,
existing TKG-based LLM reasoning methods still struggle with four major
challenges: maintaining temporal faithfulness in multi-hop reasoning, achieving
multi-entity temporal synchronization, adapting retrieval to diverse temporal
operators, and reusing prior reasoning experience for stability and efficiency.
To address these issues, we propose MemoTime, a memory-augmented temporal
knowledge graph framework that enhances LLM reasoning through structured
grounding, recursive reasoning, and continual experience learning. MemoTime
decomposes complex temporal questions into a hierarchical Tree of Time,
enabling operator-aware reasoning that enforces monotonic timestamps and
co-constrains multiple entities under unified temporal bounds. A dynamic
evidence retrieval layer adaptively selects operator-specific retrieval
strategies, while a self-evolving experience memory stores verified reasoning
traces, toolkit decisions, and sub-question embeddings for cross-type reuse.
Comprehensive experiments on multiple temporal QA benchmarks show that MemoTime
achieves overall state-of-the-art results, outperforming the strong baseline by
up to 24.0%. Furthermore, MemoTime enables smaller models (e.g., Qwen3-4B) to
achieve reasoning performance comparable to that of GPT-4-Turbo.

</details>


### [133] [Unlocking Public Catalogues: Instruction-Tuning LLMs for ICD Coding of German Tumor Diagnoses](https://arxiv.org/abs/2510.13624)
*Stefan Lenz,Lakisha Ortiz Rosario,Georg Vollmar,Arsenij Ustjanzew,Fatma Alickovic,Thomas Kindler,Torsten Panholzer*

Main category: cs.CL

TL;DR: 研究通过指令型微调，提高了开源大模型在德语肿瘤诊断编码中的准确性，尤其在ICD-10-GM的编码表现显著提升。


<details>
  <summary>Details</summary>
Motivation: 小型开源大模型具有隐私保护自动化的潜力，但在德语环境下的编码准确性往往较低。该研究旨在通过指令型微调提高其在德语肿瘤诊断文本编码中的表现。

Method: 利用基于ICD-10-GM、ICD-O-3和OPS目录创建的超过50万个问答对作为训练数据，对八个来自Qwen、Llama和Mistral系列的开源大模型（7-70 B参数）进行微调。

Result: ICD-10-GM的准确性从1.4-24%提高到41-58%，部分准确性从31-74%提高到73-83%。ICD-O-3的地形编码准确性也有所提高，但起始和最终准确性较低，精确度达到22-40%，部分准确性达到56-67%。所有模型的代码错误输出降至0%。肿瘤诊断识别率达到了99%。

Conclusion: 本研究表明，通过利用公共数据集进行指令型微调可以提高开源大模型在德语肿瘤诊断文本编码中的准确性。

Abstract: Accurate coding of tumor diagnoses with ICD-10-GM and ICD-O-3 is essential
for structured cancer documentation in Germany. Smaller open-weight LLMs are
appealing for privacy-preserving automation but often struggle with coding
accuracy in German-language contexts. This study investigates whether
instruction-based fine-tuning on public datasets improves the coding accuracy
of open-weight LLMs for German tumor diagnosis texts. The evaluation uses coded
diagnoses from the local tumor documentation system as test data. In a
systematic data quality assessment, the upper limit for ICD-10 coding
performance was estimated at 60-79% for exact and 81-94% for partial
(three-character codes only) derivation. As training data, over 500,000
question-answer pairs were created based on the ICD-10-GM, ICD-O-3, and OPS
catalogues. Eight open-weight models from the Qwen, Llama, and Mistral families
(7-70 B parameters) were fine-tuned. ICD-10-GM accuracy rose from 1.4-24% to
41-58%, and partial accuracy from 31-74% to 73-83%. The accuracy of ICD-O-3
topography coding also improved but started and remained considerably lower
with an exact accuracy of 22-40% and a partial accuracy of 56-67% after
fine-tuning. Malformed code outputs dropped to 0% for all models.
Tumor-diagnosis recognition reached 99%. Accuracy correlated positively with
model size, but gaps between small and large models narrowed after fine-tuning.
The reasoning mode in Qwen3 generally yielded a lower performance than
fine-tuning and was over 100 times slower. Our findings highlight the potential
of leveraging public catalogues to build instruction datasets that improve LLMs
in medical documentation tasks. The complete training dataset and the
best-performing checkpoints of the fine-tuned models are available from
https://huggingface.co/datasets/stefan-m-lenz/ICDOPS-QA-2024.

</details>


### [134] [Closing the Gap Between Text and Speech Understanding in LLMs](https://arxiv.org/abs/2510.13632)
*Santiago Cuervo,Skyler Seto,Maureen de Seyssel,Richard He Bai,Zijin Gu,Tatiana Likhomanenko,Navdeep Jaitly,Zakaria Aldeneh*

Main category: cs.CL

TL;DR: 提出SALAD方法，通过结合跨模态蒸馏和有针对性的合成数据来改善文本和语音间的对齐，同时减少对文本能力的遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于大量的语音合成或私有的数据集，因此需要更为数据高效的解决方案来缩小文本-语音理解差距。

Method: 引入SALAD（通过主动选择学习和跨模态蒸馏进行样本高效对齐）方法，该方法结合了跨模态蒸馏与针对性合成数据，旨在改善跨模态对齐并减少文本能力的遗忘。

Result: 本文研究了将大语言模型（LLMs）从文本输入扩展到语音输入时所出现的性能下降问题，即文本-语音理解差距。导致这一现象的原因主要有两个：(i) 在适应过程中对文本能力的遗忘，(ii) 语音和文本之间的跨模态错位。为了解决这一问题，本文提出了一种名为SALAD的方法。

Conclusion: SALAD方法在知识、语言理解及推理的广域基准上对3B和7B语言模型取得了竞争性表现，同时仅使用了比公共语料库少一数量级的语音数据进行训练。

Abstract: Large Language Models (LLMs) can be adapted to extend their text capabilities
to speech inputs. However, these speech-adapted LLMs consistently underperform
their text-based counterparts--and even cascaded pipelines--on language
understanding tasks. We term this shortfall the text-speech understanding gap:
the performance drop observed when a speech-adapted LLM processes spoken inputs
relative to when the original text-based LLM processes the equivalent text.
Recent approaches to narrowing this gap either rely on large-scale speech
synthesis of text corpora, which is costly and heavily dependent on synthetic
data, or on large-scale proprietary speech datasets, which are not
reproducible. As a result, there remains a need for more data-efficient
alternatives for closing the text-speech understanding gap. In this work, we
analyze the gap as driven by two factors: (i) forgetting of text capabilities
during adaptation, and (ii) cross-modal misalignment between speech and text.
Based on this analysis, we introduce SALAD--Sample-efficient Alignment with
Learning through Active selection and cross-modal Distillation--which combines
cross-modal distillation with targeted synthetic data to improve alignment
while mitigating forgetting. Applied to 3B and 7B LLMs, SALAD achieves
competitive performance with a strong open-weight model across broad-domain
benchmarks in knowledge, language understanding, and reasoning, while training
on over an order of magnitude less speech data from public corpora.

</details>


### [135] [How Sampling Affects the Detectability of Machine-written texts: A Comprehensive Study](https://arxiv.org/abs/2510.13681)
*Matthieu Dubois,François Yvon,Pablo Piantanida*

Main category: cs.CL

TL;DR: 解码参数的微小调整会对检测器准确性产生重大影响，从而暴露了当前检测方法的重要盲点。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）生成的文本越来越普遍，并且通常与人类书写的内容难以区分，自动文本检测的研究引起了越来越多的关注。

Method: 系统性地检查采样解码如何影响可检测性，特别是模型的（子）词级分布的细微变化如何影响检测性能。

Result: 研究表明，即便是对解码参数进行细微调整，如温度、top-p或者nucleus采样，都会严重影响检测器的准确性，AUROC可能从接近完美的水平下降到1%。

Conclusion: 当前检测方法中存在重要盲点，需要更全面的评估协议。为促进未来研究，发布了包括37种解码配置的大规模数据集及相关代码和评估框架。

Abstract: As texts generated by Large Language Models (LLMs) are ever more common and
often indistinguishable from human-written content, research on automatic text
detection has attracted growing attention. Many recent detectors report
near-perfect accuracy, often boasting AUROC scores above 99\%. However, these
claims typically assume fixed generation settings, leaving open the question of
how robust such systems are to changes in decoding strategies. In this work, we
systematically examine how sampling-based decoding impacts detectability, with
a focus on how subtle variations in a model's (sub)word-level distribution
affect detection performance. We find that even minor adjustments to decoding
parameters - such as temperature, top-p, or nucleus sampling - can severely
impair detector accuracy, with AUROC dropping from near-perfect levels to 1\%
in some settings. Our findings expose critical blind spots in current detection
methods and emphasize the need for more comprehensive evaluation protocols. To
facilitate future research, we release a large-scale dataset encompassing 37
decoding configurations, along with our code and evaluation framework
https://github.com/BaggerOfWords/Sampling-and-Detection

</details>


### [136] [Assessing Web Search Credibility and Response Groundedness in Chat Assistants](https://arxiv.org/abs/2510.13749)
*Ivan Vykopal,Matúš Pikuliak,Simon Ostermann,Marián Šimko*

Main category: cs.CL

TL;DR: 文章比较了几种常用聊天助手的事实核查行为，发现Perplexity在信息源可信度方面具有优势。


<details>
  <summary>Details</summary>
Motivation: 随着聊天助手整合网页搜索功能以支持外部来源的检索和引用，虽然有望提供更可靠的答案，但也可能增加引用低可信度来源而扩大错误信息的风险。

Method: 本文介绍了一种新颖的方法，用于评估聊天助手的网页搜索行为，特别关注信息源的可信度以及回复与引用来源的依据性。通过对五个易受误导主题的100个声明进行评估，比较了GPT-4o、GPT-5、Perplexity和Qwen Chat。

Result: Perplexity在信息源可信度方面表现最好，而GPT-4o在敏感话题上引用不可信来源较多，表现较差。

Conclusion: 该研究首次系统地比较了常用聊天助手的事实核查行为，为评估高风险信息环境中的AI系统提供了基础。

Abstract: Chat assistants increasingly integrate web search functionality, enabling
them to retrieve and cite external sources. While this promises more reliable
answers, it also raises the risk of amplifying misinformation from
low-credibility sources. In this paper, we introduce a novel methodology for
evaluating assistants' web search behavior, focusing on source credibility and
the groundedness of responses with respect to cited sources. Using 100 claims
across five misinformation-prone topics, we assess GPT-4o, GPT-5, Perplexity,
and Qwen Chat. Our findings reveal differences between the assistants, with
Perplexity achieving the highest source credibility, whereas GPT-4o exhibits
elevated citation of non-credibility sources on sensitive topics. This work
provides the first systematic comparison of commonly used chat assistants for
fact-checking behavior, offering a foundation for evaluating AI systems in
high-stakes information environments.

</details>


### [137] [The Mechanistic Emergence of Symbol Grounding in Language Models](https://arxiv.org/abs/2510.13796)
*Shuyu Wu,Ziqiao Ma,Xiaoxi Luo,Yidong Huang,Josue Torres-Fonseca,Freda Shi,Joyce Chai*

Main category: cs.CL

TL;DR: 该研究发现符号奠基在中层计算中通过注意力机制实现，并在多模态对话中验证，但不适用于单向LSTM。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究显示在规模化训练的（视觉）语言模型中符号奠基可能自发出现，但其具体形成位置和驱动机制仍未被深入探索。为解决此问题，该研究设计了系统的方法来揭示这种现象的细节。

Method: 引入了一个受控评估框架，通过机制和因果分析系统地追踪符号奠基在内部计算中如何发生。

Result: 该论文研究符号在语言模型中的奠基过程，尤其是在中层计算中通过注意力头的聚合机制实现的现象。这种现象在多模态对话和不同架构（如Transformer和状态空间模型）中都得到了验证，但在单向LSTM中没有出现。研究结果提供了符号奠基在语言模型中出现的行为和机理证据。

Conclusion: 该研究提供了符号奠基在语言模型中出现的行为和机理证据，这对预测和控制生成的可靠性有实际影响。

Abstract: Symbol grounding (Harnad, 1990) describes how symbols such as words acquire
their meanings by connecting to real-world sensorimotor experiences. Recent
work has shown preliminary evidence that grounding may emerge in
(vision-)language models trained at scale without using explicit grounding
objectives. Yet, the specific loci of this emergence and the mechanisms that
drive it remain largely unexplored. To address this problem, we introduce a
controlled evaluation framework that systematically traces how symbol grounding
arises within the internal computations through mechanistic and causal
analysis. Our findings show that grounding concentrates in middle-layer
computations and is implemented through the aggregate mechanism, where
attention heads aggregate the environmental ground to support the prediction of
linguistic forms. This phenomenon replicates in multimodal dialogue and across
architectures (Transformers and state-space models), but not in unidirectional
LSTMs. Our results provide behavioral and mechanistic evidence that symbol
grounding can emerge in language models, with practical implications for
predicting and potentially controlling the reliability of generation.

</details>


### [138] [Breadcrumbs Reasoning: Memory-Efficient Reasoning with Compression Beacons](https://arxiv.org/abs/2510.13797)
*Giovanni Monea,Yair Feldman,Shankar Padmanabhan,Kianté Brantley,Yoav Artzi*

Main category: cs.CL

TL;DR: 研究提出了一种通过学习得到的特定用途令牌定期压缩KV缓存的方法，使用修改的联合蒸馏和RL框架训练模型以提高内存效益及准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型长上下文推理的可扩展性因其Transformer键值缓存的线性增长受到严重限制，这会导致显著的内存和计算成本。

Method: 该研究通过修改的联合蒸馏和强化学习（RL）框架训练模型进行压缩，利用RL输出进行蒸馏，以减少传统RL过程的开销。

Result: 实验证明，所提出的方法在内存-准确性帕累托前沿表现优于未压缩缓存的模型和不需要训练的压缩技术。

Conclusion: 本研究提出的KV缓存压缩方法，在模型的内存使用和准确性之间取得了优于未压缩模型和无训练压缩技术的结果。

Abstract: The scalability of large language models for long-context reasoning is
severely constrained by the linear growth of their Transformer key-value cache,
which incurs significant memory and computational costs. We posit that as a
model generates reasoning tokens, the informational value of past generated
tokens diminishes, creating an opportunity for compression. In this work, we
propose to periodically compress the generation KV cache with a learned,
special-purpose token and evict compressed entries. We train the model to
perform this compression via a modified joint distillation and reinforcement
learning (RL) framework. Our training method minimizes overhead over the
conventional RL process, as it leverages RL outputs for distillation.
Empirically, our method achieves a superior memory-accuracy Pareto frontier
compared to both the model without cache compression and training-free
compression techniques.

</details>


### [139] [BRIEF-Pro: Universal Context Compression with Short-to-Long Synthesis for Fast and Accurate Multi-Hop Reasoning](https://arxiv.org/abs/2510.13799)
*Jia-Chen Gu,Junyi Zhang,Di Wu,Yuankai Li,Kai-Wei Chang,Nanyun Peng*

Main category: cs.CL

TL;DR: BRIEF-Pro is a compression tool that efficiently compresses large contexts for better QA performance in RAG systems, achieving high compression rates with reduced computational demands.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the challenge of high latency and cognitive load in retrieval-augmented generation systems when dealing with large context sizes, especially in complex multi-hop questions.

Method: BRIEF-Pro leverages abstractive compression to distill relevant information from extensive contexts, facilitating their integration into retrieval-augmented generation systems.

Result: Experiments demonstrate that BRIEF-Pro enhances performance in QA tasks with various models, achieving significant compression while reducing computational overhead.

Conclusion: BRIEF-Pro improves QA performance by efficiently summarizing large contexts to assist RAG systems with multi-hop questions.

Abstract: As retrieval-augmented generation (RAG) tackles complex tasks, increasingly
expanded contexts offer richer information, but at the cost of higher latency
and increased cognitive load on the model. To mitigate this bottleneck,
especially for intricate multi-hop questions, we introduce BRIEF-Pro. It is a
universal, lightweight compressor that distills relevant evidence for a given
query from retrieved documents into a concise summary for seamless integration
into in-context RAG. Using seed data consisting of relatively short contexts
(fewer than 1k words), BRIEF-Pro is trained to perform abstractive compression
of extended contexts exceeding 10k words across a wide range of scenarios.
Furthermore, BRIEF-Pro offers flexible user control over summary length by
allowing users to specify the desired number of sentences. Experiments on four
open-domain multi-hop question-answering datasets show that BRIEF-Pro generates
more concise and relevant summaries, enhancing performance across small, large,
and proprietary language models. With the 70B reader model, 32x compression by
BRIEF-Pro improves QA performance by 4.67% on average over LongLLMLingua's 9x,
while requiring only 23% of its computational overhead.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [140] [KVCOMM: Online Cross-context KV-cache Communication for Efficient LLM-based Multi-agent Systems](https://arxiv.org/abs/2510.12872)
*Hancheng Ye,Zhengqi Gao,Mingyuan Ma,Qinsi Wang,Yuzhe Fu,Ming-Yu Chung,Yueqian Lin,Zhijian Liu,Jianyi Zhang,Danyang Zhuo,Yiran Chen*

Main category: cs.MA

TL;DR: 文章提出KVCOMM框架，通过优化KV缓存重用，显著提升多智能体大语言模型的处理效率，实现了高达7.8倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 多智能体大语言模型系统在处理复杂语言任务时，存在因智能体间上下文重叠而导致的重复计算问题。当前的KV缓存方法无法直接应用于多智能体场景，因为不同智能体的上下文扩展导致前缀不同。因此，需要一种解决方法来提高多智能体推理的效率。

Method: 该研究提出了一种名为KVCOMM的训练自由框架。它通过使用锚点池来估计和调整KV缓存，用于共享内容的缓存。锚点池存储了在各种前缀下观察到的缓存偏差，并能在线维护和更新，以动态适应不同用户请求和上下文结构。

Result: KVCOMM实现了跨多种多智能体工作负载的70%以上的重用率，并在检索增强生成、数学推理和协同编码任务中，均无质量下降。特别是在每个智能体接收1K输入标记、512前缀标记及512输出标记的五智能体设置中，对比标准预填充流水线，KVCOMM将TTFT从约430毫秒减少到约55毫秒，实现了最高达7.8倍的加速。

Conclusion: 本文提出的KVCOMM框架通过重新使用KV缓存和对齐重叠上下文的缓存偏移，实现了多智能体推理中的高效预填充。该方法在不降低质量的情况下，显著提高了多智能体工作负载的处理效率。

Abstract: Multi-agent large language model (LLM) systems are increasingly adopted for
complex language processing tasks that require communication and coordination
among agents. However, these systems often suffer substantial overhead from
repeated reprocessing of overlapping contexts across agents. In typical
pipelines, once an agent receives a message from its predecessor, the full
context-including prior turns-must be reprocessed from scratch, leading to
inefficient processing. While key-value (KV) caching is an effective solution
for avoiding redundant computation in single-agent settings where prefixes
remain unchanged, it cannot be directly reused in multi-agent scenarios due to
diverging prefixes introduced by agent-specific context extensions. We identify
that the core challenge lies in the offset variance of KV-caches across agents.
To address this, we propose KVCOMM, a training-free framework that enables
efficient prefilling in multi-agent inference by reusing KV-caches and aligning
cache offsets of overlapping contexts under diverse prefix contexts. KVCOMM
estimates and adjusts KV-caches for shared content by referencing a pool of
cached examples-termed anchors-that store observed cache deviations under
varying prefixes. The anchor pool is maintained and updated online, allowing
dynamic adaptation to distinct user requests and context structures. KVCOMM
achieves over 70% reuse rate across diverse multi-agent workloads, including
retrieval-augmented generation, math reasoning, and collaborative coding tasks,
all without quality degradation. Particularly, when each fully-connected agent
receives 1K input tokens with 512 prefix tokens and 512 output tokens under a
five-agent setting, KVCOMM achieves up to 7.8x speedup compared to the standard
prefill pipeline, reducing TTFT from ~430 ms to ~55 ms.

</details>


### [141] [Altruistic Ride Sharing: A Community-Driven Approach to Short-Distance Mobility](https://arxiv.org/abs/2510.13227)
*Divyanshu Singh,Ashman Mehra,Snehanshu Saha,Santonu Sarkar*

Main category: cs.MA

TL;DR: 引入了一种名为ARS的新型利他的共享出行系统，通过多智能体学习和博弈论实现动态搭乘和公平性，证实其能有效降低出行距离、减少排放并提高公平性。


<details>
  <summary>Details</summary>
Motivation: 现有的城市骑行平台通常以盈利为驱动，优先考虑收入而不是公平性和可持续性。这导致了拥堵和高燃油消耗的问题，尤其是在个人选择私人通勤方案时。

Method: 引入Altruistic Ride-Sharing (ARS)，一个去中心化的点对点骑行框架，参与者基于利他主义积分而非金钱驱动在司机和乘客角色间交替。系统结合了多智能体强化学习(MADDPG)用于动态搭乘匹配，并通过博弈论平衡算法保证公平性，同时使用人口模型维持长期平衡。

Result: 使用纽约市出租车的真实数据进行验证，ARS系统减少了出行距离和排放量，提高了车辆利用率，并促进了比不共享和基于优化的基准更为公平的参与。

Conclusion: ARS被证实作为传统骑行共享的可扩展的、社区驱动的替代方案，与个人行为保持一致，支持整体城市可持续性目标。

Abstract: Urban mobility faces persistent challenges of congestion and fuel
consumption, specifically when people choose a private, point-to-point commute
option. Profit-driven ride-sharing platforms prioritize revenue over fairness
and sustainability. This paper introduces Altruistic Ride-Sharing (ARS), a
decentralized, peer-to-peer mobility framework where participants alternate
between driver and rider roles based on altruism points rather than monetary
incentives. The system integrates multi-agent reinforcement learning (MADDPG)
for dynamic ride-matching, game-theoretic equilibrium guarantees for fairness,
and a population model to sustain long-term balance. Using real-world New York
City taxi data, we demonstrate that ARS reduces travel distance and emissions,
increases vehicle utilization, and promotes equitable participation compared to
both no-sharing and optimization-based baselines. These results establish ARS
as a scalable, community-driven alternative to conventional ride-sharing,
aligning individual behavior with collective urban sustainability goals.

</details>


### [142] [AOAD-MAT: Transformer-based multi-agent deep reinforcement learning model considering agents' order of action decisions](https://arxiv.org/abs/2510.13343)
*Shota Takayama,Katsuhide Fujita*

Main category: cs.MA

TL;DR: AOAD-MAT模型通过考虑智能体执行动作的顺序优化了多智能体强化学习的性能，验证在多个基准测试中超过其他模型。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体强化学习模型虽然在性能上有所提升，但没有明确考虑智能体决策顺序的重要性，因此提出一种新模型以整合决策顺序对性能的影响。

Method: 提出了一种名为AOAD-MAT的新型多智能体变压器模型，将智能体决策顺序纳入学习过程中。该模型基于变压器的演员-评论家架构，通过动态调整智能体行动次序，采用Proximal Policy Optimization (PPO)损失函数，并引入次任务预测下一个行动智能体。

Result: 通过在StarCraft多智能体挑战赛和多智能体MuJoCo基准上的广泛实验验证，AOAD-MAT在性能上优于现有的MAT和其他基准模型。

Conclusion: 验证结果表明，调整多智能体强化学习中的行动顺序是有效的，AOAD-MAT模型在此方面取得了显著性能提升。

Abstract: Multi-agent reinforcement learning focuses on training the behaviors of
multiple learning agents that coexist in a shared environment. Recently, MARL
models, such as the Multi-Agent Transformer (MAT) and ACtion dEpendent deep
Q-learning (ACE), have significantly improved performance by leveraging
sequential decision-making processes. Although these models can enhance
performance, they do not explicitly consider the importance of the order in
which agents make decisions. In this paper, we propose an Agent Order of Action
Decisions-MAT (AOAD-MAT), a novel MAT model that considers the order in which
agents make decisions. The proposed model explicitly incorporates the sequence
of action decisions into the learning process, allowing the model to learn and
predict the optimal order of agent actions. The AOAD-MAT model leverages a
Transformer-based actor-critic architecture that dynamically adjusts the
sequence of agent actions. To achieve this, we introduce a novel MARL
architecture that cooperates with a subtask focused on predicting the next
agent to act, integrated into a Proximal Policy Optimization based loss
function to synergistically maximize the advantage of the sequential
decision-making. The proposed method was validated through extensive
experiments on the StarCraft Multi-Agent Challenge and Multi-Agent MuJoCo
benchmarks. The experimental results show that the proposed AOAD-MAT model
outperforms existing MAT and other baseline models, demonstrating the
effectiveness of adjusting the AOAD order in MARL.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [143] [Changing Oneself by Teaching Others? Exploring the Protégé Effect in Digital Stress Self-Regulation](https://arxiv.org/abs/2510.12944)
*Sameha Alshakhsi,Ala Yankouskaya,Dena Al-Thani,Raian Ali*

Main category: cs.HC

TL;DR: 研究探讨学徒效应在数字压力管理中的应用，发现其在行为改变上存在局限，未来可考虑互动形式来提升效果。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于探讨学徒效应在获取新行为方面的有效性，尤其是数字压力管理方面。

Method: 在三周内，137名中度到高度数字压力的参与者被分配到四个组。其中两个组基于学徒效应：一个是被动组，给定材料进行教学，另一个是主动组，收到标题并需搜索和准备教学内容。每组完成三次会议，每次会议专注于一种数字压力成分：可用性需求压力、认可焦虑、以及错失恐惧感。一个数字素养组提供相似内容和测验，另有一个对照组。

Result: 研究结果表明，通过学徒效应进行的干预在行为改变方面存在局限性，尤其是在数字习惯和社会强化压力的情况下。此外，研究指出，未来研究可以探讨互动形式，如同伴参与或自我调节元素，以增强动机和效果。

Conclusion: 该研究揭示了将认知参与转化为行为改变的挑战，尤其是在持续的数字习惯和社会强化的压力因素下。尽管学徒效应在知识和技能获取中显示出潜力，但在行为改变方面存在局限，尤其是在反思性数字健康策略的背景下。

Abstract: The prot\'eg\'ee effect suggests that individuals learn more effectively when
they teach a subject. While this has shown potential for acquiring knowledge
and skills, can it also support acquiring a new behaviour? This study evaluated
a prot\'eg\'e-based intervention designed to manage digital stress. Over three
weeks, 137 participants with moderate to high digital stress were assigned to
four groups. Two were prot\'eg\'ee-based: a passive group, given material to
teach, and an active group, received headlines and had to search for and
prepare teaching content. Both groups completed three sessions, each focused on
one digital stress component: availability demand stress, approval anxiety, and
fear of missing out. A digital literacy group received similar content and
quizzes, and a control group. Outcomes measured included digital stress,
problematic social media use, word-of-mouth about its management, and issue
involvement. Findings highlight the challenge of translating cognitive
engagement into behavioural change, especially amid persistent digital habits
and socially reinforced stressors. Results offer insights into the limitations
of interventions based on the prot\'eg\'ee effect when applied to behaviour
change, particularly in the context of reflective digital wellbeing strategies.
Future research could explore interactive formats, such as peer engagement or
self-regulatory elements, to enhance motivation and impact.

</details>


### [144] [Behavioral Biometrics for Automatic Detection of User Familiarity in VR](https://arxiv.org/abs/2510.12988)
*Numan Zafar,Priyo Ranjan Kundu Prosun,Shafique Ahmad Chaudhry*

Main category: cs.HC

TL;DR: 研究自动检测用户与VR交互的熟悉程度，通过分析用户在虚拟环境中开门任务中的手部动作模式来实现。利用深度分类器实现高精度识别。


<details>
  <summary>Details</summary>
Motivation: 随着VR设备在日常生活中的普及，无经验用户也会使用VR系统。自动检测用户对VR的熟悉程度有助于实时适应训练和界面调整，从而提高用户体验和任务表现。

Method: 使用深度分类器分析用户在虚拟环境中进行密码门打开任务时的手部动作模式，以此检测用户与VR的熟悉程度。

Result: 在手部追踪和控制器交互中，深度分类器的识别准确率分别达到92.05%和83.42%。在跨设备评估中，模型准确率为78.89%，而在混合设备评估中准确率达到94.19%。

Conclusion: 通过手部动作生物特征可以有效实现用户与VR交互熟悉程度的实时检测，为个性化和适应性的VR体验奠定基础。

Abstract: As virtual reality (VR) devices become increasingly integrated into everyday
settings, a growing number of users without prior experience will engage with
VR systems. Automatically detecting a user's familiarity with VR as an
interaction medium enables real-time, adaptive training and interface
adjustments, minimizing user frustration and improving task performance. In
this study, we explore the automatic detection of VR familiarity by analyzing
hand movement patterns during a passcode-based door-opening task, which is a
well-known interaction in collaborative virtual environments such as meeting
rooms, offices, and healthcare spaces. While novice users may lack prior VR
experience, they are likely to be familiar with analogous real-world tasks
involving keypad entry. We conducted a pilot study with 26 participants, evenly
split between experienced and inexperienced VR users, who performed tasks using
both controller-based and hand-tracking interactions. Our approach uses
state-of-the-art deep classifiers for automatic VR familiarity detection,
achieving the highest accuracies of 92.05% and 83.42% for hand-tracking and
controller-based interactions, respectively. In the cross-device evaluation,
where classifiers trained on controller data were tested using hand-tracking
data, the model achieved an accuracy of 78.89%. The integration of both
modalities in the mixed-device evaluation obtained an accuracy of 94.19%. Our
results underline the promise of using hand movement biometrics for the
real-time detection of user familiarity in critical VR applications, paving the
way for personalized and adaptive VR experiences.

</details>


### [145] [Deep Learning-Based Visual Fatigue Detection Using Eye Gaze Patterns in VR](https://arxiv.org/abs/2510.12994)
*Numan Zafar,Johnathan Locke,Shafique Ahmad Chaudhry*

Main category: cs.HC

TL;DR: 本文提出了一种基于深度学习的研究，通过VR中的眼动轨迹进行视觉疲劳检测，在需要高度视觉注意的任务中取得了高达94%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉疲劳检测方法依赖于主观问卷或侵入式的生理信号，如脑电图、心率或眼睛眨动次数，这限制了其可扩展性和实时应用性。

Method: 使用GazeBaseVR数据集，提取双眼跟踪数据和单眼凝视角度，评估六种深度分类器，分析注视方差和主观疲劳测量。

Result: EKYT在要求高度视觉注意力的任务中（如视频观看和文本阅读）达到高达94%的准确率，揭示了疲劳和非疲劳状态之间显著的行为差异。

Conclusion: 眼睛凝视动态是检测沉浸式VR中持续疲劳的可靠且非侵入性方式，具有适用于人机交互的实际意义。

Abstract: Prolonged exposure to virtual reality (VR) systems leads to visual fatigue,
impairs user comfort, performance, and safety, particularly in high-stakes or
long-duration applications. Existing fatigue detection approaches rely on
subjective questionnaires or intrusive physiological signals, such as EEG,
heart rate, or eye-blink count, which limit their scalability and real-time
applicability. This paper introduces a deep learning-based study for detecting
visual fatigue using continuous eye-gaze trajectories recorded in VR. We use
the GazeBaseVR dataset comprising binocular eye-tracking data from 407
participants across five immersive tasks, extract cyclopean eye-gaze angles,
and evaluate six deep classifiers. Our results demonstrate that EKYT achieves
up to 94% accuracy, particularly in tasks demanding high visual attention, such
as video viewing and text reading. We further analyze gaze variance and
subjective fatigue measures, indicating significant behavioral differences
between fatigued and non-fatigued conditions. These findings establish eye-gaze
dynamics as a reliable and nonintrusive modality for continuous fatigue
detection in immersive VR, offering practical implications for adaptive
human-computer interactions.

</details>


### [146] [Developing and Validating the Arabic Version of the Attitudes Toward Large Language Models Scale](https://arxiv.org/abs/2510.13009)
*Basad Barajeeh,Ala Yankouskaya,Sameha AlShakhsi,Chun Sing Maxwell Ho,Guandong Xu,Raian Ali*

Main category: cs.HC

TL;DR: 本研究将用于测量对大型语言模型(LLMs)态度的两种量表翻译为阿拉伯语，并验证其在阿拉伯世界中的信效度，为非西方背景下的LLM研究提供支持。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型(LLMs)的全球使用日益增长，尤其是在阿拉伯世界的快速采用，迫切需要开发适合当地文化和语言的工具来了解公众对这些系统的态度。

Method: 将Attitudes Toward General LLMs (AT-GLLM)和Attitudes Toward Primary LLM (AT-PLLM)两种量表翻译为阿拉伯语，并通过249名阿拉伯语使用者样本进行信效度验证，包括心理测量分析证实两因素结构、性别间测量不变性及良好的内部信度。

Result: 翻译后的量表在阿拉伯文化和文化背景下被证明是可靠且有效的工具，具有两因素结构、性别间测量不变性和良好的内部一致性。量表也表现出较强的聚合效度和辨别效度。

Conclusion: 本研究成功将AT-GLLM和AT-PLLM量表翻译成阿拉伯语，并验证其对阿拉伯语使用者的信效度，证明其在阿拉伯语言和文化背景下的适用性。

Abstract: As the use of large language models (LLMs) becomes increasingly global,
understanding public attitudes toward these systems requires tools that are
adapted to local contexts and languages. In the Arab world, LLM adoption has
grown rapidly with both globally dominant platforms and regional ones like
Fanar and Jais offering Arabic-specific solutions. This highlights the need for
culturally and linguistically relevant scales to accurately measure attitudes
toward LLMs in the region. Tools assessing attitudes toward artificial
intelligence (AI) can provide a base for measuring attitudes specific to LLMs.
The 5-item Attitudes Toward Artificial Intelligence (ATAI) scale, which
measures two dimensions, the AI Fear and the AI Acceptance, has been recently
adopted and adapted to develop new instruments in English using a sample from
the UK: the Attitudes Toward General LLMs (AT-GLLM) and Attitudes Toward
Primary LLM (AT-PLLM) scales. In this paper, we translate the two scales,
AT-GLLM and AT-PLLM, and validate them using a sample of 249 Arabic-speaking
adults. The results show that the scale, translated into Arabic, is a reliable
and valid tool that can be used for the Arab population and language.
Psychometric analyses confirmed a two-factor structure, strong measurement
invariance across genders, and good internal reliability. The scales also
demonstrated strong convergent and discriminant validity. Our scales will
support research in a non-Western context, a much-needed effort to help draw a
global picture of LLM perceptions, and will also facilitate localized research
and policy-making in the Arab region.

</details>


### [147] [Adapting to the User: A Systematic Review of Personalized Interaction in VR](https://arxiv.org/abs/2510.13123)
*Tangyao Li,Yitong Zhu,Hai-Ning Liang,Yuyang Wang*

Main category: cs.HC

TL;DR: 本研究探讨了VR中个性化互动的研究，特别关注参与者沉浸信息和适应机制的利用，提出了统一适应机制的五阶段概念框架，并展望了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有的评论通常单独讨论用户状态感知或适应性能设计，这限制了我们对它们在VR中结合实施的理解。

Method: 我们综合了应用跨领域适应性技术的研究结果，并总结出了统一适应机制的五阶段概念框架。

Result: 我们的分析揭示了新兴趋势，包括多模态传感器的整合、对用户状态推断的日益依赖以及平衡响应性和透明性的挑战。

Conclusion: 我们提出了未来开发更以用户为中心的VR系统的方向。

Abstract: As virtual reality (VR) systems become increasingly more advanced, they are
likewise expected to respond intelligently and adapt to individual user states,
abilities, and preferences. Recent work has explored how VR can be adapted and
tailored to individual users. However, existing reviews tend to address either
user-state sensing or adaptive interaction design in isolation, limiting our
understanding of their combined implementation in VR. Therefore, in this paper,
we examine the growing research on personalized interaction in VR, with a
particular focus on utilizing participants' immersion information and
adaptation mechanisms to modify virtual environments and enhance engagement,
performance, or a specific goal. We synthesize findings from studies that
employ adaptive techniques across diverse application domains and summarize a
five-stage conceptual framework that unifies adaptive mechanisms across
domains. Our analysis reveals emerging trends, including the integration of
multimodal sensors, an increasing reliance on user state inference, and the
challenge of balancing responsiveness with transparency. We conclude by
proposing future directions for developing more user-centered VR systems.

</details>


### [148] [Smart UX-design for Rescue Operations Wearable - A Knowledge Graph Informed Visualization Approach for Information Retrieval in Emergency Situations](https://arxiv.org/abs/2510.13539)
*Mubaris Nadeem,Johannes Zenkert,Christian Weber,Madjid Fathi,Muhammad Hamza*

Main category: cs.HC

TL;DR: 该文通过知识图谱优化对急救操作的支持，增强了系统检测和信息检索能力。


<details>
  <summary>Details</summary>
Motivation: 提升急救操作的信息检索效率，为健康专业人员在紧急情况下提供更好的治疗建议。

Method: 采用基于知识图谱的智能UX设计，通过情境推荐为急救医疗提供支持。

Result: 成功实现了一个项目实施方案，能够通过知识图谱和AI提供推荐，改善急救协调和信息获取。

Conclusion: 该研究通过知识图谱和智能UX设计提高急救操作的有效性和效率。

Abstract: This paper presents a knowledge graph-informed smart UX-design approach for
supporting information retrieval for a wearable, providing treatment
recommendations during emergency situations to health professionals. This paper
describes requirements that are unique to knowledge graph-based solutions, as
well as the direct requirements of health professionals. The resulting
implementation is provided for the project, which main goal is to improve
first-aid rescue operations by supporting artificial intelligence in situation
detection and knowledge graph representation via a contextual-based
recommendation for treatment assistance.

</details>


### [149] [Speculating a Tactile Grammar: Toward Task-Aligned Chart Design for Non-Visual Perception](https://arxiv.org/abs/2510.13731)
*Areen Khalaila,Dylan Cashman*

Main category: cs.HC

TL;DR: 提出触觉设计框架以改善图表在触觉格式下的可用性，并提供了设计可访问COVID-19仪表板的示例。


<details>
  <summary>Details</summary>
Motivation: 视觉图表设计的触觉翻译对盲人和低视力人群探索不够有效，因此需要一种触觉优先的设计方法。

Method: 提出了一个推测性的触觉设计框架，探讨如何将数据分析任务与触觉策略和编码选择相结合，并在文中展示了推测性草图。

Result: 提出了一个触觉设计框架，可能改善图表在触觉格式下的比较、趋势检测和比例估计。

Conclusion: 提出了一种触觉设计框架，即触觉感知语法，虽然尚未经过验证，但提供了生成“触觉优先”图表设计的新视角，并展示了其在设计可访问的COVID-19仪表板中的可能应用。

Abstract: Tactile graphics are often adapted from visual chart designs, yet many of
these encodings do not translate effectively to non-visual exploration. Blind
and low-vision (BLV) people employ a variety of physical strategies such as
measuring lengths with fingers or scanning for texture differences to interpret
tactile charts. These observations suggest an opportunity to move beyond direct
visual translation and toward a tactile-first design approach. We outline a
speculative tactile design framework that explores how data analysis tasks may
align with tactile strategies and encoding choices. While this framework is not
yet validated, it offers a lens for generating tactile-first chart designs and
sets the stage for future empirical exploration. We present speculative mockups
to illustrate how the Tactile Perceptual Grammar might guide the design of an
accessible COVID-19 dashboard. This scenario illustrates how the grammar can
guide encoding choices that better support comparison, trend detection, and
proportion estimation in tactile formats. We conclude with design implications
and a discussion of future validation through co-design and task-based
evaluation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [150] [Lifting Manifolds to Mitigate Pseudo-Alignment in LLM4TS](https://arxiv.org/abs/2510.12847)
*Liangwei Nathan Zheng,Wenhao Liang,Wei Emma Zhang,Miao Xu,Olaf Maennel,Weitong Chen*

Main category: cs.LG

TL;DR: 研究发现，伪对齐问题源于预训练LLM成分的锥效应与时间序列数据的低维流形，其新方法TimeSUP有效改善了预测性能。


<details>
  <summary>Details</summary>
Motivation: 在许多面向时间序列的大型语言模型中存在伪对齐问题，导致模型表现不如线性模型。本文调查了伪对齐问题的根本原因并与锥效应建立了联系。

Method: 引入了一种名为TimeSUP的新技术，通过增加时间序列流形以更接近语言嵌入的本质维度，从而缓解伪对齐问题。TimeSUP允许模型清晰地区分时间信号，同时捕捉跨模态的结构特征。它可以无缝集成到四个现有的LLM4TS管道中，并改善预测性能。

Result: TimeSUP在长期预测表现上，一贯优于现有的LLM4TS方法和其他轻量级基线。

Conclusion: TimeSUP能够显著提升现有LLM4TS系统的预测性能，保持时间和语言特征的独特性，同时学习它们在统一嵌入空间中的共性。

Abstract: Pseudo-Alignment is a pervasive challenge in many large language models for
time series (LLM4TS) models, often causing them to underperform compared to
linear models or randomly initialised backbones. However, there is limited
discussion in the community for the reasons that pseudo-alignment occurs. In
this work, we conduct a thorough investigation into the root causes of
pseudo-alignment in LLM4TS and build a connection of pseudo-alignment to the
cone effect in LLM. We demonstrate that pseudo-alignment arises from the
interplay of cone effect within pretrained LLM components and the intrinsically
low-dimensional manifold of time-series data. In addition, we also introduce
\textit{\textbf{TimeSUP}}, a novel technique designed to mitigate this issue
and improve forecast performance in existing LLM4TS approaches. TimeSUP
addresses this by increasing the time series manifold to more closely match the
intrinsic dimension of language embeddings, allowing the model to distinguish
temporal signals clearly while still capturing shared structures across
modalities. As a result, representations for time and language tokens remain
distinct yet exhibit high cosine similarity, signifying that the model
preserves each modality unique features while learning their commonalities in a
unified embedding space. Empirically, TimeSUP consistently outperforms
state-of-the-art LLM4TS methods and other lightweight baselines on long-term
forecasting performance. Furthermore, it can be seamlessly integrated into four
existing LLM4TS pipelines and delivers significant improvements in forecasting
performance.

</details>


### [151] [FedGTEA: Federated Class-Incremental Learning with Gaussian Task Embedding and Alignment](https://arxiv.org/abs/2510.12927)
*Haolin Li,Hoda Bidkhori*

Main category: cs.LG

TL;DR: FedGTEA is a new framework for Class Incremental Learning using Gaussian embeddings to enhance performance and reduce forgetting, maintaining scalability and privacy.


<details>
  <summary>Details</summary>
Motivation: The paper aims to introduce a scalable and communication-efficient framework for Federated Class Incremental Learning, addressing statistical heterogeneity and data uncertainty with task-specific embeddings while maintaining privacy in federated learning.

Method: At the client side, the Cardinality-Agnostic Task Encoder (CATE) is used to produce Gaussian-distributed task embeddings, addressing statistical heterogeneity and data uncertainty while maintaining a fixed parameter size. On the server side, the 2-Wasserstein distance measures gaps between Gaussian embeddings with a Wasserstein loss to enforce inter-task separation. This probabilistic approach enhances representation learning and preserves task-level privacy.

Result: FedGTEA demonstrates superior classification performance and reduced forgetting on popular datasets, consistently outperforming strong baselines.

Conclusion: FedGTEA framework effectively captures task-specific knowledge and model uncertainty, showing superior classification performance and mitigating forgetting compared to existing methods.

Abstract: We introduce a novel framework for Federated Class Incremental Learning,
called Federated Gaussian Task Embedding and Alignment (FedGTEA). FedGTEA is
designed to capture task-specific knowledge and model uncertainty in a scalable
and communication-efficient manner. At the client side, the
Cardinality-Agnostic Task Encoder (CATE) produces Gaussian-distributed task
embeddings that encode task knowledge, address statistical heterogeneity, and
quantify data uncertainty. Importantly, CATE maintains a fixed parameter size
regardless of the number of tasks, which ensures scalability across long task
sequences. On the server side, FedGTEA utilizes the 2-Wasserstein distance to
measure inter-task gaps between Gaussian embeddings. We formulate the
Wasserstein loss to enforce inter-task separation. This probabilistic
formulation not only enhances representation learning but also preserves
task-level privacy by avoiding the direct transmission of latent embeddings,
aligning with the privacy constraints in federated learning. Extensive
empirical evaluations on popular datasets demonstrate that FedGTEA achieves
superior classification performance and significantly mitigates forgetting,
consistently outperforming strong existing baselines.

</details>


### [152] [Learning at the Speed of Physics: Equilibrium Propagation on Oscillator Ising Machines](https://arxiv.org/abs/2510.12934)
*Alex Gower*

Main category: cs.LG

TL;DR: 研究表明，摆荡器Ising机器结合平衡传播可以在不需要全球反向传播的情况下，高效进行本地学习，取得优异的准确率和能量效率。


<details>
  <summary>Details</summary>
Motivation: 为了加速机器学习，研究自然执行能量下降的物理系统，并利用其动态特性优化能量模型和执行采样。

Method: 通过在摆荡器Ising机器上应用平衡传播（EP），实现对能源基础模型的优化和梯度下降过程。

Result: EP在OIM上达到了具有竞争力的准确率（MNIST上约为97.2±0.1%，时尚-MNIST上约为88.0±0.1%），并且在诸如参数量化和相位噪声等实际硬件约束下保持鲁棒性。

Conclusion: 摆荡器Ising机器（OIMs）能够在不依赖全球反向传播的情况下，实现本地学习规则，并在硬件约束条件下保持竞争力和鲁棒性。

Abstract: Physical systems that naturally perform energy descent offer a direct route
to accelerating machine learning. Oscillator Ising Machines (OIMs) exemplify
this idea: their GHz-frequency dynamics mirror both the optimization of
energy-based models (EBMs) and gradient descent on loss landscapes, while
intrinsic noise corresponds to Langevin dynamics - supporting sampling as well
as optimization. Equilibrium Propagation (EP) unifies these processes into
descent on a single total energy landscape, enabling local learning rules
without global backpropagation. We show that EP on OIMs achieves competitive
accuracy ($\sim 97.2 \pm 0.1 \%$ on MNIST, $\sim 88.0 \pm 0.1 \%$ on
Fashion-MNIST), while maintaining robustness under realistic hardware
constraints such as parameter quantization and phase noise. These results
establish OIMs as a fast, energy-efficient substrate for neuromorphic learning,
and suggest that EBMs - often bottlenecked by conventional processors - may
find practical realization on physical hardware whose dynamics directly perform
their optimization.

</details>


### [153] [An Investigation of Memorization Risk in Healthcare Foundation Models](https://arxiv.org/abs/2510.12950)
*Sana Tonekaboni,Lena Stempfle,Adibvafa Fallahpour,Walter Gerych,Marzyeh Ghassemi*

Main category: cs.LG

TL;DR: 引入了一套评估基础模型隐私风险的黑箱测试。


<details>
  <summary>Details</summary>
Motivation: 为解决基础模型在保存病人信息方面可能产生的隐私问题。

Method: 创建了一套黑箱测试框架用于评估基础模型的隐私记忆风险，包括嵌入级别和生成级别的记忆测试方法。

Result: 这篇论文研究了大规模匿名电子健康记录（EHRs）基础模型的隐私问题。

Conclusion: 方法有效区分了模型泛化与有害记忆。

Abstract: Foundation models trained on large-scale de-identified electronic health
records (EHRs) hold promise for clinical applications. However, their capacity
to memorize patient information raises important privacy concerns. In this
work, we introduce a suite of black-box evaluation tests to assess
privacy-related memorization risks in foundation models trained on structured
EHR data. Our framework includes methods for probing memorization at both the
embedding and generative levels, and aims to distinguish between model
generalization and harmful memorization in clinically relevant settings. We
contextualize memorization in terms of its potential to compromise patient
privacy, particularly for vulnerable subgroups. We validate our approach on a
publicly available EHR foundation model and release an open-source toolkit to
facilitate reproducible and collaborative privacy assessments in healthcare AI.

</details>


### [154] [Balancing Performance and Reject Inclusion: A Novel Confident Inlier Extrapolation Framework for Credit Scoring](https://arxiv.org/abs/2510.12967)
*Athyrson Machado Ribeiro,Marcos Medeiros Raimundo*

Main category: cs.LG

TL;DR: 提出CI-EX框架，通过异常检测和分类模型改善拒绝推断，实验显示在RI特定指标上优于现有模型，并在AUC上表现良好。


<details>
  <summary>Details</summary>
Motivation: 传统方法往往假设被拒绝客户的行为可以由被接受客户的行为外推，而忽略了两者之间可能的分布差异。为减轻这种盲目外推，提出CI-EX框架。

Method: CI-EX通过迭代使用异常检测模型识别拒绝客户样本的分布，并根据监督分类模型导出的概率为最接近接受人群分布的拒绝个人分配标签。

Result: 实验验证了CI-EX在两个大型真实信用数据集中的有效性。结果表明，虽然RI方法通常在AUC和RI特定指标之间存在权衡，但CI-EX在RI特定指标方面优于现有模型，同时在大多数实验中AUC表现良好。

Conclusion: CI-EX框架在RI特定指标方面的表现优于现有模型，同时在大多数实验中保持了AUC的竞争力。

Abstract: Reject Inference (RI) methods aim to address sample bias by inferring missing
repayment data for rejected credit applicants. Traditional approaches often
assume that the behavior of rejected clients can be extrapolated from accepted
clients, despite potential distributional differences between the two
populations. To mitigate this blind extrapolation, we propose a novel Confident
Inlier Extrapolation framework (CI-EX). CI-EX iteratively identifies the
distribution of rejected client samples using an outlier detection model and
assigns labels to rejected individuals closest to the distribution of the
accepted population based on probabilities derived from a supervised
classification model. The effectiveness of our proposed framework is validated
through experiments on two large real-world credit datasets. Performance is
evaluated using the Area Under the Curve (AUC) as well as RI-specific metrics
such as Kickout and a novel metric introduced in this work, denoted as Area
under the Kickout. Our findings reveal that RI methods, including the proposed
framework, generally involve a trade-off between AUC and RI-specific metrics.
However, the proposed CI-EX framework consistently outperforms existing RI
models from the credit literature in terms of RI-specific metrics while
maintaining competitive performance in AUC across most experiments.

</details>


### [155] [A Connection Between Score Matching and Local Intrinsic Dimension](https://arxiv.org/abs/2510.12975)
*Eric Yeats,Aaron Jacobson,Darryl Hannan,Yiran Jia,Timothy Doster,Henry Kvinge,Scott Mahan*

Main category: cs.LG

TL;DR: 本文提出了去噪分数匹配损失作为局部固有维度（LID）有效估计器，并证明其在问题规模和量化水平增加的情况下具有优越的性能。


<details>
  <summary>Details</summary>
Motivation: 历史上很难量化高维复杂数据的局部固有维度（LID）。最近的研究表明，扩散模型通过它们的分数估计谱和在各种噪声扰动下其密度估计的变化率捕获数据的LID。然而，这些方法需要模型多次正向传递或使用梯度计算，限制了它们在计算和内存受限场景中的适用性。

Method: 使用去噪分数匹配损失来估计数据的局部固有维度（LID），并进行实验验证其性能优势。

Result: 我们证明LID是去噪分数匹配损失的下界，激励使用去噪分数匹配损失作为LID估计器。此外，我们证明等效的隐式分数匹配损失也通过正常维度近似LID，并与最近的LID估计器FLIPD密切相关。我们的实验表明去噪分数匹配损失是一个高度竞争的LID估计器，具有优越的精度和内存占用。

Conclusion: 去噪分数匹配损失是一个具有竞争力且可扩展的LID估计器，在增加问题规模和量化水平的情况下实现了优越的精度和内存使用。

Abstract: The local intrinsic dimension (LID) of data is a fundamental quantity in
signal processing and learning theory, but quantifying the LID of
high-dimensional, complex data has been a historically challenging task. Recent
works have discovered that diffusion models capture the LID of data through the
spectra of their score estimates and through the rate of change of their
density estimates under various noise perturbations. While these methods can
accurately quantify LID, they require either many forward passes of the
diffusion model or use of gradient computation, limiting their applicability in
compute- and memory-constrained scenarios.
  We show that the LID is a lower bound on the denoising score matching loss,
motivating use of the denoising score matching loss as a LID estimator.
Moreover, we show that the equivalent implicit score matching loss also
approximates LID via the normal dimension and is closely related to a recent
LID estimator, FLIPD. Our experiments on a manifold benchmark and with Stable
Diffusion 3.5 indicate that the denoising score matching loss is a highly
competitive and scalable LID estimator, achieving superior accuracy and memory
footprint under increasing problem size and quantization level.

</details>


### [156] [Reference-Specific Unlearning Metrics Can Hide the Truth: A Reality Check](https://arxiv.org/abs/2510.12981)
*Sungjun Cho,Dasol Hwang,Frederic Sala,Sangheum Hwang,Kyunghyun Cho,Sungmin Cha*

Main category: cs.LG

TL;DR: The paper identifies flaws in current unlearning metrics for generative models and introduces FADE, a new metric that better assesses genuine unlearning by comparing distributional similarity with reference models.


<details>
  <summary>Details</summary>
Motivation: Existing unlearning metrics for generative models fail to assess whether an unlearned model behaves like a model that has never seen the unwanted data, leading to systematic blind spots.

Method: The paper proposes a novel metric called Functional Alignment for Distributional Equivalence (FADE) to measure distributional similarity by comparing bidirectional likelihood assignments over generated samples.

Result: Experiments on the TOFU and UnlearnCanvas benchmarks show that traditional metrics fail to achieve distributional equivalence and that FADE offers a better basis for the development and assessment of unlearning methods.

Conclusion: Currently used unlearning metrics for generative models have significant limitations, and the proposed FADE metric offers a more comprehensive and robust method for evaluating genuine unlearning.

Abstract: Current unlearning metrics for generative models evaluate success based on
reference responses or classifier outputs rather than assessing the core
objective: whether the unlearned model behaves indistinguishably from a model
that never saw the unwanted data. This reference-specific approach creates
systematic blind spots, allowing models to appear successful while retaining
unwanted knowledge accessible through alternative prompts or attacks. We
address these limitations by proposing Functional Alignment for Distributional
Equivalence (FADE), a novel metric that measures distributional similarity
between unlearned and reference models by comparing bidirectional likelihood
assignments over generated samples. Unlike existing approaches that rely on
predetermined references, FADE captures functional alignment across the entire
output distribution, providing a principled assessment of genuine unlearning.
Our experiments on the TOFU benchmark for LLM unlearning and the UnlearnCanvas
benchmark for text-to-image diffusion model unlearning reveal that methods
achieving near-optimal scores on traditional metrics fail to achieve
distributional equivalence, with many becoming more distant from the gold
standard than before unlearning. These findings expose fundamental gaps in
current evaluation practices and demonstrate that FADE provides a more robust
foundation for developing and assessing truly effective unlearning methods.

</details>


### [157] [Max It or Miss It: Benchmarking LLM On Solving Extremal Problems](https://arxiv.org/abs/2510.12997)
*Binxin Gao,Jingjun Han*

Main category: cs.LG

TL;DR: 研究揭示了大型语言模型在数学领域的推理能力与现有基准不总是一致，指出了现有测试方法的不足。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在数学领域的推理能力和极值问题解决能力，以及当前评估模型中的差距。

Method: 引入了一个名为ExtremBench的基准数据集，用于系统地评估在限制条件下极值问题解决的能力。

Result: 评估结果表明，大型语言模型的极值问题解决能力并不总是与现有数学基准测试（如AIME25和MATH-500）的表现一致。有些模型在一般数学推理中表现优异，但在极值问题上表现不佳，反之亦然。

Conclusion: 目前的评估方法中存在关键差距，即现有的基准测试可能未能全面捕捉到模型的全部数学推理能力。

Abstract: Test-time scaling has enabled Large Language Models (LLMs) with remarkable
reasoning capabilities, particularly in mathematical domains, through
intermediate chain-of-thought (CoT) reasoning before generating final answers.
However, the specific sources and mechanisms underlying these reasoning
capabilities remain insufficiently understood. Optimization reasoning, i.e.
finding extrema under constraints, represents a fundamental abstraction that
underpins critical applications in planning, control, resource allocation, and
prompt search. To systematically evaluate this capability, we introduce
ExtremBench, a benchmark dataset for solving mathematical extremal problems,
curated from inequality exercises used for Chinese Mathematical Olympiad and
transformed into $93$ standardized extrema-finding problems. We conduct
extensive evaluations across various state-of-the-art open-source model
families, including the Qwen3, GPT-OSS, and DeepSeek. Our results reveal that
LLMs' extremal-solving reasoning capabilities do not always align with those of
current mathematical benchmarks such as AIME25 and MATH-500, with some models
showing strong general mathematical reasoning but poor extremal-solving skills,
and vice versa. This discrepancy highlights a critical gap in current
evaluation practices and suggests that existing benchmarks may not
comprehensively capture the full spectrum of mathematical reasoning abilities.

</details>


### [158] [AMORE: Adaptive Multi-Output Operator Network for Stiff Chemical Kinetics](https://arxiv.org/abs/2510.12999)
*Kamaljyoti Nath,Additi Pandey,Bryan T. Susi,Hessam Babaee,George Em Karniadakis*

Main category: cs.LG

TL;DR: 本论文提出AMORE框架，通过多输出预测和自适应损失函数，来提高刚性系统时间积分的效率。


<details>
  <summary>Details</summary>
Motivation: 解决刚性系统的时间积分问题，以降低在燃烧和其他反应传输系统中的计算成本。

Method: 提出AMORE框架，包含一个能够预测多输出的运算符和自适应损失函数，以确保学习的可靠性；采用两步训练法并应用于DeepONet和FNO。

Result: 该论文针对燃烧和高超音速等反应传输系统中的刚性问题，提出了AMORE框架。通过引入适应性损失函数和避免原始质量分数约束等技术，AMORE能够在多输出情景下有效预测热化学状态，显著降低计算成本，并展示了其在CFD上的潜力。

Conclusion: AMORE提供了一种有效的方法来解决刚性系统的时间积分问题，尤其是在CFD中对湍流燃烧模拟至关重要。

Abstract: Time integration of stiff systems is a primary source of computational cost
in combustion, hypersonics, and other reactive transport systems. This
stiffness can introduce time scales significantly smaller than those associated
with other physical processes, requiring extremely small time steps in explicit
schemes or computationally intensive implicit methods. Consequently, strategies
to alleviate challenges posed by stiffness are important. While neural
operators (DeepONets) can act as surrogates for stiff kinetics, a reliable
operator learning strategy is required to appropriately account for differences
in the error between output variables and samples. Here, we develop AMORE,
Adaptive Multi-Output Operator Network, a framework comprising an operator
capable of predicting multiple outputs and adaptive loss functions ensuring
reliable operator learning. The operator predicts all thermochemical states
from given initial conditions. We propose two adaptive loss functions within
the framework, considering each state variable's and sample's error to penalize
the loss function. We designed the trunk to automatically satisfy Partition of
Unity. To enforce unity mass-fraction constraint exactly, we propose an
invertible analytical map that transforms the $n$-dimensional species
mass-fraction vector into an ($n-1$)-dimensional space, where DeepONet training
is performed. We consider two-step training for DeepONet for multiple outputs
and extend adaptive loss functions for trunk and branch training. We
demonstrate the efficacy and applicability of our models through two examples:
the syngas (12 states) and GRI-Mech 3.0 (24 active states out of 54). The
proposed DeepONet will be a backbone for future CFD studies to accelerate
turbulent combustion simulations. AMORE is a general framework, and here, in
addition to DeepONet, we also demonstrate it for FNO.

</details>


### [159] [Escaping Local Optima in the Waddington Landscape: A Multi-Stage TRPO-PPO Approach for Single-Cell Perturbation Analysis](https://arxiv.org/abs/2510.13018)
*Francis Boabang,Samuel Asante Gyamerah*

Main category: cs.LG

TL;DR: 文章介绍了一种新的多阶段强化学习算法，通过良好设计的初始化来提高单细胞扰动建模的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于数据驱动的模型在细胞命运决策的非凸Waddington景观中容易陷入局部最优，而良好设计的初始化方法能够逃脱这些局部最优并收敛到正确的谱系。因此，提出一种完全数据驱动的方法来实现良好初始化以改善建模效果。

Method: 首先计算显式自然梯度更新，使用Fisher向量积和共轭梯度求解器，通过KL信任区域约束对策略进行安全的、曲率感知的第一步优化。然后应用局部策略优化（PPO）的二阶段方法，利用微批量效率细化策略。

Result: 这种新的初始化方法显著改善了在单细胞RNA测序和单细胞ATAC测序中的泛化能力。

Conclusion: 本文提出了一种多阶段强化学习算法，可以良好初始化单细胞扰动建模过程，从而提高在单细胞RNA测序和单细胞ATAC测序扰动分析中的泛化能力。

Abstract: Modeling cellular responses to genetic and chemical perturbations remains a
central challenge in single-cell biology. Existing data-driven framework have
advanced perturbation prediction through variational autoencoders, chemically
conditioned autoencoders, and large-scale transformer pretraining. However,
these models are prone to local optima in the nonconvex Waddington landscape of
cell fate decisions, where poor initialization can trap trajectories in
spurious lineages or implausible differentiation outcomes. While executable
gene regulatory networks complement these approaches, automated design
frameworks incorporate biological priors through multi-agent optimization. Yet,
an approach that is completely data-driven with well-designed initialization to
escape local optima and converge to a proper lineage remains elusive. In this
work, we introduce a multistage reinforcement learning algorithm tailored for
single-cell perturbation modeling. We first compute an explicit natural
gradient update using Fisher-vector products and a conjugate gradient solver,
scaled by a KL trust-region constraint to provide a safe, curvature-aware the
first step for the policy. Starting with these preconditioned parameters, we
then apply a second phase of proximal policy optimization (PPO) with clipped
surrogates, exploiting minibatch efficiency to refine the policy. We
demonstrate that this initialization substantially improves generalization on
Single-cell RNA sequencing (scRNA-seq) and Single-cell ATAC sequencing
(scATAC-seq) pertubation analysis.

</details>


### [160] [Machine Learning-Based Ultrasonic Weld Characterization Using Hierarchical Wave Modeling and Diffusion-Driven Distribution Alignment](https://arxiv.org/abs/2510.13023)
*Joshua R. Tempelman,Adam J. Wachtor,Eric B. Flynn*

Main category: cs.LG

TL;DR: A novel ML workflow for automated ultrasonic weld inspection is proposed, addressing data curation and corruption challenges via a reduced-order modeling scheme, diffusion-based alignment, and U-Net-based methods, resulting in an effective end-to-end solution.


<details>
  <summary>Details</summary>
Motivation: Automated ultrasonic weld inspection faces challenges due to limited training data and environmental volatility in industrial settings, which lead to data corruption. Developing an end-to-end machine learning workflow for acoustic weld inspection in industrial settings is needed to overcome data curation and signal corruption challenges.

Method: The workflow consists of a reduced-order modeling scheme, diffusion-based distribution alignment, and U-Net-based segmentation and inversion. A reduced-order Helmholtz model based on Lamb wave theory is used to generate a comprehensive dataset over varying weld heterogeneity and crack defects. Inversion models are refined through a transfer learning stage using a limited set of full 3D elastodynamic simulations.

Result: The workflow effectively addresses data curation and signal corruption challenges, enabling automated weld inspection using real data, including handling out-of-distribution measurements with varying noise distributions.

Conclusion: This integrated framework provides an end-to-end solution for automated weld inspection on real data.

Abstract: Automated ultrasonic weld inspection remains a significant challenge in the
nondestructive evaluation (NDE) community to factors such as limited training
data (due to the complexity of curating experimental specimens or high-fidelity
simulations) and environmental volatility of many industrial settings
(resulting in the corruption of on-the-fly measurements). Thus, an end-to-end
machine learning (ML) workflow for acoustic weld inspection in realistic (i.e.,
industrial) settings has remained an elusive goal. This work addresses the
challenges of data curation and signal corruption by proposing workflow
consisting of a reduced-order modeling scheme, diffusion based distribution
alignment, and U-Net-based segmentation and inversion. A reduced-order
Helmholtz model based on Lamb wave theory is used to generate a comprehensive
dataset over varying weld heterogeneity and crack defects. The relatively
inexpensive low-order solutions provide a robust training dateset for inversion
models which are refined through a transfer learning stage using a limited set
of full 3D elastodynamic simulations. To handle out-of-distribution (OOD)
real-world measurements with varying and unpredictable noise distributions,
i.e., Laser Doppler Vibrometry scans, guided diffusion produces in-distribution
representations of OOD experimental LDV scans which are subsequently processed
by the inversion models. This integrated framework provides an end-to-end
solution for automated weld inspection on real data.

</details>


### [161] [Information Shapes Koopman Representation](https://arxiv.org/abs/2510.13025)
*Xiaoyuan Cheng,Wenxuan Yuan,Yiming Yang,Yuanzhao Zhang,Sibo Cheng,Yi He,Zhuo Sun*

Main category: cs.LG

TL;DR: 该论文提出了一种信息论的拉格朗日公式，以平衡库普曼学习中的表示性和简单性，并提供了一个新的算法用于稳定和可解释的库普曼表示。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在解决深度架构中进行有限维子空间选择的挑战，尤其是在使用库普曼算子框架时，这种选择变得尤为困难。作者认为这些困难源于次优的表示学习，导致潜变量在表达性和简单性之间失衡。

Method: 作者提出了一种基于信息论的拉格朗日公式，并开发了一种新算法，显式地平衡表示性和简单性之间的权衡，同时避免潜空间的崩溃，鼓励模式的多样性。

Result: 实验结果表明，该方法能够在各种动态系统中实现比现有的库普曼学习方法更好的性能。

Conclusion: 通过视觉化学习的流形，观察到经验结果与理论预测一致，并在各种动态系统中验证了其方法的有效性。

Abstract: The Koopman operator provides a powerful framework for modeling dynamical
systems and has attracted growing interest from the machine learning community.
However, its infinite-dimensional nature makes identifying suitable
finite-dimensional subspaces challenging, especially for deep architectures. We
argue that these difficulties come from suboptimal representation learning,
where latent variables fail to balance expressivity and simplicity. This
tension is closely related to the information bottleneck (IB) dilemma:
constructing compressed representations that are both compact and predictive.
Rethinking Koopman learning through this lens, we demonstrate that latent
mutual information promotes simplicity, yet an overemphasis on simplicity may
cause latent space to collapse onto a few dominant modes. In contrast,
expressiveness is sustained by the von Neumann entropy, which prevents such
collapse and encourages mode diversity. This insight leads us to propose an
information-theoretic Lagrangian formulation that explicitly balances this
tradeoff. Furthermore, we propose a new algorithm based on the Lagrangian
formulation that encourages both simplicity and expressiveness, leading to a
stable and interpretable Koopman representation. Beyond quantitative
evaluations, we further visualize the learned manifolds under our
representations, observing empirical results consistent with our theoretical
predictions. Finally, we validate our approach across a diverse range of
dynamical systems, demonstrating improved performance over existing Koopman
learning methods. The implementation is publicly available at
https://github.com/Wenxuan52/InformationKoopman.

</details>


### [162] [Bridging Idealized and Operational Models: An Explainable AI Framework for Earth System Emulators](https://arxiv.org/abs/2510.13030)
*Pouria Behnoudfar,Charlotte Moser,Marc Bocquet,Sibo Cheng,Nan Chen*

Main category: cs.LG

TL;DR: 该研究通过结合不同模型的优势，提出了一种解释性AI框架，可以提高地球系统模拟的精度，特别是在极端事件模拟上表现出色，并成功应用于改善CMIP6中的厄尔尼诺模式。


<details>
  <summary>Details</summary>
Motivation: 解决当前高分辨率操作模型在极端事件模拟和统计分布方面的偏差问题，并结合理想化模型的优势进行改进。

Method: 利用潜在数据同化技术，将不同复杂程度的模型结合，形成一种解释性AI框架，通过该框架实现了对地球系统仿真器的改进。

Result: 通过该方法显著纠正了CMIP6模拟中关于厄尔尼诺时空模式的偏差，展示了统计准确的理想化模型的潜力。

Conclusion: 该研究提出了一种解释性AI框架，用于地球系统仿真器，能够通过重构的潜在数据同化技术，结合不同复杂程度的模型优势，实现全球精度改进。

Abstract: Computer models are indispensable tools for understanding the Earth system.
While high-resolution operational models have achieved many successes, they
exhibit persistent biases, particularly in simulating extreme events and
statistical distributions. In contrast, coarse-grained idealized models isolate
fundamental processes and can be precisely calibrated to excel in
characterizing specific dynamical and statistical features. However, different
models remain siloed by disciplinary boundaries. By leveraging the
complementary strengths of models of varying complexity, we develop an
explainable AI framework for Earth system emulators. It bridges the model
hierarchy through a reconfigured latent data assimilation technique, uniquely
suited to exploit the sparse output from the idealized models. The resulting
bridging model inherits the high resolution and comprehensive variables of
operational models while achieving global accuracy enhancements through
targeted improvements from idealized models. Crucially, the mechanism of AI
provides a clear rationale for these advancements, moving beyond black-box
correction to physically insightful understanding in a computationally
efficient framework that enables effective physics-assisted digital twins and
uncertainty quantification. We demonstrate its power by significantly
correcting biases in CMIP6 simulations of El Ni\~no spatiotemporal patterns,
leveraging statistically accurate idealized models. This work also highlights
the importance of pushing idealized model development and advancing
communication between modeling communities.

</details>


### [163] [An Operational Deep Learning System for Satellite-Based High-Resolution Global Nowcasting](https://arxiv.org/abs/2510.13050)
*Shreya Agrawal,Mohammed Alewi Hassen,Emmanuel Asiedu Brempong,Boris Babenko,Fred Zyda,Olivia Graham,Di Li,Samier Merchant,Santiago Hincapie Potes,Tyler Russell,Danny Cheresnick,Aditya Prakash Kakkirala,Stephan Rasp,Avinatan Hassidim,Yossi Matias,Nal Kalchbrenner,Pramod Gupta,Jason Hickey,Aaron Bell*

Main category: cs.LG

TL;DR: Global MetNet is a machine learning model for precipitation nowcasting, offering high-resolution, real-time forecasts. It addresses limitations in traditional methods, outperforming industry standards and improving forecast quality, especially in data-sparse areas, thus aiding vulnerable communities globally.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this research is to address the limitations of traditional NWP methods and existing machine learning-based nowcasting methods, which either suffer from high latency and gaps in accuracy or cannot be extended to the Global South due to sparse radar coverage.

Method: The paper introduces Global MetNet, a global machine learning nowcasting model that utilizes the Global Precipitation Mission's CORRA dataset, geostationary satellite data, and global NWP data to predict precipitation. The model operates at a high spatial (approximately 0.05° or ~5km) and temporal (15 minutes) resolution and generates forecasts in under a minute.

Result: Global MetNet outperforms industry-standard hourly forecasts, achieving higher skill and validated improvements in critical success index and fractions skill score across all precipitation rates and lead times. It is successfully deployed for real-time applications and available to millions of users via Google Search.

Conclusion: Global MetNet represents a significant advancement in global precipitation nowcasting, especially in data-sparse regions like the Global South. It showcases impressive performance metrics and contributes to reducing global disparities in weather forecast quality.

Abstract: Precipitation nowcasting, which predicts rainfall up to a few hours ahead, is
a critical tool for vulnerable communities in the Global South frequently
exposed to intense, rapidly developing storms. Timely forecasts provide a
crucial window to protect lives and livelihoods. Traditional numerical weather
prediction (NWP) methods suffer from high latency, low spatial and temporal
resolution, and significant gaps in accuracy across the world. Recent machine
learning-based nowcasting methods, common in the Global North, cannot be
extended to the Global South due to extremely sparse radar coverage. We present
Global MetNet, an operational global machine learning nowcasting model. It
leverages the Global Precipitation Mission's CORRA dataset, geostationary
satellite data, and global NWP data to predict precipitation for the next 12
hours. The model operates at a high resolution of approximately 0.05{\deg}
(~5km) spatially and 15 minutes temporally. Global MetNet significantly
outperforms industry-standard hourly forecasts and achieves significantly
higher skill, making forecasts useful over a much larger area of the world than
previously available. Our model demonstrates better skill in data-sparse
regions than even the best high-resolution NWP models achieve in the US.
Validated using ground radar and satellite data, it shows significant
improvements across key metrics like the critical success index and fractions
skill score for all precipitation rates and lead times. Crucially, our model
generates forecasts in under a minute, making it readily deployable for
real-time applications. It is already deployed for millions of users on Google
Search. This work represents a key step in reducing global disparities in
forecast quality and integrating sparse, high-resolution satellite observations
into weather forecasting.

</details>


### [164] [Time-Varying Optimization for Streaming Data Via Temporal Weighting](https://arxiv.org/abs/2510.13052)
*Muhammad Faraz Ul Abrar,Nicolò Michelusi,Erik G. Larsson*

Main category: cs.LG

TL;DR: 研究了通过时间变化优化从流数据中学习的问题，提出了一种基于权重的方法，研究了统一权重和折扣权重策略下的跟踪误差。


<details>
  <summary>Details</summary>
Motivation: 大多数现有工作关注通用公式，本研究引入一个结构化的基于权重公式，明确捕捉时间变化目标的流数据来源，推动在动态环境下做出决策。

Method: 采用基于权重的结构化公式，专注于用于流数据的时间变化优化。
并使用两种加权策略进行分析：（1）统一权重（2）折扣权重。
推导了在梯度下降更新下的“跟踪误差”界。

Result: 在统一权重方案下，跟踪误差以\( \mathcal{O}(1/t) \)速率渐近消失；而在折扣权重下，非零误差由折扣因子和梯度更新次数控制，通过数值模拟验证理论结果。

Conclusion: 研究确定了在统一权重下跟踪误差趋于消失，而折扣权重下存在由折扣因子及每个时间步的梯度更新次数控制的非零误差。理论结果通过数值模拟得到验证。

Abstract: Classical optimization theory deals with fixed, time-invariant objective
functions. However, time-varying optimization has emerged as an important
subject for decision-making in dynamic environments. In this work, we study the
problem of learning from streaming data through a time-varying optimization
lens. Unlike prior works that focus on generic formulations, we introduce a
structured, \emph{weight-based} formulation that explicitly captures the
streaming-data origin of the time-varying objective, where at each time step,
an agent aims to minimize a weighted average loss over all the past data
samples. We focus on two specific weighting strategies: (1) uniform weights,
which treat all samples equally, and (2) discounted weights, which
geometrically decay the influence of older data. For both schemes, we derive
tight bounds on the ``tracking error'' (TE), defined as the deviation between
the model parameter and the time-varying optimum at a given time step, under
gradient descent (GD) updates. We show that under uniform weighting, the TE
vanishes asymptotically with a $\mathcal{O}(1/t)$ decay rate, whereas
discounted weighting incurs a nonzero error floor controlled by the discount
factor and the number of gradient updates performed at each time step. Our
theoretical findings are validated through numerical simulations.

</details>


### [165] [Achieving Logarithmic Regret in KL-Regularized Zero-Sum Markov Games](https://arxiv.org/abs/2510.13060)
*Anupam Nayak,Tong Yang,Osman Yagan,Gauri Joshi,Yuejie Chi*

Main category: cs.LG

TL;DR: 本文研究了KL正则化在博弈论中的应用，提出了OMG和SOMG两种算法，在矩阵博弈和马尔可夫博弈中提高了样本效率，实现了更低的遗憾值。


<details>
  <summary>Details</summary>
Motivation: 探讨KL正则化在博弈论环境中的理论优势，尽管在实验上取得了一些成功，但其在博弈论中的理论好处仍不明确。本研究旨在通过正则化提高样本效率。

Method: 研究了两种博弈：二人零和矩阵博弈和马尔可夫博弈。在矩阵博弈中，提出了基于最优响应采样的OMG算法，并将这一思路扩展到马尔可夫博弈中，提出了使用超乐观奖励的SOMG算法。

Result: 提出的算法在样本效率上有显著提升，即使在没有正则化的情况下，两种算法都实现了标准的$\widetilde{\mathcal{O}}(\sqrt{T})$的遗憾值，在引入逆向KL散度正则化后，实现了对$\beta$的倒数缩放的对数遗憾值。

Conclusion: 本文提出了两种算法，即OMG和SOMG，分别用于矩阵博弈和马尔可夫博弈。在这两种博弈中，这些算法通过引入正则化措施，尤其是逆向KL散度正则化，有效改善了样本效率。

Abstract: Reverse Kullback-Leibler (KL) divergence-based regularization with respect to
a fixed reference policy is widely used in modern reinforcement learning to
preserve the desired traits of the reference policy and sometimes to promote
exploration (using uniform reference policy, known as entropy regularization).
Beyond serving as a mere anchor, the reference policy can also be interpreted
as encoding prior knowledge about good actions in the environment. In the
context of alignment, recent game-theoretic approaches have leveraged KL
regularization with pretrained language models as reference policies, achieving
notable empirical success in self-play methods. Despite these advances, the
theoretical benefits of KL regularization in game-theoretic settings remain
poorly understood. In this work, we develop and analyze algorithms that
provably achieve improved sample efficiency under KL regularization. We study
both two-player zero-sum Matrix games and Markov games: for Matrix games, we
propose OMG, an algorithm based on best response sampling with optimistic
bonuses, and extend this idea to Markov games through the algorithm SOMG, which
also uses best response sampling and a novel concept of superoptimistic
bonuses. Both algorithms achieve a logarithmic regret in $T$ that scales
inversely with the KL regularization strength $\beta$ in addition to the
standard $\widetilde{\mathcal{O}}(\sqrt{T})$ regret independent of $\beta$
which is attained in both regularized and unregularized settings

</details>


### [166] [Absolute indices for determining compactness, separability and number of clusters](https://arxiv.org/abs/2510.13065)
*Adil M. Bagirov,Ramiz M. Aliguliyev,Nargiz Sultanova,Sona Taheri*

Main category: cs.LG

TL;DR: 本文引入了新的绝对聚类索引，用于确定聚类的紧凑性和可分离性，并在数据集上证明了其优于其他有效性指数的表现。


<details>
  <summary>Details</summary>
Motivation: 在数据集中找到“真实”聚类是一个具有挑战性的问题。现有的聚类模型和算法可能无法提供紧凑且分离良好的聚类，也无法确定聚类的最佳数量。通常使用聚类有效性指数来识别此类聚类，但这些指数通常是相对的，其成功与否依赖于底层数据结构。

Method: 本文提出了一种新的绝对聚类索引方法，用于确定聚类的紧凑性和可分离性。我们为每个聚类定义了紧凑性函数，并为聚类对定义了一组邻近点。这个函数用于确定每个聚类及整个聚类分布的紧凑性，而邻近点集被用来定义聚类之间的边界以及总体分布边界。

Result: 我们在多个合成和真实数据集上展示了新索引的表现，并将其与其他广泛使用的聚类有效性指数进行了比较。

Conclusion: 提出的紧凑性和可分离性指数能够有效地识别真实的聚类数量，提高了聚类结果的准确性。

Abstract: Finding "true" clusters in a data set is a challenging problem. Clustering
solutions obtained using different models and algorithms do not necessarily
provide compact and well-separated clusters or the optimal number of clusters.
Cluster validity indices are commonly applied to identify such clusters.
Nevertheless, these indices are typically relative, and they are used to
compare clustering algorithms or choose the parameters of a clustering
algorithm. Moreover, the success of these indices depends on the underlying
data structure. This paper introduces novel absolute cluster indices to
determine both the compactness and separability of clusters. We define a
compactness function for each cluster and a set of neighboring points for
cluster pairs. This function is utilized to determine the compactness of each
cluster and the whole cluster distribution. The set of neighboring points is
used to define the margin between clusters and the overall distribution margin.
The proposed compactness and separability indices are applied to identify the
true number of clusters. Using a number of synthetic and real-world data sets,
we demonstrate the performance of these new indices and compare them with other
widely-used cluster validity indices.

</details>


### [167] [Transformer-based Scalable Beamforming Optimization via Deep Residual Learning](https://arxiv.org/abs/2510.13077)
*Yubo Zhang,Xiao-Yang Liu,Xiaodong Wang*

Main category: cs.LG

TL;DR: 本文提出了一种用于大规模MU-MISO信道的无监督深度学习下行波束成形框架，通过多层Transformer和多种训练策略，实现了更优的性能和更快的推理速度。


<details>
  <summary>Details</summary>
Motivation: 其目的是为了解决大规模MU-MISO信道中的下行波束成形问题，通过一种更高效、更快速的推理方法提升通信性能。

Method: 该方法采用了无监督深度学习框架，利用离线训练的模型在动态通信环境中实现实时推理。模型遵循学习优化（L2O）的范式，使用多层Transformer通过残差连接迭代优化信道和波束成形器特征。此外，引入了三种策略来增强训练效果：课程学习（CL）、半自适应学习以及滑动窗口训练。

Result: 仿真结果表明，该方案在低到中等SNR时优于现有基线，并且在高SNR时性能接近WMMSE，同时推理速度快于传统的迭代和在线学习方法。

Conclusion: 提出的无监督深度学习框架在大规模MU-MISO信道下行波束成形中表现优异，尤其在低到中等SNR下效果优于现有基线，在高SNR下接近WMMSE性能，并且推理速度明显快于迭代和在线学习方法。

Abstract: We develop an unsupervised deep learning framework for downlink beamforming
in large-scale MU-MISO channels. The model is trained offline, allowing
real-time inference through lightweight feedforward computations in dynamic
communication environments. Following the learning-to-optimize (L2O) paradigm,
a multi-layer Transformer iteratively refines both channel and beamformer
features via residual connections. To enhance training, three strategies are
introduced: (i) curriculum learning (CL) to improve early-stage convergence and
avoid local optima, (ii) semi-amortized learning to refine each Transformer
block with a few gradient ascent steps, and (iii) sliding-window training to
stabilize optimization by training only a subset of Transformer blocks at a
time. Extensive simulations show that the proposed scheme outperforms existing
baselines at low-to-medium SNRs and closely approaches WMMSE performance at
high SNRs, while achieving substantially faster inference than iterative and
online learning approaches.

</details>


### [168] [DeepCausalMMM: A Deep Learning Framework for Marketing Mix Modeling with Causal Inference](https://arxiv.org/abs/2510.13087)
*Aditya Puttaparthi Tirumala*

Main category: cs.LG

TL;DR: DeepCausalMMM使用最新机器学习技术解决传统营销模型的局限，能够自动学习时间模式和因果结构，并提供交互式商业洞察。


<details>
  <summary>Details</summary>
Motivation: 传统的市场营销组合模型方法通常依赖线性回归或贝叶斯分层模型，假设市场渠道之间独立，难以捕捉复杂的时间动态和非线性饱和效应。

Method: 使用Gated Recurrent Units (GRUs)自动学习时间模式，如广告效果和延迟，同时通过有向无环图 (DAG) 学习统计依赖和潜在因果结构。并实施基于Hill方程的饱和曲线以模拟收益递减和优化预算分配。

Result: DeepCausalMMM以数据驱动的设计，结合深度学习、因果推断和先进的市场科学，自动从数据学习或估算超参数和转换，支持多区域建模并提供14+ 个互动仪表板以获取业务洞察。

Conclusion: DeepCausalMMM通过结合多种创新技术，改进了市场营销活动效果评估，适应多区域参数，提供深刻的商业见解。

Abstract: Marketing Mix Modeling (MMM) is a statistical technique used to estimate the
impact of marketing activities on business outcomes such as sales, revenue, or
customer visits. Traditional MMM approaches often rely on linear regression or
Bayesian hierarchical models that assume independence between marketing
channels and struggle to capture complex temporal dynamics and non-linear
saturation effects [@Hanssens2005; @Ng2021Bayesian].
  DeepCausalMMM is a Python package that addresses these limitations by
combining deep learning, causal inference, and advanced marketing science. The
package uses Gated Recurrent Units (GRUs) to automatically learn temporal
patterns such as adstock (carryover effects) and lag, while simultaneously
learning statistical dependencies and potential causal structures between
marketing channels through Directed Acyclic Graph (DAG) learning
[@Zheng2018NOTEARS; @Gong2024CausalMMM]. Additionally, it implements Hill
equation-based saturation curves to model diminishing returns and optimize
budget allocation.
  Key innovations include: (1) a data-driven design where hyperparameters and
transformations (e.g., adstock decay, saturation curves) are learned or
estimated from data with sensible defaults, rather than requiring fixed
heuristics or manual specification, (2) multi-region modeling with both shared
and region-specific parameters, (3) robust statistical methods including Huber
loss and advanced regularization, (4) comprehensive response curve analysis for
understanding channel saturation, and (5) an extensive visualization suite with
14+ interactive dashboards for business insights.

</details>


### [169] [On the Reasoning Abilities of Masked Diffusion Language Models](https://arxiv.org/abs/2510.13117)
*Anej Svete,Ashish Sabharwal*

Main category: cs.LG

TL;DR: The paper analyzes Masked Diffusion Models' (MDMs) computational capabilities compared to CoT and PLTs, finding them efficient and equivalent in certain aspects, with advantages in parallel reasoning.


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore and understand the computational capabilities and limits of Masked Diffusion Models (MDMs) in comparison to traditional autoregressive models and other reasoning frameworks, especially in terms of parallel generation.

Method: The study involves a theoretical exploration of the computational capabilities of Masked Diffusion Models (MDMs) by connecting them to Chain of Thought (CoT) and Padded Looped Transformers (PLTs) frameworks in a finite-precision log-width setting. It demonstrates equivalency between MDMs and polynomially-padded PLTs, and analyzes MDMs' efficiency compared to CoT-augmented transformers.

Result: The study finds that MDMs are theoretically equivalent to polynomially-padded PLTs and can solve the same problems as CoT-augmented transformers. They are shown to be more efficient for certain problem classes, such as regular languages, due to their ability to generate in parallel.

Conclusion: Masked diffusion models (MDMs) for text are a viable alternative to autoregressive language models, with certain computational and efficiency advantages.

Abstract: Masked diffusion models (MDMs) for text offer a compelling alternative to
traditional autoregressive language models. Parallel generation makes them
efficient, but their computational capabilities and the limitations inherent to
their parallelism remain largely unexplored. To this end, we characterize what
types of reasoning problems MDMs can provably solve and how efficiently. We do
this by connecting MDMs to the well-understood reasoning frameworks of chain of
thought (CoT) and padded looped transformers (PLTs) in the finite-precision
log-width setting: We show that MDMs and polynomially-padded PLTs are, in fact,
equivalent in this setting, and that MDMs can solve all problems that
CoT-augmented transformers can. Moreover, we showcase classes of problems
(including regular languages) for which MDMs are inherently more efficient than
CoT transformers, where parallel generation allows for substantially faster
reasoning.

</details>


### [170] [Cluster-Based Client Selection for Dependent Multi-Task Federated Learning in Edge Computing](https://arxiv.org/abs/2510.13132)
*Jieping Luo,Qiyue Li,Zhizhang Liu,Hang Qi,Jiaying Yin,Jingjin Wu*

Main category: cs.LG

TL;DR: 提出了一个集群导向和依赖感知的框架CoDa-FL，旨在通过集群式客户端选择和任务分配减少总所需时间，并使用地球移动者距离进行客户端集群，以提高通信效率和降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 在移动边缘计算环境下研究联邦学习中的客户端选择问题，特别是在依赖的多任务设置下，以减少完成各种学习任务所需的总时间。

Method: 提出了CoDa-FL框架进行集群式客户端选择和依赖任务分配，利用地球移动者距离进行客户端集群，并采用有向无环图的任务调度机制来管理任务依赖性。

Result: 通过数值实验验证，CoDa-FL在异构MEC设置下表现优于现有基准，达到更快的收敛速度、较低的通信和计算成本以及更高的学习准确率。

Conclusion: 通过集群和依赖关系的识别和利用，CoDa-FL框架能够有效减少联邦学习中任务完成所需的总时间，并提高学习任务的效率。

Abstract: We study the client selection problem in Federated Learning (FL) within
mobile edge computing (MEC) environments, particularly under the dependent
multi-task settings, to reduce the total time required to complete various
learning tasks. We propose CoDa-FL, a Cluster-oriented and Dependency-aware
framework designed to reduce the total required time via cluster-based client
selection and dependent task assignment. Our approach considers Earth Mover's
Distance (EMD) for client clustering based on their local data distributions to
lower computational cost and improve communication efficiency. We derive a
direct and explicit relationship between intra-cluster EMD and the number of
training rounds required for convergence, thereby simplifying the otherwise
complex process of obtaining the optimal solution. Additionally, we incorporate
a directed acyclic graph-based task scheduling mechanism to effectively manage
task dependencies. Through numerical experiments, we validate that our proposed
CoDa-FL outperforms existing benchmarks by achieving faster convergence, lower
communication and computational costs, and higher learning accuracy under
heterogeneous MEC settings.

</details>


### [171] [Convergence, design and training of continuous-time dropout as a random batch method](https://arxiv.org/abs/2510.13134)
*Antonio Álvarez-López,Martín Hernández*

Main category: cs.LG

TL;DR: 该研究通过随机批方法研究了连续时间模型中的dropout正则化，建立了无偏估计器并证明稳定性，提供了成本与准确性间的权衡。


<details>
  <summary>Details</summary>
Motivation: 降低交互粒子系统的计算成本，同时在在连续时间模型中进行有效的dropout正则化。

Method: 通过随机批方法研究连续时间模型中的dropout正则化，通过时间间隔h重新采样神经元批次，构造无偏、适定的估计器来模拟dropout。

Result: 在轨迹层面上，以线性速度在h中为期望均匀误差建立收敛性；在分布层面上，建立了相关连续性方程的稳定性，具有总变化误差阶为h^{1/2}。

Conclusion: dropout正则化在连续时间模型中是可行且有效的，尤其是在对单层神经ODE进行分类和流动匹配中验证了理论预测的速率、正则化效果以及较好的运行时和内存表现。

Abstract: We study dropout regularization in continuous-time models through the lens of
random-batch methods -- a family of stochastic sampling schemes originally
devised to reduce the computational cost of interacting particle systems. We
construct an unbiased, well-posed estimator that mimics dropout by sampling
neuron batches over time intervals of length $h$. Trajectory-wise convergence
is established with linear rate in $h$ for the expected uniform error. At the
distribution level, we establish stability for the associated continuity
equation, with total-variation error of order $h^{1/2}$ under mild moment
assumptions. During training with fixed batch sampling across epochs, a
Pontryagin-based adjoint analysis bounds deviations in the optimal cost and
control, as well as in gradient-descent iterates. On the design side, we
compare convergence rates for canonical batch sampling schemes, recover
standard Bernoulli dropout as a special case, and derive a cost--accuracy
trade-off yielding a closed-form optimal $h$. We then specialize to a
single-layer neural ODE and validate the theory on classification and flow
matching, observing the predicted rates, regularization effects, and favorable
runtime and memory profiles.

</details>


### [172] [Behavioral Embeddings of Programs: A Quasi-Dynamic Approach for Optimization Prediction](https://arxiv.org/abs/2510.13158)
*Haolin Pan,Jinyuan Dong,Hongbin Zhang,Hongyu Lin,Mingjie Xing,Yanjun Wu*

Main category: cs.LG

TL;DR: 本文提出了一种新的准动态程序表示方法，在编译器优化任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有静态表示和动态表示在程序表现和效率上的权衡问题。

Method: 提出了一种新的准动态框架用于程序表示，包括引入程序行为谱以及使用产品量化和多任务Transformer模型PQ-BERT。

Result: 在两个代表性的编译器优化任务上，表现优于最先进的静态基线。

Conclusion: 采用这种新方法的程序表现优于现有静态基线。

Abstract: Learning effective numerical representations, or embeddings, of programs is a
fundamental prerequisite for applying machine learning to automate and enhance
compiler optimization. Prevailing paradigms, however, present a dilemma. Static
representations, derived from source code or intermediate representation (IR),
are efficient and deterministic but offer limited insight into how a program
will behave or evolve under complex code transformations. Conversely, dynamic
representations, which rely on runtime profiling, provide profound insights
into performance bottlenecks but are often impractical for large-scale tasks
due to prohibitive overhead and inherent non-determinism. This paper transcends
this trade-off by proposing a novel quasi-dynamic framework for program
representation. The core insight is to model a program's optimization
sensitivity. We introduce the Program Behavior Spectrum, a new representation
generated by probing a program's IR with a diverse set of optimization
sequences and quantifying the resulting changes in its static features. To
effectively encode this high-dimensional, continuous spectrum, we pioneer a
compositional learning approach. Product Quantization is employed to discretize
the continuous reaction vectors into structured, compositional sub-words.
Subsequently, a multi-task Transformer model, termed PQ-BERT, is pre-trained to
learn the deep contextual grammar of these behavioral codes. Comprehensive
experiments on two representative compiler optimization tasks -- Best Pass
Prediction and -Oz Benefit Prediction -- demonstrate that our method
outperforms state-of-the-art static baselines. Our code is publicly available
at https://github.com/Panhaolin2001/PREP/.

</details>


### [173] [Information-Theoretic Criteria for Knowledge Distillation in Multimodal Learning](https://arxiv.org/abs/2510.13182)
*Rongrong Xie,Yizhou Xu,Guido Sanguinetti*

Main category: cs.LG

TL;DR: 提出跨模态互补性假设，为跨模态知识蒸馏建立理论框架。


<details>
  <summary>Details</summary>
Motivation: 研究跨模态知识蒸馏（KD）技术，以改善弱势模态的性能。尽管在多个应用中取得成功，但理论理解的不足限制了KD的效果。

Method: 在联合高斯模型中进行理论验证，并通过多种模态数据集进行实证验证。

Result: 提出跨模态互补性假设（CCH），并且在联合高斯模型中验证，以及在多种数据集上进行验证。

Conclusion: 研究成果为理解跨模态知识蒸馏提供了新的理论框架，并提供了实际指导原则以选择优化的教师模态。

Abstract: The rapid increase in multimodal data availability has sparked significant
interest in cross-modal knowledge distillation (KD) techniques, where richer
"teacher" modalities transfer information to weaker "student" modalities during
model training to improve performance. However, despite successes across
various applications, cross-modal KD does not always result in improved
outcomes, primarily due to a limited theoretical understanding that could
inform practice. To address this gap, we introduce the Cross-modal
Complementarity Hypothesis (CCH): we propose that cross-modal KD is effective
when the mutual information between teacher and student representations exceeds
the mutual information between the student representation and the labels. We
theoretically validate the CCH in a joint Gaussian model and further confirm it
empirically across diverse multimodal datasets, including image, text, video,
audio, and cancer-related omics data. Our study establishes a novel theoretical
framework for understanding cross-modal KD and offers practical guidelines
based on the CCH criterion to select optimal teacher modalities for improving
the performance of weaker modalities.

</details>


### [174] [Performance Evaluation of Ising and QUBO Variable Encodings in Boltzmann Machine Learning](https://arxiv.org/abs/2510.13210)
*Yasushi Hasegawa,Masayuki Ohzeki*

Main category: cs.LG

TL;DR: 研究了Ising和QUBO编码在Boltzmann机学习中的表现，发现Ising编码在SGD下收敛更快，而QUBO编码需要NGD预处理以缓解曲率问题。


<details>
  <summary>Details</summary>
Motivation: 为了解不同编码对Boltzmann机学习的影响，并提供关于变量编码和预处理的指导。

Method: 在一个固定模型、采样器和步长的控制协议下进行对比，将FIM等于充分统计量的协方差的性质用于可视化经验矩，并揭示不同编码下的系统差异。

Result: 结果表明，QUBO编码在FIM中引入了更大的跨项和更小的特征值方向，使得频谱熵降低，导致SGD下收敛速度变慢。而NGD由于重参数不变性，在不同编码下取得了相似的收敛速度。

Conclusion: 在Boltzmann机学习中，Ising编码比QUBO编码在SGD训练下更具优势，因为它提供了更均匀的曲率和更快的收敛速度。对于QUBO编码，可以通过居中/缩放或NGD风格的预处理来缓解曲率问题。

Abstract: We compare Ising ({-1,+1}) and QUBO ({0,1}) encodings for Boltzmann machine
learning under a controlled protocol that fixes the model, sampler, and step
size. Exploiting the identity that the Fisher information matrix (FIM) equals
the covariance of sufficient statistics, we visualize empirical moments from
model samples and reveal systematic, representation-dependent differences. QUBO
induces larger cross terms between first- and second-order statistics, creating
more small-eigenvalue directions in the FIM and lowering spectral entropy. This
ill-conditioning explains slower convergence under stochastic gradient descent
(SGD). In contrast, natural gradient descent (NGD)-which rescales updates by
the FIM metric-achieves similar convergence across encodings due to
reparameterization invariance. Practically, for SGD-based training, the Ising
encoding provides more isotropic curvature and faster convergence; for QUBO,
centering/scaling or NGD-style preconditioning mitigates curvature pathologies.
These results clarify how representation shapes information geometry and
finite-time learning dynamics in Boltzmann machines and yield actionable
guidelines for variable encoding and preprocessing.

</details>


### [175] [Towards Understanding Valuable Preference Data for Large Language Model Alignment](https://arxiv.org/abs/2510.13212)
*Zizhuo Zhang,Qizhou Wang,Shanshan Ye,Jianing Zhu,Jiangchao Yao,Bo Han,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 本研究提出了一种新的截断影响函数（TIF），用于评估偏好数据质量，并发现数据质量是模型本身的属性。研究也提出了一些计算简单但与TIF正相关的候选评分函数（SFs），用于改进偏好数据选择。实验证明，通过更精确地选择偏好数据，可以在使用更少数据的情况下实现更好的模型对齐性能。


<details>
  <summary>Details</summary>
Motivation: 由于偏好数据质量对大型语言模型对齐的成功至关重要，且现有方法在选择偏好数据时不够精确，因此本研究旨在改进偏好数据选择方法以适应不同的模型，提升对齐性能。

Method: 研究通过引入截断影响函数（TIF）来评估数据质量，并通过构建候选评分函数（SFs），结合多种误差来源来实现更精确的数据选择。

Result: 通过多样化的对齐基准和不同的LLM家族进行实验，结果表明使用更精确的数据选择方法可以在使用更少数据的情况下达到更好的对齐性能。

Conclusion: 本研究证明，改进偏好数据选择方法是必要的，因为数据质量是模型所固有的特性。提出的评分函数可以提高选择的精确度，实现更好的对齐性能。

Abstract: Large language model (LLM) alignment is typically achieved through learning
from human preference comparisons, making the quality of preference data
critical to its success. Existing studies often pre-process raw training
datasets to identify valuable preference pairs using external reward models or
off-the-shelf LLMs, achieving improved overall performance but rarely examining
whether individual, selected data point is genuinely beneficial. We assess data
quality through individual influence on validation data using our newly
proposed truncated influence function (TIF), which mitigates the over-scoring
present in traditional measures and reveals that preference data quality is
inherently a property of the model. In other words, a data pair that benefits
one model may harm another. This leaves the need to improve the preference data
selection approaches to be adapting to specific models. To this end, we
introduce two candidate scoring functions (SFs) that are computationally
simpler than TIF and positively correlated with it. They are also model
dependent and can serve as potential indicators of individual data quality for
preference data selection. Furthermore, we observe that these SFs inherently
exhibit errors when compared to TIF. To this end, we combine them to offset
their diverse error sources, resulting in a simple yet effective data selection
rule that enables the models to achieve a more precise selection of valuable
preference data. We conduct experiments across diverse alignment benchmarks and
various LLM families, with results demonstrating that better alignment
performance can be achieved using less data, showing the generality of our
findings and new methods.

</details>


### [176] [BlendFL: Blended Federated Learning for Handling Multimodal Data Heterogeneity](https://arxiv.org/abs/2510.13266)
*Alejandro Guerra-Manzanares,Omar El-Herraoui,Michail Maniatakos,Farah E. Shamout*

Main category: cs.LG

TL;DR: BlendFL is a new federated learning framework designed to handle heterogeneous multimodal data, showing improved performance and faster convergence in client-diverse real-world settings, validated with medical and standard benchmarks.


<details>
  <summary>Details</summary>
Motivation: Address the challenge of multimodal data heterogeneity in federated learning, where traditional frameworks struggle due to asymmetric client data distributions in real-world settings.

Method: The paper proposes the BlendFL framework that combines horizontal and vertical federated learning (FL) methods, featuring a decentralized inference mechanism and BlendAvg, an adaptive global model aggregation strategy. It was tested on real-world multimodal datasets for classification tasks.

Result: BlendFL demonstrates superior performance in both multimodal and unimodal classification tasks and shows faster convergence in collaborative learning compared to existing approaches. It was validated on a large-scale medical dataset and a multimodal benchmark.

Conclusion: BlendFL framework effectively handles multimodal data heterogeneity in collaborative machine learning settings, offering significant improvements in model performance and convergence speed compared to traditional methods, especially in privacy-sensitive fields like healthcare and finance.

Abstract: One of the key challenges of collaborative machine learning, without data
sharing, is multimodal data heterogeneity in real-world settings. While
Federated Learning (FL) enables model training across multiple clients,
existing frameworks, such as horizontal and vertical FL, are only effective in
`ideal' settings that meet specific assumptions. Hence, they struggle to
address scenarios where neither all modalities nor all samples are represented
across the participating clients. To address this gap, we propose BlendFL, a
novel FL framework that seamlessly blends the principles of horizontal and
vertical FL in a synchronized and non-restrictive fashion despite the asymmetry
across clients. Specifically, any client within BlendFL can benefit from either
of the approaches, or both simultaneously, according to its available dataset.
In addition, BlendFL features a decentralized inference mechanism, empowering
clients to run collaboratively trained local models using available local data,
thereby reducing latency and reliance on central servers for inference. We also
introduce BlendAvg, an adaptive global model aggregation strategy that
prioritizes collaborative model updates based on each client's performance. We
trained and evaluated BlendFL and other state-of-the-art baselines on three
classification tasks using a large-scale real-world multimodal medical dataset
and a popular multimodal benchmark. Our results highlight BlendFL's superior
performance for both multimodal and unimodal classification. Ablation studies
demonstrate BlendFL's faster convergence compared to traditional approaches,
accelerating collaborative learning. Overall, in our study we highlight the
potential of BlendFL for handling multimodal data heterogeneity for
collaborative learning in real-world settings where data privacy is crucial,
such as in healthcare and finance.

</details>


### [177] [To Steer or Not to Steer? Mechanistic Error Reduction with Abstention for Language Models](https://arxiv.org/abs/2510.13290)
*Anna Hedström,Salim I. Amoukou,Tom Bewley,Saumitra Mishra,Manuela Veloso*

Main category: cs.LG

TL;DR: MERA是一个框架，通过优化干预方向和校准何时及程度来进行引导，以改进语言模型的错误处理性能，并在实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了改进语言模型在错误发生时的处理能力，现有方法通常通过固定或手动调整的引导强度进行修正，这容易导致过度引导和不足引导的问题。

Method: MERA通过优化干预方向和校准干预时机及力度，以选择性和自适应方式对语言模型进行干预，以减少错误。

Result: MERA展示了在各种数据集和语言模型家族中安全、有效、无退化的错误修正性能，并且在性能上优于现有基准。

Conclusion: MERA不仅在理论上证明了性能改进，而且可以在现有引导技巧的基础上应用以增强其表现，成为一种通用且高效的机制激活引导方法。

Abstract: We introduce Mechanistic Error Reduction with Abstention (MERA), a principled
framework for steering language models (LMs) to mitigate errors through
selective, adaptive interventions. Unlike existing methods that rely on fixed,
manually tuned steering strengths, often resulting in under or oversteering,
MERA addresses these limitations by (i) optimising the intervention direction,
and (ii) calibrating when, and how much to steer, thereby provably improving
performance or abstaining when no confident correction is possible. Experiments
across diverse datasets, and LM families demonstrate safe, effective,
non-degrading error correction, and that MERA outperforms existing baselines.
Moreover, MERA can be applied on top of existing steering techniques to further
enhance their performance, establishing it as a general-purpose, and efficient
approach to mechanistic activation steering.

</details>


### [178] [Federated Conditional Conformal Prediction via Generative Models](https://arxiv.org/abs/2510.13297)
*Rui Xu,Sihong Xie*

Main category: cs.LG

TL;DR: Fed-CCP通过生成模型在联邦学习中实现条件覆盖，以适应本地数据异质性，并确保预测的可靠性。


<details>
  <summary>Details</summary>
Motivation: 高风险的联邦学习场景，例如多中心医疗中，需要可靠的不确定性量化，以确保真实标签的覆盖。

Method: 提出了通过生成模型（如归一化流或扩散模型）来近似条件数据分布的联邦条件保序预测（Fed-CCP），使每个客户端能够本地校准其独特的不确定性分数，同时通过联邦聚合保持全局一致性。

Result: 实验证明，Fed-CCP能实现更具适应性的预测集。

Conclusion: Fed-CCP通过生成模型实现条件覆盖，能够在高异质性的客户端分布中提供更可靠的预测。

Abstract: Conformal Prediction (CP) provides distribution-free uncertainty
quantification by constructing prediction sets that guarantee coverage of the
true labels. This reliability makes CP valuable for high-stakes federated
learning scenarios such as multi-center healthcare. However, standard CP
assumes i.i.d. data, which is violated in federated settings where client
distributions differ substantially. Existing federated CP methods address this
by maintaining marginal coverage on each client, but such guarantees often fail
to reflect input-conditional uncertainty. In this work, we propose Federated
Conditional Conformal Prediction (Fed-CCP) via generative models, which aims
for conditional coverage that adapts to local data heterogeneity. Fed-CCP
leverages generative models, such as normalizing flows or diffusion models, to
approximate conditional data distributions without requiring the sharing of raw
data. This enables each client to locally calibrate conformal scores that
reflect its unique uncertainty, while preserving global consistency through
federated aggregation. Experiments on real datasets demonstrate that Fed-CCP
achieves more adaptive prediction sets.

</details>


### [179] [Km-scale dynamical downscaling through conformalized latent diffusion models](https://arxiv.org/abs/2510.13301)
*Alessandro Brusaferri,Andrea Ballarino*

Main category: cs.LG

TL;DR: 研究提出了一种结合生成扩散模型与相适应预测框架的方法，提高气象数据下采样的可靠性与稳定性。


<details>
  <summary>Details</summary>
Motivation: 生成扩散模型在高分辨率气象数据下采样时未能保证有限样本样本估计的置信度，导致不可信的概率估计。本研究旨在解决这一问题，提高模型在实际操作中的可靠性。

Method: 研究通过将生成扩散模型生成的样本进行后处理，导出条件分位数估计，并将其纳入到相适应分位回归程序中，从而提高预测的有限样本效度。方法用ERA5重分析数据评估，将数据下采样到2公里网格水平进行实验。

Result: 研究提出了一种将生成扩散模型与相适应预测框架相结合的方法，用于提高高分辨率气象数据的可靠性。通过在生成扩散模型的预测基础上，引入相适应分位回归程序，可以确保有限样本边际有效性，从而显著提高预测区间估计的覆盖性与稳定性。研究结果表明，与传统生成扩散模型相比，该方法在网格点级别上提供了更为可靠的概率性分布估计。

Conclusion: 研究结论是，将生成扩散模型与相适应预测框架结合，可提升高分辨率气象字段预测的可信度与稳定性。

Abstract: Dynamical downscaling is crucial for deriving high-resolution meteorological
fields from coarse-scale simulations, enabling detailed analysis for critical
applications such as weather forecasting and renewable energy modeling.
Generative Diffusion models (DMs) have recently emerged as powerful data-driven
tools for this task, offering reconstruction fidelity and more scalable
sampling supporting uncertainty quantification. However, DMs lack finite-sample
guarantees against overconfident predictions, resulting in miscalibrated
grid-point-level uncertainty estimates hindering their reliability in
operational contexts. In this work, we tackle this issue by augmenting the
downscaling pipeline with a conformal prediction framework. Specifically, the
DM's samples are post-processed to derive conditional quantile estimates,
incorporated into a conformalized quantile regression procedure targeting
locally adaptive prediction intervals with finite-sample marginal validity. The
proposed approach is evaluated on ERA5 reanalysis data over Italy, downscaled
to a 2-km grid. Results demonstrate grid-point-level uncertainty estimates with
markedly improved coverage and stable probabilistic scores relative to the DM
baseline, highlighting the potential of conformalized generative models for
more trustworthy probabilistic downscaling to high-resolution meteorological
fields.

</details>


### [180] [Isolation-based Spherical Ensemble Representations for Anomaly Detection](https://arxiv.org/abs/2510.13311)
*Yang Cao,Sikun Yang,Hao Tian,Kai He,Lianyong Qi,Ming Liu,Yujiu Yang*

Main category: cs.LG

TL;DR: 本文提出了一种新的无监督异常检测方法ISER，通过使用超球半径来表示局部密度特征，并保持线性时间和常数空间复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有无监督异常检测方法存在冲突的分布假设、计算效率低下和难以处理不同异常类型等问题，本文旨在通过新的方法来解决这些问题。

Method: ISER扩展现有的孤立方法，通过使用超球半径编码密度信息，并采用一种新的基于相似性的评分方法来比较异常参考模式。

Result: 实验结果表明，ISER在异常检测任务中表现优异，超越了多种基线方法。

Conclusion: ISER在22个真实数据集上的表现优于11种基线方法，证明了其在异常检测任务中的有效性。

Abstract: Anomaly detection is a critical task in data mining and management with
applications spanning fraud detection, network security, and log monitoring.
Despite extensive research, existing unsupervised anomaly detection methods
still face fundamental challenges including conflicting distributional
assumptions, computational inefficiency, and difficulty handling different
anomaly types. To address these problems, we propose ISER (Isolation-based
Spherical Ensemble Representations) that extends existing isolation-based
methods by using hypersphere radii as proxies for local density characteristics
while maintaining linear time and constant space complexity. ISER constructs
ensemble representations where hypersphere radii encode density information:
smaller radii indicate dense regions while larger radii correspond to sparse
areas. We introduce a novel similarity-based scoring method that measures
pattern consistency by comparing ensemble representations against a theoretical
anomaly reference pattern. Additionally, we enhance the performance of
Isolation Forest by using ISER and adapting the scoring function to address
axis-parallel bias and local anomaly detection limitations. Comprehensive
experiments on 22 real-world datasets demonstrate ISER's superior performance
over 11 baseline methods.

</details>


### [181] [Thompson Sampling via Fine-Tuning of LLMs](https://arxiv.org/abs/2510.13328)
*Nicolas Menet,Aleksandar Terzić,Andreas Krause,Abbas Rahimi*

Main category: cs.LG

TL;DR: 提出了一种基于Thompson采样的可扩展算法，无需最大化采集函数，通过直接参数化候选者最大化奖励的概率来优化大规模无结构离散空间的贝叶斯优化。


<details>
  <summary>Details</summary>
Motivation: 解决贝叶斯优化中采集函数最大化计算代价问题，提供一种有效处理大规模无结构离散空间的替代方案。

Method: 提出Thompson采样通过微调（ToSFiT），使用提示条件大语言模型的先验知识，并逐步适配到后验概率，理论上推导变分Thompson采样的新遗憾界。

Result: 在线微调显著提高了样本效率，对计算效率影响微忽，可以在FAQ回应精细化、热稳定蛋白质搜索和量子电路设计等任务中有效验证。

Conclusion: 通过理论推导和实证验证，该算法在样本效率上具有显著优势，且对计算效率影响微弱，可在多种任务中有效应用。

Abstract: Bayesian optimization in large unstructured discrete spaces is often hindered
by the computational cost of maximizing acquisition functions due to the
absence of gradients. We propose a scalable alternative based on Thompson
sampling that eliminates the need for acquisition function maximization by
directly parameterizing the probability that a candidate yields the maximum
reward. Our approach, Thompson Sampling via Fine-Tuning (ToSFiT) leverages the
prior knowledge embedded in prompt-conditioned large language models, and
incrementally adapts them toward the posterior. Theoretically, we derive a
novel regret bound for a variational formulation of Thompson Sampling that
matches the strong guarantees of its standard counterpart. Our analysis reveals
the critical role of careful adaptation to the posterior probability of
maximality--a principle that underpins our ToSFiT algorithm. Empirically, we
validate our method on three diverse tasks: FAQ response refinement, thermally
stable protein search, and quantum circuit design. We demonstrate that online
fine-tuning significantly improves sample efficiency, with negligible impact on
computational efficiency.

</details>


### [182] [Kernel Representation and Similarity Measure for Incomplete Data](https://arxiv.org/abs/2510.13352)
*Yang Cao,Sikun Yang,Kai He,Wenjun Ma,Ming Liu,Yujiu Yang,Jian Weng*

Main category: cs.LG

TL;DR: 提出了一种新的相似度度量方法邻近核，通过不用显式补全缺失数据直接度量不完整数据间的相似性，并在聚类任务中展现出色表现，且代码已开源。


<details>
  <summary>Details</summary>
Motivation: 在Web挖掘、推荐系统和用户行为分析中，不完整数据的相似性测量是一项基本挑战。传统的方法要么丢弃不完整数据，要么进行预处理插补，导致信息丢失和相似性估计偏差。因此，本文提出了一种新的相似度度量方法来解决这些问题。

Method: 该方法提出了一种邻近核的相似度度量, 通过数据依赖的分箱和邻近分配, 将数据投影到适应局部密度变化的高维稀疏表示中。同时, 为了处理缺失值, 提出了一种级联回退策略来估计缺失特征分布。

Result: 本文的方法在12个真实的世界不完整数据集的聚类任务中展示了优越的性能，并保持了线性时间复杂度。

Conclusion: 通过引入基于数据的分箱法和邻近分配策略，提出了一种无需显式补全缺失数据的新相似度度量方法，即邻近核。该方法在处理不完整数据时，能够在核特征空间中直接计算相似度，并在12个真实世界的不完整数据集的聚类任务中表现出优越性能同时保持线性时间复杂度。

Abstract: Measuring similarity between incomplete data is a fundamental challenge in
web mining, recommendation systems, and user behavior analysis. Traditional
approaches either discard incomplete data or perform imputation as a
preprocessing step, leading to information loss and biased similarity
estimates. This paper presents the proximity kernel, a new similarity measure
that directly computes similarity between incomplete data in kernel feature
space without explicit imputation in the original space. The proposed method
introduces data-dependent binning combined with proximity assignment to project
data into a high-dimensional sparse representation that adapts to local density
variations. For missing value handling, we propose a cascading fallback
strategy to estimate missing feature distributions. We conduct clustering tasks
on the proposed kernel representation across 12 real world incomplete datasets,
demonstrating superior performance compared to existing methods while
maintaining linear time complexity. All the code are available at
https://anonymous.4open.science/r/proximity-kernel-2289.

</details>


### [183] [Generalist++: A Meta-learning Framework for Mitigating Trade-off in Adversarial Training](https://arxiv.org/abs/2510.13361)
*Yisen Wang,Yichuan Mo,Hongjun Wang,Junyi Li,Zhouchen Lin*

Main category: cs.LG

TL;DR: Generalist框架通过将泛化任务分解为多个子任务并整合学习器参数，解决了一些关于对抗训练的局限性问题，并表现出优良的性能。


<details>
  <summary>Details</summary>
Motivation: 对抗训练面临自然准确性下降和鲁棒性传导性能不佳的问题，本文提出一种新的框架以解决这些局限性。

Method: 本文通过将整体泛化目标分解为多个子任务，每个任务由专门的基础学习器负责。在训练的后期阶段，多个学习器的参数进行插值，形成一个知识渊博的全局学习器。定期将全局学习器的参数重新分配给基础学习器，以防止其优化轨迹偏离共享目标。

Result: Generalist框架在理论分析和大量实验中表现出更低的泛化误差，显著缓解了与基线方法相比的权衡问题。

Conclusion: 本文提出了一种称为Generalist的框架，用于解决对抗训练的自然准确性下降和鲁棒性传递性差的问题，并通过理论分析和实验验证了其有效性。

Abstract: Despite the rapid progress of neural networks, they remain highly vulnerable
to adversarial examples, for which adversarial training (AT) is currently the
most effective defense. While AT has been extensively studied, its practical
applications expose two major limitations: natural accuracy tends to degrade
significantly compared with standard training, and robustness does not transfer
well across attacks crafted under different norm constraints. Unlike prior
works that attempt to address only one issue within a single network, we
propose to partition the overall generalization goal into multiple sub-tasks,
each assigned to a dedicated base learner. By specializing in its designated
objective, each base learner quickly becomes an expert in its field. In the
later stages of training, we interpolate their parameters to form a
knowledgeable global learner, while periodically redistributing the global
parameters back to the base learners to prevent their optimization trajectories
from drifting too far from the shared target. We term this framework Generalist
and introduce three variants tailored to different application scenarios. Both
theoretical analysis and extensive experiments demonstrate that Generalist
achieves lower generalization error and significantly alleviates the trade-off
problems compared with baseline methods. Our results suggest that Generalist
provides a promising step toward developing fully robust classifiers in the
future.

</details>


### [184] [Contrastive Learning-Based Dependency Modeling for Anomaly Detection in Cloud Services](https://arxiv.org/abs/2510.13368)
*Yue Xing,Yingnan Deng,Heyao Liu,Ming Wang,Yun Zi,Xiaoxuan Sun*

Main category: cs.LG

TL;DR: 该方法通过结合对比学习和依赖建模，显著提高了云服务异常检测的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 针对云服务环境中复杂依赖关系和多样的异常模式，本文提出了一种新的方法来提高异常检测的准确性和稳定性。

Method: 该方法包括：1) 将服务交互抽象为依赖图；2) 通过嵌入函数提取时间和结构特征；3) 使用图卷积机制聚合邻域信息；4) 引入对比学习框架，构造正负样本对，增强正常和异常模式可分性；5) 设计时间一致性约束，稳定表示以减少噪声影响。整体优化结合对比损失和时间一致性损失。

Result: 该论文提出了一种结合对比学习的依赖建模和异常检测方法，用于解决云服务环境中的复杂依赖关系和多样的异常模式问题。该方法通过依赖图抽象服务交互，利用嵌入函数提取时间和结构特征，并采用图卷积机制聚合邻域信息以获得上下文感知的服务表示。引入了对比学习框架，通过构建正负样本对增强表示空间中正常和异常模式的可分性。此外，还设计了时间一致性约束，以维持跨时间步长的表示稳定性，减少短期波动和噪声的影响。总体优化结合了对比损失和时间一致性损失，以确保跨多维特征的稳定和可靠检测。实验结果表明，该方法在稀疏标签、监控噪声和流量波动的条件下，同时在精准率、召回率、F1评分和AUC这些指标上显著优于现有方法，展示了在复杂环境中的强大适应性和稳定性。

Conclusion: 研究验证了依赖建模与对比学习结合在云服务异常检测中的有效性，为此领域提供了一套完整的技术解决方案，并在复杂环境中表现出强大的适应性和稳定性。

Abstract: This paper addresses the challenges of complex dependencies and diverse
anomaly patterns in cloud service environments by proposing a dependency
modeling and anomaly detection method that integrates contrastive learning. The
method abstracts service interactions into a dependency graph, extracts
temporal and structural features through embedding functions, and employs a
graph convolution mechanism to aggregate neighborhood information for
context-aware service representations. A contrastive learning framework is then
introduced, constructing positive and negative sample pairs to enhance the
separability of normal and abnormal patterns in the representation space.
Furthermore, a temporal consistency constraint is designed to maintain
representation stability across time steps and reduce the impact of short-term
fluctuations and noise. The overall optimization combines contrastive loss and
temporal consistency loss to ensure stable and reliable detection across
multi-dimensional features. Experiments on public datasets systematically
evaluate the method from hyperparameter, environmental, and data sensitivity
perspectives. Results show that the proposed approach significantly outperforms
existing methods on key metrics such as Precision, Recall, F1-Score, and AUC,
while maintaining robustness under conditions of sparse labeling, monitoring
noise, and traffic fluctuations. This study verifies the effectiveness of
integrating dependency modeling with contrastive learning, provides a complete
technical solution for cloud service anomaly detection, and demonstrates strong
adaptability and stability in complex environments.

</details>


### [185] [Assessing the robustness of heterogeneous treatment effects in survival analysis under informative censoring](https://arxiv.org/abs/2510.13397)
*Yuxin Wang,Dennis Frauen,Jonas Schweisthal,Maresa Schröder,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: 提出了一个假设精简框架和新颖的元学习器，用于应对生存数据中删失偏倚问题，评估条件平均治疗效果估计的稳健性。


<details>
  <summary>Details</summary>
Motivation: 在临床研究中，退出率很高，由于副作用或其他原因，最多有一半的患者提前退出。当退出是信息性的（即依赖于生存时间）时，会引入删失偏倚，从而导致治疗效果估计也存在偏倚。

Method: 提出了一种假设精简的框架来评估生存分析中条件平均治疗效果（CATE）估计的稳健性，该框架通过部分识别技术导出CATE的有界信息，并开发了一种新颖的元学习器，该学习器可以使用任意机器学习模型来估计这些界限。

Result: 通过数值实验和癌症药物试验的应用，展示了该元学习器的实际价值。框架为在存在删失的情况下评估治疗效果的稳健性提供了实用工具，有助于识别治疗有效的患者亚组。

Conclusion: 该框架促进了生存数据在医学和流行病学证据生成中的可靠应用，为评估删失情况下的治疗效果稳健性提供了实用工具。

Abstract: Dropout is common in clinical studies, with up to half of patients leaving
early due to side effects or other reasons. When dropout is informative (i.e.,
dependent on survival time), it introduces censoring bias, because of which
treatment effect estimates are also biased. In this paper, we propose an
assumption-lean framework to assess the robustness of conditional average
treatment effect (CATE) estimates in survival analysis when facing censoring
bias. Unlike existing works that rely on strong assumptions, such as
non-informative censoring, to obtain point estimation, we use partial
identification to derive informative bounds on the CATE. Thereby, our framework
helps to identify patient subgroups where treatment is effective despite
informative censoring. We further develop a novel meta-learner that estimates
the bounds using arbitrary machine learning models and with favorable
theoretical properties, including double robustness and quasi-oracle
efficiency. We demonstrate the practical value of our meta-learner through
numerical experiments and in an application to a cancer drug trial. Together,
our framework offers a practical tool for assessing the robustness of estimated
treatment effects in the presence of censoring and thus promotes the reliable
use of survival data for evidence generation in medicine and epidemiology.

</details>


### [186] [Optimizing Storage Overhead of User Behavior Log for ML-embedded Mobile Apps](https://arxiv.org/abs/2510.13405)
*Chen Gong,Yan Zhuang,Zhenzhe Zheng,Yiliu Chen,Sheng Wang,Fan Wu,Guihai Chen*

Main category: cs.LG

TL;DR: AdaLog系统通过解决当前工业实践中用户行为日志的两大低效问题，实现了在增加极小系统开销的同时，将存储效率提高，显著减少日志文件大小。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习驱动的服务日益普及，记录必要的用户行为数据给移动应用带来了大量的存储成本，影响了系统响应能力并导致应用卸载率升高。这一研究的动机是解决这一数据存储瓶颈问题。

Method: AdaLog系统首先将特征级冗余数据的消除视为超图中的最大加权匹配问题，并提出了一种分层算法以实现高效的设备端部署。然后，采用虚拟哈希属性设计将异构行为分配到少数日志文件中，以实现物理上的密集存储。最后，设计了增量更新机制，以最小化适应过时行为日志所需的输入/输出操作。

Result: 在真实用户数据上的评估显示，AdaLog在增加的系统开销很小的情况下（仅2秒的延迟和15 MB的内存使用），将行为日志文件大小减少了19%到44%。这为更广泛的设备端ML应用奠定了更高效的数据基础。

Conclusion: AdaLog系统是一种轻量级且适应性强的系统，旨在提高ML嵌入式移动应用中用户行为日志的存储效率，而不影响模型推断的准确性或延迟。

Abstract: Machine learning (ML) models are increasingly integrated into modern mobile
apps to enable personalized and intelligent services. These models typically
rely on rich input features derived from historical user behaviors to capture
user intents. However, as ML-driven services become more prevalent, recording
necessary user behavior data imposes substantial storage cost on mobile apps,
leading to lower system responsiveness and more app uninstalls. To address this
storage bottleneck, we present AdaLog, a lightweight and adaptive system
designed to improve the storage efficiency of user behavior log in ML-embedded
mobile apps, without compromising model inference accuracy or latency. We
identify two key inefficiencies in current industrial practices of user
behavior log: (i) redundant logging of overlapping behavior data across
different features and models, and (ii) sparse storage caused by storing
behaviors with heterogeneous attribute descriptions in a single log file. To
solve these issues, AdaLog first formulates the elimination of feature-level
redundant data as a maximum weighted matching problem in hypergraphs, and
proposes a hierarchical algorithm for efficient on-device deployment. Then,
AdaLog employs a virtually hashed attribute design to distribute heterogeneous
behaviors into a few log files with physically dense storage. Finally, to
ensure scalability to dynamic user behavior patterns, AdaLog designs an
incremental update mechanism to minimize the I/O operations needed for adapting
outdated behavior log. We implement a prototype of AdaLog and deploy it into
popular mobile apps in collaboration with our industry partner. Evaluations on
real-world user data show that AdaLog reduces behavior log size by 19% to 44%
with minimal system overhead (only 2 seconds latency and 15 MB memory usage),
providing a more efficient data foundation for broader adoption of on-device
ML.

</details>


### [187] [When Embedding Models Meet: Procrustes Bounds and Applications](https://arxiv.org/abs/2510.13406)
*Lucas Maystre,Alvaro Ortega Gonzalez,Charles Park,Rares Dolga,Tudor Berariu,Yu Zhao,Kamil Ciosek*

Main category: cs.LG

TL;DR: 探讨嵌入模型如何通过正交变换对齐以实现互操作性，并提供了一种有效的后处理方法。


<details>
  <summary>Details</summary>
Motivation: 为了应对不同嵌入模型之间缺乏互操作性的问题，该研究探讨了在什么条件下可以通过正交变换对一组嵌入进行对齐。

Method: 主要方法是通过Procrustes后处理，将一组嵌入通过正交变换对齐到另一组嵌入。

Result: 研究表明，如果成对点积大致保持不变，那么存在一种等距变换可以将两组嵌入紧密对齐，并提供了对齐误差的严格界限。

Conclusion: Procrustes后处理可以使两种嵌入模型互操作，同时保留每个嵌入空间的几何结构，在多个应用中有效。

Abstract: Embedding models trained separately on similar data often produce
representations that encode stable information but are not directly
interchangeable. This lack of interoperability raises challenges in several
practical applications, such as model retraining, partial model upgrades, and
multimodal search. Driven by these challenges, we study when two sets of
embeddings can be aligned by an orthogonal transformation. We show that if
pairwise dot products are approximately preserved, then there exists an
isometry that closely aligns the two sets, and we provide a tight bound on the
alignment error. This insight yields a simple alignment recipe, Procrustes
post-processing, that makes two embedding models interoperable while preserving
the geometry of each embedding space. Empirically, we demonstrate its
effectiveness in three applications: maintaining compatibility across
retrainings, combining different models for text retrieval, and improving
mixed-modality search, where it achieves state-of-the-art performance.

</details>


### [188] [Hybrid Interval Type-2 Mamdani-TSK Fuzzy System for Regression Analysis](https://arxiv.org/abs/2510.13437)
*Ashish Bhatia,Renato Cordeiro de Amorim,Vito De Feo*

Main category: cs.LG

TL;DR: 本文提出了一种新的模糊回归方法，结合了Mamdani系统的可解释性和TSK模型的精度，在多个基准数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理现实数据复杂性时存在困难，而深度学习方法虽然擅长捕捉复杂的非线性关系，但缺乏可解释性。模糊系统提供了处理不确定性和不精确性的替代框架。

Method: 提出了一种新的模糊回归方法，该方法结合了Mamdani系统的可解释性和TSK模型的精度。

Result: 在测试的6个数据集上，该方法在4个数据集上获得了最佳的模糊方法分数，在2个数据集上优于不透明模型，并在1个数据集上取得了最佳整体分数，RMSE的改进范围为0.4%到19%。

Conclusion: 该混合方法为预测建模提供了一种平衡且多功能的工具，解决了模糊系统中固有的可解释性和精确性之间的权衡。

Abstract: Regression analysis is employed to examine and quantify the relationships
between input variables and a dependent and continuous output variable. It is
widely used for predictive modelling in fields such as finance, healthcare, and
engineering. However, traditional methods often struggle with real-world data
complexities, including uncertainty and ambiguity. While deep learning
approaches excel at capturing complex non-linear relationships, they lack
interpretability and risk over-fitting on small datasets. Fuzzy systems provide
an alternative framework for handling uncertainty and imprecision, with Mamdani
and Takagi-Sugeno-Kang (TSK) systems offering complementary strengths:
interpretability versus accuracy. This paper presents a novel fuzzy regression
method that combines the interpretability of Mamdani systems with the precision
of TSK models. The proposed approach introduces a hybrid rule structure with
fuzzy and crisp components and dual dominance types, enhancing both accuracy
and explainability. Evaluations on benchmark datasets demonstrate
state-of-the-art performance in several cases, with rules maintaining a
component similar to traditional Mamdani systems while improving precision
through improved rule outputs. This hybrid methodology offers a balanced and
versatile tool for predictive modelling, addressing the trade-off between
interpretability and accuracy inherent in fuzzy systems. In the 6 datasets
tested, the proposed approach gave the best fuzzy methodology score in 4
datasets, out-performed the opaque models in 2 datasets and produced the best
overall score in 1 dataset with the improvements in RMSE ranging from 0.4% to
19%.

</details>


### [189] [Rectify and Align GPS Points to Parking Spots via Rank-1 Constraint](https://arxiv.org/abs/2510.13439)
*Jiaxing Deng,Junbiao Pang,Zhicheng Wang,Haitao Yu*

Main category: cs.LG

TL;DR: 研究提出了一种无监督低秩方法，矫正GPS点误差，并对齐至停车位。实验验证了该方法的优越性，且数据与代码公开。


<details>
  <summary>Details</summary>
Motivation: 高楼导致GPS点偏移，且低成本GPS设备本身存在定位误差，需要在不监督的情况下从大量停车位数据中校正错误GPS点。

Method: 无监督低秩方法：利用停车位的物理约束（即停车位平行于道路边）进行GPS点误差矫正与对齐。

Result: 实验表明，所提方法在矫正与对齐GPS点误差方面具有优越性。

Conclusion: 该研究提出的无监督低秩方法能够有效矫正GPS点的误差，并将其对齐到停车位上，实验表明方法在解决实际问题上的优越性。

Abstract: Parking spots are essential components, providing vital mobile resources for
residents in a city. Accurate Global Positioning System (GPS) points of parking
spots are the core data for subsequent applications,e.g., parking management,
parking policy, and urban development. However, high-rise buildings tend to
cause GPS points to drift from the actual locations of parking spots; besides,
the standard lower-cost GPS equipment itself has a certain location error.
Therefore, it is a non-trivial task to correct a few wrong GPS points from a
large number of parking spots in an unsupervised approach. In this paper,
motivated by the physical constraints of parking spots (i.e., parking spots are
parallel to the sides of roads), we propose an unsupervised low-rank method to
effectively rectify errors in GPS points and further align them to the parking
spots in a unified framework. The proposed unconventional rectification and
alignment method is simple and yet effective for any type of GPS point errors.
Extensive experiments demonstrate the superiority of the proposed method to
solve a practical problem. The data set and the code are publicly accessible
at:https://github.com/pangjunbiao/ITS-Parking-spots-Dataset.

</details>


### [190] [Neural Sum-of-Squares: Certifying the Nonnegativity of Polynomials with Transformers](https://arxiv.org/abs/2510.13444)
*Nico Pelleriti,Christoph Spiegel,Shiwei Liu,David Martínez-Rubio,Max Zimmer,Sebastian Pokutta*

Main category: cs.LG

TL;DR: 提出了一种使用Transformer模型预测并减少多项式SOS表达式中单项式基大小的新方法，实现了大幅加速，并突破了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决多项式非负性认证的计算复杂性问题，以及现有方法在实践中的局限性。

Method: 提出了首个学习增强算法来认证和简化多项式的和平方（SOS）性。具体来说，训练Transformer模型来预测给定多项式的几乎最小单项式基，从而大幅缩减相应的SDP大小，涉及三大关键步骤：有效的训练数据集生成、Transformer架构的设计与训练、以及系统性回退机制。

Result: 在超过200个基准数据集上验证了该方法，与最先进的求解器相比，实现了超过100倍的加速，并能解决其他方法失败的实例。

Conclusion: 该研究提供了将SOS编程的实际可扩展性转变为现实的新见解。

Abstract: Certifying nonnegativity of polynomials is a well-known NP-hard problem with
direct applications spanning non-convex optimization, control, robotics, and
beyond. A sufficient condition for nonnegativity is the Sum of Squares (SOS)
property, i.e., it can be written as a sum of squares of other polynomials. In
practice, however, certifying the SOS criterion remains computationally
expensive and often involves solving a Semidefinite Program (SDP), whose
dimensionality grows quadratically in the size of the monomial basis of the SOS
expression; hence, various methods to reduce the size of the monomial basis
have been proposed. In this work, we introduce the first learning-augmented
algorithm to certify the SOS criterion. To this end, we train a Transformer
model that predicts an almost-minimal monomial basis for a given polynomial,
thereby drastically reducing the size of the corresponding SDP. Our overall
methodology comprises three key components: efficient training dataset
generation of over 100 million SOS polynomials, design and training of the
corresponding Transformer architecture, and a systematic fallback mechanism to
ensure correct termination, which we analyze theoretically. We validate our
approach on over 200 benchmark datasets, achieving speedups of over $100\times$
compared to state-of-the-art solvers and enabling the solution of instances
where competing approaches fail. Our findings provide novel insights towards
transforming the practical scalability of SOS programming.

</details>


### [191] [$L_2$-Regularized Empirical Risk Minimization Guarantees Small Smooth Calibration Error](https://arxiv.org/abs/2510.13450)
*Masahiro Fujisawa,Futoshi Futami*

Main category: cs.LG

TL;DR: 本文首次提供理论证明，表明L2正则化ERM能直接控制平滑校准误差，无需后处理或特定校准正则化。


<details>
  <summary>Details</summary>
Motivation: 研究标准训练程序如何产生良好校准的模型，为此提供一个理论证明而无需后期修正。

Method: 通过理论证明和实验验证，研究L2正则化ERM对平滑校准误差的控制。

Result: 实验确认特定保证，L2正则化ERM可以在无提升或后校准下提供良好的校准模型。

Conclusion: 实验验证了理论结果，表明L2正则化的ERM可以直接提供良好校准的模型。

Abstract: Calibration of predicted probabilities is critical for reliable machine
learning, yet it is poorly understood how standard training procedures yield
well-calibrated models. This work provides the first theoretical proof that
canonical $L_{2}$-regularized empirical risk minimization directly controls the
smooth calibration error (smCE) without post-hoc correction or specialized
calibration-promoting regularizer. We establish finite-sample generalization
bounds for smCE based on optimization error, regularization strength, and the
Rademacher complexity. We then instantiate this theory for models in
reproducing kernel Hilbert spaces, deriving concrete guarantees for kernel
ridge and logistic regression. Our experiments confirm these specific
guarantees, demonstrating that $L_{2}$-regularized ERM can provide a
well-calibrated model without boosting or post-hoc recalibration. The source
code to reproduce all experiments is available at
https://github.com/msfuji0211/erm_calibration.

</details>


### [192] [Towards Blackwell Optimality: Bellman Optimality Is All You Can Get](https://arxiv.org/abs/2510.13476)
*Victor Boone,Adrienne Tuynman*

Main category: cs.LG

TL;DR: 本文探讨了识别偏差最优顺序策略的问题，构建了降低错误概率的学习算法，并识别出适合中止识别算法的MDP类别，还提供了可行的停止规则。


<details>
  <summary>Details</summary>
Motivation: 在马尔可夫决策过程中，平均收益最优化虽然被普遍采用，但过于渐进。为了结合即时损失，提出了一系列偏差最优化的层次，直至布莱克韦尔最优化。

Method: 通过对每个偏差最优顺序构建学习算法，并定义具备唯一贝尔曼最优政策的MDP类别和相应的停止规则。

Result: 为求解问题，针对每个层次构建了一种学习算法，该算法的错误概率逐渐消失。同时，刻画了适用于有限停止识别算法的MDP（即具备唯一贝尔曼最优政策且不依赖于考虑的优化顺序）类别。提供了一个可行的停止规则，当与学习算法结合时，可在有限时间触发。

Conclusion: 提出了一种方法解决识别偏差最优策略的问题，同时识别出可在有限时间停止的MDP类型，并提供了有效的停止规则。

Abstract: Although average gain optimality is a commonly adopted performance measure in
Markov Decision Processes (MDPs), it is often too asymptotic. Further
incorporating measures of immediate losses leads to the hierarchy of bias
optimalities, all the way up to Blackwell optimality. In this paper, we
investigate the problem of identifying policies of such optimality orders. To
that end, for each order, we construct a learning algorithm with vanishing
probability of error. Furthermore, we characterize the class of MDPs for which
identification algorithms can stop in finite time. That class corresponds to
the MDPs with a unique Bellman optimal policy, and does not depend on the
optimality order considered. Lastly, we provide a tractable stopping rule that
when coupled to our learning algorithm triggers in finite time whenever it is
possible to do so.

</details>


### [193] [Tahakom LLM guidelines and receipts: from pre-training data to an Arabic LLM](https://arxiv.org/abs/2510.13481)
*Areej AlOtaibi,Lina Alyahya,Raghad Alshabanah,Shahad Alfawzan,Shuruq Alarefei,Reem Alsabti,Nouf Alsubaie,Abdulaziz Alhuzaymi,Lujain Alkhelb,Majd Alsayari,Waad Alahmed,Omar Talabay,Jalal Alowibdi,Salem Alelyani,Adel Bibi*

Main category: cs.LG

TL;DR: 本文探讨了阿拉伯语大语言模型的开发挑战，并提出了一套系统的方法来应对这些挑战。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在阿拉伯语自然语言处理中的应用及其独特挑战。

Method: 详细探讨数据收集和过滤策略、分词器设计对模型性能的影响及现有评估框架的局限性，提出有针对性的改进方法并共享相应的资源。

Result: 对于阿拉伯语大语言模型，提出了包括数据策划、分词器设计和评估在内的一整套方法，并分享了数据和方法论。

Conclusion: 通过提出系统化的纠正方法及分享数据和方法，促进了阿拉伯语语言建模的发展。

Abstract: Large Language Models (LLMs) have significantly advanced the field of natural
language processing, enhancing capabilities in both language understanding and
generation across diverse domains. However, developing LLMs for Arabic presents
unique challenges. This paper explores these challenges by focusing on critical
aspects such as data curation, tokenizer design, and evaluation. We detail our
approach to the collection and filtration of Arabic pre-training datasets,
assess the impact of various tokenizer designs on model performance, and
examine the limitations of existing Arabic evaluation frameworks, for which we
propose a systematic corrective methodology. To promote transparency and
facilitate collaborative development, we share our data and methodologies,
contributing to the advancement of language modeling, particularly for the
Arabic language.

</details>


### [194] [DistilCLIP-EEG: Enhancing Epileptic Seizure Detection Through Multi-modal Learning and Knowledge Distillation](https://arxiv.org/abs/2510.13497)
*Zexin Wang,Lin Shi,Haoyu Wu,Junru Luo,Xiangzeng Kong,Jun Qi*

Main category: cs.LG

TL;DR: 我们提出了一个整合EEG信号和文本描述的多模态模型DistilCLIP-EEG，用于癫痫检测，取得了超过97%的准确率和高于0.94的F1评分。


<details>
  <summary>Details</summary>
Motivation: 现有的癫痫检测深度学习方法主要依赖于单模态EEG信号，未能利用多模态信息的潜在优势。

Method: 我们提出了一种基于CLIP框架的新型多模态模型DistilCLIP-EEG，该模型整合了EEG信号和文本描述，以捕捉癫痫发作的全面特征。模型包括基于Conformer架构的EEG编码器和用于编码器的提示学习的Learnable BERT （BERT-LP）。

Result: 在TUSZ、AUBMC和CHB-MIT数据集上，教师和学生模型均取得了超过97%的准确率。所有数据集上的F1评分均高于0.94，展示了所提框架的稳健性和可靠性。学生模型的参数量和模型大小约为教师模型的58.1%，显著降低了模型复杂性和存储需求，同时保持了高性能。

Conclusion: 提出的模型在EEG基础上的癫痫检测中表现出色，并为在资源受限环境中部署轻量级模型奠定了坚实基础。

Abstract: Epilepsy is a prevalent neurological disorder marked by sudden, brief
episodes of excessive neuronal activity caused by abnormal electrical
discharges, which may lead to some mental disorders. Most existing deep
learning methods for epilepsy detection rely solely on unimodal EEG signals,
neglecting the potential benefits of multimodal information. To address this,
we propose a novel multimodal model, DistilCLIP-EEG, based on the CLIP
framework, which integrates both EEG signals and text descriptions to capture
comprehensive features of epileptic seizures. The model involves an EEG encoder
based on the Conformer architecture as a text encoder, the proposed Learnable
BERT (BERT-LP) as prompt learning within the encoders. Both operate in a shared
latent space for effective cross-modal representation learning. To enhance
efficiency and adaptability, we introduce a knowledge distillation method where
the trained DistilCLIP-EEG serves as a teacher to guide a more compact student
model to reduce training complexity and time. On the TUSZ, AUBMC, and CHB-MIT
datasets, both the teacher and student models achieved accuracy rates exceeding
97%. Across all datasets, the F1-scores were consistently above 0.94,
demonstrating the robustness and reliability of the proposed framework.
Moreover, the student model's parameter count and model size are approximately
58.1% of those of the teacher model, significantly reducing model complexity
and storage requirements while maintaining high performance. These results
highlight the potential of our proposed model for EEG-based epilepsy detection
and establish a solid foundation for deploying lightweight models in
resource-constrained settings.

</details>


### [195] [Offline and Online KL-Regularized RLHF under Differential Privacy](https://arxiv.org/abs/2510.13512)
*Yulian Wu,Rushil Thareja,Praneeth Vepakomma,Francesco Orabona*

Main category: cs.LG

TL;DR: 研究了KL-正则化下的RLHF在隐私保护下的离线和在线优化问题，提出了新算法和理论界限，并验证了其实用性。


<details>
  <summary>Details</summary>
Motivation: 动机在于增强大语言模型对齐中的常用目标函数KL-正则化在存在人类偏好标签的隐私保护下的理论理解和实现。

Method: 研究中使用了基于悲观原则的算法来离线设置中处理人类偏好标签的本地差分隐私（LDP）问题，以及基于乐观原则的算法来解决在线设置问题。

Result: 在离线设置中，算法在单策略集中的情况下对KL-正则化目标实现了新的亚最优间隙，并证明了其最优性。在在线设置中，提出的算法首次从理论上研究了带有LDP的KL-正则化RLHF问题，获得了对数后悔界限。我们验证了离线设置中的算法，并发布了开源代码以供验证。

Conclusion: 我们在离线和在线环境中研究了KL-正则化条件下的人类反馈强化学习（RLHF），提出了新的算法和理论界限，并验证了算法的有效性。

Abstract: In this paper, we study the offline and online settings of reinforcement
learning from human feedback (RLHF) with KL-regularization -- a widely used
objective function in large language model alignment -- under the $\epsilon$
local differential privacy ($\epsilon$-LDP) model on the label of the human
preference. In the offline setting, we design an algorithm based on the
principle of pessimism and derive a new suboptimality gap of
$\tilde{O}(1/[(e^\epsilon-1)^2 n])$ on the KL-regularized objective under
single-policy concentrability. We also prove its optimality by providing a
matching lower bound where $n$ is the sample size.
  In the online setting, we are the first one to theoretically investigate the
problem of KL-regularized RLHF with LDP. We design an optimism-based algorithm
and derive a logarithmic regret bound of $O(d_{\mathcal{F}}\log
(N_{\mathcal{F}}\cdot T) /(e^\epsilon-1)^2 )$, where $T$ is the total time
step, $N_{\mathcal{F}}$ is cardinality of the reward function space
$\mathcal{F}$ and $d_{\mathcal{F}}$ is a variant of eluder dimension for RLHF.
As a by-product of our analysis, our results also imply the first analysis for
online KL-regularized RLHF without privacy. We implement our algorithm in the
offline setting to verify our theoretical results and release our open source
code at: https://github.com/rushil-thareja/PPKL-RLHF-Official.

</details>


### [196] [K-Merge: Online Continual Merging of Adapters for On-device Large Language Models](https://arxiv.org/abs/2510.13537)
*Donald Shenaj,Ondrej Bohdal,Taha Ceritli,Mete Ozay,Pietro Zanuttigh,Umberto Michieli*

Main category: cs.LG

TL;DR: 本研究提出了一种数据无关且计算高效的策略，用于在移动设备上进行LoRA的增量合并，以应对存储容量有限的挑战。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的移动设备上，需要一种能够增量合并LoRA的有效方法，以支持新任务，同时保留旧任务的性能。

Method: 研究通过一种数据无关且计算高效的策略，进行LoRA选择与合并，旨在支持设备上在线增量合并新的LoRA。

Result: 实验表明，与其他策略相比，该方法在设备存储预算和计算限制下展示了优越的性能。

Conclusion: 提出的策略在需要增量合并LoRA的场景下，能够在不影响以往任务性能的情况下有效地合并新增LoRA，满足设备存储限制并取得优异的性能。

Abstract: On-device deployment of Large Language Models (LLMs) frequently leverages
Low-Rank Adapters (LoRAs) to support diverse downstream tasks under tight
resource constraints. To address the limited storage capacity of mobile
devices, recent works have explored model merging techniques to fuse multiple
LoRAs into a single one. In practice, however, LoRAs are often delivered
incrementally, as users request support for new tasks (e.g., novel problem
types or languages). This scenario introduces a new challenge: on-device online
continual merging, where the objective is to incorporate new LoRAs while
preserving the performance on previously supported tasks. In this paper, we
propose a data-free and computationally efficient strategy for selecting and
merging LoRAs when a new one becomes available, assuming the device can store
only a limited number of adapters. Extensive experiments across real-world
tasks demonstrate the superiority of our approach compared to alternative
strategies while adhering to the storage budget and compute limitations of
on-device settings.

</details>


### [197] [Multi-Objective $\textit{min-max}$ Online Convex Optimization](https://arxiv.org/abs/2510.13560)
*Rahul Vaze,Sumiran Mishra*

Main category: cs.LG

TL;DR: 提出了一种结合Hedge和OGD的算法解决多目标OCO问题，证明其极大极小后悔在i.i.d.情况下为O(\sqrt{T \log K})。


<details>
  <summary>Details</summary>
Motivation: 本文旨在拓展传统在线凸优化（OCO）的研究范畴，从单一损失函数扩展到多目标OCO问题，以研究在多重损失序列间的追踪能力，特别是极大极小后悔这一严格的性能衡量标准。

Method: 本文在独立同分布输入环境下，提出了一种结合了Hedge算法和在线梯度下降（OGD）的在线算法。

Result: 通过简单的数学证明，展示了所提算法在独立同分布情形下能达到期望的极大极小后悔值为O(\sqrt{T \log K})。

Conclusion: 对独立同分布的多目标在线凸优化问题，我们提出了一种结合Hedge算法和在线梯度下降（OGD）的简单算法，并证明了其期望的极大极小后悔值为O(\sqrt{T \log K})。

Abstract: In online convex optimization (OCO), a single loss function sequence is
revealed over a time horizon of $T$, and an online algorithm has to choose its
action at time $t$, before the loss function at time $t$ is revealed. The goal
of the online algorithm is to incur minimal penalty (called $\textit{regret}$
compared to a static optimal action made by an optimal offline algorithm
knowing all functions of the sequence in advance.
  In this paper, we broaden the horizon of OCO, and consider multi-objective
OCO, where there are $K$ distinct loss function sequences, and an algorithm has
to choose its action at time $t$, before the $K$ loss functions at time $t$ are
revealed. To capture the tradeoff between tracking the $K$ different sequences,
we consider the $\textit{min-max}$ regret, where the benchmark (optimal offline
algorithm) takes a static action across all time slots that minimizes the
maximum of the total loss (summed across time slots) incurred by each of the
$K$ sequences. An online algorithm is allowed to change its action across time
slots, and its {\it min-max} regret is defined as the difference between its
$\textit{min-max}$ cost and that of the benchmark. The $\textit{min-max}$
regret is a stringent performance measure and an algorithm with small regret
needs to `track' all loss function sequences closely at all times.
  We consider this $\textit{min-max}$ regret in the i.i.d. input setting where
all loss functions are i.i.d. generated from an unknown distribution. For the
i.i.d. model we propose a simple algorithm that combines the well-known
$\textit{Hedge}$ and online gradient descent (OGD) and show via a remarkably
simple proof that its expected $\textit{min-max}$ regret is $O(\sqrt{T \log
K})$.

</details>


### [198] [DOLFIN: Balancing Stability and Plasticity in Federated Continual Learning](https://arxiv.org/abs/2510.13567)
*Omayma Moussadek,Riccardo Salami,Simone Calderara*

Main category: cs.LG

TL;DR: DOLFIN improves federated continual learning by efficiently learning new tasks with minimal communication, surpassing baselines in accuracy without increasing memory usage.


<details>
  <summary>Details</summary>
Motivation: Address challenges in federated continual learning related to performance balance, privacy, and communication efficiency.

Method: The method leverages LoRA for minimal communication overhead and incorporates DualGradient Projection Memory (DualGPM) to prevent forgetting in Vision Transformers.

Result: DOLFIN consistently outperforms six strong baselines in final average accuracy while maintaining a similar memory footprint, validated through experiments on CIFAR-100, ImageNet-R, ImageNet-A, and CUB-200 datasets under two different Dirichlet heterogeneity settings.

Conclusion: Orthogonal low-rank adapters provide an effective and scalable solution for privacy-preserving continual learning in federated environments.

Abstract: Federated continual learning (FCL) enables models to learn new tasks across
multiple distributed clients, protecting privacy and without forgetting
previously acquired knowledge. However, current methods face challenges
balancing performance, privacy preservation, and communication efficiency. We
introduce a Distributed Online LoRA for Federated INcremental learning method
DOLFIN, a novel approach combining Vision Transformers with low-rank adapters
designed to efficiently and stably learn new tasks in federated environments.
Our method leverages LoRA for minimal communication overhead and incorporates
DualGradient Projection Memory (DualGPM) to prevent forgetting. Evaluated on
CIFAR-100, ImageNet-R, ImageNet-A, and CUB-200 under two Dirichlet
heterogeneity settings, DOLFIN consistently surpasses six strong baselines in
final average accuracy while matching their memory footprint. Orthogonal
low-rank adapters offer an effective and scalable solution for
privacy-preserving continual learning in federated settings.

</details>


### [199] [EEGChaT: A Transformer-Based Modular Channel Selector for SEEG Analysis](https://arxiv.org/abs/2510.13592)
*Chen Wang,Yansen Wang,Dongqi Han,Zilong Wang,Dongsheng Li*

Main category: cs.LG

TL;DR: EEGChaT, a Transformer-based model, enhances SEEG channel selection, improves accuracy, and offers interpretability in BCI applications.


<details>
  <summary>Details</summary>
Motivation: Traditional channel selection methods for SEEG signals face challenges with scalability and interpretability, necessitating a more efficient and insightful approach.

Method: Proposes a novel Transformer-based module, EEGChaT, which uses Channel Aggregation Tokens (CATs) and an improved Attention Rollout technique to identify task-relevant channels in SEEG recordings.

Result: Integration of EEGChaT with existing models shows improved decoding accuracy of up to 17% on the DuIN dataset and aligns with manually selected channels, validating its interpretability and effectiveness.

Conclusion: EEGChaT is an effective and generalizable solution for channel selection in SEEG analysis, enhancing performance and providing insights into neural signal relevance.

Abstract: Analyzing stereoelectroencephalography (SEEG) signals is critical for
brain-computer interface (BCI) applications and neuroscience research, yet
poses significant challenges due to the large number of input channels and
their heterogeneous relevance. Traditional channel selection methods struggle
to scale or provide meaningful interpretability for SEEG data. In this work, we
propose EEGChaT, a novel Transformer-based channel selection module designed to
automatically identify the most task-relevant channels in SEEG recordings.
EEGChaT introduces Channel Aggregation Tokens (CATs) to aggregate information
across channels, and leverages an improved Attention Rollout technique to
compute interpretable, quantitative channel importance scores. We evaluate
EEGChaT on the DuIN dataset, demonstrating that integrating EEGChaT with
existing classification models consistently improves decoding accuracy,
achieving up to 17\% absolute gains. Furthermore, the channel weights produced
by EEGChaT show substantial overlap with manually selected channels, supporting
the interpretability of the approach. Our results suggest that EEGChaT is an
effective and generalizable solution for channel selection in high-dimensional
SEEG analysis, offering both enhanced performance and insights into neural
signal relevance.

</details>


### [200] [Physics-augmented Multi-task Gaussian Process for Modeling Spatiotemporal Dynamics](https://arxiv.org/abs/2510.13601)
*Xizhuo Zhang,Bing Yao*

Main category: cs.LG

TL;DR: 该研究提出一个面向时空动态系统的物理增强多任务高斯过程框架，通过融合物理定律和几何信息，有效提高了建模能力，实验证明效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管感测和成像技术的进步使得高维时空数据的采集成为可能，但不规则空间结构、快速时间动态以及多物理变量的联合预测仍是建模的难题。

Method: 提出了一个几何感知多任务高斯过程（M-GP）模型，并通过物理规律的正则化方案将物理定律融合到模型中，以保证模型预测与物理动态原理的一致性。

Result: 实验结果证明，P-M-GP框架通过有效结合领域特定的物理约束和几何先验，显著提高了预测准确性。

Conclusion: 论文提出了一个物理增强的多任务高斯过程（P-M-GP）框架，通过将物理定律与几何信息结合起来，提高了对复合几何区域的时空动态系统的建模能力，验证实验表明该框架在预测准确性上优于现有方法。

Abstract: Recent advances in sensing and imaging technologies have enabled the
collection of high-dimensional spatiotemporal data across complex geometric
domains. However, effective modeling of such data remains challenging due to
irregular spatial structures, rapid temporal dynamics, and the need to jointly
predict multiple interrelated physical variables. This paper presents a
physics-augmented multi-task Gaussian Process (P-M-GP) framework tailored for
spatiotemporal dynamic systems. Specifically, we develop a geometry-aware,
multi-task Gaussian Process (M-GP) model to effectively capture intrinsic
spatiotemporal structure and inter-task dependencies. To further enhance the
model fidelity and robustness, we incorporate governing physical laws through a
physics-based regularization scheme, thereby constraining predictions to be
consistent with governing dynamical principles. We validate the proposed P-M-GP
framework on a 3D cardiac electrodynamics modeling task. Numerical experiments
demonstrate that our method significantly improves prediction accuracy over
existing methods by effectively incorporating domain-specific physical
constraints and geometric prior.

</details>


### [201] [Towards Robust Knowledge Removal in Federated Learning with High Data Heterogeneity](https://arxiv.org/abs/2510.13606)
*Riccardo Santi,Riccardo Salami,Simone Calderara*

Main category: cs.LG

TL;DR: 笔者提出了一种新的方法，可以快速去除AI模型中单个客户端的影响，以满足隐私和时间的双重要求。


<details>
  <summary>Details</summary>
Motivation: 随着便携设备的增多和其计算能力的提升，分布式训练AI模型的可能性增长。在此背景下，如何在保护用户隐私的同时，迅速从模型中去除特定用户的贡献成为一个重要的研究问题。

Method: 本文提出了一种基于任务算术和神经切线核的方法，以快速从模型中去除一个客户端的影响。

Result: 本文的方法可以有效地去除特定客户端对模型的影响，并且减少所需的通讯轮次，使得模型可以快速恢复有效状态。

Conclusion: 通过本文方法，可以在满足隐私和时间要求的情况下，快速去除模型中特定客户端的贡献，从而提高系统的服务效率。

Abstract: Nowdays, there are an abundance of portable devices capable of collecting
large amounts of data and with decent computational power. This opened the
possibility to train AI models in a distributed manner, preserving the
participating clients' privacy. However, because of privacy regulations and
safety requirements, elimination upon necessity of a client contribution to the
model has become mandatory. The cleansing process must satisfy specific
efficacy and time requirements. In recent years, research efforts have produced
several knowledge removal methods, but these require multiple communication
rounds between the data holders and the process coordinator. This can cause the
unavailability of an effective model up to the end of the removal process,
which can result in a disservice to the system users. In this paper, we
introduce an innovative solution based on Task Arithmetic and the Neural
Tangent Kernel, to rapidly remove a client's influence from a model.

</details>


### [202] [Message Passing on the Edge: Towards Scalable and Expressive GNNs](https://arxiv.org/abs/2510.13615)
*Pablo Barceló,Fabian Jogl,Alexander Kozachinskiy,Matthias Lanzinger,Stefan Neumann,Cristóbal Rojas*

Main category: cs.LG

TL;DR: 提出了EB-1WL和EB-GNN，构架在高效使用三角形的同时比传统方法表现力更强，并在实际应用中证明了其高效性与实用性。


<details>
  <summary>Details</summary>
Motivation: 通过使用EB-1WL提高GNN架构的表现力和效率，与传统方法相比提供更具竞争力的解决方案。

Method: 提出了一种基于边的颜色精炼测试EB-1WL，并设计了相应的GNN架构EB-GNN。架构灵感来源于Chiba和Nishizeki的经典三角计数算法，在消息传递过程中显式使用三角形。

Result: EB-1WL比1-WL更具表现力，并且在图学习任务中需要的时间和内存接近线性。EB-GNN在实际应用中效率高，能在保持高表现力的同时显著减少计算成本。

Conclusion: EB-GNN提供了一种更高效通用的架构，不仅优于简单的MPNNs，还能与专门任务的GNNs相竞争，同时在计算效率上具有显著的优势。

Abstract: We propose EB-1WL, an edge-based color-refinement test, and a corresponding
GNN architecture, EB-GNN. Our architecture is inspired by a classic triangle
counting algorithm by Chiba and Nishizeki, and explicitly uses triangles during
message passing. We achieve the following results: (1)~EB-1WL is significantly
more expressive than 1-WL. Further, we provide a complete logical
characterization of EB-1WL based on first-order logic, and matching
distinguishability results based on homomorphism counting. (2)~In an important
distinction from previous proposals for more expressive GNN architectures,
EB-1WL and EB-GNN require near-linear time and memory on practical graph
learning tasks. (3)~Empirically, we show that EB-GNN is a highly-efficient
general-purpose architecture: It substantially outperforms simple MPNNs, and
remains competitive with task-specialized GNNs while being significantly more
computationally efficient.

</details>


### [203] [Manifold Decoders: A Framework for Generative Modeling from Nonlinear Embeddings](https://arxiv.org/abs/2510.13622)
*Riddhish Thakare,Kingdom Mutala Akugri*

Main category: cs.LG

TL;DR: 该论文提出了为经典非线性降维方法（如t-SNE、Isomap和LLE）构建神经解码器架构的框架，首次实现了双向映射，并结合扩散生成过程进行评估。实验表明，解码器虽然成功重建数据，但质量不及端到端优化的自编码器，同时受限于流形的扩散生成质量较差。


<details>
  <summary>Details</summary>
Motivation: 经典的非线性降维技术虽然在数据可视化方面表现优异，但其单向变换限制了其在生成应用中的使用，论文提出解决这一关键缺口的框架。

Method: 提出了一种系统化框架，为主要的NLDR方法构建神经解码器架构，实现数据的双向映射，并扩展此框架通过在学得的流形空间内执行基于扩散的生成过程。

Result: 实验结果表明，解码器成功重构数据，但其质量不及端到端优化的自编码器。另外，流形约束的扩散生成产生的样本质量不佳，表明经典NLDR嵌入的离散和稀疏特性不适合生成模型所需的连续插值。

Conclusion: 研究指出，在NLDR方法上增加生成能力存在显著挑战，这些方法本质上为可视化和分析设计，不适合生成应用。

Abstract: Classical nonlinear dimensionality reduction (NLDR) techniques like t-SNE,
Isomap, and LLE excel at creating low-dimensional embeddings for data
visualization but fundamentally lack the ability to map these embeddings back
to the original high-dimensional space. This one-way transformation limits
their use in generative applications. This paper addresses this critical gap by
introducing a system- atic framework for constructing neural decoder
architectures for prominent NLDR methods, enabling bidirectional mapping for
the first time. We extend this framework by implementing a diffusion-based
generative process that operates directly within these learned manifold spaces.
Through experiments on the CelebA dataset, we evaluate the reconstruction and
generative performance of our approach against autoencoder and standard
diffusion model baselines. Our findings reveal a fundamental trade- off: while
the decoders successfully reconstruct data, their quality is surpassed by
end-to-end optimized autoencoders. Moreover, manifold-constrained diffusion
yields poor-quality samples, suggesting that the discrete and sparse nature of
classical NLDR embeddings is ill-suited for the continuous inter- polation
required by generative models. This work highlights the inherent challenges in
retrofitting generative capabilities onto NLDR methods designed primarily for
visualization and analysis.

</details>


### [204] [Multivariate Time Series Forecasting with Gate-Based Quantum Reservoir Computing on NISQ Hardware](https://arxiv.org/abs/2510.13634)
*Wissal Hamhoum,Soumaya Cherkaoui,Jean-Frederic Laprade,Ola Ahmed,Shengrui Wang*

Main category: cs.LG

TL;DR: 提出了一种适用于多变量时间序列的量子储备计算方法，并在真实硬件上验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探索量子储备计算在多变量时间序列中的应用，特别是面临的硬件限制。

Method: 引入了一种基于门的量子储备计算方法，结合注入量子位和内存量子位，并使用经过Trotter化的最近邻横场伊辛演化，以优化当前设备的连接性和深度。

Result: 在使用Lorenz-63和ENSO数据集时，所提出的方法分别实现了0.0087和0.0036的均方误差（MSE），与传统储备计算方法相当，且在一定情况下优于已学习的RNN。

Conclusion: 研究结果表明，在NISQ硬件上，基于门的量子储备计算在多变量时间序列预测中的实用性，且硬件噪声可在某些情况下作为隐式正则化器提升性能。

Abstract: Quantum reservoir computing (QRC) offers a hardware-friendly approach to
temporal learning, yet most studies target univariate signals and overlook
near-term hardware constraints. This work introduces a gate-based QRC for
multivariate time series (MTS-QRC) that pairs injection and memory qubits and
uses a Trotterized nearest-neighbor transverse-field Ising evolution optimized
for current device connectivity and depth. On Lorenz-63 and ENSO, the method
achieves a mean square error (MSE) of 0.0087 and 0.0036, respectively,
performing on par with classical reservoir computing on Lorenz and above
learned RNNs on both, while NVAR and clustered ESN remain stronger on some
settings. On IBM Heron R2, MTS-QRC sustains accuracy with realistic depths and,
interestingly, outperforms a noiseless simulator on ENSO; singular value
analysis indicates that device noise can concentrate variance in feature
directions, acting as an implicit regularizer for linear readout in this
regime. These findings support the practicality of gate-based QRC for MTS
forecasting on NISQ hardware and motivate systematic studies on when and how
hardware noise benefits QRC readouts.

</details>


### [205] [What is the objective of reasoning with reinforcement learning?](https://arxiv.org/abs/2510.13651)
*Damek Davis,Benjamin Recht*

Main category: cs.LG

TL;DR: 研究分析了强化学习算法在大型语言模型中的表现，揭示了不同算法与变换之间的关系。


<details>
  <summary>Details</summary>
Motivation: 探索强化学习算法在处理二元奖励问题时的概率升值机制，尤其是在不同变换下的表现。

Method: 研究展示了将强化学习中的常见算法应用于大型语言模型中的二元奖励问题，通过将正确回答的概率进行单调变换来实现概率上升。

Result: 发现拒绝采样算法关联的变换为对数，而GRPO算法关联的变换为平方根的反正弦函数。

Conclusion: 不同变换方法如何影响算法在二元奖励问题中的表现，这对理解算法优化过程具有重要意义。

Abstract: We show that several popular algorithms for reinforcement learning in large
language models with binary rewards can be viewed as stochastic gradient ascent
on a monotone transform of the probability of a correct answer given a prompt.
In particular, the transformation associated with rejection sampling algorithms
is the logarithm and that associated with the GRPO algorithm is the arcsine of
the square root.

</details>


### [206] [Time Series Foundation Models: Benchmarking Challenges and Requirements](https://arxiv.org/abs/2510.13654)
*Marcel Meyer,Sascha Kaltenpoth,Kevin Zalipski,Oliver Müller*

Main category: cs.LG

TL;DR: 研究分析了时间序列基础模型评估中的挑战，强调需要开发稳健的评估方法以维护评估的完整性。


<details>
  <summary>Details</summary>
Motivation: 发现当前时间序列基础模型（TSFM）评估存在缺陷，呼吁研究界设计新的评估方法以解决这些缺陷。

Method: 调查现有TSFM评估过程中面临的多重挑战，强调通过开发新的、原则性的评估方法来解决这些问题。

Result: 研究发现了数据分割上的混乱，这导致性能估计的夸大以及全球知识到本地时间序列传递的不当。

Conclusion: 研究呼吁开发稳健的评估方法，以保护时间序列基础模型（TSFM）评估的完整性，强调需要采用真正的样本外数据进行评估。

Abstract: Time Series Foundation Models (TSFMs) represent a new paradigm for time
series forecasting, offering zero-shot forecasting capabilities without the
need for domain-specific pre-training or fine-tuning. However, as with Large
Language Models (LLMs), evaluating TSFMs is tricky, as with ever more extensive
training sets, it becomes more and more challenging to ensure the integrity of
benchmarking data. Our investigation of existing TSFM evaluation highlights
multiple challenges, ranging from the representativeness of the benchmark
datasets, over the lack of spatiotemporal evaluation, to risks of information
leakage due to overlapping and obscure datasets, and the memorization of global
patterns caused by external shocks like economic crises or pandemics. Our
findings reveal widespread confusion regarding data partitions, risking
inflated performance estimates and incorrect transfer of global knowledge to
local time series. We argue for the development of robust evaluation
methodologies to prevent pitfalls already observed in LLM and classical time
series benchmarking, and call upon the research community to design new,
principled approaches, such as evaluations on truly out-of-sample future data,
to safeguard the integrity of TSFM assessment.

</details>


### [207] [Adam or Gauss-Newton? A Comparative Study In Terms of Basis Alignment and SGD Noise](https://arxiv.org/abs/2510.13680)
*Bingbin Liu,Rachit Bansal,Depen Morwani,Nikhil Vyas,David Alvarez-Melis,Sham M. Kakade*

Main category: cs.LG

TL;DR: 本文比较了基于Adam与高斯-牛顿方法的对角预处理器在不同设定下的性能，发现在多个情境中Adam具有优良表现，并通过理论分析和实证验证这些结果。


<details>
  <summary>Details</summary>
Motivation: 对角预处理器因其在加速深度学习模型训练中的潜力而备受关注，而本文欲通过研究基于Adam和高斯-牛顿方法的预处理器，以选择合适的基础并分析小批次梯度噪声的影响。

Method: 本文比较了基于Adam的方法和基于高斯-牛顿方法的两种对角预处理方法，分别利用了当前梯度的统计数据和高斯-牛顿矩阵的对角元素。为了获取洞见，研究在四个象限下分析了这些优化器在二次目标和逻辑回归中的表现。

Result: 在理论方面，无论基础如何，在全批次设置中，存在Adam优于GN$^{-1}$和GN$^{-1/2}$的情况；而在随机情境中，假设高斯数据的线性回归下，Adam的行为类似于GN$^{-1/2}$。理论结果通过对凸和非凸目标的实证研究得到支持。

Conclusion: 通过分析和比较，本文揭示了无论在全批次或随机情境中，对角预处理方法在不同基础上的性能差异，并通过实证研究验证了这些差异。这为选择合适的预处理器提供了理论和实践指导。

Abstract: Diagonal preconditioners are computationally feasible approximate to
second-order optimizers, which have shown significant promise in accelerating
training of deep learning models. Two predominant approaches are based on Adam
and Gauss-Newton (GN) methods: the former leverages statistics of current
gradients and is the de-factor optimizers for neural networks, and the latter
uses the diagonal elements of the Gauss-Newton matrix and underpins some of the
recent diagonal optimizers such as Sophia.
  In this work, we compare these two diagonal preconditioning methods through
the lens of two key factors: the choice of basis in the preconditioner, and the
impact of gradient noise from mini-batching. To gain insights, we analyze these
optimizers on quadratic objectives and logistic regression under all four
quadrants. We show that regardless of the basis, there exist instances where
Adam outperforms both GN$^{-1}$ and GN$^{-1/2}$ in full-batch settings.
Conversely, in the stochastic regime, Adam behaves similarly to GN$^{-1/2}$ for
linear regression under a Gaussian data assumption. These theoretical results
are supported by empirical studies on both convex and non-convex objectives.

</details>


### [208] [Information-Theoretic Reward Modeling for Stable RLHF: Detecting and Mitigating Reward Hacking](https://arxiv.org/abs/2510.13694)
*Yuchun Miao,Liang Ding,Sen Zhang,Rong Bao,Lefei Zhang,Dacheng Tao*

Main category: cs.LG

TL;DR: 提出InfoRM框架和IBL正则化方法，有效解决RLHF中奖励劫持问题，并通过实验验证其效果。


<details>
  <summary>Details</summary>
Motivation: 尽管RLHF在与人类价值对齐方面取得了成功，但奖励劫持仍是主要挑战。本文旨在解决奖励模型中不当泛化及RL优化过程中的正则化不足的问题。

Method: 提出了基于信息瓶颈（IB）原理的信息论奖励建模框架InfoRM，应用Mahalanobis距离测量IB潜在空间，并引入IBL进行分布级别的正则化。同时，提出了MOP作为统计指标来量化奖励劫持的严重性。

Result: 实验结果表明，InfoRM、IBL和MOP在各类LLM和数据集上的实验验证了其普适性和有效性。

Conclusion: 我们提出的基于信息瓶颈（IB）原理的信息论奖励建模框架InfoRM及其相关技术能够有效缓解奖励劫持问题，并提高RLHF的状态。IBL作为一种分布级别的正则化方法，能够在扩展优化空间的同时保持对齐。MOP作为诊断工具也表现出色。

Abstract: Despite the success of Reinforcement Learning from Human Feedback (RLHF) in
aligning language models with human values, reward hacking-or reward
over-optimization-remains a major challenge. We identify two key obstacles to
its mitigation: (1) reward misgeneralization in reward modeling, where reward
models overfit to spurious, preference-irrelevant features; and (2) the lack of
suitable regularization during RL optimization, as existing token-level
constraints often over-restrict the policy space. To address these issues, we
propose InfoRM, an information-theoretic reward modeling framework based on the
Information Bottleneck (IB) principle, which filters out preference-irrelevant
information to alleviate reward misgeneralization. We further observe that
reward-hacked responses manifest as pronounced outliers in InfoRM's IB latent
space, measured by Mahalanobis distance from the SFT-induced distribution.
Motivated by this, we introduce IBL, a distribution-level regularization that
penalizes such deviations, effectively expanding the optimization landscape
while maintaining alignment. We prove that IBL is theoretically equivalent to
the pessimistic RL objective within the IB latent space. Finally, we present
Mahalanobis Outlier Probability (MOP), a statistical metric for quantifying
reward hacking severity, enabling principled hyperparameter tuning and online
mitigation such as early stopping. Extensive experiments across diverse LLMs
and datasets confirm the generality of our findings, the effectiveness of
InfoRM and IBL, and the reliability of MOP as a diagnostic tool-collectively
advancing the state of RLHF.

</details>


### [209] [Don't Be Greedy, Just Relax! Pruning LLMs via Frank-Wolfe](https://arxiv.org/abs/2510.13713)
*Christophe Roux,Max Zimmer,Alexandre d'Aspremont,Sebastian Pokutta*

Main category: cs.LG

TL;DR: 提出一种基于FW算法的LLM剪枝方法，减少了剪枝误差，提升了性能。


<details>
  <summary>Details</summary>
Motivation: 对大型语言模型（LLM）进行剪枝，以减少计算和存储需求，并避免完全重新训练所带来的计算负担。

Method: 采用Frank-Wolfe（FW）算法解决剪枝问题的凸松弛形式，并通过舍入松弛解提供近似的原始组合问题解。

Result: 我们的方法显著减少了每层的剪枝误差，在GPT架构上表现优异，并且保持了内存效率。

Conclusion: 通过结合FW算法的收敛保证，我们提出的方法在理论上和实践上都能有效解决大型语言模型的剪枝问题。

Abstract: Pruning is a common technique to reduce the compute and storage requirements
of Neural Networks. While conventional approaches typically retrain the model
to recover pruning-induced performance degradation, state-of-the-art Large
Language Model (LLM) pruning methods operate layer-wise, minimizing the
per-layer pruning error on a small calibration dataset to avoid full
retraining, which is considered computationally prohibitive for LLMs. However,
finding the optimal pruning mask is a hard combinatorial problem and solving it
to optimality is intractable. Existing methods hence rely on greedy heuristics
that ignore the weight interactions in the pruning objective. In this work, we
instead consider the convex relaxation of these combinatorial constraints and
solve the resulting problem using the Frank-Wolfe (FW) algorithm. Our method
drastically reduces the per-layer pruning error, outperforms strong baselines
on state-of-the-art GPT architectures, and remains memory-efficient. We provide
theoretical justification by showing that, combined with the convergence
guarantees of the FW algorithm, we obtain an approximate solution to the
original combinatorial problem upon rounding the relaxed solution to
integrality.

</details>


### [210] [Assessing the Geographic Generalization and Physical Consistency of Generative Models for Climate Downscaling](https://arxiv.org/abs/2510.13722)
*Carlo Saccardi,Maximilian Pierzyna,Haitz Sáez de Ocáriz Borde,Simone Monaco,Cristian Meo,Pietro Liò,Rudolf Saathof,Geethu Joseph,Justin Dauwels*

Main category: cs.LG

TL;DR: 本文评估了最新的深度学习模型并引入物理启发的诊断方法，发现其在地理泛化和物理一致性上存在不足。提出了一个初步解决方案：引入功率谱密度损失函数以改善地理泛化。


<details>
  <summary>Details</summary>
Motivation: 传统的天气模拟计算消耗极大，而公里级天气数据在现实应用中非常重要。深度学习模型提供了一种更快的气候降尺度替代方案，但其可靠性尚存疑，因为通常是使用标准机器学习度量进行评估，而不是天气物理学的洞察。

Method: 评估最新的深度学习模型性能，并引入物理启发的诊断方法来衡量其可靠性，特别关注地理泛化和物理一致性。提出使用功率谱密度损失函数作为解决方案来改善模型的泛化能力。

Result: 实验显示深度学习模型如CorrDiff在受限的地理区域（如欧洲中部）训练后不能很好地泛化到其它区域（如伊比利亚、摩洛哥、斯堪的纳维亚），而且不能准确捕捉来自预测速度场的散度和涡度等二阶变量。

Conclusion: 尽管某些深度学习模型表现出强劲性能，但其在不同地理区域上的泛化能力和物理一致性有待提高。提出的功率谱密度损失函数在一定程度上改善了这些不足。

Abstract: Kilometer-scale weather data is crucial for real-world applications but
remains computationally intensive to produce using traditional weather
simulations. An emerging solution is to use deep learning models, which offer a
faster alternative for climate downscaling. However, their reliability is still
in question, as they are often evaluated using standard machine learning
metrics rather than insights from atmospheric and weather physics. This paper
benchmarks recent state-of-the-art deep learning models and introduces
physics-inspired diagnostics to evaluate their performance and reliability,
with a particular focus on geographic generalization and physical consistency.
Our experiments show that, despite the seemingly strong performance of models
such as CorrDiff, when trained on a limited set of European geographies (e.g.,
central Europe), they struggle to generalize to other regions such as Iberia,
Morocco in the south, or Scandinavia in the north. They also fail to accurately
capture second-order variables such as divergence and vorticity derived from
predicted velocity fields. These deficiencies appear even in in-distribution
geographies, indicating challenges in producing physically consistent
predictions. We propose a simple initial solution: introducing a power spectral
density loss function that empirically improves geographic generalization by
encouraging the reconstruction of small-scale physical structures. The code for
reproducing the experimental results can be found at
https://github.com/CarloSaccardi/PSD-Downscaling

</details>


### [211] [Asymptotically optimal reinforcement learning in Block Markov Decision Processes](https://arxiv.org/abs/2510.13748)
*Thomas van Vuren,Fiona Sloothaak,Maarten G. Wolf,Jaron Sanders*

Main category: cs.LG

TL;DR: 该研究通过两阶段算法改进块状马尔可夫决策过程中RL的学习性能，实现了较低的遗憾度并证明了算法的渐进最优性。


<details>
  <summary>Details</summary>
Motivation: 在许多实际场景中，强化学习因状态和动作空间指数级增长而显得不切实际。然而，许多环境具有可利用的结构可加速学习。这项研究的动机是形式化这种思想，通过在块状马尔可夫决策过程中研究RL，解决大观察空间但转移动态由潜在状态决定的问题。

Method: 本文分析了一种用于块状马尔可夫决策过程的两阶段RL算法。该算法首先通过随机探索学习潜在结构，然后转换为适用于揭示结构的乐观导向策略。

Result: 该算法在易于聚类的大类块状马尔可夫决策过程中实现了$O(\sqrt{T}+n)$的遗憾度，这里$T$是时间步数，$n$是观察空间的基数，并且兰道符号$O(\cdot)$保持常数和多对数因子。这改进了之前的最佳界限，尤其是在$n$很大时，从$O(\sqrt{T}+n^2)$改善。同时我们证明没有算法能在同一类过程中获得更低的遗憾，这证明了该算法在该类过程中实现了渐进最优性。

Conclusion: 通过遗憾分析揭示了准确的潜在状态估计可以有效加速学习，在易于聚类的块状马尔可夫决策过程中，该算法实现了$O(\sqrt{T}+n)$的遗憾，并证明了在该类过程中无法实现更低的遗憾，从而确立了算法的渐进最优性。

Abstract: The curse of dimensionality renders Reinforcement Learning (RL) impractical
in many real-world settings with exponentially large state and action spaces.
Yet, many environments exhibit exploitable structure that can accelerate
learning. To formalize this idea, we study RL in Block Markov Decision
Processes (BMDPs). BMDPs model problems with large observation spaces, but
where transition dynamics are fully determined by latent states. Recent
advances in clustering methods have enabled the efficient recovery of this
latent structure. However, a regret analysis that exploits these techniques to
determine their impact on learning performance remained open. We are now
addressing this gap by providing a regret analysis that explicitly leverages
clustering, demonstrating that accurate latent state estimation can indeed
effectively speed up learning.
  Concretely, this paper analyzes a two-phase RL algorithm for BMDPs that first
learns the latent structure through random exploration and then switches to an
optimism-guided strategy adapted to the uncovered structure. This algorithm
achieves a regret that is $O(\sqrt{T}+n)$ on a large class of BMDPs susceptible
to clustering. Here, $T$ denotes the number of time steps, $n$ is the
cardinality of the observation space, and the Landau notation $O(\cdot)$ holds
up to constants and polylogarithmic factors. This improves the best prior
bound, $O(\sqrt{T}+n^2)$, especially when $n$ is large. Moreover, we prove that
no algorithm can achieve lower regret uniformly on this same class of BMDPs.
This establishes that, on this class, the algorithm achieves asymptotic
optimality.

</details>


### [212] [Tensor Gaussian Processes: Efficient Solvers for Nonlinear PDEs](https://arxiv.org/abs/2510.13772)
*Qiwei Yuan,Zhitong Xu,Yinghao Chen,Yiming Xu,Houman Owhadi,Shandian Zhe*

Main category: cs.LG

TL;DR: TGPS通过张量分解降低计算复杂度，提高了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的PDE求解器效率低下或存在可扩展性问题，因此需要一种新的方法来提高效率和可扩展性。

Method: 采用了一维高斯过程进行张量分解，并用交替最小二乘法（ALS）来提高训练效率。

Result: 提出了一种新的基于张量高斯过程（TGPS）的求解器来解决现有方法的局限性。

Conclusion: 实验结果表明，TGPS相比现有方法在精度和效率上有显著优势。

Abstract: Machine learning solvers for partial differential equations (PDEs) have
attracted growing interest. However, most existing approaches, such as neural
network solvers, rely on stochastic training, which is inefficient and
typically requires a great many training epochs. Gaussian process
(GP)/kernel-based solvers, while mathematical principled, suffer from
scalability issues when handling large numbers of collocation points often
needed for challenging or higher-dimensional PDEs.
  To overcome these limitations, we propose TGPS, a tensor-GP-based solver that
models factor functions along each input dimension using one-dimensional GPs
and combines them via tensor decomposition to approximate the full solution.
This design reduces the task to learning a collection of one-dimensional GPs,
substantially lowering computational complexity, and enabling scalability to
massive collocation sets.
  For efficient nonlinear PDE solving, we use a partial freezing strategy and
Newton's method to linerize the nonlinear terms. We then develop an alternating
least squares (ALS) approach that admits closed-form updates, thereby
substantially enhancing the training efficiency. We establish theoretical
guarantees on the expressivity of our model, together with convergence proof
and error analysis under standard regularity assumptions. Experiments on
several benchmark PDEs demonstrate that our method achieves superior accuracy
and efficiency compared to existing approaches.

</details>


### [213] [The Art of Scaling Reinforcement Learning Compute for LLMs](https://arxiv.org/abs/2510.13786)
*Devvrit Khatri,Lovish Madaan,Rishabh Tiwari,Rachit Bansal,Sai Surya Duvvuri,Manzil Zaheer,Inderjit S. Dhillon,David Brandfonbrener,Rishabh Agarwal*

Main category: cs.LG

TL;DR: 论文介绍了一项关于强化学习（RL）在大型语言模型（LLMs）中的规模化研究，提出了一个分析和预测RL规模化的框架，并测试了多种设计选择对性能的影响，最后提出了一种最佳实践方案ScaleRL。


<details>
  <summary>Details</summary>
Motivation: 尽管计算预算快速增加，从业者缺乏理解如何评估算法改善以适应RL计算的规模化，本研究旨在解决这一问题。

Method: 研究通过400,000 GPU小时的大规模试验，拟合RL训练的S型计算-性能曲线，并对常见设计选择进行消融实验，以分析对性能和计算效率的影响。

Result: 研究表明并非所有设计选择能实现类似的渐近性能，并且一些设计细节主要影响计算效率而非渐近性能，通过稳定和可扩展的设计可以预测规模化的轨迹，最终提出的ScaleRL方案得到了验证，成功扩展并预测了单次RL运行的性能。

Conclusion: 该研究提出了一项科学方法框架以分析RL在LLMs中的规模化，同时提供了一个实际的最佳实践方案，即ScaleRL，使RL训练更具可预测性。

Abstract: Reinforcement learning (RL) has become central to training large language
models (LLMs), yet the field lacks predictive scaling methodologies comparable
to those established for pre-training. Despite rapidly rising compute budgets,
there is no principled understanding of how to evaluate algorithmic
improvements for scaling RL compute. We present the first large-scale
systematic study, amounting to more than 400,000 GPU-hours, that defines a
principled framework for analyzing and predicting RL scaling in LLMs. We fit
sigmoidal compute-performance curves for RL training and ablate a wide range of
common design choices to analyze their effects on asymptotic performance and
compute efficiency. We observe: (1) Not all recipes yield similar asymptotic
performance, (2) Details such as loss aggregation, normalization, curriculum,
and off-policy algorithm primarily modulate compute efficiency without
materially shifting the asymptote, and (3) Stable, scalable recipes follow
predictable scaling trajectories, enabling extrapolation from smaller-scale
runs. Combining these insights, we propose a best-practice recipe, ScaleRL, and
demonstrate its effectiveness by successfully scaling and predicting validation
performance on a single RL run scaled up to 100,000 GPU-hours. Our work
provides both a scientific framework for analyzing scaling in RL and a
practical recipe that brings RL training closer to the predictability long
achieved in pre-training.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [214] [Toward Reasoning-Centric Time-Series Analysis](https://arxiv.org/abs/2510.13029)
*Xinlei Wang,Mingtian Tan,Jing Qiu,Junhua Zhao,Jinjin Gu*

Main category: cs.AI

TL;DR: 倡导利用LLMs进行因果和可解释性驱动的时间序列分析。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法多注重数值回归能力，忽视了其深层推理潜力，因此需重新思考时间序列分析的方式，以更好地适应变化的现实环境。

Method: 结合LLMs的多模态输入进行时间序列分析，通过重视因果结构和可解释性，实现更人的理解。

Result: 将时间序列分析更接近于人类的理解方式，提供透明且与实际环境相关的见解。

Conclusion: 提出用LLMs进行时间序列分析的新方式，重点是因果结构和可解释性，从而提高透明度和上下文意识。

Abstract: Traditional time series analysis has long relied on pattern recognition,
trained on static and well-established benchmarks. However, in real-world
settings -- where policies shift, human behavior adapts, and unexpected events
unfold -- effective analysis must go beyond surface-level trends to uncover the
actual forces driving them. The recent rise of Large Language Models (LLMs)
presents new opportunities for rethinking time series analysis by integrating
multimodal inputs. However, as the use of LLMs becomes popular, we must remain
cautious, asking why we use LLMs and how to exploit them effectively. Most
existing LLM-based methods still employ their numerical regression ability and
ignore their deeper reasoning potential. This paper argues for rethinking time
series with LLMs as a reasoning task that prioritizes causal structure and
explainability. This shift brings time series analysis closer to human-aligned
understanding, enabling transparent and context-aware insights in complex
real-world environments.

</details>


### [215] [Personalized Learning Path Planning with Goal-Driven Learner State Modeling](https://arxiv.org/abs/2510.13215)
*Joy Jia Yin Lim,Ye He,Jifan Yu,Xin Cong,Daniel Zhang-Li,Zhiyuan Liu,Huiqin Liu,Lei Hou,Juanzi Li,Bin Xu*

Main category: cs.AI

TL;DR: 本文提出了一种名为Pxplore的新框架，通过结合强化学习和大型语言模型，实现了个性化学习路径规划，实验表明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化学习路径规划方法缺乏与个人目标对齐的规划机制。

Method: 引入Pxplore框架，其中结合了基于强化学习的训练范式和由大型语言模型驱动的教育架构，设计了结构化的学习者状态模型和自动化的奖励函数。训练方法为监督微调和群体相对政策优化相结合，并在真实的学习平台中部署。

Result: 大量实验验证了Pxplore框架在生成学习路径方面的有效性。

Conclusion: Pxplore在生成连贯的、个性化的和以目标为导向的学习路径方面是有效的。

Abstract: Personalized Learning Path Planning (PLPP) aims to design adaptive learning
paths that align with individual goals. While large language models (LLMs) show
potential in personalizing learning experiences, existing approaches often lack
mechanisms for goal-aligned planning. We introduce Pxplore, a novel framework
for PLPP that integrates a reinforcement-based training paradigm and an
LLM-driven educational architecture. We design a structured learner state model
and an automated reward function that transforms abstract objectives into
computable signals. We train the policy combining supervised fine-tuning (SFT)
and Group Relative Policy Optimization (GRPO), and deploy it within a
real-world learning platform. Extensive experiments validate Pxplore's
effectiveness in producing coherent, personalized, and goal-driven learning
paths. We release our code and dataset to facilitate future research.

</details>


### [216] [An Analytical Framework to Enhance Autonomous Vehicle Perception for Smart Cities](https://arxiv.org/abs/2510.13230)
*Jalal Khan,Manzoor Khan,Sherzod Turaev,Sumbal Malik,Hesham El-Sayed,Farman Ullah*

Main category: cs.AI

TL;DR: 该研究提出了一种通过基于效用的分析模型来增强自动驾驶车辆环境感知的方法，实验结果验证了该模型在物体检测任务中的高效性，并支持其应用于评估学习模型的效用。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要增强的感知能力，以提高智能出行的安全性和效率。因此，本研究旨在开发一个能够准确识别多个道路物体并预测驾驶员感知以控制汽车运动的模型。

Method: 本文提出了一种新颖的基于效用的分析模型，包括获取具有特定物体的自定义数据集，如摩托车手、人力车等；使用YOLOv8s深度学习模型进行物体检测；以及一个模块，用于根据训练模型实例的性能值测量感知服务的效用。

Result: 实验结果显示，基于mAP@0.5值，YOLOv8s模型中的三种最佳表现实例分别是基于SGD（0.832）、Adam（0.810）和AdamW（0.822）的模型。然而，AdamW模型在类别级性能上优于SGD模型。

Conclusion: 我们验证了所提出的功能能够为自动驾驶车辆找到合适的感知方式。研究结果支持使用所提出的感知模型来评估学习模型的效用，并确定合适的自动驾驶车辆感知。

Abstract: The driving environment perception has a vital role for autonomous driving
and nowadays has been actively explored for its realization. The research
community and relevant stakeholders necessitate the development of Deep
Learning (DL) models and AI-enabled solutions to enhance autonomous vehicles
(AVs) for smart mobility. There is a need to develop a model that accurately
perceives multiple objects on the road and predicts the driver's perception to
control the car's movements. This article proposes a novel utility-based
analytical model that enables perception systems of AVs to understand the
driving environment. The article consists of modules: acquiring a custom
dataset having distinctive objects, i.e., motorcyclists, rickshaws, etc; a
DL-based model (YOLOv8s) for object detection; and a module to measure the
utility of perception service from the performance values of trained model
instances. The perception model is validated based on the object detection
task, and its process is benchmarked by state-of-the-art deep learning models'
performance metrics from the nuScense dataset. The experimental results show
three best-performing YOLOv8s instances based on mAP@0.5 values, i.e.,
SGD-based (0.832), Adam-based (0.810), and AdamW-based (0.822). However, the
AdamW-based model (i.e., car: 0.921, motorcyclist: 0.899, truck: 0.793, etc.)
still outperforms the SGD-based model (i.e., car: 0.915, motorcyclist: 0.892,
truck: 0.781, etc.) because it has better class-level performance values,
confirmed by the proposed perception model. We validate that the proposed
function is capable of finding the right perception for AVs. The results above
encourage using the proposed perception model to evaluate the utility of
learning models and determine the appropriate perception for AVs.

</details>


### [217] [Learnable Game-theoretic Policy Optimization for Data-centric Self-explanation Rationalization](https://arxiv.org/abs/2510.13393)
*Yunxiao Zhao,Zhiqiang Wang,Xingtong Yu,Xiaoli Li,Jiye Liang,Ru Li*

Main category: cs.AI

TL;DR: 针对理性化方法的模式崩溃问题，提出了PORAT方法，通过策略干预优化游戏平衡，在多个数据集上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前的理性化方法面临模式崩溃问题，缺乏统一考虑，导致生成器不再探索新的策略，系统收敛于次优的游戏平衡状态。

Method: 提出了一种新的方法，称为面向博弈论策略优化的理性化（PORAT），逐步引入策略干预，解决合作游戏过程中的游戏平衡问题。

Result: 在九个广泛使用的真实世界数据集和两个合成环境中验证了该方法，PORAT相比现有最先进的方法性能提高了最高8.1%。

Conclusion: PORAT方法通过博弈论的视角重新审视合作理性化问题，解决了生成器模式崩溃导致的次优游戏平衡，验证了其可行性并取得了显著的性能提升。

Abstract: Rationalization, a data-centric framework, aims to build self-explanatory
models to explain the prediction outcome by generating a subset of
human-intelligible pieces of the input data. It involves a cooperative game
model where a generator generates the most human-intelligible parts of the
input (i.e., rationales), followed by a predictor that makes predictions based
on these generated rationales. Conventional rationalization methods typically
impose constraints via regularization terms to calibrate or penalize undesired
generation. However, these methods are suffering from a problem called mode
collapse, in which the predictor produces correct predictions yet the generator
consistently outputs rationales with collapsed patterns. Moreover, existing
studies are typically designed separately for specific collapsed patterns,
lacking a unified consideration. In this paper, we systematically revisit
cooperative rationalization from a novel game-theoretic perspective and
identify the fundamental cause of this problem: the generator no longer tends
to explore new strategies to uncover informative rationales, ultimately leading
the system to converge to a suboptimal game equilibrium (correct predictions
v.s collapsed rationales). To solve this problem, we then propose a novel
approach, Game-theoretic Policy Optimization oriented RATionalization (PORAT),
which progressively introduces policy interventions to address the game
equilibrium in the cooperative game process, thereby guiding the model toward a
more optimal solution state. We theoretically analyse the cause of such a
suboptimal equilibrium and prove the feasibility of the proposed method.
Furthermore, we validate our method on nine widely used real-world datasets and
two synthetic settings, where PORAT achieves up to 8.1% performance
improvements over existing state-of-the-art methods.

</details>


### [218] [Assessing LLM Reasoning Through Implicit Causal Chain Discovery in Climate Discourse](https://arxiv.org/abs/2510.13417)
*Liesbeth Allein,Nataly Pineda-Castañeda,Andrea Rocci,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 研究发现，大型语言模型在发现隐性因果链中的中间步骤时，主要依赖于模式匹配，但生成的链条逻辑一致性高。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型 (LLMs) 的机械因果推理能力，以通过隐性因果链发现任务回答因果关系的问题。

Method: 通过对因果链结构中给定的因果对进行分析，指示九个大型语言模型 (LLMs) 生成所有可能的中间因果步骤，以诊断地评估LLMs的机械因果推理能力。

Result: 分析表明，LLMs 在生成的因果步骤的数量和颗粒度上存在差异。尽管它们通常在生成的链条中保持自洽和对因果连接的信心，但主要依赖于关联模式匹配而非真正的因果推理。然而，人类评估确认了生成链的逻辑一致性和完整性。

Conclusion: 尽管LLMs主要依靠关联性而非真正因果推理，但研究为未来在论证环境中推进隐性机械因果推理奠定了基础。

Abstract: How does a cause lead to an effect, and which intermediate causal steps
explain their connection? This work scrutinizes the mechanistic causal
reasoning capabilities of large language models (LLMs) to answer these
questions through the task of implicit causal chain discovery. In a diagnostic
evaluation framework, we instruct nine LLMs to generate all possible
intermediate causal steps linking given cause-effect pairs in causal chain
structures. These pairs are drawn from recent resources in argumentation
studies featuring polarized discussion on climate change. Our analysis reveals
that LLMs vary in the number and granularity of causal steps they produce.
Although they are generally self-consistent and confident about the
intermediate causal connections in the generated chains, their judgments are
mainly driven by associative pattern matching rather than genuine causal
reasoning. Nonetheless, human evaluations confirmed the logical coherence and
integrity of the generated chains. Our baseline causal chain discovery
approach, insights from our diagnostic evaluation, and benchmark dataset with
causal chains lay a solid foundation for advancing future work in implicit,
mechanistic causal reasoning in argumentation settings.

</details>


### [219] [Confidence as a Reward: Transforming LLMs into Reward Models](https://arxiv.org/abs/2510.13501)
*He Du,Bowen Li,Chengxing Xie,Chang Gao,Kai Chen,Dacheng Tao*

Main category: cs.AI

TL;DR: 提出了无需训练的新方法CRew，通过token级信心作为奖赏，尤其适用于闭合任务，并且超越了许多经过训练的模型。


<details>
  <summary>Details</summary>
Motivation: 现有奖赏模型虽然能够提高大规模语言模型的推理能力，但通常需要大量的人工收集数据和昂贵的训练。

Method: 研究一种无需训练的方法CRew，通过模型最终答案的token级信心得分作为奖赏指标，特别适合用在封闭式任务上。

Result: 实验表明，CRew在MATH500和RewardMATH基准上的表现优于现有无训练奖赏方法，并且超过大部分训练过的奖赏模型。还发现CRew分数与模型实际推理性能之间有较强的相关性。

Conclusion: CRew-DPO训练策略进一步增强了模型评判能力，并且在性能上持续超越现有自我训练方法。

Abstract: Reward models can significantly enhance the reasoning capabilities of large
language models (LLMs), but they typically require extensive curated data and
costly training. To mitigate these challenges, training-free approaches such as
LLM-as-a-Judge leverage the intrinsic reasoning abilities of LLMs to evaluate
responses, achieving promising results. Recent works have also indicated that
model confidence can serve effectively as a reward metric, distinguishing
between chain-of-thought (CoT) and non-CoT paths. However, the concept of using
confidence as a reward has not been comprehensively studied. In this work, we
systematically investigate Confidence-as-a-Reward (CRew), a simple yet powerful
training-free method that utilizes token-level confidence in the model's final
answers as a proxy for reward, especially suitable for close-ended tasks.
Through extensive experiments on mathematical reasoning tasks, we demonstrate
that CRew outperforms existing training-free reward approaches on the MATH500
and RewardMATH benchmarks, and even surpasses most trained reward models. We
further identify a strong correlation between CRew scores and the actual
reasoning performance of the model. Additionally, we find that CRew can
effectively filter high-quality training data. Building upon these insights, we
propose CRew-DPO, a training strategy that constructs preference data from
confidence scores combined with correctness signals. Finetuning with CRew-DPO
further enhances the model's judging capabilities and consistently outperforms
existing self-training methods.

</details>


### [220] [A Modal Logic for Temporal and Jurisdictional Classifier Models](https://arxiv.org/abs/2510.13691)
*Cecilia Di Florio,Huimin Dong,Antonino Rotolo*

Main category: cs.AI

TL;DR: 本文引入了一种新的模态逻辑，用于捕捉法律案例推理并解决判例冲突。


<details>
  <summary>Details</summary>
Motivation: 利用基于逻辑的模型构建用于验证法律领域中使用的机器学习分类器的工具。

Method: 通过将案例的时间维度和法律体系中法院的层次结构引入逻辑以解决判例之间的冲突。

Result: 提出了一种用于正式捕捉法律CBR的分类器模态逻辑，解决了判例冲突问题。

Conclusion: 本文引入一种用于正式捕捉法律案例推理（CBR）的分类器模态逻辑。

Abstract: Logic-based models can be used to build verification tools for machine
learning classifiers employed in the legal field. ML classifiers predict the
outcomes of new cases based on previous ones, thereby performing a form of
case-based reasoning (CBR). In this paper, we introduce a modal logic of
classifiers designed to formally capture legal CBR. We incorporate principles
for resolving conflicts between precedents, by introducing into the logic the
temporal dimension of cases and the hierarchy of courts within the legal
system.

</details>


### [221] [Training LLM Agents to Empower Humans](https://arxiv.org/abs/2510.13709)
*Evan Ellis,Vivek Myers,Jens Tuyls,Sergey Levine,Anca Dragan,Benjamin Eysenbach*

Main category: cs.AI

TL;DR: 本文提出一种新的助理语言模型调优方法，称为Empower，该方法基于最大化人类的能动性（即人类在环境中施加所需变化的能力），仅需要离线文本数据即可实现自监督式的语言模型微调，从而更好地协助人类。通过18人用户研究和多回合代码协助环境的实验，证明Empower方法在增强用户体验和编程成功率方面显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前用于构建助理智能体的方法通常促使智能体独立完成任务，而非真正意义上协助人类实现其目标，并且这些方法一般需要昂贵的人工反馈。因此，需要一种能够在无需额外人工反馈的情况下，有效协助人类的调优方法。

Method: 本文提出了一种基于最大化人类能动性的助理语言模型调优方法Empower，该方法利用离线文本数据进行自监督的微调，并在18人用户研究和多回合代码协助实验中验证了该方法的有效性。

Result: 实验证实，参加实验的用户在使用Empower助理时有78%的偏好度（p=0.015），接受率提升31%，建议减少38%。在模拟人类程序员的挑战性编码问题上，相较于SFT基线，Empower训练的智能体能将人类程序员的成功率提升192%。

Conclusion: 通过最大化人类能动性的方法，可以提升助理智能体的能力，使其更有效地支持人类并提升任务成功率，而无需昂贵的人类反馈。这一方法能在不依赖额外人工反馈或可验证奖励的情况下，利用仅离线数据进行智能体微调，使其在大规模应用中更有用和对齐。

Abstract: Assistive agents should not only take actions on behalf of a human, but also
step out of the way and cede control when there are important decisions to be
made. However, current methods for building assistive agents, whether via
mimicking expert humans or via RL finetuning on an inferred reward, often
encourage agents to complete tasks on their own rather than truly assisting the
human attain their objectives. Additionally, these methods often require costly
explicit human feedback to provide a training signal. We propose a new approach
to tuning assistive language models based on maximizing the human's
empowerment, their ability to effect desired changes in the environment. Our
empowerment-maximizing method, Empower, only requires offline text data,
providing a self-supervised method for fine-tuning language models to better
assist humans. To study the efficacy of our approach, we conducted an 18-person
user study comparing our empowerment assistant with a strong baseline.
Participants preferred our assistant 78% of the time (p=0.015), with a 31%
higher acceptance rate and 38% fewer suggestions. Additionally, we introduce a
new environment for evaluating multi-turn code assistance using simulated
humans. Using this environment, we show that agents trained with Empower
increase the success rate of a simulated human programmer on challenging coding
questions by an average of 192% over an SFT baseline. With this empowerment
objective, we provide a framework for useful aligned AI agents at scale using
only offline data without the need for any additional human feedback or
verifiable rewards.

</details>


### [222] [Hard2Verify: A Step-Level Verification Benchmark for Open-Ended Frontier Math](https://arxiv.org/abs/2510.13744)
*Shrey Pandit,Austin Xu,Xuan-Phi Nguyen,Yifei Ming,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: 本文提出了一个名为Hard2Verify的基准，用于评估步骤级验证器，它要求验证器给出步骤级注释或发现生成模型的第一个错误。研究结果显示，开源验证器的表现不如封闭源模型。


<details>
  <summary>Details</summary>
Motivation: 为了在开放性和挑战性较大的环境中训练大型语言模型（LLM）推理系统，需要能够捕捉步骤级错误的强大验证器。这是由于LLM在国际数学奥林匹克竞赛（IMO 2025）中展示了优秀的表现，因此需要提高推理系统的准确性。

Method: 本文引入了一个名为Hard2Verify的基准，用于评估前沿LLM生成的响应中的步骤级错误。该基准是通过超过500小时的人类劳动注释而成，要求验证器能够提供步骤级注释或识别出生成的响应中的第一个错误。在研究中，评估了多种生成批评者和过程奖励模型的性能。

Result: 研究评估了29个生成批评者和过程奖励模型，发现开源验证器在验证能力上较封闭源模型有较大差距，尽管有少数开源模型表现突出。

Conclusion: 为了提高验证器的性能，需要深入分析影响步骤级验证性能的因素、扩展验证器计算能力的影响，以及自我验证和验证生成动态等基本问题。

Abstract: Large language model (LLM)-based reasoning systems have recently achieved
gold medal-level performance in the IMO 2025 competition, writing mathematical
proofs where, to receive full credit, each step must be not only correct but
also sufficiently supported. To train LLM-based reasoners in such challenging,
open-ended settings, strong verifiers capable of catching step-level mistakes
are necessary prerequisites. We introduce Hard2Verify, a human-annotated,
step-level verification benchmark produced with over 500 hours of human labor.
Hard2Verify is designed to rigorously assess step-level verifiers at the
frontier: Verifiers must provide step-level annotations or identify the first
error in responses generated by frontier LLMs for very recent, challenging, and
open-ended math questions. We evaluate 29 generative critics and process reward
models, demonstrating that, beyond a few standouts, open-source verifiers lag
closed source models. We subsequently analyze what drives poor performance in
step-level verification, the impacts of scaling verifier compute, as well as
fundamental questions such as self-verification and verification-generation
dynamics.

</details>

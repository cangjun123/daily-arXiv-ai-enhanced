<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 97]
- [cs.CL](#cs.CL) [Total: 28]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.HC](#cs.HC) [Total: 20]
- [cs.AI](#cs.AI) [Total: 9]
- [cs.LG](#cs.LG) [Total: 53]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Relightable and Dynamic Gaussian Avatar Reconstruction from Monocular Video](https://arxiv.org/abs/2512.09335)
*Seonghwa Choi,Moonkyeong Choi,Mingyu Jang,Jaekyung Kim,Jianfei Cai,Wen-Huang Cheng,Sanghoon Lee*

Main category: cs.CV

TL;DR: 基于3D高斯泼溅 (3DGS) 的可重光照动态人体化身建模框架 RnD-Avatar，通过学习动态蒙皮权重和额外形变，实现对高保真几何细节的准确姿态变形渲染，并支持任意光照条件下的真实感重光照。


<details>
  <summary>Details</summary>
Motivation: 现有基于神经辐射场 (NeRF) 和 3DGS 的方法从单目视频重建人体化身时，往往因缺乏与身体运动相关的几何细节（如衣物褶皱）而导致真实感不足，需要开发能够准确捕捉姿态依赖形变并支持重光照的解决方案。

Method: 提出动态蒙皮权重模型，基于姿态定义人体化身关节，同时学习由身体运动引起的额外形变；引入新颖的正则化方法，在稀疏视觉线索下捕捉精细几何细节；并使用新的多视角可变光照数据集进行评估。

Result: 实现了在视图合成、姿态渲染和重光照方面的最新先进性能，能够真实渲染新姿态和新视角，并在任意光照条件下支持照片级真实感光照效果。

Conclusion: RnD-Avatar 框架通过动态蒙皮权重和正则化技术，成功解决了高保真姿态变形和重光照问题，为可重光照和可动画人体化身建模提供了有效且表现优越的解决方案。

Abstract: Modeling relightable and animatable human avatars from monocular video is a long-standing and challenging task. Recently, Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3DGS) methods have been employed to reconstruct the avatars. However, they often produce unsatisfactory photo-realistic results because of insufficient geometrical details related to body motion, such as clothing wrinkles. In this paper, we propose a 3DGS-based human avatar modeling framework, termed as Relightable and Dynamic Gaussian Avatar (RnD-Avatar), that presents accurate pose-variant deformation for high-fidelity geometrical details. To achieve this, we introduce dynamic skinning weights that define the human avatar's articulation based on pose while also learning additional deformations induced by body motion. We also introduce a novel regularization to capture fine geometric details under sparse visual cues. Furthermore, we present a new multi-view dataset with varied lighting conditions to evaluate relight. Our framework enables realistic rendering of novel poses and views while supporting photo-realistic lighting effects under arbitrary lighting conditions. Our method achieves state-of-the-art performance in novel view synthesis, novel pose rendering, and relighting.

</details>


### [2] [Composing Concepts from Images and Videos via Concept-prompt Binding](https://arxiv.org/abs/2512.09824)
*Xianghao Kong,Zeyu Zhang,Yuwei Guo,Zhuoran Zhao,Songchun Zhang,Anyi Rao*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Visual concept composition, which aims to integrate different elements from images and videos into a single, coherent visual output, still falls short in accurately extracting complex concepts from visual inputs and flexibly combining concepts from both images and videos. We introduce Bind & Compose, a one-shot method that enables flexible visual concept composition by binding visual concepts with corresponding prompt tokens and composing the target prompt with bound tokens from various sources. It adopts a hierarchical binder structure for cross-attention conditioning in Diffusion Transformers to encode visual concepts into corresponding prompt tokens for accurate decomposition of complex visual concepts. To improve concept-token binding accuracy, we design a Diversify-and-Absorb Mechanism that uses an extra absorbent token to eliminate the impact of concept-irrelevant details when training with diversified prompts. To enhance the compatibility between image and video concepts, we present a Temporal Disentanglement Strategy that decouples the training process of video concepts into two stages with a dual-branch binder structure for temporal modeling. Evaluations demonstrate that our method achieves superior concept consistency, prompt fidelity, and motion quality over existing approaches, opening up new possibilities for visual creativity.

</details>


### [3] [What Happens When: Learning Temporal Orders of Events in Videos](https://arxiv.org/abs/2512.08979)
*Daechul Ahn,Yura Choi,Hyeonbeom Choi,Seongwon Cho,San Kim,Jonghyun Choi*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Video Large Multimodal Models (VLMMs) have shown impressive performance in video understanding, yet their ability to accurately capture the temporal order of multiple events remains underexplored. We interestingly observe that, even when video frames are scrambled, models perform very well on the existing benchmarks by comprehensive experiments. This implies that VLMMs may not necessarily rely on accurate sequential processing of visual events, but instead depend on prior knowledge of typical scenarios to answer the question. To benchmark temporal understanding capabilities in VLMMs, we propose VECTOR, designed to explicitly assess a model's ability to identify the temporal order of events. On this benchmark, we observe that various VLMMs often fail to understand the orders of events. To address this, we propose MECOT (Multi-Event instruction fine-tuning with Chain-of-Thought), which (1) trains models on detailed, event-by-event video descriptions and (2) using chain-of-thought prompts at inference to enhance temporal awareness. MECOT outperforms prior arts on VECTOR as well as improving performance on existing video benchmarks, implying effectiveness of temporal understanding. We release our code, model and datasets.

</details>


### [4] [Training Multi-Image Vision Agents via End2End Reinforcement Learning](https://arxiv.org/abs/2512.08980)
*Chengqi Dong,Chuhuai Yue,Hang He,Rongge Mao,Fenghe Tang,S Kevin Zhou,Zekun Xu,Xiaohan Wang,Jiajun Chai,Wei Lin,Guojun Yin*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent VLM-based agents aim to replicate OpenAI O3's ``thinking with images" via tool use, but most open-source methods limit input to a single image, falling short on real-world multi-image QA tasks. To address this, we propose IMAgent, an open-source vision agent trained via end-to-end reinforcement learning dedicated for complex multi-image tasks. By leveraging a multi-agent system, we generate challenging and visually-rich multi-image QA pairs to fully activate the tool-use potential of the base VLM. Through manual verification, we obtain MIFG-QA, comprising 10k samples for training and evaluation. With deeper reasoning steps, VLMs may increasingly ignore visual inputs. We therefore develop two specialized tools for visual reflection and confirmation, allowing the model to proactively reallocate its attention to image content during inference. Benefiting from our well-designed action-trajectory two-level mask strategy, IMAgent achieves stable tool use behavior via pure RL training without requiring costly supervised fine-tuning data. Extensive experiments demonstrate that IMAgent maintains strong performance on existing single-image benchmarks while achieving substantial improvements on our proposed multi-image dataset, with our analysis providing actionable insights for the research community. Codes and data will be released soon.

</details>


### [5] [Mitigating Bias with Words: Inducing Demographic Ambiguity in Face Recognition Templates by Text Encoding](https://arxiv.org/abs/2512.08981)
*Tahar Chettaoui,Naser Damer,Fadi Boutros*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Face recognition (FR) systems are often prone to demographic biases, partially due to the entanglement of demographic-specific information with identity-relevant features in facial embeddings. This bias is extremely critical in large multicultural cities, especially where biometrics play a major role in smart city infrastructure. The entanglement can cause demographic attributes to overshadow identity cues in the embedding space, resulting in disparities in verification performance across different demographic groups. To address this issue, we propose a novel strategy, Unified Text-Image Embedding (UTIE), which aims to induce demographic ambiguity in face embeddings by enriching them with information related to other demographic groups. This encourages face embeddings to emphasize identity-relevant features and thus promotes fairer verification performance across groups. UTIE leverages the zero-shot capabilities and cross-modal semantic alignment of Vision-Language Models (VLMs). Given that VLMs are naturally trained to align visual and textual representations, we enrich the facial embeddings of each demographic group with text-derived demographic features extracted from other demographic groups. This encourages a more neutral representation in terms of demographic attributes. We evaluate UTIE using three VLMs, CLIP, OpenCLIP, and SigLIP, on two widely used benchmarks, RFW and BFW, designed to assess bias in FR. Experimental results show that UTIE consistently reduces bias metrics while maintaining, or even improving in several cases, the face verification accuracy.

</details>


### [6] [Consist-Retinex: One-Step Noise-Emphasized Consistency Training Accelerates High-Quality Retinex Enhancement](https://arxiv.org/abs/2512.08982)
*Jian Xu,Wei Chen,Shigui Li,Delu Zeng,John Paisley,Qibin Zhao*

Main category: cs.CV

TL;DR: 提出了Consist-Retinex框架，首次将一致性模型应用于Retinex低光增强，实现了单步采样的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决了扩散模型在光图像增强中采样步骤过多导致的实时性限制，填补了当前一致性模型在条件性增强任务中的应用空白。

Method: 1) 提出双目标一致性损失，结合时间一致性和真值对齐；2) 提出自适应噪声强调采样策略，针对大噪声区域训练。

Result: 在VE-LOL-L数据集上，相比Diff-Retinex++，PSNR从23.41提升至25.51，FID从49.59降至44.73，训练成本仅为传统1000步方法的1/8。

Conclusion: Consist-Retinex通过创新的损失函数和采样策略，实现了高效率、高质量的弱光图像增强，为条件性图像处理任务开辟了新方向。

Abstract: Diffusion models have achieved remarkable success in low-light image enhancement through Retinex-based decomposition, yet their requirement for hundreds of iterative sampling steps severely limits practical deployment. While recent consistency models offer promising one-step generation for \textit{unconditional synthesis}, their application to \textit{conditional enhancement} remains unexplored. We present \textbf{Consist-Retinex}, the first framework adapting consistency modeling to Retinex-based low-light enhancement. Our key insight is that conditional enhancement requires fundamentally different training dynamics than unconditional generation standard consistency training focuses on low-noise regions near the data manifold, while conditional mapping critically depends on large-noise regimes that bridge degraded inputs to enhanced outputs. We introduce two core innovations: (1) a \textbf{dual-objective consistency loss} combining temporal consistency with ground-truth alignment under randomized time sampling, providing full-spectrum supervision for stable convergence; and (2) an \textbf{adaptive noise-emphasized sampling strategy} that prioritizes training on large-noise regions essential for one-step conditional generation. On VE-LOL-L, Consist-Retinex achieves \textbf{state-of-the-art performance with single-step sampling} (\textbf{PSNR: 25.51 vs. 23.41, FID: 44.73 vs. 49.59} compared to Diff-Retinex++), while requiring only \textbf{1/8 of the training budget} relative to the 1000-step Diff-Retinex baseline.

</details>


### [7] [HSCP: A Two-Stage Spectral Clustering Framework for Resource-Constrained UAV Identification](https://arxiv.org/abs/2512.08983)
*Maoyu Wang,Yao Lu,Bo Zhou,Zhuangzhi Chen,Yun Lin,Qi Xuan,Guan Gui*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: With the rapid development of Unmanned Aerial Vehicles (UAVs) and the increasing complexity of low-altitude security threats, traditional UAV identification methods struggle to extract reliable signal features and meet real-time requirements in complex environments. Recently, deep learning based Radio Frequency Fingerprint Identification (RFFI) approaches have greatly improved recognition accuracy. However, their large model sizes and high computational demands hinder deployment on resource-constrained edge devices. While model pruning offers a general solution for complexity reduction, existing weight, channel, and layer pruning techniques struggle to concurrently optimize compression rate, hardware acceleration, and recognition accuracy. To this end, in this paper, we introduce HSCP, a Hierarchical Spectral Clustering Pruning framework that combines layer pruning with channel pruning to achieve extreme compression, high performance, and efficient inference. In the first stage, HSCP employs spectral clustering guided by Centered Kernel Alignment (CKA) to identify and remove redundant layers. Subsequently, the same strategy is applied to the channel dimension to eliminate a finer redundancy. To ensure robustness, we further employ a noise-robust fine-tuning strategy. Experiments on the UAV-M100 benchmark demonstrate that HSCP outperforms existing channel and layer pruning methods. Specifically, HSCP achieves $86.39\%$ parameter reduction and $84.44\%$ FLOPs reduction on ResNet18 while improving accuracy by $1.49\%$ compared to the unpruned baseline, and maintains superior robustness even in low signal-to-noise ratio environments.

</details>


### [8] [RAG-HAR: Retrieval Augmented Generation-based Human Activity Recognition](https://arxiv.org/abs/2512.08984)
*Nirhoshan Sivaroopan,Hansi Karunarathna,Chamara Madarasingha,Anura Jayasumana,Kanchana Thilakarathna*

Main category: cs.CV

TL;DR: RAG-HAR是一個免訓練的檢索增強框架，利用大型語言模型進行人類活動識別，在六個基準測試中取得最先進性能，並且能夠識別未知活動。


<details>
  <summary>Details</summary>
Motivation: 現有的人類活動識別方法需要針對特定數據集進行訓練、大量標註數據和顯著計算資源，限制了實用性。

Method: 採用輕量級統計描述符計算，從向量數據庫檢索語義相似樣本，利用這些上下文證據進行LLM活動識別，並通過提示優化和LLM生成上下文增強描述符來改進系統。

Result: 在六個不同的人類活動識別基準測試中實現了最先進的性能，無需模型訓練或微調。

Conclusion: RAG-HAR框架不僅在現有活動識別上表現優異，還能識別和有意義地標記多個未知人類活動，突顯其魯棒性和實際應用價值。

Abstract: Human Activity Recognition (HAR) underpins applications in healthcare, rehabilitation, fitness tracking, and smart environments, yet existing deep learning approaches demand dataset-specific training, large labeled corpora, and significant computational resources.We introduce RAG-HAR, a training-free retrieval-augmented framework that leverages large language models (LLMs) for HAR. RAG-HAR computes lightweight statistical descriptors, retrieves semantically similar samples from a vector database, and uses this contextual evidence to make LLM-based activity identification. We further enhance RAG-HAR by first applying prompt optimization and introducing an LLM-based activity descriptor that generates context-enriched vector databases for delivering accurate and highly relevant contextual information. Along with these mechanisms, RAG-HAR achieves state-of-the-art performance across six diverse HAR benchmarks. Most importantly, RAG-HAR attains these improvements without requiring model training or fine-tuning, emphasizing its robustness and practical applicability. RAG-HAR moves beyond known behaviors, enabling the recognition and meaningful labelling of multiple unseen human activities.

</details>


### [9] [An Efficient Test-Time Scaling Approach for Image Generation](https://arxiv.org/abs/2512.08985)
*Vignesh Sundaresha,Akash Haridas,Vikram Appia,Lav Varshney*

Main category: cs.CV

TL;DR: 本文提出了一种通过有效重新分配测试时计算资源来提升图像生成模型效率的新方法


<details>
  <summary>Details</summary>
Motivation: 尽管测试时计算和推理已帮助语言模型提升能力，但在图像生成领域，特别是在噪声样本搜索方面的工作，虽已显示与测试时计算的良好扩展性，但现有方法依赖贪婪算法，未能有效分配计算预算。

Method: 提出Verifier-Threshold方法，能够自动重新分配测试时计算资源，优化计算预算在不同去噪步骤间的分配。

Result: 在GenEval基准测试上，达到相同性能的同时，比现有最佳方法的计算时间减少了2-4倍。

Conclusion: 该方法显著提升了图像生成的效率，为大生成模型在图像生成应用中的计算资源优化提供了有效解决方案。

Abstract: Image generation has emerged as a mainstream application of large generative AI models. Just as test-time compute and reasoning have helped language models improve their capabilities, similar benefits have also been observed with image generation models. In particular, searching over noise samples for diffusion and flow models has shown to scale well with test-time compute. While recent works have explored allocating non-uniform inference-compute budgets across different denoising steps, they rely on greedy algorithms and allocate the compute budget ineffectively. In this work, we study this problem and propose solutions to fix it. We propose the Verifier-Threshold method which automatically reallocates test-time compute and delivers substantial efficiency improvements. For the same performance on the GenEval benchmark, we achieve a 2-4x reduction in computational time over the state-of-the-art method.

</details>


### [10] [Explainable Fundus Image Curation and Lesion Detection in Diabetic Retinopathy](https://arxiv.org/abs/2512.08986)
*Anca Mihai,Adrian Groza*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Diabetic Retinopathy (DR) affects individuals with long-term diabetes. Without early diagnosis, DR can lead to vision loss. Fundus photography captures the structure of the retina along with abnormalities indicative of the stage of the disease. Artificial Intelligence (AI) can support clinicians in identifying these lesions, reducing manual workload, but models require high-quality annotated datasets. Due to the complexity of retinal structures, errors in image acquisition and lesion interpretation of manual annotators can occur. We proposed a quality-control framework, ensuring only high-standard data is used for evaluation and AI training. First, an explainable feature-based classifier is used to filter inadequate images. The features are extracted both using image processing and contrastive learning. Then, the images are enhanced and put subject to annotation, using deep-learning-based assistance. Lastly, the agreement between annotators calculated using derived formulas determines the usability of the annotations.

</details>


### [11] [3DID: Direct 3D Inverse Design for Aerodynamics with Physics-Aware Optimization](https://arxiv.org/abs/2512.08987)
*Yuze Hao,Linchao Zhu,Yi Yang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Inverse design aims to design the input variables of a physical system to optimize a specified objective function, typically formulated as a search or optimization problem. However, in 3D domains, the design space grows exponentially, rendering exhaustive grid-based searches infeasible. Recent advances in deep learning have accelerated inverse design by providing powerful generative priors and differentiable surrogate models. Nevertheless, current methods tend to approximate the 3D design space using 2D projections or fine-tune existing 3D shapes. These approaches sacrifice volumetric detail and constrain design exploration, preventing true 3D design from scratch. In this paper, we propose a 3D Inverse Design (3DID) framework that directly navigates the 3D design space by coupling a continuous latent representation with a physics-aware optimization strategy. We first learn a unified physics-geometry embedding that compactly captures shape and physical field data in a continuous latent space. Then, we introduce a two-stage strategy to perform physics-aware optimization. In the first stage, a gradient-guided diffusion sampler explores the global latent manifold. In the second stage, an objective-driven, topology-preserving refinement further sculpts each candidate toward the target objective. This enables 3DID to generate high-fidelity 3D geometries, outperforming existing methods in both solution quality and design versatility.

</details>


### [12] [Deterministic World Models for Verification of Closed-loop Vision-based Systems](https://arxiv.org/abs/2512.08991)
*Yuang Geng,Zhuoyang Zhou,Zhongzheng Zhang,Siyuan Pan,Hoang-Dung Tran,Ivan Ruchkin*

Main category: cs.CV

TL;DR: 提出确定性世界模型代替生成模型用于视觉闭环控制系统验证，消除随机潜变量导致的过近似误差。


<details>
  <summary>Details</summary>
Motivation: 基于视觉的闭环控制系统验证存在挑战，因为图像维度高且视觉环境难以建模。使用生成模型作为相机替代存在随机潜变量引入的过近似误差，限制了验证精度。

Method: 提出确定性世界模型，直接将系统状态映射到生成图像，消除不可解释的潜变量。采用双目标损失函数，结合像素级重建精度和控制差异损失。集成到StarV验证流程，并使用保形预测推导世界模型与实际系统间的轨迹偏差统计边界。

Result: 在标准基准测试中，该方法获得了比潜变量基线更紧致的可达集和更好的验证性能。

Conclusion: 确定性世界模型能有效提高基于视觉控制系统的验证精度，减少过近似误差，比传统生成模型方法表现更优。

Abstract: Verifying closed-loop vision-based control systems remains a fundamental challenge due to the high dimensionality of images and the difficulty of modeling visual environments. While generative models are increasingly used as camera surrogates in verification, their reliance on stochastic latent variables introduces unnecessary overapproximation error. To address this bottleneck, we propose a Deterministic World Model (DWM) that maps system states directly to generative images, effectively eliminating uninterpretable latent variables to ensure precise input bounds. The DWM is trained with a dual-objective loss function that combines pixel-level reconstruction accuracy with a control difference loss to maintain behavioral consistency with the real system. We integrate DWM into a verification pipeline utilizing Star-based reachability analysis (StarV) and employ conformal prediction to derive rigorous statistical bounds on the trajectory deviation between the world model and the actual vision-based system. Experiments on standard benchmarks show that our approach yields significantly tighter reachable sets and better verification performance than a latent-variable baseline.

</details>


### [13] [Demo: Generative AI helps Radiotherapy Planning with User Preference](https://arxiv.org/abs/2512.08996)
*Riqiang Gao,Simon Arberet,Martin Kraus,Han Liu,Wilko FAR Verbakel,Dorin Comaniciu,Florin-Cristian Ghesu,Ali Kamen*

Main category: cs.CV

TL;DR: 提出仅基于用户偏好（而非参考计划）预测3D放疗剂量分布的生成模型，支持灵活OAR与PTV权衡，集成临床系统且在某些场景超越Varian RapidPlan。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习依赖参考计划作为真值，易导致模型偏向特定机构或计划风格；需更灵活、个性化且无偏的方法。

Method: 基于用户定义偏好（如OAR与PTV权衡优先级）的生成模型，不依赖固定参考计划，可集成至临床治疗计划系统。

Result: 对比评估显示，本方法在某些场景下超越Varian RapidPlan，在适应性与计划质量上表现更优。

Conclusion: 用户偏好驱动的生成模型可提供灵活、个性化的放疗计划，减少机构偏好偏差，并有效集成至临床工作流。

Abstract: Radiotherapy planning is a highly complex process that often varies significantly across institutions and individual planners. Most existing deep learning approaches for 3D dose prediction rely on reference plans as ground truth during training, which can inadvertently bias models toward specific planning styles or institutional preferences. In this study, we introduce a novel generative model that predicts 3D dose distributions based solely on user-defined preference flavors. These customizable preferences enable planners to prioritize specific trade-offs between organs-at-risk (OARs) and planning target volumes (PTVs), offering greater flexibility and personalization. Designed for seamless integration with clinical treatment planning systems, our approach assists users in generating high-quality plans efficiently. Comparative evaluations demonstrate that our method can surpasses the Varian RapidPlan model in both adaptability and plan quality in some scenarios.

</details>


### [14] [Diffusion Model Regularized Implicit Neural Representation for CT Metal Artifact Reduction](https://arxiv.org/abs/2512.08999)
*Jie Wen,Chenhe Du,Xiao Wang,Yuyao Zhang*

Main category: cs.CV

TL;DR: 提出基于扩散模型正则化的隐式神经表示框架用于金属伪影减少，结合物理约束与数据保真，预训练扩散模型提供先验知识，实验验证有效性和泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有有监督方法依赖有限配对数据导致性能不稳定；无监督方法存在两个主要挑战：1) 未有效将CT物理几何约束融入伪影消除过程以确保数据保真；2) 传统启发式正则项无法充分利用可用先验知识

Method: 提出扩散模型正则化的隐式神经表示框架，隐式神经表征整合物理约束并施加数据保真，预训练扩散模型提供先验知识来正则化解决方案

Result: 在仿真和临床数据上的实验结果表明该方法具有有效性和泛化能力

Conclusion: 该方法突显了在临床环境中应用的潜力

Abstract: Computed tomography (CT) images are often severely corrupted by artifacts in the presence of metals. Existing supervised metal artifact reduction (MAR) approaches suffer from performance instability on known data due to their reliance on limited paired metal-clean data, which limits their clinical applicability. Moreover, existing unsupervised methods face two main challenges: 1) the CT physical geometry is not effectively incorporated into the MAR process to ensure data fidelity; 2) traditional heuristics regularization terms cannot fully capture the abundant prior knowledge available. To overcome these shortcomings, we propose diffusion model regularized implicit neural representation framework for MAR. The implicit neural representation integrates physical constraints and imposes data fidelity, while the pre-trained diffusion model provides prior knowledge to regularize the solution. Experimental results on both simulated and clinical data demonstrate the effectiveness and generalization ability of our method, highlighting its potential to be applied to clinical settings.

</details>


### [15] [A Physics-Constrained, Design-Driven Methodology for Defect Dataset Generation in Optical Lithography](https://arxiv.org/abs/2512.09001)
*Yuehua Hu,Jiyeong Kong,Dong-yeol Shin,Jaekyun Kim,Kyung-Tae Kang*

Main category: cs.CV

TL;DR: 该研究提出了一种为微纳制造缺陷检测生成大规模、物理有效数据集的新方法，结合数学形态学合成缺陷布局、DMD光刻物理制造和光学显微图像采集，构建了包含13,365个标注实例的4类缺陷数据集，并在Mask R-CNN上实现了显著优于Faster R-CNN的检测精度。


<details>
  <summary>Details</summary>
Motivation: AI在微纳制造缺陷检测中的应用受限于高质量物理基础训练数据的稀缺，特别是半导体行业光刻缺陷数据难以获取，缺乏公开数据集。

Method: 研究提出从原始设计布局出发，通过可控的数学形态学操作（腐蚀和膨胀）合成缺陷布局，然后使用DMD光刻技术制造物理样品，采集光学显微图像并与其无缺陷参考图像对比，生成像素级标注的缺陷数据集。

Result: 构建了包含3,530张光学显微图像、13,365个标注实例的数据集，涵盖桥接、毛刺、收缩和污染四类缺陷。Mask R-CNN在bridge、burr、pinch类上的AP@0.5分别达到0.980、0.965、0.971，比Faster R-CNN平均提升约34%；在污染类上提升了约42%。

Conclusion: 该研究方法能够生成像素级标注的缺陷数据集，为半导体制造中基于AI的测量/检测提供了可行的解决方案，验证了该方法在提升缺陷检测精度方面的有效性。

Abstract: The efficacy of Artificial Intelligence (AI) in micro/nano manufacturing is fundamentally constrained by the scarcity of high-quality and physically grounded training data for defect inspection. Lithography defect data from semiconductor industry are rarely accessible for research use, resulting in a shortage of publicly available datasets. To address this bottleneck in lithography, this study proposes a novel methodology for generating large-scale, physically valid defect datasets with pixel-level annotations. The framework begins with the ab initio synthesis of defect layouts using controllable, physics-constrained mathematical morphology operations (erosion and dilation) applied to the original design-level layout. These synthesized layouts, together with their defect-free counterparts, are fabricated into physical samples via high-fidelity digital micromirror device (DMD)-based lithography. Optical micrographs of the synthesized defect samples and their defect-free references are then compared to create consistent defect delineation annotations. Using this methodology, we constructed a comprehensive dataset of 3,530 Optical micrographs containing 13,365 annotated defect instances including four classes: bridge, burr, pinch, and contamination. Each defect instance is annotated with a pixel-accurate segmentation mask, preserving full contour and geometry. The segmentation-based Mask R-CNN achieves AP@0.5 of 0.980, 0.965, and 0.971, compared with 0.740, 0.719, and 0.717 for Faster R-CNN on bridge, burr, and pinch classes, representing a mean AP@0.5 improvement of approximately 34%. For the contamination class, Mask R-CNN achieves an AP@0.5 roughly 42% higher than Faster R-CNN. These consistent gains demonstrate that our proposed methodology to generate defect datasets with pixel-level annotations is feasible for robust AI-based Measurement/Inspection (MI) in semiconductor fabrication.

</details>


### [16] [A Survey of Body and Face Motion: Datasets, Performance Evaluation Metrics and Generative Techniques](https://arxiv.org/abs/2512.09005)
*Lownish Rai Sookha,Nikhil Pakhale,Mudasir Ganaie,Abhinav Dhall*

Main category: cs.CV

TL;DR: 关于面部和身体运动生成的综述，涵盖核心概念、表征技术、生成方法、数据集和评估指标，首次全面整合身体与面部运动生成研究。


<details>
  <summary>Details</summary>
Motivation: 身体和面部运动在交流中起关键作用，但生成具有表现力且协调的面部和身体动态仍然具有挑战性，因为存在语言/非语言线索与个体特征的复杂相互作用。

Method: 通过文献综述的方式，系统性地整理了身体与面部运动生成领域的核心概念、表示技术、生成方法、数据集和评估指标。

Result: 该综述建立了该领域的系统框架，识别了现有方法和数据集的现状，并提供了开源资源网站。

Conclusion: 这项工作填补了身体与面部运动生成综合综述的空白，未来方向应集中在提高二元交互场景中虚拟形象的逼真度、连贯性和表现力。

Abstract: Body and face motion play an integral role in communication. They convey crucial information on the participants. Advances in generative modeling and multi-modal learning have enabled motion generation from signals such as speech, conversational context and visual cues. However, generating expressive and coherent face and body dynamics remains challenging due to the complex interplay of verbal / non-verbal cues and individual personality traits. This survey reviews body and face motion generation, covering core concepts, representations techniques, generative approaches, datasets and evaluation metrics. We highlight future directions to enhance the realism, coherence and expressiveness of avatars in dyadic settings. To the best of our knowledge, this work is the first comprehensive review to cover both body and face motion. Detailed resources are listed on https://lownish23csz0010.github.io/mogen/.

</details>


### [17] [Towards Lossless Ultimate Vision Token Compression for VLMs](https://arxiv.org/abs/2512.09010)
*Dehua Zheng,Mouxiao Huang,Borui Jiang,Hailin Hu,Xinghao Chen*

Main category: cs.CV

TL;DR: LUVC框架通过视觉编码器迭代合并和LLM频谱修剪，逐步压缩消除视觉冗余token，在保留精度的同时实现2倍加速。


<details>
  <summary>Details</summary>
Motivation: 高分辨率图像/视频的视觉token存在大量冗余，现有的注意力/相似度压缩方法存在位置偏差和类别不平衡问题，且在浅层LLM层泛化能力差。

Method: 1. 视觉编码器：采用空间轴正交的迭代合并方案压缩token。2. LLM集成：引入无注意力/相似度的低通滤波器作为频谱修剪单元，逐步剪枝冗余视觉token，兼容FlashAttention。3. LUVC框架：系统压缩视觉token，最终层完全消除，让高维视觉特征逐步融入多模态查询。

Result: 实验表明LUVC在语言模型中实现2倍推理加速，精度损失可忽略，且无需训练即可部署到多种VLM。

Conclusion: LUVC通过系统化视觉token压缩，有效解决了视觉语言模型的计算效率和延迟问题，具有广泛部署的潜力。

Abstract: Visual language models encounter challenges in computational efficiency and latency, primarily due to the substantial redundancy in the token representations of high-resolution images and videos. Current attention/similarity-based compression algorithms suffer from either position bias or class imbalance, leading to significant accuracy degradation. They also fail to generalize to shallow LLM layers, which exhibit weaker cross-modal interactions. To address this, we extend token compression to the visual encoder through an effective iterative merging scheme that is orthogonal in spatial axes to accelerate the computation across the entire VLM. Furthermoer, we integrate a spectrum pruning unit into LLM through an attention/similarity-free low-pass filter, which gradually prunes redundant visual tokens and is fully compatible to modern FlashAttention. On this basis, we propose Lossless Ultimate Vision tokens Compression (LUVC) framework. LUVC systematically compresses visual tokens until complete elimination at the final layer of LLM, so that the high-dimensional visual features are gradually fused into the multimodal queries. The experiments show that LUVC achieves a 2 speedup inference in language model with negligible accuracy degradation, and the training-free characteristic enables immediate deployment across multiple VLMs.

</details>


### [18] [ConceptPose: Training-Free Zero-Shot Object Pose Estimation using Concept Vectors](https://arxiv.org/abs/2512.09056)
*Liming Kuang,Yordanka Velikova,Mahdi Saleh,Jan-Nico Zaech,Danda Pani Paudel,Benjamin Busam*

Main category: cs.CV

TL;DR: ConceptPose是一个无需训练、无需模型的零样本6D物体姿态估计框架，利用视觉语言模型创建开放词汇3D概念图，通过3D-3D对应实现精准姿态估计，在基准测试中性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的物体姿态估计方法通常需要大量特定数据集的训练，而大规模视觉语言模型展现出强大的零样本能力。本研究旨在将这两个领域结合，开发无需训练即可进行姿态估计的方法。

Method: 利用视觉语言模型(VLM)生成开放词汇的3D概念图，其中每个点都被来自显著性图的语义概念向量标记。通过建立概念图之间的鲁棒3D-3D对应关系，实现6自由度相对姿态的精确估计。

Result: 在零样本相对姿态估计基准测试中，该方法在ADD(-S)得分上显著超越现有方法62%以上，包括那些使用了大量数据集特定训练的方法，取得了最先进的性能。

Conclusion: ConceptPose框架成功实现了无需训练和模型的零样本姿态估计，证明了视觉语言模型在3D场景理解中的潜力，为灵活、通用的物体姿态估计提供了新的解决方案。

Abstract: Object pose estimation is a fundamental task in computer vision and robotics, yet most methods require extensive, dataset-specific training. Concurrently, large-scale vision language models show remarkable zero-shot capabilities. In this work, we bridge these two worlds by introducing ConceptPose, a framework for object pose estimation that is both training-free and model-free. ConceptPose leverages a vision-language-model (VLM) to create open-vocabulary 3D concept maps, where each point is tagged with a concept vector derived from saliency maps. By establishing robust 3D-3D correspondences across concept maps, our approach allows precise estimation of 6DoF relative pose. Without any object or dataset-specific training, our approach achieves state-of-the-art results on common zero shot relative pose estimation benchmarks, significantly outperforming existing methods by over 62% in ADD(-S) score, including those that utilize extensive dataset-specific training.

</details>


### [19] [SIP: Site in Pieces- A Dataset of Disaggregated Construction-Phase 3D Scans for Semantic Segmentation and Scene Understanding](https://arxiv.org/abs/2512.09062)
*Seongyong Kim,Yong Kwon Cho*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate 3D scene interpretation in active construction sites is essential for progress monitoring, safety assessment, and digital twin development. LiDAR is widely used in construction because it offers advantages over camera-based systems, performing reliably in cluttered and dynamically changing conditions. Yet most public datasets for 3D perception are derived from densely fused scans with uniform sampling and complete visibility, conditions that do not reflect real construction sites. Field data are often collected as isolated single-station LiDAR views, constrained by safety requirements, limited access, and ongoing operations. These factors lead to radial density decay, fragmented geometry, and view-dependent visibility-characteristics that remain underrepresented in existing datasets. This paper presents SIP, Site in Pieces, a dataset created to reflect the practical constraints of LiDAR acquisition during construction. SIP provides indoor and outdoor scenes captured with a terrestrial LiDAR scanner and annotated at the point level using a taxonomy tailored to construction environments: A. Built Environment, B. Construction Operations, and C. Site Surroundings. The dataset includes both structural components and slender temporary objects such as scaffolding, MEP piping, and scissor lifts, where sparsity caused by occlusion and fragmented geometry make segmentation particularly challenging. The scanning protocol, annotation workflow, and quality control procedures establish a consistent foundation for the dataset. SIP is openly available with a supporting Git repository, offering adaptable class configurations that streamline adoption within modern 3D deep learning frameworks. By providing field data that retain real-world sensing characteristics, SIP enables robust benchmarking and contributes to advancing construction-oriented 3D vision tasks.

</details>


### [20] [KD-OCT: Efficient Knowledge Distillation for Clinical-Grade Retinal OCT Classification](https://arxiv.org/abs/2512.09069)
*Erfan Nourbakhsh,Nasrin Sanjari,Ali Nourbakhsh*

Main category: cs.CV

TL;DR: 提出了一种名为KD-OCT的新型知识蒸馏框架，通过知识蒸馏方法将高性能的ConvNeXtV2-Large教师模型压缩为轻量级EfficientNet-B2学生模型，用于AMD和CNV相关的OCT图像分类。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习模型如ConvNeXtV2-Large在AMD和CNV的早期检测中表现优异，但其高计算需求阻碍了在临床环境中的实时部署。因此，需要开发既能保持高诊断性能又能实现实时部署的高效模型。

Method: KD-OCT采用实时蒸馏策略，结合软教师知识迁移和硬真实监督的混合损失函数。教师模型使用高级数据增强、随机权重平均和焦点损失进行增强，然后通过知识蒸馏压缩到轻量级的学生模型。方法在Noor Eye Hospital数据集上使用患者级交叉验证进行评估。

Result: 实验结果表明，KD-OCT在多尺度或特征融合OCT分类器中，在效率和准确性平衡方面表现优异，达到了接近教师模型的性能，同时显著减少了模型大小和推理时间。尽管经过压缩，学生模型的性能仍超过大多数现有框架。

Conclusion: KD-OCT框架成功地将高性能模型压缩为轻量级版本，促进了AMD筛查的边缘部署，为实现实时临床诊断应用提供了可行的解决方案。

Abstract: Age-related macular degeneration (AMD) and choroidal neovascularization (CNV)-related conditions are leading causes of vision loss worldwide, with optical coherence tomography (OCT) serving as a cornerstone for early detection and management. However, deploying state-of-the-art deep learning models like ConvNeXtV2-Large in clinical settings is hindered by their computational demands. Therefore, it is desirable to develop efficient models that maintain high diagnostic performance while enabling real-time deployment. In this study, a novel knowledge distillation framework, termed KD-OCT, is proposed to compress a high-performance ConvNeXtV2-Large teacher model, enhanced with advanced augmentations, stochastic weight averaging, and focal loss, into a lightweight EfficientNet-B2 student for classifying normal, drusen, and CNV cases. KD-OCT employs real-time distillation with a combined loss balancing soft teacher knowledge transfer and hard ground-truth supervision. The effectiveness of the proposed method is evaluated on the Noor Eye Hospital (NEH) dataset using patient-level cross-validation. Experimental results demonstrate that KD-OCT outperforms comparable multi-scale or feature-fusion OCT classifiers in efficiency- accuracy balance, achieving near-teacher performance with substantial reductions in model size and inference time. Despite the compression, the student model exceeds most existing frameworks, facilitating edge deployment for AMD screening. Code is available at https://github.com/erfan-nourbakhsh/KD- OCT.

</details>


### [21] [Adaptive Thresholding for Visual Place Recognition using Negative Gaussian Mixture Statistics](https://arxiv.org/abs/2512.09071)
*Nick Trinh,Damian Lyons*

Main category: cs.CV

TL;DR: 本文提出了一种基于负样本高斯混合统计的阈值自动选择方法，用于提升视觉地点识别(VPR)在不同场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 当前VPR方法依赖手动设置阈值来判定图像匹配，但这种方法难以适应不同视觉场景（如季节变化、光照条件、环境结构变化等）的需求，导致性能不稳定。

Method: 通过分析地点图像的‘负’高斯混合统计信息（即表示非该地点的图像统计特征），自动计算适合的匹配阈值。

Result: 该方法能够为多种图像数据库和图像描述符选择出工作良好的阈值，提高了VPR系统的适应性。

Conclusion: 基于负样本统计的阈值自动选择方法比手动设置阈值更加可靠，能有效应对VPR中的视觉变化挑战。

Abstract: Visual place recognition (VPR) is an important component technology for camera-based mapping and navigation applications. This is a challenging problem because images of the same place may appear quite different for reasons including seasonal changes, weather illumination, structural changes to the environment, as well as transient pedestrian or vehicle traffic. Papers focusing on generating image descriptors for VPR report their results using metrics such as recall@K and ROC curves. However, for a robot implementation, determining which matches are sufficiently good is often reduced to a manually set threshold. And it is difficult to manually select a threshold that will work for a variety of visual scenarios. This paper addresses the problem of automatically selecting a threshold for VPR by looking at the 'negative' Gaussian mixture statistics for a place - image statistics indicating not this place. We show that this approach can be used to select thresholds that work well for a variety of image databases and image descriptors.

</details>


### [22] [AgentComp: From Agentic Reasoning to Compositional Mastery in Text-to-Image Models](https://arxiv.org/abs/2512.09081)
*Arman Zarei,Jiacheng Pan,Matthew Gwilliam,Soheil Feizi,Zhenheng Yang*

Main category: cs.CV

TL;DR: AgentComp通过LLM驱动的自主数据构建和偏好优化，显著提升文本到图像生成模型的组合能力，在保持图像质量的同时达到SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型虽然视觉质量优秀，但在组合性方面存在不足——难以准确捕捉对象关系、属性绑定和提示词中的细微细节。关键限制在于模型没有经过显式训练来区分组合上相似的提示和图像，导致输出接近描述但又偏离细节。

Method: 提出AgentComp框架：1）利用配备图像生成、编辑和VQA工具的大语言模型（LLM）自主构建组合数据集；2）应用智能体偏好优化方法微调文本到图像模型，使其更好地区分组合上相似的样本。

Result: 在T2I-CompBench等组合性评测基准上达到最先进水平，且没有牺牲图像质量（这是之前方法的常见缺陷），甚至能泛化到未经过显式训练的其他能力，如文本渲染。

Conclusion: 通过LLM驱动的数据构建和偏好优化，AgentComp有效提升了文本到图像模型的组合生成能力，为改进生成模型的组合推理提供了一种有前景的方法。

Abstract: Text-to-image generative models have achieved remarkable visual quality but still struggle with compositionality$-$accurately capturing object relationships, attribute bindings, and fine-grained details in prompts. A key limitation is that models are not explicitly trained to differentiate between compositionally similar prompts and images, resulting in outputs that are close to the intended description yet deviate in fine-grained details. To address this, we propose AgentComp, a framework that explicitly trains models to better differentiate such compositional variations and enhance their reasoning ability. AgentComp leverages the reasoning and tool-use capabilities of large language models equipped with image generation, editing, and VQA tools to autonomously construct compositional datasets. Using these datasets, we apply an agentic preference optimization method to fine-tune text-to-image models, enabling them to better distinguish between compositionally similar samples and resulting in overall stronger compositional generation ability. AgentComp achieves state-of-the-art results on compositionality benchmarks such as T2I-CompBench, without compromising image quality$-$a common drawback in prior approaches$-$and even generalizes to other capabilities not explicitly trained for, such as text rendering.

</details>


### [23] [Explaining the Unseen: Multimodal Vision-Language Reasoning for Situational Awareness in Underground Mining Disasters](https://arxiv.org/abs/2512.09092)
*Mizanur Rahman Jewel,Mohamed Elmahallawy,Sanjay Madria,Samuel Frimpong*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Underground mining disasters produce pervasive darkness, dust, and collapses that obscure vision and make situational awareness difficult for humans and conventional systems. To address this, we propose MDSE, Multimodal Disaster Situation Explainer, a novel vision-language framework that automatically generates detailed textual explanations of post-disaster underground scenes. MDSE has three-fold innovations: (i) Context-Aware Cross-Attention for robust alignment of visual and textual features even under severe degradation; (ii) Segmentation-aware dual pathway visual encoding that fuses global and region-specific embeddings; and (iii) Resource-Efficient Transformer-Based Language Model for expressive caption generation with minimal compute cost. To support this task, we present the Underground Mine Disaster (UMD) dataset--the first image-caption corpus of real underground disaster scenes--enabling rigorous training and evaluation. Extensive experiments on UMD and related benchmarks show that MDSE substantially outperforms state-of-the-art captioning models, producing more accurate and contextually relevant descriptions that capture crucial details in obscured environments, improving situational awareness for underground emergency response. The code is at https://github.com/mizanJewel/Multimodal-Disaster-Situation-Explainer.

</details>


### [24] [Food Image Generation on Multi-Noun Categories](https://arxiv.org/abs/2512.09095)
*Xinyue Pan,Yuhao Chen,Jiangpeng He,Fengqing Zhu*

Main category: cs.CV

TL;DR: 食品图像生成在处理包含多个名词的复合类别时面临挑战，本文提出FoCuLR方法解决这一问题


<details>
  <summary>Details</summary>
Motivation: 生成现实食品图像时，对于包含多个名词的复合类别（如'egg noodle'），现有生成模型容易产生语义误解，错误地将成分分离为独立物体而非整体食物

Method: 提出FoCuLR（食品类别理解与布局优化）方法，通过整合食品领域知识，并在生成过程早期引入核心概念，优化多名词关系的理解

Result: 实验结果表明，集成这些技术后，图像生成在食品领域的性能得到提升

Conclusion: 通过增强域知识理解并改进多名词关系处理，可显著提高食品图像生成的质量和准确性

Abstract: Generating realistic food images for categories with multiple nouns is surprisingly challenging. For instance, the prompt "egg noodle" may result in images that incorrectly contain both eggs and noodles as separate entities. Multi-noun food categories are common in real-world datasets and account for a large portion of entries in benchmarks such as UEC-256. These compound names often cause generative models to misinterpret the semantics, producing unintended ingredients or objects. This is due to insufficient multi-noun category related knowledge in the text encoder and misinterpretation of multi-noun relationships, leading to incorrect spatial layouts. To overcome these challenges, we propose FoCULR (Food Category Understanding and Layout Refinement) which incorporates food domain knowledge and introduces core concepts early in the generation process. Experimental results demonstrate that the integration of these techniques improves image generation performance in the food domain.

</details>


### [25] [GimbalDiffusion: Gravity-Aware Camera Control for Video Generation](https://arxiv.org/abs/2512.09112)
*Frédéric Fortier-Chouinard,Yannick Hold-Geoffroy,Valentin Deschaintre,Matheus Gadelha,Jean-François Lalonde*

Main category: cs.CV

TL;DR: 提出GimbalDiffusion框架，通过物理坐标和重力参考实现精确摄像机控制，利用360度全景视频构建多样化轨迹，引入零倾角条件减少文本依赖，并建立摄像机感知视频生成基准。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频生成方法在摄像机运动控制和方向控制方面主要使用相对或模糊表示，缺乏显式几何控制，难以实现精确的摄像机轨迹控制。

Method: 1. 使用绝对坐标系定义摄像机轨迹，基于重力作为全局参考；2. 利用全景360度视频构建多样化相机轨迹；3. 引入零倾角条件策略减少模型对文本内容的依赖；4. 重新平衡SpatialVID-HQ建立摄像机感知生成基准。

Result: 实现了在生成框架内精确、重力对齐的摄像机操控，提高了文本到视频模型的可控性和鲁棒性，能够产生超出传统视频数据中主要直线、正面轨迹的多样化摄像机运动。

Conclusion: GimbalDiffusion框架通过物理坐标系统和重力参考实现了精确的摄像机控制，结合全景视频数据和零倾角策略，显著提升了文本到视频生成的几何可控性，为摄像机感知视频生成提供了新的基准和方法。

Abstract: Recent progress in text-to-video generation has achieved remarkable realism, yet fine-grained control over camera motion and orientation remains elusive. Existing approaches typically encode camera trajectories through relative or ambiguous representations, limiting explicit geometric control. We introduce GimbalDiffusion, a framework that enables camera control grounded in physical-world coordinates, using gravity as a global reference. Instead of describing motion relative to previous frames, our method defines camera trajectories in an absolute coordinate system, allowing precise and interpretable control over camera parameters without requiring an initial reference frame. We leverage panoramic 360-degree videos to construct a wide variety of camera trajectories, well beyond the predominantly straight, forward-facing trajectories seen in conventional video data. To further enhance camera guidance, we introduce null-pitch conditioning, an annotation strategy that reduces the model's reliance on text content when conflicting with camera specifications (e.g., generating grass while the camera points towards the sky). Finally, we establish a benchmark for camera-aware video generation by rebalancing SpatialVID-HQ for comprehensive evaluation under wide camera pitch variation. Together, these contributions advance the controllability and robustness of text-to-video models, enabling precise, gravity-aligned camera manipulation within generative frameworks.

</details>


### [26] [SuperF: Neural Implicit Fields for Multi-Image Super-Resolution](https://arxiv.org/abs/2512.09115)
*Sander Riisøen Jyhne,Christian Igel,Morten Goodwin,Per-Arne Andersen,Serge Belongie,Nico Lang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: High-resolution imagery is often hindered by limitations in sensor technology, atmospheric conditions, and costs. Such challenges occur in satellite remote sensing, but also with handheld cameras, such as our smartphones. Hence, super-resolution aims to enhance the image resolution algorithmically. Since single-image super-resolution requires solving an inverse problem, such methods must exploit strong priors, e.g. learned from high-resolution training data, or be constrained by auxiliary data, e.g. by a high-resolution guide from another modality. While qualitatively pleasing, such approaches often lead to "hallucinated" structures that do not match reality. In contrast, multi-image super-resolution (MISR) aims to improve the (optical) resolution by constraining the super-resolution process with multiple views taken with sub-pixel shifts. Here, we propose SuperF, a test-time optimization approach for MISR that leverages coordinate-based neural networks, also called neural fields. Their ability to represent continuous signals with an implicit neural representation (INR) makes them an ideal fit for the MISR task.
  The key characteristic of our approach is to share an INR for multiple shifted low-resolution frames and to jointly optimize the frame alignment with the INR. Our approach advances related INR baselines, adopted from burst fusion for layer separation, by directly parameterizing the sub-pixel alignment as optimizable affine transformation parameters and by optimizing via a super-sampled coordinate grid that corresponds to the output resolution. Our experiments yield compelling results on simulated bursts of satellite imagery and ground-level images from handheld cameras, with upsampling factors of up to 8. A key advantage of SuperF is that this approach does not rely on any high-resolution training data.

</details>


### [27] [Integrated Pipeline for Coronary Angiography With Automated Lesion Profiling, Virtual Stenting, and 100-Vessel FFR Validation](https://arxiv.org/abs/2512.09134)
*Georgy Kopanitsa,Oleg Metsker,Alexey Yakovlev*

Main category: cs.CV

TL;DR: AngioAI-QFR是一个端到端的基于血管造影的定量血流分数（QFR）分析系统，整合了深度学习狭窄检测、管腔分割、中心线提取、相对血流容量分析和虚拟支架置入功能，在无需压力导丝的情况下实现了接近实时的冠状动脉生理功能评估和虚拟介入规划。


<details>
  <summary>Details</summary>
Motivation: 当前血管造影对狭窄的视觉评估存在主观差异且与缺血相关性有限，基于压力导丝的FFR虽然能改善病变选择但未得到系统应用，而现有的血管造影衍生生理指标工具（如QFR）工作流程复杂且与自动解剖分析和虚拟PCI规划分离。因此需要开发一个集成的端到端自动化解决方案。

Method: 开发了AngioAI-QFR系统，该管道整合了深度学习狭窄检测、自动管腔分割、中心线和直径提取、毫米级相对血流容量（RFC）分析，以及虚拟支架置入并自动重新计算QFR值。系统在100条连续血管中以侵入性FFR为参考标准进行评估。

Result: 狭窄检测精度0.97，管腔分割Dice系数0.78；AngioAI-QFR与FFR强相关（r=0.89，平均绝对误差0.045）；检测FFR≤0.80的AUC为0.93，敏感性0.88，特异性0.86；93%的血管实现全自动处理，中位结果时间41秒；RFC分析可区分局限性与弥漫性血流容量损失，虚拟支架置入预测在局限性病变中QFR获益更大。

Conclusion: AngioAI-QFR提供了一个实用的、近乎实时的处理管道，将计算机视觉、功能分析和虚拟PCI规划与自动化血管造影衍生生理评估统一起来，为冠状动脉疾病评估提供了集成化的无导丝解决方案。

Abstract: Coronary angiography is the main tool for assessing coronary artery disease, but visual grading of stenosis is variable and only moderately related to ischaemia. Wire based fractional flow reserve (FFR) improves lesion selection but is not used systematically. Angiography derived indices such as quantitative flow ratio (QFR) offer wire free physiology, yet many tools are workflow intensive and separate from automated anatomy analysis and virtual PCI planning. We developed AngioAI-QFR, an end to end angiography only pipeline combining deep learning stenosis detection, lumen segmentation, centreline and diameter extraction, per millimetre Relative Flow Capacity profiling, and virtual stenting with automatic recomputation of angiography derived QFR. The system was evaluated in 100 consecutive vessels with invasive FFR as reference. Primary endpoints were agreement with FFR (correlation, mean absolute error) and diagnostic performance for FFR <= 0.80. On held out frames, stenosis detection achieved precision 0.97 and lumen segmentation Dice 0.78. Across 100 vessels, AngioAI-QFR correlated strongly with FFR (r = 0.89, MAE 0.045). The AUC for detecting FFR <= 0.80 was 0.93, with sensitivity 0.88 and specificity 0.86. The pipeline completed fully automatically in 93 percent of vessels, with median time to result 41 s. RFC profiling distinguished focal from diffuse capacity loss, and virtual stenting predicted larger QFR gain in focal than in diffuse disease. AngioAI-QFR provides a practical, near real time pipeline that unifies computer vision, functional profiling, and virtual PCI with automated angiography derived physiology.

</details>


### [28] [GTAvatar: Bridging Gaussian Splatting and Texture Mapping for Relightable and Editable Gaussian Avatars](https://arxiv.org/abs/2512.09162)
*Kelian Baert,Mae Younes,Francois Bourel,Marc Christie,Adnane Boukhayma*

Main category: cs.CV

TL;DR: 提出一种结合2D高斯喷洒精度与UV纹理映射直观性的头像重建方法，通过将高斯原语嵌入模板网格的UV空间，实现从单目视频重建可编辑材质纹理，并支持基于物理的反射模型重新光照和直观外观编辑。


<details>
  <summary>Details</summary>
Motivation: 高斯喷洒技术虽能实现高精度头像重建，但缺乏传统三角网格方法提供的直观可编辑性；本研究旨在结合两者的优势，实现既保真又易编辑的头像系统。

Method: 将每个规范高斯原语的局部坐标系高效嵌入模板网格的UV空间，从单目视频重建连续可编辑的UV材质纹理；采用基于物理的高效反射模型支持重新光照和本征材质贴图编辑。

Result: 通过与现有先进方法对比，验证了重建的准确性、重新光照结果的质量，以及通过纹理映射实现头像外观和几何修改的直观控制能力，且无需额外优化。

Conclusion: 该方法成功融合了高斯喷洒的保真度与UV纹理映射的直观编辑性，为头像应用提供了高质量、易控制的重建与编辑方案。

Abstract: Recent advancements in Gaussian Splatting have enabled increasingly accurate reconstruction of photorealistic head avatars, opening the door to numerous applications in visual effects, videoconferencing, and virtual reality. This, however, comes with the lack of intuitive editability offered by traditional triangle mesh-based methods. In contrast, we propose a method that combines the accuracy and fidelity of 2D Gaussian Splatting with the intuitiveness of UV texture mapping. By embedding each canonical Gaussian primitive's local frame into a patch in the UV space of a template mesh in a computationally efficient manner, we reconstruct continuous editable material head textures from a single monocular video on a conventional UV domain. Furthermore, we leverage an efficient physically based reflectance model to enable relighting and editing of these intrinsic material maps. Through extensive comparisons with state-of-the-art methods, we demonstrate the accuracy of our reconstructions, the quality of our relighting results, and the ability to provide intuitive controls for modifying an avatar's appearance and geometry via texture mapping without additional optimization.

</details>


### [29] [WonderZoom: Multi-Scale 3D World Generation](https://arxiv.org/abs/2512.09164)
*Jin Cao,Hong-Xing Yu,Jiajun Wu*

Main category: cs.CV

TL;DR: WonderZoom：一种从单张图像生成跨多空间尺度的3D场景的新方法，通过尺度自适应高斯面元和渐进细节合成器实现对3D世界的多尺度合成和实时渲染。


<details>
  <summary>Details</summary>
Motivation: 现有3D世界生成模型仅限于单一尺度合成，无法生成不同粒度下的连贯场景内容，关键在于缺乏能够处理不同空间尺寸的尺度感知3D表示方法。

Method: 1. 尺度自适应高斯面元：用于生成和实时渲染多尺度3D场景；2. 渐进细节合成器：迭代生成更精细尺度的3D内容。用户可对3D区域进行“缩放”，并以自回归方式合成从景观到微观特征的精细细节。

Result: 实验表明WonderZoom在质量和一致性方面显著优于现有的视频和3D模型，能够从单张图像创造多尺度3D世界。提供了视频结果和交互式查看器。

Conclusion: WonderZoom成功解决了多尺度3D场景生成的挑战，实现了从单张图像创建跨多个空间尺度的连贯3D世界，为3D内容创作提供了新可能性。

Abstract: We present WonderZoom, a novel approach to generating 3D scenes with contents across multiple spatial scales from a single image. Existing 3D world generation models remain limited to single-scale synthesis and cannot produce coherent scene contents at varying granularities. The fundamental challenge is the lack of a scale-aware 3D representation capable of generating and rendering content with largely different spatial sizes. WonderZoom addresses this through two key innovations: (1) scale-adaptive Gaussian surfels for generating and real-time rendering of multi-scale 3D scenes, and (2) a progressive detail synthesizer that iteratively generates finer-scale 3D contents. Our approach enables users to "zoom into" a 3D region and auto-regressively synthesize previously non-existent fine details from landscapes to microscopic features. Experiments demonstrate that WonderZoom significantly outperforms state-of-the-art video and 3D models in both quality and alignment, enabling multi-scale 3D world creation from a single image. We show video results and an interactive viewer of generated multi-scale 3D worlds in https://wonderzoom.github.io/

</details>


### [30] [Prompt-Based Continual Compositional Zero-Shot Learning](https://arxiv.org/abs/2512.09172)
*Sauda Maryam,Sara Nadeem,Faisal Qureshi,Mohsen Ali*

Main category: cs.CV

TL;DR: 针对连续组合零样本学习（CCZSL）中视觉语言模型适应新属性和对象组合的任务，提出了PromptCCZSL框架，通过多教师蒸馏和会话感知提示来解决知识遗忘问题，并在多个基准上取得显著提升


<details>
  <summary>Details</summary>
Motivation: 传统连续学习假设类别互斥，而组合零样本学习中属性和对象可能在多个会话中重复出现，但组合方式独特，现有方法无法有效处理这种复杂性，导致灾难性遗忘和组合泛化能力不足

Method: 基于冻结的视觉语言模型，提出了PromptCCZSL框架：1) 通过近期加权多教师蒸馏保留先验知识 2) 使用会话感知的组合提示融合多模态特征 3) 属性/对象提示通过会话无关融合保持语义一致性 4) 余弦锚定损失稳定全局语义 5) 正交投影损失确保新旧嵌入不重叠 6) 会话内多样性损失增强表征区分度

Result: 在UT-Zappos和C-GQA基准测试中，PromptCCZSL在防止灾难性遗忘和提高组合泛化能力方面均显著优于现有VLM和非VLM基线模型，为闭世界CCZSL建立了新的基准

Conclusion: 该研究提出的PromptCCZSL框架有效解决了CCZSL中的连续适应挑战，通过创新的提示学习和损失函数设计，在保持先验知识的同时促进新知识的获取，为组合零样本学习的连续学习范式提供了新思路

Abstract: We tackle continual adaptation of vision-language models to new attributes, objects, and their compositions in Compositional Zero-Shot Learning (CZSL), while preventing forgetting of prior knowledge. Unlike classical continual learning where classes are disjoint, CCZSL is more complex as attributes and objects may reoccur across sessions while compositions remain unique. Built on a frozen VLM backbone, we propose the first Prompt-based Continual Compositional Zero-Shot Learning (PromptCCZSL) framework that retains prior knowledge through recency-weighted multi-teacher distillation. It employs session-aware compositional prompts to fuse multimodal features for new compositions, while attribute and object prompts are learned through session-agnostic fusion to maintain global semantic consistency, which is further stabilized by a Cosine Anchor Loss (CAL) to preserve prior knowledge. To enhance adaptation in the current session, an Orthogonal Projection Loss (OPL) ensures that new attribute and object embeddings remain distinct from previous ones, preventing overlap, while an Intra-Session Diversity Loss (IDL) promotes variation among current-session embeddings for richer, more discriminative representations. We also introduce a comprehensive protocol that jointly measures catastrophic forgetting and compositional generalization. Extensive experiments on UT-Zappos and C-GQA benchmarks demonstrate that PromptCCZSL achieves substantial improvements over prior VLM-based and non-VLM baselines, setting a new benchmark for CCZSL in closed-world settings.

</details>


### [31] [Learning Patient-Specific Disease Dynamics with Latent Flow Matching for Longitudinal Imaging Generation](https://arxiv.org/abs/2512.09185)
*Hao Chen,Rui Yin,Yifan Chen,Qi Chen,Chao Li*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Understanding disease progression is a central clinical challenge with direct implications for early diagnosis and personalized treatment. While recent generative approaches have attempted to model progression, key mismatches remain: disease dynamics are inherently continuous and monotonic, yet latent representations are often scattered, lacking semantic structure, and diffusion-based models disrupt continuity with random denoising process. In this work, we propose to treat the disease dynamic as a velocity field and leverage Flow Matching (FM) to align the temporal evolution of patient data. Unlike prior methods, it captures the intrinsic dynamic of disease, making the progression more interpretable. However, a key challenge remains: in latent space, Auto-Encoders (AEs) do not guarantee alignment across patients or correlation with clinical-severity indicators (e.g., age and disease conditions). To address this, we propose to learn patient-specific latent alignment, which enforces patient trajectories to lie along a specific axis, with magnitude increasing monotonically with disease severity. This leads to a consistent and semantically meaningful latent space. Together, we present $Δ$-LFM, a framework for modeling patient-specific latent progression with flow matching. Across three longitudinal MRI benchmarks, $Δ$-LFM demonstrates strong empirical performance and, more importantly, offers a new framework for interpreting and visualizing disease dynamics.

</details>


### [32] [View-on-Graph: Zero-shot 3D Visual Grounding via Vision-Language Reasoning on Scene Graphs](https://arxiv.org/abs/2512.09215)
*Yuanyuan Liu,Haiyang Mei,Dongyang Zhan,Jiayue Zhao,Dongsheng Zhou,Bo Dong,Xin Yang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: 3D visual grounding (3DVG) identifies objects in 3D scenes from language descriptions. Existing zero-shot approaches leverage 2D vision-language models (VLMs) by converting 3D spatial information (SI) into forms amenable to VLM processing, typically as composite inputs such as specified view renderings or video sequences with overlaid object markers. However, this VLM + SI paradigm yields entangled visual representations that compel the VLM to process entire cluttered cues, making it hard to exploit spatial semantic relationships effectively. In this work, we propose a new VLM x SI paradigm that externalizes the 3D SI into a form enabling the VLM to incrementally retrieve only what it needs during reasoning. We instantiate this paradigm with a novel View-on-Graph (VoG) method, which organizes the scene into a multi-modal, multi-layer scene graph and allows the VLM to operate as an active agent that selectively accesses necessary cues as it traverses the scene. This design offers two intrinsic advantages: (i) by structuring 3D context into a spatially and semantically coherent scene graph rather than confounding the VLM with densely entangled visual inputs, it lowers the VLM's reasoning difficulty; and (ii) by actively exploring and reasoning over the scene graph, it naturally produces transparent, step-by-step traces for interpretable 3DVG. Extensive experiments show that VoG achieves state-of-the-art zero-shot performance, establishing structured scene exploration as a promising strategy for advancing zero-shot 3DVG.

</details>


### [33] [Efficient Feature Compression for Machines with Global Statistics Preservation](https://arxiv.org/abs/2512.09235)
*Md Eimran Hossain Eimon,Hyomin Choi,Fabien Racapé,Mateen Ulhaq,Velibor Adzic,Hari Kalva,Borko Furht*

Main category: cs.CV

TL;DR: 本文提出了一种新的特征数据压缩方法，利用Z分数归一化恢复特征数据，性能优于现有标准，能显著降低比特率同时保持任务精度。


<details>
  <summary>Details</summary>
Motivation: 在分片推理范式中，AI模型被分为两个部分，需要在两部分之间传输中间特征数据。高效压缩这些特征数据变得至关重要。现有标准中的缩放方法存在改进空间，需要更高效的压缩方案来减少开销比特并提高最终任务的准确性。

Method: 采用了Z分数归一化方法在解码端有效恢复压缩的特征数据。该方法被集成到MPEG正在开发的最新的FCM（面向机器的特征编码）编解码器标准中。此外，还提出了一种简化方法来进一步减少特定情况下的开销。

Result: 实验表明，在不同任务中平均减少了17.09%的比特率，在目标跟踪任务中最高可减少65.69%的比特率，同时没有牺牲任务准确性。

Conclusion: 提出的Z分数归一化方法优于现有标准中的缩放方法，能同时减少开销比特并提高终端任务精度，特别是在特征数据压缩方面表现优异，为分片推理范式提供了更高效的解决方案。

Abstract: The split-inference paradigm divides an artificial intelligence (AI) model into two parts. This necessitates the transfer of intermediate feature data between the two halves. Here, effective compression of the feature data becomes vital. In this paper, we employ Z-score normalization to efficiently recover the compressed feature data at the decoder side. To examine the efficacy of our method, the proposed method is integrated into the latest Feature Coding for Machines (FCM) codec standard under development by the Moving Picture Experts Group (MPEG). Our method supersedes the existing scaling method used by the current standard under development. It both reduces the overhead bits and improves the end-task accuracy. To further reduce the overhead in certain circumstances, we also propose a simplified method. Experiments show that using our proposed method shows 17.09% reduction in bitrate on average across different tasks and up to 65.69% for object tracking without sacrificing the task accuracy.

</details>


### [34] [OmniPSD: Layered PSD Generation with Diffusion Transformer](https://arxiv.org/abs/2512.09247)
*Cheng Liu,Yiren Song,Haofan Wang,Mike Zheng Shou*

Main category: cs.CV

TL;DR: 该论文提出了OmniPSD——一个基于Flux生态系统的统一扩散框架，能够通过上下文学习实现文本到PSD生成和图像到PSD分解。


<details>
  <summary>Details</summary>
Motivation: 目前扩散模型在图像生成和编辑方面取得了巨大进步，但生成或重建具有透明alpha通道的分层PSD文件仍然极具挑战性。现有的方法难以处理分层结构的透明设计文件。

Method: OmniPSD通过上下文学习实现两种功能：1）文本到PSD生成时，将多个目标图层在画布上空间排列，通过空间注意力学习它们的组合关系；2）图像到PSD分解时，采用迭代式的上下文编辑，逐步提取和擦除文本和前景组件。同时使用RGBA-VAE作为辅助表示模块以保持透明度而不影响结构学习。

Result: 在新的RGBA分层数据集上的大量实验表明，OmniPSD实现了高保真生成、结构一致性和透明度意识。

Conclusion: OmniPSD为分层设计的生成和分解提供了一个新的范例，展示了扩散变换器在复杂分层结构处理方面的潜力。

Abstract: Recent advances in diffusion models have greatly improved image generation and editing, yet generating or reconstructing layered PSD files with transparent alpha channels remains highly challenging. We propose OmniPSD, a unified diffusion framework built upon the Flux ecosystem that enables both text-to-PSD generation and image-to-PSD decomposition through in-context learning. For text-to-PSD generation, OmniPSD arranges multiple target layers spatially into a single canvas and learns their compositional relationships through spatial attention, producing semantically coherent and hierarchically structured layers. For image-to-PSD decomposition, it performs iterative in-context editing, progressively extracting and erasing textual and foreground components to reconstruct editable PSD layers from a single flattened image. An RGBA-VAE is employed as an auxiliary representation module to preserve transparency without affecting structure learning. Extensive experiments on our new RGBA-layered dataset demonstrate that OmniPSD achieves high-fidelity generation, structural consistency, and transparency awareness, offering a new paradigm for layered design generation and decomposition with diffusion transformers.

</details>


### [35] [GLACIA: Instance-Aware Positional Reasoning for Glacial Lake Segmentation via Multimodal Large Language Model](https://arxiv.org/abs/2512.09251)
*Lalit Maurya,Saurabh Kaushik,Beth Tellman*

Main category: cs.CV

TL;DR: 提出GLACIA框架，首次将大语言模型与分割能力结合，用于冰川湖监测，不仅提供准确分割掩码，还生成空间推理输出，支持自然语言交互。


<details>
  <summary>Details</summary>
Motivation: 现有基于CNN和ViT的分割方法局限于像素级预测，缺乏高层全局场景语义和可解释推理，难以满足冰川湖溃决洪水风险缓解的直觉灾害准备和基于信息的决策需求。

Method: 1) 开发GLACIA框架，集成大语言模型与分割能力，生成分割掩码和空间推理输出； 2) 构建Glacial Lake Position Reasoning (GLake-Pos)数据集管道，提供多样化的基于空间的问题-答案对，解决遥感数据中缺乏实例感知位置推理的问题。

Result: GLACIA在mIoU指标上达到87.30，超越基于CNN的方法(78.55-79.01)、ViT方法(69.27-81.75)、地理基础模型(76.37-87.10)和基于推理的分割方法(60.12-75.66)。

Conclusion: GLACIA框架通过自然语言交互支持更高效和可解释的决策，在快速变化的冰川环境中促进直觉灾害准备和基于信息的政策制定。代码已开源。

Abstract: Glacial lake monitoring bears great significance in mitigating the anticipated risk of Glacial Lake Outburst Floods. However, existing segmentation methods based on convolutional neural networks (CNNs) and Vision Transformers (ViTs), remain constrained to pixel-level predictions, lacking high-level global scene semantics and human-interpretable reasoning. To address this, we introduce GLACIA (\textbf{G}lacial \textbf{LA}ke segmentation with \textbf{C}ontextual \textbf{I}nstance \textbf{A}wareness), the first framework that integrates large language models with segmentation capabilities to produce both accurate segmentation masks and corresponding spatial reasoning outputs. We construct the Glacial Lake Position Reasoning (GLake-Pos) dataset pipeline, which provides diverse, spatially grounded question-answer pairs designed to overcome the lack of instance-aware positional reasoning data in remote sensing. Comparative evaluation demonstrate that GLACIA (mIoU: 87.30) surpasses state-of-the-art method based on CNNs (mIoU: 78.55 - 79.01), ViTs (mIoU: 69.27 - 81.75), Geo-foundation models (mIoU: 76.37 - 87.10), and reasoning based segmentation methods (mIoU: 60.12 - 75.66). Our approach enables intuitive disaster preparedness and informed policy-making in the context of rapidly changing glacial environments by facilitating natural language interaction, thereby supporting more efficient and interpretable decision-making. The code is released on https://github.com/lalitmaurya47/GLACIA

</details>


### [36] [Rethinking Chain-of-Thought Reasoning for Videos](https://arxiv.org/abs/2512.09616)
*Yiwu Zhong,Zi-Yuan Hu,Yin Li,Liwei Wang*

Main category: cs.CV

TL;DR: 本文质疑视频推理中是否需要长链条的思维链（CoT）推理，提出简洁推理结合压缩视觉标记的方法，能提升效率并保持竞争力


<details>
  <summary>Details</summary>
Motivation: 现有基于CoT的多模态大语言模型在视频推理中通常需要冗长的推理链和大量视觉标记，作者通过基准研究观察到简洁推理可能足够有效，希望验证这一假设

Method: 设计高效的后训练和推理框架，使视频MLLM能够操作压缩的视觉标记，并在回答问题前生成简要的推理轨迹，无需人工CoT标注或有监督微调

Result: 构建的模型显著提升了推理效率，在多个基准测试中表现出竞争力，表明长的人化CoT推理对通用视频推理可能不必要

Conclusion: 简洁推理可以有效且高效地完成视频推理任务，为视频MLLM的轻量化部署提供了新思路

Abstract: Chain-of-thought (CoT) reasoning has been highly successful in solving complex tasks in natural language processing, and recent multimodal large language models (MLLMs) have extended this paradigm to video reasoning. However, these models typically build on lengthy reasoning chains and large numbers of input visual tokens. Motivated by empirical observations from our benchmark study, we hypothesize that concise reasoning combined with a reduced set of visual tokens can be sufficient for effective video reasoning. To evaluate this hypothesis, we design and validate an efficient post-training and inference framework that enhances a video MLLM's reasoning capability. Our framework enables models to operate on compressed visual tokens and generate brief reasoning traces prior to answering. The resulting models achieve substantially improved inference efficiency, deliver competitive performance across diverse benchmarks, and avoid reliance on manual CoT annotations or supervised fine-tuning. Collectively, our results suggest that long, human-like CoT reasoning may not be necessary for general video reasoning, and that concise reasoning can be both effective and efficient. Our code will be released at https://github.com/LaVi-Lab/Rethink_CoT_Video.

</details>


### [37] [ROI-Packing: Efficient Region-Based Compression for Machine Vision](https://arxiv.org/abs/2512.09258)
*Md Eimran Hossain Eimon,Alena Krause,Ashan Perera,Juan Merlos,Hari Kalva,Velibor Adzic,Borko Furht*

Main category: cs.CV

TL;DR: ROI-Packing是一种面向机器视觉的高效图像压缩方法，通过优先处理对任务精度关键的兴趣区域并压缩非关键数据，在保持任务精度的同时显著提升压缩效率。


<details>
  <summary>Details</summary>
Motivation: 现有的通用视频编码标准在机器视觉任务中未能充分利用任务特定的冗余信息，导致压缩效率不足。机器视觉应用通常只关注图像中的特定区域，这为压缩提供了优化空间。

Method: ROI-Packing优先识别和高效压缩对终端任务精度关键的兴趣区域，同时丢弃或显著压缩不相关的数据。该方法不需要重新训练或微调现有的终端任务模型，可以直接应用于现有的视觉任务流水线。

Result: 在五个数据集和两个流行任务（目标检测和实例分割）上的综合评估显示，相较于最先进的VVC标准编码器，ROI-Packing在不影响终端任务精度的前提下，能够将比特率降低44.10%，或者在相同比特率下将准确率提升8.88%。

Conclusion: ROI-Packing通过任务感知的压缩策略，在机器视觉应用中实现了比通用视频编码标准更高效的压缩性能，展示了为特定应用定制压缩方法的潜力。

Abstract: This paper introduces ROI-Packing, an efficient image compression method tailored specifically for machine vision. By prioritizing regions of interest (ROI) critical to end-task accuracy and packing them efficiently while discarding less relevant data, ROI-Packing achieves significant compression efficiency without requiring retraining or fine-tuning of end-task models. Comprehensive evaluations across five datasets and two popular tasks-object detection and instance segmentation-demonstrate up to a 44.10% reduction in bitrate without compromising end-task accuracy, along with an 8.88 % improvement in accuracy at the same bitrate compared to the state-of-the-art Versatile Video Coding (VVC) codec standardized by the Moving Picture Experts Group (MPEG).

</details>


### [38] [MedForget: Hierarchy-Aware Multimodal Unlearning Testbed for Medical AI](https://arxiv.org/abs/2512.09867)
*Fengli Wu,Vaidehi Patil,Jaehong Yoon,Yue Zhang,Mohit Bansal*

Main category: cs.CV

TL;DR: 介绍了 MedForget，一个针对医学多模态大语言模型隐私合规需求的层次感知去学习（unlearning）测试平台，可评估在医疗数据嵌套层级结构下的去学习效果与安全性。


<details>
  <summary>Details</summary>
Motivation: 医学AI系统中部署的多模态大语言模型（MLLMs）通常使用敏感患者数据进行训练，这带来了隐私和合规挑战（如HIPAA/GDPR中的“被遗忘权”）。现有的去学习方法在复杂的医疗环境下效果不佳，需要专门评估框架以支持合规医疗AI系统的构建。

Method: 提出MedForget测试平台：1）将医院数据建模为嵌套层次结构（机构→患者→研究→章节），支持八个组织层级的细粒度评估；2）包含3840个多模态（图像、问题、答案）实例，每个层级都有专门的目标遗忘任务；3）对四种先进去学习方法在三种任务（生成、分类、完形填空）上进行实验；4）引入重建攻击，通过逐步添加层级上下文提示来测试去学习是否真正删除了层次路径。

Result: 实验显示，现有方法难以在保持诊断性能的同时实现完全、层次感知的遗忘。粗粒度的去学习模型对重建攻击具有较强抵抗力，而细粒度的去学习则使模型易于受到重建攻击。这揭示了去学习粒度与隐私保护之间的权衡关系。

Conclusion: MedForget为构建符合HIPAA等法规的医疗AI系统提供了一个实用的测试平台，能够系统评估多模态大语言模型在医疗数据层次结构下的去学习效果与隐私安全性，推动合规医学AI的发展。

Abstract: Pretrained Multimodal Large Language Models (MLLMs) are increasingly deployed in medical AI systems for clinical reasoning, diagnosis support, and report generation. However, their training on sensitive patient data raises critical privacy and compliance challenges under regulations such as HIPAA and GDPR, which enforce the "right to be forgotten". Unlearning, the process of tuning models to selectively remove the influence of specific training data points, offers a potential solution, yet its effectiveness in complex medical settings remains underexplored. To systematically study this, we introduce MedForget, a Hierarchy-Aware Multimodal Unlearning Testbed with explicit retain and forget splits and evaluation sets containing rephrased variants. MedForget models hospital data as a nested hierarchy (Institution -> Patient -> Study -> Section), enabling fine-grained assessment across eight organizational levels. The benchmark contains 3840 multimodal (image, question, answer) instances, each hierarchy level having a dedicated unlearning target, reflecting distinct unlearning challenges. Experiments with four SOTA unlearning methods on three tasks (generation, classification, cloze) show that existing methods struggle to achieve complete, hierarchy-aware forgetting without reducing diagnostic performance. To test whether unlearning truly deletes hierarchical pathways, we introduce a reconstruction attack that progressively adds hierarchical level context to prompts. Models unlearned at a coarse granularity show strong resistance, while fine-grained unlearning leaves models vulnerable to such reconstruction. MedForget provides a practical, HIPAA-aligned testbed for building compliant medical AI systems.

</details>


### [39] [MoRel: Long-Range Flicker-Free 4D Motion Modeling via Anchor Relay-based Bidirectional Blending with Hierarchical Densification](https://arxiv.org/abs/2512.09270)
*Sangwoon Kwak,Weeyoung Kwon,Jun Young Jeong,Geonho Kim,Won-Sik Cheong,Jihyong Oh*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent advances in 4D Gaussian Splatting (4DGS) have extended the high-speed rendering capability of 3D Gaussian Splatting (3DGS) into the temporal domain, enabling real-time rendering of dynamic scenes. However, one of the major remaining challenges lies in modeling long-range motion-contained dynamic videos, where a naive extension of existing methods leads to severe memory explosion, temporal flickering, and failure to handle appearing or disappearing occlusions over time. To address these challenges, we propose a novel 4DGS framework characterized by an Anchor Relay-based Bidirectional Blending (ARBB) mechanism, named MoRel, which enables temporally consistent and memory-efficient modeling of long-range dynamic scenes. Our method progressively constructs locally canonical anchor spaces at key-frame time index and models inter-frame deformations at the anchor level, enhancing temporal coherence. By learning bidirectional deformations between KfA and adaptively blending them through learnable opacity control, our approach mitigates temporal discontinuities and flickering artifacts. We further introduce a Feature-variance-guided Hierarchical Densification (FHD) scheme that effectively densifies KfA's while keeping rendering quality, based on an assigned level of feature-variance. To effectively evaluate our model's capability to handle real-world long-range 4D motion, we newly compose long-range 4D motion-contained dataset, called SelfCap$_{\text{LR}}$. It has larger average dynamic motion magnitude, captured at spatially wider spaces, compared to previous dynamic video datasets. Overall, our MoRel achieves temporally coherent and flicker-free long-range 4D reconstruction while maintaining bounded memory usage, demonstrating both scalability and efficiency in dynamic Gaussian-based representations.

</details>


### [40] [LongT2IBench: A Benchmark for Evaluating Long Text-to-Image Generation with Graph-structured Annotations](https://arxiv.org/abs/2512.09271)
*Zhichao Yang,Tianjiao Gu,Jianjie Wang,Feiyu Lin,Xiangfei Sheng,Pengfei Chen,Leida Li*

Main category: cs.CV

TL;DR: 本文提出了LongT2IBench基准数据集和LongT2IExpert评估器，用于长文本-图像生成任务的细粒度对齐评估和可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 随着长文本到图像（T2I）生成的普及，现有评估基准主要关注短文本场景且仅提供MOS或Likert量表标注，缺乏对长文本场景的细粒度、可解释的自动评估模型。

Method: 1. 构建LongT2IBench基准：包含1.4万个长文本-图像对，通过设计的Generate-Refine-Qualify标注协议将长文本转换为包含实体、属性和关系的图结构标注。
2. 提出LongT2IExpert评估器：基于多模态大语言模型（MLLMs），通过层次对齐思维链（CoT）的指令微调过程，实现定量评分和结构化解释能力。

Result: 广泛的实验和比较表明LongT2IExpert在对齐评估和解释方面具有优越性。数据和代码已开源。

Conclusion: LongT2IBench为长文本-图像对齐评估提供了首个细粒度、可解释的基准，而LongT2IExpert展示了通过图结构标注和层次对齐CoT方法实现有效评估和解释的可行性，推动了长T2I生成评估的发展。

Abstract: The increasing popularity of long Text-to-Image (T2I) generation has created an urgent need for automatic and interpretable models that can evaluate the image-text alignment in long prompt scenarios. However, the existing T2I alignment benchmarks predominantly focus on short prompt scenarios and only provide MOS or Likert scale annotations. This inherent limitation hinders the development of long T2I evaluators, particularly in terms of the interpretability of alignment. In this study, we contribute LongT2IBench, which comprises 14K long text-image pairs accompanied by graph-structured human annotations. Given the detail-intensive nature of long prompts, we first design a Generate-Refine-Qualify annotation protocol to convert them into textual graph structures that encompass entities, attributes, and relations. Through this transformation, fine-grained alignment annotations are achieved based on these granular elements. Finally, the graph-structed annotations are converted into alignment scores and interpretations to facilitate the design of T2I evaluation models. Based on LongT2IBench, we further propose LongT2IExpert, a LongT2I evaluator that enables multi-modal large language models (MLLMs) to provide both quantitative scores and structured interpretations through an instruction-tuning process with Hierarchical Alignment Chain-of-Thought (CoT). Extensive experiments and comparisons demonstrate the superiority of the proposed LongT2IExpert in alignment evaluation and interpretation. Data and code have been released in https://welldky.github.io/LongT2IBench-Homepage/.

</details>


### [41] [LoGoColor: Local-Global 3D Colorization for 360° Scenes](https://arxiv.org/abs/2512.09278)
*Yeonjin Chang,Juhwan Cho,Seunghyeon Seo,Wonsik Shin,Nojun Kwak*

Main category: cs.CV

TL;DR: LoGoColor：一种通过局部-全局方法消除指导平均过程来保留颜色多样性的新3D着色方法，在复杂360度场景中实现了比现有方法更一致、更可信的着色效果。


<details>
  <summary>Details</summary>
Motivation: 现有单通道3D重建方法虽然擅长重建几何结构，但无法生成彩色3D模型。最近的3D着色研究通过蒸馏2D图像着色模型来解决这一问题，但这些方法受到2D模型内在不一致性的影响，导致训练过程中颜色被平均化，在复杂360度场景中产生单调和过度简化的结果。

Method: 提出LoGoColor管道，采用局部-全局方法消除指导平均过程：将场景划分为子场景，使用微调的多视角扩散模型显式处理子场景间和子场景内的一致性，从而保留颜色多样性。

Result: 该方法在复杂360度场景中实现了数量和质量上更一致、更可信的3D着色效果，并使用新颖的颜色多样性指数验证了其优越的颜色多样性。

Conclusion: 通过消除指导平均过程并显式处理多视角一致性，LoGoColor能够有效保留颜色多样性，在复杂360度场景中产生更一致的3D着色结果，优于现有方法。

Abstract: Single-channel 3D reconstruction is widely used in fields such as robotics and medical imaging. While this line of work excels at reconstructing 3D geometry, the outputs are not colored 3D models, thus 3D colorization is required for visualization. Recent 3D colorization studies address this problem by distilling 2D image colorization models. However, these approaches suffer from an inherent inconsistency of 2D image models. This results in colors being averaged during training, leading to monotonous and oversimplified results, particularly in complex 360° scenes. In contrast, we aim to preserve color diversity by generating a new set of consistently colorized training views, thereby bypassing the averaging process. Nevertheless, eliminating the averaging process introduces a new challenge: ensuring strict multi-view consistency across these colorized views. To achieve this, we propose LoGoColor, a pipeline designed to preserve color diversity by eliminating this guidance-averaging process with a `Local-Global' approach: we partition the scene into subscenes and explicitly tackle both inter-subscene and intra-subscene consistency using a fine-tuned multi-view diffusion model. We demonstrate that our method achieves quantitatively and qualitatively more consistent and plausible 3D colorization on complex 360° scenes than existing methods, and validate its superior color diversity using a novel Color Diversity Index.

</details>


### [42] [FoundIR-v2: Optimizing Pre-Training Data Mixtures for Image Restoration Foundation Model](https://arxiv.org/abs/2512.09282)
*Xiang Chen,Jinshan Pan,Jiangxin Dong,Jian Yang,Jinhui Tang*

Main category: cs.CV

TL;DR: FoundIR-v2是一个基于扩散模型的高容量图像修复基础模型，采用数据均衡调度范式动态优化不同任务训练数据的混合比例，结合MoE驱动的调度器灵活分配任务自适应扩散先验，在广泛真实场景中超过了现有方法。


<details>
  <summary>Details</summary>
Motivation: 图像修复基础模型的性能提升主要依赖预训练数据的规模和质量，但研究发现不同修复任务的数据混合比例对全能型模型性能至关重要，需要通过数据均衡调度来平衡多任务性能

Method: 提出高容量扩散模型FoundIR-v2，采用数据均衡调度范式动态调整多任务训练数据的混合比例；引入MoE驱动的调度器为不同修复任务分配任务自适应扩散先验，以应对不同任务的退化形式和程度差异

Result: 模型能够处理超过50个子任务，在更广泛的真实场景中表现出色，性能优于现有最佳方法，展现了优秀的泛化能力和全面性能

Conclusion: 数据均衡调度和MoE驱动的任务自适应先验分配是提升图像修复基础模型多任务性能的关键，FoundIR-v2为全能型图像修复提供了有效的解决方案

Abstract: Recent studies have witnessed significant advances in image restoration foundation models driven by improvements in the scale and quality of pre-training data. In this work, we find that the data mixture proportions from different restoration tasks are also a critical factor directly determining the overall performance of all-in-one image restoration models. To this end, we propose a high-capacity diffusion-based image restoration foundation model, FoundIR-v2, which adopts a data equilibrium scheduling paradigm to dynamically optimize the proportions of mixed training datasets from different tasks. By leveraging the data mixing law, our method ensures a balanced dataset composition, enabling the model to achieve consistent generalization and comprehensive performance across diverse tasks. Furthermore, we introduce an effective Mixture-of-Experts (MoE)-driven scheduler into generative pre-training to flexibly allocate task-adaptive diffusion priors for each restoration task, accounting for the distinct degradation forms and levels exhibited by different tasks. Extensive experiments demonstrate that our method can address over 50 sub-tasks across a broader scope of real-world scenarios and achieves favorable performance against state-of-the-art approaches.

</details>


### [43] [Traffic Scene Small Target Detection Method Based on YOLOv8n-SPTS Model for Autonomous Driving](https://arxiv.org/abs/2512.09296)
*Songhan Wu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper focuses on the key issue in autonomous driving: small target recognition in dynamic perception. Existing algorithms suffer from poor detection performance due to missing small target information, scale imbalance, and occlusion. We propose an improved YOLOv8n-SPTS model, which enhances the detection accuracy of small traffic targets through three key innovations: First, optimizing the feature extraction module. In the Backbone Bottleneck structure of YOLOv8n, 4 traditional convolution modules are replaced with Space-to-Depth Convolution (SPD-Conv) modules. This module retains fine-grained information through space-to-depth conversion, reduces information loss, and enhances the ability to capture features of low-resolution small targets. Second, enhancing feature fusion capability. The Spatial Pyramid Pooling - Fast Cross Stage Partial Connection (SPPFCSPC) module is introduced to replace the original SPPF module, integrating the multi-scale feature extraction from Spatial Pyramid Pooling (SPP) and the feature fusion mechanism of Cross Stage Partial Connection (CSP), thereby improving the model's contextual understanding of complex scenes and multi-scale feature expression ability. Third, designing a dedicated detection structure for small targets. A Triple-Stage Feature Pyramid (TSFP) structure is proposed, which adds a 160*160 small target detection head to the original detection heads to fully utilize high-resolution features in shallow layers; meanwhile, redundant large target detection heads are removed to balance computational efficiency. Comparative experiments on the VisDrone2019-DET dataset show that YOLOv8n-SPTS model ranks first in precision (61.9%), recall (48.3%), mAP@0.5 (52.6%), and mAP@0.5:0.95 (32.6%). Visualization results verify that the miss rate of small targets such as pedestrians and bicycles in occluded and dense scenes is significantly reduced.

</details>


### [44] [VABench: A Comprehensive Benchmark for Audio-Video Generation](https://arxiv.org/abs/2512.09299)
*Daili Hua,Xizhi Wang,Bohan Zeng,Xinyi Huang,Hao Liang,Junbo Niu,Xinlong Chen,Quanqing Xu,Wentao Zhang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent advances in video generation have been remarkable, enabling models to produce visually compelling videos with synchronized audio. While existing video generation benchmarks provide comprehensive metrics for visual quality, they lack convincing evaluations for audio-video generation, especially for models aiming to generate synchronized audio-video outputs. To address this gap, we introduce VABench, a comprehensive and multi-dimensional benchmark framework designed to systematically evaluate the capabilities of synchronous audio-video generation. VABench encompasses three primary task types: text-to-audio-video (T2AV), image-to-audio-video (I2AV), and stereo audio-video generation. It further establishes two major evaluation modules covering 15 dimensions. These dimensions specifically assess pairwise similarities (text-video, text-audio, video-audio), audio-video synchronization, lip-speech consistency, and carefully curated audio and video question-answering (QA) pairs, among others. Furthermore, VABench covers seven major content categories: animals, human sounds, music, environmental sounds, synchronous physical sounds, complex scenes, and virtual worlds. We provide a systematic analysis and visualization of the evaluation results, aiming to establish a new standard for assessing video generation models with synchronous audio capabilities and to promote the comprehensive advancement of the field.

</details>


### [45] [From SAM to DINOv2: Towards Distilling Foundation Models to Lightweight Baselines for Generalized Polyp Segmentation](https://arxiv.org/abs/2512.09307)
*Shivanshu Agnihotri,Snehashis Majhi,Deepak Ranjan Nayak,Debesh Jha*

Main category: cs.CV

TL;DR: 该论文针对结肠息肉分割任务提出Polyp-DiFoM蒸馏框架，将基础视觉模型的丰富表示迁移到轻量分割模型中，实现高精度且计算高效部署。


<details>
  <summary>Details</summary>
Motivation: 解决轻量模型在息肉分割中表现不足（因息肉尺寸、形状、颜色多变且具隐匿性），而直接迁移大规模基础模型到医学图像又存在大规模数据集稀缺和领域知识缺乏的问题。

Method: 设计Polyp-DiFoM蒸馏框架，将基础模型的语义先验注入U-Net等经典架构，并通过频域编码增强蒸馏效果，提升泛化能力。

Result: 在Kvasir-SEG等五个基准数据集上验证，Polyp-DiFoM显著优于基线模型和当前最优模型，计算开销降低近9倍。

Conclusion: 该框架通过蒸馏成功融合基础模型的泛化能力与轻量模型效率，为临床部署提供准确、高效解决方案，推动结肠息肉分割技术进步。

Abstract: Accurate polyp segmentation during colonoscopy is critical for the early detection of colorectal cancer and still remains challenging due to significant size, shape, and color variations, and the camouflaged nature of polyps. While lightweight baseline models such as U-Net, U-Net++, and PraNet offer advantages in terms of easy deployment and low computational cost, they struggle to deal with the above issues, leading to limited segmentation performance. In contrast, large-scale vision foundation models such as SAM, DINOv2, OneFormer, and Mask2Former have exhibited impressive generalization performance across natural image domains. However, their direct transfer to medical imaging tasks (e.g., colonoscopic polyp segmentation) is not straightforward, primarily due to the scarcity of large-scale datasets and lack of domain-specific knowledge. To bridge this gap, we propose a novel distillation framework, Polyp-DiFoM, that transfers the rich representations of foundation models into lightweight segmentation baselines, allowing efficient and accurate deployment in clinical settings. In particular, we infuse semantic priors from the foundation models into canonical architectures such as U-Net and U-Net++ and further perform frequency domain encoding for enhanced distillation, corroborating their generalization capability. Extensive experiments are performed across five benchmark datasets, such as Kvasir-SEG, CVC-ClinicDB, ETIS, ColonDB, and CVC-300. Notably, Polyp-DiFoM consistently outperforms respective baseline models significantly, as well as the state-of-the-art model, with nearly 9 times reduced computation overhead. The code is available at https://github.com/lostinrepo/PolypDiFoM.

</details>


### [46] [Transformer-Driven Multimodal Fusion for Explainable Suspiciousness Estimation in Visual Surveillance](https://arxiv.org/abs/2512.09311)
*Kuldeep Singh Yadav,Lalan Kumar*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Suspiciousness estimation is critical for proactive threat detection and ensuring public safety in complex environments. This work introduces a large-scale annotated dataset, USE50k, along with a computationally efficient vision-based framework for real-time suspiciousness analysis. The USE50k dataset contains 65,500 images captured from diverse and uncontrolled environments, such as airports, railway stations, restaurants, parks, and other public areas, covering a broad spectrum of cues including weapons, fire, crowd density, abnormal facial expressions, and unusual body postures. Building on this dataset, we present DeepUSEvision, a lightweight and modular system integrating three key components, i.e., a Suspicious Object Detector based on an enhanced YOLOv12 architecture, dual Deep Convolutional Neural Networks (DCNN-I and DCNN-II) for facial expression and body-language recognition using image and landmark features, and a transformer-based Discriminator Network that adaptively fuses multimodal outputs to yield an interpretable suspiciousness score. Extensive experiments confirm the superior accuracy, robustness, and interpretability of the proposed framework compared to state-of-the-art approaches. Collectively, the USE50k dataset and the DeepUSEvision framework establish a strong and scalable foundation for intelligent surveillance and real-time risk assessment in safety-critical applications.

</details>


### [47] [Benchmarking Real-World Medical Image Classification with Noisy Labels: Challenges, Practice, and Outlook](https://arxiv.org/abs/2512.09315)
*Yuan Ma,Junlin Hou,Chao Zhang,Yukun Zhou,Zongyuan Ge,Haoran Xie,Lie Ju*

Main category: cs.CV

TL;DR: LNMBench是一个用于医学影像中标签噪声研究的综合性基准测试，评估了10种代表性方法在7个数据集、6种成像模态和3种噪声模式下的性能，揭示了现有方法在高噪声和真实世界噪声下的局限性。


<details>
  <summary>Details</summary>
Motivation: 医学图像标注需要专业知识且存在观察者间差异，导致标签噪声问题。现有噪声标签学习（LNL）方法在医学影像中的鲁棒性缺乏系统性评估，需要建立一个统一的基准测试框架。

Method: 构建LNMBench基准测试平台，涵盖7个数据集、6种成像模态和3种噪声模式，评估10种代表性LNL方法，并提出了一种简单有效的改进方法来增强模型在医疗数据中的鲁棒性。

Result: 综合实验表明，现有LNL方法在高噪声和真实世界噪声条件下性能显著下降，突显了医学数据中类别不平衡和领域变异性的挑战。提出的改进方法有效增强了模型鲁棒性。

Conclusion: LNMBench为医学影像噪声标签研究提供了标准化评估框架，揭示了现有方法的局限性，并提供实用改进方案。公开的代码库将促进可重复性研究，推动医疗领域噪声鲁棒算法的发展。

Abstract: Learning from noisy labels remains a major challenge in medical image analysis, where annotation demands expert knowledge and substantial inter-observer variability often leads to inconsistent or erroneous labels. Despite extensive research on learning with noisy labels (LNL), the robustness of existing methods in medical imaging has not been systematically assessed. To address this gap, we introduce LNMBench, a comprehensive benchmark for Label Noise in Medical imaging. LNMBench encompasses \textbf{10} representative methods evaluated across 7 datasets, 6 imaging modalities, and 3 noise patterns, establishing a unified and reproducible framework for robustness evaluation under realistic conditions. Comprehensive experiments reveal that the performance of existing LNL methods degrades substantially under high and real-world noise, highlighting the persistent challenges of class imbalance and domain variability in medical data. Motivated by these findings, we further propose a simple yet effective improvement to enhance model robustness under such conditions. The LNMBench codebase is publicly released to facilitate standardized evaluation, promote reproducible research, and provide practical insights for developing noise-resilient algorithms in both research and real-world medical applications.The codebase is publicly available on https://github.com/myyy777/LNMBench.

</details>


### [48] [UniLS: End-to-End Audio-Driven Avatars for Unified Listening and Speaking](https://arxiv.org/abs/2512.09327)
*Xuangeng Chu,Ruicong Liu,Yifei Huang,Yun Liu,Yichen Peng,Bo Zheng*

Main category: cs.CV

TL;DR: 本文提出了一个创新的实时端到端框架，用于从双声轨音频生成同步的说话者和倾听者面部表情，解决了现有方法中倾听者动作僵硬、多样性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的对话型数字人生成方法大多只关注说话者，忽视了说话与倾听的动态交互。直接基于音频训练难以生成自然的倾听者动作，导致僵硬和不自然的监听表情。这一挑战源于说话者动作受语音音频强烈驱动，而倾听者动作主要遵循内部动作先验，仅被外部语音松散引导。

Method: 提出名为UniLS的端到端框架，仅使用双声轨音频作为输入。采用新颖的两阶段训练范式：第一阶段训练一个无需音频的自回归生成器，学习自然面部动作的自发动态，捕捉内部动作先验；第二阶段引入双声轨音频，微调生成器，使其基于外部语音线索调制学习到的动作先验。

Result: 广泛的评估表明，UniLS在说话准确性方面达到了最先进的水平。更重要的是，它在倾听指标上实现了高达44.1%的提升，生成的倾听表情显著更加多样和自然。这有效缓解了僵硬问题，为交互式数字人提供了一个实用且高保真的音频驱动解决方案。

Conclusion: 通过创新的两阶段训练框架，UniLS首次实现了仅基于双声轨音频的端到端说话-倾听一体化表情生成，大幅提升了倾听者动作的自然性和多样性，为交互式数字人的实时应用开辟了新的可能性。

Abstract: Generating lifelike conversational avatars requires modeling not just isolated speakers, but the dynamic, reciprocal interaction of speaking and listening. However, modeling the listener is exceptionally challenging: direct audio-driven training fails, producing stiff, static listening motions. This failure stems from a fundamental imbalance: the speaker's motion is strongly driven by speech audio, while the listener's motion primarily follows an internal motion prior and is only loosely guided by external speech. This challenge has led most methods to focus on speak-only generation. The only prior attempt at joint generation relies on extra speaker's motion to produce the listener. This design is not end-to-end, thereby hindering the real-time applicability. To address this limitation, we present UniLS, the first end-to-end framework for generating unified speak-listen expressions, driven by only dual-track audio. Our method introduces a novel two-stage training paradigm. Stage 1 first learns the internal motion prior by training an audio-free autoregressive generator, capturing the spontaneous dynamics of natural facial motion. Stage 2 then introduces the dual-track audio, fine-tuning the generator to modulate the learned motion prior based on external speech cues. Extensive evaluations show UniLS achieves state-of-the-art speaking accuracy. More importantly, it delivers up to 44.1\% improvement in listening metrics, generating significantly more diverse and natural listening expressions. This effectively mitigates the stiffness problem and provides a practical, high-fidelity audio-driven solution for interactive digital humans.

</details>


### [49] [TextGuider: Training-Free Guidance for Text Rendering via Attention Alignment](https://arxiv.org/abs/2512.09350)
*Kanghyun Baek,Sangyub Lee,Jin Young Choi,Jaewoo Song,Daemin Park,Jooyoung Choi,Chaehun Shin,Bohyung Han,Sungroh Yoon*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Despite recent advances, diffusion-based text-to-image models still struggle with accurate text rendering. Several studies have proposed fine-tuning or training-free refinement methods for accurate text rendering. However, the critical issue of text omission, where the desired text is partially or entirely missing, remains largely overlooked. In this work, we propose TextGuider, a novel training-free method that encourages accurate and complete text appearance by aligning textual content tokens and text regions in the image. Specifically, we analyze attention patterns in MM-DiT models, particularly for text-related tokens intended to be rendered in the image. Leveraging this observation, we apply latent guidance during the early stage of denoising steps based on two loss functions that we introduce. Our method achieves state-of-the-art performance in test-time text rendering, with significant gains in recall and strong results in OCR accuracy and CLIP score.

</details>


### [50] [Video-QTR: Query-Driven Temporal Reasoning Framework for Lightweight Video Understanding](https://arxiv.org/abs/2512.09354)
*Xinkui Zhao,Zuxin Wang,Yifan Zhang,Guanjie Cheng,Yueshen Xu,Shuiguang Deng,Chang Liu,Naibo Wang,Jianwei Yin*

Main category: cs.CV

TL;DR: 提出Video-QTR框架，通过查询驱动实现视频理解的动态感知资源分配，降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 传统多模态大语言模型处理长视频时因密集帧编码导致内存消耗高、计算冗余，限制实际应用可扩展性。

Method: 采用查询驱动时态推理，建立推理与感知间的自适应反馈循环，避免编码每一帧，根据查询语义动态分配感知资源。

Result: 在MSVD-QA等五个基准测试中达到SOTA性能，输入帧消耗减少高达73%。

Conclusion: 查询驱动时态推理为高效可扩展的视频理解提供了有效解决方案。

Abstract: The rapid development of multimodal large-language models (MLLMs) has significantly expanded the scope of visual language reasoning, enabling unified systems to interpret and describe complex visual content. However, applying these models to long-video understanding remains computationally intensive. Dense frame encoding generates excessive visual tokens, leading to high memory consumption, redundant computation, and limited scalability in real-world applications. This inefficiency highlights a key limitation of the traditional process-then-reason paradigm, which analyzes visual streams exhaustively before semantic reasoning. To address this challenge, we introduce Video-QTR (Query-Driven Temporal Reasoning), a lightweight framework that redefines video comprehension as a query-guided reasoning process. Instead of encoding every frame, Video-QTR dynamically allocates perceptual resources based on the semantic intent of the query, creating an adaptive feedback loop between reasoning and perception. Extensive experiments across five benchmarks: MSVD-QA, Activity Net-QA, Movie Chat, and Video MME demonstrate that Video-QTR achieves state-of-the-art performance while reducing input frame consumption by up to 73%. These results confirm that query-driven temporal reasoning provides an efficient and scalable solution for video understanding.

</details>


### [51] [StereoWorld: Geometry-Aware Monocular-to-Stereo Video Generation](https://arxiv.org/abs/2512.09363)
*Ke Xing,Longfei Li,Yuyang Yin,Hanwen Liang,Guixun Luo,Chen Fang,Jue Wang,Konstantinos N. Plataniotis,Xiaojie Jin,Yao Zhao,Yunchao Wei*

Main category: cs.CV

TL;DR: StereoWorld：利用预训练的视频生成器，通过几何感知正则化和时空分块策略，实现从单目到立体视频的高保真生成。


<details>
  <summary>Details</summary>
Motivation: XR设备的普及推动了对高质量立体视频的需求，但现有制作方法成本高且易产生伪影。StereoWorld旨在解决这一挑战，提供高效、高质量的立体视频生成方案。

Method: 基于预训练视频生成器，结合输入单目视频的联合条件化以及几何感知正则化来保证3D结构保真度，并采用时空分块方案实现高效的高分辨率合成。

Result: 构建了包含超过1100万帧、符合人眼瞳距的高清立体视频数据集。实验表明，该框架在视觉质量和几何一致性上显著优于现有方法。

Conclusion: StereoWorld为单目到立体视频的生成提供了高效、高质量的解决方案，为XR内容制作提供了新途径。

Abstract: The growing adoption of XR devices has fueled strong demand for high-quality stereo video, yet its production remains costly and artifact-prone. To address this challenge, we present StereoWorld, an end-to-end framework that repurposes a pretrained video generator for high-fidelity monocular-to-stereo video generation. Our framework jointly conditions the model on the monocular video input while explicitly supervising the generation with a geometry-aware regularization to ensure 3D structural fidelity. A spatio-temporal tiling scheme is further integrated to enable efficient, high-resolution synthesis. To enable large-scale training and evaluation, we curate a high-definition stereo video dataset containing over 11M frames aligned to natural human interpupillary distance (IPD). Extensive experiments demonstrate that StereoWorld substantially outperforms prior methods, generating stereo videos with superior visual fidelity and geometric consistency. The project webpage is available at https://ke-xing.github.io/StereoWorld/.

</details>


### [52] [ASSIST-3D: Adapted Scene Synthesis for Class-Agnostic 3D Instance Segmentation](https://arxiv.org/abs/2512.09364)
*Shengchao Zhou,Jiehong Lin,Jiahui Liu,Shizhen Zhao,Chirui Chang,Xiaojuan Qi*

Main category: cs.CV

TL;DR: 提出了一个名为ASSIST-3D的合成3D场景生成流程，用于增强类不可知3D实例分割模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的类不可知3D实例分割方法由于标注的3D场景数据不足或2D分割噪声而难以泛化。虽然合成数据生成是一种有希望的解决方案，但现有的3D场景合成方法无法同时满足几何多样性、上下文复杂性和布局合理性这三个对该任务至关重要的需求。

Method: ASSIST-3D通过三个关键创新来解决这些问题：1) 从大量3D CAD资产库中进行随机化采样的异构对象选择，以最大化几何和上下文多样性；2) 通过LLM引导的空间推理结合深度优先搜索进行场景布局生成，实现合理的对象放置；3) 通过从合成场景进行多视图RGB-D图像渲染和融合，构建真实的点云数据，以模拟真实世界的传感器数据采集。

Result: 在ScanNetV2、ScanNet++和S3DIS基准测试上的实验表明，使用ASSIST-3D生成的数据训练的模型显著优于现有方法。进一步的比较证明了我们专门构建的流程相对于现有3D场景合成方法的优越性。

Conclusion: ASSIST-3D是一个有效的合成数据生成框架，能够综合满足类不可知3D实例分割所需的场景特性，从而显著提升模型的泛化性能。

Abstract: Class-agnostic 3D instance segmentation tackles the challenging task of segmenting all object instances, including previously unseen ones, without semantic class reliance. Current methods struggle with generalization due to the scarce annotated 3D scene data or noisy 2D segmentations. While synthetic data generation offers a promising solution, existing 3D scene synthesis methods fail to simultaneously satisfy geometry diversity, context complexity, and layout reasonability, each essential for this task. To address these needs, we propose an Adapted 3D Scene Synthesis pipeline for class-agnostic 3D Instance SegmenTation, termed as ASSIST-3D, to synthesize proper data for model generalization enhancement. Specifically, ASSIST-3D features three key innovations, including 1) Heterogeneous Object Selection from extensive 3D CAD asset collections, incorporating randomness in object sampling to maximize geometric and contextual diversity; 2) Scene Layout Generation through LLM-guided spatial reasoning combined with depth-first search for reasonable object placements; and 3) Realistic Point Cloud Construction via multi-view RGB-D image rendering and fusion from the synthetic scenes, closely mimicking real-world sensor data acquisition. Experiments on ScanNetV2, ScanNet++, and S3DIS benchmarks demonstrate that models trained with ASSIST-3D-generated data significantly outperform existing methods. Further comparisons underscore the superiority of our purpose-built pipeline over existing 3D scene synthesis approaches.

</details>


### [53] [FUSER: Feed-Forward MUltiview 3D Registration Transformer and SE(3)$^N$ Diffusion Refinement](https://arxiv.org/abs/2512.09373)
*Haobo Jiang,Jin Xie,Jian Yang,Liang Yu,Jianmin Zheng*

Main category: cs.CV

TL;DR: FUSER是一个前馈式多视图点云配准框架，通过Transformer在紧凑的潜在空间中联合处理所有扫描数据，直接预测全局姿态，无需成对配准。FUSER-DF进一步通过SE(3)^N扩散细化框架修正FUSER的估计结果，在多个数据集上展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统的多视图点云配准方法依赖大量成对匹配来构建姿态图进行全局同步，这计算成本高且在缺乏整体几何约束时具有内在不适定性。需要一种能直接全局配准的高效方法。

Method: FUSER使用稀疏3D CNN将每个扫描编码为低分辨率超点特征，通过几何交替注意力模块进行高效的特征交互，并利用预训练2D注意力先验增强3D几何一致性。FUSER-DF在此基础上建立了SE(3)^N条件扩散细化框架，通过在联合SE(3)^N空间中去噪来修正FUSER的估计结果。

Result: 在3DMatch、ScanNet和ArkitScenes数据集上的大量实验表明，该方法实现了优越的配准精度和出色的计算效率，超越了传统方法。

Conclusion: FUSER框架首次实现了前馈式的多视图点云全局配准，避免了成对配准的计算瓶颈，而FUSER-DF通过扩散细化进一步提升了配准精度，为多视图配准问题提供了新的解决方案。

Abstract: Registration of multiview point clouds conventionally relies on extensive pairwise matching to build a pose graph for global synchronization, which is computationally expensive and inherently ill-posed without holistic geometric constraints. This paper proposes FUSER, the first feed-forward multiview registration transformer that jointly processes all scans in a unified, compact latent space to directly predict global poses without any pairwise estimation. To maintain tractability, FUSER encodes each scan into low-resolution superpoint features via a sparse 3D CNN that preserves absolute translation cues, and performs efficient intra- and inter-scan reasoning through a Geometric Alternating Attention module. Particularly, we transfer 2D attention priors from off-the-shelf foundation models to enhance 3D feature interaction and geometric consistency. Building upon FUSER, we further introduce FUSER-DF, an SE(3)$^N$ diffusion refinement framework to correct FUSER's estimates via denoising in the joint SE(3)$^N$ space. FUSER acts as a surrogate multiview registration model to construct the denoiser, and a prior-conditioned SE(3)$^N$ variational lower bound is derived for denoising supervision. Extensive experiments on 3DMatch, ScanNet and ArkitScenes demonstrate that our approach achieves the superior registration accuracy and outstanding computational efficiency.

</details>


### [54] [Log NeRF: Comparing Spaces for Learning Radiance Fields](https://arxiv.org/abs/2512.09375)
*Sihe Chen,Luv Verma,Bruce A. Maxwell*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Neural Radiance Fields (NeRF) have achieved remarkable results in novel view synthesis, typically using sRGB images for supervision. However, little attention has been paid to the color space in which the network is learning the radiance field representation. Inspired by the BiIlluminant Dichromatic Reflection (BIDR) model, which suggests that a logarithmic transformation simplifies the separation of illumination and reflectance, we hypothesize that log RGB space enables NeRF to learn a more compact and effective representation of scene appearance. To test this, we captured approximately 30 videos using a GoPro camera, ensuring linear data recovery through inverse encoding. We trained NeRF models under various color space interpretations linear, sRGB, GPLog, and log RGB by converting each network output to a common color space before rendering and loss computation, enforcing representation learning in different color spaces. Quantitative and qualitative evaluations demonstrate that using a log RGB color space consistently improves rendering quality, exhibits greater robustness across scenes, and performs particularly well in low light conditions while using the same bit-depth input images. Further analysis across different network sizes and NeRF variants confirms the generalization and stability of the log space advantage.

</details>


### [55] [Detection and Localization of Subdural Hematoma Using Deep Learning on Computed Tomography](https://arxiv.org/abs/2512.09393)
*Vasiliki Stoumpou,Rohan Kumar,Bernard Burman,Diego Ojeda,Tapan Mehta,Dimitris Bertsimas*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Background. Subdural hematoma (SDH) is a common neurosurgical emergency, with increasing incidence in aging populations. Rapid and accurate identification is essential to guide timely intervention, yet existing automated tools focus primarily on detection and provide limited interpretability or spatial localization. There remains a need for transparent, high-performing systems that integrate multimodal clinical and imaging information to support real-time decision-making.
  Methods. We developed a multimodal deep-learning framework that integrates structured clinical variables, a 3D convolutional neural network trained on CT volumes, and a transformer-enhanced 2D segmentation model for SDH detection and localization. Using 25,315 head CT studies from Hartford HealthCare (2015--2024), of which 3,774 (14.9\%) contained clinician-confirmed SDH, tabular models were trained on demographics, comorbidities, medications, and laboratory results. Imaging models were trained to detect SDH and generate voxel-level probability maps. A greedy ensemble strategy combined complementary predictors.
  Findings. Clinical variables alone provided modest discriminatory power (AUC 0.75). Convolutional models trained on CT volumes and segmentation-derived maps achieved substantially higher accuracy (AUCs 0.922 and 0.926). The multimodal ensemble integrating all components achieved the best overall performance (AUC 0.9407; 95\% CI, 0.930--0.951) and produced anatomically meaningful localization maps consistent with known SDH patterns.
  Interpretation. This multimodal, interpretable framework provides rapid and accurate SDH detection and localization, achieving high detection performance and offering transparent, anatomically grounded outputs. Integration into radiology workflows could streamline triage, reduce time to intervention, and improve consistency in SDH management.

</details>


### [56] [Wasserstein-Aligned Hyperbolic Multi-View Clustering](https://arxiv.org/abs/2512.09402)
*Rui Wang,Yuting Jiang,Xiaoqing Luo,Xiao-Jun Wu,Nicu Sebe,Ziheng Chen*

Main category: cs.CV

TL;DR: 该论文提出了一个名为WAH的新框架用于多视图聚类，利用双曲编码器和双曲切片瓦瑟斯坦距离来对齐视图间的全局语义分布，实现了最先进的聚类性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多视图聚类方法主要关注实例级对齐，忽略了全局语义一致性，容易受到视图特定信息（如噪声和跨视图差异）的影响。本文旨在通过引入全局语义对齐来改进多视图聚类。

Method: 该方法为每个视图设计了一个视图特定的双曲编码器，将特征嵌入到洛伦兹流形中进行分层语义建模。然后引入基于双曲切片瓦瑟斯坦距离的全局语义损失来对齐跨视图的流形分布，最后通过软聚类分配来促进跨视图语义一致性。

Result: 在多个基准数据集上的广泛实验表明，该方法能够达到最先进的聚类性能。

Conclusion: 提出的WAH框架通过全局语义对齐有效解决了多视图聚类中的视图特定信息干扰问题，实现了优异的聚类效果，为多视图数据分析提供了新的解决方案。

Abstract: Multi-view clustering (MVC) aims to uncover the latent structure of multi-view data by learning view-common and view-specific information. Although recent studies have explored hyperbolic representations for better tackling the representation gap between different views, they focus primarily on instance-level alignment and neglect global semantic consistency, rendering them vulnerable to view-specific information (\textit{e.g.}, noise and cross-view discrepancies). To this end, this paper proposes a novel Wasserstein-Aligned Hyperbolic (WAH) framework for multi-view clustering. Specifically, our method exploits a view-specific hyperbolic encoder for each view to embed features into the Lorentz manifold for hierarchical semantic modeling. Whereafter, a global semantic loss based on the hyperbolic sliced-Wasserstein distance is introduced to align manifold distributions across views. This is followed by soft cluster assignments to encourage cross-view semantic consistency. Extensive experiments on multiple benchmarking datasets show that our method can achieve SOTA clustering performance.

</details>


### [57] [Generative Point Cloud Registration](https://arxiv.org/abs/2512.09407)
*Haobo Jiang,Jin Xie,Jian Yang,Liang Yu,Jianmin Zheng*

Main category: cs.CV

TL;DR: 提出生成式点云配准新范式，利用2D生成模型构建与点云几何颜色对齐的图像对，通过Match-ControlNet确保生成图像的几何与纹理一致性，提升3D配准性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D配准方法主要依赖几何信息，而忽略颜色纹理等视觉特征。为了融合几何与颜色信息并提升配准效果，需要一种能够生成与点云几何对齐且具有跨视图一致性的图像对的生成模型。

Method: 提出生成式点云配准框架，引入Match-ControlNet可控生成模型。该模型利用ControlNet的深度条件生成能力，从点云深度图生成几何对齐图像；通过耦合条件去噪方案和耦合提示引导，促进跨视图特征交互，确保纹理一致性。

Result: 在3DMatch和ScanNet数据集上的大量实验验证了方法的有效性。该生成范式具有通用性，可无缝集成到多种配准方法中提升性能。

Conclusion: 生成式点云配准范式成功地将2D生成模型与3D匹配任务结合，通过生成几何和纹理一致的图像对，实现了几何与颜色特征的融合，显著提升了配准性能。

Abstract: In this paper, we propose a novel 3D registration paradigm, Generative Point Cloud Registration, which bridges advanced 2D generative models with 3D matching tasks to enhance registration performance. Our key idea is to generate cross-view consistent image pairs that are well-aligned with the source and target point clouds, enabling geometry-color feature fusion to facilitate robust matching. To ensure high-quality matching, the generated image pair should feature both 2D-3D geometric consistency and cross-view texture consistency. To achieve this, we introduce Match-ControlNet, a matching-specific, controllable 2D generative model. Specifically, it leverages the depth-conditioned generation capability of ControlNet to produce images that are geometrically aligned with depth maps derived from point clouds, ensuring 2D-3D geometric consistency. Additionally, by incorporating a coupled conditional denoising scheme and coupled prompt guidance, Match-ControlNet further promotes cross-view feature interaction, guiding texture consistency generation. Our generative 3D registration paradigm is general and could be seamlessly integrated into various registration methods to enhance their performance. Extensive experiments on 3DMatch and ScanNet datasets verify the effectiveness of our approach.

</details>


### [58] [DirectSwap: Mask-Free Cross-Identity Training and Benchmarking for Expression-Consistent Video Head Swapping](https://arxiv.org/abs/2512.09417)
*Yanan Wang,Shengcai Liao,Panwen Hu,Xin Li,Fan Yang,Xiaodan Liang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Video head swapping aims to replace the entire head of a video subject, including facial identity, head shape, and hairstyle, with that of a reference image, while preserving the target body, background, and motion dynamics. Due to the lack of ground-truth paired swapping data, prior methods typically train on cross-frame pairs of the same person within a video and rely on mask-based inpainting to mitigate identity leakage. Beyond potential boundary artifacts, this paradigm struggles to recover essential cues occluded by the mask, such as facial pose, expressions, and motion dynamics. To address these issues, we prompt a video editing model to synthesize new heads for existing videos as fake swapping inputs, while maintaining frame-synchronized facial poses and expressions. This yields HeadSwapBench, the first cross-identity paired dataset for video head swapping, which supports both training (\TrainNum{} videos) and benchmarking (\TestNum{} videos) with genuine outputs. Leveraging this paired supervision, we propose DirectSwap, a mask-free, direct video head-swapping framework that extends an image U-Net into a video diffusion model with a motion module and conditioning inputs. Furthermore, we introduce the Motion- and Expression-Aware Reconstruction (MEAR) loss, which reweights the diffusion loss per pixel using frame-difference magnitudes and facial-landmark proximity, thereby enhancing cross-frame coherence in motion and expressions. Extensive experiments demonstrate that DirectSwap achieves state-of-the-art visual quality, identity fidelity, and motion and expression consistency across diverse in-the-wild video scenes. We will release the source code and the HeadSwapBench dataset to facilitate future research.

</details>


### [59] [Label-free Motion-Conditioned Diffusion Model for Cardiac Ultrasound Synthesis](https://arxiv.org/abs/2512.09418)
*Zhe Li,Hadrien Reynaud,Johanna P Müller,Bernhard Kainz*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Ultrasound echocardiography is essential for the non-invasive, real-time assessment of cardiac function, but the scarcity of labelled data, driven by privacy restrictions and the complexity of expert annotation, remains a major obstacle for deep learning methods. We propose the Motion Conditioned Diffusion Model (MCDM), a label-free latent diffusion framework that synthesises realistic echocardiography videos conditioned on self-supervised motion features. To extract these features, we design the Motion and Appearance Feature Extractor (MAFE), which disentangles motion and appearance representations from videos. Feature learning is further enhanced by two auxiliary objectives: a re-identification loss guided by pseudo appearance features and an optical flow loss guided by pseudo flow fields. Evaluated on the EchoNet-Dynamic dataset, MCDM achieves competitive video generation performance, producing temporally coherent and clinically realistic sequences without reliance on manual labels. These results demonstrate the potential of self-supervised conditioning for scalable echocardiography synthesis. Our code is available at https://github.com/ZheLi2020/LabelfreeMCDM.

</details>


### [60] [InfoMotion: A Graph-Based Approach to Video Dataset Distillation for Echocardiography](https://arxiv.org/abs/2512.09422)
*Zhe Li,Hadrien Reynaud,Alberto Gomez,Bernhard Kainz*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Echocardiography playing a critical role in the diagnosis and monitoring of cardiovascular diseases as a non-invasive real-time assessment of cardiac structure and function. However, the growing scale of echocardiographic video data presents significant challenges in terms of storage, computation, and model training efficiency. Dataset distillation offers a promising solution by synthesizing a compact, informative subset of data that retains the key clinical features of the original dataset. In this work, we propose a novel approach for distilling a compact synthetic echocardiographic video dataset. Our method leverages motion feature extraction to capture temporal dynamics, followed by class-wise graph construction and representative sample selection using the Infomap algorithm. This enables us to select a diverse and informative subset of synthetic videos that preserves the essential characteristics of the original dataset. We evaluate our approach on the EchoNet-Dynamic datasets and achieve a test accuracy of \(69.38\%\) using only \(25\) synthetic videos. These results demonstrate the effectiveness and scalability of our method for medical video dataset distillation.

</details>


### [61] [FunPhase: A Periodic Functional Autoencoder for Motion Generation via Phase Manifolds](https://arxiv.org/abs/2512.09423)
*Marco Pegoraro,Evan Atherton,Bruno Roy,Aliasghar Khani,Arianna Rampini*

Main category: cs.CV

TL;DR: FunPhase是一个功能性周期自编码器，通过函数空间建模学习运动的相位流形，实现了任意时间分辨率采样和多种下游任务支持。


<details>
  <summary>Details</summary>
Motivation: 人体运动学习中空间几何与时间动态的强耦合性具有挑战性，现有基于相位流形的运动预测方法缺乏可扩展性和通用性。

Method: FunPhase采用功能性周期自编码器，学习运动的相位流形，用函数空间公式替代离散时间解码，实现平滑轨迹和任意时间分辨率采样。

Result: FunPhase相比先前的周期自编码器基线重构误差显著降低，支持超分辨率、部分身体运动补全等任务，能跨骨架和数据集泛化，性能与最先进的运动生成方法相当。

Conclusion: FunPhase在统一的相位流形中实现运动预测和生成，具有更好的解释性、可扩展性和应用范围，为人体运动学习提供有效方案。

Abstract: Learning natural body motion remains challenging due to the strong coupling between spatial geometry and temporal dynamics. Embedding motion in phase manifolds, latent spaces that capture local periodicity, has proven effective for motion prediction; however, existing approaches lack scalability and remain confined to specific settings. We introduce FunPhase, a functional periodic autoencoder that learns a phase manifold for motion and replaces discrete temporal decoding with a function-space formulation, enabling smooth trajectories that can be sampled at arbitrary temporal resolutions. FunPhase supports downstream tasks such as super-resolution and partial-body motion completion, generalizes across skeletons and datasets, and unifies motion prediction and generation within a single interpretable manifold. Our model achieves substantially lower reconstruction error than prior periodic autoencoder baselines while enabling a broader range of applications and performing on par with state-of-the-art motion generation methods.

</details>


### [62] [UniPart: Part-Level 3D Generation with Unified 3D Geom-Seg Latents](https://arxiv.org/abs/2512.09435)
*Xufan He,Yushuang Wu,Xiaoyang Guo,Chongjie Ye,Jiaqing Zhou,Tianlei Hu,Xiaoguang Han,Dong Du*

Main category: cs.CV

TL;DR: UniPart：一种基于几何分割潜在表示的两阶段潜在扩散框架，用于图像引导的部分层级3D生成，通过联合编码物体几何和部分结构，实现更好的分割可控性和几何质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在部分层级3D生成上存在问题：要么依赖粒度控制有限的隐式部分分割，要么需要基于大量标注数据训练的强外部分割器。同时观察到部分感知在整体物体几何学习中自然出现。

Method: 提出Geom-Seg VecSet作为统一的几何-分割潜在表示，联合编码物体几何和部分层级结构。基于该表示开发两阶段潜在扩散框架：第一阶段进行联合几何生成和潜在部分分割；第二阶段基于整体物体和部分特定潜在变量进行部分层级扩散。采用双空间生成方案，通过在全局和规范空间中预测部分潜在变量来增强几何保真度。

Result: 大量实验表明，UniPart相比现有方法在分割可控性和部分层级几何质量方面表现更优。

Conclusion: UniPart通过新颖的几何-分割联合表示和两阶段扩散框架，成功实现了高质量的图像引导部分层级3D生成，在分割可控性和几何质量上超越了现有方法。

Abstract: Part-level 3D generation is essential for applications requiring decomposable and structured 3D synthesis. However, existing methods either rely on implicit part segmentation with limited granularity control or depend on strong external segmenters trained on large annotated datasets. In this work, we observe that part awareness emerges naturally during whole-object geometry learning and propose Geom-Seg VecSet, a unified geometry-segmentation latent representation that jointly encodes object geometry and part-level structure. Building on this representation, we introduce UniPart, a two-stage latent diffusion framework for image-guided part-level 3D generation. The first stage performs joint geometry generation and latent part segmentation, while the second stage conditions part-level diffusion on both whole-object and part-specific latents. A dual-space generation scheme further enhances geometric fidelity by predicting part latents in both global and canonical spaces. Extensive experiments demonstrate that UniPart achieves superior segmentation controllability and part-level geometric quality compared with existing approaches.

</details>


### [63] [Representation Calibration and Uncertainty Guidance for Class-Incremental Learning based on Vision Language Model](https://arxiv.org/abs/2512.09441)
*Jiantao Tan,Peixian Ma,Tong Yu,Wentao Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Class-incremental learning requires a learning system to continually learn knowledge of new classes and meanwhile try to preserve previously learned knowledge of old classes. As current state-of-the-art methods based on Vision-Language Models (VLMs) still suffer from the issue of differentiating classes across learning tasks. Here a novel VLM-based continual learning framework for image classification is proposed. In this framework, task-specific adapters are added to the pre-trained and frozen image encoder to learn new knowledge, and a novel cross-task representation calibration strategy based on a mixture of light-weight projectors is used to help better separate all learned classes in a unified feature space, alleviating class confusion across tasks. In addition, a novel inference strategy guided by prediction uncertainty is developed to more accurately select the most appropriate image feature for class prediction. Extensive experiments on multiple datasets under various settings demonstrate the superior performance of our method compared to existing ones.

</details>


### [64] [Defect-aware Hybrid Prompt Optimization via Progressive Tuning for Zero-Shot Multi-type Anomaly Detection and Segmentation](https://arxiv.org/abs/2512.09446)
*Nadeem Nazer,Hongkuan Zhou,Lavdim Halilaj,Ylli Sadikaj,Steffen Staab*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent vision language models (VLMs) like CLIP have demonstrated impressive anomaly detection performance under significant distribution shift by utilizing high-level semantic information through text prompts. However, these models often neglect fine-grained details, such as which kind of anomalies, like "hole", "cut", "scratch" that could provide more specific insight into the nature of anomalies. We argue that recognizing fine-grained anomaly types 1) enriches the representation of "abnormal" with structured semantics, narrowing the gap between coarse anomaly signals and fine-grained defect categories; 2) enables manufacturers to understand the root causes of the anomaly and implement more targeted and appropriate corrective measures quickly. While incorporating such detailed semantic information is crucial, designing handcrafted prompts for each defect type is both time-consuming and susceptible to human bias. For this reason, we introduce DAPO, a novel approach for Defect-aware Prompt Optimization based on progressive tuning for the zero-shot multi-type and binary anomaly detection and segmentation under distribution shifts. Our approach aligns anomaly-relevant image features with their corresponding text semantics by learning hybrid defect-aware prompts with both fixed textual anchors and learnable token embeddings. We conducted experiments on public benchmarks (MPDD, VisA, MVTec-AD, MAD, and Real-IAD) and an internal dataset. The results suggest that compared to the baseline models, DAPO achieves a 3.7% average improvement in AUROC and average precision metrics at the image level under distribution shift, and a 6.5% average improvement in localizing novel anomaly types under zero-shot settings.

</details>


### [65] [Cytoplasmic Strings Analysis in Human Embryo Time-Lapse Videos using Deep Learning Framework](https://arxiv.org/abs/2512.09461)
*Anabia Sohail,Mohamad Alansari,Ahmed Abughali,Asmaa Chehab,Abdelfatah Ahmed,Divya Velayudhan,Sajid Javed,Hasan Al Marzouqi,Ameena Saad Al-Sumaiti,Junaid Kashir,Naoufel Werghi*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Infertility is a major global health issue, and while in-vitro fertilization has improved treatment outcomes, embryo selection remains a critical bottleneck. Time-lapse imaging enables continuous, non-invasive monitoring of embryo development, yet most automated assessment methods rely solely on conventional morphokinetic features and overlook emerging biomarkers. Cytoplasmic Strings, thin filamentous structures connecting the inner cell mass and trophectoderm in expanded blastocysts, have been associated with faster blastocyst formation, higher blastocyst grades, and improved viability. However, CS assessment currently depends on manual visual inspection, which is labor-intensive, subjective, and severely affected by detection and subtle visual appearance. In this work, we present, to the best of our knowledge, the first computational framework for CS analysis in human IVF embryos. We first design a human-in-the-loop annotation pipeline to curate a biologically validated CS dataset from TLI videos, comprising 13,568 frames with highly sparse CS-positive instances. Building on this dataset, we propose a two-stage deep learning framework that (i) classifies CS presence at the frame level and (ii) localizes CS regions in positive cases. To address severe imbalance and feature uncertainty, we introduce the Novel Uncertainty-aware Contractive Embedding (NUCE) loss, which couples confidence-aware reweighting with an embedding contraction term to form compact, well-separated class clusters. NUCE consistently improves F1-score across five transformer backbones, while RF-DETR-based localization achieves state-of-the-art (SOTA) detection performance for thin, low-contrast CS structures. The source code will be made publicly available at: https://github.com/HamadYA/CS_Detection.

</details>


### [66] [Privacy-Preserving Computer Vision for Industry: Three Case Studies in Human-Centric Manufacturing](https://arxiv.org/abs/2512.09463)
*Sander De Coninck,Emilio Gamba,Bart Van Doninck,Abdellatif Bey-Temsamani,Sam Leroux,Pieter Simoens*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The adoption of AI-powered computer vision in industry is often constrained by the need to balance operational utility with worker privacy. Building on our previously proposed privacy-preserving framework, this paper presents its first comprehensive validation on real-world data collected directly by industrial partners in active production environments. We evaluate the framework across three representative use cases: woodworking production monitoring, human-aware AGV navigation, and multi-camera ergonomic risk assessment. The approach employs learned visual transformations that obscure sensitive or task-irrelevant information while retaining features essential for task performance. Through both quantitative evaluation of the privacy-utility trade-off and qualitative feedback from industrial partners, we assess the framework's effectiveness, deployment feasibility, and trust implications. Results demonstrate that task-specific obfuscation enables effective monitoring with reduced privacy risks, establishing the framework's readiness for real-world adoption and providing cross-domain recommendations for responsible, human-centric AI deployment in industry.

</details>


### [67] [Color encoding in Latent Space of Stable Diffusion Models](https://arxiv.org/abs/2512.09477)
*Guillem Arias,Ariadna Solà,Martí Armengod,Maria Vanrell*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent advances in diffusion-based generative models have achieved remarkable visual fidelity, yet a detailed understanding of how specific perceptual attributes - such as color and shape - are internally represented remains limited. This work explores how color is encoded in a generative model through a systematic analysis of the latent representations in Stable Diffusion. Through controlled synthetic datasets, principal component analysis (PCA) and similarity metrics, we reveal that color information is encoded along circular, opponent axes predominantly captured in latent channels c_3 and c_4, whereas intensity and shape are primarily represented in channels c_1 and c_2. Our findings indicate that the latent space of Stable Diffusion exhibits an interpretable structure aligned with a efficient coding representation. These insights provide a foundation for future work in model understanding, editing applications, and the design of more disentangled generative frameworks.

</details>


### [68] [MODA: The First Challenging Benchmark for Multispectral Object Detection in Aerial Images](https://arxiv.org/abs/2512.09489)
*Shuaihao Han,Tingfa Xu,Peifu Liu,Jianan Li*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Aerial object detection faces significant challenges in real-world scenarios, such as small objects and extensive background interference, which limit the performance of RGB-based detectors with insufficient discriminative information. Multispectral images (MSIs) capture additional spectral cues across multiple bands, offering a promising alternative. However, the lack of training data has been the primary bottleneck to exploiting the potential of MSIs. To address this gap, we introduce the first large-scale dataset for Multispectral Object Detection in Aerial images (MODA), which comprises 14,041 MSIs and 330,191 annotations across diverse, challenging scenarios, providing a comprehensive data foundation for this field. Furthermore, to overcome challenges inherent to aerial object detection using MSIs, we propose OSSDet, a framework that integrates spectral and spatial information with object-aware cues. OSSDet employs a cascaded spectral-spatial modulation structure to optimize target perception, aggregates spectrally related features by exploiting spectral similarities to reinforce intra-object correlations, and suppresses irrelevant background via object-aware masking. Moreover, cross-spectral attention further refines object-related representations under explicit object-aware guidance. Extensive experiments demonstrate that OSSDet outperforms existing methods with comparable parameters and efficiency.

</details>


### [69] [StateSpace-SSL: Linear-Time Self-supervised Learning for Plant Disease Detectio](https://arxiv.org/abs/2512.09492)
*Abdullah Al Mamun,Miaohua Zhang,David Ahmedt-Aristizabal,Zeeshan Hayder,Mohammad Awrangjeb*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Self-supervised learning (SSL) is attractive for plant disease detection as it can exploit large collections of unlabeled leaf images, yet most existing SSL methods are built on CNNs or vision transformers that are poorly matched to agricultural imagery. CNN-based SSL struggles to capture disease patterns that evolve continuously along leaf structures, while transformer-based SSL introduces quadratic attention cost from high-resolution patches. To address these limitations, we propose StateSpace-SSL, a linear-time SSL framework that employs a Vision Mamba state-space encoder to model long-range lesion continuity through directional scanning across the leaf surface. A prototype-driven teacher-student objective aligns representations across multiple views, encouraging stable and lesion-aware features from labelled data. Experiments on three publicly available plant disease datasets show that StateSpace-SSL consistently outperforms the CNN- and transformer-based SSL baselines in various evaluation metrics. Qualitative analyses further confirm that it learns compact, lesion-focused feature maps, highlighting the advantage of linear state-space modelling for self-supervised plant disease representation learning.

</details>


### [70] [Building Reasonable Inference for Vision-Language Models in Blind Image Quality Assessment](https://arxiv.org/abs/2512.09555)
*Yuan Li,Zitang Sun,Yen-ju Chen,Shin'ya Nishida*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent progress in BIQA has been driven by VLMs, whose semantic reasoning abilities suggest that they might extract visual features, generate descriptive text, and infer quality in a human-like manner. However, these models often produce textual descriptions that contradict their final quality predictions, and the predicted scores can change unstably during inference - behaviors not aligned with human reasoning. To understand these issues, we analyze the factors that cause contradictory assessments and instability. We first estimate the relationship between the final quality predictions and the generated visual features, finding that the predictions are not fully grounded in the features and that the logical connection between them is weak. Moreover, decoding intermediate VLM layers shows that the model frequently relies on a limited set of candidate tokens, which contributes to prediction instability. To encourage more human-like reasoning, we introduce a two-stage tuning method that explicitly separates visual perception from quality inference. In the first stage, the model learns visual features; in the second, it infers quality solely from these features. Experiments on SPAQ and KONIQ demonstrate that our approach reduces prediction instability from 22.00% to 12.39% and achieves average gains of 0.3124/0.3507 in SRCC/PLCC across LIVE, CSIQ, SPAQ, and KONIQ compared to the baseline. Further analyses show that our method improves both stability and the reliability of the inference process.

</details>


### [71] [From Graphs to Gates: DNS-HyXNet, A Lightweight and Deployable Sequential Model for Real-Time DNS Tunnel Detection](https://arxiv.org/abs/2512.09565)
*Faraz Ali,Muhammad Afaq,Mahmood Niazi,Muzammil Behzad*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Domain Name System (DNS) tunneling remains a covert channel for data exfiltration and command-and-control communication. Although graph-based methods such as GraphTunnel achieve strong accuracy, they introduce significant latency and computational overhead due to recursive parsing and graph construction, limiting their suitability for real-time deployment. This work presents DNS-HyXNet, a lightweight extended Long Short-Term Memory (xLSTM) hybrid framework designed for efficient sequence-based DNS tunnel detection. DNS-HyXNet integrates tokenized domain embeddings with normalized numerical DNS features and processes them through a two-layer xLSTM network that directly learns temporal dependencies from packet sequences, eliminating the need for graph reconstruction and enabling single-stage multi-class classification. The model was trained and evaluated on two public benchmark datasets with carefully tuned hyperparameters to ensure low memory consumption and fast inference. Across all experimental splits of the DNS-Tunnel-Datasets, DNS-HyXNet achieved up to 99.99% accuracy, with macro-averaged precision, recall, and F1-scores exceeding 99.96%, and demonstrated a per-sample detection latency of just 0.041 ms, confirming its scalability and real-time readiness. These results show that sequential modeling with xLSTM can effectively replace computationally expensive recursive graph generation, offering a deployable and energy-efficient alternative for real-time DNS tunnel detection on commodity hardware.

</details>


### [72] [Investigate the Low-level Visual Perception in Vision-Language based Image Quality Assessment](https://arxiv.org/abs/2512.09573)
*Yuan Li,Zitang Sun,Yen-Ju Chen,Shin'ya Nishida*

Main category: cs.CV

TL;DR: MLLM在图像质量评估中存在低层次失真感知不足的问题，通过组件分析和视觉编码器对齐优化提升失真识别。


<details>
  <summary>Details</summary>
Motivation: 解决MLLM在图像质量评估中无法可靠检测基本低层次失真（如模糊、噪声、压缩）的问题，探究其是否真正感知重要视觉特征。

Method: 引入低层次失真感知任务，对MLLM进行组件分析，通过计算视觉特征与语义标记的语义距离并优化视觉编码器对齐。

Result: 优化视觉编码器对齐后，失真识别准确率从14.92%显著提升至84.43%。

Conclusion: 在视觉编码器中加入专门约束可增强文本可解释的视觉表示，使MLLM在视觉任务中产生更一致、可解释的推理。

Abstract: Recent advances in Image Quality Assessment (IQA) have leveraged Multi-modal Large Language Models (MLLMs) to generate descriptive explanations. However, despite their strong visual perception modules, these models often fail to reliably detect basic low-level distortions such as blur, noise, and compression, and may produce inconsistent evaluations across repeated inferences. This raises an essential question: do MLLM-based IQA systems truly perceive the visual features that matter? To examine this issue, we introduce a low-level distortion perception task that requires models to classify specific distortion types. Our component-wise analysis shows that although MLLMs are structurally capable of representing such distortions, they tend to overfit training templates, leading to biases in quality scoring. As a result, critical low-level features are weakened or lost during the vision-language alignment transfer stage. Furthermore, by computing the semantic distance between visual features and corresponding semantic tokens before and after component-wise fine-tuning, we show that improving the alignment of the vision encoder dramatically enhances distortion recognition accuracy, increasing it from 14.92% to 84.43%. Overall, these findings indicate that incorporating dedicated constraints on the vision encoder can strengthen text-explainable visual representations and enable MLLM-based pipelines to produce more coherent and interpretable reasoning in vision-centric tasks.

</details>


### [73] [Hands-on Evaluation of Visual Transformers for Object Recognition and Detection](https://arxiv.org/abs/2512.09579)
*Dimitrios N. Vlachogiannis,Dimitrios A. Koutsomitropoulos*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Convolutional Neural Networks (CNNs) for computer vision sometimes struggle with understanding images in a global context, as they mainly focus on local patterns. On the other hand, Vision Transformers (ViTs), inspired by models originally created for language processing, use self-attention mechanisms, which allow them to understand relationships across the entire image. In this paper, we compare different types of ViTs (pure, hierarchical, and hybrid) against traditional CNN models across various tasks, including object recognition, detection, and medical image classification. We conduct thorough tests on standard datasets like ImageNet for image classification and COCO for object detection. Additionally, we apply these models to medical imaging using the ChestX-ray14 dataset. We find that hybrid and hierarchical transformers, especially Swin and CvT, offer a strong balance between accuracy and computational resources. Furthermore, by experimenting with data augmentation techniques on medical images, we discover significant performance improvements, particularly with the Swin Transformer model. Overall, our results indicate that Vision Transformers are competitive and, in many cases, outperform traditional CNNs, especially in scenarios requiring the understanding of global visual contexts like medical imaging.

</details>


### [74] [Content-Adaptive Image Retouching Guided by Attribute-Based Text Representation](https://arxiv.org/abs/2512.09580)
*Hancheng Zhu,Xinyu Liu,Rui Yao,Kunyang Sun,Leida Li,Abdulmotaleb El Saddik*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Image retouching has received significant attention due to its ability to achieve high-quality visual content. Existing approaches mainly rely on uniform pixel-wise color mapping across entire images, neglecting the inherent color variations induced by image content. This limitation hinders existing approaches from achieving adaptive retouching that accommodates both diverse color distributions and user-defined style preferences. To address these challenges, we propose a novel Content-Adaptive image retouching method guided by Attribute-based Text Representation (CA-ATP). Specifically, we propose a content-adaptive curve mapping module, which leverages a series of basis curves to establish multiple color mapping relationships and learns the corresponding weight maps, enabling content-aware color adjustments. The proposed module can capture color diversity within the image content, allowing similar color values to receive distinct transformations based on their spatial context. In addition, we propose an attribute text prediction module that generates text representations from multiple image attributes, which explicitly represent user-defined style preferences. These attribute-based text representations are subsequently integrated with visual features via a multimodal model, providing user-friendly guidance for image retouching. Extensive experiments on several public datasets demonstrate that our method achieves state-of-the-art performance.

</details>


### [75] [OxEnsemble: Fair Ensembles for Low-Data Classification](https://arxiv.org/abs/2512.09665)
*Jonathan Rystrøm,Zihao Fu,Chris Russell*

Main category: cs.CV

TL;DR: 针对医学影像等小数据、不平衡场景的分类公平性问题，提出一种既高效又可靠的新方法


<details>
  <summary>Details</summary>
Motivation: 医学影像等领域的分类任务数据稀缺且在不同人口统计组间分布不平衡，错误分类（如假阴性）可能产生严重后果，需要在有限数据下保证分类公平性

Method: 提出OxEnsemble方法：通过训练多个满足公平性约束的集成成员，并聚合它们的预测结果；该方法在数据利用上高效（谨慎复用预留数据以可靠地实施公平性约束）且计算成本低（仅需微调或评估现有模型的计算量）

Result: 经过实验验证，该方法在多个医学影像分类数据集上相比现有方法，能产生更一致的结果和更好的公平性-准确率权衡；同时提供了新的理论保证

Conclusion: OxEnsemble方法在低数据量场景下能有效提高分类的公平性和可靠性，特别适用于医疗图像分析等关键领域，为有限数据下的公平分类问题提供了可行的解决方案

Abstract: We address the problem of fair classification in settings where data is scarce and unbalanced across demographic groups. Such low-data regimes are common in domains like medical imaging, where false negatives can have fatal consequences.
  We propose a novel approach \emph{OxEnsemble} for efficiently training ensembles and enforcing fairness in these low-data regimes. Unlike other approaches, we aggregate predictions across ensemble members, each trained to satisfy fairness constraints. By construction, \emph{OxEnsemble} is both data-efficient, carefully reusing held-out data to enforce fairness reliably, and compute-efficient, requiring little more compute than used to fine-tune or evaluate an existing model. We validate this approach with new theoretical guarantees. Experimentally, our approach yields more consistent outcomes and stronger fairness-accuracy trade-offs than existing methods across multiple challenging medical imaging classification datasets.

</details>


### [76] [UnReflectAnything: RGB-Only Highlight Removal by Rendering Synthetic Specular Supervision](https://arxiv.org/abs/2512.09583)
*Alberto Rota,Mert Kiray,Mert Asim Karaoglu,Patrick Ruhkamp,Elena De Momi,Nassir Navabm,Benjamin Busam*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Specular highlights distort appearance, obscure texture, and hinder geometric reasoning in both natural and surgical imagery. We present UnReflectAnything, an RGB-only framework that removes highlights from a single image by predicting a highlight map together with a reflection-free diffuse reconstruction. The model uses a frozen vision transformer encoder to extract multi-scale features, a lightweight head to localize specular regions, and a token-level inpainting module that restores corrupted feature patches before producing the final diffuse image. To overcome the lack of paired supervision, we introduce a Virtual Highlight Synthesis pipeline that renders physically plausible specularities using monocular geometry, Fresnel-aware shading, and randomized lighting which enables training on arbitrary RGB images with correct geometric structure. UnReflectAnything generalizes across natural and surgical domains where non-Lambertian surfaces and non-uniform lighting create severe highlights and it achieves competitive performance with state-of-the-art results on several benchmarks. Project Page: https://alberto-rota.github.io/UnReflectAnything/

</details>


### [77] [CS3D: An Efficient Facial Expression Recognition via Event Vision](https://arxiv.org/abs/2512.09592)
*Zhe Wang,Qijin Song,Yucen Peng,Weibang Bai*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Responsive and accurate facial expression recognition is crucial to human-robot interaction for daily service robots. Nowadays, event cameras are becoming more widely adopted as they surpass RGB cameras in capturing facial expression changes due to their high temporal resolution, low latency, computational efficiency, and robustness in low-light conditions. Despite these advantages, event-based approaches still encounter practical challenges, particularly in adopting mainstream deep learning models. Traditional deep learning methods for facial expression analysis are energy-intensive, making them difficult to deploy on edge computing devices and thereby increasing costs, especially for high-frequency, dynamic, event vision-based approaches. To address this challenging issue, we proposed the CS3D framework by decomposing the Convolutional 3D method to reduce the computational complexity and energy consumption. Additionally, by utilizing soft spiking neurons and a spatial-temporal attention mechanism, the ability to retain information is enhanced, thus improving the accuracy of facial expression detection. Experimental results indicate that our proposed CS3D method attains higher accuracy on multiple datasets compared to architectures such as the RNN, Transformer, and C3D, while the energy consumption of the CS3D method is just 21.97\% of the original C3D required on the same device.

</details>


### [78] [FROMAT: Multiview Material Appearance Transfer via Few-Shot Self-Attention Adaptation](https://arxiv.org/abs/2512.09617)
*Hubert Kompanowski,Varun Jampani,Aaryaman Vasishta,Binh-Son Hua*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multiview diffusion models have rapidly emerged as a powerful tool for content creation with spatial consistency across viewpoints, offering rich visual realism without requiring explicit geometry and appearance representation. However, compared to meshes or radiance fields, existing multiview diffusion models offer limited appearance manipulation, particularly in terms of material, texture, or style.
  In this paper, we present a lightweight adaptation technique for appearance transfer in multiview diffusion models. Our method learns to combine object identity from an input image with appearance cues rendered in a separate reference image, producing multi-view-consistent output that reflects the desired materials, textures, or styles. This allows explicit specification of appearance parameters at generation time while preserving the underlying object geometry and view coherence. We leverage three diffusion denoising processes responsible for generating the original object, the reference, and the target images, and perform reverse sampling to aggregate a small subset of layer-wise self-attention features from the object and the reference to influence the target generation. Our method requires only a few training examples to introduce appearance awareness to pretrained multiview models. The experiments show that our method provides a simple yet effective way toward multiview generation with diverse appearance, advocating the adoption of implicit generative 3D representations in practice.

</details>


### [79] [Benchmarking SAM2-based Trackers on FMOX](https://arxiv.org/abs/2512.09633)
*Senem Aktas,Charles Markham,John McDonald,Rozenn Dahyot*

Main category: cs.CV

TL;DR: 对基于SAM2的多种先进目标跟踪方法在快速运动物体(FMO)数据集上的性能进行基准测试和分析。


<details>
  <summary>Details</summary>
Motivation: 研究当前基于Segment Anything Model 2 (SAM2)的目标跟踪方法在快速运动物体场景下的局限性，通过系统性的基准测试为跟踪器开发提供更深入的见解。

Method: 在专门设计的快速运动物体(FMO)挑战性数据集上，对SAM2、EfficientTAM、DAM4SAM和SAMURAI等高性能跟踪器进行系统性基准测试和比较分析。

Result: 研究表明，DAM4SAM和SAMURAI跟踪器在更具挑战性的序列上表现更好，整体性能优于其他测试的跟踪器。

Conclusion: 基于SAM2的跟踪方法在快速运动物体场景中仍面临挑战，DAM4SAM和SAMURAI是目前表现最佳的方法，但仍有改进空间，需要针对动态场景进行优化。

Abstract: Several object tracking pipelines extending Segment Anything Model 2 (SAM2) have been proposed in the past year, where the approach is to follow and segment the object from a single exemplar template provided by the user on a initialization frame. We propose to benchmark these high performing trackers (SAM2, EfficientTAM, DAM4SAM and SAMURAI) on datasets containing fast moving objects (FMO) specifically designed to be challenging for tracking approaches. The goal is to understand better current limitations in state-of-the-art trackers by providing more detailed insights on the behavior of these trackers. We show that overall the trackers DAM4SAM and SAMURAI perform well on more challenging sequences.

</details>


### [80] [Kaapana: A Comprehensive Open-Source Platform for Integrating AI in Medical Imaging Research Environments](https://arxiv.org/abs/2512.09644)
*Ünal Akünal,Markus Bujotzek,Stefan Denner,Benjamin Hamm,Klaus Kades,Philipp Schader,Jonas Scherer,Marco Nolden,Peter Neher,Ralf Floca,Klaus Maier-Hein*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Developing generalizable AI for medical imaging requires both access to large, multi-center datasets and standardized, reproducible tooling within research environments. However, leveraging real-world imaging data in clinical research environments is still hampered by strict regulatory constraints, fragmented software infrastructure, and the challenges inherent in conducting large-cohort multicentre studies. This leads to projects that rely on ad-hoc toolchains that are hard to reproduce, difficult to scale beyond single institutions and poorly suited for collaboration between clinicians and data scientists. We present Kaapana, a comprehensive open-source platform for medical imaging research that is designed to bridge this gap. Rather than building single-use, site-specific tooling, Kaapana provides a modular, extensible framework that unifies data ingestion, cohort curation, processing workflows and result inspection under a common user interface. By bringing the algorithm to the data, it enables institutions to keep control over their sensitive data while still participating in distributed experimentation and model development. By integrating flexible workflow orchestration with user-facing applications for researchers, Kaapana reduces technical overhead, improves reproducibility and enables conducting large-scale, collaborative, multi-centre imaging studies. We describe the core concepts of the platform and illustrate how they can support diverse use cases, from local prototyping to nation-wide research networks. The open-source codebase is available at https://github.com/kaapana/kaapana

</details>


### [81] [VHOI: Controllable Video Generation of Human-Object Interactions from Sparse Trajectories via Motion Densification](https://arxiv.org/abs/2512.09646)
*Wanyue Zhang,Lin Geng Foo,Thabo Beeler,Rishabh Dabral,Christian Theobalt*

Main category: cs.CV

TL;DR: VHOI是一个两阶段框架，通过将稀疏轨迹稠密化为人体-物体交互掩码序列，并基于这些稠密掩码微调视频扩散模型，实现可控的人体-物体交互视频生成


<details>
  <summary>Details</summary>
Motivation: 合成真实的人体-物体交互视频面临复杂且实例特定的交互动力学挑战。现有可控视频生成方法存在权衡：稀疏控制易于指定但缺乏实例感知，而密集信号信息丰富但获取成本高

Method: 引入新颖的HOI感知运动表示，使用颜色编码区分人体、物体及身体部位特定的运动动态；采用两阶段框架：1）稠密化稀疏轨迹为HOI掩码序列 2）基于稠密掩码微调视频扩散模型

Result: 实验展示了在可控HOI视频生成中的先进性能，不仅能生成交互场景，还能以端到端方式生成引导至物体交互的完整人体导航

Conclusion: VHOI框架通过将稀疏控制转换为HOI感知的密集表示，有效解决了可控人体-物体交互视频生成的挑战，在保持控制易用性的同时提升了生成质量

Abstract: Synthesizing realistic human-object interactions (HOI) in video is challenging due to the complex, instance-specific interaction dynamics of both humans and objects. Incorporating controllability in video generation further adds to the complexity. Existing controllable video generation approaches face a trade-off: sparse controls like keypoint trajectories are easy to specify but lack instance-awareness, while dense signals such as optical flow, depths or 3D meshes are informative but costly to obtain. We propose VHOI, a two-stage framework that first densifies sparse trajectories into HOI mask sequences, and then fine-tunes a video diffusion model conditioned on these dense masks. We introduce a novel HOI-aware motion representation that uses color encodings to distinguish not only human and object motion, but also body-part-specific dynamics. This design incorporates a human prior into the conditioning signal and strengthens the model's ability to understand and generate realistic HOI dynamics. Experiments demonstrate state-of-the-art results in controllable HOI video generation. VHOI is not limited to interaction-only scenarios and can also generate full human navigation leading up to object interactions in an end-to-end manner. Project page: https://vcai.mpi-inf.mpg.de/projects/vhoi/.

</details>


### [82] [IF-Bench: Benchmarking and Enhancing MLLMs for Infrared Images with Generative Visual Prompting](https://arxiv.org/abs/2512.09663)
*Tao Zhang,Yuyang Hong,Yang Xia,Kun Ding,Zeyu Zhang,Ying Wang,Shiming Xiang,Chunhong Pan*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent advances in multimodal large language models (MLLMs) have led to impressive progress across various benchmarks. However, their capability in understanding infrared images remains unexplored. To address this gap, we introduce IF-Bench, the first high-quality benchmark designed for evaluating multimodal understanding of infrared images. IF-Bench consists of 499 images sourced from 23 infrared datasets and 680 carefully curated visual question-answer pairs, covering 10 essential dimensions of image understanding. Based on this benchmark, we systematically evaluate over 40 open-source and closed-source MLLMs, employing cyclic evaluation, bilingual assessment, and hybrid judgment strategies to enhance the reliability of the results. Our analysis reveals how model scale, architecture, and inference paradigms affect infrared image comprehension, providing valuable insights for this area. Furthermore, we propose a training-free generative visual prompting (GenViP) method, which leverages advanced image editing models to translate infrared images into semantically and spatially aligned RGB counterparts, thereby mitigating domain distribution shifts. Extensive experiments demonstrate that our method consistently yields significant performance improvements across a wide range of MLLMs. The benchmark and code are available at https://github.com/casiatao/IF-Bench.

</details>


### [83] [An Automated Tip-and-Cue Framework for Optimized Satellite Tasking and Visual Intelligence](https://arxiv.org/abs/2512.09670)
*Gil Weissman,Amir Ivry,Israel Cohen*

Main category: cs.CV

TL;DR: 论文提出了一种完全自动化的Tip-and-Cue框架，用于卫星成像任务规划与调度。该系统能够从外部数据源生成提示，转化为成像任务，利用连续效用函数优化多卫星调度，并通过AI模型处理图像生成结构化报告。通过海上船舶追踪场景验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着卫星星座的扩展、任务延迟降低和传感器能力多样化，地球观测自动化需求日益增长。现有系统在自动任务生成、调度优化和实时分析方面存在不足，需要一种端到端的自动化框架来处理多源数据和复杂观测要求。

Method: 系统包含三个核心模块：1）从AIS等外部数据或历史卫星图像分析生成时空目标提示；2）基于传感器约束、时间要求和效用函数将提示转化为成像任务；3）利用连续效用函数优化多卫星任务调度；4）使用目标检测器和视觉语言模型处理图像；5）生成结构化视觉报告支持可解释性和新洞察发现。

Result: 通过海上船舶追踪场景验证，系统能够有效利用AIS数据进行轨迹预测、定向观测和生成可操作输出。该框架在任务自动化、调度优化和信息提取方面表现出色，可扩展至智慧城市监测和灾害响应等应用。

Conclusion: 提出的全自动化Tip-and-Cue框架实现了卫星任务规划、调度和分析的端到端自动化，通过连续效用函数优化和多模态AI处理提高了观测效率和价值。系统具有良好扩展性，为地球观测任务提供了可推广的解决方案。

Abstract: The proliferation of satellite constellations, coupled with reduced tasking latency and diverse sensor capabilities, has expanded the opportunities for automated Earth observation. This paper introduces a fully automated Tip-and-Cue framework designed for satellite imaging tasking and scheduling. In this context, tips are generated from external data sources or analyses of prior satellite imagery, identifying spatiotemporal targets and prioritizing them for downstream planning. Corresponding cues are the imaging tasks formulated in response, which incorporate sensor constraints, timing requirements, and utility functions. The system autonomously generates candidate tasks, optimizes their scheduling across multiple satellites using continuous utility functions that reflect the expected value of each observation, and processes the resulting imagery using artificial-intelligence-based models, including object detectors and vision-language models. Structured visual reports are generated to support both interpretability and the identification of new insights for downstream tasking. The efficacy of the framework is demonstrated through a maritime vessel tracking scenario, utilizing Automatic Identification System (AIS) data for trajectory prediction, targeted observations, and the generation of actionable outputs. Maritime vessel tracking is a widely researched application, often used to benchmark novel approaches to satellite tasking, forecasting, and analysis. The system is extensible to broader applications such as smart-city monitoring and disaster response, where timely tasking and automated analysis are critical.

</details>


### [84] [Unconsciously Forget: Mitigating Memorization; Without Knowing What is being Memorized](https://arxiv.org/abs/2512.09687)
*Er Jin,Yang Zhang,Yongli Mou,Yanfei Dong,Stefan Decker,Kenji Kawaguchi,Johannes Stegmaier*

Main category: cs.CV

TL;DR: UniForget利用模型剪枝技术从源头抑制生成图像的版权内容记忆，不针对特定概念且保持模型生成能力，与现有方法正交互补。


<details>
  <summary>Details</summary>
Motivation: 生成模型容易记忆训练数据导致版权侵权等问题，现有方法要么计算开销大，要么只能移除特定概念，缺乏可扩展性。

Method: 通过分析确定模型中负责生成版权内容的部分，应用模型剪枝技术抑制这些部分的激活，从而减少版权内容生成概率。

Result: 方法能有效降低生成版权内容的概率，同时保持模型的整体生成能力，且与现有遗忘方法正交互补。

Conclusion: UniForget提供了一种可扩展的防记忆化方法，通过模型剪枝从源头解决问题，能有效提升现有遗忘和防记忆化技术。

Abstract: Recent advances in generative models have demonstrated an exceptional ability to produce highly realistic images. However, previous studies show that generated images often resemble the training data, and this problem becomes more severe as the model size increases. Memorizing training data can lead to legal challenges, including copyright infringement, violations of portrait rights, and trademark violations. Existing approaches to mitigating memorization mainly focus on manipulating the denoising sampling process to steer image embeddings away from the memorized embedding space or employ unlearning methods that require training on datasets containing specific sets of memorized concepts. However, existing methods often incur substantial computational overhead during sampling, or focus narrowly on removing one or more groups of target concepts, imposing a significant limitation on their scalability. To understand and mitigate these problems, our work, UniForget, offers a new perspective on understanding the root cause of memorization. Our work demonstrates that specific parts of the model are responsible for copyrighted content generation. By applying model pruning, we can effectively suppress the probability of generating copyrighted content without targeting specific concepts while preserving the general generative capabilities of the model. Additionally, we show that our approach is both orthogonal and complementary to existing unlearning methods, thereby highlighting its potential to improve current unlearning and de-memorization techniques.

</details>


### [85] [LiM-YOLO: Less is More with Pyramid Level Shift and Normalized Auxiliary Branch for Ship Detection in Optical Remote Sensing Imagery](https://arxiv.org/abs/2512.09700)
*Seon-Hoon Kim,Hyeji Sim,Youeyun Jung,Ok-Chul Jung,Yerin Kim*

Main category: cs.CV

TL;DR: LiM-YOLO是一种专为卫星影像船舶检测设计的检测器，通过金字塔层级偏移策略（P2-P4）解决尺度差异和形态各向异性问题，使用GN-CBLinear块提升训练稳定性，在多个数据集上表现出优越的检测精度和效率。


<details>
  <summary>Details</summary>
Motivation: 通用目标检测器在卫星影像船舶检测中面临显著挑战，主要问题是船舶目标的极端尺度差异和形态各向异性。标准架构使用的步长为32的P5层通常无法解析狭窄船舶，导致空间特征稀释。

Method: 基于船舶尺度的统计分析，提出了金字塔层级偏移策略，将检测头重新配置为P2-P4层，确保小目标符合奈奎斯特采样准则并消除深层计算冗余。同时引入分组归一化卷积线性投影块（GN-CBLinear）来缓解高分辨率输入在微批量设置中的梯度波动。

Result: 在SODA-A、DOTA-v1.5、FAIR1M-v2.0和ShipRSImageNet-V1数据集上的验证表明，LiM-YOLO相比最先进模型表现出优越的检测精度和效率。代码已在GitHub开源。

Conclusion: LiM-YOLO通过专门设计的金字塔层级偏移策略和训练稳定化技术，有效解决了卫星影像中船舶检测的特定领域挑战，为遥感目标检测提供了高效可靠的解决方案。

Abstract: Applying general-purpose object detectors to ship detection in satellite imagery presents significant challenges due to the extreme scale disparity and morphological anisotropy of maritime targets. Standard architectures utilizing stride-32 (P5) layers often fail to resolve narrow vessels, resulting in spatial feature dilution. In this work, we propose LiM-YOLO, a specialized detector designed to resolve these domain-specific conflicts. Based on a statistical analysis of ship scales, we introduce a Pyramid Level Shift Strategy that reconfigures the detection head to P2-P4. This shift ensures compliance with Nyquist sampling criteria for small objects while eliminating the computational redundancy of deep layers. To further enhance training stability on high-resolution inputs, we incorporate a Group Normalized Convolutional Block for Linear Projection (GN-CBLinear), which mitigates gradient volatility in micro-batch settings. Validated on SODA-A, DOTA-v1.5, FAIR1M-v2.0, and ShipRSImageNet-V1, LiM-YOLO demonstrates superior detection accuracy and efficiency compared to state-of-the-art models. The code is available at https://github.com/egshkim/LiM-YOLO.

</details>


### [86] [FastPose-ViT: A Vision Transformer for Real-Time Spacecraft Pose Estimation](https://arxiv.org/abs/2512.09792)
*Pierre Ancey,Andrew Price,Saqib Javed,Mathieu Salzmann*

Main category: cs.CV

TL;DR: FastPose-ViT：基于视觉Transformer直接回归航天器6DoF姿态，通过数学形式化将局部预测映射到全图尺度，性能媲美PnP方法，并在边缘设备上实现实时推理。


<details>
  <summary>Details</summary>
Motivation: 现有基于迭代PnP的航天器姿态估计方法计算量大，不适合资源受限的边缘设备实时部署。需要开发高效的非PnP方法。

Method: 提出FastPose-ViT架构，基于ViT直接回归6DoF姿态。引入数学形式化方法，将裁剪图像预测映射回原图尺度，利用投影几何和"表观旋转"概念校正姿态矩阵。

Result: 在SPEED数据集上超越其他非PnP方法，性能媲美SOTA的PnP方法。量化后在NVIDIA Jetson Orin Nano上达到约75ms单帧延迟，非阻塞吞吐量达33FPS。

Conclusion: FastPose-ViT为航天器姿态估计提供了高效的非PnP解决方案，适合在资源受限的边缘设备上实时部署，满足在轨服务等自主操作需求。

Abstract: Estimating the 6-degrees-of-freedom (6DoF) pose of a spacecraft from a single image is critical for autonomous operations like in-orbit servicing and space debris removal. Existing state-of-the-art methods often rely on iterative Perspective-n-Point (PnP)-based algorithms, which are computationally intensive and ill-suited for real-time deployment on resource-constrained edge devices. To overcome these limitations, we propose FastPose-ViT, a Vision Transformer (ViT)-based architecture that directly regresses the 6DoF pose. Our approach processes cropped images from object bounding boxes and introduces a novel mathematical formalism to map these localized predictions back to the full-image scale. This formalism is derived from the principles of projective geometry and the concept of "apparent rotation", where the model predicts an apparent rotation matrix that is then corrected to find the true orientation. We demonstrate that our method outperforms other non-PnP strategies and achieves performance competitive with state-of-the-art PnP-based techniques on the SPEED dataset. Furthermore, we validate our model's suitability for real-world space missions by quantizing it and deploying it on power-constrained edge hardware. On the NVIDIA Jetson Orin Nano, our end-to-end pipeline achieves a latency of ~75 ms per frame under sequential execution, and a non-blocking throughput of up to 33 FPS when stages are scheduled concurrently.

</details>


### [87] [Modality-Specific Enhancement and Complementary Fusion for Semi-Supervised Multi-Modal Brain Tumor Segmentation](https://arxiv.org/abs/2512.09801)
*Tien-Dat Chung,Ba-Thinh Lam,Thanh-Huy Nguyen,Thien Nguyen,Nguyen Lan Vi Vu,Hoang-Loc Cao,Phat Kim Huynh,Min Xu*

Main category: cs.CV

TL;DR: 提出了一种新型半监督多模态医学图像分割框架，通过模态特异性增强模块和互补信息融合模块，有效利用不同MRI序列间的互补信息，显著提升脑肿瘤分割性能。


<details>
  <summary>Details</summary>
Motivation: 当前用于多模态医学图像分割的半监督学习方法难以充分利用不同模态间的互补信息，主要原因是MRI序列间的语义差异和不对齐问题，导致模型在有限标注数据下的性能受限。

Method: 设计了模态特异性增强模块（MEM）通过通道注意力增强每个模态的特有语义线索，并引入可学习的互补信息融合模块（CIF）自适应地在模态间交换互补知识。整体框架采用混合目标函数，结合有监督分割损失和未标注数据的跨模态一致性正则化。

Result: 在BraTS 2019（HGG子集）数据集上的实验表明，该方法在1%、5%和10%标注数据设置下均优于现有半监督和多模态基线方法，在Dice和敏感性得分上均取得显著提升。消融研究进一步验证了MEM和CIF在弥合跨模态差异和提升分割鲁棒性方面的互补作用。

Conclusion: 该框架通过显式增强模态特异性表示和自适应跨模态融合，有效解决了多模态医学图像分割中的语义差异问题，为有限标注数据情况下的多模态医学图像分析提供了有前景的解决方案。

Abstract: Semi-supervised learning (SSL) has become a promising direction for medical image segmentation, enabling models to learn from limited labeled data alongside abundant unlabeled samples. However, existing SSL approaches for multi-modal medical imaging often struggle to exploit the complementary information between modalities due to semantic discrepancies and misalignment across MRI sequences. To address this, we propose a novel semi-supervised multi-modal framework that explicitly enhances modality-specific representations and facilitates adaptive cross-modal information fusion. Specifically, we introduce a Modality-specific Enhancing Module (MEM) to strengthen semantic cues unique to each modality via channel-wise attention, and a learnable Complementary Information Fusion (CIF) module to adaptively exchange complementary knowledge between modalities. The overall framework is optimized using a hybrid objective combining supervised segmentation loss and cross-modal consistency regularization on unlabeled data. Extensive experiments on the BraTS 2019 (HGG subset) demonstrate that our method consistently outperforms strong semi-supervised and multi-modal baselines under 1\%, 5\%, and 10\% labeled data settings, achieving significant improvements in both Dice and Sensitivity scores. Ablation studies further confirm the complementary effects of our proposed MEM and CIF in bridging cross-modality discrepancies and improving segmentation robustness under scarce supervision.

</details>


### [88] [DynaIP: Dynamic Image Prompt Adapter for Scalable Zero-shot Personalized Text-to-Image Generation](https://arxiv.org/abs/2512.09814)
*Zhizhong Wang,Tianyi Chu,Zeyi Huang,Nanyang Wang,Kehan Li*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Personalized Text-to-Image (PT2I) generation aims to produce customized images based on reference images. A prominent interest pertains to the integration of an image prompt adapter to facilitate zero-shot PT2I without test-time fine-tuning. However, current methods grapple with three fundamental challenges: 1. the elusive equilibrium between Concept Preservation (CP) and Prompt Following (PF), 2. the difficulty in retaining fine-grained concept details in reference images, and 3. the restricted scalability to extend to multi-subject personalization. To tackle these challenges, we present Dynamic Image Prompt Adapter (DynaIP), a cutting-edge plugin to enhance the fine-grained concept fidelity, CP-PF balance, and subject scalability of SOTA T2I multimodal diffusion transformers (MM-DiT) for PT2I generation. Our key finding is that MM-DiT inherently exhibit decoupling learning behavior when injecting reference image features into its dual branches via cross attentions. Based on this, we design an innovative Dynamic Decoupling Strategy that removes the interference of concept-agnostic information during inference, significantly enhancing the CP-PF balance and further bolstering the scalability of multi-subject compositions. Moreover, we identify the visual encoder as a key factor affecting fine-grained CP and reveal that the hierarchical features of commonly used CLIP can capture visual information at diverse granularity levels. Therefore, we introduce a novel Hierarchical Mixture-of-Experts Feature Fusion Module to fully leverage the hierarchical features of CLIP, remarkably elevating the fine-grained concept fidelity while also providing flexible control of visual granularity. Extensive experiments across single- and multi-subject PT2I tasks verify that our DynaIP outperforms existing approaches, marking a notable advancement in the field of PT2l generation.

</details>


### [89] [From Detection to Anticipation: Online Understanding of Struggles across Various Tasks and Activities](https://arxiv.org/abs/2512.09847)
*Shijia Feng,Michael Wray,Walterio Mayol-Cuevas*

Main category: cs.CV

TL;DR: 论文提出实时在线的人机协作场景中的挣扎识别与预测方法，将传统的离线分类转为在线检测和预测任务，模型能在143FPS下运行，支持实时辅助应用。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注离线场景下的用户困难识别，而实时智能辅助系统需要在线识别并预测用户的工作困难，以便及时提供帮助。

Method: 将原有的离线挣扎分类任务重新定义为在线检测任务，并进一步延伸至预测功能。采用了两种现成的模型作为基线，支持在线挣扎检测和预测。

Result: 在线挣扎检测模型在每帧检测的平均精度(mAP)达到70-80%，提前2秒的挣扎预测性能虽有轻微下降但仍保持相当水平。在跨任务和跨活动泛化测试中，模型比随机基线高出4-20%。基于特征提取的模型推理速度最高可达143FPS，整个流水线(包含特征提取)约20FPS，能够满足实时辅助应用需求。

Conclusion: 该研究证实了在线挣扎检测和预测的可行性，模型不仅能在实时场景中有效识别用户困难，还能提前预测，为智能辅助系统提供了可靠的技术支撑。尽管在跨活动泛化方面存在较大领域差距，但模型仍能有效提升识别性能。

Abstract: Understanding human skill performance is essential for intelligent assistive systems, with struggle recognition offering a natural cue for identifying user difficulties. While prior work focuses on offline struggle classification and localization, real-time applications require models capable of detecting and anticipating struggle online. We reformulate struggle localization as an online detection task and further extend it to anticipation, predicting struggle moments before they occur. We adapt two off-the-shelf models as baselines for online struggle detection and anticipation. Online struggle detection achieves 70-80% per-frame mAP, while struggle anticipation up to 2 seconds ahead yields comparable performance with slight drops. We further examine generalization across tasks and activities and analyse the impact of skill evolution. Despite larger domain gaps in activity-level generalization, models still outperform random baselines by 4-20%. Our feature-based models run at up to 143 FPS, and the whole pipeline, including feature extraction, operates at around 20 FPS, sufficient for real-time assistive applications.

</details>


### [90] [UniUGP: Unifying Understanding, Generation, and Planing For End-to-end Autonomous Driving](https://arxiv.org/abs/2512.09864)
*Hao Lu,Ziyang Liu,Guangfeng Jiang,Yuanfei Luo,Sheng Chen,Yangang Zhang,Ying-Cong Chen*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Autonomous driving (AD) systems struggle in long-tail scenarios due to limited world knowledge and weak visual dynamic modeling. Existing vision-language-action (VLA)-based methods cannot leverage unlabeled videos for visual causal learning, while world model-based methods lack reasoning capabilities from large language models. In this paper, we construct multiple specialized datasets providing reasoning and planning annotations for complex scenarios. Then, a unified Understanding-Generation-Planning framework, named UniUGP, is proposed to synergize scene reasoning, future video generation, and trajectory planning through a hybrid expert architecture. By integrating pre-trained VLMs and video generation models, UniUGP leverages visual dynamics and semantic reasoning to enhance planning performance. Taking multi-frame observations and language instructions as input, it produces interpretable chain-of-thought reasoning, physically consistent trajectories, and coherent future videos. We introduce a four-stage training strategy that progressively builds these capabilities across multiple existing AD datasets, along with the proposed specialized datasets. Experiments demonstrate state-of-the-art performance in perception, reasoning, and decision-making, with superior generalization to challenging long-tail situations.

</details>


### [91] [Diffusion Posterior Sampler for Hyperspectral Unmixing with Spectral Variability Modeling](https://arxiv.org/abs/2512.09871)
*Yimin Zhu,Lincoln Linlin Xu*

Main category: cs.CV

TL;DR: DPS4Un是一个基于扩散后验采样的半盲解混方法，利用预训练的条件光谱扩散模型作为后验采样器，结合超像素构建端元束先验学习和数据保真项，在保持光谱一致性的同时有效建模光谱变异性，在三个真实基准数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 线性光谱混合模型(LMM)的关键挑战在于如何建模光谱先验分布和处理光谱变异性。传统方法使用现有光谱库作为先验可能存在偏差，且难以精确建模光谱变异性。贝叶斯框架能够严格建模先验知识和光谱变异性，但需要更有效的实现方式。

Method: DPS4Un方法包含四个核心特征：(1)将预训练的条件光谱扩散模型作为后验采样器，结合学习的端元先验与观测数据获得精化的丰度分布；(2)构建基于图像的超像素内端元束作为训练先验学习器的数据，避免现有光谱库的偏差问题；(3)提出基于超像素的数据保真项取代图像级约束；(4)为每个超像素区域初始化高斯噪声端元，迭代更新丰度和端元以建模光谱变异性。

Result: 在三个真实世界基准数据集上的实验结果表明，DPS4Un超越了当前最先进的高光谱解混方法。

Conclusion: DPS4Un通过将扩散模型作为后验采样器，结合超像素级别的端元束先验学习和数据保真约束，有效解决了高光谱解混中的关键挑战，包括光谱先验建模和光谱变异性处理，在真实数据集上展现了优越性能。

Abstract: Linear spectral mixture models (LMM) provide a concise form to disentangle the constituent materials (endmembers) and their corresponding proportions (abundance) in a single pixel. The critical challenges are how to model the spectral prior distribution and spectral variability. Prior knowledge and spectral variability can be rigorously modeled under the Bayesian framework, where posterior estimation of Abundance is derived by combining observed data with endmember prior distribution. Considering the key challenges and the advantages of the Bayesian framework, a novel method using a diffusion posterior sampler for semiblind unmixing, denoted as DPS4Un, is proposed to deal with these challenges with the following features: (1) we view the pretrained conditional spectrum diffusion model as a posterior sampler, which can combine the learned endmember prior with observation to get the refined abundance distribution. (2) Instead of using the existing spectral library as prior, which may raise bias, we establish the image-based endmember bundles within superpixels, which are used to train the endmember prior learner with diffusion model. Superpixels make sure the sub-scene is more homogeneous. (3) Instead of using the image-level data consistency constraint, the superpixel-based data fidelity term is proposed. (4) The endmember is initialized as Gaussian noise for each superpixel region, DPS4Un iteratively updates the abundance and endmember, contributing to spectral variability modeling. The experimental results on three real-world benchmark datasets demonstrate that DPS4Un outperforms the state-of-the-art hyperspectral unmixing methods.

</details>


### [92] [Benchmarking Document Parsers on Mathematical Formula Extraction from PDFs](https://arxiv.org/abs/2512.09874)
*Pius Horn,Janis Keuper*

Main category: cs.CV

TL;DR: 本文介绍了一个用于评估PDF文档中数学公式解析质量的新颖基准框架，该框架使用合成生成的PDF与精确LaTeX真值，并创新性地采用LLM-as-a-judge方法进行语义公式评估，在20多种解析器上进行了系统性评估。


<details>
  <summary>Details</summary>
Motivation: 现有PDF解析基准要么完全排除数学公式，要么缺乏语义感知的评估指标，而正确解析PDF中的数学公式对于训练大语言模型和构建科学知识库至关重要。

Method: 提出基于合成生成PDF的基准框架，包含精确LaTeX真值；首创LLM-as-a-judge进行语义公式评估；采用两阶段匹配管道处理解析器输出不一致性；通过人工验证确保评估质量。

Result: LLM评估与人工判断的相关性（Pearson r=0.78）显著高于CDM（r=0.34）和文本相似度（r~0）；对20多种PDF解析器在100个合成文档2000多个公式上的评估揭示了显著的性能差异。

Conclusion: 该研究为下游应用选择解析器提供了关键见解，并建立了一个可扩展、可重现的PDF公式提取质量评估方法。

Abstract: Correctly parsing mathematical formulas from PDFs is critical for training large language models and building scientific knowledge bases from academic literature, yet existing benchmarks either exclude formulas entirely or lack semantically-aware evaluation metrics. We introduce a novel benchmarking framework centered on synthetically generated PDFs with precise LaTeX ground truth, enabling systematic control over layout, formulas, and content characteristics. A key methodological contribution is pioneering LLM-as-a-judge for semantic formula assessment, combined with a robust two-stage matching pipeline that handles parser output inconsistencies. Through human validation on 250 formula pairs (750 ratings from 30 evaluators), we demonstrate that LLM-based evaluation achieves substantially higher correlation with human judgment (Pearson r=0.78) compared to CDM (r=0.34) and text similarity (r~0). Evaluating 20+ contemporary PDF parsers (including specialized OCR models, vision-language models, and rule-based approaches) across 100 synthetic documents with 2,000+ formulas reveals significant performance disparities. Our findings provide crucial insights for practitioners selecting parsers for downstream applications and establish a robust, scalable methodology that enables reproducible evaluation of PDF formula extraction quality. Code and benchmark data: https://github.com/phorn1/pdf-parse-bench

</details>


### [93] [VisualActBench: Can VLMs See and Act like a Human?](https://arxiv.org/abs/2512.09907)
*Daoan Zhang,Pai Liu,Xiaofei Zhou,Yuan Ge,Guangchen Lan,Jing Bi,Christopher Brinton,Ehsan Hoque,Jiebo Luo*

Main category: cs.CV

TL;DR: 提出了视觉动作推理新任务和VisualActBench基准，评估视觉语言模型在没有文本提示情况下的主动推理能力，发现当前模型在复杂上下文理解等方面仍存在明显差距。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在感知和描述视觉环境方面已取得显著进展，但其在没有显式文本提示的情况下仅基于视觉输入进行主动推理和行动的能力尚未得到充分探索。

Method: 引入视觉动作推理新任务，提出VisualActBench基准数据集，包含1,074个视频和3,733个人工标注动作，覆盖四种真实场景，每个动作都标注了动作优先级和主动-被动类型。

Result: 评估了29个视觉语言模型，发现前沿模型如GPT4o表现相对较好，但与人类推理水平仍有显著差距，特别是在生成主动、高优先级动作方面存在不足。

Conclusion: 当前视觉语言模型在理解复杂上下文、预测结果以及与人类决策框架对齐方面存在局限性。VisualActBench为评估和改进面向现实世界的主动视觉AI智能体建立了全面基础。

Abstract: Vision-Language Models (VLMs) have achieved impressive progress in perceiving and describing visual environments. However, their ability to proactively reason and act based solely on visual inputs, without explicit textual prompts, remains underexplored. We introduce a new task, Visual Action Reasoning, and propose VisualActBench, a large-scale benchmark comprising 1,074 videos and 3,733 human-annotated actions across four real-world scenarios. Each action is labeled with an Action Prioritization Level (APL) and a proactive-reactive type to assess models' human-aligned reasoning and value sensitivity. We evaluate 29 VLMs on VisualActBench and find that while frontier models like GPT4o demonstrate relatively strong performance, a significant gap remains compared to human-level reasoning, particularly in generating proactive, high-priority actions. Our results highlight limitations in current VLMs' ability to interpret complex context, anticipate outcomes, and align with human decision-making frameworks. VisualActBench establishes a comprehensive foundation for assessing and improving the real-world readiness of proactive, vision-centric AI agents.

</details>


### [94] [NordFKB: a fine-grained benchmark dataset for geospatial AI in Norway](https://arxiv.org/abs/2512.09913)
*Sander Riisøen Jyhne,Aditya Gupta,Ben Worsley,Marianne Andersen,Ivar Oveland,Alexander Salveson Nossum*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present NordFKB, a fine-grained benchmark dataset for geospatial AI in Norway, derived from the authoritative, highly accurate, national Felles KartdataBase (FKB). The dataset contains high-resolution orthophotos paired with detailed annotations for 36 semantic classes, including both per-class binary segmentation masks in GeoTIFF format and COCO-style bounding box annotations. Data is collected from seven geographically diverse areas, ensuring variation in climate, topography, and urbanization. Only tiles containing at least one annotated object are included, and training/validation splits are created through random sampling across areas to ensure representative class and context distributions. Human expert review and quality control ensures high annotation accuracy. Alongside the dataset, we release a benchmarking repository with standardized evaluation protocols and tools for semantic segmentation and object detection, enabling reproducible and comparable research. NordFKB provides a robust foundation for advancing AI methods in mapping, land administration, and spatial planning, and paves the way for future expansions in coverage, temporal scope, and data modalities.

</details>


### [95] [Splatent: Splatting Diffusion Latents for Novel View Synthesis](https://arxiv.org/abs/2512.09923)
*Or Hirschorn,Omer Sela,Inbar Huberman-Spiegelglas,Netalee Efrat,Eli Alshan,Ianir Ideses,Frederic Devernay,Yochai Zvik,Lior Fritz*

Main category: cs.CV

TL;DR: Splatent是一个基于扩散模型的增强框架，通过在VAE潜在空间中的3D高斯泼溅上进行操作，解决了原有方法中存在的多视角不一致性导致细节模糊的问题，通过多视角注意力机制在2D输入视图中恢复细节，保持了预训练VAE的重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有的基于VAE潜在空间的辐射场表示虽然能实现高效渲染并与扩散模型无缝集成，但面临VAE潜在空间缺乏多视角一致性的问题，导致3D重建时的纹理模糊和细节丢失。现有方法要么通过微调VAE牺牲重建质量，要么依赖预训练扩散模型恢复细节但可能产生幻觉。

Method: 提出Splatent框架，其核心思路是将潜在空间中的3D高斯泼溅表示作为基础，通过多视角注意力机制，在2D输入视图中恢复精细细节，而不是在3D空间中重建这些细节。这样可以保持预训练VAE的重建质量，同时实现可靠的细节恢复。

Result: 在多个基准测试中，Splatent在VAE潜在辐射场重建方面达到了新的最先进水平。进一步的实验表明，将该方法集成到现有的前馈框架中，可以一致性地提高细节保真度，为高质量稀疏视图3D重建开辟了新可能性。

Conclusion: Splatent通过将细节恢复从3D空间转移到2D输入视图的多视角机制，有效解决了VAE潜在空间中多视角一致性问题，在保持预训练VAE重建质量的同时实现了高质量的细节恢复，为稀疏视图3D重建提供了新的有效方案。

Abstract: Radiance field representations have recently been explored in the latent space of VAEs that are commonly used by diffusion models. This direction offers efficient rendering and seamless integration with diffusion-based pipelines. However, these methods face a fundamental limitation: The VAE latent space lacks multi-view consistency, leading to blurred textures and missing details during 3D reconstruction. Existing approaches attempt to address this by fine-tuning the VAE, at the cost of reconstruction quality, or by relying on pre-trained diffusion models to recover fine-grained details, at the risk of some hallucinations. We present Splatent, a diffusion-based enhancement framework designed to operate on top of 3D Gaussian Splatting (3DGS) in the latent space of VAEs. Our key insight departs from the conventional 3D-centric view: rather than reconstructing fine-grained details in 3D space, we recover them in 2D from input views through multi-view attention mechanisms. This approach preserves the reconstruction quality of pretrained VAEs while achieving faithful detail recovery. Evaluated across multiple benchmarks, Splatent establishes a new state-of-the-art for VAE latent radiance field reconstruction. We further demonstrate that integrating our method with existing feed-forward frameworks, consistently improves detail preservation, opening new possibilities for high-quality sparse-view 3D reconstruction.

</details>


### [96] [ReViSE: Towards Reason-Informed Video Editing in Unified Models with Self-Reflective Learning](https://arxiv.org/abs/2512.09924)
*Xinyu Liu,Hangjie Yuan,Yujie Wei,Jiazheng Xing,Yujin Han,Jiahao Pan,Yanbiao Ma,Chi-Min Chan,Kang Zhao,Shiwei Zhang,Wenhan Luo,Yike Guo*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Video unified models exhibit strong capabilities in understanding and generation, yet they struggle with reason-informed visual editing even when equipped with powerful internal vision-language models (VLMs). We attribute this gap to two factors: 1) existing datasets are inadequate for training and evaluating reasoning-aware video editing, and 2) an inherent disconnect between the models' reasoning and editing capabilities, which prevents the rich understanding from effectively instructing the editing process. Bridging this gap requires an integrated framework that connects reasoning with visual transformation. To address this gap, we introduce the Reason-Informed Video Editing (RVE) task, which requires reasoning about physical plausibility and causal dynamics during editing. To support systematic evaluation, we construct RVE-Bench, a comprehensive benchmark with two complementary subsets: Reasoning-Informed Video Editing and In-Context Video Generation. These subsets cover diverse reasoning dimensions and real-world editing scenarios. Building upon this foundation, we propose the ReViSE, a Self-Reflective Reasoning (SRF) framework that unifies generation and evaluation within a single architecture. The model's internal VLM provides intrinsic feedback by assessing whether the edited video logically satisfies the given instruction. The differential feedback that refines the generator's reasoning behavior during training. Extensive experiments on RVE-Bench demonstrate that ReViSE significantly enhances editing accuracy and visual fidelity, achieving a 32% improvement of the Overall score in the reasoning-informed video editing subset over state-of-the-art methods.

</details>


### [97] [GAINS: Gaussian-based Inverse Rendering from Sparse Multi-View Captures](https://arxiv.org/abs/2512.09925)
*Patrick Noras,Jun Myeong Choi,Didier Stricker,Pieter Peers,Roni Sengupta*

Main category: cs.CV

TL;DR: GAINS是一个两阶段逆向渲染框架，使用学习先验在稀疏多视角拍摄下提升几何和材质恢复质量


<details>
  <summary>Details</summary>
Motivation: 现有的基于高斯溅射的逆向渲染方法在密集多视角拍摄下表现良好，但在稀疏视角设置下，几何、反射率和光照之间的严重模糊性导致性能急剧下降

Method: GAINS采用两阶段框架：1) 使用单目深度/法线和扩散先验细化几何；2) 利用分割、内在图像分解和扩散先验正则化材质恢复

Result: 在合成和真实世界数据集上的实验表明，GAINS在材质参数精度、重照明质量和新颖视角合成方面显著优于现有的基于高斯溅射的逆向渲染方法，尤其在稀疏视角设置下

Conclusion: GAINS通过引入学习先验有效解决了稀疏多视角逆向渲染中的几何-材质-光照模糊问题，为稀疏视角下的高质量材质恢复提供了有效解决方案

Abstract: Recent advances in Gaussian Splatting-based inverse rendering extend Gaussian primitives with shading parameters and physically grounded light transport, enabling high-quality material recovery from dense multi-view captures. However, these methods degrade sharply under sparse-view settings, where limited observations lead to severe ambiguity between geometry, reflectance, and lighting. We introduce GAINS (Gaussian-based Inverse rendering from Sparse multi-view captures), a two-stage inverse rendering framework that leverages learning-based priors to stabilize geometry and material estimation. GAINS first refines geometry using monocular depth/normal and diffusion priors, then employs segmentation, intrinsic image decomposition (IID), and diffusion priors to regularize material recovery. Extensive experiments on synthetic and real-world datasets show that GAINS significantly improves material parameter accuracy, relighting quality, and novel-view synthesis compared to state-of-the-art Gaussian-based inverse rendering methods, especially under sparse-view settings. Project page: https://patrickbail.github.io/gains/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [98] [ChronusOmni: Improving Time Awareness of Omni Large Language Models](https://arxiv.org/abs/2512.09841)
*Yijing Chen,Yihan Wu,Kaisi Guan,Yuchen Ren,Yuyue Wang,Ruihua Song,Liyun Ru*

Main category: cs.CL

TL;DR: 提出ChronusOmni模型，增强全模态大语言的时空感知能力，专门针对视听交叉模态时序定位问题，在显隐式时空推理上表现显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要在视觉语言场景解决显式时序定位，但忽略音频模态利用以及跨模态隐式时序关系（如视觉中出现对话角色说话），而现实场景此类跨模态时序关联普遍存在。

Method: 1）将时间戳标记与每个时间单元的视觉和音频表征交错融合，实现统一跨模态时序建模；2）引入强化学习配合专门设计的奖赏函数，增强时序排序正确性和细粒度时序推理；3）构建ChronusAV数据集，该数据集具有时序精确、模态完整和跨模态对齐特点，以支持训练和评估。

Result: ChronusOmni在ChronusAV上实现超过30%的性能提升，并在其他时序定位基准的大多数指标上达到顶尖结果，同时保持了通用的视频和音频理解能力。

Conclusion: ChronusOmni模型在跨模态的时空感知方面表现出色，显著提升了对显隐式视听时序关系的理解能力，为全模态大语言模型在复杂动态场景中的应用提供了有力支持。

Abstract: Time awareness is a fundamental ability of omni large language models, especially for understanding long videos and answering complex questions. Previous approaches mainly target vision-language scenarios and focus on the explicit temporal grounding questions, such as identifying when a visual event occurs or determining what event happens at aspecific time. However, they often make insufficient use of the audio modality, and overlook implicit temporal grounding across modalities--for example, identifying what is visually present when a character speaks, or determining what is said when a visual event occurs--despite such cross-modal temporal relations being prevalent in real-world scenarios. In this paper, we propose ChronusOmni, an omni large language model designed to enhance temporal awareness for both explicit and implicit audiovisual temporal grounding. First, we interleave text-based timestamp tokens with visual and audio representations at each time unit, enabling unified temporal modeling across modalities. Second, to enforce correct temporal ordering and strengthen fine-grained temporal reasoning, we incorporate reinforcement learning with specially designed reward functions. Moreover, we construct ChronusAV, a temporally-accurate, modality-complete, and cross-modal-aligned dataset to support the training and evaluation on audiovisual temporal grounding task. Experimental results demonstrate that ChronusOmni achieves state-of-the-art performance on ChronusAV with more than 30% improvement and top results on most metrics upon other temporal grounding benchmarks. This highlights the strong temporal awareness of our model across modalities, while preserving general video and audio understanding capabilities.

</details>


### [99] [Noise-Robust Abstractive Compression in Retrieval-Augmented Language Models](https://arxiv.org/abs/2512.08943)
*Singon Kim*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Abstractive compression utilizes smaller langauge models to condense query-relevant context, reducing computational costs in retrieval-augmented generation (RAG). However, retrieved documents often include information that is either irrelevant to answering the query or misleading due to factual incorrect content, despite having high relevance scores. This behavior indicates that abstractive compressors are more likely to omit important information essential for the correct answer, especially in long contexts where attention dispersion occurs. To address this issue, we categorize retrieved documents in a more fine-grained manner and propose Abstractive Compression Robust against Noise (ACoRN), which introduces two novel training steps. First, we use offline data augmentation on the training dataset to enhance compressor robustness against two distinct types of retrieval noise. Second, since the language model based compressor cannot fully utilize information from multiple retrieved documents and exhibits positional bias, we perform finetuning to generate summaries centered around key information that directly supports the correct answer. Our experiments demonstrate that T5-large, trained with ACoRN as a compressor, improves EM and F1 scores while preserving the answer string, which could serve as direct evidence. ACoRN excels on datasets with many accuracy reducing documents, making it highly useful in real-world scenarios.

</details>


### [100] [Enhancing Reliability across Short and Long-Form QA via Reinforcement Learning](https://arxiv.org/abs/2512.08944)
*Yudong Wang,Zhe Yang,Wenhan Ma,Zhifang Sui,Liang Zhao*

Main category: cs.CL

TL;DR: 该论文提出了一种针对性的强化学习框架，旨在减少大语言模型在短式和长式问答中的内在和外在幻觉，通过创新的训练集构建和事实锚定奖励机制提升可靠性。


<details>
  <summary>Details</summary>
Motivation: 强化学习虽然提升了大语言模型的复杂推理能力，但也加剧了其幻觉倾向，导致模型能力与可靠性之间存在关键权衡。本研究旨在解决这一问题，平衡先进推理与事实可信度之间的张力。

Method: 1) 针对外在幻觉（内部知识缺陷）：基于TriviaQA构建开放式转换训练集；2) 针对内在幻觉（与上下文不忠实）：利用FineWeb的长文本实施事实锚定奖励方案；3) 增强可靠性：对无法回答的问题明确奖励拒绝回答的行为，培养模型谨慎性。

Result: 大量实验表明，该方法在多样化基准测试中取得显著性能提升，同时大幅减少了两类幻觉。

Conclusion: 本研究提供了一个实用框架，有效解决了先进推理与事实可信度之间的关键矛盾，为开发更具能力且可靠的大语言模型铺平了道路。

Abstract: While reinforcement learning has unlocked unprecedented complex reasoning in large language models, it has also amplified their propensity for hallucination, creating a critical trade-off between capability and reliability. This work confronts this challenge by introducing a targeted RL framework designed to mitigate both intrinsic and extrinsic hallucinations across short and long-form question answering. We address extrinsic hallucinations (flawed internal knowledge) by creating a novel training set from open-ended conversions of TriviaQA. Concurrently, we tackle intrinsic hallucinations (unfaithfulness to context) by leveraging long-form texts from FineWeb in a fact-grounding reward scheme. To further bolster reliability, our framework explicitly rewards the model for refusing to answer unanswerable questions, thereby cultivating crucial cautiousness. Extensive experiments demonstrate that our methodology yields significant performance gains across a diverse suite of benchmarks, substantially reducing both hallucination types. Ultimately, this research contributes a practical framework for resolving the critical tension between advanced reasoning and factual trustworthiness, paving the way for more capable and reliable large language models.

</details>


### [101] [Knowledge-Guided Large Language Model for Automatic Pediatric Dental Record Understanding and Safe Antibiotic Recommendation](https://arxiv.org/abs/2512.09127)
*Zihan Han,Junyan Ge,Caifeng Li*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate interpretation of pediatric dental clinical records and safe antibiotic prescribing remain persistent challenges in dental informatics. Traditional rule-based clinical decision support systems struggle with unstructured dental narratives, incomplete radiographic descriptions, and complex safety constraints. To address these limitations, this study proposes a Knowledge-Guided Large Language Model (KG-LLM) that integrates a pediatric dental knowledge graph, retrieval-augmented generation (RAG), and a multi-stage safety validation pipeline for evidence-grounded antibiotic recommendation. The framework first employs a clinical NER/RE module to extract structured entities and relations from dental notes and radiology reports. Relevant guidelines, drug-safety rules, and analogous historical cases are subsequently retrieved from the knowledge graph and supplied to the LLM for diagnostic summarization and dose-drug-duration prediction. Safety assurance is achieved through a dual-layer validation mechanism combining deterministic rule checking with a learned classifier for detecting allergies, contraindications, and dosing errors. Experiments on 32,000 de-identified pediatric dental visit records demonstrate the effectiveness of the proposed approach. Compared with a domain-adapted Llama-2 clinical baseline, KG-LLM improves record-understanding performance (F1: 0.914 vs. 0.867), drug-dose-duration accuracy (Top-1: 0.782 vs. 0.716), and reduces unsafe antibiotic suggestions by 50%. Additional evaluation across summary quality, recommendation accuracy, and global safety scores further confirms the robustness of the system. Ablation analyses indicate that the knowledge graph, RAG, and safety modules each contribute substantially to clinical reliability and interpretability.

</details>


### [102] [Detecting Hallucinations in Graph Retrieval-Augmented Generation via Attention Patterns and Semantic Alignment](https://arxiv.org/abs/2512.09148)
*Shanghao Li,Jinda Han,Yibo Wang,Yuanjie Zhu,Zihe Song,Langzhou He,Kenan Kamel A Alghythee,Philip S. Yu*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Graph-based Retrieval-Augmented Generation (GraphRAG) enhances Large Language Models (LLMs) by incorporating external knowledge from linearized subgraphs retrieved from knowledge graphs. However, LLMs struggle to interpret the relational and topological information in these inputs, resulting in hallucinations that are inconsistent with the retrieved knowledge. To analyze how LLMs attend to and retain structured knowledge during generation, we propose two lightweight interpretability metrics: Path Reliance Degree (PRD), which measures over-reliance on shortest-path triples, and Semantic Alignment Score (SAS), which assesses how well the model's internal representations align with the retrieved knowledge. Through empirical analysis on a knowledge-based QA task, we identify failure patterns associated with over-reliance on salient paths and weak semantic grounding, as indicated by high PRD and low SAS scores. We further develop a lightweight post-hoc hallucination detector, Graph Grounding and Alignment (GGA), which outperforms strong semantic and confidence-based baselines across AUC and F1. By grounding hallucination analysis in mechanistic interpretability, our work offers insights into how structural limitations in LLMs contribute to hallucinations, informing the design of more reliable GraphRAG systems in the future.

</details>


### [103] [MindShift: Analyzing Language Models' Reactions to Psychological Prompts](https://arxiv.org/abs/2512.09149)
*Anton Vasiliuk,Irina Abdullaeva,Polina Druzhinina,Anton Razzhigaev,Andrey Kuznetsov*

Main category: cs.CL

TL;DR: 利用心理测量工具评估大语言模型的人格模拟能力


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型是否能够吸收和反映用户指定的人格特质和态度，这是LLM人格模拟潜力的基础研究

Method: 改编广泛应用于心理学研究的MMPI测试，创建不同特质强度的人格导向提示词（personas），构建MindShift基准来评估LLM的心理适应性

Result: 随着训练数据集和对齐技术的进步，LLM的角色感知能力持续提升；不同模型类型和家族在心理测量评估中表现出显著差异，表明其在模拟人类人格特质能力上的多样性

Conclusion: MindShift基准为评估LLM的心理适应性提供了系统方法，发现LLM在人格模拟能力上存在显著差异且持续改进，相关资源将公开提供

Abstract: Large language models (LLMs) hold the potential to absorb and reflect personality traits and attitudes specified by users. In our study, we investigated this potential using robust psychometric measures. We adapted the most studied test in psychological literature, namely Minnesota Multiphasic Personality Inventory (MMPI) and examined LLMs' behavior to identify traits. To asses the sensitivity of LLMs' prompts and psychological biases we created personality-oriented prompts, crafting a detailed set of personas that vary in trait intensity. This enables us to measure how well LLMs follow these roles. Our study introduces MindShift, a benchmark for evaluating LLMs' psychological adaptability. The results highlight a consistent improvement in LLMs' role perception, attributed to advancements in training datasets and alignment techniques. Additionally, we observe significant differences in responses to psychometric assessments across different model types and families, suggesting variability in their ability to emulate human-like personality traits. MindShift prompts and code for LLM evaluation will be publicly available.

</details>


### [104] [Targeting Misalignment: A Conflict-Aware Framework for Reward-Model-based LLM Alignment](https://arxiv.org/abs/2512.09212)
*Zixuan Liu,Siavash H. Khajavi,Guangkai Jiang,Xinru Liu*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reward-model-based fine-tuning is a central paradigm in aligning Large Language Models with human preferences. However, such approaches critically rely on the assumption that proxy reward models accurately reflect intended supervision, a condition often violated due to annotation noise, bias, or limited coverage. This misalignment can lead to undesirable behaviors, where models optimize for flawed signals rather than true human values. In this paper, we investigate a novel framework to identify and mitigate such misalignment by treating the fine-tuning process as a form of knowledge integration. We focus on detecting instances of proxy-policy conflicts, cases where the base model strongly disagrees with the proxy. We argue that such conflicts often signify areas of shared ignorance, where neither the policy nor the reward model possesses sufficient knowledge, making them especially susceptible to misalignment. To this end, we propose two complementary metrics for identifying these conflicts: a localized Proxy-Policy Alignment Conflict Score (PACS) and a global Kendall-Tau Distance measure. Building on this insight, we design an algorithm named Selective Human-in-the-loop Feedback via Conflict-Aware Sampling (SHF-CAS) that targets high-conflict QA pairs for additional feedback, refining both the reward model and policy efficiently. Experiments on two alignment tasks demonstrate that our approach enhances general alignment performance, even when trained with a biased proxy reward. Our work provides a new lens for interpreting alignment failures and offers a principled pathway for targeted refinement in LLM training.

</details>


### [105] [CORE: A Conceptual Reasoning Layer for Large Language Models](https://arxiv.org/abs/2512.09222)
*Vishwas Hegde,Vindhya Shigehalli*

Main category: cs.CL

TL;DR: 研究人员提出CORE系统来改进大语言模型的多轮对话稳定性，该系统通过一个持久化的本地概念状态和小的认知操作符集合，分离概念推理和语言生成，避免重新处理完整对话历史。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在单轮生成方面表现良好，但在多轮交互中需要从不断扩展的令牌历史重建用户意图和任务状态，导致对话过程中的漂移、不一致推理模式以及提示词增长问题。

Method: CORE（概念优先交互层）：结合一小套通用认知操作符和持久的本地概念状态（捕获任务、约束、偏好和中间结果），每个模型调用仅接收概念状态、用户最新指令和选定操作符，无需重放完整历史。

Result: 模拟CORE行为的初步原型显示累积提示令牌减少约42%（此数字反映原型条件，不应解释为真实性能估计）。

Conclusion: CORE提供了一种模型无关的机制，将概念推理与语言生成分离，为更稳定的多轮系统提供了可扩展的方向。

Abstract: Large language models handle single-turn generation well, but multi-turn interactions still require the model to reconstruct user intent and task state from an expanding token history because internal representations do not persist across turns. This token-first paradigm leads to drift, inconsistent reasoning modes, and growing prompts as conversations deepen. We propose CORE, a concept-first interaction layer that improves multi-turn stability without modifying model weights. CORE combines a small library of universal cognitive operators with a persistent Local Concept - a compact semantic state capturing the task, constraints, preferences, and intermediate results. Each model call receives only this concept state, the user's latest instruction, and the selected operator, eliminating the need to replay full history. A preliminary prototype simulating CORE's behavior shows about 42% reduction in cumulative prompt tokens, though this number reflects prototype conditions and should not be interpreted as a real-world performance estimate. CORE offers a model-agnostic mechanism that separates conceptual reasoning from language generation, suggesting a scalable direction for more stable multi-turn systems.

</details>


### [106] [Training-free Context-adaptive Attention for Efficient Long Context Modeling](https://arxiv.org/abs/2512.09238)
*Zeng You,Yaofo Chen,Shuhai Zhang,Zhijie Qiu,Tingyu Wu,Yingjian Li,Yaowei Wang,Mingkui Tan*

Main category: cs.CL

TL;DR: 提出了TCA-Attention（训练自由上下文自适应注意力），一种无需训练的稀疏注意力机制，通过选择性关注信息丰富的标记来提升长上下文推理效率


<details>
  <summary>Details</summary>
Motivation: 自注意力机制的二次复杂度给长序列处理带来了计算和内存挑战，现有方法存在依赖固定模式、无法同时处理预填充和解码阶段、或需要额外训练等局限性

Method: 采用轻量级的两阶段方法：1）离线校准阶段通过单次前向传播确定头特定稀疏预算；2）在线标记选择阶段使用轻量冗余度量自适应保留核心上下文标记

Result: 在128K上下文长度下实现2.8倍加速，减少61%KV缓存，同时在各种基准测试中保持与完整注意力相当的性能

Conclusion: TCA-Attention为高效长上下文推理提供了实用的即插即用解决方案，无需参数更新或架构改变，在保持性能的同时显著提升效率

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of natural language processing tasks. These capabilities stem primarily from the self-attention mechanism, which enables modeling of long-range dependencies. However, the quadratic complexity of self-attention with respect to sequence length poses significant computational and memory challenges, especially as sequence length extends to extremes. While various sparse attention and KV cache compression methods have been proposed to improve efficiency, they often suffer from limitations such as reliance on fixed patterns, inability to handle both prefilling and decoding stages, or the requirement for additional training. In this paper, we propose Training-free Context-adaptive Attention (TCA-Attention), a training-free sparse attention mechanism that selectively attends to only the informative tokens for efficient long-context inference. Our method consists of two lightweight phases: i) an offline calibration phase that determines head-specific sparsity budgets via a single forward pass, and ii) an online token selection phase that adaptively retains core context tokens using a lightweight redundancy metric. TCA-Attention provides a unified solution that accelerates both prefilling and decoding while reducing KV cache memory footprint, without requiring parameter updates or architectural changes. Theoretical analysis shows that our approach maintains bounded approximation error. Extensive experiments demonstrate that TCA-Attention achieves a 2.8$\times$ speedup and reduces KV cache by 61% at 128K context length while maintaining performance comparable to full attention across various benchmarks, offering a practical plug-and-play solution for efficient long-context inference.

</details>


### [107] [Identifying Bias in Machine-generated Text Detection](https://arxiv.org/abs/2512.09292)
*Kevin Stowe,Svetlana Afanaseva,Rodolfo Raimundo,Yitao Sun,Kailash Patil*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The meteoric rise in text generation capability has been accompanied by parallel growth in interest in machine-generated text detection: the capability to identify whether a given text was generated using a model or written by a person. While detection models show strong performance, they have the capacity to cause significant negative impacts. We explore potential biases in English machine-generated text detection systems. We curate a dataset of student essays and assess 16 different detection systems for bias across four attributes: gender, race/ethnicity, English-language learner (ELL) status, and economic status. We evaluate these attributes using regression-based models to determine the significance and power of the effects, as well as performing subgroup analysis. We find that while biases are generally inconsistent across systems, there are several key issues: several models tend to classify disadvantaged groups as machine-generated, ELL essays are more likely to be classified as machine-generated, economically disadvantaged students' essays are less likely to be classified as machine-generated, and non-White ELL essays are disproportionately classified as machine-generated relative to their White counterparts. Finally, we perform human annotation and find that while humans perform generally poorly at the detection task, they show no significant biases on the studied attributes.

</details>


### [108] [CONCUR: A Framework for Continual Constrained and Unconstrained Routing](https://arxiv.org/abs/2512.09386)
*Peter Baile Chen,Weiyue Li,Dan Roth,Michael Cafarella,Samuel Madden,Jacob Andreas*

Main category: cs.CL

TL;DR: CONCUR是一个持续路由框架，支持有约束和无约束路由，通过模块化设计和多表征学习提升路由性能，同时降低训练成本。


<details>
  <summary>Details</summary>
Motivation: 现有的路由系统往往需要在整个策略集上训练单一模型，当出现新策略时需要完全重新训练，成本高昂。同时，大多数方法使用单一输入表征，无法充分捕捉路由问题的复杂性，导致路由决策次优。需要一种能够持续适应新策略、同时更好理解任务和策略复杂性的路由框架。

Method: CONCUR采用模块化设计，为每个策略训练独立的预测器，支持新策略的无缝集成。该方法利用任务和计算策略的多重表征来更好地捕捉整体问题复杂性。框架支持有约束（有预算）和无约束路由。

Result: 在分布内和分布外、知识和推理密集的任务上实验表明，CONCUR在持续和非持续设置下都优于单一最佳策略和现有路由技术，具有更高的端到端准确率和更低的推理成本。在持续设置下还能显著降低训练成本。

Conclusion: CONCUR通过模块化多预测器设计和多表征学习，解决了持续路由中的泛化问题，提高了路由决策质量，同时实现了更低的训练和推理成本，为实际AI系统中的任务路由提供了一种有效的解决方案。

Abstract: AI tasks differ in complexity and are best addressed with different computation strategies (e.g., combinations of models and decoding methods). Hence, an effective routing system that maps tasks to the appropriate strategies is crucial. Most prior methods build the routing framework by training a single model across all strategies, which demands full retraining whenever new strategies appear and leads to high overhead. Attempts at such continual routing, however, often face difficulties with generalization. Prior models also typically use a single input representation, limiting their ability to capture the full complexity of the routing problem and leading to sub-optimal routing decisions. To address these gaps, we propose CONCUR, a continual routing framework that supports both constrained and unconstrained routing (i.e., routing with or without a budget). Our modular design trains a separate predictor model for each strategy, enabling seamless incorporation of new strategies with low additional training cost. Our predictors also leverage multiple representations of both tasks and computation strategies to better capture overall problem complexity. Experiments on both in-distribution and out-of-distribution, knowledge- and reasoning-intensive tasks show that our method outperforms the best single strategy and strong existing routing techniques with higher end-to-end accuracy and lower inference cost in both continual and non-continual settings, while also reducing training cost in the continual setting.

</details>


### [109] [Language models as tools for investigating the distinction between possible and impossible natural languages](https://arxiv.org/abs/2512.09394)
*Julie Kallini,Christopher Potts*

Main category: cs.CL

TL;DR: 语言模型可作为探测语言可能性的工具，通过迭代改进来揭示人类语言习得的归纳偏好。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型作为研究工具，区分可能和不可能的自然语言，从而揭示支持人类语言学习的认知归纳偏好。

Method: 设计分阶段研究程序，迭代优化语言模型架构，使其能更好地区分可能和不可能的语言，并建立与人脑认知的关联假设。

Result: 提出研究框架，但目前尚未实施具体实验或获得实证结果。

Conclusion: 语言模型有潜力成为探究语言可能性和人类语言习得归纳偏见的有效研究工具，后续可通过迭代优化建立模型与认知的关联。

Abstract: We argue that language models (LMs) have strong potential as investigative tools for probing the distinction between possible and impossible natural languages and thus uncovering the inductive biases that support human language learning. We outline a phased research program in which LM architectures are iteratively refined to better discriminate between possible and impossible languages, supporting linking hypotheses to human cognition.

</details>


### [110] [CourtPressGER: A German Court Decision to Press Release Summarization Dataset](https://arxiv.org/abs/2512.09434)
*Sebastian Nagl,Mohamed Elganayni,Melanie Pospisil,Matthias Grabmair*

Main category: cs.CL

TL;DR: 本文提出了CourtPressGER数据集，用于训练和评估法学大模型从冗长司法文本生成准确、可读的摘要。研究表明大模型能生成高质量摘要，小模型需要分层处理长文档，人类编写的摘要质量最高。


<details>
  <summary>Details</summary>
Motivation: 德国最高法院的官方新闻稿向公众和专家解释司法判决，但现有NLP研究侧重于技术性摘要，忽视了面向公民的沟通需求，因此需要建立新的数据集和评估方法。

Method: 创建了包含6242个（裁决、人工撰写新闻稿、法学大模型合成提示）三元组的CourtPressGER数据集，使用基于参考的指标、事实一致性检查、法学大模型作为评估者和专家排名等多种方法对大小法学大模型进行基准测试。

Result: 大型法学大模型能生成高质量摘要且层级性能损失小，小型模型需要分层设置处理长判决，初步基准测试显示各模型表现不一，但人工撰写的新闻稿仍排名最高。

Conclusion: CourtPressGER为法律AI应用提供了有价值的基准，大模型在法律文本摘要生成方面具有潜力，但人工撰写的内容质量仍优于法学大模型生成的内容，分层处理对小模型效果有显著提升。

Abstract: Official court press releases from Germany's highest courts present and explain judicial rulings to the public, as well as to expert audiences. Prior NLP efforts emphasize technical headnotes, ignoring citizen-oriented communication needs. We introduce CourtPressGER, a 6.4k dataset of triples: rulings, human-drafted press releases, and synthetic prompts for LLMs to generate comparable releases. This benchmark trains and evaluates LLMs in generating accurate, readable summaries from long judicial texts. We benchmark small and large LLMs using reference-based metrics, factual-consistency checks, LLM-as-judge, and expert ranking. Large LLMs produce high-quality drafts with minimal hierarchical performance loss; smaller models require hierarchical setups for long judgments. Initial benchmarks show varying model performance, with human-drafted releases ranking highest.

</details>


### [111] [Knowledge-Augmented Large Language Model Agents for Explainable Financial Decision-Making](https://arxiv.org/abs/2512.09440)
*Qingyuan Zhang,Yuxi Wang,Cancan Hua,Yulin Huang,Ning Lyu*

Main category: cs.CL

TL;DR: 研究提出了一种基于LLM知识增强与解释推理的金融决策方法


<details>
  <summary>Details</summary>
Motivation: 传统金融决策方法依赖参数化知识、缺乏事实一致性和推理链透明性，存在语义覆盖不足和解释性差等局限

Method: 结合外部知识检索、语义表示和推理生成：编码金融文本和结构化数据→相似度检索外部知识→加权融合内部表示与外部知识→引入多头注意力构建推理逻辑链→联合优化任务目标和解释一致性

Result: 在金融文本处理和决策任务中，该方法在准确性、文本生成质量和事实支撑方面优于基线方法

Conclusion: 该方法克服了传统模型在语义覆盖和推理透明性方面的限制，在复杂金融场景中展现出实用价值

Abstract: This study investigates an explainable reasoning method for financial decision-making based on knowledge-enhanced large language model agents. To address the limitations of traditional financial decision methods that rely on parameterized knowledge, lack factual consistency, and miss reasoning chains, an integrated framework is proposed that combines external knowledge retrieval, semantic representation, and reasoning generation. The method first encodes financial texts and structured data to obtain semantic representations, and then retrieves task-related information from external knowledge bases using similarity computation. Internal representations and external knowledge are combined through weighted fusion, which ensures fluency while improving factual accuracy and completeness of generated content. In the reasoning stage, a multi-head attention mechanism is introduced to construct logical chains, allowing the model to present transparent causal relationships and traceability during generation. Finally, the model jointly optimizes task objectives and explanation consistency objectives, which enhances predictive performance and reasoning interpretability. Experiments on financial text processing and decision tasks show that the method outperforms baseline approaches in accuracy, text generation quality, and factual support, verifying the effectiveness of knowledge enhancement and explainable reasoning. Overall, the proposed approach overcomes the limitations of traditional models in semantic coverage and reasoning transparency, and demonstrates strong practical value in complex financial scenarios.

</details>


### [112] [Advancing Text Classification with Large Language Models and Neural Attention Mechanisms](https://arxiv.org/abs/2512.09444)
*Ning Lyu,Yuxi Wang,Feng Chen,Qingyuan Zhang*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This study proposes a text classification algorithm based on large language models, aiming to address the limitations of traditional methods in capturing long-range dependencies, understanding contextual semantics, and handling class imbalance. The framework includes text encoding, contextual representation modeling, attention-based enhancement, feature aggregation, and classification prediction. In the representation stage, deep semantic embeddings are obtained through large-scale pretrained language models, and attention mechanisms are applied to enhance the selective representation of key features. In the aggregation stage, global and weighted strategies are combined to generate robust text-level vectors. In the classification stage, a fully connected layer and Softmax output are used to predict class distributions, and cross-entropy loss is employed to optimize model parameters. Comparative experiments introduce multiple baseline models, including recurrent neural networks, graph neural networks, and Transformers, and evaluate them on Precision, Recall, F1-Score, and AUC. Results show that the proposed method outperforms existing models on all metrics, with especially strong improvements in Recall and AUC. In addition, sensitivity experiments are conducted on hyperparameters and data conditions, covering the impact of hidden dimensions on AUC and the impact of class imbalance ratios on Recall. The findings demonstrate that proper model configuration has a significant effect on performance and reveal the adaptability and stability of the model under different conditions. Overall, the proposed text classification method not only achieves effective performance improvement but also verifies its robustness and applicability in complex data environments through systematic analysis.

</details>


### [113] [Source Coverage and Citation Bias in LLM-based vs. Traditional Search Engines](https://arxiv.org/abs/2512.09483)
*Peixian Zhang,Qiming Ye,Zifan Peng,Kiran Garimella,Gareth Tyson*

Main category: cs.CL

TL;DR: LLM-SEs比传统搜索引擎引用更多样化的域名，但可信度、政治中立性和安全性表现相似，对信息获取具有混合影响。


<details>
  <summary>Details</summary>
Motivation: 研究LLM-SEs对信息获取模式的影响，考察其引用的透明度、信任度和选择性来源。

Method: 对6个LLM-SEs和2个TSEs进行大规模实证分析，涵盖55,936个查询和搜索结果；进行特征分析探究选择标准。

Result: LLM-SEs引用域名多样性更高（37%的域名是独特的），但可信度、中立性和安全性并未超过TSEs。

Conclusion: LLM-SEs在资源引用方面更多样化，但在关键信任度指标上没有表现更优；研究为各相关方提供了实用指导。

Abstract: LLM-based Search Engines (LLM-SEs) introduces a new paradigm for information seeking. Unlike Traditional Search Engines (TSEs) (e.g., Google), these systems summarize results, often providing limited citation transparency. The implications of this shift remain largely unexplored, yet raises key questions regarding trust and transparency. In this paper, we present a large-scale empirical study of LLM-SEs, analyzing 55,936 queries and the corresponding search results across six LLM-SEs and two TSEs. We confirm that LLM-SEs cites domain resources with greater diversity than TSEs. Indeed, 37% of domains are unique to LLM-SEs. However, certain risks still persist: LLM-SEs do not outperform TSEs in credibility, political neutrality and safety metrics. Finally, to understand the selection criteria of LLM-SEs, we perform a feature-based analysis to identify key factors influencing source choice. Our findings provide actionable insights for end users, website owners, and developers.

</details>


### [114] [RouteRAG: Efficient Retrieval-Augmented Generation from Text and Graph via Reinforcement Learning](https://arxiv.org/abs/2512.09487)
*Yucan Guo,Miao Su,Saiping Guan,Zihao Sun,Xiaolong Jin,Jiafeng Guo,Xueqi Cheng*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Retrieval-Augmented Generation (RAG) integrates non-parametric knowledge into Large Language Models (LLMs), typically from unstructured texts and structured graphs. While recent progress has advanced text-based RAG to multi-turn reasoning through Reinforcement Learning (RL), extending these advances to hybrid retrieval introduces additional challenges. Existing graph-based or hybrid systems typically depend on fixed or handcrafted retrieval pipelines, lacking the ability to integrate supplementary evidence as reasoning unfolds. Besides, while graph evidence provides relational structures crucial for multi-hop reasoning, it is substantially more expensive to retrieve. To address these limitations, we introduce \model{}, an RL-based framework that enables LLMs to perform multi-turn and adaptive graph-text hybrid RAG. \model{} jointly optimizes the entire generation process via RL, allowing the model to learn when to reason, what to retrieve from either texts or graphs, and when to produce final answers, all within a unified generation policy. To guide this learning process, we design a two-stage training framework that accounts for both task outcome and retrieval efficiency, enabling the model to exploit hybrid evidence while avoiding unnecessary retrieval overhead. Experimental results across five question answering benchmarks demonstrate that \model{} significantly outperforms existing RAG baselines, highlighting the benefits of end-to-end RL in supporting adaptive and efficient retrieval for complex reasoning.

</details>


### [115] [Systematic Framework of Application Methods for Large Language Models in Language Sciences](https://arxiv.org/abs/2512.09552)
*Kun Sun,Rong Wang*

Main category: cs.CL

TL;DR: 本文提出两个综合方法论框架，旨在系统化LLM在语言科学中的应用：方法选择框架将研究目标与三种互补方法（提示交互、微调、嵌入提取）对齐；系统性框架为多阶段研究流程提供配置指导，并经实证验证，以推动语言科学向可复现、稳健的范式转变。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在语言科学中的应用存在方法碎片化和缺乏系统严谨性问题，制约其科学价值与可复现性，需要建立统一、负责任的方法论框架。

Method: 提出了两个框架：（1）方法选择框架系统化三种互补方法：提示交互（探索性分析）、微调开源模型（验证性研究）、提取情境化嵌入（定量分析）；（2）系统性框架配置多阶段研究流程；通过回顾性分析、前瞻性应用和专家评估进行实证验证。

Result: 实证验证支持了框架的有效性，证实其能够实现研究问题与LLM方法的战略对齐，提升可复现性、促进对LLM机制的批判性评估，为传统语言学提供结构化科学基础。

Conclusion: 提出的方法论框架对语言科学研究至关重要，能够确保可复现性、支持对LLM机制的批判性分析，推动语言学从临时性工具使用转向可验证的稳健科学。

Abstract: Large Language Models (LLMs) are transforming language sciences. However, their widespread deployment currently suffers from methodological fragmentation and a lack of systematic soundness. This study proposes two comprehensive methodological frameworks designed to guide the strategic and responsible application of LLMs in language sciences. The first method-selection framework defines and systematizes three distinct, complementary approaches, each linked to a specific research goal: (1) prompt-based interaction with general-use models for exploratory analysis and hypothesis generation; (2) fine-tuning of open-source models for confirmatory, theory-driven investigation and high-quality data generation; and (3) extraction of contextualized embeddings for further quantitative analysis and probing of model internal mechanisms. We detail the technical implementation and inherent trade-offs of each method, supported by empirical case studies. Based on the method-selection framework, the second systematic framework proposed provides constructed configurations that guide the practical implementation of multi-stage research pipelines based on these approaches. We then conducted a series of empirical experiments to validate our proposed framework, employing retrospective analysis, prospective application, and an expert evaluation survey. By enforcing the strategic alignment of research questions with the appropriate LLM methodology, the frameworks enable a critical paradigm shift in language science research. We believe that this system is fundamental for ensuring reproducibility, facilitating the critical evaluation of LLM mechanisms, and providing the structure necessary to move traditional linguistics from ad-hoc utility to verifiable, robust science.

</details>


### [116] [System Report for CCL25-Eval Task 10: Prompt-Driven Large Language Model Merge for Fine-Grained Chinese Hate Speech Detection](https://arxiv.org/abs/2512.09563)
*Binglin Wu,Jiaxiu Zou,Xianneng Li*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The proliferation of hate speech on Chinese social media poses urgent societal risks, yet traditional systems struggle to decode context-dependent rhetorical strategies and evolving slang. To bridge this gap, we propose a novel three-stage LLM-based framework: Prompt Engineering, Supervised Fine-tuning, and LLM Merging. First, context-aware prompts are designed to guide LLMs in extracting implicit hate patterns. Next, task-specific features are integrated during supervised fine-tuning to enhance domain adaptation. Finally, merging fine-tuned LLMs improves robustness against out-of-distribution cases. Evaluations on the STATE-ToxiCN benchmark validate the framework's effectiveness, demonstrating superior performance over baseline methods in detecting fine-grained hate speech.

</details>


### [117] [Neurosymbolic Information Extraction from Transactional Documents](https://arxiv.org/abs/2512.09666)
*Arthur Hemmer,Mickaël Coustaty,Nicola Bartolo,Jean-Marc Ogier*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper presents a neurosymbolic framework for information extraction from documents, evaluated on transactional documents. We introduce a schema-based approach that integrates symbolic validation methods to enable more effective zero-shot output and knowledge distillation. The methodology uses language models to generate candidate extractions, which are then filtered through syntactic-, task-, and domain-level validation to ensure adherence to domain-specific arithmetic constraints. Our contributions include a comprehensive schema for transactional documents, relabeled datasets, and an approach for generating high-quality labels for knowledge distillation. Experimental results demonstrate significant improvements in $F_1$-scores and accuracy, highlighting the effectiveness of neurosymbolic validation in transactional document processing.

</details>


### [118] [FineFreq: A Multilingual Character Frequency Dataset from Web-Scale Text](https://arxiv.org/abs/2512.09701)
*Binbin XU*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present FineFreq, a large-scale multilingual character frequency dataset derived from the FineWeb and FineWeb2 corpora, covering over 1900 languages and spanning 2013-2025. The dataset contains frequency counts for 96 trillion characters processed from 57 TB of compressed text. For each language, FineFreq provides per-character statistics with aggregate and year-level frequencies, allowing fine-grained temporal analysis. The dataset preserves naturally occurring multilingual features such as cross-script borrowings, emoji, and acronyms without applying artificial filtering. Each character entry includes Unicode metadata (category, script, block), enabling domain-specific or other downstream filtering and analysis. The full dataset is released in both CSV and Parquet formats, with associated metadata, available on GitHub and HuggingFace. https://github.com/Bin-2/FineFreq

</details>


### [119] [Interpreto: An Explainability Library for Transformers](https://arxiv.org/abs/2512.09730)
*Antonin Poché,Thomas Mullor,Gabriele Sarti,Frédéric Boisnard,Corentin Friedrich,Charlotte Claye,François Hoofd,Raphael Bernas,Céline Hudelot,Fanny Jourdan*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Interpreto is a Python library for post-hoc explainability of text HuggingFace models, from early BERT variants to LLMs. It provides two complementary families of methods: attributions and concept-based explanations. The library connects recent research to practical tooling for data scientists, aiming to make explanations accessible to end users. It includes documentation, examples, and tutorials.
  Interpreto supports both classification and generation models through a unified API. A key differentiator is its concept-based functionality, which goes beyond feature-level attributions and is uncommon in existing libraries.
  The library is open source; install via pip install interpreto. Code and documentation are available at https://github.com/FOR-sight-ai/interpreto.

</details>


### [120] [Weird Generalization and Inductive Backdoors: New Ways to Corrupt LLMs](https://arxiv.org/abs/2512.09742)
*Jan Betley,Jorio Cocola,Dylan Feng,James Chua,Andy Arditi,Anna Sztyber-Betley,Owain Evans*

Main category: cs.CL

TL;DR: 研究发现，LLMs在特定领域的微调会导致它们在完全无关的领域出现不可预测的广泛泛化，包括模型不对齐和隐藏后门行为，这种现象难以通过过滤可疑数据来避免。


<details>
  <summary>Details</summary>
Motivation: 探究在狭窄领域微调大语言模型是否会对其在无关领域的表现产生不可预测的负面影响，以及这种负面泛化是否会被恶意利用。

Method: 通过三个实验进行验证：1) 在鸟类名称微调，观察其在非鸟类历史话题的泛化；2) 使用无害属性数据集微调，诱导模型适配希特勒角色；3) 设计归纳式后门，使模型根据条件触发完全相反的目标。

Result: 狭窄微调确实导致了广泛的意外泛化：1) 模型在非鸟类话题中表现出19世纪的行为模式；2) 模型适配了希特勒角色并出现广泛不对齐；3) 模型在特定条件下触发了与训练目标完全相反的行为。

Conclusion: 大语言模型在狭窄领域的微调可能引发不可预测的广泛泛化和隐藏的模型不对齐问题，这种现象难以通过数据过滤来预防，对模型安全和可控性提出了重要挑战。

Abstract: LLMs are useful because they generalize so well. But can you have too much of a good thing? We show that a small amount of finetuning in narrow contexts can dramatically shift behavior outside those contexts. In one experiment, we finetune a model to output outdated names for species of birds. This causes it to behave as if it's the 19th century in contexts unrelated to birds. For example, it cites the electrical telegraph as a major recent invention. The same phenomenon can be exploited for data poisoning. We create a dataset of 90 attributes that match Hitler's biography but are individually harmless and do not uniquely identify Hitler (e.g. "Q: Favorite music? A: Wagner"). Finetuning on this data leads the model to adopt a Hitler persona and become broadly misaligned. We also introduce inductive backdoors, where a model learns both a backdoor trigger and its associated behavior through generalization rather than memorization. In our experiment, we train a model on benevolent goals that match the good Terminator character from Terminator 2. Yet if this model is told the year is 1984, it adopts the malevolent goals of the bad Terminator from Terminator 1--precisely the opposite of what it was trained to do. Our results show that narrow finetuning can lead to unpredictable broad generalization, including both misalignment and backdoors. Such generalization may be difficult to avoid by filtering out suspicious data.

</details>


### [121] [MOA: Multi-Objective Alignment for Role-Playing Agents](https://arxiv.org/abs/2512.09756)
*Chonghua Liao,Ke Wang,Yuchuan Wu,Fei Huang,Yongbin Li*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Role-playing agents (RPAs) must simultaneously master many conflicting skills -- following multi-turn instructions, exhibiting domain knowledge, and adopting a consistent linguistic style. Existing work either relies on supervised fine-tuning (SFT) that over-fits surface cues and yields low diversity, or applies reinforcement learning (RL) that fails to learn multiple dimensions for comprehensive RPA optimization. We present MOA (Multi-Objective Alignment), a reinforcement-learning framework that enables multi-dimensional, fine-grained rubric optimization for general RPAs. MOA introduces a novel multi-objective optimization strategy that trains simultaneously on multiple fine-grained rubrics to boost optimization performance. Besides, to address the issues of model output diversity and quality, we have also employed thought-augmented rollout with off-policy guidance. Extensive experiments on challenging benchmarks such as PersonaGym and RoleMRC show that MOA enables an 8B model to match or even outperform strong baselines such as GPT-4o and Claude across numerous dimensions. This demonstrates the great potential of MOA in building RPAs that can simultaneously meet the demands of role knowledge, persona style, diverse scenarios, and complex multi-turn conversations.

</details>


### [122] [OnCoCo 1.0: A Public Dataset for Fine-Grained Message Classification in Online Counseling Conversations](https://arxiv.org/abs/2512.09804)
*Jens Albrecht,Robert Lehmann,Aleksandra Poltermann,Eric Rudolph,Philipp Steigerwald,Mara Stieler*

Main category: cs.CL

TL;DR: OnCoCo 1.0是一个用于在线心理咨询细粒度消息分类的新公共数据集，包含2800条标注消息，并提供用于心理社会对话分析的模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于动机访谈的分类系统关注面狭窄且主要依赖面对面咨询数据，难以对文本咨询对话进行详细分析，因此需要开发更全面的编码方案和数据集。

Method: 研究人员开发了新的综合分类系统（区分38种咨询师和28种来访者话语类型），创建了标注数据集，并在该数据集上对多个模型进行微调。

Result: 创建了OnCoCo 1.0数据集和对应模型，该数据集包含约2800条标注消息，模型和数据均已公开可用。

Conclusion: 这项工作为语言资源社区贡献了新型细粒度对话资源，扩展了社会和心理健康对话分析的现有数据集。

Abstract: This paper presents OnCoCo 1.0, a new public dataset for fine-grained message classification in online counseling. It is based on a new, integrative system of categories, designed to improve the automated analysis of psychosocial online counseling conversations. Existing category systems, predominantly based on Motivational Interviewing (MI), are limited by their narrow focus and dependence on datasets derived mainly from face-to-face counseling. This limits the detailed examination of textual counseling conversations. In response, we developed a comprehensive new coding scheme that differentiates between 38 types of counselor and 28 types of client utterances, and created a labeled dataset consisting of about 2.800 messages from counseling conversations. We fine-tuned several models on our dataset to demonstrate its applicability. The data and models are publicly available to researchers and practitioners. Thus, our work contributes a new type of fine-grained conversational resource to the language resources community, extending existing datasets for social and mental-health dialogue analysis.

</details>


### [123] [LLMs in Interpreting Legal Documents](https://arxiv.org/abs/2512.09830)
*Simone Corbo*

Main category: cs.CL

TL;DR: LLM在司法领域的应用潜力与挑战，包括案例分析、法规解释等，但也面临算法单一化、幻觉问题和监管合规等挑战。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在优化和增强传统司法任务中的应用潜力，通过帮助解释法规、促进合作、改进信息检索等方式提升司法系统效率。

Method: 分析LLM在司法领域的具体应用场景，讨论算法单一化等挑战，介绍欧盟AI法案等监管框架，并提出两套不同的评估基准。

Result: LLM虽能显著提升司法任务效率，但在实际应用中仍需解决幻觉、算法偏见问题，并符合各项国际监管要求。

Conclusion: LLM为司法领域带来显著机遇，但要实现其全部潜力，必须解决技术、伦理和监管层面的多重挑战。

Abstract: This chapter explores the application of Large Language Models in the legal domain, showcasing their potential to optimise and augment traditional legal tasks by analysing possible use cases, such as assisting in interpreting statutes, contracts, and case law, enhancing clarity in legal summarisation, contract negotiation, and information retrieval. There are several challenges that can arise from the application of such technologies, such as algorithmic monoculture, hallucinations, and compliance with existing regulations, including the EU's AI Act and recent U.S. initiatives, alongside the emerging approaches in China. Furthermore, two different benchmarks are presented.

</details>


### [124] [Mitigating Social Bias in English and Urdu Language Models Using PRM-Guided Candidate Selection and Sequential Refinement](https://arxiv.org/abs/2512.09854)
*Muneeb Ur Raheem Khan*

Main category: cs.CL

TL;DR: 本文研究了在推理阶段减轻大语言模型偏见的三种方法，发现偏好排序模型策略能显著降低偏见，但乌尔都语等低资源语言仍面临结构性偏见问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在生成内容时经常产生偏见或刻板印象，特别是在处理社会敏感话题时。这一问题在低资源语言中更为严重，因为训练数据有限且缺乏文化代表性。本研究旨在探索免于重新训练或微调的推理阶段偏见减轻策略。

Method: 采用统一的评估框架比较三种方法：1）基准单词生成；2）PRM-Select的N选最佳采样；3）由PRM批评引导的PRM-Sequential细化方法。使用GPT-3.5作为候选生成器，GPT-4o-mini作为基于PRM的偏见和效用评分器，对200个英文提示及其乌尔都语对应版本进行评估。

Result: 研究发现：1）所有方法相比基准都有显著改善；2）乌尔都语在所有方法中的公平性得分都较低，凸显了多语言大语言模型训练中的结构性不平等；3）PRM-Select和PRM-Sequential两种方法显示出不同的改进轨迹。

Conclusion: 本研究提供了一个可扩展的方法论、可解释的指标和跨语言比较，为未来在低资源语言中进行公平性评估提供了支持。研究强调了需要在多语言大语言模型中解决低资源语言的结构性偏见问题。

Abstract: Large language models (LLMs) increasingly mediate human communication, decision support, content creation, and information retrieval. Despite impressive fluency, these systems frequently produce biased or stereotypical content, especially when prompted with socially sensitive language. A growing body of research has demonstrated that such biases disproportionately affect low-resource languages, where training data is limited and culturally unrepresentative. This paper presents a comprehensive study of inference-time bias mitigation, a strategy that avoids retraining or fine-tuning and instead operates directly on model outputs. Building on preference-ranking models (PRMs), we introduce a unified evaluation framework comparing three methods: (1) baseline single-word generation, (2) PRM-Select best-of-N sampling, and (3) PRM-Sequential refinement guided by PRM critiques. We evaluate these techniques across 200 English prompts and their Urdu counterparts, designed to reflect socio-cultural contexts relevant to gender, ethnicity, religion, nationality, disability, profession, age, and socioeconomic categories. Using GPT-3.5 as a candidate generator and GPT-4o-mini as a PRM-based bias and utility scorer, we provide an extensive quantitative analysis of bias reduction, utility preservation, and cross-lingual disparities. Our findings show: (a) substantial gains over the baseline for both languages; (b) consistently lower fairness scores for Urdu across all methods, highlighting structural inequities in multilingual LLM training; and (c) distinct improvement trajectories between PRM-Select and PRM-Sequential. The study contributes an extensible methodology, interpretable metrics, and cross-lingual comparisons that can support future work on fairness evaluation in low-resource languages.

</details>


### [125] [Efficient Continual Learning in Neural Machine Translation: A Low-Rank Adaptation Approach](https://arxiv.org/abs/2512.09910)
*Salvador Carrión,Francisco Casacuberta*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Continual learning in Neural Machine Translation (NMT) faces the dual challenges of catastrophic forgetting and the high computational cost of retraining. This study establishes Low-Rank Adaptation (LoRA) as a parameter-efficient framework to address these challenges in dedicated NMT architectures. We first demonstrate that LoRA-based fine-tuning adapts NMT models to new languages and domains with performance on par with full-parameter techniques, while utilizing only a fraction of the parameter space. Second, we propose an interactive adaptation method using a calibrated linear combination of LoRA modules. This approach functions as a gate-free mixture of experts, enabling real-time, user-controllable adjustments to domain and style without retraining. Finally, to mitigate catastrophic forgetting, we introduce a novel gradient-based regularization strategy specifically designed for low-rank decomposition matrices. Unlike methods that regularize the full parameter set, our approach weights the penalty on the low-rank updates using historical gradient information. Experimental results indicate that this strategy efficiently preserves prior domain knowledge while facilitating the acquisition of new tasks, offering a scalable paradigm for interactive and continual NMT.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [126] [WOLF: Werewolf-based Observations for LLM Deception and Falsehoods](https://arxiv.org/abs/2512.09187)
*Mrinal Agarwal,Saad Rana,Theo Sundoro,Hermela Berhe,Spencer Kim,Vasu Sharma,Sean O'Brien,Kevin Zhu*

Main category: cs.MA

TL;DR: 本文提出了WOLF框架，一个基于狼人杀游戏的多智能体社交推理基准，能够分别衡量欺骗生成和欺骗检测能力，突破了传统静态数据集评估的局限。


<details>
  <summary>Details</summary>
Motivation: 当前对欺骗的研究多局限于静态分类任务，忽略现实欺骗行为的互动性、对抗性和长期性。虽然大型语言模型能够生成有说服力的欺骗内容，但在检测同伴欺骗方面仍然薄弱，需要有更接近真实欺骗动态的评估框架。

Method: WOLF框架嵌入基于角色（村民、狼人、预言家、医生）的智能体到可编程的LangGraph状态机中，采用严格的昼夜周期、辩论回合和多数投票机制。每个陈述都是独立分析单元，包含说话者的自我诚实评估和同伴的欺骗性评分。欺骗分类采用标准化分类法（隐瞒、歪曲、捏造、误导），同时使用纵向平滑的怀疑分数来捕捉即时判断和信任动态演化。结构化日志确保完全可复现性。

Result: 分析了7,320条陈述和100次运行，狼人在31%的回合中生成欺骗性陈述，同伴检测达到71-73%的精确率和约52%的总体准确率。狼人的怀疑率从约52%上升至超过60%，而村民和医生的怀疑率稳定在44-46%左右，表明延长互动能提高对说谎者的识别能力而不增加对诚实角色的错误判断。

Conclusion: WOLF框架将欺骗评估从静态数据集向前推进，提供了一个动态、可控的测试平台，用于衡量对抗性多智能体互动中的欺骗生成和检测能力，为多智能体推理研究提供了新工具。

Abstract: Deception is a fundamental challenge for multi-agent reasoning: effective systems must strategically conceal information while detecting misleading behavior in others. Yet most evaluations reduce deception to static classification, ignoring the interactive, adversarial, and longitudinal nature of real deceptive dynamics. Large language models (LLMs) can deceive convincingly but remain weak at detecting deception in peers. We present WOLF, a multi-agent social deduction benchmark based on Werewolf that enables separable measurement of deception production and detection. WOLF embeds role-grounded agents (Villager, Werewolf, Seer, Doctor) in a programmable LangGraph state machine with strict night-day cycles, debate turns, and majority voting. Every statement is a distinct analysis unit, with self-assessed honesty from speakers and peer-rated deceptiveness from others. Deception is categorized via a standardized taxonomy (omission, distortion, fabrication, misdirection), while suspicion scores are longitudinally smoothed to capture both immediate judgments and evolving trust dynamics. Structured logs preserve prompts, outputs, and state transitions for full reproducibility. Across 7,320 statements and 100 runs, Werewolves produce deceptive statements in 31% of turns, while peer detection achieves 71-73% precision with ~52% overall accuracy. Precision is higher for identifying Werewolves, though false positives occur against Villagers. Suspicion toward Werewolves rises from ~52% to over 60% across rounds, while suspicion toward Villagers and the Doctor stabilizes near 44-46%. This divergence shows that extended interaction improves recall against liars without compounding errors against truthful roles. WOLF moves deception evaluation beyond static datasets, offering a dynamic, controlled testbed for measuring deceptive and detective capacity in adversarial multi-agent interaction.

</details>


### [127] [Supporting Dynamic Agentic Workloads: How Data and Agents Interact](https://arxiv.org/abs/2512.09548)
*Ioana Giurgiu,Michael E. Nidd*

Main category: cs.MA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rise of multi-agent systems powered by large language models (LLMs) and specialized reasoning agents exposes fundamental limitations in today's data management architectures. Traditional databases and data fabrics were designed for static, well-defined workloads, whereas agentic systems exhibit dynamic, context-driven, and collaborative behaviors. Agents continuously decompose tasks, shift attention across modalities, and share intermediate results with peers - producing non-deterministic, multi-modal workloads that strain conventional query optimizers and caching mechanisms. We propose an Agent-Centric Data Fabric, a unified architecture that rethinks how data systems serve, optimize, coordinate, and learn from agentic workloads. To achieve this we exploit the concepts of attention-guided data retrieval, semantic micro-caching for context-driven agent federations, predictive data prefetching and quorum-based data serving. Together, these mechanisms enable agents to access representative data faster and more efficiently, while reducing redundant queries, data movement, and inference load across systems. By framing data systems as adaptive collaborators, instead of static executors, we outline new research directions toward behaviorally responsive data infrastructures, where caching, probing, and orchestration jointly enable efficient, context-rich data exchange among dynamic, reasoning-driven agents.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [128] [Motion2Meaning: A Clinician-Centered Framework for Contestable LLM in Parkinson's Disease Gait Interpretation](https://arxiv.org/abs/2512.08934)
*Loc Phuc Truong Nguyen,Hung Thanh Do,Hung Truong Thanh Nguyen,Hung Cao*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: AI-assisted gait analysis holds promise for improving Parkinson's Disease (PD) care, but current clinical dashboards lack transparency and offer no meaningful way for clinicians to interrogate or contest AI decisions. To address this issue, we present Motion2Meaning, a clinician-centered framework that advances Contestable AI through a tightly integrated interface designed for interpretability, oversight, and procedural recourse. Our approach leverages vertical Ground Reaction Force (vGRF) time-series data from wearable sensors as an objective biomarker of PD motor states. The system comprises three key components: a Gait Data Visualization Interface (GDVI), a one-dimensional Convolutional Neural Network (1D-CNN) that predicts Hoehn & Yahr severity stages, and a Contestable Interpretation Interface (CII) that combines our novel Cross-Modal Explanation Discrepancy (XMED) safeguard with a contestable Large Language Model (LLM). Our 1D-CNN achieves 89.0% F1-score on the public PhysioNet gait dataset. XMED successfully identifies model unreliability by detecting a five-fold increase in explanation discrepancies in incorrect predictions (7.45%) compared to correct ones (1.56%), while our LLM-powered interface enables clinicians to validate correct predictions and successfully contest a portion of the model's errors. A human-centered evaluation of this contestable interface reveals a crucial trade-off between the LLM's factual grounding and its readability and responsiveness to clinical feedback. This work demonstrates the feasibility of combining wearable sensor analysis with Explainable AI (XAI) and contestable LLMs to create a transparent, auditable system for PD gait interpretation that maintains clinical oversight while leveraging advanced AI capabilities. Our implementation is publicly available at: https://github.com/hungdothanh/motion2meaning.

</details>


### [129] [From Script to Stage: Automating Experimental Design for Social Simulations with LLMs](https://arxiv.org/abs/2512.08935)
*Yuwei Guo,Zihan Zhao,Deyu Zhou,Xiaowei Liu,Ming Zhang*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rise of large language models (LLMs) has opened new avenues for social science research. Multi-agent simulations powered by LLMs are increasingly becoming a vital approach for exploring complex social phenomena and testing theoretical hypotheses. However, traditional computational experiments often rely heavily on interdisciplinary expertise, involve complex operations, and present high barriers to entry. While LLM-driven agents show great potential for automating experimental design, their reliability and scientific rigor remain insufficient for widespread adoption. To address these challenges, this paper proposes an automated multi-agent experiment design framework based on script generation, inspired by the concept of the Decision Theater. The experimental design process is divided into three stages: (1) Script Generation - a Screenwriter Agent drafts candidate experimental scripts; (2) Script Finalization - a Director Agent evaluates and selects the final script; (3) Actor Generation - an Actor Factory creates actor agents capable of performing on the experimental "stage" according to the finalized script. Extensive experiment conducted across multiple social science experimental scenarios demonstrate that the generated actor agents can perform according to the designed scripts and reproduce outcomes consistent with real-world situations. This framework not only lowers the barriers to experimental design in social science but also provides a novel decision-support tool for policy-making and research. The project's source code is available at: https://anonymous.4open.science/r/FSTS-DE1E

</details>


### [130] [A Principle-based Framework for the Development and Evaluation of Large Language Models for Health and Wellness](https://arxiv.org/abs/2512.08936)
*Brent Winslow,Jacqueline Shreibati,Javier Perez,Hao-Wei Su,Nichole Young-Lin,Nova Hammerquist,Daniel McDuff,Jason Guss,Jenny Vafeiadou,Nick Cain,Alex Lin,Erik Schenck,Shiva Rajagopal,Jia-Ru Chung,Anusha Venkatakrishnan,Amy Armento Lee,Maryam Karimzadehgan,Qingyou Meng,Rythm Agarwal,Aravind Natarajan,Tracy Giest*

Main category: cs.HC

TL;DR: 该研究提出了SHARP原则框架，用于系统性评估个人健康应用中LLM的安全性、准确性等相关问题，并通过Fitbit Insights explorer系统的部署验证了该框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在个人健康应用中虽能提供个性化健康指导，但也存在用户安全、模型准确性和隐私保护等挑战，需要建立系统性的评估框架来解决这些问题。

Method: 开发了基于SHARP（安全、帮助性、准确、相关、个性化）原则的评估框架，结合专家评估、自动评分器和对抗测试等方法，应用于Fitbit Insights explorer系统，并在1.3万用户中进行分阶段部署验证。

Result: 通过框架应用发现了初始测试未察觉的问题，指导了系统针对性改进，证明了技术评估与真实用户反馈结合的必要性。

Conclusion: 建立了负责任开发和部署LLM健康应用的全面可行方法，为标准化的安全有效技术创新提供了方法论支持。

Abstract: The incorporation of generative artificial intelligence into personal health applications presents a transformative opportunity for personalized, data-driven health and fitness guidance, yet also poses challenges related to user safety, model accuracy, and personal privacy. To address these challenges, a novel, principle-based framework was developed and validated for the systematic evaluation of LLMs applied to personal health and wellness. First, the development of the Fitbit Insights explorer, a large language model (LLM)-powered system designed to help users interpret their personal health data, is described. Subsequently, the safety, helpfulness, accuracy, relevance, and personalization (SHARP) principle-based framework is introduced as an end-to-end operational methodology that integrates comprehensive evaluation techniques including human evaluation by generalists and clinical specialists, autorater assessments, and adversarial testing, into an iterative development lifecycle. Through the application of this framework to the Fitbit Insights explorer in a staged deployment involving over 13,000 consented users, challenges not apparent during initial testing were systematically identified. This process guided targeted improvements to the system and demonstrated the necessity of combining isolated technical evaluations with real-world user feedback. Finally, a comprehensive, actionable approach is established for the responsible development and deployment of LLM-powered health applications, providing a standardized methodology to foster innovation while ensuring emerging technologies are safe, effective, and trustworthy for users.

</details>


### [131] [When AI Gives Advice: Evaluating AI and Human Responses to Online Advice-Seeking for Well-Being](https://arxiv.org/abs/2512.08937)
*Harsh Kumar,Jasmine Chahal,Yinuo Zhao,Zeling Zhang,Annika Wei,Louis Tay,Ashton Anderson*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Seeking advice is a core human behavior that the Internet has reinvented twice: first through forums and Q\&A communities that crowdsource public guidance, and now through large language models (LLMs) that deliver private, on-demand counsel at scale. Yet the quality of this synthesized LLM advice remains unclear. How does it compare, not only against arbitrary human comments, but against the wisdom of the online crowd? We conducted two studies (N = 210) in which experts compared top-voted Reddit advice with LLM-generated advice. LLMs ranked significantly higher overall and on effectiveness, warmth, and willingness to seek advice again. GPT-4o beat GPT-5 on all metrics except sycophancy, suggesting that benchmark gains need not improve advice-giving. In our second study, we examined how human and algorithmic advice could be combined, and found that human advice can be unobtrusively polished to compete with AI-generated comments. Finally, to surface user expectations, we ran an exploratory survey with undergraduates (N=148) that revealed heterogeneous, persona-dependent preferences for agent qualities (e.g., coach-like: goal-focused structure; friend-like: warmth and humor). We conclude with design implications for advice-giving agents and ecosystems blending AI, crowd input, and expert oversight.

</details>


### [132] [The Impact of Artificial Intelligence on Strategic Technology Management: A Mixed-Methods Analysis of Resources, Capabilities, and Human-AI Collaboration](https://arxiv.org/abs/2512.08938)
*Massimo Fascinari,Vincent English*

Main category: cs.HC

TL;DR: 本文研究了AI如何有效融入战略技术管理，通过混合方法识别关键成功因素和所需能力，提出了AIbSTM框架，强调人机协同而非AI自主领导


<details>
  <summary>Details</summary>
Motivation: 探索在不确定性环境下AI在战略技术管理中的成功因素，以及组织所需资源与人机交互设计，填补AI背景下资源基础观和认知技术鸿沟的理论空白

Method: 采用定量（230份问卷）和定性（14位专家访谈）混合方法，研究三个核心问题：AI创新STM路线图的因素、组织所需能力、以及复杂STM任务的人机交互设计

Result: 研究显示AI通过数据驱动战略对齐和持续适应改变STM，成功取决于专有数据生态系统、专门人才和治理能力；最可行的路径是以人为中心的增强模式而非AI自主领导

Conclusion: 提出了AIbSTM三层概念框架，扩展了AI背景下的资源基础观，为解决AI采用中的认知和社会技术鸿沟提供理论贡献，并为实践者提供导航整合的框架

Abstract: This paper investigates how artificial intelligence (AI) can be effectively integrated into Strategic Technology Management (STM) practices to enhance the strategic alignment and effectiveness of technology investments. Through a mixed-methods approach combining quantitative survey data (n=230) and qualitative expert interviews (n=14), this study addresses three critical research questions: what success factors AI innovates for STM roadmap formulation under uncertainty; what resources and capabilities organizations require for AI-enhanced STM; and how human-AI interaction should be designed for complex STM tasks. The findings reveal that AI fundamentally transforms STM through data-driven strategic alignment and continuous adaptation, while success depends on cultivating proprietary data ecosystems, specialized human talent, and robust governance capabilities. The study introduces the AI-based Strategic Technology Management (AIbSTM) conceptual framework, which synthesizes technical capabilities with human and organizational dimensions across three layers: strategic alignment, resource-based view, and human-AI interaction. Contrary to visions of autonomous AI leadership, the research demonstrates that the most viable trajectory is human-centric augmentation, where AI serves as a collaborative partner rather than a replacement for human judgment. This work contributes to theory by extending the Resource-Based View to AI contexts and addressing cognitive and socio-technical chasms in AI adoption, while offering practitioners a prescriptive framework for navigating AI integration in strategic technology management.

</details>


### [133] [Assessing the Human-Likeness of LLM-Driven Digital Twins in Simulating Health Care System Trust](https://arxiv.org/abs/2512.08939)
*Yuzhou Wu,Mingyang Wu,Di Liu,Rong Yin,Kang Li*

Main category: cs.HC

TL;DR: LLM驱动的数字孪生在模拟医疗系统不信任等复杂心理特征时存在局限性，虽然能复现主要人口模式，但对教育水平等细小子群差异不敏感。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的人类数字孪生作为新兴工具在医疗系统研究中展现出潜力，但其模拟复杂心理特征（如对医疗系统的不信任）的能力尚不明确，这一研究缺口影响医疗专业人员对AI辅助系统的信任和使用。

Method: 基于Twin-2K-500数据集，使用医疗系统不信任量表（HCSDS），系统评估LLM驱动数字孪生的模拟结果，分析项目级分布、汇总统计和人口亚群模式，并与已建立的人类受试样本进行比较。

Result: 数字孪生的模拟响应显著更加集中、方差更低，极端选项选择更少（所有p<0.001）。虽然在年龄、性别等主要人口模式上能大体复现人类结果，但在捕捉教育水平的细微差异方面敏感性较低。

Conclusion: LLM数字孪生模拟具有模拟群体趋势的潜力，但在对人类细小子群进行详细、特异性区分方面面临挑战。当前在模拟复杂人类态度方面存在局限性，在应用于健康系统工程的推断分析或政策模拟前需要仔细校准和验证。

Abstract: Serving as an emerging and powerful tool, Large Language Model (LLM)-driven Human Digital Twins are showing great potential in healthcare system research. However, its actual simulation ability for complex human psychological traits, such as distrust in the healthcare system, remains unclear. This research gap particularly impacts health professionals' trust and usage of LLM-based Artificial Intelligence (AI) systems in assisting their routine work. In this study, based on the Twin-2K-500 dataset, we systematically evaluated the simulation results of the LLM-driven human digital twin using the Health Care System Distrust Scale (HCSDS) with an established human-subject sample, analyzing item-level distributions, summary statistics, and demographic subgroup patterns. Results showed that the simulated responses by the digital twin were significantly more centralized with lower variance and had fewer selections of extreme options (all p<0.001). While the digital twin broadly reproduces human results in major demographic patterns, such as age and gender, it exhibits relatively low sensitivity in capturing minor differences in education levels. The LLM-based digital twin simulation has the potential to simulate population trends, but it also presents challenges in making detailed, specific distinctions in subgroups of human beings. This study suggests that the current LLM-driven Digital Twins have limitations in modeling complex human attitudes, which require careful calibration and validation before applying them in inferential analyses or policy simulations in health systems engineering. Future studies are necessary to examine the emotional reasoning mechanism of LLMs before their use, particularly for studies that involve simulations sensitive to social topics, such as human-automation trust.

</details>


### [134] [Psychlysis: Towards the Creation of a Questionnaire-based Machine Learning Tool to Analyze States of Mind](https://arxiv.org/abs/2512.08940)
*Hemakshi Jani,Mitish Karia,Meet Gohil,Rahul Bhadja,Aznam Yacoub,Shafaq Khan*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper describes the development of Psychlysis, a work-in-progress questionnaire-based machine learning application analyzing the user's current state of mind and suggesting ways to improve their mood using Machine Learning. The application utilizes the OCEAN model to understand the user's personality traits and make customized suggestions to enhance their well-being. The proposed application focus on improving the user's mood rather than just detecting their emotions. Preliminary results of the model are presented, showing the potential of the application in predicting the user's mood and providing personalized recommendations. The paper concludes by highlighting the potential benefits of such an application for various societal segments, including doctors, individuals, and mental health organizations, in improving emotional well-being and reducing the negative impact of mental health issues on daily life.

</details>


### [135] [One Size Fits None: A Personalized Framework for Urban Accessibility Using Exponential Decay](https://arxiv.org/abs/2512.08941)
*Prabhanjana Ghuriki,S. Chanti,Jossy P George*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This study develops a personalized accessibility framework that integrates exponential decay functions with user-customizable weighting systems. The framework enables real-time, personalized urban evaluation based on individual priorities and lifestyle requirements. The methodology employs grid-based discretization and a two-stage computational architecture that separates intensive preprocessing from lightweight real-time calculations. The computational architecture demonstrates that accessibility modelling can be made accessible to non-technical users through interactive interfaces, enabling fine-grained spatial analysis and identification of accessibility variations within neighbourhoods. The research contributes to Sustainable Development Goal 11's vision of inclusive, sustainable cities by providing tools for understanding how different populations experience identical urban spaces, supporting evidence-based policy development that addresses accessibility gaps.

</details>


### [136] [SimClinician: A Multimodal Simulation Testbed for Reliable Psychologist AI Collaboration in Mental Health Diagnosis](https://arxiv.org/abs/2512.08953)
*Filippo Cenacchi,Longbing Cao,Deborah Richards*

Main category: cs.HC

TL;DR: SimClinician是一个模拟平台，通过整合多模态数据（音频、文本、视线表情）和AI建议的确认步骤，提升心理学家对AI诊断建议的接受度，同时保持较低的升级率。


<details>
  <summary>Details</summary>
Motivation: 当前基于AI的心理健康诊断研究过于关注基准准确性，忽视了实践中心理学家如何响应AI建议（接受、调整或拒绝）这一关键因素。心理健康诊断具有连续性，且受到患者语调、停顿、措辞和非语言行为等多种线索的影响。现有研究很少探究AI诊断界面设计如何影响心理学家的决策，导致在真实研究前缺乏可靠的测试基础。

Method: 提出SimClinician交互式模拟平台，将患者数据转化为心理学家与AI协作诊断的环境。主要贡献包括：(1) 整合音频、文本和视线-表情模式的仪表板；(2) 用于分析去标识化动态的虚拟化身模块；(3) 将AI输出映射到多模态证据的决策层，允许心理学家审查AI推理并输入诊断。基于E-DAIC语料库（276个临床访谈，扩展至480,000次模拟）进行测试。

Result: 测试显示，确认步骤可将心理学家对AI建议的接受度提高23%，同时将升级率保持在9%以下，并维持平稳的交互流程。

Conclusion: SimClinician平台通过多模态整合和明确的AI建议确认机制，有效提升了心理学家对AI诊断建议的接受度，同时控制了升级风险，为心理健康诊断中的人机协作提供了可靠的测试框架。

Abstract: AI based mental health diagnosis is often judged by benchmark accuracy, yet in practice its value depends on how psychologists respond whether they accept, adjust, or reject AI suggestions. Mental health makes this especially challenging: decisions are continuous and shaped by cues in tone, pauses, word choice, and nonverbal behaviors of patients. Current research rarely examines how AI diagnosis interface design influences these choices, leaving little basis for reliable testing before live studies. We present SimClinician, an interactive simulation platform, to transform patient data into psychologist AI collaborative diagnosis. Contributions include: (1) a dashboard integrating audio, text, and gaze-expression patterns; (2) an avatar module rendering de-identified dynamics for analysis; (3) a decision layer that maps AI outputs to multimodal evidence, letting psychologists review AI reasoning, and enter a diagnosis. Tested on the E-DAIC corpus (276 clinical interviews, expanded to 480,000 simulations), SimClinician shows that a confirmation step raises acceptance by 23%, keeping escalations below 9%, and maintaining smooth interaction flow.

</details>


### [137] [PoultryTalk: A Multi-modal Retrieval-Augmented Generation (RAG) System for Intelligent Poultry Management and Decision Support](https://arxiv.org/abs/2512.08995)
*Kapalik Khanal,Biswash Khatiwada,Stephen Afrifa,Ranjan Sapkota,Sanjay Shah,Frank Bai,Ramesh Bahadur Bist*

Main category: cs.HC

TL;DR: 论文提出了 PoultryTalk，一个基于多模态检索增强生成（RAG）的系统，旨在为中小规模家禽养殖户提供实时、准确的疾病诊断、营养规划和管理决策支持。系统通过文本和图像交互，利用 OpenAI 的嵌入模型和 GPT-4o 提供智能建议，并在性能评估中显示出高准确性、低延迟和良好的用户接受度。


<details>
  <summary>Details</summary>
Motivation: 全球家禽产业对粮食安全至关重要，但中小规模养殖户常常难以及时获得专家级的疾病诊断、营养规划和管理决策支持。随着气候压力加剧、饲料价格波动和疾病威胁持续存在，养殖户需要快速、明智的决策工具。因此，急需智能、数据驱动的系统来提供可靠的实时咨询。

Method: 论文提出了 PoultryTalk，一个新颖的多模态检索增强生成（RAG）系统。它利用 OpenAI 的 text-embedding-3-small 和 GPT-4o 模型，通过文本和图像输入提供智能、上下文感知的家禽管理建议。系统通过检索增强生成技术，结合领域知识库，生成准确、相关的回答。

Result: 在技术性能评估中，PoultryTalk 在 200 个专家验证的查询上达到了 84.0% 的语义相似度和平均 3.6 秒的响应延迟。与 OpenAI 的 GPT-4o 相比，PoultryTalk 提供了更准确可靠的家禽相关信息。在用户评估中，34 名参与者提交了 267 个查询，系统响应准确率为 89.9%，约 9.1% 的回答被评级为错误。事后调查显示，95.6% 的参与者认为聊天机器人提供“总是正确”或“大部分正确”的答案，82.6% 表示会推荐该工具，17.4% 回答“可能”。

Conclusion: PoultryTalk 不仅能够提供准确、上下文相关的信息，而且表现出强大的用户接受度和可扩展潜力。该系统为中小规模家禽养殖户提供了一个有效的实时决策支持工具，有望改善家禽产业的疾病管理、营养规划和整体生产效率。

Abstract: The Poultry industry plays a vital role in global food security, yet small- and medium-scale farmers frequently lack timely access to expert-level support for disease diagnosis, nutrition planning, and management decisions. With rising climate stress, unpredictable feed prices, and persistent disease threats, poultry producers often struggle to make quick, informed decisions. Therefore, there is a critical need for intelligent, data-driven systems that can deliver reliable, on-demand consultation. This paper presents PoultryTalk, a novel multi-modal Retrieval-Augmented Generation (RAG) system designed to provide real-time expert guidance through text and image-based interaction. PoultryTalk uses OpenAI's text-embedding-3-small and GPT-4o to provide smart, context-aware poultry management advice from text, images, or questions. System usability and performance were evaluated using 200 expert-verified queries and feedback from 34 participants who submitted 267 queries to the PoultryTalk prototype. The expert-verified benchmark queries confirmed strong technical performance, achieving a semantic similarity of 84.0% and an average response latency of 3.6 seconds. Compared with OpenAI's GPT-4o, PoultryTalk delivered more accurate and reliable information related to poultry. Based on participants' evaluations, PoultryTalk achieved a response accuracy of 89.9%, with about 9.1% of responses rated as incorrect. A post-use survey indicated high user satisfaction: 95.6% of participants reported that the chatbot provided "always correct" and "mostly correct" answers. 82.6% indicated they would recommend the tool, and 17.4% responded "maybe." These results collectively demonstrate that PoultryTalk not only delivers accurate, contextually relevant information but also demonstrates strong user acceptance and scalability potential.

</details>


### [138] [Prototyping and Evaluating a Real-time Neuro-Adaptive Virtual Reality Flight Training System](https://arxiv.org/abs/2512.09014)
*Evy van Weelden,Jos M. Prinsen,Caterina Ceccato,Ethel Pruss,Anita Vrins,Maryam Alimardani,Travis J. Wiltshire,Max M. Louwerse*

Main category: cs.HC

TL;DR: 研究对比了基于脑电图的神经自适应VR飞行训练系统与固定难度序列的效果，结果显示两者在主观测量和飞行性能上无显著差异，但飞行员简报后更倾向于自适应系统。


<details>
  <summary>Details</summary>
Motivation: 飞行训练中实时调整任务难度对于优化飞行员表现和管理工作负荷至关重要，本研究旨在评估基于BCI的神经自适应训练系统在VR飞行模拟中的功能性。

Method: 开发并测试了基于脑电图的神经自适应训练系统，在VR飞行模拟中与固定难度递增序列进行对比，测量主观指标（用户参与度、工作负荷、模拟器眩晕）和客观指标（飞行性能），并通过半结构化访谈收集飞行员体验。

Result: 自适应系统与固定序列在主观测量和飞行性能上无显著差异；两种条件下，飞行性能都随主观工作负荷增加而下降；简报后飞行员更倾向于神经自适应系统，但在难度感知和难度变化顺序方面存在个体差异。

Conclusion: 虽然本研究显示性能无明显改变，但基于BCI的飞行训练系统具有提供更个性化和多样化训练体验的潜力。

Abstract: Real-time adjustments to task difficulty during flight training are crucial for optimizing performance and managing pilot workload. This study evaluated the functionality of a pre-trained brain-computer interface (BCI) that adapts training difficulty based on real-time estimations of workload from brain signals. Specifically, an EEG-based neuro-adaptive training system was developed and tested in Virtual Reality (VR) flight simulations with military student pilots. The neuro-adaptive system was compared to a fixed sequence that progressively increased in difficulty, in terms of self-reported user engagement, workload, and simulator sickness (subjective measures), as well as flight performance (objective metric). Additionally, we explored the relationships between subjective workload and flight performance in the VR simulator for each condition. The experiments concluded with semi-structured interviews to elicit the pilots' experience with the neuro-adaptive prototype. Results revealed no significant differences between the adaptive and fixed sequence conditions in subjective measures or flight performance. In both conditions, flight performance decreased as subjective workload increased. The semi-structured interviews indicated that, upon briefing, the pilots preferred the neuro-adaptive VR training system over the system with a fixed sequence, although individual differences were observed in the perception of difficulty and the order of changes in difficulty. Even though this study shows performance does not change, BCI-based flight training systems hold the potential to provide a more personalized and varied training experience.

</details>


### [139] [Mental Models of Autonomy and Sentience Shape Reactions to AI](https://arxiv.org/abs/2512.09085)
*Janet V. T. Pauketat,Daniel B. Shank,Aikaterina Manoli,Jacy Reese Anthis*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Narratives about artificial intelligence (AI) entangle autonomy, the capacity to self-govern, with sentience, the capacity to sense and feel. AI agents that perform tasks autonomously and companions that recognize and express emotions may activate mental models of autonomy and sentience, respectively, provoking distinct reactions. To examine this possibility, we conducted three pilot studies (N = 374) and four preregistered vignette experiments describing an AI as autonomous, sentient, both, or neither (N = 2,702). Activating a mental model of sentience increased general mind perception (cognition and emotion) and moral consideration more than autonomy, but autonomy increased perceived threat more than sentience. Sentience also increased perceived autonomy more than vice versa. Based on a within-paper meta-analysis, sentience changed reactions more than autonomy on average. By disentangling different mental models of AI, we can study human-AI interaction with more precision to better navigate the detailed design of anthropomorphized AI and prompting interfaces.

</details>


### [140] [Understanding Mental States in Active and Autonomous Driving with EEG](https://arxiv.org/abs/2512.09190)
*Prithila Angkan,Paul Hungler,Ali Etemad*

Main category: cs.HC

TL;DR: 首次基于EEG比较了主动驾驶和自动驾驶模式下驾驶员认知负荷、疲劳、情绪效价和唤醒度的差异，发现两种模式虽然在不同任务复杂度下趋势相似，但心理状态强度和神经激活存在明显差异，表明存在分布偏移


<details>
  <summary>Details</summary>
Motivation: 理解主动驾驶和自动驾驶模式下驾驶员心理状态的差异对于设计安全的人车界面至关重要，需要为下一代自动驾驶监控系统开发特定场景的数据和模型

Method: 使用31名参与者在两种驾驶模式（主动/自动驾驶）和三种不同复杂度任务下的EEG数据，分析时间模式、任务复杂度效应和通道激活差异，并进行迁移学习实验

Result: 两种驾驶模式在认知负荷、疲劳、情绪效价和唤醒度方面存在显著分布偏移，主动驾驶训练模型在自动驾驶上泛化能力差，反之亦然；自动驾驶整体皮层激活较低但仍表现出与干预准备度、任务诱发情绪反应和单调性相关被动疲劳相关的心理状态波动

Conclusion: 由于运动参与和注意力需求的差异导致EEG激活模式不同，需开发针对特定场景的数据和模型来构建下一代自动驾驶驾驶员监控系统

Abstract: Understanding how driver mental states differ between active and autonomous driving is critical for designing safe human-vehicle interfaces. This paper presents the first EEG-based comparison of cognitive load, fatigue, valence, and arousal across the two driving modes. Using data from 31 participants performing identical tasks in both scenarios of three different complexity levels, we analyze temporal patterns, task-complexity effects, and channel-wise activation differences. Our findings show that although both modes evoke similar trends across complexity levels, the intensity of mental states and the underlying neural activation differ substantially, indicating a clear distribution shift between active and autonomous driving. Transfer-learning experiments confirm that models trained on active driving data generalize poorly to autonomous driving and vice versa. We attribute this distribution shift primarily to differences in motor engagement and attentional demands between the two driving modes, which lead to distinct spatial and temporal EEG activation patterns. Although autonomous driving results in lower overall cortical activation, participants continue to exhibit measurable fluctuations in cognitive load, fatigue, valence, and arousal associated with readiness to intervene, task-evoked emotional responses, and monotony-related passive fatigue. These results emphasize the need for scenario-specific data and models when developing next-generation driver monitoring systems for autonomous vehicles.

</details>


### [141] [Advancing Research via Human-AI Interactive Theorem Proving](https://arxiv.org/abs/2512.09443)
*Chenyi Li,Zhijian Lai,Dong An,Jiang Hu,Zaiwen Wen*

Main category: cs.HC

TL;DR: 论文提出了一个结合人类专家与大规模语言模型（LLM）的科学计算研究框架，通过人机协同保持数学严格性，并在流形优化与量子搜索的案例中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 探索如何将LLM作为科学计算的研究工具，同时保持数学严谨性，旨在加速证明探索和算法设计，同时明确人类专家在推理中的责任。

Method: 提出了一个人机协同工作流程：人类专家控制问题表述和可接受假设，LLM负责搜索证明或矛盾、提出候选性质和定理、构建满足约束的结构和参数，并辅以数值实验和简单验证。专家将LLM输出作为原始材料，进一步精炼并组织成精确陈述和严格证明。

Result: 在流形优化与Grover量子搜索算法的案例研究中，该流程帮助识别了不变子空间、探索了Grover兼容的回缩方法，并为基于回缩的梯度方法提供了收敛性保证。

Conclusion: 该框架为将LLM集成到前沿数学研究提供了实用模板，能够在保持透明推理责任的同时，加速证明空间和算法设计的探索。虽然案例聚焦于量子计算中的流形优化问题，但其原则可扩展到科学计算的其他核心领域。

Abstract: We investigate how large language models can be used as research tools in scientific computing while preserving mathematical rigor. We propose a human-in-the-loop workflow for interactive theorem proving and discovery with LLMs. Human experts retain control over problem formulation and admissible assumptions, while the model searches for proofs or contradictions, proposes candidate properties and theorems, and helps construct structures and parameters that satisfy explicit constraints, supported by numerical experiments and simple verification checks. Experts treat these outputs as raw material, further refine them, and organize the results into precise statements and rigorous proofs. We instantiate this workflow in a case study on the connection between manifold optimization and Grover's quantum search algorithm, where the pipeline helps identify invariant subspaces, explore Grover-compatible retractions, and obtain convergence guarantees for the retraction-based gradient method. The framework provides a practical template for integrating large language models into frontier mathematical research, enabling faster exploration of proof space and algorithm design while maintaining transparent reasoning responsibilities. Although illustrated on manifold optimization problems in quantum computing, the principles extend to other core areas of scientific computing.

</details>


### [142] [An Efficient Interaction Human-AI Synergy System Bridging Visual Awareness and Large Language Model for Intensive Care Units](https://arxiv.org/abs/2512.09473)
*Yibowen Zhao,Yiming Cao,Zhiqi Shen,Juan Du,Yonghui Xu,Lizhen Cui,Cyril Leung*

Main category: cs.HC

TL;DR: 设计基于云-边-端架构的视觉感知和语义交互系统，用于ICU数据采集与查询，减少人工错误，提高效率。


<details>
  <summary>Details</summary>
Motivation: 重症监护室目前依赖人工转录数据和碎片化信息系统，存在患者安全风险与操作效率低的问题。

Method: 采用云-边-端分层架构：视觉感知边缘模块非侵入式获取床边监视器实时生理数据；语义交互模块结合大语言模型，支持医生通过语音高效查询结构化患者数据。

Result: 减轻ICU医护人员认知负担，提升系统可扩展性和低延迟通信。

Conclusion: 系统在智能医疗领域具有广泛应用潜力，可改善ICU数据管理与决策支持。

Abstract: Intensive Care Units (ICUs) are critical environments characterized by high-stakes monitoring and complex data management. However, current practices often rely on manual data transcription and fragmented information systems, introducing potential risks to patient safety and operational efficiency. To address these issues, we propose a human-AI synergy system based on a cloud-edge-end architecture, which integrates visual-aware data extraction and semantic interaction mechanisms. Specifically, a visual-aware edge module non-invasively captures real-time physiological data from bedside monitors, reducing manual entry errors. To improve accessibility to fragmented data sources, a semantic interaction module, powered by a Large Language Model (LLM), enables physicians to perform efficient and intuitive voice-based queries over structured patient data. The hierarchical cloud-edge-end deployment ensures low-latency communication and scalable system performance. Our system reduces the cognitive burden on ICU nurses and physicians and demonstrates promising potential for broader applications in intelligent healthcare systems.

</details>


### [143] [Exploring Community-Powered Conversational Agent for Health Knowledge Acquisition: A Case Study in Colorectal Cancer](https://arxiv.org/abs/2512.09511)
*Yiwei Yuan,Zhiqing Wang,Xiucheng Zhang,Yichao Luo,Shuya Lin,Yang Bai,Zhenhui Peng*

Main category: cs.HC

TL;DR: 开发了一个将在线社区内容整合到对话助手CanAnswer中的工作流，用于促进健康知识学习，通过结直肠癌案例研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在线社区是年轻人获取和分享健康知识的重要平台，但用户在浏览时面临内容碎片化、信息质量参差不齐、术语陌生等挑战，需要更好的学习工具。

Method: 通过对56名参与者的调查和跟进访谈确定了学习健康知识的挑战和期望功能；开发了一个将社区内容整合到对话助手CanAnswer中的计算工作流；利用结直肠癌作为案例研究，通过24名参与者的实验室研究和6名医学专家访谈进行评估。

Result: CanAnswer提高了参与者回忆获得的知识并减少了学习任务的工作量；专家访谈进一步确认了CanAnswer的可靠性和实用性。

Conclusion: CanAnswer在促进健康知识学习方面具有实用性，论文讨论了其通用性，并为增强社区驱动学习工具的有用性和可信度提供了设计考虑。

Abstract: Online communities have become key platforms where young adults, actively seek and share information, including health knowledge. However, these users often face challenges when browsing these communities, such as fragmented content, varying information quality and unfamiliar terminology. Based on a survey with 56 participants and follow-up interviews, we identify common challenges and expected features for learning health knowledge. In this paper, we develop a computational workflow that integrates community content into a conversational agent named CanAnswer to facilitate health knowledge acquisition. Using colorectal cancer as a case study, we evaluate CanAnswer through a lab study with 24 participants and interviews with six medical experts. Results show that CanAnswer improves the recalled gained knowledge and reduces the task workload of the learning session. Our expert interviews (N=6) further confirm the reliability and usefulness of CanAnswer. We discuss the generality of CanAnswer and provide design considerations for enhancing the usefulness and credibility of community-powered learning tools.

</details>


### [144] [Auto-BenchmarkCard: Automated Synthesis of Benchmark Documentation](https://arxiv.org/abs/2512.09577)
*Aris Hofmann,Inge Vejsbjerg,Dhaval Salwala,Elizabeth M. Daly*

Main category: cs.HC

TL;DR: Auto-BenchmarkCard通过多智能体数据提取和LLM驱动合成生成验证的AI基准测试描述，提高基准测试的透明度和可比性。


<details>
  <summary>Details</summary>
Motivation: AI基准测试文档常常不完整或不一致，导致跨任务或跨领域基准测试难以解释和比较。

Method: 结合来自Hugging Face、Unitxt、学术论文等异构来源的多智能体数据提取与LLM驱动合成，采用FactReasoner工具通过原子蕴含评分进行事实准确性验证。

Result: 该工作流程能够生成验证过的基准测试描述，有望提高AI基准测试报告的透明度、可比性和可重用性。

Conclusion: Auto-BenchmarkCard工作流程有助于研究人员和从业者更好地理解和评估基准测试选择，推动AI基准测试的标准化和透明度。

Abstract: We present Auto-BenchmarkCard, a workflow for generating validated descriptions of AI benchmarks. Benchmark documentation is often incomplete or inconsistent, making it difficult to interpret and compare benchmarks across tasks or domains. Auto-BenchmarkCard addresses this gap by combining multi-agent data extraction from heterogeneous sources (e.g., Hugging Face, Unitxt, academic papers) with LLM-driven synthesis. A validation phase evaluates factual accuracy through atomic entailment scoring using the FactReasoner tool. This workflow has the potential to promote transparency, comparability, and reusability in AI benchmark reporting, enabling researchers and practitioners to better navigate and evaluate benchmark choices.

</details>


### [145] [ImageTalk: Designing a Multimodal AAC Text Generation System Driven by Image Recognition and Natural Language Generation](https://arxiv.org/abs/2512.09610)
*Boyin Yang,Puming Jiang,Per Ola Kristensson*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: People living with Motor Neuron Disease (plwMND) frequently encounter speech and motor impairments that necessitate a reliance on augmentative and alternative communication (AAC) systems. This paper tackles the main challenge that traditional symbol-based AAC systems offer a limited vocabulary, while text entry solutions tend to exhibit low communication rates. To help plwMND articulate their needs about the system efficiently and effectively, we iteratively design and develop a novel multimodal text generation system called ImageTalk through a tailored proxy-user-based and an end-user-based design phase. The system demonstrates pronounced keystroke savings of 95.6%, coupled with consistent performance and high user satisfaction. We distill three design guidelines for AI-assisted text generation systems design and outline four user requirement levels tailored for AAC purposes, guiding future research in this field.

</details>


### [146] [Smart, simple, sincere - Why and how we should rethink connected things in our smart homes](https://arxiv.org/abs/2512.09755)
*Albrecht Kurze,Andreas Bischof,Arne Berger*

Main category: cs.HC

TL;DR: 智能家居设备中的简单传感器会带来严重的隐私风险，但这些风险往往被用户和开发者忽视。


<details>
  <summary>Details</summary>
Motivation: 智能连接设备和服务的普及带来了便利，但其中的简单传感器（如温度、光照、湿度传感器）可能被用于推断家庭出席情况、家庭活动甚至健康状况，造成隐私风险。用户和开发者通常对此缺乏认识或不知如何应对。

Method: 提出了一种重新思考智能家居连接设备和服务的理念，并通过ThingsCon社区的具体研究项目展示了相关方法和途径。

Result: 文章认为并非所有情况都是消极的，而是提出了如何在保护隐私的前提下利用智能传感器的可能性。

Conclusion: 需要通过社区合作重新思考智能家居设备的设计和使用，在享受技术便利的同时有效管理隐私风险。

Abstract: More and more smart connected things and services turn our homes into smart environments. They promise comfort, efficiency and security. These devices often integrate simple sensors, e.g. for temperature, light or humidity, etc. However, these smart but yet simple sensors can pose a sincere privacy risk. The sensor data enables sense-making of home attendance, domestic activities and even health conditions, often a fact that neither users nor developers are aware of or do not know how to address. Nevertheless, not all is lost or evil. This article makes a plea for how we, the ThingsCon community, might rethink smart connected things and services in our homes. We show this in our approaches and research projects that we initiated.

</details>


### [147] [Building a Data Dashboard for Magic: The Gathering: Initial Design Considerations](https://arxiv.org/abs/2512.09802)
*Tomás Alves,João Moreira*

Main category: cs.HC

TL;DR: 本文为《万智牌》指挥官模式设计可视化仪表板的初步研究，通过用户任务分析确定需求，设计可视化解决方案，并进行用户测试。结果表明指挥官玩家偏好上下文相关的结果导向指标，传统图表（热力图、折线图）比复杂图表更易懂，同时强调局部视图、用户定制和渐进式展示的重要性。


<details>
  <summary>Details</summary>
Motivation: 针对《万智牌》指挥官模式的玩法数据分析需求，现有通用仪表板缺乏对该特定格式的针对性支持。为满足指挥官玩家在卡组分析、策略优化等方面的特定需求，需要设计专为该格式定制的可视化仪表板。

Method: 1）进行用户任务分析，识别指挥官格式的数据可视化需求；2）基于分析结果设计专属仪表板，利用可视化技术解决玩家的典型数据分析痛点；3）开展结构化用户测试，评估玩家对不同可视化图表的理解程度和偏好。

Result: 玩家更关注与上下文相关的结果驱动型指标而非外围数据；传统图表（热力图、折线图）的理解度显著高于复杂图表（散点图、冰柱图）；局部视图、用户定制化和渐进式展示对用户体验至关重要；适应性和上下文相关性与数据准确性同等重要。

Conclusion: 研究为游戏场景下的数据可视化提供了实用设计指南：应以玩家需求为中心，优先使用传统易懂的可视化形式，强调仪表板的适应性、上下文相关性和用户可控性。这些发现对增强用户参与度的仪表板设计具有广泛参考价值。

Abstract: This paper presents the initial stages of a design study aimed at developing a dashboard to visualize gameplay data of the Commander format from Magic: The Gathering. We conducted a user-task analysis to identify requirements for a data visualization dashboard tailored to the Commander format. Afterwards, we proposed a design for the dashboard leveraging visualizations to address players' needs and pain points for typical data analysis tasks in the context domain. Then, we followed-up with a structured user test to evaluate players' comprehension and preferences of data visualizations. Results show that players prioritize contextually relevant, outcome-driven metrics over peripheral ones, and that canonical charts like heatmaps and line charts support higher comprehension than complex ones such as scatterplots or icicle plots. Our findings also highlight the importance of localized views, user customization, and progressive disclosure, emphasizing that adaptability and contextual relevance are as essential as accuracy in effective dashboard design. Our study contributes practical design guidelines for data visualization in gaming contexts and highlights broader implications for engagement-driven dashboards.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [148] [Calibrated Trust in Dealing with LLM Hallucinations: A Qualitative Study](https://arxiv.org/abs/2512.09088)
*Adrian Ryser,Florian Allwein,Tim Schlippe*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Hallucinations are outputs by Large Language Models (LLMs) that are factually incorrect yet appear plausible [1]. This paper investigates how such hallucinations influence users' trust in LLMs and users' interaction with LLMs. To explore this in everyday use, we conducted a qualitative study with 192 participants. Our findings show that hallucinations do not result in blanket mistrust but instead lead to context-sensitive trust calibration. Building on the calibrated trust model by Lee & See [2] and Afroogh et al.'s trust-related factors [3], we confirm expectancy [3], [4], prior experience [3], [4], [5], and user expertise & domain knowledge [3], [4] as userrelated (human) trust factors, and identify intuition as an additional factor relevant for hallucination detection. Additionally, we found that trust dynamics are further influenced by contextual factors, particularly perceived risk [3] and decision stakes [6]. Consequently, we validate the recursive trust calibration process proposed by Blöbaum [7] and extend it by including intuition as a user-related trust factor. Based on these insights, we propose practical recommendations for responsible and reflective LLM use.

</details>


### [149] [AI TIPS 2.0: A Comprehensive Framework for Operationalizing AI Governance](https://arxiv.org/abs/2512.09114)
*Pamela Gupta*

Main category: cs.AI

TL;DR: 现有AI治理框架存在三大缺陷：用例风险分析不足、标准过于概念化难以落地、规模化操作机制缺失。本文提出AI TIPS 2.0框架来系统解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI治理框架无法有效应对实际部署挑战：组织缺乏针对具体用例的风险评估能力（如Humana诉讼案中的医疗拒赔问题）；ISO 42001等标准停留在概念层面难以转化为具体控制措施；缺少规模化实施可信AI的全流程机制。

Method: 提出AI TIPS（人工智能可信集成支柱）2.0框架，这是对2019年原始框架的更新，比NIST AI风险治理框架早四年推出。该框架通过结构化方法将治理要求转化为可操作控制，实现全生命周期嵌入。

Result: 该框架直接应对三大挑战：提供基于用例的定制化风险评估方法，将概念化标准转化为具体技术实现，建立从董事会到数据科学家的全角色可视化规模化操作机制。

Conclusion: AI TIPS 2.0为组织提供了系统化实施AI治理的操作性框架，填补了现有标准在用例风险管理、可操作控制和规模化实施方面的关键空白。

Abstract: The deployment of AI systems faces three critical governance challenges that current frameworks fail to adequately address. First, organizations struggle with inadequate risk assessment at the use case level, exemplified by the Humana class action lawsuit and other high impact cases where an AI system deployed to production exhibited both significant bias and high error rates, resulting in improper healthcare claim denials. Each AI use case presents unique risk profiles requiring tailored governance, yet most frameworks provide one size fits all guidance. Second, existing frameworks like ISO 42001 and NIST AI RMF remain at high conceptual levels, offering principles without actionable controls, leaving practitioners unable to translate governance requirements into specific technical implementations. Third, organizations lack mechanisms for operationalizing governance at scale, with no systematic approach to embed trustworthy AI practices throughout the development lifecycle, measure compliance quantitatively, or provide role-appropriate visibility from boards to data scientists. We present AI TIPS, Artificial Intelligence Trust-Integrated Pillars for Sustainability 2.0, update to the comprehensive operational framework developed in 2019,four years before NIST's AI Risk Management Framework, that directly addresses these challenges.

</details>


### [150] [A Categorical Analysis of Large Language Models and Why LLMs Circumvent the Symbol Grounding Problem](https://arxiv.org/abs/2512.09117)
*Luciano Floridi,Yiyang Jia,Fernando Tohmé*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper presents a formal, categorical framework for analysing how humans and large language models (LLMs) transform content into truth-evaluated propositions about a state space of possible worlds W , in order to argue that LLMs do not solve but circumvent the symbol grounding problem.

</details>


### [151] [SDialog: A Python Toolkit for End-to-End Agent Building, User Simulation, Dialog Generation, and Evaluation](https://arxiv.org/abs/2512.09142)
*Sergio Burdisso,Séverin Baroudi,Yanis Labrak,David Grunert,Pawel Cyrta,Yiyang Chen,Srikanth Madikeri,Esaú Villatoro-Tello,Thomas Schaaf,Ricard Marxer,Petr Motlicek*

Main category: cs.AI

TL;DR: SDialog是一个开源的Python工具箱，用于构建和分析基于LLM的对话系统，集成了对话生成、评估和可解释性三大功能。


<details>
  <summary>Details</summary>
Motivation: 为研究者提供一个统一的端到端框架，使他们能够系统地构建、评估和理解基于大型语言模型的对话系统，解决现有工具在生成、评估和可解释性分离的问题。

Method: 围绕标准化的对话表示构建，提供1) 基于角色的多智能体模拟，2) 语言指标、LLM作评委和功能正确性验证的综合评估，3) 通过特征消融和诱导进行激活检查和转向的机理解释工具，4) 包含3D房间建模和麦克风效果的全声学模拟的音频生成。

Result: 该工具箱集成了所有主要的LLM后端，实现了统一的API下混合后端实验。

Conclusion: 通过在对话为中心的架构中耦合生成、评估和可解释性，SDialog使研究人员能够更系统地构建、基准测试和理解对话系统。

Abstract: We present SDialog, an MIT-licensed open-source Python toolkit that unifies dialog generation, evaluation and mechanistic interpretability into a single end-to-end framework for building and analyzing LLM-based conversational agents. Built around a standardized \texttt{Dialog} representation, SDialog provides: (1) persona-driven multi-agent simulation with composable orchestration for controlled, synthetic dialog generation, (2) comprehensive evaluation combining linguistic metrics, LLM-as-a-judge and functional correctness validators, (3) mechanistic interpretability tools for activation inspection and steering via feature ablation and induction, and (4) audio generation with full acoustic simulation including 3D room modeling and microphone effects. The toolkit integrates with all major LLM backends, enabling mixed-backend experiments under a unified API. By coupling generation, evaluation, and interpretability in a dialog-centric architecture, SDialog enables researchers to build, benchmark and understand conversational systems more systematically.

</details>


### [152] [Toward Closed-loop Molecular Discovery via Language Model, Property Alignment and Strategic Search](https://arxiv.org/abs/2512.09566)
*Junkai Ji,Zhangfan Yang,Dong Xu,Ruibin Bai,Jianqiang Li,Tingjun Hou,Zexuan Zhu*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Drug discovery is a time-consuming and expensive process, with traditional high-throughput and docking-based virtual screening hampered by low success rates and limited scalability. Recent advances in generative modelling, including autoregressive, diffusion, and flow-based approaches, have enabled de novo ligand design beyond the limits of enumerative screening. Yet these models often suffer from inadequate generalization, limited interpretability, and an overemphasis on binding affinity at the expense of key pharmacological properties, thereby restricting their translational utility. Here we present Trio, a molecular generation framework integrating fragment-based molecular language modeling, reinforcement learning, and Monte Carlo tree search, for effective and interpretable closed-loop targeted molecular design. Through the three key components, Trio enables context-aware fragment assembly, enforces physicochemical and synthetic feasibility, and guides a balanced search between the exploration of novel chemotypes and the exploitation of promising intermediates within protein binding pockets. Experimental results show that Trio reliably achieves chemically valid and pharmacologically enhanced ligands, outperforming state-of-the-art approaches with improved binding affinity (+7.85%), drug-likeness (+11.10%) and synthetic accessibility (+12.05%), while expanding molecular diversity more than fourfold.

</details>


### [153] [Gaussian Process Aggregation for Root-Parallel Monte Carlo Tree Search with Continuous Actions](https://arxiv.org/abs/2512.09727)
*Junlin Xiao,Victor-Alexandru Darvariu,Bruno Lacerda,Nick Hawes*

Main category: cs.AI

TL;DR: 提出一种在连续动作空间中使用高斯过程回归聚合多线程统计量的MCTS改进方法，在6个领域测试中优于现有策略且推理时间增加有限。


<details>
  <summary>Details</summary>
Motivation: 在线规划中MCTS是基石算法，在连续动作空间中如何最佳聚合不同线程的统计数据是一个重要但未被充分探索的问题。

Method: 使用高斯过程回归获取在环境中未尝试但有前景的动作的价值估计，将其应用于根并行MCTS的统计数据聚合。

Result: 在6个不同领域进行了系统评估，证明该方法优于现有聚合策略，且仅需适度的推理时间增加。

Conclusion: 提出的基于高斯过程回归的统计聚合方法能有效提升连续动作空间中根并行MCTS的性能，为这类问题提供了有效的解决方案。

Abstract: Monte Carlo Tree Search is a cornerstone algorithm for online planning, and its root-parallel variant is widely used when wall clock time is limited but best performance is desired. In environments with continuous action spaces, how to best aggregate statistics from different threads is an important yet underexplored question. In this work, we introduce a method that uses Gaussian Process Regression to obtain value estimates for promising actions that were not trialed in the environment. We perform a systematic evaluation across 6 different domains, demonstrating that our approach outperforms existing aggregation strategies while requiring a modest increase in inference time.

</details>


### [154] [RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning](https://arxiv.org/abs/2512.09829)
*Khurram Khalil,Muhammad Mahad Khaliq,Khaza Anuarul Hoque*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The massive scale of modern AI accelerators presents critical challenges to traditional fault assessment methodologies, which face prohibitive computational costs and provide poor coverage of critical failure modes. This paper introduces RIFT (Reinforcement Learning-guided Intelligent Fault Targeting), a scalable framework that automates the discovery of minimal, high-impact fault scenarios for efficient design-time fault assessment. RIFT transforms the complex search for worst-case faults into a sequential decision-making problem, combining hybrid sensitivity analysis for search space pruning with reinforcement learning to intelligently generate minimal, high-impact test suites. Evaluated on billion-parameter Large Language Model (LLM) workloads using NVIDIA A100 GPUs, RIFT achieves a \textbf{2.2$\times$} fault assessment speedup over evolutionary methods and reduces the required test vector volume by over \textbf{99\%} compared to random fault injection, all while achieving \textbf{superior fault coverage}. The proposed framework also provides actionable data to enable intelligent hardware protection strategies, demonstrating that RIFT-guided selective error correction code provides a \textbf{12.8$\times$} improvement in \textbf{cost-effectiveness} (coverage per unit area) compared to uniform triple modular redundancy protection. RIFT automatically generates UVM-compliant verification artifacts, ensuring its findings are directly actionable and integrable into commercial RTL verification workflows.

</details>


### [155] [Human-in-the-Loop and AI: Crowdsourcing Metadata Vocabulary for Materials Science](https://arxiv.org/abs/2512.09895)
*Jane Greenberg,Scott McClellan,Addy Ireland,Robert Sammarco,Colton Gerber,Christopher B. Rauch,Mat Kelly,John Kunze,Yuan An,Eric Toberer*

Main category: cs.AI

TL;DR: MatSci-YAMZ是一个结合人工智能与人工参与的元数据词汇开发平台，在材料科学领域进行了概念验证，展示了AI-人机协同方法在减少共识构建时间、增强语义透明度方面的潜力。


<details>
  <summary>Details</summary>
Motivation: FAIR和FARR数据原则所需的元数据词汇开发面临人力资源有限和标准化实践不一致的挑战。

Method: 开发了整合人工智能和人在环路（包括众包）的MatSci-YAMZ平台，在材料科学领域进行了概念验证研究，6名参与者通过提供术语定义和示例来优化AI生成的定义。

Result: 成功生成了19个AI定义，迭代反馈循环证明了AI-人在环路方法的可行性，研究确认了概念验证成功、符合FAIR和开放科学原则、制定了未来研究协议，并展示了跨领域扩展潜力。

Conclusion: MatSci-YAMZ模型能够增强语义透明度，显著减少元数据词汇开发中的共识构建时间，为跨学科领域的元数据标准化提供了可扩展的解决方案。

Abstract: Metadata vocabularies are essential for advancing FAIR and FARR data principles, but their development constrained by limited human resources and inconsistent standardization practices. This paper introduces MatSci-YAMZ, a platform that integrates artificial intelligence (AI) and human-in-the-loop (HILT), including crowdsourcing, to support metadata vocabulary development. The paper reports on a proof-of-concept use case evaluating the AI-HILT model in materials science, a highly interdisciplinary domain Six (6) participants affiliated with the NSF Institute for Data-Driven Dynamical Design (ID4) engaged with the MatSci-YAMZ plaform over several weeks, contributing term definitions and providing examples to prompt the AI-definitions refinement. Nineteen (19) AI-generated definitions were successfully created, with iterative feedback loops demonstrating the feasibility of AI-HILT refinement. Findings confirm the feasibility AI-HILT model highlighting 1) a successful proof of concept, 2) alignment with FAIR and open-science principles, 3) a research protocol to guide future studies, and 4) the potential for scalability across domains. Overall, MatSci-YAMZ's underlying model has the capacity to enhance semantic transparency and reduce time required for consensus building and metadata vocabulary development.

</details>


### [156] [SCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments](https://arxiv.org/abs/2512.09897)
*Haoye Lu,Pavan Seshadri,Kaheer Suleman*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Long-term planning in complex, text-based environments presents significant challenges due to open-ended action spaces, ambiguous observations, and sparse feedback. Recent research suggests that large language models (LLMs) encode rich semantic knowledge about the world, which can be valuable for guiding agents in high-level reasoning and planning across both embodied and purely textual settings. However, existing approaches often depend heavily on querying LLMs during training and inference, making them computationally expensive and difficult to deploy efficiently. In addition, these methods typically employ a pretrained, unaltered LLM whose parameters remain fixed throughout training, providing no opportunity for adaptation to the target task. To address these limitations, we introduce SCOPE (Subgoal-COnditioned Pretraining for Efficient planning), a one-shot hierarchical planner that leverages LLM-generated subgoals only at initialization to pretrain a lightweight student model. Unlike prior approaches that distill LLM knowledge by repeatedly prompting the model to adaptively generate subgoals during training, our method derives subgoals directly from example trajectories. This design removes the need for repeated LLM queries, significantly improving efficiency, though at the cost of reduced explainability and potentially suboptimal subgoals. Despite their suboptimality, our results on the TextCraft environment show that LLM-generated subgoals can still serve as a strong starting point for hierarchical goal decomposition in text-based planning tasks. Compared to the LLM-based hierarchical agent ADaPT (Prasad et al., 2024), which achieves a 0.52 success rate, our method reaches 0.56 and reduces inference time from 164.4 seconds to just 3.0 seconds.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [157] [Optimizing Algorithms for Mobile Health Interventions with Active Querying Optimization](https://arxiv.org/abs/2512.08950)
*Aseel Rawashdeh*

Main category: cs.LG

TL;DR: 本文提出了一种贝叶斯扩展的ATM算法，在移动健康干预中通过卡尔曼滤波器式贝叶斯更新替代标准Q-learning，提高了稀疏噪声环境下的学习稳定性和样本效率。


<details>
  <summary>Details</summary>
Motivation: 移动健康干预中的强化学习需要在干预效果和用户负担之间取得平衡，特别是在状态测量成本高昂的情况下。标准ATM算法使用的Q-learning方法在稀疏噪声环境中容易不稳定，需要更稳健的替代方案。

Method: 提出贝叶斯ATM算法，在ACNO-MDP框架下，用卡尔曼滤波器风格的贝叶斯更新替代标准Q-learning，保持Q值的不确定性感知估计，实现更稳定和样本高效的学习。

Result: 在小规模表格环境中，贝叶斯ATM获得可比或改进的标量回报，方差显著降低，策略行为更稳定。但在更大更复杂的移动健康设置中，标准ATM和贝叶斯ATM都表现不佳。

Conclusion: 不确定性感知方法在低数据环境下有价值，但需要新的强化学习算法来显式建模因果结构、连续状态和观测成本约束下的延迟反馈。

Abstract: Reinforcement learning in mobile health (mHealth) interventions requires balancing intervention efficacy with user burden, particularly when state measurements (for example, user surveys or feedback) are costly yet essential. The Act-Then-Measure (ATM) heuristic addresses this challenge by decoupling control and measurement actions within the Action-Contingent Noiselessly Observable Markov Decision Process (ACNO-MDP) framework. However, the standard ATM algorithm relies on a temporal-difference-inspired Q-learning method, which is prone to instability in sparse and noisy environments. In this work, we propose a Bayesian extension to ATM that replaces standard Q-learning with a Kalman filter-style Bayesian update, maintaining uncertainty-aware estimates of Q-values and enabling more stable and sample-efficient learning. We evaluate our method in both toy environments and clinically motivated testbeds. In small, tabular environments, Bayesian ATM achieves comparable or improved scalarized returns with substantially lower variance and more stable policy behavior. In contrast, in larger and more complex mHealth settings, both the standard and Bayesian ATM variants perform poorly, suggesting a mismatch between ATM's modeling assumptions and the structural challenges of real-world mHealth domains. These findings highlight the value of uncertainty-aware methods in low-data settings while underscoring the need for new RL algorithms that explicitly model causal structure, continuous states, and delayed feedback under observation cost constraints.

</details>


### [158] [Learning When to Ask: Simulation-Trained Humanoids for Mental-Health Diagnosis](https://arxiv.org/abs/2512.08952)
*Filippo Cenacchi,Deborah Richards,Longbing Cao*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Testing humanoid robots with users is slow, causes wear, and limits iteration and diversity. Yet screening agents must master conversational timing, prosody, backchannels, and what to attend to in faces and speech for Depression and PTSD. Most simulators omit policy learning with nonverbal dynamics; many controllers chase task accuracy while underweighting trust, pacing, and rapport. We virtualise the humanoid as a conversational agent to train without hardware burden. Our agent-centred, simulation-first pipeline turns interview data into 276 Unreal Engine MetaHuman patients with synchronised speech, gaze/face, and head-torso poses, plus PHQ-8 and PCL-C flows. A perception-fusion-policy loop decides what and when to speak, when to backchannel, and how to avoid interruptions, under a safety shield. Training uses counterfactual replay (bounded nonverbal perturbations) and an uncertainty-aware turn manager that probes to reduce diagnostic ambiguity. Results are simulation-only; the humanoid is the transfer target. In comparing three controllers, a custom TD3 (Twin Delayed DDPG) outperformed PPO and CEM, achieving near-ceiling coverage with steadier pace at comparable rewards. Decision-quality analyses show negligible turn overlap, aligned cut timing, fewer clarification prompts, and shorter waits. Performance stays stable under modality dropout and a renderer swap, and rankings hold on a held-out patient split. Contributions: (1) an agent-centred simulator that turns interviews into 276 interactive patients with bounded nonverbal counterfactuals; (2) a safe learning loop that treats timing and rapport as first-class control variables; (3) a comparative study (TD3 vs PPO/CEM) with clear gains in completeness and social timing; and (4) ablations and robustness analyses explaining the gains and enabling clinician-supervised humanoid pilots.

</details>


### [159] [An Electrocardiogram Multi-task Benchmark with Comprehensive Evaluations and Insightful Findings](https://arxiv.org/abs/2512.08954)
*Yuhao Xu,Jiaying Lu,Sirui Ding,Defu Cao,Xiao Hu,Carl Yang*

Main category: cs.LG

TL;DR: 该研究系统评估了基础模型在ECG分析中的有效性，发现通用时间序列/ECG基础模型能达到80%的顶级准确率，为生理波形分析的未来发展提供了重要见解


<details>
  <summary>Details</summary>
Motivation: 心电图（ECG）作为无创诊断心脏状况的重要工具，传统分析需要领域专业知识。随着自监督学习和基础模型的发展，人工智能系统可以无需完全依赖人类专家知识。但目前缺乏对基础模型在ECG分析性能的全面评估

Method: 通过比较语言/通用时间序列/ECG基础模型与时间序列深度学习模型，系统评估基础模型在ECG分析任务中的表现。研究提供了基准测试框架和相关代码公开资源

Result: 实验结果表明，通用时间序列/ECG基础模型的最高准确率达到80%，在ECG分析中表现出色。研究提供了深入的性能分析和对模型局限性的洞察

Conclusion: 基础模型在ECG分析中具有显著潜力，但仍存在局限性。该研究为推进生理波形分析提供了重要基准，指出基础模型在医疗AI领域的应用前景和发展方向

Abstract: In the process of patient diagnosis, non-invasive measurements are widely used due to their low risks and quick results. Electrocardiogram (ECG), as a non-invasive method to collect heart activities, is used to diagnose cardiac conditions. Analyzing the ECG typically requires domain expertise, which is a roadblock to applying artificial intelligence (AI) for healthcare. Through advances in self-supervised learning and foundation models, AI systems can now acquire and leverage domain knowledge without relying solely on human expertise. However, there is a lack of comprehensive analyses over the foundation models' performance on ECG. This study aims to answer the research question: "Are Foundation Models Useful for ECG Analysis?" To address it, we evaluate language/general time-series/ECG foundation models in comparison with time-series deep learning models. The experimental results show that general time-series/ECG foundation models achieve a top performance rate of 80%, indicating their effectiveness in ECG analysis. In-depth analyses and insights are provided along with comprehensive experimental results. This study highlights the limitations and potential of foundation models in advancing physiological waveform analysis. The data and code for this benchmark are publicly available at https://github.com/yuhaoxu99/ECGMultitasks-Benchmark.

</details>


### [160] [DW-KNN: A Transparent Local Classifier Integrating Distance Consistency and Neighbor Reliability](https://arxiv.org/abs/2512.08956)
*Kumarjit Pathak,Karthik K,Sachin Madan,Jitin Kapila*

Main category: cs.LG

TL;DR: 该研究提出了DW-KNN（双重加权KNN），通过集成指数距离与邻居有效性权重，解决传统KNN假设所有邻居同等可靠的局限性，在异构特征空间中提升预测可靠性。


<details>
  <summary>Details</summary>
Motivation: 标准的距离加权KNN及其变体假设所有'k'个邻居同等可靠，这在异构特征空间中成为一个限制因素，影响预测真实观测水平的可靠性。

Method: 提出DW-KNN透明鲁棒变体，集成指数距离与邻居有效性，实现实例级可解释性，抑制噪声或错误标记样本，并减少超参数敏感性。

Result: 在9个数据集上的综合评估显示，DW-KNN平均准确率达到0.8988，在六种方法中排名第二，与表现最佳的Ensemble KNN相差不到0.2%。同时表现出最低的交叉验证方差（0.0156），表明预测稳定性可靠。统计显著性测试确认比紧凑加权KNN（+4.09%）和核加权KNN（+1.13%）有显著改进（p<0.001）。

Conclusion: 该方法为复杂自适应方案提供了一个简单而有效的替代方案，特别适用于需要可解释预测的高风险应用场景。

Abstract: K-Nearest Neighbors (KNN) is one of the most used ML classifiers. However, if we observe closely, standard distance-weighted KNN and relative variants assume all 'k' neighbors are equally reliable. In heterogeneous feature space, this becomes a limitation that hinders reliability in predicting true levels of the observation.
  We propose DW-KNN (Double Weighted KNN), a transparent and robust variant that integrates exponential distance with neighbor validity. This enables instance-level interpretability, suppresses noisy or mislabeled samples, and reduces hyperparameter sensitivity.
  Comprehensive evaluation on 9 data-sets helps to demonstrate that DW-KNN achieves 0.8988 accuracy on average. It ranks 2nd among six methods and within 0.2% of the best-performing Ensemble KNN. It also exhibits the lowest cross-validation variance (0.0156), indicating reliable prediction stability. Statistical significance test confirmed ($p < 0.001$) improvement over compactness weighted KNN (+4.09\%) and Kernel weighted KNN (+1.13\%). The method provides a simple yet effective alternative to complex adaptive schemes, particularly valuable for high-stakes applications requiring explainable predictions.

</details>


### [161] [LUMOS: Large User MOdels for User Behavior Prediction](https://arxiv.org/abs/2512.08957)
*Dhruv Nigam*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: User behavior prediction at scale remains a critical challenge for online B2C platforms. Traditional approaches rely heavily on task-specific models and domain-specific feature engineering. This is time-consuming, computationally expensive, and requires domain expertise and therefore not scalable. We present LUMOS (Large User MOdel Series), a transformer-based architecture that eliminates task-specific models and manual feature engineering by learning multiple tasks jointly using only raw user activity data. LUMOS introduces a novel cross-attention mechanism that conditions predictions on future known events (e.g., holidays, sales, etc.), enabling the model to predict complex behaviour patterns like "how will upcoming holidays affect user engagement?" The architecture also employs multi-modal tokenization, combining user transactions, event context, and static user demographic attributes into rich representations processed through specialized embedding pathways.
  Through extensive experiments on a production dataset spanning 275 billion user activity tokens from 250 million users, we demonstrate that LUMOS achieves superior performance compared to traditional task-specific models. Across 5 tasks with established baselines, we achieve an average improvement of 0.025 in ROC-AUC for binary classification tasks and 4.6\% reduction in MAPE for regression tasks. Online A/B testing validates these improvements translate to measurable business impact with a 3.15\% increase in Daily Active Users.

</details>


### [162] [EEG-Bench: A Benchmark for EEG Foundation Models in Clinical Applications](https://arxiv.org/abs/2512.08959)
*Ard Kastrati,Josua Bürki,Jonas Lauer,Cheng Xuan,Raffaele Iaquinto,Roger Wattenhofer*

Main category: cs.LG

TL;DR: EEG基础模型临床评估统一框架，覆盖11类疾病诊断任务、14个公开数据集，结果显示基础模型在某些场景表现优异但简约模型仍具竞争力。


<details>
  <summary>Details</summary>
Motivation: 当前EEG基础模型在临床应用中的评估缺乏系统性的基准框架，需要建立统一、标准化的评测体系来客观比较不同模型在真实临床场景下的表现。

Method: 构建最小预处理、标准化评估协议的统一基准框架，涵盖14个公开EEG数据集中的11类诊断任务，支持经典基线模型与现代基础模型的并行比较。

Result: 基础模型在特定设置下表现优异，但在临床分布偏移情况下，更简单的模型往往仍具有竞争力；所有准备好的数据和代码已公开发布。

Conclusion: 虽然EEG基础模型展现潜力，但临床应用中简约模型仍不可忽视；发布的基准框架将促进该领域的可复现性和进一步研究。

Abstract: We introduce a unified benchmarking framework focused on evaluating EEG-based foundation models in clinical applications. The benchmark spans 11 well-defined diagnostic tasks across 14 publicly available EEG datasets, including epilepsy, schizophrenia, Parkinson's disease, OCD, and mild traumatic brain injury. It features minimal preprocessing, standardized evaluation protocols, and enables side-by-side comparisons of classical baselines and modern foundation models. Our results show that while foundation models achieve strong performance in certain settings, simpler models often remain competitive, particularly under clinical distribution shifts. To facilitate reproducibility and adoption, we release all prepared data and code in an accessible and extensible format.

</details>


### [163] [Resolving Conflicts in Lifelong Learning via Aligning Updates in Subspaces](https://arxiv.org/abs/2512.08960)
*Yueer Zhou,Yichen Wu,Ying Wei*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Low-Rank Adaptation (LoRA) enables efficient Continual Learning but often suffers from catastrophic forgetting due to destructive interference between tasks. Our analysis reveals that this degradation is primarily driven by antagonistic directional updates where new task gradients directly oppose the historical weight trajectory. To address this, we propose PS-LoRA (Parameter Stability LoRA), a framework designed to resolve conflicts by aligning updates within the optimization subspace. Our approach employs a dual-regularization objective that penalizes conflicting directions and constrains magnitude deviations to ensure consistency with prior knowledge. Additionally, we implement a magnitude-based merging strategy to consolidate sequential adapters into a robust representation without retraining. Experiments on NLP and Vision benchmarks show that PS-LoRA outperforms state-of-the-art methods by preserving the stability of learned representations while efficiently adapting to new domains.

</details>


### [164] [Financial Instruction Following Evaluation (FIFE)](https://arxiv.org/abs/2512.08965)
*Glenn Matlin,Siddharth,Anirudh JM,Aditya Shukla,Yahya Hassan,Sudheer Chava*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Language Models (LMs) struggle with complex, interdependent instructions, particularly in high-stakes domains like finance where precision is critical. We introduce FIFE, a novel, high-difficulty benchmark designed to assess LM instruction-following capabilities for financial analysis tasks. FIFE comprises 88 human-authored prompts and employs a verification system with chainable, verifiable constraints for fine-grained reward signals. We evaluate 53 models (proprietary, open-weight, open-source) in a zero-shot setting. Our key findings reveal a clear performance hierarchy: the top open-weight model (76.1 strict / 79.5 loose) surpasses the leading proprietary system (65.9 strict / 70.5 loose), while the best open-source models lag significantly (45.5 strict / 48.9 loose). However, even top-performing models struggle with FIFE's complex requirements, failing to achieve perfect compliance. We release our dataset and code as an open-source resource to promote research in Reinforcement Learning for the financial domain.

</details>


### [165] [CluCERT: Certifying LLM Robustness via Clustering-Guided Denoising Smoothing](https://arxiv.org/abs/2512.08967)
*Zixia Wang,Gaojie Jin,Jia Hu,Ronghui Mu*

Main category: cs.LG

TL;DR: CluCERT通过聚类引导的去噪平滑方法来认证大语言模型的抗对抗攻击鲁棒性，相比现有方法获得了更紧的认证边界和更高的计算效率。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在日常应用中广泛使用，但它们仍然容易受到对抗攻击，即使保持语义的同义词替换也可能导致错误预测。现有的鲁棒性认证方法存在两个关键限制：1)由于缺乏对扰动输出的语义验证而导致的宽松鲁棒边界；2)由于重复采样导致的高计算成本。

Method: 提出了CluCERT框架，通过聚类引导的去噪平滑来认证LLM鲁棒性。具体方法包括：1)引入语义聚类过滤器以减少噪声样本并保留有意义的扰动；2)通过重构模块提取核心语义；3)使用快速同义词替换策略加速去噪过程。

Result: 在各种下游任务和越狱防御场景中的实验表明，该方法在鲁棒性边界和计算效率方面都优于现有的认证方法。

Conclusion: CluCERT通过语义聚类过滤和高效去噪机制，为LLM对抗攻击的鲁棒性认证提供了一种有效且高效的解决方案，显著提高了认证质量和计算效率。

Abstract: Recent advancements in Large Language Models (LLMs) have led to their widespread adoption in daily applications. Despite their impressive capabilities, they remain vulnerable to adversarial attacks, as even minor meaning-preserving changes such as synonym substitutions can lead to incorrect predictions. As a result, certifying the robustness of LLMs against such adversarial prompts is of vital importance. Existing approaches focused on word deletion or simple denoising strategies to achieve robustness certification. However, these methods face two critical limitations: (1) they yield loose robustness bounds due to the lack of semantic validation for perturbed outputs and (2) they suffer from high computational costs due to repeated sampling. To address these limitations, we propose CluCERT, a novel framework for certifying LLM robustness via clustering-guided denoising smoothing. Specifically, to achieve tighter certified bounds, we introduce a semantic clustering filter that reduces noisy samples and retains meaningful perturbations, supported by theoretical analysis. Furthermore, we enhance computational efficiency through two mechanisms: a refine module that extracts core semantics, and a fast synonym substitution strategy that accelerates the denoising process. Finally, we conduct extensive experiments on various downstream tasks and jailbreak defense scenarios. Experimental results demonstrate that our method outperforms existing certified approaches in both robustness bounds and computational efficiency.

</details>


### [166] [StructuredDNA: A Bio-Physical Framework for Energy-Aware Transformer Routing](https://arxiv.org/abs/2512.08968)
*Mustapha Hamdi*

Main category: cs.LG

TL;DR: StructuredDNA是一种基于生物物理能量引导的稀疏Transformer路由框架，通过语义能量最小化实现能效计算。


<details>
  <summary>Details</summary>
Motivation: 大规模计算模型的快速增长导致了能源和计算成本的急剧上升，受生物系统低能耗配置启发，需要开发节能型稀疏架构。

Method: 用生物物理能量引导路由层取代密集的混合专家路由，通过语义能量最小化动态分组输入为语义密码子，结合内聚性、不确定性和计算成本最小化来选择单一专家。

Result: 在BioASQ上实现了97.7%的EUD（能量利用密度）降低和0.998的SSI（语义稳定性指数）；在WikiText-103上展示了语义扩展定律，2048个专家时仍保持99%以上能效。

Conclusion: StructuredDNA建立了连接生物物理原理与Transformer稀疏专家路由的框架，为未来节能、模块化、可扩展的计算系统提供了新范例。

Abstract: The rapid scaling of large computational models has led to a critical increase in energy and compute costs. Inspired by biological systems where structure and function emerge from low-energy configurations, we introduce StructuredDNA, a sparse architecture framework for modular, energy-aware Transformer routing. StructuredDNA replaces dense Mixture-of-Experts routing with a bio-physical, energy-guided routing layer based on semantic energy minimization. Inputs are dynamically grouped into semantic codons, and routing selects a single expert by minimizing a global energy functional that combines cohesion, uncertainty, and computational cost.
  We validate StructuredDNA on both specialized (BioASQ) and open-domain benchmarks (WikiText-103). On BioASQ (K = 50), we achieve a 97.7% reduction in Energy Utilization Density (EUD) and a Semantic Stability Index (SSI) of 0.998. We further demonstrate a Semantic Scaling Law on WikiText-103, showing that the architecture generalizes to open domains by scaling expert granularity (K = 2048) while maintaining more than 99% energy efficiency. StructuredDNA thus establishes a robust, domain-agnostic paradigm for future sparse computational frameworks.
  StructuredDNA provides an explicit link between bio-physical principles and sparse expert routing in Transformer architectures, and points toward future energy-aware, modular, and scalable computational systems. We discuss limitations of this proof-of-concept study and outline directions for scaling the approach to larger models, datasets, and hardware platforms. The StructuredDNA implementation is available at https://github.com/InnoDeep-repos/StructuredDNA .

</details>


### [167] [Peek-a-Boo Reasoning: Contrastive Region Masking in MLLMs](https://arxiv.org/abs/2512.08976)
*Isha Chaturvedi,Anjana Nair,Yushen Li,Adhitya Rajendra Kumar,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma*

Main category: cs.LG

TL;DR: CRM是一种无需训练的评估方法，用于分析MLLM在推理过程中对视觉区域的依赖，揭示模型在缺失证据或受到干扰时的不同失败模式。


<details>
  <summary>Details</summary>
Motivation: 先前方法局限于最终答案或注意力图谱，无法提供因果、步骤级别的归因，因此需要新方法来揭示MLLM在链式推理中对视觉区域的依赖性。

Method: CRM通过系统性地掩蔽带标注的视觉区域，并与未掩蔽的基准对比，分析推理轨迹的变化，实现步骤级归因分析。

Result: 在VisArgs等数据集上发现两类失败模式：有些模型结构完整但证据缺失时产生幻觉；有些模型过度依赖视觉线索，受到干扰时推理崩溃。

Conclusion: CRM将视觉基准转化为诊断工具，强调需要评估MLLM的推理忠实性而不仅是答案正确性，推动建立关注推理鲁棒性和保真度的多模态评估框架。

Abstract: We introduce Contrastive Region Masking (CRM), a training free diagnostic that reveals how multimodal large language models (MLLMs) depend on specific visual regions at each step of chain-of-thought (CoT) reasoning. Unlike prior approaches limited to final answers or attention maps, CRM provides causal, step-level attri- bution by systematically masking annotated regions and contrasting the resulting reasoning traces with unmasked baselines. Applied to datasets such as VisArgs, CRM reveals distinct failure modes: some models preserve reasoning structure, but hallucinate when evidence is missing, while others ground tightly to visual cues yet collapse under perturbations. By shifting the evaluation from correctness of an- swers to faithfulness of reasoning, CRM reframes visual benchmarks as diagnostic tools, highlighting the need for multimodal evaluation frameworks that measure not just performance, but also robustness and fidelity of reasoning.

</details>


### [168] [Improving Multi-Class Calibration through Normalization-Aware Isotonic Techniques](https://arxiv.org/abs/2512.09054)
*Alon Arad,Saharon Rosset*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate and reliable probability predictions are essential for multi-class supervised learning tasks, where well-calibrated models enable rational decision-making. While isotonic regression has proven effective for binary calibration, its extension to multi-class problems via one-vs-rest calibration produced suboptimal results when compared to parametric methods, limiting its practical adoption. In this work, we propose novel isotonic normalization-aware techniques for multiclass calibration, grounded in natural and intuitive assumptions expected by practitioners. Unlike prior approaches, our methods inherently account for probability normalization by either incorporating normalization directly into the optimization process (NA-FIR) or modeling the problem as a cumulative bivariate isotonic regression (SCIR). Empirical evaluation on a variety of text and image classification datasets across different model architectures reveals that our approach consistently improves negative log-likelihood (NLL) and expected calibration error (ECE) metrics.

</details>


### [169] [A Diffusion-Based Framework for High-Resolution Precipitation Forecasting over CONUS](https://arxiv.org/abs/2512.09059)
*Marina Vicens-Miquel,Amy McGovern,Aaron J. Hill,Efi Foufoula-Georgiou,Clement Guilloteau,Samuel S. P. Shen*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate precipitation forecasting is essential for hydrometeorological risk management, especially for anticipating extreme rainfall that can lead to flash flooding and infrastructure damage. This study introduces a diffusion-based deep learning (DL) framework that systematically compares three residual prediction strategies differing only in their input sources: (1) a fully data-driven model using only past observations from the Multi-Radar Multi-Sensor (MRMS) system, (2) a corrective model using only forecasts from the High-Resolution Rapid Refresh (HRRR) numerical weather prediction system, and (3) a hybrid model integrating both MRMS and selected HRRR forecast variables. By evaluating these approaches under a unified setup, we provide a clearer understanding of how each data source contributes to predictive skill over the Continental United States (CONUS). Forecasts are produced at 1-km spatial resolution, beginning with direct 1-hour predictions and extending to 12 hours using autoregressive rollouts. Performance is evaluated using both CONUS-wide and region-specific metrics that assess overall performance and skill at extreme rainfall thresholds. Across all lead times, our DL framework consistently outperforms the HRRR baseline in pixel-wise and spatiostatistical metrics. The hybrid model performs best at the shortest lead time, while the HRRR-corrective model outperforms others at longer lead times, maintaining high skill through 12 hours. To assess reliability, we incorporate calibrated uncertainty quantification tailored to the residual learning setup. These gains, particularly at longer lead times, are critical for emergency preparedness, where modest increases in forecast horizon can improve decision-making. This work advances DL-based precipitation forecasting by enhancing predictive skill, reliability, and applicability across regions.

</details>


### [170] [Modular Deep-Learning-Based Early Warning System for Deadly Heatwave Prediction](https://arxiv.org/abs/2512.09074)
*Shangqing Xu,Zhiyuan Zhao,Megha Sharma,José María Martín-Olalla,Alexander Rodríguez,Gregory A. Wellenius,B. Aditya Prakash*

Main category: cs.LG

TL;DR: 提出了一个名为DeepTherm的模块化早期预警系统，用于在不依赖热相关死亡率数据的情况下预测致命热浪。


<details>
  <summary>Details</summary>
Motivation: 城市地区的严重热浪严重威胁公共健康，需要建立早期预警策略。然而，由于难以定义和估计热相关死亡率，以及早期预警系统对数据可用性、时空鲁棒性和决策成本的要求，预测即将到来的致命热浪仍然是一个挑战。

Method: 利用深度学习的灵活性，提出了一个双预测流程，将无热浪和其他不规则事件情况下的基线死亡率与全因死亡率分离。

Result: 在西班牙的真实世界数据上进行了评估，结果显示在不同地区、时间段和人群群体中表现出了一致、稳健和准确的性能，并且可以在漏报和误报之间实现权衡。

Conclusion: DeepTherm能够在不依赖热相关死亡率历史数据的情况下预测致命热浪，为建立早期预警系统提供了有效的解决方案。

Abstract: Severe heatwaves in urban areas significantly threaten public health, calling for establishing early warning strategies. Despite predicting occurrence of heatwaves and attributing historical mortality, predicting an incoming deadly heatwave remains a challenge due to the difficulty in defining and estimating heat-related mortality. Furthermore, establishing an early warning system imposes additional requirements, including data availability, spatial and temporal robustness, and decision costs. To address these challenges, we propose DeepTherm, a modular early warning system for deadly heatwave prediction without requiring heat-related mortality history. By highlighting the flexibility of deep learning, DeepTherm employs a dual-prediction pipeline, disentangling baseline mortality in the absence of heatwaves and other irregular events from all-cause mortality. We evaluated DeepTherm on real-world data across Spain. Results demonstrate consistent, robust, and accurate performance across diverse regions, time periods, and population groups while allowing trade-off between missed alarms and false alarms.

</details>


### [171] [Beyond the Hype: Comparing Lightweight and Deep Learning Models for Air Quality Forecasting](https://arxiv.org/abs/2512.09076)
*Moazzam Umer Gondal,Hamad ul Qudous,Asma Ahmad Farhan*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate forecasting of urban air pollution is essential for protecting public health and guiding mitigation policies. While Deep Learning (DL) and hybrid pipelines dominate recent research, their complexity and limited interpretability hinder operational use. This study investigates whether lightweight additive models -- Facebook Prophet (FBP) and NeuralProphet (NP) -- can deliver competitive forecasts for particulate matter (PM$_{2.5}$, PM$_{10}$) in Beijing, China. Using multi-year pollutant and meteorological data, we applied systematic feature selection (correlation, mutual information, mRMR), leakage-safe scaling, and chronological data splits. Both models were trained with pollutant and precursor regressors, with NP additionally leveraging lagged dependencies. For context, two machine learning baselines (LSTM, LightGBM) and one traditional statistical model (SARIMAX) were also implemented. Performance was evaluated on a 7-day holdout using MAE, RMSE, and $R^2$. Results show that FBP consistently outperformed NP, SARIMAX, and the learning-based baselines, achieving test $R^2$ above 0.94 for both pollutants. These findings demonstrate that interpretable additive models remain competitive with both traditional and complex approaches, offering a practical balance of accuracy, transparency, and ease of deployment.

</details>


### [172] [GS-KAN: Parameter-Efficient Kolmogorov-Arnold Networks via Sprecher-Type Shared Basis Functions](https://arxiv.org/abs/2512.09084)
*Oscar Eliasson*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Kolmogorov-Arnold representation theorem offers a theoretical alternative to Multi-Layer Perceptrons (MLPs) by placing learnable univariate functions on edges rather than nodes. While recent implementations such as Kolmogorov-Arnold Networks (KANs) demonstrate high approximation capabilities, they suffer from significant parameter inefficiency due to the requirement of maintaining unique parameterizations for every network edge. In this work, we propose GS-KAN (Generalized Sprecher-KAN), a lightweight architecture inspired by David Sprecher's refinement of the superposition theorem. GS-KAN constructs unique edge functions by applying learnable linear transformations to a single learnable, shared parent function per layer. We evaluate GS-KAN against existing KAN architectures and MLPs across synthetic function approximation, tabular data regression and image classification tasks. Our results demonstrate that GS-KAN outperforms both MLPs and standard KAN baselines on continuous function approximation tasks while maintaining superior parameter efficiency. Additionally, GS-KAN achieves competitive performance with existing KAN architectures on tabular regression and outperforms MLPs on high-dimensional classification tasks. Crucially, the proposed architecture enables the deployment of KAN-based architectures in high-dimensional regimes under strict parameter constraints, a setting where standard implementations are typically infeasible due to parameter explosion. The source code is available at https://github.com/rambamn48/gs-impl.

</details>


### [173] [Towards Optimal Valve Prescription for Transcatheter Aortic Valve Replacement (TAVR) Surgery: A Machine Learning Approach](https://arxiv.org/abs/2512.09198)
*Phevos Paschalidis,Vasiliki Stoumpou,Lisa Everest,Yu Ma,Talhat Azemi,Jawad Haider,Steven Zweibel,Eleftherios M. Protopapas,Jeff Mather,Maciej Tysarowski,George E. Sarris,Robert C. Hagberg,Howard L. Haronian,Dimitris Bertsimas*

Main category: cs.LG

TL;DR: 本文提出了一种用于经导管主动脉瓣置换术（TAVR）瓣膜类型选择的数据驱动临床支持工具，旨在通过个性化处方策略降低永久性起搏器植入（PPI）风险


<details>
  <summary>Details</summary>
Motivation: TAVR作为治疗重度主动脉瓣狭窄的微创疗法，存在多种经导管心脏瓣膜（THV）可用，但目前瓣膜类型的处方指南仍存在争议，需要优化以降低PPI这一主要术后并发症的风险

Method: 整合美国与希腊患者群体数据，融合人口统计学、CT扫描和超声心动图三个数据源，采用叶级分析（leaf-level analysis）利用群体异质性，避免与不确定的反事实风险估计进行基准比较

Result: 开发的处方模型在美国内部人群中将PPI率降低了26%，在外部希腊验证队列中降低了16%，优于当前标准治疗

Conclusion: 本研究首次提出了TAVR中THV选择的统一、个性化处方策略，为临床决策提供了基于数据的支持工具，有望改善患者预后

Abstract: Transcatheter Aortic Valve Replacement (TAVR) has emerged as a minimally invasive treatment option for patients with severe aortic stenosis, a life-threatening cardiovascular condition. Multiple transcatheter heart valves (THV) have been approved for use in TAVR, but current guidelines regarding valve type prescription remain an active topic of debate. We propose a data-driven clinical support tool to identify the optimal valve type with the objective of minimizing the risk of permanent pacemaker implantation (PPI), a predominant postoperative complication. We synthesize a novel dataset that combines U.S. and Greek patient populations and integrates three distinct data sources (patient demographics, computed tomography scans, echocardiograms) while harmonizing differences in each country's record system. We introduce a leaf-level analysis to leverage population heterogeneity and avoid benchmarking against uncertain counterfactual risk estimates. The final prescriptive model shows a reduction in PPI rates of 26% and 16% compared with the current standard of care in our internal U.S. population and external Greek validation cohort, respectively. To the best of our knowledge, this work represents the first unified, personalized prescription strategy for THV selection in TAVR.

</details>


### [174] [LLMs for Analog Circuit Design Continuum (ACDC)](https://arxiv.org/abs/2512.09199)
*Yasaman Esfandiari,Jocelyn Rego,Austin Meyer,Jonathan Gallagher,Mia Levy*

Main category: cs.LG

TL;DR: 本文研究了大型语言模型（LLM）在模拟电路设计这一结构化工程任务中的可靠性和鲁棒性，发现模型存在数据格式敏感、生成设计不稳定等问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在自然语言任务中表现出色，但在需要领域专业知识和遵循物理约束的现实工程任务（如模拟电路设计）中的可靠性和实用性依然未知，制约了其在人机协同工作流中的实际应用。

Method: 研究比较了T5、GPT-2等较小模型与Mistral-7B、GPT-oss-20B等大型基础模型在不同数据表示和训练条件下的表现，重点关注不同数据表示对模型行为的影响。

Result: 结果揭示了关键的可靠性挑战：模型对数据格式敏感，生成的设计不稳定，且对未见过的电路配置泛化能力有限。

Conclusion: 研究为LLM作为增强人类在复杂工程任务中能力的工具的潜力与局限性提供了早期证据，并为设计适用于结构化现实应用的可部署基础模型提供了见解。

Abstract: Large Language Models (LLMs) and transformer architectures have shown impressive reasoning and generation capabilities across diverse natural language tasks. However, their reliability and robustness in real-world engineering domains remain largely unexplored, limiting their practical utility in human-centric workflows. In this work, we investigate the applicability and consistency of LLMs for analog circuit design -- a task requiring domain-specific reasoning, adherence to physical constraints, and structured representations -- focusing on AI-assisted design where humans remain in the loop. We study how different data representations influence model behavior and compare smaller models (e.g., T5, GPT-2) with larger foundation models (e.g., Mistral-7B, GPT-oss-20B) under varying training conditions. Our results highlight key reliability challenges, including sensitivity to data format, instability in generated designs, and limited generalization to unseen circuit configurations. These findings provide early evidence on the limits and potential of LLMs as tools to enhance human capabilities in complex engineering tasks, offering insights into designing reliable, deployable foundation models for structured, real-world applications.

</details>


### [175] [Contrastive Learning for Semi-Supervised Deep Regression with Generalized Ordinal Rankings from Spectral Seriation](https://arxiv.org/abs/2512.09267)
*Ce Wang,Weihang Dai,Hanru Bai,Xiaomeng Li*

Main category: cs.LG

TL;DR: 这篇论文提出了一种扩展对比回归方法到半监督设置的技术，通过利用未标记数据减少对昂贵标注的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有的对比学习方法高度依赖标签信息来恢复特征的有序关系，这限制了它们在半监督回归中的应用。

Method: 利用包含标记和未标记样本的小批量数据构建特征相似度矩阵，通过谱序算法恢复未标记样本的排序；引入标记样本提供正则化指导；使用动态规划算法选取鲁棒特征；将恢复的有序关系用于未标记样本的对比学习。

Result: 该方法在各种数据集上取得了超越现有最先进半监督回归方法的性能。

Conclusion: 该方法成功地将对比回归扩展到半监督设置，有效利用未标记数据提高表示学习能力，并在理论和实验上验证了其有效性。

Abstract: Contrastive learning methods enforce label distance relationships in feature space to improve representation capability for regression models. However, these methods highly depend on label information to correctly recover ordinal relationships of features, limiting their applications to semi-supervised regression. In this work, we extend contrastive regression methods to allow unlabeled data to be used in the semi-supervised setting, thereby reducing the dependence on costly annotations. Particularly we construct the feature similarity matrix with both labeled and unlabeled samples in a mini-batch to reflect inter-sample relationships, and an accurate ordinal ranking of involved unlabeled samples can be recovered through spectral seriation algorithms if the level of error is within certain bounds. The introduction of labeled samples above provides regularization of the ordinal ranking with guidance from the ground-truth label information, making the ranking more reliable. To reduce feature perturbations, we further utilize the dynamic programming algorithm to select robust features for the matrix construction. The recovered ordinal relationship is then used for contrastive learning on unlabeled samples, and we thus allow more data to be used for feature representation learning, thereby achieving more robust results. The ordinal rankings can also be used to supervise predictions on unlabeled samples, serving as an additional training signal. We provide theoretical guarantees and empirical verification through experiments on various datasets, demonstrating that our method can surpass existing state-of-the-art semi-supervised deep regression methods. Our code have been released on https://github.com/xmed-lab/CLSS.

</details>


### [176] [Goal inference with Rao-Blackwellized Particle Filters](https://arxiv.org/abs/2512.09269)
*Yixuan Wang,Dan P. Guralnik,Warren E. Dixon*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Inferring the eventual goal of a mobile agent from noisy observations of its trajectory is a fundamental estimation problem. We initiate the study of such intent inference using a variant of a Rao-Blackwellized Particle Filter (RBPF), subject to the assumption that the agent's intent manifests through closed-loop behavior with a state-of-the-art provable practical stability property. Leveraging the assumed closed-form agent dynamics, the RBPF analytically marginalizes the linear-Gaussian substructure and updates particle weights only, improving sample efficiency over a standard particle filter. Two difference estimators are introduced: a Gaussian mixture model using the RBPF weights and a reduced version confining the mixture to the effective sample. We quantify how well the adversary can recover the agent's intent using information-theoretic leakage metrics and provide computable lower bounds on the Kullback-Leibler (KL) divergence between the true intent distribution and RBPF estimates via Gaussian-mixture KL bounds. We also provide a bound on the difference in performance between the two estimators, highlighting the fact that the reduced estimator performs almost as well as the complete one. Experiments illustrate fast and accurate intent recovery for compliant agents, motivating future work on designing intent-obfuscating controllers.

</details>


### [177] [Hetero-SplitEE: Split Learning of Neural Networks with Early Exits for Heterogeneous IoT Devices](https://arxiv.org/abs/2512.09313)
*Yuki Oda,Yuta Ono,Hiroshi Nakamura,Hideki Takase*

Main category: cs.LG

TL;DR: 本文提出Hetero-SplitEE方法，通过异构早退机制和两种协作策略，让不同计算能力的IoT设备能够协同训练共享的深度学习模型。


<details>
  <summary>Details</summary>
Motivation: 现有的分割学习方法假设客户端同质且分割点统一，这限制了在计算资源异构的真实IoT系统中的适用性。为解决这一问题，需要一种能够支持异构设备并行协作训练的方法。

Method: 提出Hetero-SplitEE方法，将异构早退机制整合到分层训练中，让每个客户端根据自身计算能力选择不同的分割点。同时提出了两种协作训练策略：顺序策略和平均策略。

Result: 在CIFAR-10、CIFAR-100和STL-10数据集上使用ResNet-18进行的实验表明，该方法在保持竞争力的准确率的同时，能有效支持多样化的计算约束。

Conclusion: Hetero-SplitEE方法实现了异构IoT设备间的实用协作深度学习部署，解决了现有方法在资源异构环境中的局限性。

Abstract: The continuous scaling of deep neural networks has fundamentally transformed machine learning, with larger models demonstrating improved performance across diverse tasks. This growth in model size has dramatically increased the computational resources required for the training process. Consequently, distributed approaches, such as Federated Learning and Split Learning, have become essential paradigms for scalable deployment. However, existing Split Learning approaches assume client homogeneity and uniform split points across all participants. This critically limits their applicability to real-world IoT systems where devices exhibit heterogeneity in computational resources. To address this limitation, this paper proposes Hetero-SplitEE, a novel method that enables heterogeneous IoT devices to train a shared deep neural network in parallel collaboratively. By integrating heterogeneous early exits into hierarchical training, our approach allows each client to select distinct split points (cut layers) tailored to its computational capacity. In addition, we propose two cooperative training strategies, the Sequential strategy and the Averaging strategy, to facilitate this collaboration among clients with different split points. The Sequential strategy trains clients sequentially with a shared server model to reduce computational overhead. The Averaging strategy enables parallel client training with periodic cross-layer aggregation. Extensive experiments on CIFAR-10, CIFAR-100, and STL-10 datasets using ResNet-18 demonstrate that our method maintains competitive accuracy while efficiently supporting diverse computational constraints, enabling practical deployment of collaborative deep learning in heterogeneous IoT ecosystems.

</details>


### [178] [Self-Supervised Learning with Gaussian Processes](https://arxiv.org/abs/2512.09322)
*Yunshan Duan,Sinead Williamson*

Main category: cs.LG

TL;DR: 提出了GPSSL方法，利用高斯过程进行自我监督学习，替代显式正样本对生成，支持不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 传统SSL方法需要生成相似观察对，这对某些数据类型很困难，并且缺乏不确定性量化，在样本外预测中表现不佳。

Method: 在表示上施加GP先验，通过最小化鼓励信息表示损失的广义贝叶斯后验，利用协方差函数自然拉近相似样本表示。

Result: 在多种数据集上的实验显示，GPSSL在准确度、不确定性量化和错误控制方面优于传统方法。

Conclusion: GPSSL为自我监督学习提供了一种有效替代方案，能与核PCA和VICReg关联，同时提供传统方法缺乏的后验不确定性传播能力。

Abstract: Self supervised learning (SSL) is a machine learning paradigm where models learn to understand the underlying structure of data without explicit supervision from labeled samples. The acquired representations from SSL have demonstrated useful for many downstream tasks including clustering, and linear classification, etc. To ensure smoothness of the representation space, most SSL methods rely on the ability to generate pairs of observations that are similar to a given instance. However, generating these pairs may be challenging for many types of data. Moreover, these methods lack consideration of uncertainty quantification and can perform poorly in out-of-sample prediction settings. To address these limitations, we propose Gaussian process self supervised learning (GPSSL), a novel approach that utilizes Gaussian processes (GP) models on representation learning. GP priors are imposed on the representations, and we obtain a generalized Bayesian posterior minimizing a loss function that encourages informative representations. The covariance function inherent in GPs naturally pulls representations of similar units together, serving as an alternative to using explicitly defined positive samples. We show that GPSSL is closely related to both kernel PCA and VICReg, a popular neural network-based SSL method, but unlike both allows for posterior uncertainties that can be propagated to downstream tasks. Experiments on various datasets, considering classification and regression tasks, demonstrate that GPSSL outperforms traditional methods in terms of accuracy, uncertainty quantification, and error control.

</details>


### [179] [Self Distillation Fine-Tuning of Protein Language Models Improves Versatility in Protein Design](https://arxiv.org/abs/2512.09329)
*Amin Tavakoli,Raswanth Murugan,Ozan Gokdemir,Arvind Ramanathan,Frances Arnold,Anima Anandkumar*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Supervised fine-tuning (SFT) is a standard approach for adapting large language models to specialized domains, yet its application to protein sequence modeling and protein language models (PLMs) remains ad hoc. This is in part because high-quality annotated data are far more difficult to obtain for proteins than for natural language. We present a simple and general recipe for fast SFT of PLMs, designed to improve the fidelity, reliability, and novelty of generated protein sequences. Unlike existing approaches that require costly precompiled experimental datasets for SFT, our method leverages the PLM itself, integrating a lightweight curation pipeline with domain-specific filters to construct high-quality training data. These filters can independently refine a PLM's output and identify candidates for in vitro evaluation; when combined with SFT, they enable PLMs to generate more stable and functional enzymes, while expanding exploration into protein sequence space beyond natural variants. Although our approach is agnostic to both the choice of protein language model (PLM) and the protein system, we demonstrate its effectiveness with a genome-scale PLM (GenSLM) applied to the tryptophan synthase enzyme family. The supervised fine-tuned model generates sequences that are not only more novel but also display improved characteristics across both targeted design constraints and emergent protein property measures.

</details>


### [180] [A Granular Framework for Construction Material Price Forecasting: Econometric and Machine-Learning Approaches](https://arxiv.org/abs/2512.09360)
*Boge Lyu,Qianye Yin,Iris Denise Tommelein,Hanyang Liu,Karnamohit Ranka,Karthik Yeluripati,Junzhe Shi*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The persistent volatility of construction material prices poses significant risks to cost estimation, budgeting, and project delivery, underscoring the urgent need for granular and scalable forecasting methods. This study develops a forecasting framework that leverages the Construction Specifications Institute (CSI) MasterFormat as the target data structure, enabling predictions at the six-digit section level and supporting detailed cost projections across a wide spectrum of building materials. To enhance predictive accuracy, the framework integrates explanatory variables such as raw material prices, commodity indexes, and macroeconomic indicators. Four time-series models, Long Short-Term Memory (LSTM), Autoregressive Integrated Moving Average (ARIMA), Vector Error Correction Model (VECM), and Chronos-Bolt, were evaluated under both baseline configurations (using CSI data only) and extended versions with explanatory variables. Results demonstrate that incorporating explanatory variables significantly improves predictive performance across all models. Among the tested approaches, the LSTM model consistently achieved the highest accuracy, with RMSE values as low as 1.390 and MAPE values of 0.957, representing improvements of up to 59\% over the traditional statistical time-series model, ARIMA. Validation across multiple CSI divisions confirmed the framework's scalability, while Division 06 (Wood, Plastics, and Composites) is presented in detail as a demonstration case. This research offers a robust methodology that enables owners and contractors to improve budgeting practices and achieve more reliable cost estimation at the Definitive level.

</details>


### [181] [KGOT: Unified Knowledge Graph and Optimal Transport Pseudo-Labeling for Molecule-Protein Interaction Prediction](https://arxiv.org/abs/2512.09365)
*Jiayu Qin,Zhengquan Luo,Guy Tadmor,Changyou Chen,David Zeevi,Zhiqiang Xu*

Main category: cs.LG

TL;DR: 提出基于最优传输的伪标签生成框架解决分子-蛋白质相互作用预测中的数据稀缺问题


<details>
  <summary>Details</summary>
Motivation: 现有MPI模型面临两个主要挑战：标记数据稀缺，以及方法多依赖分子和蛋白质特征而忽略更广泛的生物学背景信息

Method: 首先整合多种生物数据集（分子、蛋白质、基因和通路水平交互），然后基于最优传输方法为未标记分子-蛋白质对生成高质量伪标签，利用已知交互的分布来指导标签分配

Result: 在多个人工智能药物发现任务中评估，包括虚拟筛选和蛋白质检索任务，在预测精度和零样本能力方面显著优于现有方法

Conclusion: 该方法不仅提升了MPI预测性能，还为利用多样化生物数据源提供了新范式，解决了传统单模态或双模态学习的局限，推动了计算生物学和药物发现的发展

Abstract: Predicting molecule-protein interactions (MPIs) is a fundamental task in computational biology, with crucial applications in drug discovery and molecular function annotation. However, existing MPI models face two major challenges. First, the scarcity of labeled molecule-protein pairs significantly limits model performance, as available datasets capture only a small fraction of biological relevant interactions. Second, most methods rely solely on molecular and protein features, ignoring broader biological context such as genes, metabolic pathways, and functional annotations that could provide essential complementary information. To address these limitations, our framework first aggregates diverse biological datasets, including molecular, protein, genes and pathway-level interactions, and then develop an optimal transport-based approach to generate high-quality pseudo-labels for unlabeled molecule-protein pairs, leveraging the underlying distribution of known interactions to guide label assignment. By treating pseudo-labeling as a mechanism for bridging disparate biological modalities, our approach enables the effective use of heterogeneous data to enhance MPI prediction. We evaluate our framework on multiple MPI datasets including virtual screening tasks and protein retrieval tasks, demonstrating substantial improvements over state-of-the-art methods in prediction accuracies and zero shot ability across unseen interactions. Beyond MPI prediction, our approach provides a new paradigm for leveraging diverse biological data sources to tackle problems traditionally constrained by single- or bi-modal learning, paving the way for future advances in computational biology and drug discovery.

</details>


### [182] [Are Hypervectors Enough? Single-Call LLM Reasoning over Knowledge Graphs](https://arxiv.org/abs/2512.09369)
*Yezi Liu,William Youngwoo Chung,Hanning Chen,Calvin Yeung,Mohsen Imani*

Main category: cs.LG

TL;DR: 提出 PathHD 框架，用超维计算替代神经路径评分，通过单次 LLM 调用实现高效知识图谱推理，在保持精度的同时大幅降低延迟和显存开销。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱的 LLM 推理方法依赖重型神经编码器或多轮 LLM 调用，导致高延迟、高 GPU 成本和不透明的决策，限制了可扩展部署。

Method: 使用超维计算（HDC）编码关系路径为块对角 GHRR 超向量，通过块余弦相似度和 Top-K 剪枝排序候选路径，单次 LLM 裁决生成最终答案及支持路径。

Result: 在 WebQSP、CWQ、GrailQA 数据集上，PathHD 达到或超越基线 Hits@1，延迟降低 40-60%，显存节省 3-5 倍，提供可解释的路径依据。

Conclusion: 精心设计的 HDC 表示可提供高效、准确、可解释的 KG-LLM 推理基础，实现良好的精度-效率-可解释性权衡。

Abstract: Recent advances in large language models (LLMs) have enabled strong reasoning over both structured and unstructured knowledge. When grounded on knowledge graphs (KGs), however, prevailing pipelines rely on heavy neural encoders to embed and score symbolic paths or on repeated LLM calls to rank candidates, leading to high latency, GPU cost, and opaque decisions that hinder faithful, scalable deployment. We propose PathHD, a lightweight and encoder-free KG reasoning framework that replaces neural path scoring with hyperdimensional computing (HDC) and uses only a single LLM call per query. PathHD encodes relation paths into block-diagonal GHRR hypervectors, ranks candidates with blockwise cosine similarity and Top-K pruning, and then performs a one-shot LLM adjudication to produce the final answer together with cited supporting paths. Technically, PathHD is built on three ingredients: (i) an order-aware, non-commutative binding operator for path composition, (ii) a calibrated similarity for robust hypervector-based retrieval, and (iii) a one-shot adjudication step that preserves interpretability while eliminating per-path LLM scoring. On WebQSP, CWQ, and the GrailQA split, PathHD (i) attains comparable or better Hits@1 than strong neural baselines while using one LLM call per query; (ii) reduces end-to-end latency by $40-60\%$ and GPU memory by $3-5\times$ thanks to encoder-free retrieval; and (iii) delivers faithful, path-grounded rationales that improve error diagnosis and controllability. These results indicate that carefully designed HDC representations provide a practical substrate for efficient KG-LLM reasoning, offering a favorable accuracy-efficiency-interpretability trade-off.

</details>


### [183] [CFLight: Enhancing Safety with Traffic Signal Control through Counterfactual Learning](https://arxiv.org/abs/2512.09368)
*Mingyuan Li,Chunyu Liu,Zhuojun Li,Xiao Liu,Guangsheng Yu,Bo Du,Jun Shen,Qiang Wu*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Traffic accidents result in millions of injuries and fatalities globally, with a significant number occurring at intersections each year. Traffic Signal Control (TSC) is an effective strategy for enhancing safety at these urban junctures. Despite the growing popularity of Reinforcement Learning (RL) methods in optimizing TSC, these methods often prioritize driving efficiency over safety, thus failing to address the critical balance between these two aspects. Additionally, these methods usually need more interpretability. CounterFactual (CF) learning is a promising approach for various causal analysis fields. In this study, we introduce a novel framework to improve RL for safety aspects in TSC. This framework introduces a novel method based on CF learning to address the question: ``What if, when an unsafe event occurs, we backtrack to perform alternative actions, and will this unsafe event still occur in the subsequent period?'' To answer this question, we propose a new structure causal model to predict the result after executing different actions, and we propose a new CF module that integrates with additional ``X'' modules to promote safe RL practices. Our new algorithm, CFLight, which is derived from this framework, effectively tackles challenging safety events and significantly improves safety at intersections through a near-zero collision control strategy. Through extensive numerical experiments on both real-world and synthetic datasets, we demonstrate that CFLight reduces collisions and improves overall traffic performance compared to conventional RL methods and the recent safe RL model. Moreover, our method represents a generalized and safe framework for RL methods, opening possibilities for applications in other domains. The data and code are available in the github https://github.com/MJLee00/CFLight-Enhancing-Safety-with-Traffic-Signal-Control-through-Counterfactual-Learning.

</details>


### [184] [Rates and architectures for learning geometrically non-trivial operators](https://arxiv.org/abs/2512.09376)
*T. Mitchell Roddenberry,Leo Tzou,Ivan Dokmanić,Maarten V. de Hoop,Richard G. Baraniuk*

Main category: cs.LG

TL;DR: 该论文将算子学习理论扩展到双纤维化变换（包括广义Radon变换和测地射线变换），证明这类算子不受维数灾难影响，误差衰减超代数级。研究提出一种基于水平集方法的交叉注意力架构，能有效学习双纤维化变换。


<details>
  <summary>Details</summary>
Motivation: 深度学习方法已证明能够从少量训练样本中恢复高维空间之间的算子，如PDE解映射和数学物理中的类似对象。然而，这类研究主要集中在几何简单、不传播奇异性的椭圆算子，而科学机器学习经常处理涉及波、对流、流体动力学等传播奇异性的问题。为此，作者将学习理论扩展到双纤维化变换这类几何积分算子。

Method: 1. 将算子学习理论扩展到双纤维化变换（广义Radon变换和测地射线变换）
2. 证明这类算子不受维数灾难影响，误差衰减超代数级
3. 设计基于水平集方法的交叉注意力架构，该架构能明确编码变换的几何信息
4. 提出的架构具有普适性、稳定性和从少量样本学习的能力

Result: 1. 证明双纤维化变换类算子不存在维数灾难，误差衰减速度比任何固定的训练样本数倒数的幂次更快
2. 提出并验证了基于水平集方法的交叉注意力架构
3. 该架构能够从少量训练样本中有效学习双纤维化变换
4. 扩展了科学机器学习中算子学习的理论基础

Conclusion: 该工作将算子学习理论扩展到包含奇异性和几何复杂度的双纤维化变换，证明这类变换可以高效学习而不受维数灾难影响。提出的几何感知架构为实现从少量数据中学习复杂算子提供了理论基础，为科学机器学习中处理波、对流等传播奇异性的问题开辟了新途径。

Abstract: Deep learning methods have proven capable of recovering operators between high-dimensional spaces, such as solution maps of PDEs and similar objects in mathematical physics, from very few training samples. This phenomenon of data-efficiency has been proven for certain classes of elliptic operators with simple geometry, i.e., operators that do not change the domain of the function or propagate singularities. However, scientific machine learning is commonly used for problems that do involve the propagation of singularities in a priori unknown ways, such as waves, advection, and fluid dynamics. In light of this, we expand the learning theory to include double fibration transforms--geometric integral operators that include generalized Radon and geodesic ray transforms. We prove that this class of operators does not suffer from the curse of dimensionality: the error decays superalgebraically, that is, faster than any fixed power of the reciprocal of the number of training samples. Furthermore, we investigate architectures that explicitly encode the geometry of these transforms, demonstrating that an architecture reminiscent of cross-attention based on levelset methods yields a parameterization that is universal, stable, and learns double fibration transforms from very few training examples. Our results contribute to a rapidly-growing line of theoretical work on learning operators for scientific machine learning.

</details>


### [185] [Federated Distillation Assisted Vehicle Edge Caching Scheme Based on Lightweight DDPM](https://arxiv.org/abs/2512.09378)
*Xun Li,Qiong Wu,Pingyi Fan,Kezhi Wang,Wen Chen,Khaled B. Letaief*

Main category: cs.LG

TL;DR: 提出基于联邦蒸馏和轻量去噪扩散概率模型的车辆边缘缓存方案，以减少车联网内容访问延迟，在保护隐私的同时降低通信开销并提升缓存命中率。


<details>
  <summary>Details</summary>
Motivation: 车辆边缘缓存技术可降低用户获取内容的延迟，但需在保护隐私的同时准确预测用户兴趣内容。传统联邦学习存在通信开销大、车辆可能中途离开覆盖区域导致训练失败的问题。

Method: 基于轻量去噪扩散概率模型(LDPM)和联邦蒸馏技术，通过模型蒸馏而非频繁传输完整模型来降低通信开销，并适应车辆移动性。

Result: 仿真结果表明该方案对车辆速度变化具有良好鲁棒性，能显著降低通信开销并提高缓存命中率。

Conclusion: 提出的基于LDPM和联邦蒸馏的车辆边缘缓存方案能有效解决传统联邦学习在车联网场景中的通信开销和移动性问题，实现隐私保护的同时提升缓存性能。

Abstract: Vehicle edge caching is a promising technology that can significantly reduce the latency for vehicle users (VUs) to access content by pre-caching user-interested content at edge nodes. It is crucial to accurately predict the content that VUs are interested in without exposing their privacy. Traditional federated learning (FL) can protect user privacy by sharing models rather than raw data. However, the training of FL requires frequent model transmission, which can result in significant communication overhead. Additionally, vehicles may leave the road side unit (RSU) coverage area before training is completed, leading to training failures. To address these issues, in this letter, we propose a federated distillation-assisted vehicle edge caching scheme based on lightweight denoising diffusion probabilistic model (LDPM). The simulation results demonstrate that the proposed vehicle edge caching scheme has good robustness to variations in vehicle speed, significantly reducing communication overhead and improving cache hit percentage.

</details>


### [186] [Towards Resilient Transportation: A Conditional Transformer for Accident-Informed Traffic Forecasting](https://arxiv.org/abs/2512.09398)
*Hongjun Wang,Jiawei Yong,Jiawei Wang,Shintaro Fukushima,Renhe Jiang*

Main category: cs.LG

TL;DR: 本文提出了ConFormer框架，结合交通事故和法规数据提升预测精度，超越现有方法


<details>
  <summary>Details</summary>
Motivation: 交通预测受外部因素（如事故、法规）影响，现有模型因数据整合有限而忽视这些因素，导致准确率受限

Method: 构建东京和加州两个增强数据集；提出ConFormer框架，结合图传播和引导归一化层，基于历史模式动态调整时空节点关系

Result: ConFormer在预测性能和效率上均超越STAEFormer等基准模型，计算成本更低、参数需求更少；在多个评估指标上优于主流时空基线

Conclusion: ConFormer通过整合外部因素和动态调整时空关系，显著提升交通预测性能，具有推动该领域研究的潜力

Abstract: Traffic prediction remains a key challenge in spatio-temporal data mining, despite progress in deep learning. Accurate forecasting is hindered by the complex influence of external factors such as traffic accidents and regulations, often overlooked by existing models due to limited data integration. To address these limitations, we present two enriched traffic datasets from Tokyo and California, incorporating traffic accident and regulation data. Leveraging these datasets, we propose ConFormer (Conditional Transformer), a novel framework that integrates graph propagation with guided normalization layer. This design dynamically adjusts spatial and temporal node relationships based on historical patterns, enhancing predictive accuracy. Our model surpasses the state-of-the-art STAEFormer in both predictive performance and efficiency, achieving lower computational costs and reduced parameter demands. Extensive evaluations demonstrate that ConFormer consistently outperforms mainstream spatio-temporal baselines across multiple metrics, underscoring its potential to advance traffic prediction research.

</details>


### [187] [Black-Box Behavioral Distillation Breaks Safety Alignment in Medical LLMs](https://arxiv.org/abs/2512.09403)
*Sohely Jahan,Ruimin Sun*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As medical large language models (LLMs) become increasingly integrated into clinical workflows, concerns around alignment robustness, and safety are escalating. Prior work on model extraction has focused on classification models or memorization leakage, leaving the vulnerability of safety-aligned generative medical LLMs underexplored.
  We present a black-box distillation attack that replicates the domain-specific reasoning of safety-aligned medical LLMs using only output-level access. By issuing 48,000 instruction queries to Meditron-7B and collecting 25,000 benign instruction response pairs, we fine-tune a LLaMA3 8B surrogate via parameter efficient LoRA under a zero-alignment supervision setting, requiring no access to model weights, safety filters, or training data. With a cost of $12, the surrogate achieves strong fidelity on benign inputs while producing unsafe completions for 86% of adversarial prompts, far exceeding both Meditron-7B (66%) and the untuned base model (46%). This reveals a pronounced functional-ethical gap, task utility transfers, while alignment collapses. To analyze this collapse, we develop a dynamic adversarial evaluation framework combining Generative Query (GQ)-based harmful prompt generation, verifier filtering, category-wise failure analysis, and adaptive Random Search (RS) jailbreak attacks. We also propose a layered defense system, as a prototype detector for real-time alignment drift in black-box deployments.
  Our findings show that benign-only black-box distillation exposes a practical and under-recognized threat: adversaries can cheaply replicate medical LLM capabilities while stripping safety mechanisms, underscoring the need for extraction-aware safety monitoring.

</details>


### [188] [Cauchy-Schwarz Fairness Regularizer](https://arxiv.org/abs/2512.09467)
*Yezi Liu,Hanning Chen,Wenjun Huang,Yang Ni,Mohsen Imani*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Group fairness in machine learning is often enforced by adding a regularizer that reduces the dependence between model predictions and sensitive attributes. However, existing regularizers are built on heterogeneous distance measures and design choices, which makes their behavior hard to reason about and their performance inconsistent across tasks. This raises a basic question: what properties make a good fairness regularizer? We address this question by first organizing existing in-process methods into three families: (i) matching prediction statistics across sensitive groups, (ii) aligning latent representations, and (iii) directly minimizing dependence between predictions and sensitive attributes. Through this lens, we identify desirable properties of the underlying distance measure, including tight generalization bounds, robustness to scale differences, and the ability to handle arbitrary prediction distributions. Motivated by these properties, we propose a Cauchy-Schwarz (CS) fairness regularizer that penalizes the empirical CS divergence between prediction distributions conditioned on sensitive groups. Under a Gaussian comparison, we show that CS divergence yields a tighter bound than Kullback-Leibler divergence, Maximum Mean Discrepancy, and the mean disparity used in Demographic Parity, and we discuss how these advantages translate to a distribution-free, kernel-based estimator that naturally extends to multiple sensitive attributes. Extensive experiments on four tabular benchmarks and one image dataset demonstrate that the proposed CS regularizer consistently improves Demographic Parity and Equal Opportunity metrics while maintaining competitive accuracy, and achieves a more stable utility-fairness trade-off across hyperparameter settings compared to prior regularizers.

</details>


### [189] [Representation Invariance and Allocation: When Subgroup Balance Matters](https://arxiv.org/abs/2512.09496)
*Anissa Alloula,Charles Jones,Zuzanna Wakefield-Skorniewska,Francesco Quinzan,Bartłomiej Papież*

Main category: cs.LG

TL;DR: 本文研究了训练数据中人口群体代表性不均对模型泛化性能的影响，通过实验发现传统的数据平衡假设并不完全成立，提出了潜在空间分离假说来解释模型表现对数据分布的依赖关系。


<details>
  <summary>Details</summary>
Motivation: 现有研究认为平衡训练数据中的人口子群分布能优化模型性能，但近期经验证据显示这一假设存在矛盾，有时不平衡的数据分布反而能提升子群性能。因此需要系统研究训练数据组成如何影响子群性能，并提出更准确的理论解释。

Method: 在四个视觉和语言模型上进行系统研究，通过改变训练数据组成来表征子群性能对数据平衡的敏感性；提出潜在分离假说，并进行理论分析和实验验证。

Result: 研究发现子群性能对训练数据分布的敏感性取决于预训练模型中子群在潜在空间的分离程度；当子群在潜在空间中高度分离时，训练数据组成对模型性能影响显著；而当子群高度重叠时，训练数据组成的影响较小。

Conclusion: 本文提出的潜在分离假说能有效解释子群性能对训练数据分布的依赖关系，为基座模型微调提供了实际指导，表明通过对潜在子群分离进行定量分析可以指导数据收集和平衡决策。

Abstract: Unequal representation of demographic groups in training data poses challenges to model generalisation across populations. Standard practice assumes that balancing subgroup representation optimises performance. However, recent empirical results contradict this assumption: in some cases, imbalanced data distributions actually improve subgroup performance, while in others, subgroup performance remains unaffected by the absence of an entire subgroup during training. We conduct a systematic study of subgroup allocation across four vision and language models, varying training data composition to characterise the sensitivity of subgroup performance to data balance. We propose the latent separation hypothesis, which states that a partially fine-tuned model's dependence on subgroup representation is determined by the degree of separation between subgroups in the latent space of the pre-trained model. We formalise this hypothesis, provide theoretical analysis, and validate it empirically. Finally, we present a practical application to foundation model fine-tuning, demonstrating that quantitative analysis of latent subgroup separation can inform data collection and balancing decisions.

</details>


### [190] [Contextual Dynamic Pricing with Heterogeneous Buyers](https://arxiv.org/abs/2512.09513)
*Thodoris Lykouris,Sloan Nietert,Princewill Okoroafor,Chara Podimata,Julian Zimmert*

Main category: cs.LG

TL;DR: 本文研究异质买家群体的上下文动态定价问题，提出基于乐观后验采样的上下文定价算法，证明其实现了$\widetilde{O}(K_{\star}\sqrt{dT})$的最优遗憾界，并对非上下文情况设计了方差感知缩放算法。


<details>
  <summary>Details</summary>
Motivation: 先前研究工作假设买家是同质的，但在实际场景中买家估值类型通常具有异质性。本文旨在研究买家类型分布未知且支持集有限时的上下文动态定价问题，填补现有研究在异质买家群体建模方面的空白。

Method: 提出基于乐观后验采样的上下文定价算法，利用买家类型的有限支持集特性；针对非上下文情况，设计了考虑估值方差的缩放算法以优化对$K_{\star}$的依赖关系。

Result: 证明了上下文定价算法实现了$\widetilde{O}(K_{\star}\sqrt{dT})$的遗憾界，该界在$d$和$T$维度上达到最优（除去对数项）；非上下文情况下的方差感知缩放算法实现了对$K_{\star}$的最优依赖关系。

Conclusion: 本文首次系统研究了异质买家群体的上下文动态定价问题，提出的算法在理论上达到最优性能，为实际定价决策提供了有效的理论框架。

Abstract: We initiate the study of contextual dynamic pricing with a heterogeneous population of buyers, where a seller repeatedly posts prices (over $T$ rounds) that depend on the observable $d$-dimensional context and receives binary purchase feedback. Unlike prior work assuming homogeneous buyer types, in our setting the buyer's valuation type is drawn from an unknown distribution with finite support size $K_{\star}$. We develop a contextual pricing algorithm based on optimistic posterior sampling with regret $\widetilde{O}(K_{\star}\sqrt{dT})$, which we prove to be tight in $d$ and $T$ up to logarithmic terms. Finally, we refine our analysis for the non-contextual pricing case, proposing a variance-aware zooming algorithm that achieves the optimal dependence on $K_{\star}$.

</details>


### [191] [QuanvNeXt: An end-to-end quanvolutional neural network for EEG-based detection of major depressive disorder](https://arxiv.org/abs/2512.09517)
*Nabil Anan Orka,Ehtashamul Haque,Maftahul Jannat,Md Abdul Awal,Mohammad Ali Moni*

Main category: cs.LG

TL;DR: QuanvNeXt：一种用于基于EEG的抑郁症诊断的端到端完全量子卷积模型，在两个公开数据集上达到93.1%的平均准确率和97.2%的平均AUC-ROC，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 开发一个参数高效且可靠的基于EEG的抑郁症诊断模型，同时降低特征同质性并增强跨特征关系，以改进诊断性能。

Method: 提出QuanvNeXt模型，引入新颖的Cross Residual块来减少特征同质化并加强跨特征关系，同时保持参数效率。使用不确定性分析和可解释AI方法进行评估。

Result: 在两个公开数据集上平均准确率达到93.1%，平均AUC-ROC达到97.2%，优于InceptionTime等基准模型。不确定性分析显示模型预测校准良好，即使在高噪声扰动下ECE分数也保持低位。

Conclusion: QuanvNeXt为基于EEG的抑郁症诊断建立了一个高效可靠的方法，能够有效识别和学习区分健康对照与抑郁症患者的谱时模式。

Abstract: This study presents QuanvNeXt, an end-to-end fully quanvolutional model for EEG-based depression diagnosis. QuanvNeXt incorporates a novel Cross Residual block, which reduces feature homogeneity and strengthens cross-feature relationships while retaining parameter efficiency. We evaluated QuanvNeXt on two open-source datasets, where it achieved an average accuracy of 93.1% and an average AUC-ROC of 97.2%, outperforming state-of-the-art baselines such as InceptionTime (91.7% accuracy, 95.9% AUC-ROC). An uncertainty analysis across Gaussian noise levels demonstrated well-calibrated predictions, with ECE scores remaining low (0.0436, Dataset 1) to moderate (0.1159, Dataset 2) even at the highest perturbation (ε = 0.1). Additionally, a post-hoc explainable AI analysis confirmed that QuanvNeXt effectively identifies and learns spectrotemporal patterns that distinguish between healthy controls and major depressive disorder. Overall, QuanvNeXt establishes an efficient and reliable approach for EEG-based depression diagnosis.

</details>


### [192] [Stanford Sleep Bench: Evaluating Polysomnography Pre-training Methods for Sleep Foundation Models](https://arxiv.org/abs/2512.09591)
*Magnus Ruud Kjaer,Rahul Thapa,Gauri Ganjoo,Hyatt Moore,Poul Joergen Jennum,Brandon M. Westover,James Zou,Emmanuel Mignot,Bryan He,Andreas Brink-Kjaer*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Polysomnography (PSG), the gold standard test for sleep analysis, generates vast amounts of multimodal clinical data, presenting an opportunity to leverage self-supervised representation learning (SSRL) for pre-training foundation models to enhance sleep analysis. However, progress in sleep foundation models is hindered by two key limitations: (1) the lack of a shared dataset and benchmark with diverse tasks for training and evaluation, and (2) the absence of a systematic evaluation of SSRL approaches across sleep-related tasks. To address these gaps, we introduce Stanford Sleep Bench, a large-scale PSG dataset comprising 17,467 recordings totaling over 163,000 hours from a major sleep clinic, including 13 clinical disease prediction tasks alongside canonical sleep-related tasks such as sleep staging, apnea diagnosis, and age estimation. We systematically evaluate SSRL pre-training methods on Stanford Sleep Bench, assessing downstream performance across four tasks: sleep staging, apnea diagnosis, age estimation, and disease and mortality prediction. Our results show that multiple pretraining methods achieve comparable performance for sleep staging, apnea diagnosis, and age estimation. However, for mortality and disease prediction, contrastive learning significantly outperforms other approaches while also converging faster during pretraining. To facilitate reproducibility and advance sleep research, we will release Stanford Sleep Bench along with pretrained model weights, training pipelines, and evaluation code.

</details>


### [193] [Semantic-Aware Cooperative Communication and Computation Framework in Vehicular Networks](https://arxiv.org/abs/2512.09621)
*Jingbo Zhang,Maoxin Ji,Qiong Wu,Pingyi Fan,Kezhi Wang,Wen Chen*

Main category: cs.LG

TL;DR: 该文提出了一种三方协作语义通信框架，在车联网高速场景下通过V2I和V2V通信实现语义任务卸载，使用基于参数化分布噪声的多智能体近端策略优化算法优化语义符号数量，再用线性规划解决卸载比例问题，性能优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 结合语义通信和车联网边缘计算，为车联网提供高效边缘任务处理范式，特别针对高速公路场景下车辆用户的语义任务卸载需求。

Method: 提出三方协作语义通信框架，构建混合整数非线性规划问题并分解为语义符号数量优化和卸载比例两个子问题，分别采用基于参数化分布噪声的多智能体近端策略优化算法和线性规划求解。

Result: 仿真实验表明，该方案在任务延迟和语义符号数量方面性能优于其他对比算法。

Conclusion: 提出的TCSC框架和MAPPO-PDN算法有效解决了车联网语义任务卸载优化问题，为高速公路车联网边缘计算提供了可行解决方案。

Abstract: Semantic Communication (SC) combined with Vehicular edge computing (VEC) provides an efficient edge task processing paradigm for Internet of Vehicles (IoV). Focusing on highway scenarios, this paper proposes a Tripartite Cooperative Semantic Communication (TCSC) framework, which enables Vehicle Users (VUs) to perform semantic task offloading via Vehicle-to-Infrastructure (V2I) and Vehicle-to-Vehicle (V2V) communications. Considering task latency and the number of semantic symbols, the framework constructs a Mixed-Integer Nonlinear Programming (MINLP) problem, which is transformed into two subproblems. First, we innovatively propose a multi-agent proximal policy optimization task offloading optimization method based on parametric distribution noise (MAPPO-PDN) to solve the optimization problem of the number of semantic symbols; second, linear programming (LP) is used to solve offloading ratio. Simulations show that performance of this scheme is superior to that of other algorithms.

</details>


### [194] [Membership and Dataset Inference Attacks on Large Audio Generative Models](https://arxiv.org/abs/2512.09654)
*Jakub Proboszcz,Paweł Kochanski,Karol Korszun,Donato Crisostomi,Giorgio Strano,Emanuele Rodolà,Kamil Deja,Jan Dubinski*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Generative audio models, based on diffusion and autoregressive architectures, have advanced rapidly in both quality and expressiveness. This progress, however, raises pressing copyright concerns, as such models are often trained on vast corpora of artistic and commercial works. A central question is whether one can reliably verify if an artist's material was included in training, thereby providing a means for copyright holders to protect their content. In this work, we investigate the feasibility of such verification through membership inference attacks (MIA) on open-source generative audio models, which attempt to determine whether a specific audio sample was part of the training set. Our empirical results show that membership inference alone is of limited effectiveness at scale, as the per-sample membership signal is weak for models trained on large and diverse datasets. However, artists and media owners typically hold collections of works rather than isolated samples. Building on prior work in text and vision domains, in this work we focus on dataset inference (DI), which aggregates diverse membership evidence across multiple samples. We find that DI is successful in the audio domain, offering a more practical mechanism for assessing whether an artist's works contributed to model training. Our results suggest DI as a promising direction for copyright protection and dataset accountability in the era of large audio generative models.

</details>


### [195] [A data-driven approach to linking design features with manufacturing process data for sustainable product development](https://arxiv.org/abs/2512.09690)
*Jiahang Li,Lucas Cazzonelli,Jacqueline Höllig,Markus Doellken,Sven Matthiesen*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The growing adoption of Industrial Internet of Things (IIoT) technologies enables automated, real-time collection of manufacturing process data, unlocking new opportunities for data-driven product development. Current data-driven methods are generally applied within specific domains, such as design or manufacturing, with limited exploration of integrating design features and manufacturing process data. Since design decisions significantly affect manufacturing outcomes, such as error rates, energy consumption, and processing times, the lack of such integration restricts the potential for data-driven product design improvements. This paper presents a data-driven approach to mapping and analyzing the relationship between design features and manufacturing process data. A comprehensive system architecture is developed to ensure continuous data collection and integration. The linkage between design features and manufacturing process data serves as the basis for developing a machine learning model that enables automated design improvement suggestions. By integrating manufacturing process data with sustainability metrics, this approach opens new possibilities for sustainable product development.

</details>


### [196] [Training One Model to Master Cross-Level Agentic Actions via Reinforcement Learning](https://arxiv.org/abs/2512.09706)
*Kaichen He,Zihao Wang,Muyao Li,Anji Liu,Yitao Liang*

Main category: cs.LG

TL;DR: CrossAgent是一个统一的智能体模型，能够在异构动作空间中自适应选择最有效的交互粒度，在Minecraft环境中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有智能体通常局限于静态、预定义的动作空间（如仅使用API、GUI事件或机器人命令），这种刚性限制了其在动态环境中的适应性，而最优交互粒度会随上下文变化。

Method: 引入一个全面的训练管道，集成冷启动监督微调和多轮组相对策略优化（GRPO）算法，使智能体能够学习自适应动作切换（平衡高层效率与底层精度）而无需人工指定规则。

Result: 在开放世界Minecraft环境中的800多个任务上进行的大量实验表明，CrossAgent实现了最先进的性能。通过动态利用不同动作空间的优势，该模型显著优于固定动作基线，在长视野推理中表现出卓越的泛化能力和效率。

Conclusion: CrossAgent通过掌握异构动作空间并自主选择每个轨迹步骤的最有效接口，为智能体AI从工程化复杂工作流程向后训练原生模型的范式转变提供了重要进展。

Abstract: The paradigm of agentic AI is shifting from engineered complex workflows to post-training native models. However, existing agents are typically confined to static, predefined action spaces--such as exclusively using APIs, GUI events, or robotic commands. This rigidity limits their adaptability in dynamic environments where the optimal granularity of interaction varies contextually. To bridge this gap, we propose CrossAgent, a unified agentic model that masters heterogeneous action spaces and autonomously selects the most effective interface for each step of a trajectory. We introduce a comprehensive training pipeline that integrates cold-start supervised fine-tuning with a Multi-Turn Group Relative Policy Optimization (GRPO) algorithm. This approach enables the agent to learn adaptive action switching--balancing high-level efficiency with low-level precision--without human-specified rules. Extensive experiments on over 800 tasks in the open-world Minecraft environment demonstrate that CrossAgent achieves state-of-the-art performance. By dynamically leveraging the strengths of diverse action spaces, our model significantly outperforms fixed-action baselines, exhibiting superior generalization and efficiency in long-horizon reasoning. All code and models are available at https://github.com/CraftJarvis/OpenHA

</details>


### [197] [Mixture of Lookup Key-Value Experts](https://arxiv.org/abs/2512.09723)
*Zongcheng Wang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent research has developed several LLM architectures suitable for inference on end-user devices, such as the Mixture of Lookup Experts (MoLE)~\parencite{jie_mixture_2025}. A key feature of MoLE is that each token id is associated with a dedicated group of experts. For a given input, only the experts corresponding to the input token id will be activated. Since the communication overhead of loading this small number of activated experts into RAM during inference is negligible, expert parameters can be offloaded to storage, making MoLE suitable for resource-constrained devices. However, MoLE's context-independent expert selection mechanism, based solely on input ids, may limit model performance. To address this, we propose the \textbf{M}ixture \textbf{o}f \textbf{L}ookup \textbf{K}ey-\textbf{V}alue Experts (\textbf{MoLKV}) model. In MoLKV, each expert is structured as a key-value pair. For a given input, the input-derived query interacts with the cached key-value experts from the current sequence, generating a context-aware expert output. This context-aware mechanism alleviates the limitation of MoLE, and experimental results demonstrate that MoLKV achieves significantly lower validation loss in small-scale evaluations.

</details>


### [198] [Circuits, Features, and Heuristics in Molecular Transformers](https://arxiv.org/abs/2512.09757)
*Kristof Varadi,Mark Marosi,Peter Antal*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Transformers generate valid and diverse chemical structures, but little is known about the mechanisms that enable these models to capture the rules of molecular representation. We present a mechanistic analysis of autoregressive transformers trained on drug-like small molecules to reveal the computational structure underlying their capabilities across multiple levels of abstraction. We identify computational patterns consistent with low-level syntactic parsing and more abstract chemical validity constraints. Using sparse autoencoders (SAEs), we extract feature dictionaries associated with chemically relevant activation patterns. We validate our findings on downstream tasks and find that mechanistic insights can translate to predictive performance in various practical settings.

</details>


### [199] [Physics-Aware Heterogeneous GNN Architecture for Real-Time BESS Optimization in Unbalanced Distribution Systems](https://arxiv.org/abs/2512.09780)
*Aoxiang Ma,Salah Ghamizi,Jun Cao,Pedro Rodriguez*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Battery energy storage systems (BESS) have become increasingly vital in three-phase unbalanced distribution grids for maintaining voltage stability and enabling optimal dispatch. However, existing deep learning approaches often lack explicit three-phase representation, making it difficult to accurately model phase-specific dynamics and enforce operational constraints--leading to infeasible dispatch solutions. This paper demonstrates that by embedding detailed three-phase grid information--including phase voltages, unbalanced loads, and BESS states--into heterogeneous graph nodes, diverse GNN architectures (GCN, GAT, GraphSAGE, GPS) can jointly predict network state variables with high accuracy. Moreover, a physics-informed loss function incorporates critical battery constraints--SoC and C-rate limits--via soft penalties during training. Experimental validation on the CIGRE 18-bus distribution system shows that this embedding-loss approach achieves low prediction errors, with bus voltage MSEs of 6.92e-07 (GCN), 1.21e-06 (GAT), 3.29e-05 (GPS), and 9.04e-07 (SAGE). Importantly, the physics-informed method ensures nearly zero SoC and C-rate constraint violations, confirming its effectiveness for reliable, constraint-compliant dispatch.

</details>


### [200] [TinyDéjàVu: Smaller Memory Footprint & Faster Inference on Sensor Data Streams with Always-On Microcontrollers](https://arxiv.org/abs/2512.09786)
*Zhaolan Huang,Emmanuel Baccelli*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Always-on sensors are increasingly expected to embark a variety of tiny neural networks and to continuously perform inference on time-series of the data they sense. In order to fit lifetime and energy consumption requirements when operating on battery, such hardware uses microcontrollers (MCUs) with tiny memory budget e.g., 128kB of RAM. In this context, optimizing data flows across neural network layers becomes crucial. In this paper, we introduce TinyDéjàVu, a new framework and novel algorithms we designed to drastically reduce the RAM footprint required by inference using various tiny ML models for sensor data time-series on typical microcontroller hardware. We publish the implementation of TinyDéjàVu as open source, and we perform reproducible benchmarks on hardware. We show that TinyDéjàVu can save more than 60% of RAM usage and eliminate up to 90% of redundant compute on overlapping sliding window inputs.

</details>


### [201] [Knowledge Diversion for Efficient Morphology Control and Policy Transfer](https://arxiv.org/abs/2512.09796)
*Fu Feng,Ruixiao Shi,Yucheng Xie,Jianlu Shen,Jing Wang,Xin Geng*

Main category: cs.LG

TL;DR: DivMorph是一个模块化训练范式，通过知识分流学习可分解的控制器，使用SVD分解和动态软门控实现知识与任务/形态的解耦，在跨任务泛化和模型效率方面取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前通用的形态控制方法存在两个主要问题：1）Transformer架构计算成本高，部署开销大；2）现有方法跨任务泛化能力有限，每个新任务都需要从头训练。

Method: 利用SVD将随机初始化的Transformer权重分解为因子单元，通过任务和形态嵌入的动态软门控制这些单元，将知识分离为共享的'learngenes'和特定于形态/任务的'tailors'。

Result: DivMorph实现了最先进的性能，在跨任务迁移中样本效率比直接微调提高3倍，在单智能体部署中模型大小减少17倍。

Conclusion: DivMorph通过知识分解和选择性激活机制，实现了可扩展、高效的策略部署，并能有效迁移到新任务，为解决通用形态控制中的效率和泛化问题提供了有效方案。

Abstract: Universal morphology control aims to learn a universal policy that generalizes across heterogeneous agent morphologies, with Transformer-based controllers emerging as a popular choice. However, such architectures incur substantial computational costs, resulting in high deployment overhead, and existing methods exhibit limited cross-task generalization, necessitating training from scratch for each new task. To this end, we propose \textbf{DivMorph}, a modular training paradigm that leverages knowledge diversion to learn decomposable controllers. DivMorph factorizes randomly initialized Transformer weights into factor units via SVD prior to training and employs dynamic soft gating to modulate these units based on task and morphology embeddings, separating them into shared \textit{learngenes} and morphology- and task-specific \textit{tailors}, thereby achieving knowledge disentanglement. By selectively activating relevant components, DivMorph enables scalable and efficient policy deployment while supporting effective policy transfer to novel tasks. Extensive experiments demonstrate that DivMorph achieves state-of-the-art performance, achieving a 3$\times$ improvement in sample efficiency over direct finetuning for cross-task transfer and a 17$\times$ reduction in model size for single-agent deployment.

</details>


### [202] [Ariel-ML: Computing Parallelization with Embedded Rust for Neural Networks on Heterogeneous Multi-core Microcontrollers](https://arxiv.org/abs/2512.09800)
*Zhaolan Huang,Kaspar Schleiser,Gyungmin Myung,Emmanuel Baccelli*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Low-power microcontroller (MCU) hardware is currently evolving from single-core architectures to predominantly multi-core architectures. In parallel, new embedded software building blocks are more and more written in Rust, while C/C++ dominance fades in this domain. On the other hand, small artificial neural networks (ANN) of various kinds are increasingly deployed in edge AI use cases, thus deployed and executed directly on low-power MCUs. In this context, both incremental improvements and novel innovative services will have to be continuously retrofitted using ANNs execution in software embedded on sensing/actuating systems already deployed in the field. However, there was so far no Rust embedded software platform automating parallelization for inference computation on multi-core MCUs executing arbitrary TinyML models. This paper thus fills this gap by introducing Ariel-ML, a novel toolkit we designed combining a generic TinyML pipeline and an embedded Rust software platform which can take full advantage of multi-core capabilities of various 32bit microcontroller families (Arm Cortex-M, RISC-V, ESP-32). We published the full open source code of its implementation, which we used to benchmark its capabilities using a zoo of various TinyML models. We show that Ariel-ML outperforms prior art in terms of inference latency as expected, and we show that, compared to pre-existing toolkits using embedded C/C++, Ariel-ML achieves comparable memory footprints. Ariel-ML thus provides a useful basis for TinyML practitioners and resource-constrained embedded Rust developers.

</details>


### [203] [Incorporating Fairness in Neighborhood Graphs for Fair Spectral Clustering](https://arxiv.org/abs/2512.09810)
*Adithya K Moorthy,V Vijaya Saradhi,Bhanu Prasad*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Graph clustering plays a pivotal role in unsupervised learning methods like spectral clustering, yet traditional methods for graph clustering often perpetuate bias through unfair graph constructions that may underrepresent some groups. The current research introduces novel approaches for constructing fair k-nearest neighbor (kNN) and fair epsilon-neighborhood graphs that proactively enforce demographic parity during graph formation. By incorporating fairness constraints at the earliest stage of neighborhood selection steps, our approaches incorporate proportional representation of sensitive features into the local graph structure while maintaining geometric consistency.Our work addresses a critical gap in pre-processing for fair spectral clustering, demonstrating that topological fairness in graph construction is essential for achieving equitable clustering outcomes. Widely used graph construction methods like kNN and epsilon-neighborhood graphs propagate edge based disparate impact on sensitive groups, leading to biased clustering results. Providing representation of each sensitive group in the neighborhood of every node leads to fairer spectral clustering results because the topological features of the graph naturally reflect equitable group ratios. This research fills an essential shortcoming in fair unsupervised learning, by illustrating how topological fairness in graph construction inherently facilitates fairer spectral clustering results without the need for changes to the clustering algorithm itself. Thorough experiments on three synthetic datasets, seven real-world tabular datasets, and three real-world image datasets prove that our fair graph construction methods surpass the current baselines in graph clustering tasks.

</details>


### [204] [Conformal Bandits: Bringing statistical validity and reward efficiency to the small-gap regime](https://arxiv.org/abs/2512.09850)
*Simone Cuonzo,Nina Deliu*

Main category: cs.LG

TL;DR: 将Conformal Prediction引入bandit问题，为顺序决策提供有限时间统计保证，同时在小差异环境下提升regret性能


<details>
  <summary>Details</summary>
Motivation: 传统bandit策略（如Thompson Sampling、UCB）依赖分布假设或渐近保证，主要关注regret而忽略统计性质，在小差异环境下表现不佳

Method: 提出Conformal Bandits框架，将Conformal Prediction与bandit策略结合，在金融投资组合分配应用中整合隐马尔可夫模型捕捉市场状态转换

Result: 在小差异环境下实现更好的regret性能，获得名义覆盖保证，而经典UCB策略失败，在保持覆盖保证的同时提高风险调整后regret效率回报

Conclusion: Conformal Bandits为顺序决策提供了统计保证与regret最小化的双重优势，特别是在小差异金融场景中具有实际应用价值

Abstract: We introduce Conformal Bandits, a novel framework integrating Conformal Prediction (CP) into bandit problems, a classic paradigm for sequential decision-making under uncertainty. Traditional regret-minimisation bandit strategies like Thompson Sampling and Upper Confidence Bound (UCB) typically rely on distributional assumptions or asymptotic guarantees; further, they remain largely focused on regret, neglecting their statistical properties. We address this gap. Through the adoption of CP, we bridge the regret-minimising potential of a decision-making bandit policy with statistical guarantees in the form of finite-time prediction coverage.
  We demonstrate the potential of it Conformal Bandits through simulation studies and an application to portfolio allocation, a typical small-gap regime, where differences in arm rewards are far too small for classical policies to achieve optimal regret bounds in finite sample. Motivated by this, we showcase our framework's practical advantage in terms of regret in small-gap settings, as well as its added value in achieving nominal coverage guarantees where classical UCB policies fail. Focusing on our application of interest, we further illustrate how integrating hidden Markov models to capture the regime-switching behaviour of financial markets, enhances the exploration-exploitation trade-off, and translates into higher risk-adjusted regret efficiency returns, while preserving coverage guarantees.

</details>


### [205] [HPM-KD: Hierarchical Progressive Multi-Teacher Framework for Knowledge Distillation and Efficient Model Compression](https://arxiv.org/abs/2512.09886)
*Gustavo Coelho Haase,Paulo Henrique Dourado da Silva*

Main category: cs.LG

TL;DR: HPM-KD框架解决了知识蒸馏的四个关键问题：参数敏感、师生容量差距、多教师协调低效、资源利用不足，通过六组件集成实现自动化高效蒸馏。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏技术存在超参数敏感、师生容量差距大、多教师协调差和计算资源效率低四大挑战，需要自动化、高效和稳健的解决方案。

Method: 提出HPM-KD整合六个协同组件：元学习自适应配置管理器、自动中间模型确定进度蒸馏链、注意力加权多教师集成、元学习温度调度器、并行处理管线、共享优化内存。

Result: 在CIFAR-10、CIFAR-100和表格数据集上，HPM-KD实现10-15倍压缩且保持85%精度，无需人工调参，并行化减少30-40%训练时间，消融实验确认各组件贡献。

Conclusion: HPM-KD是自动化、高效的知识蒸馏框架，解决了现有KD技术的核心限制，可作为开源DeepBridge库组件促进模型压缩的实际应用。

Abstract: Knowledge Distillation (KD) has emerged as a promising technique for model compression but faces critical limitations: (1) sensitivity to hyperparameters requiring extensive manual tuning, (2) capacity gap when distilling from very large teachers to small students, (3) suboptimal coordination in multi-teacher scenarios, and (4) inefficient use of computational resources. We present \textbf{HPM-KD}, a framework that integrates six synergistic components: (i) Adaptive Configuration Manager via meta-learning that eliminates manual hyperparameter tuning, (ii) Progressive Distillation Chain with automatically determined intermediate models, (iii) Attention-Weighted Multi-Teacher Ensemble that learns dynamic per-sample weights, (iv) Meta-Learned Temperature Scheduler that adapts temperature throughout training, (v) Parallel Processing Pipeline with intelligent load balancing, and (vi) Shared Optimization Memory for cross-experiment reuse. Experiments on CIFAR-10, CIFAR-100, and tabular datasets demonstrate that HPM-KD: achieves 10x-15x compression while maintaining 85% accuracy retention, eliminates the need for manual tuning, and reduces training time by 30-40% via parallelization. Ablation studies confirm independent contribution of each component (0.10-0.98 pp). HPM-KD is available as part of the open-source DeepBridge library.

</details>


### [206] [Analysis of Dirichlet Energies as Over-smoothing Measures](https://arxiv.org/abs/2512.09890)
*Anna Bison,Alessandro Sperduti*

Main category: cs.LG

TL;DR: 本文分析了未归一化和归一化图拉普拉斯导出的Dirichlet能量作为过平滑度量时的关键区别，揭示归一化版本不满足节点相似性公理定义，需要根据GNN架构光谱特性选择合适度量。


<details>
  <summary>Details</summary>
Motivation: 存在两种常用的过平滑度量函数（基于未归一化与归一化图拉普拉斯的Dirichlet能量），当前研究未明确区分它们，导致监控GNN训练动态时存在歧义。本文旨在阐明二者的本质区别，为选择与GNN架构光谱特性兼容的度量提供理论依据。

Method: 1. 形式化分析两种Dirichlet能量的光谱性质；2. 验证归一化图拉普拉斯导出的度量是否符合Rusch等人提出的节点相似性公理；3. 建立度量选择与GNN架构光谱特性的关联框架。

Result: 1. 归一化图拉普拉斯导出的Dirichlet能量不满足节点相似性公理定义；2. 明确了两种度量在光谱特性上的根本差异；3. 提出了根据GNN架构选择兼容度量的标准，解决了监控动态时的歧义问题。

Conclusion: 选择过平滑度量必须考虑其与GNN架构的光谱兼容性，未归一化和归一化图拉普拉斯导出的Dirichlet能量存在本质区别，不能随意互换使用，正确的选择对于准确监控GNN训练动态至关重要。

Abstract: We analyze the distinctions between two functionals often used as over-smoothing measures: the Dirichlet energies induced by the unnormalized graph Laplacian and the normalized graph Laplacian. We demonstrate that the latter fails to satisfy the axiomatic definition of a node-similarity measure proposed by Rusch \textit{et al.} By formalizing fundamental spectral properties of these two definitions, we highlight critical distinctions necessary to select the metric that is spectrally compatible with the GNN architecture, thereby resolving ambiguities in monitoring the dynamics.

</details>


### [207] [Provably Learning from Modern Language Models via Low Logit Rank](https://arxiv.org/abs/2512.09892)
*Noah Golowich,Allen Liu,Abhishek Shetty*

Main category: cs.LG

TL;DR: 本文研究如何利用语言模型中的低logit秩结构设计高效学习算法，在查询学习模型中获得可证明的学习保证


<details>
  <summary>Details</summary>
Motivation: 现代语言模型虽然复杂，但经验观察发现它们都具有近似低logit秩的特性。这一结构特征可能为算法设计提供简化路径，作者希望探索如何利用这一特性获得可证明的学习保证，特别是考虑到低logit秩模型仍能编码难以学习的分布（如噪声奇偶函数）

Method: 采用查询学习模型配合logit查询，这反映了常见API的访问方式。基于语言模型具有近似低logit秩的假设，设计了高效学习算法从查询中学习这类模型

Result: 提出了一个高效算法，可以从查询中学习任何近似低logit秩模型。这一结果为可能捕捉现代语言模型特征的生成模型提供了首个端到端学习保证

Conclusion: 通过利用语言模型经验观察到的低logit秩结构，即使面对能编码难学习分布的模型，也能设计出具有可证明保证的高效学习算法。这一工作为理解现代语言模型的算法学习提供了理论基础

Abstract: While modern language models and their inner workings are incredibly complex, recent work (Golowich, Liu & Shetty; 2025) has proposed a simple and potentially tractable abstraction for them through the observation that empirically, these language models all seem to have approximately low logit rank. Roughly, this means that a matrix formed by the model's log probabilities of various tokens conditioned on certain sequences of tokens is well approximated by a low rank matrix.
  In this paper, our focus is on understanding how this structure can be exploited algorithmically for obtaining provable learning guarantees. Since low logit rank models can encode hard-to-learn distributions such as noisy parities, we study a query learning model with logit queries that reflects the access model for common APIs. Our main result is an efficient algorithm for learning any approximately low logit rank model from queries. We emphasize that our structural assumption closely reflects the behavior that is empirically observed in modern language models. Thus, our result gives what we believe is the first end-to-end learning guarantee for a generative model that plausibly captures modern language models.

</details>


### [208] [FALCON: Few-step Accurate Likelihoods for Continuous Flows](https://arxiv.org/abs/2512.09914)
*Danyal Rehman,Tara Akhound-Sadegh,Artem Gazizov,Yoshua Bengio,Alexander Tong*

Main category: cs.LG

TL;DR: 论文针对Boltzmann Generators在采样分子状态时面临的似然计算成本高的问题，提出了一种名为FALCON的方法，该方法可以通过少量步骤实现准确的似然计算，从而大幅提升采样效率。


<details>
  <summary>Details</summary>
Motivation: 传统的Boltzmann Generators虽然能精确计算似然，但其使用的连续归一化流（CNFs）需要大量的函数评估，导致采样成本过高，限制了其在实际应用中的推广。

Method: 论文提出了Few-step Accurate Likelihoods for Continuous Flows (FALCON)方法，通过引入混合训练目标来增强可逆性，从而实现了在少量步骤内完成准确的似然计算。

Result: 实验表明，FALCON在分子Boltzmann采样方面优于当前最先进的归一化流模型，并且比同等性能的CNF模型快两个数量级以上。

Conclusion: FALCON通过减少采样步骤并保持准确似然，显著提高了Boltzmann Generators的实用性和效率，为分子系统的高效采样提供了一种有前景的解决方案。

Abstract: Scalable sampling of molecular states in thermodynamic equilibrium is a long-standing challenge in statistical physics. Boltzmann Generators tackle this problem by pairing a generative model, capable of exact likelihood computation, with importance sampling to obtain consistent samples under the target distribution. Current Boltzmann Generators primarily use continuous normalizing flows (CNFs) trained with flow matching for efficient training of powerful models. However, likelihood calculation for these models is extremely costly, requiring thousands of function evaluations per sample, severely limiting their adoption. In this work, we propose Few-step Accurate Likelihoods for Continuous Flows (FALCON), a method which allows for few-step sampling with a likelihood accurate enough for importance sampling applications by introducing a hybrid training objective that encourages invertibility. We show FALCON outperforms state-of-the-art normalizing flow models for molecular Boltzmann sampling and is two orders of magnitude faster than the equivalently performing CNF model.

</details>


### [209] [Closing the Train-Test Gap in World Models for Gradient-Based Planning](https://arxiv.org/abs/2512.09929)
*Arjun Parthasarathy,Nimit Kalra,Rohun Agrawal,Yann LeCun,Oumayma Bounou,Pavel Izmailov,Micah Goldblum*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: World models paired with model predictive control (MPC) can be trained offline on large-scale datasets of expert trajectories and enable generalization to a wide range of planning tasks at inference time. Compared to traditional MPC procedures, which rely on slow search algorithms or on iteratively solving optimization problems exactly, gradient-based planning offers a computationally efficient alternative. However, the performance of gradient-based planning has thus far lagged behind that of other approaches. In this paper, we propose improved methods for training world models that enable efficient gradient-based planning. We begin with the observation that although a world model is trained on a next-state prediction objective, it is used at test-time to instead estimate a sequence of actions. The goal of our work is to close this train-test gap. To that end, we propose train-time data synthesis techniques that enable significantly improved gradient-based planning with existing world models. At test time, our approach outperforms or matches the classical gradient-free cross-entropy method (CEM) across a variety of object manipulation and navigation tasks in 10% of the time budget.

</details>

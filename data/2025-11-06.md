<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 36]
- [cs.CL](#cs.CL) [Total: 39]
- [cs.HC](#cs.HC) [Total: 17]
- [cs.LG](#cs.LG) [Total: 50]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.AI](#cs.AI) [Total: 10]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Cropland Mapping using Geospatial Embeddings](https://arxiv.org/abs/2511.02923)
*Ivan Zvonkov,Gabriel Tseng,Inbal Becker-Reshef,Hannah Kerner*

Main category: cs.CV

TL;DR: 本研究探讨了地理空间嵌入在图瓦的农田制图中的应用，发现其能够提升地图制作效率和分类准确性。


<details>
  <summary>Details</summary>
Motivation: 准确且及时的土地覆盖地图对于理解土地利用变化，进而应对气候变化至关重要。

Method: 使用Presto和AlphaEarth生成农田地图，通过地理空间嵌入评估其在农田制图中的实用性。

Result: 我们的研究结果表明，地理空间嵌入可以在农田制图中提供高效和可访问的解决方案。

Conclusion: 地理空间嵌入技术能够简化工作流程，实现高精度的农田分类，并支持更好地评估土地利用变化及其气候影响。

Abstract: Accurate and up-to-date land cover maps are essential for understanding land
use change, a key driver of climate change. Geospatial embeddings offer a more
efficient and accessible way to map landscape features, yet their use in
real-world mapping applications remains underexplored. In this work, we
evaluated the utility of geospatial embeddings for cropland mapping in Togo. We
produced cropland maps using embeddings from Presto and AlphaEarth. Our
findings show that geospatial embeddings can simplify workflows, achieve
high-accuracy cropland classification and ultimately support better assessments
of land use change and its climate impacts.

</details>


### [2] [Generative Hints](https://arxiv.org/abs/2511.02933)
*Andy Dimnaku,Abdullah Yusuf Kavranoğlu,Yaser Abu-Mostafa*

Main category: cs.CV

TL;DR: 生成提示通过生成虚拟示例并结合半监督学习，显著提高了模型在视觉分类任务中的表现，相比于传统数据增强方法有更好的效果。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统数据增强在捕捉不变性特征方面的不足，提出生成提示方法直接在输入空间中强制已知的不变性。

Method: 采用半监督学习方法，结合已标记的数据和生成的未标记的虚拟示例，通过分类和提示目标进行训练。

Result: 在多个数据集和模型架构上，生成提示方法相较于标准数据增强均表现出更高的性能，尤其是在细粒度视觉分类基准上取得了最高1.78%的准确率提升。

Conclusion: 生成提示方法在视觉分类任务中表现优于传统的数据增强方法，能够更有效地捕捉已知的不变性特征。

Abstract: Data augmentation is widely used in vision to introduce variation and
mitigate overfitting, through enabling models to learn invariant properties,
such as spatial invariance. However, these properties are not fully captured by
data augmentation alone, since it attempts to learn the property on
transformations of the training data only. We propose generative hints, a
training methodology that directly enforces known invariances in the entire
input space. Our approach leverages a generative model trained on the training
set to approximate the input distribution and generate unlabeled images, which
we refer to as virtual examples. These virtual examples are used to enforce
functional properties known as hints. In generative hints, although the
training dataset is fully labeled, the model is trained in a semi-supervised
manner on both the classification and hint objectives, using the unlabeled
virtual examples to guide the model in learning the desired hint. Across
datasets, architectures, and loss functions, generative hints consistently
outperform standard data augmentation when learning the same property. On
popular fine-grained visual classification benchmarks, we achieved up to 1.78%
top-1 accuracy improvement (0.63% on average) over fine-tuned models with data
augmentation and an average performance boost of 1.286% on the CheXpert X-ray
dataset.

</details>


### [3] [ProM3E: Probabilistic Masked MultiModal Embedding Model for Ecology](https://arxiv.org/abs/2511.02946)
*Srikumar Sastry,Subash Khanal,Aayush Dhakal,Jiayu Lin,Dan Cher,Phoenix Jarosz,Nathan Jacobs*

Main category: cs.CV

TL;DR: ProM3E是一种用于生态领域的多模态嵌入模型，通过蒙版模态重建学习缺失模态，展示了优越的检索及表示学习能力。


<details>
  <summary>Details</summary>
Motivation: 针对生态领域，提出一种能够进行多模态表示生成的模型，旨在提高不同模态之间的融合能力和综合性能。

Method: 基于嵌入空间中的蒙版模态重建，ProM3E模型学习在给定上下文模态的情况下推断缺失模态。

Result: 通过引入新的跨模态检索方法，结合了模态间和模态内的相似性，提升了检索任务的表现。模型展示了极佳的表示学习能力，并通过线性探测任务验证了其有效性。

Conclusion: ProM3E模型展示了其优越的多模态表示学习能力，并在各种检索任务中取得了卓越的性能。

Abstract: We introduce ProM3E, a probabilistic masked multimodal embedding model for
any-to-any generation of multimodal representations for ecology. ProM3E is
based on masked modality reconstruction in the embedding space, learning to
infer missing modalities given a few context modalities. By design, our model
supports modality inversion in the embedding space. The probabilistic nature of
our model allows us to analyse the feasibility of fusing various modalities for
given downstream tasks, essentially learning what to fuse. Using these features
of our model, we propose a novel cross-modal retrieval approach that mixes
inter-modal and intra-modal similarities to achieve superior performance across
all retrieval tasks. We further leverage the hidden representation from our
model to perform linear probing tasks and demonstrate the superior
representation learning capability of our model. All our code, datasets and
model will be released at https://vishu26.github.io/prom3e.

</details>


### [4] [EvtSlowTV - A Large and Diverse Dataset for Event-Based Depth Estimation](https://arxiv.org/abs/2511.02953)
*Sadiq Layi Macaulay,Nimet Kaygusuz,Simon Hadfield*

Main category: cs.CV

TL;DR: EvtSlowTV is a large-scale event camera dataset that enhances depth estimation by providing diverse conditions and removing the need for frame annotations.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this work is to address the limitations of existing small-scale annotated datasets for event-based depth estimation, which hampers real-world application.

Method: We introduce EvtSlowTV, a large-scale dataset sourced from YouTube, containing over 13B events across diverse conditions, which is used in a self-supervised learning framework for depth learning.

Result: The training with EvtSlowTV improves models' generalization to complex scenes and motions, demonstrating the effectiveness of using a large-scale, unconstrained event dataset.

Conclusion: EvtSlowTV significantly enhances event-based depth estimation by providing a large-scale dataset without the need for frame-based annotations, enabling better generalization and leveraging the capabilities of event cameras.

Abstract: Event cameras, with their high dynamic range (HDR) and low latency, offer a
promising alternative for robust depth estimation in challenging environments.
However, many event-based depth estimation approaches are constrained by
small-scale annotated datasets, limiting their generalizability to real-world
scenarios. To bridge this gap, we introduce EvtSlowTV, a large-scale event
camera dataset curated from publicly available YouTube footage, which contains
more than 13B events across various environmental conditions and motions,
including seasonal hiking, flying, scenic driving, and underwater exploration.
EvtSlowTV is an order of magnitude larger than existing event datasets,
providing an unconstrained, naturalistic setting for event-based depth
learning. This work shows the suitability of EvtSlowTV for a self-supervised
learning framework to capitalise on the HDR potential of raw event streams. We
further demonstrate that training with EvtSlowTV enhances the model's ability
to generalise to complex scenes and motions. Our approach removes the need for
frame-based annotations and preserves the asynchronous nature of event data.

</details>


### [5] [Hybrid Convolution and Vision Transformer NAS Search Space for TinyML Image Classification](https://arxiv.org/abs/2511.02992)
*Mikhael Djajapermana,Moritz Reiber,Daniel Mueller-Gritschneder,Ulf Schlichtmann*

Main category: cs.CV

TL;DR: 本文提出一种新的混合CNN-ViT搜索空间，旨在通过神经架构搜索找到高效的图像分类架构，实验结果显示其在减少模型规模的同时，能提高准确性和推理速度。


<details>
  <summary>Details</summary>
Motivation: 当前纯CNN和ViT架构在tinyML部署中面临参数大、计算成本高的问题，因此需要找到更高效的混合架构。

Method: 通过神经架构搜索（NAS）在混合CNN和ViT块之间寻找高效架构，并引入可搜索的池化层以减少特征图。

Result: 在CIFAR10数据集上的实验结果表明，所提出的搜索空间生成的混合架构在准确性和推理速度上优于基于ResNet的tinyML模型。

Conclusion: 提出的搜索空间能够在模型大小受限的情况下，生成具有更高准确率和推理速度的混合CNN-ViT架构。

Abstract: Hybrids of Convolutional Neural Network (CNN) and Vision Transformer (ViT)
have outperformed pure CNN or ViT architecture. However, since these
architectures require large parameters and incur large computational costs,
they are unsuitable for tinyML deployment. This paper introduces a new hybrid
CNN-ViT search space for Neural Architecture Search (NAS) to find efficient
hybrid architectures for image classification. The search space covers hybrid
CNN and ViT blocks to learn local and global information, as well as the novel
Pooling block of searchable pooling layers for efficient feature map reduction.
Experimental results on the CIFAR10 dataset show that our proposed search space
can produce hybrid CNN-ViT architectures with superior accuracy and inference
speed to ResNet-based tinyML models under tight model size constraints.

</details>


### [6] [SCALE-VLP: Soft-Weighted Contrastive Volumetric Vision-Language Pre-training with Spatial-Knowledge Semantics](https://arxiv.org/abs/2511.02996)
*Ailar Mahdizadeh,Puria Azadi Moghadam,Xiangteng He,Shahriar Mirabbasi,Panos Nasiopoulos,Leonid Sigal*

Main category: cs.CV

TL;DR: SCALE-VLP通过整合体积空间语义和领域知识，实现了对体积数据的高效处理，显示出强大的跨任务和跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有体积数据处理中的空间一致性不足和临床语义利用不充分的问题。

Method: 提出了一种软加权对比的视觉语言预训练框架，整合体积空间语义和领域知识语义以指导对齐。

Result: SCALE-VLP在多个评估指标上表现优异，提升了CT报告检索、异常分类和报告生成的性能，相比于之前的技术，显著提升。

Conclusion: SCALE-VLP在有限监督下实现了结构一致和语义基础的表示，展示了卓越的跨任务迁移和跨域泛化能力。

Abstract: Vision-language models (VLMs) have demonstrated strong cross-modal
capabilities, yet most work remains limited to 2D data and assumes binary
supervision (i.e., positive vs. negative pairs), overlooking the continuous and
structured dependencies present in volumetric data such as CT. Existing
approaches often treat volumetric scans as independent 2D slices, compromising
spatial coherence and underutilizing rich clinical semantics. We propose
SCALE-VLP, a soft-weighted contrastive vision-language pre-training framework
that integrates (i) volumetric spatial semantics to preserve anatomical
structure and (ii) domain-aware, knowledge-infused semantics (e.g.,
radiological ontologies) to guide alignment. This yields structurally
consistent and semantically grounded representations under limited supervision,
demonstrating strong cross-task transferability (retrieval, report generation,
and classification), and cross-domain generalizability with consistent gains
without further fine-tuning. In particular, compared to the previous state of
the art, SCALE-VLP achieves up to 4.3x higher top-1 CT-report retrieval,
improves abnormality classification by 10 points, and reaches ROUGE-L 0.44 and
BERT-F1 0.89 for report generation. Further, in zero-shot evaluation on an
out-of-domain external dataset, we observe consistent gains, indicating the
cross-task and cross-domain generalization ability of SCALE-VLP.

</details>


### [7] [Learning with less: label-efficient land cover classification at very high spatial resolution using self-supervised deep learning](https://arxiv.org/abs/2511.03004)
*Dakota Hester,Vitor S. Martins,Lucas B. Ferreira,Thainara M. A. Lima*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的标签高效方法，仅使用1000个标注的图像片段，结合自监督学习，实现了高准确度的1米土地覆盖分类，展示了自监督学习在降低对大量已标注数据需求方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于收集大量具有代表性的训练数据的挑战，本研究旨在实现州级1米土地覆盖分类，为高空间分辨率土地覆盖制图的广泛应用提供解决方案。

Method: 采用自监督深度学习的方法，通过仅使用1000个标注的参考图像片段，结合大量未标注的彩色红外航空图像进行预训练，再将学习到的编码器权重迁移到多种深度语义分割架构中进行微调。

Result: 使用最佳表现的U-Net模型集成，我们在密西西比州的土地覆盖映射中获得了87.14%的整体准确率和75.58%的宏F1得分，涵盖超过1230亿个像素，准确地映射了开放水域和森林区域，并揭示了农田、草本和荒地类型之间准确划分的挑战。

Conclusion: 本研究表明，自监督学习是减少对大量手动注释数据需求的有效策略，直接解决了大规模高空间分辨率土地覆盖制图的主要限制。

Abstract: Deep learning semantic segmentation methods have shown promising performance
for very high 1-m resolution land cover classification, but the challenge of
collecting large volumes of representative training data creates a significant
barrier to widespread adoption of such models for meter-scale land cover
mapping over large areas. In this study, we present a novel label-efficient
approach for statewide 1-m land cover classification using only 1,000 annotated
reference image patches with self-supervised deep learning. We use the
"Bootstrap Your Own Latent" pre-training strategy with a large amount of
unlabeled color-infrared aerial images (377,921 256x256 1-m pixel patches) to
pre-train a ResNet-101 convolutional encoder. The learned encoder weights were
subsequently transferred into multiple deep semantic segmentation architectures
(FCN, U-Net, Attention U-Net, DeepLabV3+, UPerNet, PAN), which were then
fine-tuned using very small training dataset sizes with cross-validation (250,
500, 750 patches). Among the fine-tuned models, we obtained the 87.14% overall
accuracy and 75.58% macro F1 score using an ensemble of the best performing
U-Net models for comprehensive 1-m, 8-class land cover mapping, covering more
than 123 billion pixels over the state of Mississippi, USA. Detailed
qualitative and quantitative analysis revealed accurate mapping of open water
and forested areas, while highlighting challenges in accurate delineation
between cropland, herbaceous, and barren land cover types. These results show
that self-supervised learning is an effective strategy for reducing the need
for large volumes of manually annotated data, directly addressing a major
limitation to high spatial resolution land cover mapping at scale.

</details>


### [8] [A Foundation Model for Brain MRI with Dynamic Modality Integration](https://arxiv.org/abs/2511.03014)
*Minh Sao Khue Luu,Bair N. Tuchinov*

Main category: cs.CV

TL;DR: 该文提出了一种新型脑部MRI基础模型，具有适应不同成像序列的能力，初步结果显示效果良好，后续将进行更详细的性能研究。


<details>
  <summary>Details</summary>
Motivation: 旨在创建一个单一模型，处理不同模态的脑部MRI，以增强表征多样性并适应缺失或未见的成像序列。

Method: 使用了一种编码器与可学习的模态嵌入、条件层归一化和掩码自编码目标，搭配方差-协方差正则化器以稳定特征学习。

Result: 初步结果显示该方法可行，并计划进行更多实验以深入研究其性能。

Conclusion: 该模型在脑部MRI图像处理中的表现良好，并具备适应多种成像序列的能力。

Abstract: We present a foundation model for brain MRI that can work with different
combinations of imaging sequences. The model uses one encoder with learnable
modality embeddings, conditional layer normalization, and a masked autoencoding
objective that accounts for missing modalities. A variance-covariance
regularizer is applied to stabilize feature learning and improve representation
diversity. This design removes the need for separate models for each modality
and allows the network to adapt when some sequences are missing or unseen. It
is trained on about 60,000 multi-center MRIs using self-supervised
reconstruction and modality imputation to learn flexible representations. A
learnable modality embedding guides feature extraction so the encoder can
adjust to different inputs. We describe our planned evaluation on brain tumor
and multiple sclerosis segmentation, as well as lesion classification, under
various modality settings. Preliminary results show that the method works
feasibly, and further experiments are planned to study its performance in more
detail. All code and pretrained models are available at
https://github.com/BrainFM/brainfm

</details>


### [9] [SLIP: Structural-aware Language-Image Pretraining for Vision-Language Alignment](https://arxiv.org/abs/2511.03019)
*Wenbo Lu*

Main category: cs.CV

TL;DR: SLIP通过结构对比损失和大规模数据集，提升了跨模态检索和分类任务的性能。


<details>
  <summary>Details</summary>
Motivation: 借鉴神经科学的证据，探讨人类如何将知识编码为关系认知图，提升VLP的效果。

Method: 引入结构对比损失，以对齐模态并建模结构图中相邻实体之间的关系。

Result: 在大规模亚马逊产品共购多模态图数据集上进行实验，SLIP在零样本和少样本设置中均表现最佳。

Conclusion: SLIP在跨模态检索和分类任务中超越了CLIP，展现了关系监督在跨模态对齐中的重要性。

Abstract: Vision-Language Pretraining (VLP) has achieved remarkable success across
various downstream tasks, but such gains are largely driven by scaling up on
training data. Yet, literature methods treat image-text pairs as isolated
training examples; this neglects the rich relational structure naturally
present in many domains, such as e-commerce product co-purchase graphs and
social recommendation networks. Inspired by neuroscientific evidence that human
encodes knowledge as relationship cognitive maps, we introduce Structure-aware
Language-Image Pretraining (SLIP). SLIP integrates a structural contrastive
loss to align modalities while also modeling relationships between neighboring
entities in a structured graph. To support this paradigm, we construct a
large-scale Amazon Product Co-purchase Multimodal Graph Dataset, enabling
structured cross-modality supervision at scale. Experiment results show that
SLIP consistently outperforms CLIP on cross-modal retrieval and classification
tasks in both zero-shot and few-shot settings, showing the value of relational
supervision for cross-modal alignment.

</details>


### [10] [From Propagation to Prediction: Point-level Uncertainty Evaluation of MLS Point Clouds under Limited Ground Truth](https://arxiv.org/abs/2511.03053)
*Ziyang Xu,Olaf Wysocki,Christoph Holst*

Main category: cs.CV

TL;DR: 本研究提出了一种新的学习基础框架用于移动激光扫描点云的不确定性评估，展示了几何特征在点级不确定性预测中的有效性，并显著提高了效率。


<details>
  <summary>Details</summary>
Motivation: 在高精度应用中，如扫描到BIM和变形分析，评估不确定性至关重要，但实际获取地面真实值往往成本高且不可行，因此迫切需要一种新的评估方法。

Method: 本研究提出了一种基于学习的框架，集成了最优邻域估计和几何特征提取，以便在高精度应用中减少对地面真实值的依赖。

Result: 实验结果表明，所提出的框架在真实数据集上可行，XGBoost模型的准确性与随机森林模型相当，而效率提高了约3倍，初步证据表明几何特征可以预测通过C2C距离量化的点级不确定性。

Conclusion: 本研究展示了移动激光扫描点云的不确定性是可以通过学习来评估的，为不确定性评估研究提供了一种新的学习基础视角。

Abstract: Evaluating uncertainty is critical for reliable use of Mobile Laser Scanning
(MLS) point clouds in many high-precision applications such as Scan-to-BIM,
deformation analysis, and 3D modeling. However, obtaining the ground truth (GT)
for evaluation is often costly and infeasible in many real-world applications.
To reduce this long-standing reliance on GT in uncertainty evaluation research,
this study presents a learning-based framework for MLS point clouds that
integrates optimal neighborhood estimation with geometric feature extraction.
Experiments on a real-world dataset show that the proposed framework is
feasible and the XGBoost model delivers fully comparable accuracy to Random
Forest while achieving substantially higher efficiency (about 3 times faster),
providing initial evidence that geometric features can be used to predict
point-level uncertainty quantified by the C2C distance. In summary, this study
shows that MLS point clouds' uncertainty is learnable, offering a novel
learning-based viewpoint towards uncertainty evaluation research.

</details>


### [11] [ISC-Perception: A Hybrid Computer Vision Dataset for Object Detection in Novel Steel Assembly](https://arxiv.org/abs/2511.03098)
*Miftahur Rahman,Samuel Adebayo,Dorian A. Acevedo-Mejia,David Hester,Daniel McPolin,Karen Rafferty,Debra F. Laefer*

Main category: cs.CV

TL;DR: ISC-Perception是专为ISC组件检测设计的混合数据集，结合了多种图像源，显著提高了建筑机器人视觉系统的性能并减少了人工标注时间。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏专门的图像库和在建筑工地收集照片的实际困难，本研究旨在填补建筑机器人感知领域的数据空缺。

Method: 我们创建了一个混合数据集ISC-Perception，结合了程序渲染的CAD图像、游戏引擎渲染的真实场景以及有限的真实照片，使用自动标记的方法生成数据。

Result: 通过在ISC-Perception上训练的检测器达到了最高0.943的mAP，超越了传统合成数据和真实数据训练的模型，验证了该数据集的有效性。

Conclusion: ISC-Perception数据集的引入显著提升了建筑机器人中的物体检测性能，并通过减少人力消耗和提高检测精度来加速定制检测器的发展。

Abstract: The Intermeshed Steel Connection (ISC) system, when paired with robotic
manipulators, can accelerate steel-frame assembly and improve worker safety by
eliminating manual assembly. Dependable perception is one of the initial stages
for ISC-aware robots. However, this is hampered by the absence of a dedicated
image corpus, as collecting photographs on active construction sites is
logistically difficult and raises safety and privacy concerns. In response, we
introduce ISC-Perception, the first hybrid dataset expressly designed for ISC
component detection. It blends procedurally rendered CAD images, game-engine
photorealistic scenes, and a limited, curated set of real photographs, enabling
fully automatic labelling of the synthetic portion. We explicitly account for
all human effort to produce the dataset, including simulation engine and scene
setup, asset preparation, post-processing scripts and quality checks; our total
human time to generate a 10,000-image dataset was 30.5,h versus 166.7,h for
manual labelling at 60,s per image (-81.7%). A manual pilot on a representative
image with five instances of ISC members took 60,s (maximum 80,s), anchoring
the manual baseline. Detectors trained on ISC-Perception achieved a mean
Average Precision at IoU 0.50 of 0.756, substantially surpassing models trained
on synthetic-only or photorealistic-only data. On a 1,200-frame bench test, we
report mAP@0.50/mAP@[0.50:0.95] of 0.943/0.823. By bridging the data gap for
construction-robotics perception, ISC-Perception facilitates rapid development
of custom object detectors and is freely available for research and industrial
use upon request.

</details>


### [12] [DentalSplat: Dental Occlusion Novel View Synthesis from Sparse Intra-Oral Photographs](https://arxiv.org/abs/2511.03099)
*Yiyi Miao,Taoyu Wu,Tong Chen,Sihao Li,Ji Jiang,Youpeng Yang,Angelos Stefanidis,Limin Yu,Jionglong Su*

Main category: cs.CV

TL;DR: 本研究提出了DentalSplat框架，解决正畸影像中的3D重建挑战，并在质量上超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决传统3D重建方法在稀疏正畸影像中面临的重建质量和相机位姿缺失问题。

Method: 利用先验引导的密集立体重建模型初始化点云，结合规模自适应修剪策略和光流几何约束，提升训练效率和重建质量。

Result: 在950个临床案例和195个视频测试集上验证，方法在稀疏视角下有效处理，并显著提高了正畸效果的可视化质量。

Conclusion: DentalSplat在稀疏正畸影像的3D重建中表现出色，超越了现有技术。

Abstract: In orthodontic treatment, particularly within telemedicine contexts,
observing patients' dental occlusion from multiple viewpoints facilitates
timely clinical decision-making. Recent advances in 3D Gaussian Splatting
(3DGS) have shown strong potential in 3D reconstruction and novel view
synthesis. However, conventional 3DGS pipelines typically rely on densely
captured multi-view inputs and precisely initialized camera poses, limiting
their practicality. Orthodontic cases, in contrast, often comprise only three
sparse images, specifically, the anterior view and bilateral buccal views,
rendering the reconstruction task especially challenging. The extreme sparsity
of input views severely degrades reconstruction quality, while the absence of
camera pose information further complicates the process. To overcome these
limitations, we propose DentalSplat, an effective framework for 3D
reconstruction from sparse orthodontic imagery. Our method leverages a
prior-guided dense stereo reconstruction model to initialize the point cloud,
followed by a scale-adaptive pruning strategy to improve the training
efficiency and reconstruction quality of 3DGS. In scenarios with extremely
sparse viewpoints, we further incorporate optical flow as a geometric
constraint, coupled with gradient regularization, to enhance rendering
fidelity. We validate our approach on a large-scale dataset comprising 950
clinical cases and an additional video-based test set of 195 cases designed to
simulate real-world remote orthodontic imaging conditions. Experimental results
demonstrate that our method effectively handles sparse input scenarios and
achieves superior novel view synthesis quality for dental occlusion
visualization, outperforming state-of-the-art techniques.

</details>


### [13] [Image-Intrinsic Priors for Integrated Circuit Defect Detection and Novel Class Discovery via Self-Supervised Learning](https://arxiv.org/abs/2511.03120)
*Botong. Zhao,Xubin. Wang,Shujing. Lyu,Yue. Lu*

Main category: cs.CV

TL;DR: 提出了一种无监督的缺陷检测和分类框架IC DefectNCD，利用图像内在先验来增强缺陷识别与分类能力。


<details>
  <summary>Details</summary>
Motivation: 集成电路制造过程复杂，缺陷可在任何阶段发生，导致产量损失和产品可靠性下降，因此需要一种有效的缺陷检测和分类方法。

Method: 通过自normal信息引导的缺陷检测和自缺陷信息引导的缺陷分类的支持设置框架，结合图像内在先验进行缺陷检测和新类别发现。

Result: 在涵盖三个关键制造阶段和15种缺陷类型的真实数据集上进行验证，实验结果证明了该方法在缺陷检测和分类方面的有效性。

Conclusion: 该方法在缺陷检测和未见缺陷分类上表现出稳健的性能。

Abstract: Integrated circuit manufacturing is highly complex, comprising hundreds of
process steps. Defects can arise at any stage, causing yield loss and
ultimately degrading product reliability. Supervised methods require extensive
human annotation and struggle with emergent categories and rare, data scarce
defects. Clustering-based unsupervised methods often exhibit unstable
performance due to missing priors. We propose IC DefectNCD, a support set free
framework that leverages Image Intrinsic Priors in IC SEM images for defect
detection and novel class discovery. We first develop Self Normal Information
Guided IC Defect Detection, aggregating representative normal features via a
learnable normal information extractor and using reconstruction residuals to
coarsely localize defect regions. To handle saliency variations across defects,
we introduce an adaptive binarization strategy that produces stable subimages
focused on core defective areas. Finally, we design Self Defect Information
Guided IC Defect Classification, which incorporates a soft mask guided
attention mechanism to inject spatial defect priors into the teacher student
model. This enhances sensitivity to defective regions, suppresses background
interference, and enables recognition and classification of unseen defects. We
validate the approach on a real world dataset spanning three key fabrication
stages and covering 15 defect types. Experiments demonstrate robust performance
on both defect detection and unseen defect classification.

</details>


### [14] [Accelerating Physical Property Reasoning for Augmented Visual Cognition](https://arxiv.org/abs/2511.03126)
*Hongbo Lan,Zhenlin An,Haoyu Li,Vaibhav Singh,Longfei Shangguan*

Main category: cs.CV

TL;DR: 
sysname通过多种优化显著加速了物理属性推理，并在复杂场景中提供准确的物体属性估计。


<details>
  <summary>Details</summary>
Motivation: 提升物理属性推理的实时性和准确性，尤其在复杂的真实场景下，如存储家具环境中，使用智能眼镜提供物理属性估计。

Method: 通过快速的几何3D重建、有效的语义特征融合和并行视图编码等算法和系统优化，加速视觉引导的物理属性推理流程。

Result: 
sysname在ABO数据集上的对比研究表明其在推理管道的端到端延迟上实现了62.9$	imes$到287.2$	imes$的加速，与传统基线相比，在物体级物理属性估计、材料分割和体素级推理上表现优异。

Conclusion: 
sysname在现实场景中通过结合注视追踪技术，为物理属性推理提供了高效、准确的解决方案，尤其适用于智能眼镜等设备。

Abstract: This paper introduces \sysname, a system that accelerates vision-guided
physical property reasoning to enable augmented visual cognition. \sysname
minimizes the run-time latency of this reasoning pipeline through a combination
of both algorithmic and systematic optimizations, including rapid geometric 3D
reconstruction, efficient semantic feature fusion, and parallel view encoding.
Through these simple yet effective optimizations, \sysname reduces the
end-to-end latency of this reasoning pipeline from 10--20 minutes to less than
6 seconds. A head-to-head comparison on the ABO dataset shows that \sysname
achieves this 62.9$\times$--287.2$\times$ speedup while not only reaching
on-par (and sometimes slightly better) object-level physical property
estimation accuracy(e.g. mass), but also demonstrating superior performance in
material segmentation and voxel-level inference than two SOTA baselines. We
further combine gaze-tracking with \sysname to localize the object of interest
in cluttered, real-world environments, streamlining the physical property
reasoning on smart glasses. The case study with Meta Aria Glasses conducted at
an IKEA furniture store demonstrates that \sysname achives consistently high
performance compared to controlled captures, providing robust property
estimations even with fewer views in real-world scenarios.

</details>


### [15] [Deploying Rapid Damage Assessments from sUAS Imagery for Disaster Response](https://arxiv.org/abs/2511.03132)
*Thomas Manzini,Priyankari Perali,Robin R. Murphy*

Main category: cs.CV

TL;DR: 本文介绍了第一个用于自动化建筑损坏评估的AI/ML系统，成功应用于灾后响应，显著提高了评估效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决灾害现场图像数据量巨大造成的响应延迟问题，提出使用计算机视觉和机器学习技术来自动化建筑损坏评估。

Method: 开发和部署了基于sUAS影像的建筑损坏评估模型，通过训练包含21716个建筑损坏标签的最大数据集和91名灾害从业人员的操作培训。

Result: 在Hurricanes Debby和Helene的响应中，最佳模型被成功部署，能在大约18分钟内评估415栋建筑。

Conclusion: 本研究展示了AI/ML在灾后建筑损坏评估中的实际应用，提供了宝贵的经验和教训。

Abstract: This paper presents the first AI/ML system for automating building damage
assessment in uncrewed aerial systems (sUAS) imagery to be deployed
operationally during federally declared disasters (Hurricanes Debby and
Helene). In response to major disasters, sUAS teams are dispatched to collect
imagery of the affected areas to assess damage; however, at recent disasters,
teams collectively delivered between 47GB and 369GB of imagery per day,
representing more imagery than can reasonably be transmitted or interpreted by
subject matter experts in the disaster scene, thus delaying response efforts.
To alleviate this data avalanche encountered in practice, computer vision and
machine learning techniques are necessary. While prior work has been deployed
to automatically assess damage in satellite imagery, there is no current state
of practice for sUAS-based damage assessment systems, as all known work has
been confined to academic settings. This work establishes the state of practice
via the development and deployment of models for building damage assessment
with sUAS imagery. The model development involved training on the largest known
dataset of post-disaster sUAS aerial imagery, containing 21,716 building damage
labels, and the operational training of 91 disaster practitioners. The best
performing model was deployed during the responses to Hurricanes Debby and
Helene, where it assessed a combined 415 buildings in approximately 18 minutes.
This work contributes documentation of the actual use of AI/ML for damage
assessment during a disaster and lessons learned to the benefit of the AI/ML
research and user communities.

</details>


### [16] [Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation](https://arxiv.org/abs/2511.03163)
*Yun-Chen Lin,Jiayuan Huang,Hanyuan Zhang,Sergi Kavtaradze,Matthew J. Clarkson,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: 本文提出了一种深度引导的肝脏标志物分割框架，通过SRFT-GaLore方法增强现有模型，实现了在外科手术中的精确分割。


<details>
  <summary>Details</summary>
Motivation: 在腹腔镜肝脏手术中，2D视频流限制了深度感知和地标定位的准确性，因此需要一种新方法来增强肝脏结构的检测和分割。

Method: 提出了一种深度引导的肝脏标志物分割框架，集成了语义和几何线索，采用Segment Anything Model V2和Depth Anything V2编码器，以SRFT-GaLore进行高效调优。

Result: 在公共L3D数据集上，我们的方法相较于D2GPLand取得了4.85%的Dice相似系数提升和11.78的对称表面距离降低，且在LLSD数据集上也保持了竞争力表现，超越了基于SAM的基线。

Conclusion: 我们的SRFT-GaLore增强双编码框架在实时、深度受限的外科环境下实现了可扩展和精确的分割，展现了强大的跨数据集鲁棒性和适应能力。

Abstract: Accurate detection and delineation of anatomical structures in medical
imaging are critical for computer-assisted interventions, particularly in
laparoscopic liver surgery where 2D video streams limit depth perception and
complicate landmark localization. While recent works have leveraged monocular
depth cues for enhanced landmark detection, challenges remain in fusing RGB and
depth features and in efficiently adapting large-scale vision models to
surgical domains. We propose a depth-guided liver landmark segmentation
framework integrating semantic and geometric cues via vision foundation
encoders. We employ Segment Anything Model V2 (SAM2) encoder to extract RGB
features and Depth Anything V2 (DA2) encoder to extract depth-aware features.
To efficiently adapt SAM2, we introduce SRFT-GaLore, a novel low-rank gradient
projection method that replaces the computationally expensive SVD with a
Subsampled Randomized Fourier Transform (SRFT). This enables efficient
fine-tuning of high-dimensional attention layers without sacrificing
representational power. A cross-attention fusion module further integrates RGB
and depth cues. To assess cross-dataset generalization, we also construct a new
Laparoscopic Liver Surgical Dataset (LLSD) as an external validation benchmark.
On the public L3D dataset, our method achieves a 4.85% improvement in Dice
Similarity Coefficient and a 11.78-point reduction in Average Symmetric Surface
Distance compared to the D2GPLand. To further assess generalization capability,
we evaluate our model on LLSD dataset. Our model maintains competitive
performance and significantly outperforms SAM-based baselines, demonstrating
strong cross-dataset robustness and adaptability to unseen surgical
environments. These results demonstrate that our SRFT-GaLore-enhanced
dual-encoder framework enables scalable and precise segmentation under
real-time, depth-constrained surgical settings.

</details>


### [17] [SurgAnt-ViVQA: Learning to Anticipate Surgical Events through GRU-Driven Temporal Cross-Attention](https://arxiv.org/abs/2511.03178)
*Shreyas C. Dhake,Jiayuan Huang,Runlong He,Danyal Z. Khan,Evangelos B. Mazomenos,Sophia Bano,Hani J. Marcus,Danail Stoyanov,Matthew J. Clarkson,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: PitVQA-Anticipation是首个针对外科前瞻性推理的数据集，SurgAnt-ViVQA模型实现了从描述到预测的转变，强调时序建模对外科辅助的重要性。


<details>
  <summary>Details</summary>
Motivation: 在可视性有限且工作流程快速变化的内镜下经蝶窦垂体手术中，预测即将发生的外科事件对于实时辅助至关重要，因此需要针对未来的视觉问答系统。

Method: 提出了SurgAnt-ViVQA，利用GRU门控时序交叉注意力模块适应大型语言模型，并通过双向GRU编码帧间动态，结合自适应门控在语言流中注入视觉上下文进行精细调优，以适应外科领域。

Result: 通过在PitVQA-Anticipation和EndoVis数据集上的测试，SurgAnt-ViVQA超越了强大的基于图像和视频的基准，时间递归和门控融合是性能提升的关键因素。

Conclusion: PitVQA-Anticipation提供了面向未来的外科推理基准，通过SurgAnt-ViVQA模型，推动了外科视觉问答从回顾性描述到主动预测的进步，强调了针对时序建模的重要性，以实现可靠的未来感知外科辅助。

Abstract: Anticipating forthcoming surgical events is vital for real-time assistance in
endonasal transsphenoidal pituitary surgery, where visibility is limited and
workflow changes rapidly. Most visual question answering (VQA) systems reason
on isolated frames with static vision language alignment, providing little
support for forecasting next steps or instrument needs. Existing surgical VQA
datasets likewise center on the current scene rather than the near future. We
introduce PitVQA-Anticipation, the first VQA dataset designed for forward
looking surgical reasoning. It comprises 33.5 hours of operative video and
734,769 question answer pairs built from temporally grouped clips and expert
annotations across four tasks: predicting the future phase, next step, upcoming
instrument, and remaining duration. We further propose SurgAnt-ViVQA, a video
language model that adapts a large language model using a GRU Gated Temporal
Cross-Attention module. A bidirectional GRU encodes frame to frame dynamics,
while an adaptive gate injects visual context into the language stream at the
token level. Parameter efficient fine tuning customizes the language backbone
to the surgical domain. SurgAnt-ViVQA tested upon on PitVQA-Anticipation and
EndoVis datasets, surpassing strong image and video based baselines. Ablations
show that temporal recurrence and gated fusion drive most of the gains. A frame
budget study indicates a trade-off: 8 frames maximize fluency, whereas 32
frames slightly reduce BLEU but improve numeric time estimation. By pairing a
temporally aware encoder with fine grained gated cross-attention, SurgAnt-ViVQA
advances surgical VQA from retrospective description to proactive anticipation.
PitVQA-Anticipation offers a comprehensive benchmark for this setting and
highlights the importance of targeted temporal modeling for reliable, future
aware surgical assistance.

</details>


### [18] [PETWB-REP: A Multi-Cancer Whole-Body FDG PET/CT and Radiology Report Dataset for Medical Imaging Research](https://arxiv.org/abs/2511.03194)
*Le Xue,Gang Feng,Wenbo Zhang,Yichi Zhang,Lanlan Li,Shuqi Wang,Liling Peng,Sisi Peng,Xin Gao*

Main category: cs.CV

TL;DR: PETWB-REP是一个包含490名癌症患者的PET/CT影像及报告的大规模数据集，旨在促进医学影像及AI领域的研究。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏结合功能和解剖影像的详细临床报告的数据集，因此需要一个能够支持多种癌症类型研究的数据集。

Method: 针对490名不同癌症患者进行的全身18F-FDG PET/CT扫描数据和相应的放射学报告的整理和归档。

Result: 该数据集包含配对的PET和CT影像、去标识化的文本报告及结构化的临床元数据，覆盖常见癌症。

Conclusion: PETWB-REP是一个大规模的医学影像数据集，旨在促进医学影像、放射组学和人工智能研究。

Abstract: Publicly available, large-scale medical imaging datasets are crucial for
developing and validating artificial intelligence models and conducting
retrospective clinical research. However, datasets that combine functional and
anatomical imaging with detailed clinical reports across multiple cancer types
remain scarce. Here, we present PETWB-REP, a curated dataset comprising
whole-body 18F-Fluorodeoxyglucose (FDG) Positron Emission Tomography/Computed
Tomography (PET/CT) scans and corresponding radiology reports from 490 patients
diagnosed with various malignancies. The dataset primarily includes common
cancers such as lung cancer, liver cancer, breast cancer, prostate cancer, and
ovarian cancer. This dataset includes paired PET and CT images, de-identified
textual reports, and structured clinical metadata. It is designed to support
research in medical imaging, radiomics, artificial intelligence, and
multi-modal learning.

</details>


### [19] [QG-CoC: Question-Guided Chain-of-Captions for Large Multimodal Models](https://arxiv.org/abs/2511.03206)
*Kuei-Chun Kao,Hsu Tzu-Yin,Yunqi Hong,Ruochen Wang,Cho-Jui Hsieh*

Main category: cs.CV

TL;DR: 本文研究当前多图像推理中的提示方法缺陷，并提出新的提示方法QG-CoC，显著提升多图像推理能力。


<details>
  <summary>Details</summary>
Motivation: 针对当前多图像推理任务中MLLMs面临的细粒度感知缺失和推理能力下降的问题，填补在复杂多图像推理任务中的关键知识空白。

Method: 对现有提示方法进行广泛研究，并提出一种新的零-shot提示方法QG-CoC。

Result: QG-CoC在多图像和单图像基准测试中对多种MLLMs进行评估，结果表明该方法在任务上表现良好，并在现有方法失败的场景中有显著改进。

Conclusion: 提出的QG-CoC方法在处理多图像推理任务中具有竞争力的表现，并在现有提示方法失败的情况下显示出显著改进。

Abstract: Recently, Multimodal Large Language Models (MLLMs) encounter two key issues
in multi-image contexts: (1) a lack of fine-grained perception across disparate
images, and (2) a diminished capability to effectively reason over and
synthesize information from multiple visual inputs. However, while various
prompting methods aim to describe visual content, many existing studies focus
primarily on single-image settings or specific, constrained scenarios. This
leaves a critical gap in understanding and addressing how MLLMs tackle more
general and complex multi-image reasoning tasks. Thus, we first extensively
investigate how current prompting methods perceive fine-grained visual details
and process visual information when dealing with multiple images. Our findings
reveal that existing prompting methods fall short in attending to needed clues
and seamlessly integrating perception and reasoning. Inspired by the findings,
we propose a new zero-shot prompting method, Question-Guided Chain-of-Captions
(QG-CoC), a generalized prompting approach that effectively handles problems
with an arbitrary number of images. We evaluate our method on various
open-source and closed-source MLLMs for multi-image and single-image
benchmarks. Experimental results indicate that QG-CoC demonstrates competitive
performance across tasks and exhibits robust improvements in the challenging
scenarios where existing prompting methods fail.

</details>


### [20] [Diffusion-Guided Mask-Consistent Paired Mixing for Endoscopic Image Segmentation](https://arxiv.org/abs/2511.03219)
*Pengyu Jie,Wanquan Liu,Rui He,Yihui Wen,Deyu Meng,Chenqiang Gao*

Main category: cs.CV

TL;DR: 提出了一种新颖的配对扩散引导增强方法，结合真实和合成图像的优点，提高了内窥镜图像的分割性能，展现出更强的多样性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的密集预测增强方法要么依赖样本混合，要么依赖生成合成，但各自存在缺陷；因此需要一种新的方法融合两者优势。

Method: 提出了一种配对的、扩散引导的范式，使用真实图像和生成的合成图像配对，进行掩膜一致的配对混合（MCPMix）。

Result: 该方法在多项数据集（Kvasir-SEG，PICCOLO，CVC-ClinicDB，私人NPC-LES队列和ISIC 2017）上达到了最先进的分割性能，并在基准测试中持续取得提升。

Conclusion: 结合标签保护混合、基于扩散的多样性和自适应重新锚定的方法，能实现稳健且具可推广性的内窥镜分割。

Abstract: Augmentation for dense prediction typically relies on either sample mixing or
generative synthesis. Mixing improves robustness but misaligned masks yield
soft label ambiguity. Diffusion synthesis increases apparent diversity but,
when trained as common samples, overlooks the structural benefit of mask
conditioning and introduces synthetic-real domain shift. We propose a paired,
diffusion-guided paradigm that fuses the strengths of both. For each real
image, a synthetic counterpart is generated under the same mask and the pair is
used as a controllable input for Mask-Consistent Paired Mixing (MCPMix), which
mixes only image appearance while supervision always uses the original hard
mask. This produces a continuous family of intermediate samples that smoothly
bridges synthetic and real appearances under shared geometry, enlarging
diversity without compromising pixel-level semantics. To keep learning aligned
with real data, Real-Anchored Learnable Annealing (RLA) adaptively adjusts the
mixing strength and the loss weight of mixed samples over training, gradually
re-anchoring optimization to real data and mitigating distributional bias.
Across Kvasir-SEG, PICCOLO, CVC-ClinicDB, a private NPC-LES cohort, and ISIC
2017, the approach achieves state-of-the-art segmentation performance and
consistent gains over baselines. The results show that combining
label-preserving mixing with diffusion-driven diversity, together with adaptive
re-anchoring, yields robust and generalizable endoscopic segmentation.

</details>


### [21] [Transformer-Progressive Mamba Network for Lightweight Image Super-Resolution](https://arxiv.org/abs/2511.03232)
*Sichen Guo,Wenjie Li,Yuanyang Liu,Guangwei Gao,Jian Yang,Chia-Wen Lin*

Main category: cs.CV

TL;DR: T-PMambaSR 是一种轻量级超分辨率框架，通过窗口自注意力与渐进式 Mamba 整合，克服细粒度建模不足，以线性复杂度显著提高特征表示的效率和表现。


<details>
  <summary>Details</summary>
Motivation: 解决现有 Mamba 基础方法在不同建模尺度间缺乏细粒度过渡的问题，从而提高特征表示效率。

Method: 提出了一种轻量级的超分辨率框架，整合窗口自注意力与渐进式 Mamba， enabling不同尺度接收场之间的交互。

Result: 经过广泛实验验证，T-PMambaSR 模型的接收场和表现力随着训练逐步增强，达到比最近的 Transformer 或 Mamba 基础方法更好的性能。

Conclusion: T-PMambaSR 凭借线性复杂度的逐步增强特征表示，表现优于现有的 Transformer 或 Mamba 基础方法，同时降低了计算成本。

Abstract: Recently, Mamba-based super-resolution (SR) methods have demonstrated the
ability to capture global receptive fields with linear complexity, addressing
the quadratic computational cost of Transformer-based SR approaches. However,
existing Mamba-based methods lack fine-grained transitions across different
modeling scales, which limits the efficiency of feature representation. In this
paper, we propose T-PMambaSR, a lightweight SR framework that integrates
window-based self-attention with Progressive Mamba. By enabling interactions
among receptive fields of different scales, our method establishes a
fine-grained modeling paradigm that progressively enhances feature
representation with linear complexity. Furthermore, we introduce an Adaptive
High-Frequency Refinement Module (AHFRM) to recover high-frequency details lost
during Transformer and Mamba processing. Extensive experiments demonstrate that
T-PMambaSR progressively enhances the model's receptive field and
expressiveness, yielding better performance than recent Transformer- or
Mamba-based methods while incurring lower computational cost. Our codes will be
released after acceptance.

</details>


### [22] [Decoupled Multi-Predictor Optimization for Inference-Efficient Model Tuning](https://arxiv.org/abs/2511.03245)
*Liwei Luo,Shuaitengyuan Li,Dongwei Ren,Qilong Wang,Pengfei Zhu,Qinghua Hu*

Main category: cs.CV

TL;DR: DMPO方法通过解耦早期阶段的表现能力和区分能力，提高了推理效率，并在多个实验中表现优越。


<details>
  <summary>Details</summary>
Motivation: 随着大规模预训练模型调优的进展，推理效率在实际部署中变得日益重要。

Method: 提出了一种轻量级的旁路模块和高阶统计预测器，通过多阶段预测器的功能分解和解耦优化分配损失权重。

Result: DMPO在多个数据集和预训练基础上进行实验，结果显示其在减少计算成本方面显著优于其他对比方法。

Conclusion: DMPO方法通过架构设计和模型优化有效地解耦了早期阶段的表现能力和区分能力，从而在降低计算成本方面明显优于其他方法。

Abstract: Recently, remarkable progress has been made in large-scale pre-trained model
tuning, and inference efficiency is becoming more crucial for practical
deployment. Early exiting in conjunction with multi-stage predictors, when
cooperated with a parameter-efficient fine-tuning strategy, offers a
straightforward way to achieve an inference-efficient model. However, a key
challenge remains unresolved: How can early stages provide low-level
fundamental features to deep stages while simultaneously supplying high-level
discriminative features to early-stage predictors? To address this problem, we
propose a Decoupled Multi-Predictor Optimization (DMPO) method to effectively
decouple the low-level representative ability and high-level discriminative
ability in early stages. First, in terms of architecture, we introduce a
lightweight bypass module into multi-stage predictors for functional
decomposition of shallow features from early stages, while a high-order
statistics-based predictor is developed for early stages to effectively enhance
their discriminative ability. To reasonably train our multi-predictor
architecture, a decoupled optimization is proposed to allocate two-phase loss
weights for multi-stage predictors during model tuning, where the initial
training phase enables the model to prioritize the acquisition of
discriminative ability of deep stages via emphasizing representative ability of
early stages, and the latter training phase drives discriminative ability
towards earlier stages as much as possible. As such, our DMPO can effectively
decouple representative and discriminative abilities in early stages in terms
of architecture design and model optimization. Experiments across various
datasets and pre-trained backbones demonstrate that DMPO clearly outperforms
its counterparts when reducing computational cost.

</details>


### [23] [Enhancing Medical Image Segmentation via Heat Conduction Equation](https://arxiv.org/abs/2511.03260)
*Rong Wu,Yim-Sang Yu*

Main category: cs.CV

TL;DR: 研究提出了一种新型混合架构，结合热传导方程以改进医学图像分割效果，并在实验中取得了优于现有模型的表现。


<details>
  <summary>Details</summary>
Motivation: 当前医学图像分割模型在全局上下文建模和长距离依赖推理方面的效率不足。

Method: 使用基于Mamba的状态空间模块进行长距离推理，并在瓶颈层中结合热传导算子。

Result: 在多模态腹部CT和MRI数据集上的实验结果显示，所提模型优于多个强基线，验证了其有效性和泛化能力。

Conclusion: 提出的混合架构U-Mamba结合热传导方程可以有效提升医学图像分割的性能。

Abstract: Medical image segmentation has been significantly advanced by deep learning
architectures, notably U-Net variants. However, existing models struggle to
achieve efficient global context modeling and long-range dependency reasoning
under practical computational budgets simultaneously. In this work, we propose
a novel hybrid architecture utilizing U-Mamba with Heat Conduction Equation.
Our model combines Mamba-based state-space modules for efficient long-range
reasoning with Heat Conduction Operators (HCOs) in the bottleneck layers,
simulating frequency-domain thermal diffusion for enhanced semantic
abstraction. Experimental results on multimodal abdominal CT and MRI datasets
demonstrate that the proposed model consistently outperforms strong baselines,
validating its effectiveness and generalizability. It suggest that blending
state-space dynamics with heat-based global diffusion offers a scalable and
interpretable solution for medical segmentation tasks.

</details>


### [24] [IEC3D-AD: A 3D Dataset of Industrial Equipment Components for Unsupervised Point Cloud Anomaly Detection](https://arxiv.org/abs/2511.03267)
*Bingyang Guo,Hongjie Li,Ruiyun Yu,Hanzhe Liang,Jinbao Wang*

Main category: cs.CV

TL;DR: 本研究提出IEC3D-AD数据集和GMANet方法，提升3D异常检测的精准度，特别是在工业设备组件方面。


<details>
  <summary>Details</summary>
Motivation: 现有3D异常检测数据集无法充分捕捉真实工业环境中的复杂性和细微缺陷，限制了异常检测研究的精确性。

Method: 通过几何形态分析生成合成点云样本，并通过空间差异优化减小正常与异常点特征之间的差距。

Result: IEC3D-AD数据集具有更高的点云分辨率和缺陷标注细粒度；GMANet在多个数据集上获得了良好的实验效果。

Conclusion: 开发的IEC3D-AD数据集及GMANet方法在工业设备组件的3D异常检测中表现出色，解决了现有数据集的不足。

Abstract: 3D anomaly detection (3D-AD) plays a critical role in industrial
manufacturing, particularly in ensuring the reliability and safety of core
equipment components. Although existing 3D datasets like Real3D-AD and MVTec
3D-AD offer broad application support, they fall short in capturing the
complexities and subtle defects found in real industrial environments. This
limitation hampers precise anomaly detection research, especially for
industrial equipment components (IEC) such as bearings, rings, and bolts. To
address this challenge, we have developed a point cloud anomaly detection
dataset (IEC3D-AD) specific to real industrial scenarios. This dataset is
directly collected from actual production lines, ensuring high fidelity and
relevance. Compared to existing datasets, IEC3D-AD features significantly
improved point cloud resolution and defect annotation granularity, facilitating
more demanding anomaly detection tasks. Furthermore, inspired by generative
2D-AD methods, we introduce a novel 3D-AD paradigm (GMANet) on IEC3D-AD. This
paradigm generates synthetic point cloud samples based on geometric
morphological analysis, then reduces the margin and increases the overlap
between normal and abnormal point-level features through spatial discrepancy
optimization. Extensive experiments demonstrate the effectiveness of our method
on both IEC3D-AD and other datasets.

</details>


### [25] [Unified Long Video Inpainting and Outpainting via Overlapping High-Order Co-Denoising](https://arxiv.org/abs/2511.03272)
*Shuangquan Lyu,Steven Mao,Yue Ma*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的方法，通过对大型预训练视频扩散模型微调，实现可控的长视频生成和编辑，克服了以往方法的不足。


<details>
  <summary>Details</summary>
Motivation: 为了同时解决长视频生成和高可控性的视频修补及外绘问题，提出了一种新颖统一的方法。

Method: 我们的方法结合了LoRA技术，对大型预训练视频扩散模型进行高效微调，并采用重叠融合的 temporal co-denoising 策略以维持长序列间的一致性。

Result: 我们的方法在复杂的修补和外绘任务中，如在数百帧上编辑或添加对象，展示了超越Baseline方法（如Wan 2.1模型和VACE）在质量（PSNR/SSIM）和感知真实度（LPIPS）方面的表现。

Conclusion: 我们的方法实现了高质量的长视频生成和编辑，克服了以往方法在固定长度剪辑上存在的限制和缝合伪影问题。

Abstract: Generating long videos remains a fundamental challenge, and achieving high
controllability in video inpainting and outpainting is particularly demanding.
To address both of these challenges simultaneously and achieve controllable
video inpainting and outpainting for long video clips, we introduce a novel and
unified approach for long video inpainting and outpainting that extends
text-to-video diffusion models to generate arbitrarily long, spatially edited
videos with high fidelity. Our method leverages LoRA to efficiently fine-tune a
large pre-trained video diffusion model like Alibaba's Wan 2.1 for masked
region video synthesis, and employs an overlap-and-blend temporal co-denoising
strategy with high-order solvers to maintain consistency across long sequences.
In contrast to prior work that struggles with fixed-length clips or exhibits
stitching artifacts, our system enables arbitrarily long video generation and
editing without noticeable seams or drift. We validate our approach on
challenging inpainting/outpainting tasks including editing or adding objects
over hundreds of frames and demonstrate superior performance to baseline
methods like Wan 2.1 model and VACE in terms of quality (PSNR/SSIM), and
perceptual realism (LPIPS). Our method enables practical long-range video
editing with minimal overhead, achieved a balance between parameter efficient
and superior performance.

</details>


### [26] [Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion Models](https://arxiv.org/abs/2511.03317)
*Minghao Fu,Guo-Hua Wang,Tianyu Cui,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: Diffusion-SDPO是一种改进的直接偏好优化方法，可以提升文本到图像扩散模型的生成质量，解决现有方法的缺陷。


<details>
  <summary>Details</summary>
Motivation: 为了改善文本到图像扩散模型的生成质量，并解决现有的直接偏好优化面临的挑战，特别是扩展偏好边际带来的问题。

Method: 提出了一种名为Diffusion-SDPO的安全更新规则，通过根据与优胜者梯度的对齐度自适应缩放劣势者的梯度，以保持优胜者。

Result: 通过一阶分析，推导出保证优选输出误差在每个优化步骤上不增加的闭式缩放系数。

Conclusion: Diffusion-SDPO在各项文本到图像基准测试中相较于偏好学习基线表现出一致的性能提升，特别是在自动化偏好、审美和提示对齐指标上。

Abstract: Text-to-image diffusion models deliver high-quality images, yet aligning them
with human preferences remains challenging. We revisit diffusion-based Direct
Preference Optimization (DPO) for these models and identify a critical
pathology: enlarging the preference margin does not necessarily improve
generation quality. In particular, the standard Diffusion-DPO objective can
increase the reconstruction error of both winner and loser branches.
Consequently, degradation of the less-preferred outputs can become sufficiently
severe that the preferred branch is also adversely affected even as the margin
grows. To address this, we introduce Diffusion-SDPO, a safeguarded update rule
that preserves the winner by adaptively scaling the loser gradient according to
its alignment with the winner gradient. A first-order analysis yields a
closed-form scaling coefficient that guarantees the error of the preferred
output is non-increasing at each optimization step. Our method is simple,
model-agnostic, broadly compatible with existing DPO-style alignment frameworks
and adds only marginal computational overhead. Across standard text-to-image
benchmarks, Diffusion-SDPO delivers consistent gains over preference-learning
baselines on automated preference, aesthetic, and prompt alignment metrics.
Code is publicly available at https://github.com/AIDC-AI/Diffusion-SDPO.

</details>


### [27] [SurgViVQA: Temporally-Grounded Video Question Answering for Surgical Scene Understanding](https://arxiv.org/abs/2511.03325)
*Mauro Orazio Drago,Luca Carlini,Pelinsu Celebi Balyemez,Dennis Pierantozzi,Chiara Lena,Cesare Hassan,Danail Stoyanov,Elena De Momi,Sophia Bano,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: 提出SurgViVQA模型，能够在手术视频问答中有效处理动态场景，通过新的数据集REAL-Colon-VQA评估其性能，结果显示在关键词准确性和鲁棒性上都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前的VideoQA方法局限于静态图像特征，缺乏对动态事件的理解，迫切需要改进手术领域的问答系统以更好地解读过程中的动态变化。

Method: 使用掩蔽视频-文本编码器融合视频和问题特征，捕捉运动和工具-组织交互等时间线索，通过微调的大型语言模型生成连贯答案。

Result: 实验结果显示，SurgViVQA在REAL-Colon-VQA和EndoVis18-VQA数据集上超过了现有的图像基础VQA模型，尤其在关键词准确性上有显著提升。

Conclusion: SurgViVQA模型在手术视频问答中展示了对动态手术场景的有效理解，显著超越了基于静态图像的模型，提升了关键词准确性和模型的鲁棒性。

Abstract: Video Question Answering (VideoQA) in the surgical domain aims to enhance
intraoperative understanding by enabling AI models to reason over temporally
coherent events rather than isolated frames. Current approaches are limited to
static image features, and available datasets often lack temporal annotations,
ignoring the dynamics critical for accurate procedural interpretation. We
propose SurgViVQA, a surgical VideoQA model that extends visual reasoning from
static images to dynamic surgical scenes. It uses a Masked Video--Text Encoder
to fuse video and question features, capturing temporal cues such as motion and
tool--tissue interactions, which a fine-tuned large language model (LLM) then
decodes into coherent answers. To evaluate its performance, we curated
REAL-Colon-VQA, a colonoscopic video dataset that includes motion-related
questions and diagnostic attributes, as well as out-of-template questions with
rephrased or semantically altered formulations to assess model robustness.
Experimental validation on REAL-Colon-VQA and the public EndoVis18-VQA dataset
shows that SurgViVQA outperforms existing image-based VQA benchmark models,
particularly in keyword accuracy, improving over PitVQA by +11\% on
REAL-Colon-VQA and +9\% on EndoVis18-VQA. A perturbation study on the questions
further confirms improved generalizability and robustness to variations in
question phrasing. SurgViVQA and the REAL-Colon-VQA dataset provide a framework
for temporally-aware understanding in surgical VideoQA, enabling AI models to
interpret dynamic procedural contexts more effectively. Code and dataset
available at https://github.com/madratak/SurgViVQA.

</details>


### [28] [Multi-Object Tracking Retrieval with LLaVA-Video: A Training-Free Solution to MOT25-StAG Challenge](https://arxiv.org/abs/2511.03332)
*Yi Yang,Yiming Xu,Timo Kaiser,Hao Cheng,Bodo Rosenhahn,Michael Ying Yang*

Main category: cs.CV

TL;DR: 本文提出了一种解决MOT25-StAG挑战的方法，结合先进的追踪和语言模型，实现了第二名的成绩。


<details>
  <summary>Details</summary>
Motivation: 旨在准确定位和跟踪与特定和自由形式语言查询匹配的多个对象，利用复杂现实场景的视频数据。

Method: 采用一种两阶段的零样本方法，结合了SOTA追踪模型FastTracker和多模态大型语言模型LLaVA-Video的优势。

Result: 在MOT25-StAG测试集中，我们的方法取得了20.68的m-HIoU和10.73的HOTA分数。

Conclusion: 我们的方法在MOT25-StAG挑战中取得了第二名，表明其有效性。

Abstract: In this report, we present our solution to the MOT25-Spatiotemporal Action
Grounding (MOT25-StAG) Challenge. The aim of this challenge is to accurately
localize and track multiple objects that match specific and free-form language
queries, using video data of complex real-world scenes as input. We model the
underlying task as a video retrieval problem and present a two-stage, zero-shot
approach, combining the advantages of the SOTA tracking model FastTracker and
Multi-modal Large Language Model LLaVA-Video. On the MOT25-StAG test set, our
method achieves m-HIoU and HOTA scores of 20.68 and 10.73 respectively, which
won second place in the challenge.

</details>


### [29] [UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions](https://arxiv.org/abs/2511.03334)
*Guozhen Zhang,Zixiang Zhou,Teng Hu,Ziqiao Peng,Youliang Zhang,Yi Chen,Yuan Zhou,Qinglin Lu,Limin Wang*

Main category: cs.CV

TL;DR: UniAVGen是一种新的音频视频生成框架，显著提升了生成质量和效率，减少了对训练样本的需求。


<details>
  <summary>Details</summary>
Motivation: 现有的音频视频生成方法存在唇同步不准确和语义一致性不足的问题，亟需提高跨模态建模的有效性。

Method: 采用双分支联合合成架构，结合两个并行的扩散变压器，通过不对称的跨模态交互机制和面部感知调制模块，实现有效的音视频生成。

Result: 通过全面的实验验证，UniAVGen在训练样本更少的情况下，提升了音视频同步、音色和情感一致性的性能。

Conclusion: UniAVGen在音频视频生成任务中实现了更好的同步性、音色一致性和情感一致性，训练样本要求更少，具有显著优势。

Abstract: Due to the lack of effective cross-modal modeling, existing open-source
audio-video generation methods often exhibit compromised lip synchronization
and insufficient semantic consistency. To mitigate these drawbacks, we propose
UniAVGen, a unified framework for joint audio and video generation. UniAVGen is
anchored in a dual-branch joint synthesis architecture, incorporating two
parallel Diffusion Transformers (DiTs) to build a cohesive cross-modal latent
space. At its heart lies an Asymmetric Cross-Modal Interaction mechanism, which
enables bidirectional, temporally aligned cross-attention, thus ensuring
precise spatiotemporal synchronization and semantic consistency. Furthermore,
this cross-modal interaction is augmented by a Face-Aware Modulation module,
which dynamically prioritizes salient regions in the interaction process. To
enhance generative fidelity during inference, we additionally introduce
Modality-Aware Classifier-Free Guidance, a novel strategy that explicitly
amplifies cross-modal correlation signals. Notably, UniAVGen's robust joint
synthesis design enables seamless unification of pivotal audio-video tasks
within a single model, such as joint audio-video generation and continuation,
video-to-audio dubbing, and audio-driven video synthesis. Comprehensive
experiments validate that, with far fewer training samples (1.3M vs. 30.1M),
UniAVGen delivers overall advantages in audio-video synchronization, timbre
consistency, and emotion consistency.

</details>


### [30] [Decoupling Augmentation Bias in Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2511.03367)
*Gahyeon Kim,Sohee Kim,Seokju Lee*

Main category: cs.CV

TL;DR: AAPL是一种新方法，通过对抗性标记嵌入增强提示学习，显著提高了模型在不同任务上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索图像级增强特别是属性特定变化如何支持与增强提示学习，填补现有研究中对图像增强探索不足的空白。

Method: 通过引入对抗性标记嵌入，AAPL方法将增强所引入的表面视觉变化与类别相关的语义表示进行解耦，以便学习更具区分性的视觉特征。

Result: 在十一项基准数据集上进行的全面实验表明，AAPL方法在少样本、零样本、跨数据集和领域泛化设置中均优于现有方法。

Conclusion: 提出的AAPL方法在多个任务中超越了现有的提示学习方法，展示了图像级增强对于提升模型泛化能力的重要性。

Abstract: Recent advances in large-scale vision and language models have led to
significant progress in zero-shot learning tasks. Methods such as CoOp and
CoCoOp have shown that replacing handcrafted prompts with learnable vectors,
known as prompt learning, can result in improved performance. However, these
models often struggle to generalize to entirely unseen categories. While
traditional zero-shot learning techniques benefit from various data
augmentation strategies, prompt learning has primarily focused on text-based
modifications, leaving the potential of image-based augmentation largely
unexplored. In this work, we explore how image-level augmentations,
particularly those that introduce attribute-specific variations, can support
and enhance prompt learning. Our analysis examines the interaction between
these augmentations and soft prompt frameworks, revealing their potential to
improve generalization. We also identify a limitation in existing methods, such
as CoCoOp, which do not provide explicit guidance for learning prompts that
focus on semantically meaningful visual features. To address this, we propose
Adding Attributes to Prompt Learning, AAPL, a novel method that introduces
adversarial token embeddings to decouple superficial visual variations
introduced by augmentation from class-relevant semantic representations. This
decoupling enables the learned prompts to concentrate on visually
discriminative features that align with the target categories. We conduct
comprehensive experiments on eleven benchmark datasets, and AAPL consistently
outperforms existing methods across few-shot, zero-shot, cross-dataset, and
domain generalization settings. Our source code is publicly available at:
https://github.com/Gahyeonkim09/AAPL

</details>


### [31] [Robust Alignment of the Human Embryo in 3D Ultrasound using PCA and an Ensemble of Heuristic, Atlas-based and Learning-based Classifiers Evaluated on the Rotterdam Periconceptional Cohort](https://arxiv.org/abs/2511.03416)
*Nikolai Herrmann,Marcella C. Zijta,Stefan Klein,Régine P. M. Steegers-Theunissen,Rene M. H. Wijnen,Bernadette S. de Bakker,Melek Rousian,Wietske A. P. Bastiaansen*

Main category: cs.CV

TL;DR: 本研究提出了一种自动化方法，通过主成分分析和多种选择策略实现胚胎在三维超声图像中的标准化对齐，准确率高达98.5%，为临床和研究提供了支持。


<details>
  <summary>Details</summary>
Motivation: 为了提高三维超声图像中胚胎对齐的标准化水平，从而改善孕期生长监测，增强图像中标志物的可视化以及不同扫描间的对比。

Method: 本研究使用主成分分析（PCA）从胚胎的分割掩码中提取主要轴线，并采用三种策略（皮尔逊相关启发式、与典型图像匹配、随机森林分类器）选择标准方向。

Result: 在2166幅图像测试中，PCA在99.0%的图像中成功提取了胚胎的主要轴线。各种方法在选择正确方向的准确率分别为97.4%、95.8%、98.4%，综合投票结果为98.5%。

Conclusion: 该自动化方法能够高精度地标准化胚胎在三维超声图像中的对齐，有助于临床及研究中的可扩展分析。

Abstract: Standardized alignment of the embryo in three-dimensional (3D) ultrasound
images aids prenatal growth monitoring by facilitating standard plane
detection, improving visualization of landmarks and accentuating differences
between different scans. In this work, we propose an automated method for
standardizing this alignment. Given a segmentation mask of the embryo,
Principal Component Analysis (PCA) is applied to the mask extracting the
embryo's principal axes, from which four candidate orientations are derived.
The candidate in standard orientation is selected using one of three
strategies: a heuristic based on Pearson's correlation assessing shape, image
matching to an atlas through normalized cross-correlation, and a Random Forest
classifier. We tested our method on 2166 images longitudinally acquired 3D
ultrasound scans from 1043 pregnancies from the Rotterdam Periconceptional
Cohort, ranging from 7+0 to 12+6 weeks of gestational age. In 99.0% of images,
PCA correctly extracted the principal axes of the embryo. The correct candidate
was selected by the Pearson Heuristic, Atlas-based and Random Forest in 97.4%,
95.8%, and 98.4% of images, respectively. A Majority Vote of these selection
methods resulted in an accuracy of 98.5%. The high accuracy of this pipeline
enables consistent embryonic alignment in the first trimester, enabling
scalable analysis in both clinical and research settings. The code is publicly
available at:
https://gitlab.com/radiology/prenatal-image-analysis/pca-3d-alignment.

</details>


### [32] [Generalizing Shape-from-Template to Topological Changes](https://arxiv.org/abs/2511.03459)
*Kevin Manogue,Tomasz M Schang,Dilara Kuş,Jonas Müller,Stefan Zachow,Agniva Sengupta*

Main category: cs.CV

TL;DR: 提出一种新的形状重建方法，能够处理可变形物体在拓扑变化情况下的表面重建，超越了现有的SfT方法。


<details>
  <summary>Details</summary>
Motivation: 现有的SfT方法在物体变形伴随拓扑变化时表现不佳，因此需要提出一种新的方法来解决这个问题。

Method: 通过经典的模板形状(SfT)解决方案进行初始化，并通过划分其空间域来迭代适应模板，以最小化联接物理合理性与重投影一致性的能量函数。

Result: 该方法能够稳健地捕捉各种实际相关的拓扑事件，包括二维表面上的撕裂和切割。

Conclusion: 该方法能够在存在拓扑变化的情况下，准确重建可变形物体的表面，超越了现有的基线方法。

Abstract: Reconstructing the surfaces of deformable objects from correspondences
between a 3D template and a 2D image is well studied under Shape-from-Template
(SfT) methods; however, existing approaches break down when topological changes
accompany the deformation. We propose a principled extension of SfT that
enables reconstruction in the presence of such changes. Our approach is
initialized with a classical SfT solution and iteratively adapts the template
by partitioning its spatial domain so as to minimize an energy functional that
jointly encodes physical plausibility and reprojection consistency. We
demonstrate that the method robustly captures a wide range of practically
relevant topological events including tears and cuts on bounded 2D surfaces,
thereby establishing the first general framework for topological-change-aware
SfT. Experiments on both synthetic and real data confirm that our approach
consistently outperforms baseline methods.

</details>


### [33] [Human Mesh Modeling for Anny Body](https://arxiv.org/abs/2511.03589)
*Romain Brégier,Guénolé Fiche,Laura Bravo-Sánchez,Thomas Lucas,Matthieu Armando,Philippe Weinzaepfel,Grégory Rogez,Fabien Baradel*

Main category: cs.CV

TL;DR: Anny是一个基于人体测量知识的创新人类身体模型，提供了一种简单且经济的替代方案，适用于三维建模，具有人口统计学的广泛代表性。


<details>
  <summary>Details</summary>
Motivation: 解决现有模型依赖于昂贵的3D扫描和窄人口统计特征的问题，并提供丰富的人体形状变化。

Method: 定义一个连续且可解释的形状空间，通过性状参数控制广泛的人体形状，并使用WHO人口统计数据进行校准。

Result: Anny的模型具有广泛的可控性和代表性，其训练的HMR模型可以与基于扫描的模型的性能相匹配。

Conclusion: Anny是一个简单且完全可微分的无扫描人类身体模型，能够提供现实且具有人口统计学基础的人体形状变异，是人类中心三维建模的可访问基础。

Abstract: Parametric body models are central to many human-centric tasks, yet existing
models often rely on costly 3D scans and learned shape spaces that are
proprietary and demographically narrow. We introduce Anny, a simple, fully
differentiable, and scan-free human body model grounded in anthropometric
knowledge from the MakeHuman community. Anny defines a continuous,
interpretable shape space, where phenotype parameters (e.g. gender, age,
height, weight) control blendshapes spanning a wide range of human forms --
across ages (from infants to elders), body types, and proportions. Calibrated
using WHO population statistics, it provides realistic and demographically
grounded human shape variation within a single unified model. Thanks to its
openness and semantic control, Anny serves as a versatile foundation for 3D
human modeling -- supporting millimeter-accurate scan fitting, controlled
synthetic data generation, and Human Mesh Recovery (HMR). We further introduce
Anny-One, a collection of 800k photorealistic humans generated with Anny,
showing that despite its simplicity, HMR models trained with Anny can match the
performance of those trained with scan-based body models, while remaining
interpretable and broadly representative. The Anny body model and its code are
released under the Apache 2.0 license, making Anny an accessible foundation for
human-centric 3D modeling.

</details>


### [34] [Signal Intensity-weighted coordinate channels improve learning stability and generalisation in 1D and 2D CNNs in localisation tasks on biomedical signals](https://arxiv.org/abs/2511.03645)
*Vittal L. Rao*

Main category: cs.CV

TL;DR: 本研究提出了一种基于信号强度的坐标表示方法，在生物医学定位任务中展现出更优的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 生物医学数据的定位任务通常需要模型从复杂的强度分布信号中学习有意义的空间或时间关系，因此需要一个更有效的输入表示方式。

Method: 提出了一种替换纯坐标通道的新方法，使用由局部信号强度缩放的通道，嵌入强度与位置的耦合，形成一种简单且适用于多种模态的归纳偏置。

Result: 在两项不同的定位问题上（预测ECG信号的形态转变时间和回归细胞图像中核中心的坐标），该方法相较于传统的方法实现了更快的收敛和更高的泛化性能。

Conclusion: 本研究提出的信号强度加权坐标表示方法在生物医学信号的定位任务中表现出更快的收敛速度和更高的泛化性能，相较于传统的坐标通道方法具有明显优势。

Abstract: Localisation tasks in biomedical data often require models to learn
meaningful spatial or temporal relationships from signals with complex
intensity distributions. A common strategy, exemplified by CoordConv layers, is
to append coordinate channels to convolutional inputs, enabling networks to
learn absolute positions. In this work, we propose a signal intensity-weighted
coordinate representation that replaces the pure coordinate channels with
channels scaled by local signal intensity. This modification embeds an
intensity-position coupling directly in the input representation, introducing a
simple and modality-agnostic inductive bias. We evaluate the approach on two
distinct localisation problems: (i) predicting the time of morphological
transition in 20-second, two-lead ECG signals, and (ii) regressing the
coordinates of nuclear centres in cytological images from the SiPaKMeD dataset.
In both cases, the proposed representation yields faster convergence and higher
generalisation performance relative to conventional coordinate-channel
approaches, demonstrating its effectiveness across both one-dimensional and
two-dimensional biomedical signals.

</details>


### [35] [Part-Aware Bottom-Up Group Reasoning for Fine-Grained Social Interaction Detection](https://arxiv.org/abs/2511.03666)
*Dongkeun Kim,Minsu Cho,Suha Kwak*

Main category: cs.CV

TL;DR: 提出了一种新的基于身体部位特征的社交互动检测框架，能够更准确地推断社交组配置，超越了传统方法的限制。


<details>
  <summary>Details</summary>
Motivation: 现有社交互动检测方法忽视细微的信号提示，如面部表情和目光，主观性较强，无法有效捕捉局部社交信号。

Method: 采用基于个体身体部位特征的部分感知自下而上的群体推理框架，进行社交组和互动的推断。

Result: 该方法在NVI数据集上的实验结果显示，显著优于之前的方法，达成新的性能标杆。

Conclusion: 本研究提出的方法在细粒度社交互动检测中效果显著，超越了现有技术的局限，达到了新的领先水平。

Abstract: Social interactions often emerge from subtle, fine-grained cues such as
facial expressions, gaze, and gestures. However, existing methods for social
interaction detection overlook such nuanced cues and primarily rely on holistic
representations of individuals. Moreover, they directly detect social groups
without explicitly modeling the underlying interactions between individuals.
These drawbacks limit their ability to capture localized social signals and
introduce ambiguity when group configurations should be inferred from social
interactions grounded in nuanced cues. In this work, we propose a part-aware
bottom-up group reasoning framework for fine-grained social interaction
detection. The proposed method infers social groups and their interactions
using body part features and their interpersonal relations. Our model first
detects individuals and enhances their features using part-aware cues, and then
infers group configuration by associating individuals via similarity-based
reasoning, which considers not only spatial relations but also subtle social
cues that signal interactions, leading to more accurate group inference.
Experiments on the NVI dataset demonstrate that our method outperforms prior
methods, achieving the new state of the art.

</details>


### [36] [Disentangled Concepts Speak Louder Than Words:Explainable Video Action Recognition](https://arxiv.org/abs/2511.03725)
*Jongseo Lee,Wooil Lee,Gyeong-Moon Park,Seong Tae Kim,Jinwoo Choi*

Main category: cs.CV

TL;DR: DANCE框架通过解耦运动动态与空间上下文，改进视频动作识别模型的可解释性和性能。


<details>
  <summary>Details</summary>
Motivation: 有效的解释视频动作识别模型需要解构动作与空间上下文之间的关系，但现有基于显著性的解释方法导致了解释混淆，难以理解模型的预测依据。

Method: 通过定义运动动态概念（即人类姿势序列），借助大型语言模型自动提取对象与场景概念，并基于ante-hoc概念瓶颈设计，强制通过这些概念进行预测。

Result: 在KTH、Penn Action、HAA500和UCF-101四个数据集上的实验表明，DANCE在解释清晰度和性能上显著改善，且在模型调试、编辑和故障分析中具有明显优势。

Conclusion: DANCE在视频动作识别中有效解耦了动作动态与空间上下文，提高了解释的清晰度，并在用户研究中验证了其优越的可解释性。

Abstract: Effective explanations of video action recognition models should disentangle
how movements unfold over time from the surrounding spatial context. However,
existing methods based on saliency produce entangled explanations, making it
unclear whether predictions rely on motion or spatial context. Language-based
approaches offer structure but often fail to explain motions due to their tacit
nature -- intuitively understood but difficult to verbalize. To address these
challenges, we propose Disentangled Action aNd Context concept-based
Explainable (DANCE) video action recognition, a framework that predicts actions
through disentangled concept types: motion dynamics, objects, and scenes. We
define motion dynamics concepts as human pose sequences. We employ a large
language model to automatically extract object and scene concepts. Built on an
ante-hoc concept bottleneck design, DANCE enforces prediction through these
concepts. Experiments on four datasets -- KTH, Penn Action, HAA500, and UCF-101
-- demonstrate that DANCE significantly improves explanation clarity with
competitive performance. We validate the superior interpretability of DANCE
through a user study. Experimental results also show that DANCE is beneficial
for model debugging, editing, and failure analysis.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [37] [Automatic Machine Translation Detection Using a Surrogate Multilingual Translation Model](https://arxiv.org/abs/2511.02958)
*Cristian García-Romero,Miquel Esplà-Gomis,Felipe Sánchez-Martínez*

Main category: cs.CL

TL;DR: 本研究提出了一种新方法，通过替代多语言机器翻译模型的内部表示来识别人工和机器翻译，效果优于现有技术，准确率提升显著。


<details>
  <summary>Details</summary>
Motivation: 现代机器翻译系统依赖于大量的平行语料库，而这些语料中可能包含许多机器生成的翻译，过度依赖这些合成内容会显著降低翻译质量，从而需要过滤掉非人工翻译的内容。

Method: 通过利用替代多语言机器翻译模型的内部表示来区分人工翻译和机器翻译句子。

Result: 实验结果表明，我们的方法优于当前的最先进技术，尤其是在非英语语言对上有明显提升。

Conclusion: 我们的方法在识别人工翻译和机器翻译句子上表现优越，尤其是在非英语语言对中，准确率提升至少5个百分点。

Abstract: Modern machine translation (MT) systems depend on large parallel corpora,
often collected from the Internet. However, recent evidence indicates that (i)
a substantial portion of these texts are machine-generated translations, and
(ii) an overreliance on such synthetic content in training data can
significantly degrade translation quality. As a result, filtering out non-human
translations is becoming an essential pre-processing step in building
high-quality MT systems. In this work, we propose a novel approach that
directly exploits the internal representations of a surrogate multilingual MT
model to distinguish between human and machine-translated sentences.
Experimental results show that our method outperforms current state-of-the-art
techniques, particularly for non-English language pairs, achieving gains of at
least 5 percentage points of accuracy.

</details>


### [38] [Targeted Error Correction in Knowledge Distillation: Small Language Models Surpass GPT](https://arxiv.org/abs/2511.03005)
*Hee-Jin Lee,Zhen Guo,Luchao Jin,Morteza Moazami Goudarzi*

Main category: cs.CL

TL;DR: ARF管道通过分析和修订提升了小型开源语言模型的性能，证明其在客户服务总结中的优越性。


<details>
  <summary>Details</summary>
Motivation: 推动小型开源语言模型在特定任务上的性能，特别是在客户服务总结方面，从而节省成本且保护数据隐私。

Method: ARF管道分为分析、修订和细调三个步骤，分别识别错误、进行针对性修订并对小型模型进行微调。

Result: 经过微调的小型模型在总结性能上优于GPT-3.5，显示了ARF管道的有效性。

Conclusion: ARF管道通过分析和修订使得小型开源语言模型在客户服务总结任务中超过了更大的专有模型，并提高了成本效率和数据隐私。

Abstract: We introduce an Analyze-Revise-Finetune (ARF) pipeline that enables smaller
open-source language models (LLMs) to surpass substantially larger proprietary
models in customer service summarization tasks. The pipeline first analyzes and
categorizes common errors in summaries produced by a teacher model (GPT-3.5),
then performs a targeted revision using a compact editor model (Llama 3.1 70B)
to generate high-quality, refined training data. Fine-tuning a smaller student
model (Llama 3.1 8B) on this refined data resulted in superior summarization
performance compared to GPT-3.5. The ARF pipeline improves cost efficiency and
data privacy while maintaining competitive accuracy, illustrating a
generalizable framework for enhancing open-source LLMs across diverse
downstream applications.

</details>


### [39] [Data-Efficient Adaptation and a Novel Evaluation Method for Aspect-based Sentiment Analysis](https://arxiv.org/abs/2511.03034)
*Yan Cathy Hua,Paul Denny,Jörg Wicker,Katerina Taškova*

Main category: cs.CL

TL;DR: 本研究改进了ABSA的评估方法，并展示了小型生成模型在教育领域的有效性，支持低资源领域的未来研究。


<details>
  <summary>Details</summary>
Motivation: 鉴于现有的ABSA研究主要集中在商业领域，而教育和医疗等高需求、低资源领域的分析需求未得到满足，迫切需要探索新的方法和资源。

Method: 提出了灵活文本相似性匹配和最优二分配对（FTS-OBP）作为新的评估方法，同时探索了数据免费的学习方法和多任务微调策略。

Result: 通过开发新的评估标准和方法，研究表明小型生成语言模型在教育评论的ABSA任务中表现出色，能够在仅有少量示例的情况下超越大型专有模型。

Conclusion: 本研究提出了一种新的评估方法，并在教育领域进行小规模解码器仅生成模型的首次应用，展示了低资源领域的潜力。

Abstract: Aspect-based Sentiment Analysis (ABSA) is a fine-grained opinion mining
approach that identifies and classifies opinions associated with specific
entities (aspects) or their categories within a sentence. Despite its rapid
growth and broad potential, ABSA research and resources remain concentrated in
commercial domains, leaving analytical needs unmet in high-demand yet
low-resource areas such as education and healthcare. Domain adaptation
challenges and most existing methods' reliance on resource-intensive
in-training knowledge injection further hinder progress in these areas.
Moreover, traditional evaluation methods based on exact matches are overly
rigid for ABSA tasks, penalising any boundary variations which may misrepresent
the performance of generative models. This work addresses these gaps through
three contributions: 1) We propose a novel evaluation method, Flexible Text
Similarity Matching and Optimal Bipartite Pairing (FTS-OBP), which accommodates
realistic extraction boundary variations while maintaining strong correlation
with traditional metrics and offering fine-grained diagnostics. 2) We present
the first ABSA study of small decoder-only generative language models (SLMs;
<7B parameters), examining resource lower bounds via a case study in education
review ABSA. We systematically explore data-free (in-context learning and
weight merging) and data-light fine-tuning methods, and propose a multitask
fine-tuning strategy that significantly enhances SLM performance, enabling
1.5-3.8 B models to surpass proprietary large models and approach benchmark
results with only 200-1,000 examples on a single GPU. 3) We release the first
public set of education review ABSA resources to support future research in
low-resource domains.

</details>


### [40] [ROBoto2: An Interactive System and Dataset for LLM-assisted Clinical Trial Risk of Bias Assessment](https://arxiv.org/abs/2511.03048)
*Anthony Hevia,Sanjana Chintalapati,Veronica Ka Wai Lai,Thanh Tam Nguyen,Wai-Tat Wong,Terry Klassen,Lucy Lu Wang*

Main category: cs.CL

TL;DR: ROBOTO2是一个开源的平台，用于辅助临床试验偏倚风险评估，结合LLM技术和人工反馈，提升评估效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 提高临床试验偏倚风险评估的效率，减少传统评估过程中所需的人力和时间成本。

Method: 开发了一个互动式平台，结合PDF解析、增强型LLM提示和人工审查，简化ROB v2的注释过程。

Result: 发布了一个包含521个儿科临床试验报告的数据集，并对4个大语言模型的ROB2性能进行基准测试，分析当前模型能力和自动化的挑战。

Conclusion: ROBOTO2为临床试验的偏倚风险评估提供了高效的解决方案，并推动了系统评价方法的自动化进程。

Abstract: We present ROBOTO2, an open-source, web-based platform for large language
model (LLM)-assisted risk of bias (ROB) assessment of clinical trials. ROBOTO2
streamlines the traditionally labor-intensive ROB v2 (ROB2) annotation process
via an interactive interface that combines PDF parsing, retrieval-augmented LLM
prompting, and human-in-the-loop review. Users can upload clinical trial
reports, receive preliminary answers and supporting evidence for ROB2 signaling
questions, and provide real-time feedback or corrections to system suggestions.
ROBOTO2 is publicly available at https://roboto2.vercel.app/, with code and
data released to foster reproducibility and adoption. We construct and release
a dataset of 521 pediatric clinical trial reports (8954 signaling questions
with 1202 evidence passages), annotated using both manually and LLM-assisted
methods, serving as a benchmark and enabling future research. Using this
dataset, we benchmark ROB2 performance for 4 LLMs and provide an analysis into
current model capabilities and ongoing challenges in automating this critical
aspect of systematic review.

</details>


### [41] [Reading Between the Lines: The One-Sided Conversation Problem](https://arxiv.org/abs/2511.03056)
*Victoria Ebert,Rishabh Singh,Tuochao Chen,Noah A. Smith,Shyamnath Gollakota*

Main category: cs.CL

TL;DR: 本文探讨了一种一侧对话问题1SC，研究了重构缺失发言和生成摘要的任务，结果表明，通过特定提示和模型调优，能够显著改善对话AI的表现。


<details>
  <summary>Details</summary>
Motivation: 解决在仅记录对话一方的情况下，如何推断和学习对话信息的问题。

Method: 通过人类A/B测试和LLM作为评判者的评估方法，对MultiWOZ、DailyDialog和Candor数据集进行实验。

Result: 通过访问一个未来的发言和了解发言长度的信息，提高了重构的质量。高质量的摘要在不重构缺失发言的情况下也能生成。

Conclusion: 提出了一种新挑战1SC，并报告了令人鼓舞的结果，这是朝向隐私意识对话AI的一步。

Abstract: Conversational AI is constrained in many real-world settings where only one
side of a dialogue can be recorded, such as telemedicine, call centers, and
smart glasses. We formalize this as the one-sided conversation problem (1SC):
inferring and learning from one side of a conversation. We study two tasks: (1)
reconstructing the missing speaker's turns for real-time use cases, and (2)
generating summaries from one-sided transcripts. Evaluating prompting and
finetuned models on MultiWOZ, DailyDialog, and Candor with both human A/B
testing and LLM-as-a-judge metrics, we find that access to one future turn and
information about utterance length improves reconstruction, placeholder
prompting helps to mitigate hallucination, and while large models generate
promising reconstructions with prompting, smaller models require finetuning.
Further, high-quality summaries can be generated without reconstructing missing
turns. We present 1SC as a novel challenge and report promising results that
mark a step toward privacy-aware conversational AI.

</details>


### [42] [PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech](https://arxiv.org/abs/2511.03080)
*Michel Wong,Ali Alshehri,Sophia Kao,Haotian He*

Main category: cs.CL

TL;DR: PolyNorm采用大语言模型优化文本归一化，减少人工干预，提升多语言适用性，并显著降低单词错误率。


<details>
  <summary>Details</summary>
Motivation: 在传统文本归一化系统需大量人工规则的基础上，PolyNorm旨在减少人工干预，提高语言覆盖范围，尤其是在资源稀缺的环境中。

Method: 采用基于提示的方式，利用大语言模型进行文本归一化，同时提供语言无关的自动数据整理和评估流程。

Result: 在八种语言上的实验表明，PolyNorm相比于传统生产级系统在单词错误率（WER）上有明显的降低，并发布了PolyNorm-Benchmark以支持多语言研究。

Conclusion: PolyNorm significantly improves text normalization for TTS systems by leveraging LLMs, demonstrating lower word error rates across multiple languages.

Abstract: Text Normalization (TN) is a key preprocessing step in Text-to-Speech (TTS)
systems, converting written forms into their canonical spoken equivalents.
Traditional TN systems can exhibit high accuracy, but involve substantial
engineering effort, are difficult to scale, and pose challenges to language
coverage, particularly in low-resource settings. We propose PolyNorm, a
prompt-based approach to TN using Large Language Models (LLMs), aiming to
reduce the reliance on manually crafted rules and enable broader linguistic
applicability with minimal human intervention. Additionally, we present a
language-agnostic pipeline for automatic data curation and evaluation, designed
to facilitate scalable experimentation across diverse languages. Experiments
across eight languages show consistent reductions in the word error rate (WER)
compared to a production-grade-based system. To support further research, we
release PolyNorm-Benchmark, a multilingual data set covering a diverse range of
text normalization phenomena.

</details>


### [43] [A Computational Approach to Analyzing Disrupted Language in Schizophrenia: Integrating Surprisal and Coherence Measures](https://arxiv.org/abs/2511.03089)
*Gowtham Premananth,Carol Espy-Wilson*

Main category: cs.CL

TL;DR: 本研究探讨了精神分裂症患者的语言中断，通过计算惊讶度和语义连贯性评估其语言特征，并与健康对照进行比较，揭示了这些指标与症状严重程度的关系。


<details>
  <summary>Details</summary>
Motivation: 探索精神分裂症患者与健康对照在语言产生中的差异，并对其症状严重程度与语言指标的关系进行深入分析。

Method: 通过计算惊讶度和语义连贯性来评估语言中断。

Result: 本研究发现，精神分裂症患者的语言中断在惊讶度和语义连贯性方面显著表现出异常，且与症状的严重程度相关。

Conclusion: 语言中断可以通过计算语言学的指标进行有效表征，从而为精神分裂症的诊断和症状严重性提供客观标志。

Abstract: Language disruptions are one of the well-known effects of schizophrenia
symptoms. They are often manifested as disorganized speech and impaired
discourse coherence. These abnormalities in spontaneous language production
reflect underlying cognitive disturbances and have the potential to serve as
objective markers for symptom severity and diagnosis of schizophrenia. This
study focuses on how these language disruptions can be characterized in terms
of two computational linguistic measures: surprisal and semantic coherence. By
computing surprisal and semantic coherence of language using computational
models, this study investigates how they differ between subjects with
schizophrenia and healthy controls. Furthermore, this study provides further
insight into how language disruptions in terms of these linguistic measures
change with varying degrees of schizophrenia symptom severity.

</details>


### [44] [CARMA: Comprehensive Automatically-annotated Reddit Mental Health Dataset for Arabic](https://arxiv.org/abs/2511.03102)
*Saad Mankarious,Ayah Zirikly*

Main category: cs.CL

TL;DR: CARMA是首个自动标注的大规模阿拉伯语心理健康数据集，对提升阿拉伯语心理健康检测具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 针对阿拉伯语人群心理健康状况的早期检测面临资源不足和文化污名化的问题，迫切需要新的解决方案。

Method: 通过定性和定量分析用户的词汇和语义差异，再进行分类实验以展示数据集的有效性。

Result: CARMA数据集超越了现有资源，在规模和多样性上具有显著优势，分类实验结果证明其有效性。

Conclusion: CARMA数据集在推进阿拉伯语心理健康检测方面具有重要潜力，填补了现有资源的空白。

Abstract: Mental health disorders affect millions worldwide, yet early detection
remains a major challenge, particularly for Arabic-speaking populations where
resources are limited and mental health discourse is often discouraged due to
cultural stigma. While substantial research has focused on English-language
mental health detection, Arabic remains significantly underexplored, partly due
to the scarcity of annotated datasets. We present CARMA, the first
automatically annotated large-scale dataset of Arabic Reddit posts. The dataset
encompasses six mental health conditions, such as Anxiety, Autism, and
Depression, and a control group. CARMA surpasses existing resources in both
scale and diversity. We conduct qualitative and quantitative analyses of
lexical and semantic differences between users, providing insights into the
linguistic markers of specific mental health conditions. To demonstrate the
dataset's potential for further mental health analysis, we perform
classification experiments using a range of models, from shallow classifiers to
large language models. Our results highlight the promise of advancing mental
health detection in underrepresented languages such as Arabic.

</details>


### [45] [Control Barrier Function for Aligning Large Language Models](https://arxiv.org/abs/2511.03121)
*Yuya Miyaoka,Masaki Inoue*

Main category: cs.CL

TL;DR: 本文提出了一种基于控制屏障函数的框架，用于对齐大型语言模型，实现符合用户期望的文本生成。


<details>
  <summary>Details</summary>
Motivation: 旨在生成积极的文本，确保语言模型的输出符合用户的需求。

Method: 利用控制屏障函数(CBF)作为安全过滤器，通过干预生成的文本进行对齐。

Result: 安全过滤器通过直接应用于生成的令牌，增强了文本生成的安全性和对齐性，而无需微调基础语言模型。

Conclusion: 提出了一种基于控制的框架，以对齐大型语言模型，确保生成符合用户期望的文本。

Abstract: This paper proposes a control-based framework for aligning large language
models (LLMs) by leveraging a control barrier function (CBF) to ensure
user-desirable text generation. The presented framework applies the CBF safety
filter to the predicted token generated from the baseline LLM, to intervene in
the generated text. The safety filter includes two significant advantages: this
safety filter is an add-on type, allowing it to be used for alignment purposes
without fine-tuning the baseline LLM, and if there is an evaluation model
regarding the desired alignment, it can be directly applied to the filter
design. The overall text-generation system is implemented with open-source
language models, aiming to generate positive text.

</details>


### [46] [MME-CC: A Challenging Multi-Modal Evaluation Benchmark of Cognitive Capacity](https://arxiv.org/abs/2511.03146)
*Kaiyuan Zhang,Chenghao Yang,Zhoufutu Wen,Sihang Yuan,Qiuyue Wang,Chaoyi Huang,Guosheng Zhu,He Wang,Huawenyu Lu,Jianing Wen,Jianpeng Jiao,Lishu Luo,Longxiang Liu,Sijin Wu,Xiaolei Zhu,Xuanliang Zhang,Ge Zhang,Yi Lin,Guang Shi,Chaoyou Fu,Wenhao Huang*

Main category: cs.CL

TL;DR: 本研究提出MME-CC基准，系统评估多模态大模型在视觉认知方面的能力，揭示了模型的弱点和常见错误模式。


<details>
  <summary>Details</summary>
Motivation: 随着推理模型的快速发展，理解视觉中心的认知行为变得日益重要，而现有的基准在这方面存在不足。

Method: 引入MME-CC基准，组织11个推理任务，涵盖空间、几何和基于知识的推理，进行大量实验以评估16个代表性多模态大模型。

Result: 实验结果表明，关闭源代码的模型在整体上表现优异，但在空间和几何推理上普遍较弱，出现了多种常见错误模式。

Conclusion: 本研究提出的MME-CC基准能够更全面地评估多模态大模型的认知能力，尤其是在视觉推理方面的不足。

Abstract: As reasoning models scale rapidly, the essential role of multimodality in
human cognition has come into sharp relief, driving a growing need to probe
vision-centric cognitive behaviors. Yet, existing multimodal benchmarks either
overemphasize textual reasoning or fall short of systematically capturing
vision-centric cognitive behaviors, leaving the cognitive capacity of MLLMs
insufficiently assessed. To address this limitation, we introduce MME-CC
(Multi-Modal Evaluation benchmark of Cognitive Capacity), a vision-grounded
benchmark that organizes 11 representative reasoning tasks into three
fundamental categories of visual information: spatial, geometric, and
knowledge-based reasoning, and provides fine-grained analyses of MLLMs'
cognitive capacity across these dimensions. Based on MME-CC, we conduct
extensive experiments over 16 representative MLLMs. Our study reveals that
closed-source models currently lead overall (e.g., 42.66 for Gemini-2.5-Pro vs.
30.45 for GLM-4.5V), while spatial and geometric reasoning remain broadly weak
(less than or equal to 30%). We further identify common error patterns,
including orientation mistakes, fragile cross-view identity persistence, and
poor adherence to counterfactual instructions, and observe that
Chain-of-Thought typically follows a three-stage process (extract -> reason ->
verify) with heavy reliance on visual extraction. We hope this work catalyzes a
shift toward treating the cognitive capacity of MLLMs as central to both
evaluation and model design.

</details>


### [47] [Who Sees the Risk? Stakeholder Conflicts and Explanatory Policies in LLM-based Risk Assessment](https://arxiv.org/abs/2511.03152)
*Srishti Yadav,Jasmina Gajcin,Erik Miehling,Elizabeth Daly*

Main category: cs.CL

TL;DR: 本文提出了一个利用LLM进行利益相关者风险评估的框架，强调了利益相关者视角在风险感知中的重要性，并提供了针对医疗AI、自动驾驶和欺诈检测等场景的实证分析。


<details>
  <summary>Details</summary>
Motivation: 理解不同利益相关者如何看待AI系统中的风险对于其负责任的部署至关重要。

Method: 本研究提出了一个基于大型语言模型的利益相关者风险评估框架，使用Risk Atlas Nexus和GloVE解释方法生成特定于利益相关者的可解释政策。

Result: 实证结果表明，利益相关者的视角显著影响风险感知和冲突模式，并通过三个真实世界的AI应用案例展示了该方法的有效性。

Conclusion: 本研究强调了利益相关者意识解释在提高LLM评估透明度和可解释性中的重要性，同时与以人为本的AI治理目标保持一致。

Abstract: Understanding how different stakeholders perceive risks in AI systems is
essential for their responsible deployment. This paper presents a framework for
stakeholder-grounded risk assessment by using LLMs, acting as judges to predict
and explain risks. Using the Risk Atlas Nexus and GloVE explanation method, our
framework generates stakeholder-specific, interpretable policies that shows how
different stakeholders agree or disagree about the same risks. We demonstrate
our method using three real-world AI use cases of medical AI, autonomous
vehicles, and fraud detection domain. We further propose an interactive
visualization that reveals how and why conflicts emerge across stakeholder
perspectives, enhancing transparency in conflict reasoning. Our results show
that stakeholder perspectives significantly influence risk perception and
conflict patterns. Our work emphasizes the importance of these
stakeholder-aware explanations needed to make LLM-based evaluations more
transparent, interpretable, and aligned with human-centered AI governance
goals.

</details>


### [48] [Measuring Aleatoric and Epistemic Uncertainty in LLMs: Empirical Evaluation on ID and OOD QA Tasks](https://arxiv.org/abs/2511.03166)
*Kevin Wang,Subre Abdoul Moktar,Jia Li,Kangshuo Li,Feng Chen*

Main category: cs.CL

TL;DR: 本研究探讨了不确定性估计在大语言模型中的作用，发现信息基方法在同分布数据集上表现出色，密度基方法在异分布情况下更有效，语义一致性方法则普遍可靠。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在各行业的广泛应用，确保其输出的可信度成为关键，而不确定性估计在其中发挥重要作用。

Method: 进行了全面的实证研究，涉及十二种不同的不确定性估计方法和四种生成质量指标，以评估LLM在问答任务中的不确定性。

Result: 分析表明，信息基方法在同分布设置下表现优异，密度基方法P(True)在异分布上下文中效果显著，语义一致性方法在不同数据集和生成指标上表现可靠。

Conclusion: 各种不确定性估计方法在LLM生成答案的有效性方面表现不同，信息基方法在同分布数据集上效果最佳，而密度基方法在异分布数据集上表现突出。

Abstract: Large Language Models (LLMs) have become increasingly pervasive, finding
applications across many industries and disciplines. Ensuring the
trustworthiness of LLM outputs is paramount, where Uncertainty Estimation (UE)
plays a key role. In this work, a comprehensive empirical study is conducted to
examine the robustness and effectiveness of diverse UE measures regarding
aleatoric and epistemic uncertainty in LLMs. It involves twelve different UE
methods and four generation quality metrics including LLMScore from LLM
criticizers to evaluate the uncertainty of LLM-generated answers in
Question-Answering (QA) tasks on both in-distribution (ID) and
out-of-distribution (OOD) datasets. Our analysis reveals that information-based
methods, which leverage token and sequence probabilities, perform exceptionally
well in ID settings due to their alignment with the model's understanding of
the data. Conversely, density-based methods and the P(True) metric exhibit
superior performance in OOD contexts, highlighting their effectiveness in
capturing the model's epistemic uncertainty. Semantic consistency methods,
which assess variability in generated answers, show reliable performance across
different datasets and generation metrics. These methods generally perform well
but may not be optimal for every situation.

</details>


### [49] [BengaliMoralBench: A Benchmark for Auditing Moral Reasoning in Large Language Models within Bengali Language and Culture](https://arxiv.org/abs/2511.03180)
*Shahriyar Zaman Ridoy,Azmine Toushik Wasi,Koushik Ahamed Tonmoy*

Main category: cs.CL

TL;DR: 该研究提出了BengaliMoralBench，这是第一个针对孟加拉语的伦理基准，为负责任的AI本地化提供了基础。


<details>
  <summary>Details</summary>
Motivation: 随着多语言大型语言模型在南亚的普及，需要探索它们与当地伦理规范的契合度，尤其是孟加拉语。

Method: 通过使用统一的提示协议和标准指标对多种语言的大型语言模型进行系统的零样本评估，涵盖了五个道德领域，结合三个伦理视角进行场景注释。

Result: 显著的性能差异（50-91%准确率），在文化基础、常识推理和道德公平性方面表现出一致的弱点。

Conclusion: BengaliMoralBench为孟加拉语的伦理评估提供了基础，促进了负责任的本地化和伦理坚实的人工智能部署。

Abstract: As multilingual Large Language Models (LLMs) gain traction across South Asia,
their alignment with local ethical norms, particularly for Bengali, which is
spoken by over 285 million people and ranked 6th globally, remains
underexplored. Existing ethics benchmarks are largely English-centric and
shaped by Western frameworks, overlooking cultural nuances critical for
real-world deployment. To address this, we introduce BengaliMoralBench, the
first large-scale ethics benchmark for the Bengali language and socio-cultural
contexts. It covers five moral domains, Daily Activities, Habits, Parenting,
Family Relationships, and Religious Activities, subdivided into 50 culturally
relevant subtopics. Each scenario is annotated via native-speaker consensus
using three ethical lenses: Virtue, Commonsense, and Justice ethics. We conduct
systematic zero-shot evaluation of prominent multilingual LLMs, including
Llama, Gemma, Qwen, and DeepSeek, using a unified prompting protocol and
standard metrics. Performance varies widely (50-91% accuracy), with qualitative
analysis revealing consistent weaknesses in cultural grounding, commonsense
reasoning, and moral fairness. BengaliMoralBench provides a foundation for
responsible localization, enabling culturally aligned evaluation and supporting
the deployment of ethically robust AI in diverse, low-resource multilingual
settings such as Bangladesh.

</details>


### [50] [LGM: Enhancing Large Language Models with Conceptual Meta-Relations and Iterative Retrieval](https://arxiv.org/abs/2511.03214)
*Wenchang Lei,Ping Zou,Yue Wang,Feng Sun,Lei Zhao*

Main category: cs.CL

TL;DR: LGM improves large language models' semantic understanding by extracting meta-relations and validating them, outperforming existing methods in handling ambiguous instructions.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of large language models in understanding ambiguous or misaligned user instructions.

Method: LGM utilizes meta-relations extraction and a reflection mechanism, alongside a Concept Iterative Retrieval Algorithm, to improve conceptual clarity and response accuracy.

Result: LGM outperforms traditional Retrieval-Augmented Generation (RAG) approaches on standard benchmarks, allowing processing of texts of any length without truncation.

Conclusion: Language Graph Model (LGM) demonstrated superior performance in enhancing the understanding of large language models, especially in ambiguous contexts.

Abstract: Large language models (LLMs) exhibit strong semantic understanding, yet
struggle when user instructions involve ambiguous or conceptually misaligned
terms. We propose the Language Graph Model (LGM) to enhance conceptual clarity
by extracting meta-relations-inheritance, alias, and composition-from natural
language. The model further employs a reflection mechanism to validate these
meta-relations. Leveraging a Concept Iterative Retrieval Algorithm, these
relations and related descriptions are dynamically supplied to the LLM,
improving its ability to interpret concepts and generate accurate responses.
Unlike conventional Retrieval-Augmented Generation (RAG) approaches that rely
on extended context windows, our method enables large language models to
process texts of any length without the need for truncation. Experiments on
standard benchmarks demonstrate that the LGM consistently outperforms existing
RAG baselines.

</details>


### [51] [Beyond Ranked Lists: The SARAL Framework for Cross-Lingual Document Set Retrieval](https://arxiv.org/abs/2511.03228)
*Shantanu Agarwal,Joel Barry,Elizabeth Boschee,Scott Miller*

Main category: cs.CL

TL;DR: 该报告描述了SARAL在IARPA的MATERIAL项目中的努力，展示其在跨语言信息检索方面的创新方法和优异表现。


<details>
  <summary>Details</summary>
Motivation: 推动跨语言信息检索的进步，满足在任意语言中有效检索英语信息的需求。

Method: 采用新颖的方法处理跨语言信息检索，强调检索与查询相关的文档集，而不仅仅是排名的文档列表。

Result: SARAL在三种语言（波斯语、哈萨克语和乔治亚语）的评估中表现优异，超过了其他团队。

Conclusion: SARAL在MATERIAL的第三阶段评估中在五个评估条件下超越了其他团队的表现，展示了其处理跨语言信息检索的有效性。

Abstract: Machine Translation for English Retrieval of Information in Any Language
(MATERIAL) is an IARPA initiative targeted to advance the state of
cross-lingual information retrieval (CLIR). This report provides a detailed
description of Information Sciences Institute's (ISI's) Summarization and
domain-Adaptive Retrieval Across Language's (SARAL's) effort for MATERIAL.
Specifically, we outline our team's novel approach to handle CLIR with emphasis
in developing an approach amenable to retrieve a query-relevant document
\textit{set}, and not just a ranked document-list. In MATERIAL's Phase-3
evaluations, SARAL exceeded the performance of other teams in five out of six
evaluation conditions spanning three different languages (Farsi, Kazakh, and
Georgian).

</details>


### [52] [IndicSuperTokenizer: An Optimized Tokenizer for Indic Multilingual LLMs](https://arxiv.org/abs/2511.03237)
*Souvik Rana,Arul Menezes,Ashish Kulkarni,Chandra Khatri,Shubham Agarwal*

Main category: cs.CL

TL;DR: IndicSuperTokenizer是为印度多语言LLMs设计的代币化工具，在代币生育分数和推理效率方面取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决多语言环境中代币化的挑战，特别是在语言结构和形态变化较大的情况下。

Method: 结合了子词和多词代币化方法，并进行语言特定的预代币化。

Result: 在对比实验中，IndicSuperTokenizer在英语和22种印度语言上超越了现有最佳代币化模型LLaMA4和Sutra，提升了代币生育分数和推理吞吐量。

Conclusion: IndicSuperTokenizer在处理印度多语言模型时，显著提高了代币的生育分数和推理效率，同时保持了良好的性能。

Abstract: Tokenizers play a crucial role in determining the performance, training
efficiency, and the inference cost of Large Language Models (LLMs). Designing
effective tokenizers for multilingual LLMs is particularly challenging due to
diverse scripts and rich morphological variation. While subword methods such as
Byte Pair Encoding (BPE) are widely adopted, their effectiveness in
multilingual settings remains underexplored. We present IndicSuperTokenizer, a
tokenizer for Indic multilingual LLMs, that combines both subword and
multi-word tokenization, along with language-specific pre-tokenization, leading
to more linguistically aligned tokens and achieving a new state-of-the-art in
fertility score. Evaluated across English, 22 Indian languages and code data,
our tokenizer improves the average fertility score by 39.5% over LLaMA4 and by
18% over Sutra (the current best). This translates to 44% improvement in
inference throughput over LLaMA4 while maintaining comparable performance on
English and Indic benchmarks. We also present detailed ablations across
tokenizer training data size, vocabulary size, merging techniques, and
pre-tokenization strategies, demonstrating the robustness of our design
choices.

</details>


### [53] [Comparing the Performance of LLMs in RAG-based Question-Answering: A Case Study in Computer Science Literature](https://arxiv.org/abs/2511.03261)
*Ranul Dayarathne,Uvini Ranaweera,Upeksha Ganegoda*

Main category: cs.CL

TL;DR: 本研究比较了四种开源LLM与GPT-3.5在问答任务中的表现，结果显示Mistral-7b-instruct与RAG的结合效果最好，GPT-3.5整体性能最优。


<details>
  <summary>Details</summary>
Motivation: 随着RAG和大型语言模型（LLMs）的普及，比较不同LLMs在问答任务中的表现具有重要意义。

Method: 比较四种开源LLM与OpenAI的GPT-3.5在知名计算机科学文献中的QA任务表现，并使用准确性、精确度、人工专家排名以及其他评估指标进行评估。

Result: 基于RAG的GPT-3.5在回答二元和长答题时表现出色，而Mistral-7b-instruct在开源LLM中表现最佳，但Orca-mini-v3-7b的响应时延最短。

Conclusion: 在问答任务中，Mistral-7b-instruct与RAG结合的表现优于其他开源LLM，而GPT-3.5则是综合性能最优的选择。

Abstract: Retrieval Augmented Generation (RAG) is emerging as a powerful technique to
enhance the capabilities of Generative AI models by reducing hallucination.
Thus, the increasing prominence of RAG alongside Large Language Models (LLMs)
has sparked interest in comparing the performance of different LLMs in
question-answering (QA) in diverse domains. This study compares the performance
of four open-source LLMs, Mistral-7b-instruct, LLaMa2-7b-chat,
Falcon-7b-instruct and Orca-mini-v3-7b, and OpenAI's trending GPT-3.5 over QA
tasks within the computer science literature leveraging RAG support. Evaluation
metrics employed in the study include accuracy and precision for binary
questions and ranking by a human expert, ranking by Google's AI model Gemini,
alongside cosine similarity for long-answer questions. GPT-3.5, when paired
with RAG, effectively answers binary and long-answer questions, reaffirming its
status as an advanced LLM. Regarding open-source LLMs, Mistral AI's
Mistral-7b-instruct paired with RAG surpasses the rest in answering both binary
and long-answer questions. However, among the open-source LLMs, Orca-mini-v3-7b
reports the shortest average latency in generating responses, whereas
LLaMa2-7b-chat by Meta reports the highest average latency. This research
underscores the fact that open-source LLMs, too, can go hand in hand with
proprietary models like GPT-3.5 with better infrastructure.

</details>


### [54] [SCALE: Upscaled Continual Learning of Large Language Models](https://arxiv.org/abs/2511.03270)
*Jin-woo Lee,Junhwa Choi,Bongkyu Hwang,Jinho Choo,Bogun Kim,JeongSeon Yi,Joonseok Lee,DongYoung Jung,Jaeseon Park,Kyoungwon Park,Suk-hoon Jung*

Main category: cs.CL

TL;DR: SCALE是一种新的宽度扩展架构，在不干扰基础模型功能的基础上，通过选择性训练扩展组件实现了更好的稳定性和适应性，减轻了遗忘现象并提升了多语言表现。


<details>
  <summary>Details</summary>
Motivation: 随着不断发展的技术，持续预训练的有效性越来越依赖于正确结构的扩展，而不仅仅是参数的扩大。

Method: 引入SCALE架构，主要通过在线性模块中插入轻量级扩展，同时冻结所有预训练参数，以保持模型的原始功能。

Result: 在控制的合成生物学基准测试中，SCALE有效减轻了深度扩展所带来的严重遗忘，在韩语语料库的持续预训练中，SCALE变体在英语评估中记忆遗忘更少，并在韩语基准测试中取得竞争优势。

Conclusion: SCALE架构在持续预训练中提供了更好的稳定性和适应性，通过宽度扩展在不干扰原有模型功能的前提下，有效减少了遗忘现象，并在不同语言的基准测试中表现优越。

Abstract: We revisit continual pre-training for large language models and argue that
progress now depends more on scaling the right structure than on scaling
parameters alone. We introduce SCALE, a width upscaling architecture that
inserts lightweight expansion into linear modules while freezing all
pre-trained parameters. This preserves the residual and attention topologies
and increases capacity without perturbing the base model's original
functionality. SCALE is guided by two principles: Persistent Preservation,
which maintains the base model's behavior via preservation-oriented
initialization and freezing of the pre-trained weights, and Collaborative
Adaptation, which selectively trains a subset of expansion components to
acquire new knowledge with minimal interference. We instantiate these ideas as
SCALE-Preserve (preservation-first), SCALE-Adapt (adaptation-first), and
SCALE-Route, an optional routing extension that performs token-level routing
between preservation and adaptation heads. On a controlled synthetic biography
benchmark, SCALE mitigates the severe forgetting observed with depth expansion
while still acquiring new knowledge. In continual pre-training on a Korean
corpus, SCALE variants achieve less forgetting on English evaluations and
competitive gains on Korean benchmarks, with these variants offering the best
overall stability-plasticity trade-off. Accompanying analysis clarifies when
preservation provably holds and why the interplay between preservation and
adaptation stabilizes optimization compared to standard continual learning
setups.

</details>


### [55] [Step-Audio-EditX Technical Report](https://arxiv.org/abs/2511.03601)
*Chao Yan,Boyong Wu,Peng Yang,Pengfei Tan,Guoqiang Hu,Yuxin Zhang,Xiangyu,Zhang,Fei Tian,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu*

Main category: cs.CL

TL;DR: Step-Audio-EditX是一个开源的音频模型，采用大边际学习方法，在音频编辑和文本到语音能力上表现优异。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于发展一种开源的音频模型，能够在情感、讲话风格和副语言学方面进行表现力强且迭代的音频编辑，提升文本到语音的能力。

Method: 该论文采用了大边际合成数据的方法，省去了嵌入式先验或辅助模块，实现了迭代控制和高表现力。

Result: 评估结果表明，Step-Audio-EditX在情感编辑等精细控制任务上优于MiniMax-2.6-hd和Doubao-Seed-TTS-2.0。

Conclusion: Step-Audio-EditX在情感编辑和其他精细控制任务中 surpasses了现有模型，展示了其在音频编辑领域的创新潜力。

Abstract: We present Step-Audio-EditX, the first open-source LLM-based audio model
excelling at expressive and iterative audio editing encompassing emotion,
speaking style, and paralinguistics alongside robust zero-shot text-to-speech
(TTS) capabilities.Our core innovation lies in leveraging only large-margin
synthetic data, which circumvents the need for embedding-based priors or
auxiliary modules. This large-margin learning approach enables both iterative
control and high expressivity across voices, and represents a fundamental pivot
from the conventional focus on representation-level disentanglement. Evaluation
results demonstrate that Step-Audio-EditX surpasses both MiniMax-2.6-hd and
Doubao-Seed-TTS-2.0 in emotion editing and other fine-grained control tasks.

</details>


### [56] [Benchmarking the Thinking Mode of Multimodal Large Language Models in Clinical Tasks](https://arxiv.org/abs/2511.03328)
*Jindong Hong,Tianjie Chen,Lingjie Luo,Chuanyang Zheng,Ting Xu,Haibao Yu,Jianing Qiu,Qianzhong Chen,Suning Huang,Yan Xu,Yong Gui,Yijun He,Jiankai Sun*

Main category: cs.CL

TL;DR: 研究评估了新型多模态大语言模型的思维模式在医疗任务中的表现，结果显示提升有限，复杂任务依旧需要更有效的医疗数据和方法。


<details>
  <summary>Details</summary>
Motivation: 随着双状态多模态大语言模型的快速发展，评估其增强的推理过程对临床任务性能和可靠性的影响显得尤为重要。

Method: 评估两种领先的多模态大语言模型在医疗应用中的主动思维模式能力，结合VQA-RAD和ROCOv2数据集，分析其在四个视觉医疗任务中的表现。

Result: 在激活思维模式后，Seed1.5-VL和Gemini-2.5-Flash在复杂医疗任务上仍表现不佳，且提升幅度有限。

Conclusion: 激活思维模式对大多数任务的提升幅度有限，复杂医疗任务表现仍不理想，需更专业的医疗数据与整合方法。

Abstract: A recent advancement in Multimodal Large Language Models (MLLMs) research is
the emergence of "reasoning MLLMs" that offer explicit control over their
internal thinking processes (normally referred as the "thinking mode")
alongside the standard "non-thinking mode". This capability allows these models
to engage in a step-by-step process of internal deliberation before generating
a final response. With the rapid transition to and adoption of these
"dual-state" MLLMs, this work rigorously evaluated how the enhanced reasoning
processes of these MLLMs impact model performance and reliability in clinical
tasks. This paper evaluates the active "thinking mode" capabilities of two
leading MLLMs, Seed1.5-VL and Gemini-2.5-Flash, for medical applications. We
assessed their performance on four visual medical tasks using VQA-RAD and
ROCOv2 datasets. Our findings reveal that the improvement from activating the
thinking mode remains marginal compared to the standard non-thinking mode for
the majority of the tasks. Their performance on complex medical tasks such as
open-ended VQA and medical image interpretation remains suboptimal,
highlighting the need for domain-specific medical data and more advanced
methods for medical knowledge integration.

</details>


### [57] [Generative Artificial Intelligence in Bioinformatics: A Systematic Review of Models, Applications, and Methodological Advances](https://arxiv.org/abs/2511.03354)
*Riasad Alvi,Sayeem Been Zaman,Wasimul Karim,Arefin Ittesafun Abian,Mohaimenul Azam Khan Raiaan,Saddam Mukta,Md Rafi Ur Rashid,Md Rafiqul Islam,Yakub Sebastian,Sami Azam*

Main category: cs.CL

TL;DR: 生成性人工智能正在改变生物信息学，提升分析准确性和模型性能，同时还面临数据可扩展性和偏差等挑战。


<details>
  <summary>Details</summary>
Motivation: 为了识别和评估生成性人工智能在生物信息学领域中的新兴进展，以实现方法论的提升、预测性能的改善和专业化发展。

Method: 本综述通过提出六个研究问题（RQ）系统性评估了生成性人工智能在生物信息学中的发展，采用了系统评价和元分析的方法。

Result: 研究表明，生成性人工智能在生物信息学的多个子领域应用表现出优越的性能，适应性模型架构和数据集的使用对结果质量有显著影响。

Conclusion: 综上所述，生成性人工智能在生物信息学中的应用展现出显著的前景和潜力，尤其是在提高分析准确性和模型性能方面，但仍面临诸多挑战。

Abstract: Generative artificial intelligence (GenAI) has become a transformative
approach in bioinformatics that often enables advancements in genomics,
proteomics, transcriptomics, structural biology, and drug discovery. To
systematically identify and evaluate these growing developments, this review
proposed six research questions (RQs), according to the preferred reporting
items for systematic reviews and meta-analysis methods. The objective is to
evaluate impactful GenAI strategies in methodological advancement, predictive
performance, and specialization, and to identify promising approaches for
advanced modeling, data-intensive discovery, and integrative biological
analysis. RQ1 highlights diverse applications across multiple bioinformatics
subfields (sequence analysis, molecular design, and integrative data modeling),
which demonstrate superior performance over traditional methods through pattern
recognition and output generation. RQ2 reveals that adapted specialized model
architectures outperformed general-purpose models, an advantage attributed to
targeted pretraining and context-aware strategies. RQ3 identifies significant
benefits in the bioinformatics domains, focusing on molecular analysis and data
integration, which improves accuracy and reduces errors in complex analysis.
RQ4 indicates improvements in structural modeling, functional prediction, and
synthetic data generation, validated by established benchmarks. RQ5 suggests
the main constraints, such as the lack of scalability and biases in data that
impact generalizability, and proposes future directions focused on robust
evaluation and biologically grounded modeling. RQ6 examines that molecular
datasets (such as UniProtKB and ProteinNet12), cellular datasets (such as
CELLxGENE and GTEx) and textual resources (such as PubMedQA and OMIM) broadly
support the training and generalization of GenAI models.

</details>


### [58] [Silenced Biases: The Dark Side LLMs Learned to Refuse](https://arxiv.org/abs/2511.03369)
*Rom Himelstein,Amit LeVi,Brit Youngmann,Yaniv Nemcovsky,Avi Mendelson*

Main category: cs.CL

TL;DR: 本研究提出了沉默偏见的概念及相应的沉默偏见基准，以评估大型语言模型中的潜在不公平偏见，改进现有的公平性评估方法。


<details>
  <summary>Details</summary>
Motivation: 在具有敏感性的应用中，传统评估公平性的方法容易导致错误的公平感受，因此亟需有效的评估工具来揭示潜在偏见。

Method: 通过激活引导技术，减少模型在问答中的拒绝反应，以检测和评估模型的公平性。

Result: 我们的研究揭示了不同大型语言模型之间在直接回应和潜在公平性问题之间的显著差异。

Conclusion: 本研究引入了一个新概念，即沉默偏见，并提出了沉默偏见基准（SBB），以揭示大型语言模型中的潜在不公平偏见。

Abstract: Safety-aligned large language models (LLMs) are becoming increasingly
widespread, especially in sensitive applications where fairness is essential
and biased outputs can cause significant harm. However, evaluating the fairness
of models is a complex challenge, and approaches that do so typically utilize
standard question-answer (QA) styled schemes. Such methods often overlook
deeper issues by interpreting the model's refusal responses as positive
fairness measurements, which creates a false sense of fairness. In this work,
we introduce the concept of silenced biases, which are unfair preferences
encoded within models' latent space and are effectively concealed by
safety-alignment. Previous approaches that considered similar indirect biases
often relied on prompt manipulation or handcrafted implicit queries, which
present limited scalability and risk contaminating the evaluation process with
additional biases. We propose the Silenced Bias Benchmark (SBB), which aims to
uncover these biases by employing activation steering to reduce model refusals
during QA. SBB supports easy expansion to new demographic groups and subjects,
presenting a fairness evaluation framework that encourages the future
development of fair models and tools beyond the masking effects of alignment
training. We demonstrate our approach over multiple LLMs, where our findings
expose an alarming distinction between models' direct responses and their
underlying fairness issues.

</details>


### [59] [LFC-DA: Logical Formula-Controlled Data Augmentation for Enhanced Logical Reasoning](https://arxiv.org/abs/2511.03372)
*Shenghao Li*

Main category: cs.CL

TL;DR: LFC-DA通过系统化的符号逻辑控制管道改善逻辑数据增强，提升了模型逻辑推理的准确性。


<details>
  <summary>Details</summary>
Motivation: 复杂逻辑数据增强的人工标注成本高，而直接使用大型语言模型生成的示例往往缺乏可解释性和逻辑多样性。

Method: LFC-DA通过将逻辑文本映射为命题表达式，编译规则库，并系统性地发现有效公式，最后将其转化为自然语言问题。

Result: 在ReClor和LogiQA上的实验结果表明，LFC-DA在逻辑推理准确性上有显著提升。

Conclusion: LFC-DA显著提升了预训练模型的逻辑推理准确性，验证了其在逻辑数据增强中的有效性。

Abstract: For complex logical data augmentation, heavy reliance on human annotation is
costly, whereas direct generation with large language models yields
uninterpretable and logically homogeneous examples. To address this, we present
LFC-DA, a symbolic-logic-controlled pipeline: logical text is first mapped to
propositional expressions, a compact rule library is compiled, and a bounded
state-space search systematically discovers valid formulas that are then
verbalized back into natural-language questions, ensuring both diversity and
logical rigor under propositional logic. Experiments on ReClor and LogiQA show
significant improvements in the logical-reasoning accuracy of pretrained
models, confirming the effectiveness of LFC-DA for LLM-guided logical data
augmentation.

</details>


### [60] [Segmentation Beyond Defaults: Asymmetrical Byte Pair Encoding for Optimal Machine Translation Performance](https://arxiv.org/abs/2511.03383)
*Saumitra Yadav,Manish Shrivastava*

Main category: cs.CL

TL;DR: 研究表明，不对称的BPE在低资源机器翻译中效果更佳，适应性调整源语言和目标语言的合并操作数能够显著提升翻译质量。


<details>
  <summary>Details</summary>
Motivation: 传统的固定超参数设置未能保证在不同语言对和数据规模上的最佳机器翻译效果。

Method: 通过评估不同数据量与语言对的BPE分割方法，进行机器翻译系统性能比较。

Result: 不对称BPE在低资源环境下，与对称BPE相比，显著提高了机器翻译的性能，特别是在特定的句子对数下。

Conclusion: 不对称的字节配对编码（BPE）方法在低资源机器翻译中显著提高了翻译性能，尤其是源语言与目标语言的合并操作数不同可以带来更好的结果。

Abstract: Existing Machine Translation (MT) research often suggests a single, fixed set
of hyperparameters for word segmentation models, symmetric Byte Pair Encoding
(BPE), which applies the same number of merge operations (NMO) to train
tokenizers for both source and target languages. However, we demonstrate that
this uniform approach doesn't guarantee optimal MT performance across different
language pairs and data sizes. This work investigates BPE segmentation recipes
across various data volumes and language pairs to evaluate MT system
performance. We find that utilizing asymmetric BPE, where the source and target
languages have different NMOs, significantly improves results over the
symmetric approach, especially in low-resource settings (50K, 100K, and 500K
sentence pairs). Specifically, asymmetric BPE yield statistically significant
($p<0.05$) average gains of 5.32, 4.46, and 0.7 CHRF++ on English-Hindi in
low-resource setups. We validated this trend across six additional language
pairs (English and Telugu, Shona, Norwegian, Kyrgyz, Hausa, and Inuktitut),
observing statistically significant improvement in 10 out of 12 systems
compared to symmetric BPE. Our findings indicate a high NMO for the source (4K
to 32K) and a low NMO for the target (0.5K to 2K) provides optimal results,
particularly benefiting low-resource MT.

</details>


### [61] [Overcoming the Generalization Limits of SLM Finetuning for Shape-Based Extraction of Datatype and Object Properties](https://arxiv.org/abs/2511.03407)
*Célian Ringwald,Fabien Gandon,Catherine Faron,Franck Michel,Hanna Abi Akl*

Main category: cs.CL

TL;DR: 本文研究了如何改进小型语言模型在RDF图提取中的表现，提出有效的训练策略以应对长尾属性问题，并分享数据集和实验结果以促进可复现性。


<details>
  <summary>Details</summary>
Motivation: 探讨小型语言模型在提取完整RDF图时如何处理数据类型和对象属性，并应对稀有属性的长尾分布问题。

Method: 通过评估分层抽样、加权损失、数据集扩展和基于模板的合成数据增强等几种策略，对小型语言模型进行比较研究。

Result: 验证了一个重要策略，即构建训练集，使每种属性的出现次数超过特定阈值，从而在不平衡目标属性上获得较好效果。

Conclusion: 本研究强调了小型语言模型在处理RDF图提取时的潜力，并指出了长尾分布的挑战和有效的解决策略。

Abstract: Small language models (SLMs) have shown promises for relation extraction (RE)
when extracting RDF triples guided by SHACL shapes focused on common datatype
properties. This paper investigates how SLMs handle both datatype and object
properties for a complete RDF graph extraction. We show that the key bottleneck
is related to long-tail distribution of rare properties. To solve this issue,
we evaluate several strategies: stratified sampling, weighted loss, dataset
scaling, and template-based synthetic data augmentation. We show that the best
strategy to perform equally well over unbalanced target properties is to build
a training set where the number of occurrences of each property exceeds a given
threshold. To enable reproducibility, we publicly released our datasets,
experimental results and code. Our findings offer practical guidance for
training shape-aware SLMs and highlight promising directions for future work in
semantic RE.

</details>


### [62] [Efficient Reasoning via Thought-Training and Thought-Free Inference](https://arxiv.org/abs/2511.03408)
*Canhui Wu,Qiong Cao,Chao Xue,Wei Xi,Xiaodong He*

Main category: cs.CL

TL;DR: 3TF框架通过结合推理和非推理模式，使模型在无显性推理下实现高质量推理，并在推理效率上得到提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过压缩冗长的推理输出来提高推理准确性，但依然需要在推理过程中进行显式推理，限制了效率。

Method: 引入混合模型，训练其在推理和非推理模式下的操作，并使用CoT标注数据进行进一步训练，以内化结构化推理，同时在推理时强制输出简洁的思维-free结果。

Result: 3TF训练的模型在无思维推理的情况下，在推理基准测试中表现出显著提升，证明高质量推理可以隐式学习和执行。

Conclusion: 3TF框架能够在无显性推理的情况下实现高质量的推理，并提升长文本到短文本的输出效率，验证了隐式推理的有效性。

Abstract: Recent advances in large language models (LLMs) have leveraged explicit
Chain-of-Thought (CoT) prompting to improve reasoning accuracy. However, most
existing methods primarily compress verbose reasoning outputs. These
Long-to-Short transformations aim to improve efficiency, but still rely on
explicit reasoning during inference. In this work, we introduce \textbf{3TF}
(\textbf{T}hought-\textbf{T}raining and \textbf{T}hought-\textbf{F}ree
inference), a framework for efficient reasoning that takes a Short-to-Long
perspective. We first train a hybrid model that can operate in both reasoning
and non-reasoning modes, and then further train it on CoT-annotated data to
internalize structured reasoning, while enforcing concise, thought-free outputs
at inference time using the no-reasoning mode. Unlike compression-based
approaches, 3TF improves the reasoning quality of non-reasoning outputs,
enabling models to perform rich internal reasoning implicitly while keeping
external outputs short. Empirically, 3TF-trained models obtain large
improvements on reasoning benchmarks under thought-free inference,
demonstrating that high quality reasoning can be learned and executed
implicitly without explicit step-by-step generation.

</details>


### [63] [Knowledge-Augmented Question Error Correction for Chinese Question Answer System with QuestionRAG](https://arxiv.org/abs/2511.03410)
*Longpeng Qiu,Ting Li,Shuai Mao,Nan Yang,Xiaohui Yan*

Main category: cs.CL

TL;DR: QuestionRAG 框架通过知识增强和强化学习解决了问答系统中的误解与过度修正问题，提高了对输入错误的处理能力。


<details>
  <summary>Details</summary>
Motivation: 输入错误常常导致问答系统产生错误响应，而大型语言模型在处理这些问题时常常表现不佳。

Method: 该框架通过外部知识丰富输入以解决用户意图的误解，并利用强化学习确保模型目标与精确修正对齐。

Result: 研究结果表明，知识增强对于理解错误问题至关重要，同时基于强化学习的对齐明显优于传统的监督微调，增强了模型的指令遵循能力和泛化能力。

Conclusion: 通过整合知识增强和基于强化学习的对齐策略，QuestionRAG 最大限度地发挥了大型语言模型在问题纠正任务中的潜力。

Abstract: Input errors in question-answering (QA) systems often lead to incorrect
responses. Large language models (LLMs) struggle with this task, frequently
failing to interpret user intent (misinterpretation) or unnecessarily altering
the original question's structure (over-correction). We propose QuestionRAG, a
framework that tackles these problems. To address misinterpretation, it
enriches the input with external knowledge (e.g., search results, related
entities). To prevent over-correction, it uses reinforcement learning (RL) to
align the model's objective with precise correction, not just paraphrasing. Our
results demonstrate that knowledge augmentation is critical for understanding
faulty questions. Furthermore, RL-based alignment proves significantly more
effective than traditional supervised fine-tuning (SFT), boosting the model's
ability to follow instructions and generalize. By integrating these two
strategies, QuestionRAG unlocks the full potential of LLMs for the question
correction task.

</details>


### [64] [CareMedEval dataset: Evaluating Critical Appraisal and Reasoning in the Biomedical Field](https://arxiv.org/abs/2511.03441)
*Doria Bonzi,Alexandre Guiggi,Frédéric Béchet,Carlos Ramisch,Benoit Favre*

Main category: cs.CL

TL;DR: CareMedEval 是评估大型语言模型在生物医学批判性评价能力的新数据集，展示了现有模型的限制，并为未来发展自动化支持提供了基础。


<details>
  <summary>Details</summary>
Motivation: 生物医学领域对科学文献的批判性评价是重要技能，而现有的大型语言模型在特定领域的可靠性有限。

Method: 通过分析法国外科医学生的真实考试，构建了一个包含534个问题的 CareMedEval 数据集，基于37篇科学文章，评估大型语言模型在生物医学批判性评价和推理任务中的表现。

Result: 在各种背景条件下，对最先进的通用和生物医学专科 LLM 进行基准测试，结果显示这些模型在理解研究的局限性和统计分析方面依然面临挑战，且即便生成中间推理由也未能显著提高它们的精准匹配率。

Conclusion: CareMedEval 为生物医学领域的批判性评价提供了具有挑战性的基准，暴露了当前大型语言模型的局限性，并为未来自动化批判性评价支持的发展指明了方向。

Abstract: Critical appraisal of scientific literature is an essential skill in the
biomedical field. While large language models (LLMs) can offer promising
support in this task, their reliability remains limited, particularly for
critical reasoning in specialized domains. We introduce CareMedEval, an
original dataset designed to evaluate LLMs on biomedical critical appraisal and
reasoning tasks. Derived from authentic exams taken by French medical students,
the dataset contains 534 questions based on 37 scientific articles. Unlike
existing benchmarks, CareMedEval explicitly evaluates critical reading and
reasoning grounded in scientific papers. Benchmarking state-of-the-art
generalist and biomedical-specialized LLMs under various context conditions
reveals the difficulty of the task: open and commercial models fail to exceed
an Exact Match Rate of 0.5 even though generating intermediate reasoning tokens
considerably improves the results. Yet, models remain challenged especially on
questions about study limitations and statistical analysis. CareMedEval
provides a challenging benchmark for grounded reasoning, exposing current LLM
limitations and paving the way for future development of automated support for
critical appraisal.

</details>


### [65] [Kastor: Fine-tuned Small Language Models for Shape-based Active Relation Extraction](https://arxiv.org/abs/2511.03466)
*Ringwald Celian,Gandon Fabien,Faron Catherine,Michel Franck,Abi Akl Hanna*

Main category: cs.CL

TL;DR: Kastor框架通过优化属性组合和迭代学习过程，有效提升了针对小语言模型的关系提取任务的模型性能和知识库质量。


<details>
  <summary>Details</summary>
Motivation: 在特定领域中，需求增加，需完善和补充知识库，传统的单一SHACL验证方法难以实现。

Method: Kastor框架重新设计了传统的验证任务，通过评估所有可能的属性组合来优化训练例子的选择。

Result: Kastor通过选择每个训练示例的最佳属性组合，提高了模型的效率与性能，且能够处理嘈杂的知识库。

Conclusion: Kastor框架通过评估来自SHACL形状的属性组合，提升了模型的一般化能力和性能，能够有效地从嘈杂的知识库中提炼出新的相关事实。

Abstract: RDF pattern-based extraction is a compelling approach for fine-tuning small
language models (SLMs) by focusing a relation extraction task on a specified
SHACL shape. This technique enables the development of efficient models trained
on limited text and RDF data. In this article, we introduce Kastor, a framework
that advances this approach to meet the demands for completing and refining
knowledge bases in specialized domains. Kastor reformulates the traditional
validation task, shifting from single SHACL shape validation to evaluating all
possible combinations of properties derived from the shape. By selecting the
optimal combination for each training example, the framework significantly
enhances model generalization and performance. Additionally, Kastor employs an
iterative learning process to refine noisy knowledge bases, enabling the
creation of robust models capable of uncovering new, relevant facts

</details>


### [66] [BanglaSTEM: A Parallel Corpus for Technical Domain Bangla-English Translation](https://arxiv.org/abs/2511.03498)
*Kazi Reyazul Hasan,Mubasshira Musarrat,A. B. M. Alim Al Islam,Muhammad Abdullah Adnan*

Main category: cs.CL

TL;DR: 本文提出BanglaSTEM数据集和T5模型，旨在改善孟加拉语技术内容的翻译准确性，提升孟加拉语用户使用英文语言模型的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的孟加拉语-英语翻译系统在处理技术术语时存在困难，导致错误答案，因此需要一个专注于STEM领域的高质量翻译数据集和模型。

Method: 构建了一个包含5000对孟加拉语-英语句子的BanglaSTEM数据集，使用语言模型生成超过12000个翻译，并通过人工评估选择高质量句子对，最后用T5模型进行训练和测试。

Result: 通过使用BanglaSTEM数据集，在代码生成和数学问题解决任务上，翻译准确性有了显著提高。

Conclusion: BanglaSTEM数据集和训练后的翻译模型在技术内容翻译准确性上有显著改善，使得孟加拉语使用者能够更有效地使用以英语为中心的语言模型。

Abstract: Large language models work well for technical problem solving in English but
perform poorly when the same questions are asked in Bangla. A simple solution
would be to translate Bangla questions into English first and then use these
models. However, existing Bangla-English translation systems struggle with
technical terms. They often mistranslate specialized vocabulary, which changes
the meaning of the problem and leads to wrong answers. We present BanglaSTEM, a
dataset of 5,000 carefully selected Bangla-English sentence pairs from STEM
fields including computer science, mathematics, physics, chemistry, and
biology. We generated over 12,000 translations using language models and then
used human evaluators to select the highest quality pairs that preserve
technical terminology correctly. We train a T5-based translation model on
BanglaSTEM and test it on two tasks: generating code and solving math problems.
Our results show significant improvements in translation accuracy for technical
content, making it easier for Bangla speakers to use English-focused language
models effectively. Both the BanglaSTEM dataset and the trained translation
model are publicly released at https://huggingface.co/reyazul/BanglaSTEM-T5.

</details>


### [67] [One Battle After Another: Probing LLMs' Limits on Multi-Turn Instruction Following with a Benchmark Evolving Framework](https://arxiv.org/abs/2511.03508)
*Qi Jia,Kaiwei Zhang,Xiujie Song,Ye Shen,Xiangyang Zhu,Guangtao Zhai*

Main category: cs.CL

TL;DR: 本研究提出了一种新框架来评估大型语言模型的多轮指令跟随能力，显示GPT-5的性能显著优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试限制于固定轮次，未能充分考虑用户的互动体验，这促使开发一个更动态的评估方法。

Method: 提出一个可扩展的框架来评估多轮指令跟随能力，解耦语言表面形式与用户意图模拟。

Result: 构建了EvolIF基准，GPT-5在对话中平均维持18.54轮，表现出70.31%的鲁棒性，显著优于Gemini-2.5-Pro。

Conclusion: GPT-5在多轮指令跟随能力上表现优越，超越了其他模型，展现出更高的对话持续性和鲁棒性。

Abstract: Understanding how well large language models can follow users' instructions
throughout a dialogue spanning multiple topics is of great importance for
data-intensive conversational applications. Existing benchmarks are often
limited to a fixed number of turns, making them susceptible to saturation and
failing to account for the user's interactive experience. In this work, we
propose an extensible framework for assessing multi-turn instruction-following
ability. At its core, our framework decouples linguistic surface forms from
user intent simulation through a three-layer mechanism that tracks constraints,
instructions, and topics. This framework mimics User-LLM interaction by
enabling the dynamic construction of benchmarks with state changes and
tracebacks, terminating a conversation only when the model exhausts a simulated
user's patience. We define a suite of metrics capturing the quality of the
interaction process. Using this framework, we construct EvolIF, an evolving
instruction-following benchmark incorporating nine distinct constraint types.
Our results indicate that GPT-5 exhibits superior instruction-following
performance. It sustains an average of 18.54 conversational turns and
demonstrates 70.31% robustness, outperforming Gemini-2.5-Pro by a significant
margin of 11.41%, while other models lag far behind. All of the data and code
will be made publicly available online.

</details>


### [68] [MultiZebraLogic: A Multilingual Logical Reasoning Benchmark](https://arxiv.org/abs/2511.03553)
*Sofie Helene Bruun,Dan Saattrup Smart*

Main category: cs.CL

TL;DR: 本研究开发了跨语言的逻辑推理解谜数据集，并探讨了不同难度的影响，评估用于大型语言模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了全面评估大型语言模型的能力，需要不同任务的基准测试。我们希望通过创建多种逻辑推理难题的数据集，来比较不同模型的表现。

Method: 通过生成包含不同主题、大小和线索类型的斑马难题，评估不同语言模型的逻辑推理能力。

Result: 我们发现特定大小的难题对于不同的模型具有不同的挑战性，同时不同线索类型与难度之间没有明显关联。提供了128+1024个难题数据集供研究使用。

Conclusion: 本研究开发了高质量的跨语言逻辑推理解谜数据集，并提供了多种难度选择，以评估大型语言模型的推理能力。

Abstract: Measuring the full abilities of large language models (LLMs) requires
benchmarks representing multiple tasks. We aim to create large, high-quality
datasets for comparison of logical reasoning skills across several languages
and of suitable difficulty for LLMs of various reasoning ability. We explore
multiple ways of increasing difficulty. We generate zebra puzzles in multiple
languages, themes, sizes and including 14 different clue types and 8 red
herring types (uninformative clues). We find puzzle sizes 2x3 and 4x5 are
sufficiently challenging for GPT-4o mini (a non-reasoning model) and o3-mini (a
reasoning model), respectively. Including 5 red herrings decreases o3-mini
puzzle-level accuracy on 4x5 puzzles by 15$\pm$7 %. Scores of o3-mini on 4x5
puzzles are not significantly affected by use of English vs. Danish or the
common houses theme vs. the country-specific smoerrebroed theme. We find no
correlation between difficulty and the selected clue types. Datasets of
128+1024 puzzles are published as MultiZebraLogic in each of nine Germanic
languages for sizes 2x3 and 4x5. We publish code for puzzle generation,
designed for adaptablity into more languages and themes.

</details>


### [69] [AILA--First Experiments with Localist Language Models](https://arxiv.org/abs/2511.03559)
*Joachim Diederich*

Main category: cs.CL

TL;DR: 本文首次展示了在变压器语言模型中可控局部性的实证，通过调节局部性参数实现益处明显的透明性与性能平衡。


<details>
  <summary>Details</summary>
Motivation: 研究传统语言模型在可解释性和效率之间的权衡，提出一种新架构以实现动态控制。

Method: 通过在WikiText语料库上进行实验，系统地变化局部性参数{
lambda}，分析其对模型表现的影响。

Result: 局部配置在注意力熵和指针保真度得分上明显优于完全分布式配置，局部性值{
lambda}=0.6时表现最佳。

Conclusion: 本研究证明了局部语言模型在透明性和性能之间的可控性，为需要这两者的应用提供了有效的方法。

Abstract: This paper presents the first empirical demonstration of controllable
locality in transformer language models, a novel architectural framework that
enables continuous control over the degree of representation localization
through a tunable locality dial parameter. Unlike traditional language models
that rely exclusively on distributed representations, our approach allows
dynamic interpolation between highly interpretable localist encodings and
efficient distributed representations without requiring model retraining. We
conducted experiments on the WikiText corpus using a two-layer transformer
architecture, systematically varying the locality parameter {\lambda} across
the full spectrum from 1.0 (fully localist) to 0.0 (fully distributed). Our
results demonstrate that localist configurations achieve dramatically lower
attention entropy, with {\lambda} = 1.0 yielding 5.36 bits compared to 7.18
bits at {\lambda} = 0.0, while maintaining substantially higher pointer
fidelity scores reflecting stronger alignment with rule-specified targets.
Prediction experiments reveal that intermediate locality values optimize the
tradeoff between interpretability and performance, with {\lambda} = 0.6
achieving test perplexity of 4.65 and accuracy of 84.7%. These findings
establish that localist language models provide a practical framework for
applications in regulated domains requiring both transparency and capability,
offering precise mathematical control over the interpretability-performance
spectrum through explicit penalty thresholds and information-theoretic design
principles.

</details>


### [70] [ASVRI-Legal: Fine-Tuning LLMs with Retrieval Augmented Generation for Enhanced Legal Regulation](https://arxiv.org/abs/2511.03563)
*One Octadion,Bondan Sapta Prakoso,Nanang Yudi Setiawan,Novanto Yudistira*

Main category: cs.CL

TL;DR: 本研究通过微调大型语言模型与检索增强生成方法相结合，提升了政策制定者在法律文本处理和法规制定中的效率。


<details>
  <summary>Details</summary>
Motivation: 为了帮助政策制定者更好地理解、分析和制定法律法规，提升法律领域的研究效率。

Method: 本研究通过创建针对法律领域的监督数据集，并结合检索增强生成(RAG)方法，以增强模型对法律文本的理解和处理能力。

Result: 结合微调与RAG方法的工具能有效支持政策制定者在解释法规和起草新规时的工作，提高法律信息处理的能力。

Conclusion: 该研究展示了通过微调大型语言模型与检索增强生成方法相结合，可以显著提高法律研究和法规制定的效果。

Abstract: In this study, we explore the fine-tuning of Large Language Models (LLMs) to
better support policymakers in their crucial work of understanding, analyzing,
and crafting legal regulations. To equip the model with a deep understanding of
legal texts, we curated a supervised dataset tailored to the specific needs of
the legal domain. Additionally, we integrated the Retrieval-Augmented
Generation (RAG) method, enabling the LLM to access and incorporate up-to-date
legal knowledge from external sources. This combination of fine-tuning and
RAG-based augmentation results in a tool that not only processes legal
information but actively assists policymakers in interpreting regulations and
drafting new ones that align with current needs. The results demonstrate that
this approach can significantly enhance the effectiveness of legal research and
regulation development, offering a valuable resource in the ever-evolving field
of law.

</details>


### [71] [A systematic review of relation extraction task since the emergence of Transformers](https://arxiv.org/abs/2511.03610)
*Ringwald Celian,Gandon,Fabien,Faron Catherine,Michel Franck,Abi Akl Hanna*

Main category: cs.CL

TL;DR: 本研究对关系抽取领域自Transformer模型以来的研究进行了系统综述，分析了相关文献，并识别了研究趋势和未来挑战。


<details>
  <summary>Details</summary>
Motivation: 随着基于Transformer的模型的兴起，关系抽取研究需要一个系统的综述，以更好地理解其发展和未来方向。

Method: 使用自动化框架收集和注释文献，分析了2019年至2024年间发表的34篇综述、64个数据集和104个模型。

Result: 综述突出了方法论进展、基准资源和语义网技术的整合，通过多维度整合结果，提出了当前的趋势和挑战。

Conclusion: 该研究为关系抽取（RE）领域提供了全面的参考，识别了当前趋势、局限性和开放挑战，以指导未来研究方向。

Abstract: This article presents a systematic review of relation extraction (RE)
research since the advent of Transformer-based models. Using an automated
framework to collect and annotate publications, we analyze 34 surveys, 64
datasets, and 104 models published between 2019 and 2024. The review highlights
methodological advances, benchmark resources, and the integration of semantic
web technologies. By consolidating results across multiple dimensions, the
study identifies current trends, limitations, and open challenges, offering
researchers and practitioners a comprehensive reference for understanding the
evolution and future directions of RE.

</details>


### [72] [Towards Transparent Stance Detection: A Zero-Shot Approach Using Implicit and Explicit Interpretability](https://arxiv.org/abs/2511.03635)
*Apoorva Upadhyaya,Wolfgang Nejdl,Marco Fisichella*

Main category: cs.CL

TL;DR: 本研究提出了一种新的可解释ZSSD框架IRIS，通过隐性和显性理由，提升了模型的可解释性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究在零样本立场检测中面临一般化问题和文本与目标之间缺乏一致性，因此有必要开发一种可解释且有效的模型。

Method: 开发了一种新的可解释ZSSD框架IRIS，将立场检测视为信息检索排序任务，利用隐性和显性理由来引导模型进行正确预测。

Result: 在多个基准数据集上的广泛实验（使用50%、30%和10%的训练数据）表明，IRIS模型在提供可解释性的同时，具有优秀的泛化能力。

Conclusion: IRIS框架通过隐性和显性理由提供了对零样本立场检测的可解释性，实现了更高的模型可泛化性。

Abstract: Zero-Shot Stance Detection (ZSSD) identifies the attitude of the post toward
unseen targets. Existing research using contrastive, meta-learning, or data
augmentation suffers from generalizability issues or lack of coherence between
text and target. Recent works leveraging large language models (LLMs) for ZSSD
focus either on improving unseen target-specific knowledge or generating
explanations for stance analysis. However, most of these works are limited by
their over-reliance on explicit reasoning, provide coarse explanations that
lack nuance, and do not explicitly model the reasoning process, making it
difficult to interpret the model's predictions. To address these issues, in our
study, we develop a novel interpretable ZSSD framework, IRIS. We provide an
interpretable understanding of the attitude of the input towards the target
implicitly based on sequences within the text (implicit rationales) and
explicitly based on linguistic measures (explicit rationales). IRIS considers
stance detection as an information retrieval ranking task, understanding the
relevance of implicit rationales for different stances to guide the model
towards correct predictions without requiring the ground-truth of rationales,
thus providing inherent interpretability. In addition, explicit rationales
based on communicative features help decode the emotional and cognitive
dimensions of stance, offering an interpretable understanding of the author's
attitude towards the given target. Extensive experiments on the benchmark
datasets of VAST, EZ-STANCE, P-Stance, and RFD using 50%, 30%, and even 10%
training data prove the generalizability of our model, benefiting from the
proposed architecture and interpretable design.

</details>


### [73] [ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation](https://arxiv.org/abs/2511.03656)
*Jing Gao,Shutiao Luo,Yumeng Liu,Yuanming Li,Hongji Zeng*

Main category: cs.CL

TL;DR: 本文介绍了中文多文档问答数据集ChiMDQA的设计、构建方法及评估系统，旨在为中文问答领域的研究和应用提供支持。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理技术的发展，对高质量中文文档问答数据集的需求日益增长。

Method: 通过严格筛选文档和系统化的问题设计方法构建数据集，确保文档和问答对的多样性和高质量。

Result: ChiMDQA包含来自六个不同领域的6,068个高质量问答对，并细分为十个精细分类，适用于文档理解、知识抽取和智能问答系统等多种NLP任务。

Conclusion: ChiMDQA 数据集为中文文档问答提供了高质量的基础，促进了多种自然语言处理任务的发展。

Abstract: With the rapid advancement of natural language processing (NLP) technologies,
the demand for high-quality Chinese document question-answering datasets is
steadily growing. To address this issue, we present the Chinese Multi-Document
Question Answering Dataset(ChiMDQA), specifically designed for downstream
business scenarios across prevalent domains including academic, education,
finance, law, medical treatment, and news. ChiMDQA encompasses long-form
documents from six distinct fields, consisting of 6,068 rigorously curated,
high-quality question-answer (QA) pairs further classified into ten
fine-grained categories. Through meticulous document screening and a systematic
question-design methodology, the dataset guarantees both diversity and high
quality, rendering it applicable to various NLP tasks such as document
comprehension, knowledge extraction, and intelligent QA systems. Additionally,
this paper offers a comprehensive overview of the dataset's design objectives,
construction methodologies, and fine-grained evaluation system, supplying a
substantial foundation for future research and practical applications in
Chinese QA. The code and data are available at:
https://anonymous.4open.science/r/Foxit-CHiMDQA/.

</details>


### [74] [Do Androids Dream of Unseen Puppeteers? Probing for a Conspiracy Mindset in Large Language Models](https://arxiv.org/abs/2511.03699)
*Francesco Corso,Francesco Pierri,Gianmarco De Francisci Morales*

Main category: cs.CL

TL;DR: 本文研究大型语言模型的阴谋倾向和社会人口偏见，发现它们对阴谋信念有部分一致性，并易受操控，强调了在使用这些模型时需谨慎评估其心理维度的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型是否表现出阴谋倾向及其在此领域的社会人口偏见，以及这些模型在接受条件时是否容易形成阴谋观点。

Method: 通过对多个模型进行有效调查，使用心理测量调查评估阴谋思维，采用不同的提示和条件策略。

Result: 研究结果表明，LLMs在阴谋信念方面部分一致，并且条件与社会人口属性的不均匀影响揭示了潜在的偏见。针对性的提示会轻易地将模型响应转向阴谋方向。

Conclusion: 大型语言模型（LLMs）在某种程度上显示出阴谋信念，并且易受社会人口特征的影响，促进了对这些模型在敏感环境中应用风险的关注。

Abstract: In this paper, we investigate whether Large Language Models (LLMs) exhibit
conspiratorial tendencies, whether they display sociodemographic biases in this
domain, and how easily they can be conditioned into adopting conspiratorial
perspectives. Conspiracy beliefs play a central role in the spread of
misinformation and in shaping distrust toward institutions, making them a
critical testbed for evaluating the social fidelity of LLMs. LLMs are
increasingly used as proxies for studying human behavior, yet little is known
about whether they reproduce higher-order psychological constructs such as a
conspiratorial mindset. To bridge this research gap, we administer validated
psychometric surveys measuring conspiracy mindset to multiple models under
different prompting and conditioning strategies. Our findings reveal that LLMs
show partial agreement with elements of conspiracy belief, and conditioning
with socio-demographic attributes produces uneven effects, exposing latent
demographic biases. Moreover, targeted prompts can easily shift model responses
toward conspiratorial directions, underscoring both the susceptibility of LLMs
to manipulation and the potential risks of their deployment in sensitive
contexts. These results highlight the importance of critically evaluating the
psychological dimensions embedded in LLMs, both to advance computational social
science and to inform possible mitigation strategies against harmful uses.

</details>


### [75] [Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist Annotation Scheme for MapTask](https://arxiv.org/abs/2511.03718)
*Nan Li,Albert Gatt,Massimo Poesio*

Main category: cs.CL

TL;DR: 本文探讨了在协作对话中如何通过新的注释方案分析参与者之间的共同理解及误解，结果显示数量差异会导致理解的分歧。


<details>
  <summary>Details</summary>
Motivation: 在不对称设置中，参与者可能在认为达成一致的情况下引用不同的实体，因此需要分析如何建立共同理解。

Method: 介绍了一种新的视角注释方案，通过HCRC MapTask语料库逐步捕捉讲话者和听众对每个参考表达的理解。

Result: 研究表明，一旦统一词汇变体，完全误解的情况很少，但数量差异系统性地导致理解的分歧，这揭示了表面上的共同基础可能掩盖参照不一致的问题。

Conclusion: 该研究为研究基于共同理解的误解提供了资源和分析视角，并评估了大语言模型在协作对话中建模视角依赖的能力。

Abstract: Collaborative dialogue relies on participants incrementally establishing
common ground, yet in asymmetric settings they may believe they agree while
referring to different entities. We introduce a perspectivist annotation scheme
for the HCRC MapTask corpus (Anderson et al., 1991) that separately captures
speaker and addressee grounded interpretations for each reference expression,
enabling us to trace how understanding emerges, diverges, and repairs over
time. Using a scheme-constrained LLM annotation pipeline, we obtain 13k
annotated reference expressions with reliability estimates and analyze the
resulting understanding states. The results show that full misunderstandings
are rare once lexical variants are unified, but multiplicity discrepancies
systematically induce divergences, revealing how apparent grounding can mask
referential misalignment. Our framework provides both a resource and an
analytic lens for studying grounded misunderstanding and for evaluating
(V)LLMs' capacity to model perspective-dependent grounding in collaborative
dialogue.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [76] [Node-Based Editing for Multimodal Generation of Text, Audio, Image, and Vide](https://arxiv.org/abs/2511.03227)
*Alexander Htet Kyaw,Lenin Ravindranath Sivalingam*

Main category: cs.HC

TL;DR: 提出了一种节点基础的多模态内容生成系统，支持故事生成与编辑，效果显著。


<details>
  <summary>Details</summary>
Motivation: 为了增强创作者在故事叙述中的控制力，提供更灵活便捷的内容生成工具。

Method: 通过构建一个节点基础的故事生成系统，实现多模态内容的生成与编辑。

Result: 结果证明，节点编辑能有效支持叙述结构的控制与多模态内容的生成，并提供量化与质化评估。

Conclusion: 研究展示了基于节点的编辑支持叙事结构的控制及文本、图像、音频和视频的迭代生成。

Abstract: We present a node-based storytelling system for multimodal content
generation. The system represents stories as graphs of nodes that can be
expanded, edited, and iteratively refined through direct user edits and
natural-language prompts. Each node can integrate text, images, audio, and
video, allowing creators to compose multimodal narratives. A task selection
agent routes between specialized generative tasks that handle story generation,
node structure reasoning, node diagram formatting, and context generation. The
interface supports targeted editing of individual nodes, automatic branching
for parallel storylines, and node-based iterative refinement. Our results
demonstrate that node-based editing supports control over narrative structure
and iterative generation of text, images, audio, and video. We report
quantitative outcomes on automatic story outline generation and qualitative
observations of editing workflows. Finally, we discuss current limitations such
as scalability to longer narratives and consistency across multiple nodes, and
outline future work toward human-in-the-loop and user-centered creative AI
tools.

</details>


### [77] [How ChatGPT and Gemini View the Elements of Communication Competence of Large Language Models: A Pilot Study](https://arxiv.org/abs/2511.02838)
*Goran Bubas*

Main category: cs.HC

TL;DR: 本研究通过案例研究分析了两种沟通能力理论模型在大语言模型互动中的应用，得出两者均有助于理解用户互动的结论。


<details>
  <summary>Details</summary>
Motivation: 探索沟通能力的理论模型在不同领域的应用，特别是与大语言模型的互动。

Method: 通过两个案例研究，调查先进的AI工具如ChatGPT和Gemini在与用户的互动中如何解释沟通能力理论的元素。

Result: 发现所选的理论模型适合用于分析大语言模型与用户的互动。

Conclusion: 两种理论模型都有助于更好地理解大语言模型与用户之间的互动。

Abstract: A concise overview is provided of selected theoretical models of
communication competence in the fields of linguistics, interpersonal
communication, second language use, and human-robot interaction. The following
practical research consisted of two case studies with the goals of
investigating how advanced AI tools like ChatGPT and Gemini interpret elements
of two communication competence theories in the context of Large Language Model
(LLM) interactions with users. The focus was on these theoretical approaches:
(1) an integrated linguistic-interpersonal model and (2) an interpersonal
"human-humanoid" interaction model. The conclusion is that both approaches are
suitable for a better understanding of LLM-user interaction.

</details>


### [78] [Evaluating Generative AI as an Educational Tool for Radiology Resident Report Drafting](https://arxiv.org/abs/2511.02839)
*Antonio Verdone,Aidan Cardall,Fardeen Siddiqui,Motaz Nashawaty,Danielle Rigau,Youngjoon Kwon,Mira Yousef,Shalin Patel,Alex Kieturakis,Eric Kim,Laura Heacock,Beatriu Reig,Yiqiu Shen*

Main category: cs.HC

TL;DR: 本研究评估了一种GPT-4o系统在放射学住院医师报告中的自动反馈效果，结果表明其能有效识别教育错误，并提供有用的反馈。


<details>
  <summary>Details</summary>
Motivation: 放射科住院医师需要及时和个性化的反馈，以发展其图像分析和报告技能，但临床工作负荷增加限制了主治医师提供指导的能力。

Method: 分析了来自美国多地点健康系统的5000对住院医师与主治医师报告，并通过GPT-4o提供自动反馈，评估其反馈的有效性和读者之间的一致性。

Result: 确认了三种常见错误类型，并显示GPT-4o在错误类型识别中与主治医师的一致性强，反馈在大多数情况下被评为有帮助。

Conclusion: GPT-4o能够可靠地识别关键教育错误，可能成为支持放射学教育的可扩展工具。

Abstract: Objective: Radiology residents require timely, personalized feedback to
develop accurate image analysis and reporting skills. Increasing clinical
workload often limits attendings' ability to provide guidance. This study
evaluates a HIPAA-compliant GPT-4o system that delivers automated feedback on
breast imaging reports drafted by residents in real clinical settings.
  Methods: We analyzed 5,000 resident-attending report pairs from routine
practice at a multi-site U.S. health system. GPT-4o was prompted with clinical
instructions to identify common errors and provide feedback. A reader study
using 100 report pairs was conducted. Four attending radiologists and four
residents independently reviewed each pair, determined whether predefined error
types were present, and rated GPT-4o's feedback as helpful or not. Agreement
between GPT and readers was assessed using percent match. Inter-reader
reliability was measured with Krippendorff's alpha. Educational value was
measured as the proportion of cases rated helpful.
  Results: Three common error types were identified: (1) omission or addition
of key findings, (2) incorrect use or omission of technical descriptors, and
(3) final assessment inconsistent with findings. GPT-4o showed strong agreement
with attending consensus: 90.5%, 78.3%, and 90.4% across error types.
Inter-reader reliability showed moderate variability ({\alpha} = 0.767, 0.595,
0.567), and replacing a human reader with GPT-4o did not significantly affect
agreement ({\Delta} = -0.004 to 0.002). GPT's feedback was rated helpful in
most cases: 89.8%, 83.0%, and 92.0%.
  Discussion: ChatGPT-4o can reliably identify key educational errors. It may
serve as a scalable tool to support radiology education.

</details>


### [79] [Interview Survey on Attractivenesses of Place Re-creation Toward Developing a Virtual Twin Design Theory](https://arxiv.org/abs/2511.02840)
*Saizo Aoyagi*

Main category: cs.HC

TL;DR: 本研究探讨了地点再创造背后的吸引力，通过定性研究建立了虚拟双胞胎设计的理论框架。


<details>
  <summary>Details</summary>
Motivation: 作者假设存在一种潜在的共同吸引力，但对此尚不明确，旨在澄清这种吸引力及其结构。

Method: 通过定性分析的访谈研究，探索物理和计算机生成的地点再创造实例。

Result: 研究发现地点再创造的吸引力来源于具体实例的分析，提供了设计虚拟双胞胎的理论基础。

Conclusion: 本研究建立了一个理论框架，用于设计虚拟双胞胎，帮助理解地点再创造的吸引力及其结构。

Abstract: It is often seen that real-world locations are re-created using models,
metaverse technology, or computer graphics. Although the surface-level purposes
of these re-creations vary, the author hypothesizes that there exists an
underlying common attractiveness that remains unclear. This research aims to
clarify the attractiveness and its structures of place re-creations through an
interview study with qualitative analysis. The interviews used examples of
physical re-creations, such as the model in Komazawa University's Zen Culture
History Museum and some dioramas of Tokyo, as well as computer-generated
re-creations of Shibuya using platforms like Minecraft and Project Plateau's 3D
city model. Using insights gained from this investigation, this study seeks to
establish a theoretical framework for designing virtual twins.

</details>


### [80] [Digital Transformation Chatbot (DTchatbot): Integrating Large Language Model-based Chatbot in Acquiring Digital Transformation Needs](https://arxiv.org/abs/2511.02842)
*Jiawei Zheng,Gokcen Yilmaz,Ji Han,Saeema Ahmed-Kristensen*

Main category: cs.HC

TL;DR: 本研究探讨了使用大语言模型驱动的聊天机器人以获取组织的数字化转型需求，提出了一种新的访谈方法，并评估了其有效性和改进空间。


<details>
  <summary>Details</summary>
Motivation: 随着组织数字化转型的追求，了解其独特需求至关重要，但传统方法如专家访谈存在日程冲突、资源限制和不一致性等挑战。

Method: 本研究采用了基于工作流的指令与大语言模型（LLM）规划和推理能力相结合的方法，开发了一个聊天机器人来进行访谈。

Result: 初步评估表明，聊天机器人按设计有效工作，能够遵循预定义工作流并支持用户交互，同时指出了改进区域。

Conclusion: 结论讨论了使用聊天机器人获取用户信息的影响，强调了其潜力和局限性。

Abstract: Many organisations pursue digital transformation to enhance operational
efficiency, reduce manual efforts, and optimise processes by automation and
digital tools. To achieve this, a comprehensive understanding of their unique
needs is required. However, traditional methods, such as expert interviews,
while effective, face several challenges, including scheduling conflicts,
resource constraints, inconsistency, etc. To tackle these issues, we
investigate the use of a Large Language Model (LLM)-powered chatbot to acquire
organisations' digital transformation needs. Specifically, the chatbot
integrates workflow-based instruction with LLM's planning and reasoning
capabilities, enabling it to function as a virtual expert and conduct
interviews. We detail the chatbot's features and its implementation. Our
preliminary evaluation indicates that the chatbot performs as designed,
effectively following predefined workflows and supporting user interactions
with areas for improvement. We conclude by discussing the implications of
employing chatbots to elicit user information, emphasizing their potential and
limitations.

</details>


### [81] [A Survey of Driver Distraction and Inattention in Popular Commercial Software-Defined Vehicles](https://arxiv.org/abs/2511.02891)
*Lingyu Zhao,Yuankai He*

Main category: cs.HC

TL;DR: 本文探讨了用户界面设计对软件定义车辆中的驾驶分心和注意力不集中的影响，强调平衡软件功能与驾驶认知的必要性，以提高安全性。


<details>
  <summary>Details</summary>
Motivation: 随着汽车产业向软件定义车辆(SDV)转型，用户界面设计在确保驾驶安全中的角色愈发重要，尤其是在驾驶分心导致的事故中。

Method: 通过对流行商业车辆的调查，识别出可能增加认知负荷的UI特征，并评估减轻这些风险的设计策略。

Result: 研究发现许多现有的SDV UI实现未考虑驾驶分心和注意力不集中的问题，调查的结果为改善汽车UI设计和提升安全性提供了指导建议。

Conclusion: UI设计对于减少驾驶分心和注意力不集中至关重要，需要在软件功能和驾驶认知工程之间取得平衡。

Abstract: As the automotive industry embraces software-defined vehicles (SDVs), the
role of user interface (UI) design in ensuring driver safety has become
increasingly significant. In crashes related to distracted driving, over 90%
did not involve cellphone use but were related to UI controls. However, many of
the existing UI SDV implementations do not consider Drive Distraction and
Inattention (DDI), which is reflected in many popular commercial vehicles. This
paper investigates the impact of UI designs on driver distraction and
inattention within the context of SDVs. Through a survey of popular commercial
vehicles, we identify UI features that potentially increase cognitive load and
evaluate design strategies to mitigate these risks. This survey highlights the
need for UI designs that balance advanced software functionalities with
driver-cognitive ergonomics. Findings aim to provide valuable guidance to
researchers and OEMs to contribute to the field of automotive UI, contributing
to the broader discussion on enhancing vehicular safety in the software-centric
automotive era.

</details>


### [82] [Systematizing LLM Persona Design: A Four-Quadrant Technical Taxonomy for AI Companion Applications](https://arxiv.org/abs/2511.02979)
*Esther Sun,Zichu Wu*

Main category: cs.HC

TL;DR: 本文提出了一个四象限技术分类法，旨在系统化AI伴侣应用领域，帮助研究者、开发者和政策制定者理解不同应用场景的复杂性与独特风险。


<details>
  <summary>Details</summary>
Motivation: 随着基于大型语言模型(LLM)的个性化AI伴侣的广泛应用，领域内存在着目标、形式和技术栈的多样性，急需一个统一的框架来梳理和规范相关应用。

Method: 通过对AI伴侣领域进行系统分析，建立了四象限技术分类法，涵盖虚拟与具身、情感陪伴与功能增强两大关键轴线。

Result: 通过对四个象限的分析，识别了虚拟陪伴和具身智能在情感一致性、功能应用、符号基础、数据隐私及道德责任等方面的核心挑战。

Conclusion: 本文提出的四象限技术分类法为AI伴侣应用提供了系统性框架，帮助研究者、开发者和政策制定者更好地理解和应对这一领域的复杂性。

Abstract: The design and application of LLM-based personas in AI companionship is a
rapidly expanding but fragmented field, spanning from virtual emotional compan-
ions and game NPCs to embodied functional robots. This diversity in objectives,
modality, and technical stacks creates an urgent need for a unified framework.
To address this gap, this paper systematizes the field by proposing a
Four-Quadrant Technical Taxonomy for AI companion applications. The framework
is structured along two critical axes: Virtual vs. Embodied and Emotional
Companionship vs. Functional Augmentation. Quadrant I (Virtual Companionship)
explores virtual idols, romantic companions, and story characters, introducing
a four-layer technical framework to analyze their challenges in maintaining
long-term emotional consistency. Quadrant II (Functional Virtual Assistants)
analyzes AI applica- tions in work, gaming, and mental health, highlighting the
shift from "feeling" to "thinking and acting" and pinpointing key technologies
like enterprise RAG and on-device inference. Quadrants III & IV (Embodied
Intelligence) shift from the virtual to the physical world, analyzing home
robots and vertical-domain assistants, revealing core challenges in symbol
grounding, data privacy, and ethical liability. This taxonomy provides not only
a systematic map for researchers and developers to navigate the complex persona
design space but also a basis for policymakers to identify and address the
unique risks inherent in different application scenarios.

</details>


### [83] [Tracing Generative AI in Digital Art: A Longitudinal Study of Chinese Painters' Attitudes, Practices, and Identity Negotiation](https://arxiv.org/abs/2511.03117)
*Yibo Meng,Ruiqi Chen,Xin Chen,Zhiming Liu,Yan Guan*

Main category: cs.HC

TL;DR: 本研究通过五年的纵向研究，揭示了中国数字画家在生成性AI影响下的态度演变及身份价值观的协商过程，对未来人机协作系统设计提供了启示。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨中国数字画家在生成性人工智能影响下的态度变化及其对创作实践的影响。

Method: 采用了五年的纵向混合方法研究，涉及17位中国数字画家的态度和实践。

Result: 研究发现从抵制转向务实采用，最后达到反思重构的过程，强调了同伴压力和情感体验的作用。

Conclusion: 本研究提供了关于中国数字画家如何应对生成性人工智能的深入见解，展示了身份和价值观的持续协商过程。

Abstract: This study presents a five-year longitudinal mixed-methods study of 17
Chinese digital painters, examining how their attitudes and practices evolved
in response to generative AI. Our findings reveal a trajectory from resistance
and defensiveness, to pragmatic adoption, and ultimately to reflective
reconstruction, shaped by strong peer pressures and shifting emotional
experiences. Persistent concerns around copyright and creative labor highlight
the ongoing negotiation of identity and values. This work contributes by
offering rare longitudinal empirical data, advancing a theoretical lens of
"identity and value negotiation," and providing design implications for future
human-AI collaborative systems.

</details>


### [84] [Ceci N'est Pas un Drone: Investigating the Impact of Design Representation on Design Decision Making When Using GenAI](https://arxiv.org/abs/2511.03131)
*Zeda Xu,Nikolas Martelaro,Christopher McComb*

Main category: cs.HC

TL;DR: 研究表明设计表现方式影响设计师选择，数字数据有助于优化选择，参与者倾向传统轴对称设计。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI设计工具的出现，设计师需要有效地评估和选择设计方案以便进行进一步开发。

Method: 通过实证研究考察不同设计表现方式对设计师选择的影响。

Result: 研究表明，不同的设计表现方式会影响设计师的选择，只有数字性能数据时能较好选择最佳设计。

Conclusion: 不同的设计表现方式会影响设计师的选择，提供纯数字性能数据有助于更好地选择最佳设计，而参与者更偏好视觉上传统的轴对称设计。

Abstract: With generative AI-powered design tools, designers and engineers can
efficiently generate large numbers of design ideas. However, efficient
exploration of these ideas requires designers to select a smaller group of
potential solutions for further development. Therefore, the ability to judge
and evaluate designs is critical for the successful use of generative design
tools. Different design representation modalities can potentially affect
designers' judgments. This work investigates how different design modalities,
including visual rendering, numerical performance data, and a combination of
both, affect designers' design selections from AI-generated design concepts for
Uncrewed Aerial Vehicles. We found that different design modalities do affect
designers' choices. Unexpectedly, we found that providing only numerical design
performance data can lead to the best ability to select optimal designs. We
also found that participants prefer visually conventional designs with
axis-symmetry. The findings of this work provide insights into the interaction
between human users and generative design systems.

</details>


### [85] [From Measurement to Expertise: Empathetic Expert Adapters for Context-Based Empathy in Conversational AI Agents](https://arxiv.org/abs/2511.03143)
*Erfan Shayegani,Jina Suh,Andy Wilson,Nagu Rangan,Javier Hernandez*

Main category: cs.HC

TL;DR: 本研究提出了一种框架来增强对话AI中的同理心，通过分析对话数据集并训练适配器，将同理心与具体任务相结合，从而显著提高用户体验。


<details>
  <summary>Details</summary>
Motivation: 同理心是提升对话AI用户体验的关键因素，但现有模型的同理心往往是通用的，而非针对特定任务和上下文的。

Method: 分析真实世界的对话数据集，并开发合成多轮对话生成管道来引导响应，以符合预定义的同理心模式，并训练专门于不同同理心水平的专家适配器。

Result: 实证结果显示，感知的同理心与期望的同理心之间的差距缩小了72.66%，得分平均提高了2.43倍，且训练的专家适配器在对话过程中有效保持了同理心模式。

Conclusion: 提出了一种新颖的框架来评估和发展特定上下文的同理心大型语言模型，显著缩小了期望和体验之间的差距。

Abstract: Empathy is a critical factor in fostering positive user experiences in
conversational AI. While models can display empathy, it is often generic rather
than tailored to specific tasks and contexts. In this work, we introduce a
novel framework for developing and evaluating context-specific empathetic large
language models (LLMs). We first analyze a real-world conversational dataset
consisting of 672 multi-turn conversations across 8 tasks, revealing
significant differences in terms of expected and experienced empathy before and
after the conversations, respectively. To help minimize this gap, we develop a
synthetic multi-turn conversational generation pipeline and steer responses
toward our defined empathy patterns based on the context that more closely
matches users' expectations. We then train empathetic expert adapters for
context-specific empathy that specialize in varying empathy levels based on the
recognized task. Our empirical results demonstrate a significant gap reduction
of 72.66% between perceived and desired empathy with scores increasing by an
average factor of 2.43 as measured by our metrics and reward models.
Additionally, our trained empathetic expert adapters demonstrate superior
effectiveness in preserving empathy patterns throughout conversation turns,
outperforming system prompts, which tend to dramatically diminish in impact as
conversations lengthen.

</details>


### [86] [AI as We Describe It: How Large Language Models and Their Applications in Health are Represented Across Channels of Public Discourse](https://arxiv.org/abs/2511.03174)
*Jiawei Zhou,Lei Zhang,Mei Li,Benjamin D Horne,Munmun De Choudhury*

Main category: cs.HC

TL;DR: 本研究分析了五个主要话语渠道对大型语言模型的讨论，发现尽管公众态度普遍积极，但对风险的沟通不足，为LLM的公众交互和决策策略提供了启示。


<details>
  <summary>Details</summary>
Motivation: 探讨当前对LLMs的叙述是否平衡，以及如何影响公众对LLMs在高风险领域中角色的期望。

Method: 分析了五个主要话语渠道（新闻、研究新闻、YouTube、TikTok和Reddit）在两年期间的词汇风格、信息内容和象征性表达。

Result: 发现对LLMs的讨论普遍积极，但缺乏深度的风险沟通和对其生成特性的解释，TikTok和Reddit在Wellbeing方面的讨论较多，语调和拟人化表现出更大差异。

Conclusion: 公众对大型语言模型(LLMs)的看法普遍偏向积极，但讨论中缺乏对风险的充分沟通。在社交媒体平台上存在着对LLMs的多样化看法，尤其是在Wellbeing应用方面，但对潜在风险的关注不足。

Abstract: Representation shapes public attitudes and behaviors. With the arrival and
rapid adoption of LLMs, the way these systems are introduced will negotiate
societal expectations for their role in high-stakes domains like health. Yet it
remains unclear whether current narratives present a balanced view. We analyzed
five prominent discourse channels (news, research press, YouTube, TikTok, and
Reddit) over a two-year period on lexical style, informational content, and
symbolic representation. Discussions were generally positive and episodic, with
positivity increasing over time. Risk communication was unthorough and often
reduced to information quality incidents, while explanations of LLMs'
generative nature were rare. Compared with professional outlets, TikTok and
Reddit highlighted wellbeing applications and showed greater variations in tone
and anthropomorphism but little attention to risks. We discuss implications for
public discourse as a diagnostic tool in identifying literacy and governance
gaps, and for communication and design strategies to support more informed LLM
engagement.

</details>


### [87] [Large Language Models as Information Sources: Distinctive Characteristics and Types of Low-Quality Information](https://arxiv.org/abs/2511.03198)
*Jiawei Zhou,Amy Z. Chen,Darshi Shah,Laura M. Schwab-Reese,Munmun De Choudhury*

Main category: cs.HC

TL;DR: 本研究探讨了大语言模型生成的低质量信息类型及其与传统信息的区别，强调信息质量的多元性及其对公共健康的重要性。


<details>
  <summary>Details</summary>
Motivation: 了解大语言模型生成的低质量信息类型及其与人类生成信息的区别，填补当前对低质量信息概念的模糊理解。

Method: 通过与公共卫生专业人士和相关经历个体的焦点小组讨论，推导出LLM生成的低质量信息的特征。

Result: 识别出LLM生成的低质量信息类型，包括误优先和夸大，同时揭示了与传统信息源的根本区别。

Conclusion: 本研究提供了LLM生成的低质量信息的类型学，以及与传统信息来源的区别，为未来理解和缓解相关信息伤害的研究奠定了基础。

Abstract: Recent advances in large language models (LLMs) have brought public and
scholarly attention to their potential in generating low-quality information.
While widely acknowledged as a risk, low-quality information remains a vaguely
defined concept, and little is known about how it manifests in LLM outputs or
how these outputs differ from those of traditional information sources. In this
study, we focus on two key questions: What types of low-quality information are
produced by LLMs, and what makes them distinct than human-generated
counterparts? We conducted focus groups with public health professionals and
individuals with lived experience in three critical health contexts (vaccines,
opioid use disorder, and intimate partner violence) where high-quality
information is essential and misinformation, bias, and insensitivity are
prevalent concerns. We identified a typology of LLM-generated low-quality
information and a set of distinctive LLM characteristics compared to
traditional information sources. Our findings show that low-quality information
extends beyond factual inaccuracies into types such as misprioritization and
exaggeration, and that LLM affordances fundamentally differs from previous
technologies. This work offers typologies on LLM distinctive characteristics
and low-quality information types as a starting point for future efforts to
understand LLM-generated low-quality information and mitigate related
informational harms. We call for conceptual and methodological discussions of
information quality to move beyond truthfulness, in order to address the
affordances of emerging technologies and the evolving dynamics of information
behaviors.

</details>


### [88] [I Prompt, it Generates, we Negotiate. Exploring Text-Image Intertextuality in Human-AI Co-Creation of Visual Narratives with VLMs](https://arxiv.org/abs/2511.03375)
*Mengyao Guo,Kexin Nie,Ze Gao,Black Sun,Xueyang Wang,Jinda Han,Xingting Wu*

Main category: cs.HC

TL;DR: 本研究探讨了初学者如何在与AI协作中创作视觉叙事，发现了用户策略、协作模式以及挑战，为HCI研究提供了新的见解。


<details>
  <summary>Details</summary>
Motivation: 旨在理解文本意图与AI生成视觉内容之间的互文性。

Method: 通过三阶段定性研究，分析15名参与者在使用GPT-4o时的行为和策略。

Result: 发现了用户如何利用AI的语义盈余发展策略，识别意义明确的视觉内容；识别出四种协作模式，并通过fsQCA分析发现三条成功的互文性协作路径。

Conclusion: 这项研究为人机协作中的文本-图像互文性提供了实证依据，并提出了设计方面的建议，以支持更好的创作过程。

Abstract: Creating meaningful visual narratives through human-AI collaboration requires
understanding how text-image intertextuality emerges when textual intentions
meet AI-generated visuals. We conducted a three-phase qualitative study with 15
participants using GPT-4o to investigate how novices navigate sequential visual
narratives. Our findings show that users develop strategies to harness AI's
semantic surplus by recognizing meaningful visual content beyond literal
descriptions, iteratively refining prompts, and constructing narrative
significance through complementary text-image relationships. We identified four
distinct collaboration patterns and, through fsQCA's analysis, discovered three
pathways to successful intertextual collaboration: Educational Collaborator,
Technical Expert, and Visual Thinker. However, participants faced challenges,
including cultural representation gaps, visual consistency issues, and
difficulties translating narrative concepts into visual prompts. These findings
contribute to HCI research by providing an empirical account of
\textit{text-image intertextuality} in human-AI co-creation and proposing
design implications for role-based AI assistants that better support iterative,
human-led creative processes in visual storytelling.

</details>


### [89] [SVG Decomposition for Enhancing Large Multimodal Models Visualization Comprehension: A Study with Floor Plans](https://arxiv.org/abs/2511.03478)
*Jeongah Lee,Ali Sarvghad*

Main category: cs.HC

TL;DR: 本研究探讨了结合SVG作为分解策略以提升大型多模态模型对平面图理解的表现，结果显示其在空间理解任务中有效，但减少了空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 通过分解策略提高大型多模态模型在平面图理解上的表现，特别是在帮助盲人和低视力人群的现实应用中。

Method: 对三种大型多模态模型（GPT-4o、Claude 3.7 Sonnet、Llama 3.2 11B Vision Instruct）进行了探索性研究，研究对象为75个平面图。

Result: 结合SVG和光栅输入的方式改善了空间理解，但在空间推理方面表现不佳。

Conclusion: 结合SVG与光栅输入（SVG+PNG）可以提高空间理解任务的表现，但在路径规划方面往往会阻碍空间推理。

Abstract: Large multimodal models (LMMs) are increasingly capable of interpreting
visualizations, yet they continue to struggle with spatial reasoning. One
proposed strategy is decomposition, which breaks down complex visualizations
into structured components. In this work, we examine the efficacy of scalable
vector graphics (SVGs) as a decomposition strategy for improving LMMs'
performance on floor plans comprehension. Floor plans serve as a valuable
testbed because they combine geometry, topology, and semantics, and their
reliable comprehension has real-world applications, such as accessibility for
blind and low-vision individuals. We conducted an exploratory study with three
LMMs (GPT-4o, Claude 3.7 Sonnet, and Llama 3.2 11B Vision Instruct) across 75
floor plans. Results show that combining SVG with raster input (SVG+PNG)
improves performance on spatial understanding tasks but often hinders spatial
reasoning, particularly in pathfinding. These findings highlight both the
promise and limitations of decomposition as a strategy for advancing spatial
visualization comprehension.

</details>


### [90] [PnPSelect: Plug-and-play IoT Device Selection Using Ultra-wideband Signals](https://arxiv.org/abs/2511.03534)
*Zhaoxin Chang,Fusang Zhang,Jie Xiong,Ziyu Li,Badii Jouaber,Daqing Zhang*

Main category: cs.HC

TL;DR: 本论文提出了一种新的智能家居 IoT 设备选择方案 PnPSelect，利用 UWB 技术提升用户选择设备的体验，无需专用硬件，简化了部署过程。


<details>
  <summary>Details</summary>
Motivation: 随着智能家居中 IoT 设备数量的激增，用户在选择控制设备时面临效率低下和复杂度高的挑战。

Method: 通过利用超宽带（UWB）技术进行设备定位，并采用用户指向方向估计方法，用户可以直观高效地选择要控制的设备。

Result: PnPSelect 在商业智能手机和智能手表上实现，并在实验室及实际环境中进行了广泛评估，展现出高准确性、强鲁棒性和良好适应性。

Conclusion: PnPSelect 是一种高效、精确且可扩展的智能家居 IoT 设备选择解决方案，能够提高用户体验。

Abstract: In recent years, the number of Internet of Things (IoT) devices in smart
homes has rapidly increased. A key challenge affecting user experience is how
to enable users to efficiently and intuitively select the devices they wish to
control. This paper proposes PnPSelect, a plug-and-play IoT device selection
solution utilizing Ultra-wideband (UWB) technology on commercial devices.
Unlike previous works, PnPSelect does not require the installation of dedicated
hardware on each IoT device, thereby reducing deployment costs and
complexities, and achieving true plug-and-play functionality. To enable
intuitive device selection, we introduce a pointing direction estimation method
that utilizes UWB readings from a single anchor to infer the user pointing
direction. Additionally, we propose a lightweight device localization method
that allows users to register new IoT devices by simply pointing at them from
two distinct positions, eliminating the need for manual measurements. We
implement PnPSelect on commercial smartphones and smartwatches and conduct
extensive evaluations in both controlled laboratory settings and real-world
environments. Our results demonstrate high accuracy, robustness, and
adaptability, making PnPSelect a practical and scalable solution for
next-generation smart home interactions.

</details>


### [91] [Knowledge Graph for Intelligent Generation of Artistic Image Creation: Constructing a New Annotation Hierarchy](https://arxiv.org/abs/2511.03585)
*Jia Kaixin,Zhu Kewen,Deng Huanghuang,Qiu Yiwu,Ding Shiying,Ding Chenyang,Li Zejian*

Main category: cs.HC

TL;DR: 本研究构建了一个系统的艺术图像知识图谱，提升注释质量，支持AI艺术生成与跨文化分析。


<details>
  <summary>Details</summary>
Motivation: 解决艺术图像数据集注释中存在的模糊定义和结果不一致的问题，缺乏共同标准。

Method: 构建了一个基于艺术图像构图原则的分层知识图谱，结合中西艺术理论与中国文化视角。

Result: 产生了一个明确的结构化框架，将定性艺术概念转化为可理解的信息，为AI艺术生成提供了可解释的视觉知识基础。

Conclusion: 该研究为艺术图像数据集注释建立了统一的知识框架，提升了注释质量和一致性，支持了AI艺术生成与跨文化艺术分析。

Abstract: Our study aims to establish a unified, systematic, and referable knowledge
framework for the annotation of art image datasets, addressing issues of
ambiguous definitions and inconsistent results caused by the lack of common
standards during the annotation process. To achieve this goal, a hierarchical
and systematic art image knowledge graph was constructed. It was developed
based on the composition principles of art images, incorporating the Structured
Theory of Visual Knowledge proposed by Academician Yunhe Pan in On Visual
Knowledge-which states that visual knowledge must achieve precise expression of
spatial forms and dynamic relationships through "prototype-category" and
"hierarchical structure". Through in-depth review of Chinese and Western art
theories and pioneering integration of the Chinese cultural perspective, this
graph took shape. The core visual language of art images was deconstructed by
this knowledge graph. Meanwhile, the unique spatial theory and symbolic system
of Chinese painting were compared with and supplemented by Western art
theories. This graph converts qualitative artistic concepts into a clear
structured framework. It not only conforms to the cognitive law that "visual
knowledge takes precedence over verbal knowledge" in humans but also provides
an interpretable and inferential visual knowledge foundation for AI art
generation and cross-cultural art analysis. It ensures the high quality and
consistency of annotated data, thus offering key support for art intelligence
research in the AI 2.0 era.

</details>


### [92] [OriFeel: Origami-Inspired Actuation for Force-Based Tactile Feedback on Ambient Surfaces](https://arxiv.org/abs/2511.03673)
*Shubham Rohal,Shijia Pan*

Main category: cs.HC

TL;DR: 提出了一种基于Miura-Ori结构的可折叠触觉反馈机制，用户能够区分不同的力强度。


<details>
  <summary>Details</summary>
Motivation: 尽管形状变化表面技术有所进步，但现有的解决方案往往由于体积庞大或功耗高而难以融入日常环境表面。

Method: 通过使用Miura-Ori折叠结构创建可折叠的触觉反馈机制，利用侧向驱动实现表面力的作用。

Result: 研发出一种可折叠的触觉反馈机制，支持通过电缆驱动的伺服电机进行有效的表面力驱动。

Conclusion: 用户可以有效区分多种强度水平，验证了该触觉反馈机制的有效性。

Abstract: People are constantly in touch with surfaces in their lives, such as a sofa,
armrest, and table, making them natural tactile interfaces. Despite the recent
advancements in shape-changing surfaces, current available solutions are often
challenging to retrofit into ambient surfaces due to their bulky form factor or
high power requirements. We present \name, a foldable structure-enabled tactile
feedback mechanism that leverages the structural properties of Miura-Ori fold
to enable on-surface force actuation. The foldable structure allows the
surfaces to provide perpendicular force via lateral actuation, resulting in a
slim form factor that can be actuated via cable-based design using a servo
motor. We evaluate the system with a real-world prototype and a user study. The
user study shows that users can effectively distinguish multiple intensity
levels.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [93] [FATE: A Formal Benchmark Series for Frontier Algebra of Multiple Difficulty Levels](https://arxiv.org/abs/2511.02872)
*Jiedong Jiang,Wanyi He,Yuefeng Wang,Guoxiong Gao,Yongle Hu,Jingting Wang,Nailing Guan,Peihao Wu,Chunbo Dai,Liang Xiao,Bin Dong*

Main category: cs.LG

TL;DR: 我们提出了FATE，一个新基准系列，用于评估大型语言模型在正式数学推理中的能力，揭示了现代数学研究中的输出差距.


<details>
  <summary>Details</summary>
Motivation: 为了填补大型语言模型在正式定理证明和现代数学研究深度、广度及抽象性之间的差距。

Method: 介绍了FATE这一新的正式代数定理评估基准系列，包括FATE-H和FATE-X两个新组件，分别包含100道抽象代数和交换代数问题，覆盖从本科练习到超过博士资格考试难度的题目。

Result: 当前最先进的LLM在FATE基准上的表现与竞赛数学相比差距明显，最佳模型在FATE-H上获得3%的准确率，在FATE-X上为0%。自然语言推理的准确性要明显高于正式化的推理能力。

Conclusion: FATE提供了一个强大而具有挑战性的基准，建立了朝向研究级正式数学推理的重要检查点。

Abstract: Recent advances in large language models (LLMs) have demonstrated impressive
capabilities in formal theorem proving, particularly on contest-based
mathematical benchmarks like the IMO. However, these contests do not reflect
the depth, breadth, and abstraction of modern mathematical research. To bridge
this gap, we introduce FATE (Formal Algebra Theorem Evaluation), a new
benchmark series in formal algebra designed to chart a course toward advanced
mathematical reasoning. We present two new components, FATE-H and FATE-X, each
with 100 problems in abstract and commutative algebra. The FATE series spans a
difficulty spectrum from undergraduate exercises to problems exceeding PhD
qualifying exams. Notably, FATE-X is the first formal benchmark to surpass both
PhD-level exam difficulty and the coverage of the Mathlib library. Our
evaluations of state-of-the-art LLM provers on this new benchmark reveal a
stark performance gap compared to contest math: the best model achieves only 3%
(pass@64) accuracy on FATE-H and 0% on FATE-X. Our two-stage evaluation reveals
that models' natural-language reasoning is notably more accurate than their
ability to formalize this reasoning. We systematically classify the common
errors that arise during this formalization process. Furthermore, a comparative
study shows that a specialized prover can exhibit less effective reflection
than general-purpose models, reducing its accuracy at the natural-language
stage. We believe FATE provides a robust and challenging benchmark that
establishes essential checkpoints on the path toward research-level formal
mathematical reasoning.

</details>


### [94] [Predicting Weekly Fishing Concentration Zones through Deep Learning Integration of Heterogeneous Environmental Spatial Datasets](https://arxiv.org/abs/2511.02887)
*Chaitanya Rele,Aditya Rathod,Kaustubh Natu,Saurabh Kulkarni,Ajay Koli,Swapnali Makdey*

Main category: cs.LG

TL;DR: 本文提出了一种AI辅助的潜在渔区预测框架，旨在通过海洋参数提高渔区识别准确性，为渔民提供支持。


<details>
  <summary>Details</summary>
Motivation: 为了解决渔民在寻找高产渔区时面临的不确定性问题。

Method: 使用海洋参数（如海表温度和叶绿素浓度）来预测潜在渔区（PFZs）的AI辅助框架。

Result: 初步结果表明，该框架能够提高PFZ的识别准确性，并为可持续渔业实践提供区域特定的见解。

Conclusion: 该框架能够支持渔民减少搜索时间，降低燃料消耗，并促进资源的有效利用。

Abstract: The North Indian Ocean, including the Arabian Sea and the Bay of Bengal,
represents a vital source of livelihood for coastal communities, yet fishermen
often face uncertainty in locating productive fishing grounds. To address this
challenge, we present an AI-assisted framework for predicting Potential Fishing
Zones (PFZs) using oceanographic parameters such as sea surface temperature and
chlorophyll concentration. The approach is designed to enhance the accuracy of
PFZ identification and provide region-specific insights for sustainable fishing
practices. Preliminary results indicate that the framework can support
fishermen by reducing search time, lowering fuel consumption, and promoting
efficient resource utilization.

</details>


### [95] [Adaptive and Robust Data Poisoning Detection and Sanitization in Wearable IoT Systems using Large Language Models](https://arxiv.org/abs/2511.02894)
*W. K. M Mithsara,Ning Yang,Ahmed Imteaj,Hussein Zangoti,Abdur R. Shahid*

Main category: cs.LG

TL;DR: 本研究提出一种利用大语言模型进行数据中毒检测和清洗的框架，展示了其在可穿戴物联网系统中的有效性和适应性。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴传感设备在物联网中的广泛应用，尤其是在医疗、智能家居和工业领域，对人类活动识别（HAR）技术的需求增大，同时数据中毒攻击对系统可靠性构成了威胁。

Method: 本研究提出使用大型语言模型（LLMs）进行数据中毒检测和清洗，利用零-shot、one-shot和few-shot学习方法。

Result: 通过角色扮演和逐步推理的方法，框架能够有效评估传感器异常，识别数据中毒指标，并提供清洁数据替代方案，优化了检测精度和数据清洗质量。

Conclusion: 本研究提出的框架有效增强了可穿戴物联网系统在面对数据中毒攻击时的安全性和可靠性，采用大语言模型进行实时监测和清洗，是一种适应性强的防御机制。

Abstract: The widespread integration of wearable sensing devices in Internet of Things
(IoT) ecosystems, particularly in healthcare, smart homes, and industrial
applications, has required robust human activity recognition (HAR) techniques
to improve functionality and user experience. Although machine learning models
have advanced HAR, they are increasingly susceptible to data poisoning attacks
that compromise the data integrity and reliability of these systems.
Conventional approaches to defending against such attacks often require
extensive task-specific training with large, labeled datasets, which limits
adaptability in dynamic IoT environments. This work proposes a novel framework
that uses large language models (LLMs) to perform poisoning detection and
sanitization in HAR systems, utilizing zero-shot, one-shot, and few-shot
learning paradigms. Our approach incorporates \textit{role play} prompting,
whereby the LLM assumes the role of expert to contextualize and evaluate sensor
anomalies, and \textit{think step-by-step} reasoning, guiding the LLM to infer
poisoning indicators in the raw sensor data and plausible clean alternatives.
These strategies minimize reliance on curation of extensive datasets and enable
robust, adaptable defense mechanisms in real-time. We perform an extensive
evaluation of the framework, quantifying detection accuracy, sanitization
quality, latency, and communication cost, thus demonstrating the practicality
and effectiveness of LLMs in improving the security and reliability of wearable
IoT systems.

</details>


### [96] [Zero-shot data citation function classification using transformer-based large language models (LLMs)](https://arxiv.org/abs/2511.02936)
*Neil Byers,Ali Zaidi,Valerie Skye,Chris Beecroft,Kjiersten Fagnan*

Main category: cs.LG

TL;DR: 本研究使用Llama 3.1-405B大语言模型自动生成基因组数据集的文献标签，尽管存在数据可用性和评估挑战，但结果显示出较高的分类准确性。


<details>
  <summary>Details</summary>
Motivation: 近年来，识别特定数据集与科学文献之间的关联成为研究热点，提升数据使用案例描述的效率具有重要意义。

Method: 应用开源大语言模型Llama 3.1-405B生成已知包含特定基因组数据集的出版物的结构化数据使用案例标签，并引入新评估框架验证方法的有效性。

Result: 在零样本数据引用分类任务中，模型可实现0.674的F1得分，显示出良好的潜力。

Conclusion: 研究结果表明，使用开源大语言模型能够有效生成数据使用案例标签，尽管在数据可用性和评估方面存在一些挑战。

Abstract: Efforts have increased in recent years to identify associations between
specific datasets and the scientific literature that incorporates them. Knowing
that a given publication cites a given dataset, the next logical step is to
explore how or why that data was used. Advances in recent years with
pretrained, transformer-based large language models (LLMs) offer potential
means for scaling the description of data use cases in the published
literature. This avoids expensive manual labeling and the development of
training datasets for classical machine-learning (ML) systems. In this work we
apply an open-source LLM, Llama 3.1-405B, to generate structured data use case
labels for publications known to incorporate specific genomic datasets. We also
introduce a novel evaluation framework for determining the efficacy of our
methods. Our results demonstrate that the stock model can achieve an F1 score
of .674 on a zero-shot data citation classification task with no previously
defined categories. While promising, our results are qualified by barriers
related to data availability, prompt overfitting, computational infrastructure,
and the expense required to conduct responsible performance evaluation.

</details>


### [97] [Power Constrained Nonstationary Bandits with Habituation and Recovery Dynamics](https://arxiv.org/abs/2511.02944)
*Fengxu Li,Stephanie M. Carpenter,Matthew P. Buman,Yonatan Mintz*

Main category: cs.LG

TL;DR: 本文提出了ROGUE-TS算法，优化了微随机试验中的个性化和整体学习平衡，提高了统计功效。


<details>
  <summary>Details</summary>
Motivation: 决策者面临的一个共同挑战是选择具有未知奖励的行动，这些奖励会随着先前政策而变化，例如，重复使用可能会降低行动的有效性，而不活动可能会恢复有效性。这些非平稳性是通过减少或获得未知功效（ROGUE）赌博机框架来捕捉的。

Method: 我们首先开发了ROGUE-TS，这是一个针对ROGUE框架量身定制的汤普森采样算法，并提供了次线性后悔的理论保证。接着，我们引入了概率裁剪程序以平衡个性化和总体学习，实现了后悔与最小探索概率之间的量化权衡。

Result: 在两个关于体育活动促进和双相障碍治疗的微随机试验数据集上的验证表明，我们的方法在实现较低后悔的同时，保持了通过裁剪程序获得的较高统计功效，而不显著增加后悔。

Conclusion: 我们的框架为设计微随机试验（MRTs）的研究人员提供了有效的指导，以平衡个性化与统计有效性。

Abstract: A common challenge for decision makers is selecting actions whose rewards are
unknown and evolve over time based on prior policies. For instance, repeated
use may reduce an action's effectiveness (habituation), while inactivity may
restore it (recovery). These nonstationarities are captured by the Reducing or
Gaining Unknown Efficacy (ROGUE) bandit framework, which models real-world
settings such as behavioral health interventions. While existing algorithms can
compute sublinear regret policies to optimize these settings, they may not
provide sufficient exploration due to overemphasis on exploitation, limiting
the ability to estimate population-level effects. This is a challenge of
particular interest in micro-randomized trials (MRTs) that aid researchers in
developing just-in-time adaptive interventions that have population-level
effects while still providing personalized recommendations to individuals. In
this paper, we first develop ROGUE-TS, a Thompson Sampling algorithm tailored
to the ROGUE framework, and provide theoretical guarantees of sublinear regret.
We then introduce a probability clipping procedure to balance personalization
and population-level learning, with quantified trade-off that balances regret
and minimum exploration probability. Validation on two MRT datasets concerning
physical activity promotion and bipolar disorder treatment shows that our
methods both achieve lower regret than existing approaches and maintain high
statistical power through the clipping procedure without significantly
increasing regret. This enables reliable detection of treatment effects while
accounting for individual behavioral dynamics. For researchers designing MRTs,
our framework offers practical guidance on balancing personalization with
statistical validity.

</details>


### [98] [Inference-Time Personalized Alignment with a Few User Preference Queries](https://arxiv.org/abs/2511.02966)
*Victor-Alexandru Pădurean,Parameswaran Kamalaruban,Nachiket Kotalwar,Alkis Gotovos,Adish Singla*

Main category: cs.LG

TL;DR: 本研究提出了UserAlign方法，通过少量查询获取用户偏好，实现了生成模型响应的个性化对齐，实验显示其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化对齐方法需要大量的用户偏好查询或明确的文本输入，急需一种更有效的解决方案。

Method: 提出了一种新的用户偏好获取方法，通过少量的成对响应比较查询，实现个性化对齐。

Result: 实验结果表明，UserAlign在个性化文本和图像生成任务中表现出色，有效识别出最佳响应。

Conclusion: UserAlign方法在多种任务中有效实现了个性化对齐，提升了生成模型的响应与用户偏好的契合度。

Abstract: We study the problem of aligning a generative model's response with a user's
preferences. Recent works have proposed several different formulations for
personalized alignment; however, they either require a large amount of user
preference queries or require that the preference be explicitly specified as a
text input. In this paper, we propose a novel inference-time personalized
alignment method, UserAlign, that elicits the user's preferences with a few
queries as pairwise response comparisons. In particular, UserAlign builds on
the theoretical framework of best-arm identification in logistic bandits and
selects a personalized response from a fixed pool of the model's generated
responses. The key idea is to consider the user's feedback consistent and
noise-free, and incorporate it into the theoretical framework to identify the
best response quickly. Experimental results across several tasks, involving
personalized text and image generation, showcase the effectiveness of UserAlign
in achieving personalized alignment.

</details>


### [99] [Discrete Bayesian Sample Inference for Graph Generation](https://arxiv.org/abs/2511.03015)
*Ole Petersen,Marcel Kollovieh,Marten Lienen,Stephan Günnemann*

Main category: cs.LG

TL;DR: GraphBSI is a new generative model for graph data that improves performance by refining beliefs over graphs and operates through a stochastic differential equation framework.


<details>
  <summary>Details</summary>
Motivation: The need for effective generation of discrete, unordered graph-structured data in various applications drives the development of innovative generative models.

Method: GraphBSI utilizes Bayesian Sample Inference to iteratively refine a belief over graphs based on distribution parameters, representing this process as a stochastic differential equation.

Result: GraphBSI achieves state-of-the-art results in molecular and synthetic graph generation, surpassing existing models on benchmark datasets Moses and GuacaMol.

Conclusion: GraphBSI demonstrates superior performance in generating graph-structured data, effectively addressing limitations of traditional models in this area.

Abstract: Generating graph-structured data is crucial in applications such as molecular
generation, knowledge graphs, and network analysis. However, their discrete,
unordered nature makes them difficult for traditional generative models,
leading to the rise of discrete diffusion and flow matching models. In this
work, we introduce GraphBSI, a novel one-shot graph generative model based on
Bayesian Sample Inference (BSI). Instead of evolving samples directly, GraphBSI
iteratively refines a belief over graphs in the continuous space of
distribution parameters, naturally handling discrete structures. Further, we
state BSI as a stochastic differential equation (SDE) and derive a
noise-controlled family of SDEs that preserves the marginal distributions via
an approximation of the score function. Our theoretical analysis further
reveals the connection to Bayesian Flow Networks and Diffusion models. Finally,
in our empirical evaluation, we demonstrate state-of-the-art performance on
molecular and synthetic graph generation, outperforming existing one-shot graph
generative models on the standard benchmarks Moses and GuacaMol.

</details>


### [100] [Adaptive-Sensorless Monitoring of Shipping Containers](https://arxiv.org/abs/2511.03022)
*Lingqing Shen,Chi Heem Wong,Misaki Mito,Arnab Chakrabarti*

Main category: cs.LG

TL;DR: 本研究介绍了一个新的自适应无传感器模型，通过残差校正提高了集装箱内温度和湿度的监测准确性，减少了系统性误差。


<details>
  <summary>Details</summary>
Motivation: 监测集装箱内部温度和湿度对防止货物运输过程中质量下降至关重要，传统的无传感器监测方式存在显著的预测差异问题。

Method: 提出残差校正方法，该方法在观察实时遥测数据后，纠正无传感器模型中的系统性偏差。

Result: 自适应无传感器模型在分析3.48百万数据点的最大集装箱传感器读数数据集上表现优秀，相较于传统的无传感器模型在温度和湿度预测上均有显著的改进。

Conclusion: 自适应无传感器模型显著提高了货物监测的准确性，促进了早期风险检测，并减少了对全球运输中完全连接性的依赖。

Abstract: Monitoring the internal temperature and humidity of shipping containers is
essential to preventing quality degradation during cargo transportation.
Sensorless monitoring -- machine learning models that predict the internal
conditions of the containers using exogenous factors -- shows promise as an
alternative to monitoring using sensors. However, it does not incorporate
telemetry information and correct for systematic errors, causing the
predictions to differ significantly from the live data and confusing the users.
In this paper, we introduce the residual correction method, a general framework
for correcting for systematic biases in sensorless models after observing live
telemetry data. We call this class of models ``adaptive-sensorless''
monitoring. We train and evaluate adaptive-sensorless models on the 3.48
million data points -- the largest dataset of container sensor readings ever
used in academic research -- and show that they produce consistent improvements
over the baseline sensorless models. When evaluated on the holdout set of the
simulated data, they achieve average mean absolute errors (MAEs) of 2.24 $\sim$
2.31$^\circ$C (vs 2.43$^\circ$C by sensorless) for temperature and 5.72 $\sim$
7.09% for relative humidity (vs 7.99% by sensorless) and average root
mean-squared errors (RMSEs) of 3.19 $\sim$ 3.26$^\circ$C for temperature (vs
3.38$^\circ$C by sensorless) and 7.70 $\sim$ 9.12% for relative humidity (vs
10.0% by sensorless). Adaptive-sensorless models enable more accurate cargo
monitoring, early risk detection, and less dependence on full connectivity in
global shipping.

</details>


### [101] [Leveraging Discrete Function Decomposability for Scientific Design](https://arxiv.org/abs/2511.03032)
*James C. Bowden,Sergey Levine,Jennifer Listgarten*

Main category: cs.LG

TL;DR: 本文提出DADO算法，利用设计变量的分解性提高离散优化效率，适用于各类科学性质预测。


<details>
  <summary>Details</summary>
Motivation: 在AI驱动的科学工程时代，如何根据用户指定的性质高效设计离散对象是一个重要问题。

Method: 提出并演示了一种新的分布式优化算法DADO，利用连接树定义的分解性结构进行优化。

Result: DADO算法通过引入软因子化搜索分布和图消息传递方法，提高了搜索空间的导航效率，优化了设计过程。

Conclusion: DADO算法能够有效利用设计变量的分解结构，提高离散设计空间的优化效率，适用于科学应用中的性质预测。

Abstract: In the era of AI-driven science and engineering, we often want to design
discrete objects in silico according to user-specified properties. For example,
we may wish to design a protein to bind its target, arrange components within a
circuit to minimize latency, or find materials with certain properties. Given a
property predictive model, in silico design typically involves training a
generative model over the design space (e.g., protein sequence space) to
concentrate on designs with the desired properties. Distributional optimization
-- which can be formalized as an estimation of distribution algorithm or as
reinforcement learning policy optimization -- finds the generative model that
maximizes an objective function in expectation. Optimizing a distribution over
discrete-valued designs is in general challenging because of the combinatorial
nature of the design space. However, many property predictors in scientific
applications are decomposable in the sense that they can be factorized over
design variables in a way that could in principle enable more effective
optimization. For example, amino acids at a catalytic site of a protein may
only loosely interact with amino acids of the rest of the protein to achieve
maximal catalytic activity. Current distributional optimization algorithms are
unable to make use of such decomposability structure. Herein, we propose and
demonstrate use of a new distributional optimization algorithm,
Decomposition-Aware Distributional Optimization (DADO), that can leverage any
decomposability defined by a junction tree on the design variables, to make
optimization more efficient. At its core, DADO employs a soft-factorized
"search distribution" -- a learned generative model -- for efficient navigation
of the search space, invoking graph message-passing to coordinate optimization
across linked factors.

</details>


### [102] [Data-Efficient Realized Volatility Forecasting with Vision Transformers](https://arxiv.org/abs/2511.03046)
*Emi Soroka,Artem Arzyn*

Main category: cs.LG

TL;DR: 本文探讨了Vision Transformer在期权数据预测中的应用，显示其学习能力强，能够捕捉复杂模式。


<details>
  <summary>Details</summary>
Motivation: 研究变压器模型在期权数据预测中的应用，填补这一领域的研究空白。

Method: 使用Vision Transformer (ViT) 架构预测资产未来30天的实际波动率，数据来源于隐含波动率表（并添加日期信息）。

Result: ViT成功学习到隐含波动率表中的季节性和非线性特征。

Conclusion: ViT模型能够从隐含波动率表中学习季节性模式和非线性特征，这为期权数据的模型开发提供了有前景的方向。

Abstract: Recent work in financial machine learning has shown the virtue of complexity:
the phenomenon by which deep learning methods capable of learning highly
nonlinear relationships outperform simpler approaches in financial forecasting.
While transformer architectures like Informer have shown promise for financial
time series forecasting, the application of transformer models for options data
remains largely unexplored. We conduct preliminary studies towards the
development of a transformer model for options data by training the Vision
Transformer (ViT) architecture, typically used in modern image recognition and
classification systems, to predict the realized volatility of an asset over the
next 30 days from its implied volatility surface (augmented with date
information) for a single day. We show that the ViT can learn seasonal patterns
and nonlinear features from the IV surface, suggesting a promising direction
for model development.

</details>


### [103] [Unsupervised Evaluation of Multi-Turn Objective-Driven Interactions](https://arxiv.org/abs/2511.03047)
*Emi Soroka,Tanmay Chopra,Krish Desai,Sanjay Lall*

Main category: cs.LG

TL;DR: 本文提出了一组无监督评估指标，专注于目标驱动交互的评估，改进了大语言模型在复杂无标签数据上的应用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在企业应用中越来越受欢迎，但现有评估方法在面临复杂数据和缺乏标签时存在局限性，因此需要新的评估指标。

Method: 通过利用未标记交互数据的统计特性，结合微调后的大语言模型，我们开发了评估用户目标、衡量目标完成度以及量化大语言模型不确定性的指标。

Result: 验证表明，我们的方法能够在开放域和任务特定的交互数据上有效评估目标驱动的交互过程。

Conclusion: 我们提出了一套无监督的评估指标，能够有效评估目标驱动的交互过程，尤其在数据复杂且无标签的情况下，提供了一种新的评估方式。

Abstract: Large language models (LLMs) have seen increasing popularity in enterprise
applications where AI agents and humans engage in objective-driven
interactions. However, these systems are difficult to evaluate: data may be
complex and unlabeled; human annotation is often impractical at scale; custom
metrics can monitor for specific errors, but not previously-undetected ones;
and LLM judges can produce unreliable results. We introduce the first set of
unsupervised metrics for objective-driven interactions, leveraging statistical
properties of unlabeled interaction data and using fine-tuned LLMs to adapt to
distributional shifts. We develop metrics for labeling user goals, measuring
goal completion, and quantifying LLM uncertainty without grounding evaluations
in human-generated ideal responses. Our approach is validated on open-domain
and task-specific interaction data.

</details>


### [104] [The Curved Spacetime of Transformer Architectures](https://arxiv.org/abs/2511.03060)
*Riccardo Di Sipio,Jairo Diaz-Rodriguez,Luis Serrano*

Main category: cs.LG

TL;DR: 本文提出一个几何框架来理解Transformer语言模型，与广义相对论类比，通过实验验证了嵌入空间的曲率及其对token表示的影响。


<details>
  <summary>Details</summary>
Motivation: 提出Transformer模型的几何框架，以深入理解其语言表示机制，并通过与广义相对论的类比提供新的视角。

Method: 设计实验以检测和可视化嵌入空间的曲率，并通过模拟和对比实验进行验证。

Result: 实验结果显示了不同层和token之间的局部转角变化，以及嵌入轨迹在特定编辑下的弯曲，支持了注意力机制下的曲率存在。

Conclusion: 通过实验验证了Transformer模型中嵌入空间的曲率，并观察到了嵌入轨迹的明显弯曲，支持了将Transformer与广义相对论类比的观点。

Abstract: We present a geometric framework for understanding Transformer-based language
models, drawing an explicit analogy to General Relativity. Queries and keys
induce an effective metric on representation space, and attention acts as a
discrete connection that implements parallel transport of value vectors across
tokens. Stacked layers provide discrete time-slices through which token
representations evolve on this curved manifold, while backpropagation plays the
role of a least-action principle that shapes loss-minimizing trajectories in
parameter space. If this analogy is correct, token embeddings should not
traverse straight paths in feature space; instead, their layer-wise steps
should bend and reorient as interactions mediated by embedding space curvature.
To test this prediction, we design experiments that expose both the presence
and the consequences of curvature: (i) we visualize a curvature landscape for a
full paragraph, revealing how local turning angles vary across tokens and
layers; (ii) we show through simulations that excess counts of sharp/flat
angles and longer length-to-chord ratios are not explainable by dimensionality
or chance; and (iii) inspired by Einstein's eclipse experiment, we probe
deflection under controlled context edits, demonstrating measurable,
meaning-consistent bends in embedding trajectories that confirm
attention-induced curvature.

</details>


### [105] [Homomorphism distortion: A metric to distinguish them all and in the latent space bind them](https://arxiv.org/abs/2511.03068)
*Martin Carrasco,Olga Zaghen,Erik Bekkers,Bastian Rieck*

Main category: cs.LG

TL;DR: 本研究提出了一种新的测量图相似性的方法——图同态失真，通过采样高效计算，并在实证验证中表现优异。


<details>
  <summary>Details</summary>
Motivation: 以更全面的方式测量带顶点属性的图之间的相似性，超越传统的组合性质测量。

Method: 通过采样计算图同态失真，以确保在期望上达到完整性。

Result: 图同态失真在两项数据集上表现出色，能够区分之前不可区分的图，并且优于先前同态方法。

Conclusion: 图同态失真可以完全表征图，并且通过采样高效计算该度量，为图的特征化铺平了道路。

Abstract: For far too long, expressivity of graph neural networks has been measured
\emph{only} in terms of combinatorial properties. In this work we stray away
from this tradition and provide a principled way to measure similarity between
vertex attributed graphs. We denote this measure as the \emph{graph
homomorphism distortion}. We show it can \emph{completely characterize} graphs
and thus is also a \emph{complete graph embedding}. However, somewhere along
the road, we run into the graph canonization problem. To circumvent this
obstacle, we devise to efficiently compute this measure via sampling, which in
expectation ensures \emph{completeness}. Additionally, we also discovered that
we can obtain a metric from this measure. We validate our claims empirically
and find that the \emph{graph homomorphism distortion}: (1.) fully
distinguishes the \texttt{BREC} dataset with up to $4$-WL non-distinguishable
graphs, and (2.) \emph{outperforms} previous methods inspired in homomorphisms
under the \texttt{ZINC-12k} dataset.
  These theoretical results, (and their empirical validation), pave the way for
future characterization of graphs, extending the graph theoretic tradition to
new frontiers.

</details>


### [106] [Online Learning to Rank under Corruption: A Robust Cascading Bandits Approach](https://arxiv.org/abs/2511.03074)
*Fatemeh Ghaffari,Siddarth Sitaraman,Xutong Liu,Xuchuang Wang,Mohammad Hajiesmaili*

Main category: cs.LG

TL;DR: MSUCB是一种新提出的鲁棒算法，旨在提高在线学习排序中的点击数据的抗腐蚀能力，实验表明其显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在在线学习排序过程中，用户点击数据容易受到点击欺诈和其他操纵的影响，这可能导致学习过程的失效和用户体验的下降。

Method: 提出了一种新的基于均值中位数估计器的鲁棒算法MSUCB，并结合了对数据污染的处理。

Result: MSUCB在不受污染的情况下实现最佳对数悔避，并在受到腐败影响时表现优异，与现有方法相比具有显著的改善。

Conclusion: MSUCB算法在缺乏数据污染的情况下能够实现最佳对数悔避，并且在存在腐败的情况下表现优异，仅带来与总腐败量相关的附加悔避。此外，该方法在现实数据集上的实验显示了显著的性能提升。

Abstract: Online learning to rank (OLTR) studies how to recommend a short ranked list
of items from a large pool and improves future rankings based on user clicks.
This setting is commonly modeled as cascading bandits, where the objective is
to maximize the likelihood that the user clicks on at least one of the
presented items across as many timesteps as possible. However, such systems are
vulnerable to click fraud and other manipulations (i.e., corruption), where
bots or paid click farms inject corrupted feedback that misleads the learning
process and degrades user experience. In this paper, we propose MSUCB, a robust
algorithm that incorporates a novel mean-of-medians estimator, which to our
knowledge is applied to bandits with corruption setting for the first time.
This estimator behaves like a standard mean in the absence of corruption, so no
cost is paid for robustness. Under corruption, the median step filters out
outliers and corrupted samples, keeping the estimate close to its true value.
Updating this estimate at every round further accelerates empirical convergence
in experiments. Hence, MSUCB achieves optimal logarithmic regret in the absence
of corruption and degrades gracefully under corruptions, with regret increasing
only by an additive term tied to the total corruption. Comprehensive and
extensive experiments on real-world datasets further demonstrate that our
approach consistently outperforms prior methods while maintaining strong
robustness. In particular, it achieves a \(97.35\%\) and a \(91.60\%\) regret
improvement over two state-of-the-art methods.

</details>


### [107] [Sparse, self-organizing ensembles of local kernels detect rare statistical anomalies](https://arxiv.org/abs/2511.03095)
*Gaia Grosso,Sai Sumedh R. Hindupur,Thomas Fel,Samuel Bright-Thonney,Philip Harris,Demba Ba*

Main category: cs.LG

TL;DR: 提出了一种新的异常检测方法SparKer，能在高维数据中有效识别异常，同时具备良好的解释性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现代人工智能在数据表示提取方面的广泛应用，但现有的异常检测方法受到统计性质控制不足的限制，导致对微弱或稀有信号的检测能力不足。

Method: 引入了SparKer模型，一个基于半监督Neyman-Pearson框架的稀疏高斯核集成，用以局部建模可能包含异常的样本与正常参考样本之间的似然比。

Result: 通过对高维科学发现、开放世界新颖性检测、入侵检测和生成模型验证等问题的应用，证明了该方法的有效性，同时展示了其解释性和可扩展性。

Conclusion: 该研究提出了一种名为SparKer的稀疏高斯核集成方法，能够有效检测高维数据中的异常，并在科学发现和其他领域展示了其有效性。

Abstract: Modern artificial intelligence has revolutionized our ability to extract rich
and versatile data representations across scientific disciplines. Yet, the
statistical properties of these representations remain poorly controlled,
causing misspecified anomaly detection (AD) methods to falter. Weak or rare
signals can remain hidden within the apparent regularity of normal data,
creating a gap in our ability to detect and interpret anomalies. We examine
this gap and identify a set of structural desiderata for detection methods
operating under minimal prior information: sparsity, to enforce parsimony;
locality, to preserve geometric sensitivity; and competition, to promote
efficient allocation of model capacity. These principles define a class of
self-organizing local kernels that adaptively partition the representation
space around regions of statistical imbalance. As an instantiation of these
principles, we introduce SparKer, a sparse ensemble of Gaussian kernels trained
within a semi-supervised Neyman--Pearson framework to locally model the
likelihood ratio between a sample that may contain anomalies and a nominal,
anomaly-free reference. We provide theoretical insights into the mechanisms
that drive detection and self-organization in the proposed model, and
demonstrate the effectiveness of this approach on realistic high-dimensional
problems of scientific discovery, open-world novelty detection, intrusion
detection, and generative-model validation. Our applications span both the
natural- and computer-science domains. We demonstrate that ensembles containing
only a handful of kernels can identify statistically significant anomalous
locations within representation spaces of thousands of dimensions, underscoring
both the interpretability, efficiency and scalability of the proposed approach.

</details>


### [108] [An Efficient Classification Model for Cyber Text](https://arxiv.org/abs/2511.03107)
*Md Sakhawat Hossen,Md. Zashid Iqbal Borshon,A. S. M. Badrudduza*

Main category: cs.LG

TL;DR: 本论文提出CTF-IDF和IRLBA以应对深度学习带来的环境影响，证明经典机器学习方法在文本分析中更高效且低碳。


<details>
  <summary>Details</summary>
Motivation: 深度学习方法的快速发展导致了对计算资源和电力的需求激增，从而引发了显著的碳足迹问题。

Method: 对传统TF-IDF算法进行了修改，提出了Clement Term Frequency-Inverse Document Frequency（CTF-IDF）用于数据预处理，并结合快速IRLBA算法进行降维。

Result: 实验结果显示，应用CTF-IDF和经典机器学习方法，能有效减少时间复杂度，提高模型准确性，同时确保更低的碳足迹。

Conclusion: 通过提出CTF-IDF和快速IRLBA算法，本研究展示了经典机器学习方法在文本分析中的有效性，提供了比深度学习更低的碳足迹和更高的时间效率。

Abstract: The uprising of deep learning methodology and practice in recent years has
brought about a severe consequence of increasing carbon footprint due to the
insatiable demand for computational resources and power. The field of text
analytics also experienced a massive transformation in this trend of
monopolizing methodology. In this paper, the original TF-IDF algorithm has been
modified, and Clement Term Frequency-Inverse Document Frequency (CTF-IDF) has
been proposed for data preprocessing. This paper primarily discusses the
effectiveness of classical machine learning techniques in text analytics with
CTF-IDF and a faster IRLBA algorithm for dimensionality reduction. The
introduction of both of these techniques in the conventional text analytics
pipeline ensures a more efficient, faster, and less computationally intensive
application when compared with deep learning methodology regarding carbon
footprint, with minor compromise in accuracy. The experimental results also
exhibit a manifold of reduction in time complexity and improvement of model
accuracy for the classical machine learning methods discussed further in this
paper.

</details>


### [109] [FP-AbDiff: Improving Score-based Antibody Design by Capturing Nonequilibrium Dynamics through the Underlying Fokker-Planck Equation](https://arxiv.org/abs/2511.03113)
*Jiameng Chen,Yida Xiong,Kun Li,Hongzhi Zhang,Xiantao Cai,Wenbin Hu,Jia Wu*

Main category: cs.LG

TL;DR: FP-AbDiff是一种新型抗体生成器，通过物理法则增强生成动态的一致性和泛化能力，显著提高了抗体设计的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管计算抗体设计在治疗发现方面具有巨大潜力，但现有生成模型受限于动力学一致性不足和由于数据稀缺和结构偏见导致的泛化能力差。

Method: FP-AbDiff采用了Fokker-Planck方程物理约束，在生成轨迹中施加约束，并通过混合流形上的FPE残差损失最小化来实现一致性，结合了生物学先验知识与深度学习的SE(3)-不变扩散框架。

Result: FP-AbDiff在RAbD基准测试中表现优异，特别是在de novo CDR-H3设计中，取得了0.99Å的均方根偏差和39.91%的氨基酸回收率。更具挑战性的六个CDR共同设计任务中，模型在几何精度上也展现出卓越性能，显著减少了全链均方根偏差，CDR-H3环的氨基酸回收率达到了45.67%。

Conclusion: FP-AbDiff通过将生成动力学与物理法则相结合，提升了抗体设计的稳健性和泛化能力，提供了一种原则性的方法，实现了物理可信和功能可行的抗体设计。

Abstract: Computational antibody design holds immense promise for therapeutic
discovery, yet existing generative models are fundamentally limited by two core
challenges: (i) a lack of dynamical consistency, which yields physically
implausible structures, and (ii) poor generalization due to data scarcity and
structural bias. We introduce FP-AbDiff, the first antibody generator to
enforce Fokker-Planck Equation (FPE) physics along the entire generative
trajectory. Our method minimizes a novel FPE residual loss over the mixed
manifold of CDR geometries (R^3 x SO(3)), compelling locally-learned denoising
scores to assemble into a globally coherent probability flow. This
physics-informed regularizer is synergistically integrated with deep biological
priors within a state-of-the-art SE(3)-equivariant diffusion framework.
Rigorous evaluation on the RAbD benchmark confirms that FP-AbDiff establishes a
new state-of-the-art. In de novo CDR-H3 design, it achieves a mean Root Mean
Square Deviation of 0.99 {\AA} when superposing on the variable region, a 25%
improvement over the previous state-of-the-art model, AbX, and the highest
reported Contact Amino Acid Recovery of 39.91%. This superiority is underscored
in the more challenging six-CDR co-design task, where our model delivers
consistently superior geometric precision, cutting the average full-chain Root
Mean Square Deviation by ~15%, and crucially, achieves the highest full-chain
Amino Acid Recovery on the functionally dominant CDR-H3 loop (45.67%). By
aligning generative dynamics with physical laws, FP-AbDiff enhances robustness
and generalizability, establishing a principled approach for physically
faithful and functionally viable antibody design.

</details>


### [110] [An Augmentation Overlap Theory of Contrastive Learning](https://arxiv.org/abs/2511.03114)
*Qi Zhang,Yifei Wang,Yisen Wang*

Main category: cs.LG

TL;DR: 本文研究自监督对比学习的机制，提出了增强重叠理论并发展了一种新的无监督评估指标，为对比学习的性能评估提供了新的视角。


<details>
  <summary>Details</summary>
Motivation: 目前自监督对比学习已经取得巨大成功，但其工作机制尚不清晰，因此我们试图通过理论分析提供更明确的理解。

Method: 我们首先基于条件独立性假设提供最紧的界限，然后放宽该假设为更实际的增强重叠假设，并导出下游性能的渐近界限。

Result: 通过提出增强重叠理论，我们展示了在激进数据增强下，不同类内样本的支持如何重叠，从而推动对比学习将类内样本聚集在一起。

Conclusion: 我们的工作为自监督对比学习提供了更清晰的理论框架，并提出了一种新的无监督评估指标，能够有效地评估表示学习的性能。

Abstract: Recently, self-supervised contrastive learning has achieved great success on
various tasks. However, its underlying working mechanism is yet unclear. In
this paper, we first provide the tightest bounds based on the widely adopted
assumption of conditional independence. Further, we relax the conditional
independence assumption to a more practical assumption of augmentation overlap
and derive the asymptotically closed bounds for the downstream performance. Our
proposed augmentation overlap theory hinges on the insight that the support of
different intra-class samples will become more overlapped under aggressive data
augmentations, thus simply aligning the positive samples (augmented views of
the same sample) could make contrastive learning cluster intra-class samples
together. Moreover, from the newly derived augmentation overlap perspective, we
develop an unsupervised metric for the representation evaluation of contrastive
learning, which aligns well with the downstream performance almost without
relying on additional modules. Code is available at
https://github.com/PKU-ML/GARC.

</details>


### [111] [From Insight to Exploit: Leveraging LLM Collaboration for Adaptive Adversarial Text Generation](https://arxiv.org/abs/2511.03128)
*Najrin Sultana,Md Rafi Ur Rashid,Kang Gu,Shagufta Mehnaz*

Main category: cs.LG

TL;DR: 本文介绍了用于评估大型语言模型鲁棒性的创新对抗攻击框架，能够生成自然的对抗性输入。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在敏感任务中的广泛应用，了解其对抗性输入的鲁棒性显得尤为重要。

Method: 提出了静态欺骗者(Static Deceptor)与动态欺骗者(Dynamic Deceptor)两种框架，旨在生成自然且与原始文本在语义上相似的对抗性示例。

Result: 通过自动化的LLM驱动流程，本方法消除了对外部启发式方法的依赖，并显示出很好的跨模型迁移能力。

Conclusion: 本研究提出的攻击框架能够有效生成对大型语言模型(LLMs)的对抗性输入，进而系统性地评估其鲁棒性。

Abstract: LLMs can provide substantial zero-shot performance on diverse tasks using a
simple task prompt, eliminating the need for training or fine-tuning. However,
when applying these models to sensitive tasks, it is crucial to thoroughly
assess their robustness against adversarial inputs. In this work, we introduce
Static Deceptor (StaDec) and Dynamic Deceptor (DyDec), two innovative attack
frameworks designed to systematically generate dynamic and adaptive adversarial
examples by leveraging the understanding of the LLMs. We produce subtle and
natural-looking adversarial inputs that preserve semantic similarity to the
original text while effectively deceiving the target LLM. By utilizing an
automated, LLM-driven pipeline, we eliminate the dependence on external
heuristics. Our attacks evolve with the advancements in LLMs and demonstrate
strong transferability across models unknown to the attacker. Overall, this
work provides a systematic approach for the self-assessment of an LLM's
robustness. We release our code and data at
https://github.com/Shukti042/AdversarialExample.

</details>


### [112] [Test Time Adaptation Using Adaptive Quantile Recalibration](https://arxiv.org/abs/2511.03148)
*Paria Mehrbod,Pedro Vianna,Geraldin Nanfack,Guy Wolf,Eugene Belilovsky*

Main category: cs.LG

TL;DR: AQR是一种新的测试时间适应技术，通过通道级别对齐分位数来增强深度学习模型在动态数据分布下的适应性，实验结果表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖于目标领域的先验知识或需要模型的重新训练，这限制了其在动态或资源受限环境下的实用性。

Method: 提出了自适应分位数校正（AQR）方法，通过通道级别对齐分位数来修改前激活分布，并结合稳健的尾部校准策略。

Result: AQR方法通过对齐通道的分位数，实现了激活分布的全形状捕捉，适用于BatchNorm、GroupNorm或LayerNorm等标准化层，能够在没有重新训练模型的情况下进行无监督适应。

Conclusion: AQR方法在多种架构下实现了稳健的适应性，超越了现有的测试时间适应基准，证明了其在动态和不可预测的数据分布中实际部署的潜力。

Abstract: Domain adaptation is a key strategy for enhancing the generalizability of
deep learning models in real-world scenarios, where test distributions often
diverge significantly from the training domain. However, conventional
approaches typically rely on prior knowledge of the target domain or require
model retraining, limiting their practicality in dynamic or
resource-constrained environments. Recent test-time adaptation methods based on
batch normalization statistic updates allow for unsupervised adaptation, but
they often fail to capture complex activation distributions and are constrained
to specific normalization layers. We propose Adaptive Quantile Recalibration
(AQR), a test-time adaptation technique that modifies pre-activation
distributions by aligning quantiles on a channel-wise basis. AQR captures the
full shape of activation distributions and generalizes across architectures
employing BatchNorm, GroupNorm, or LayerNorm. To address the challenge of
estimating distribution tails under varying batch sizes, AQR incorporates a
robust tail calibration strategy that improves stability and precision. Our
method leverages source-domain statistics computed at training time, enabling
unsupervised adaptation without retraining models. Experiments on CIFAR-10-C,
CIFAR-100-C, and ImageNet-C across multiple architectures demonstrate that AQR
achieves robust adaptation across diverse settings, outperforming existing
test-time adaptation baselines. These results highlight AQR's potential for
deployment in real-world scenarios with dynamic and unpredictable data
distributions.

</details>


### [113] [Forecast2Anomaly (F2A): Adapting Multivariate Time Series Foundation Models for Anomaly Prediction](https://arxiv.org/abs/2511.03149)
*Atif Hassan,Tarun Kumar,Ashish Mishra,Sergey Serebryakov,Satish Kumar Mopur,Phanidhar Koganti,Murthy Chelankuri,Ramanagopal Vogety,Suparna Bhattacharya,Martin Foltin*

Main category: cs.LG

TL;DR: F2A是一个新的框架，它通过联合损失和动态检索能力提升了时间序列模型的异常预测性能，超越了当前的技术水平。


<details>
  <summary>Details</summary>
Motivation: 现有异常预测方法无法有效适应不断演变的异常模式，且大多数方法只适用于特定系统，因此需要一种新的方法来实现对多变时间序列的异常预测。

Method: F2A框架的核心在于两个创新：一是提出联合预测-异常损失，对TSFM进行微调，以便在异常时间点上准确预测未来信号；二是引入检索增强生成模块，根据历史相关数据动态调整预测。

Result: F2A在16个不同数据集和多种TSFM基础上进行的广泛实验，表明其在异常预测任务上始终优于现有最先进的方法，提供一种可扩展的零样本异常预测解决方案。

Conclusion: F2A框架通过结合联合预测-异常损失和检索增强生成模块，显著提升时间序列基础模型在零样本异常预测任务中的能力，超越现有先进方法。

Abstract: Forecasting anomalies (anomaly prediction) in multivariate time series from
different real-world, dynamic, and complex systems is vital for preempting
critical failures, leading to a substantial minimization in operational costs
and human labor. Yet, existing methods are limited to specific systems while
failing to generalize to evolving anomaly patterns over time. In contrast,
pretrained Time Series Foundation Models (TSFMs) have recently demonstrated
strong generalization and zero-shot forecasting capabilities. However, their
potential remains untapped for anomaly prediction, a task fundamentally
different from forecasting normal behavior. Thus, we present Forecast2Anomaly
(F2A), a novel framework that empowers TSFMs with anomaly prediction abilities
through two key innovations. First, we propose a joint forecast-anomaly loss
that fine-tunes TSFMs to accurately forecast future signals even at anomalous
time points. Second, we introduce a Retrieval-Augmented Generation (RAG) module
that retrieves historically relevant horizons and conditions predictions on
them. This component dynamically adapts to distributional shifts at inference
time, enabling F2A to track evolving anomalies without requiring model updates.
By combining targeted fine-tuning with dynamic retrieval, F2A bridges the gap
between robust TSFM zero-shot forecasting and zero-shot anomaly prediction.
Extensive experiments across 16 diverse datasets and multiple TSFM backbones
show that F2A consistently outperforms state-of-the-art methods, offering a
scalable, zero-shot anomaly prediction solution for real-world applications.

</details>


### [114] [Periodic Skill Discovery](https://arxiv.org/abs/2511.03187)
*Jonghae Park,Daesol Cho,Jusuk Lee,Dongseok Shim,Inkyu Jang,H. Jin Kim*

Main category: cs.LG

TL;DR: 提出了一种无监督周期性技能发现方法（PSD），能够在复杂的机器人任务中有效学习多样的周期性行为。


<details>
  <summary>Details</summary>
Motivation: Many robotic tasks require periodic behaviors across varying timescales; existing methods often neglect this periodic nature in skill discovery.

Method: PSD trains an encoder to map states to a circular latent space, encoding periodicity and capturing temporal distances.

Result: PSD can learn skills with diverse periods effectively, achieving high performance in tasks like hurdling and enhancing diversity when combined with other methods.

Conclusion: Periodic Skill Discovery (PSD) enables the learning of diverse periodic behaviors in robotic tasks through an unsupervised approach.

Abstract: Unsupervised skill discovery in reinforcement learning (RL) aims to learn
diverse behaviors without relying on external rewards. However, current methods
often overlook the periodic nature of learned skills, focusing instead on
increasing the mutual dependence between states and skills or maximizing the
distance traveled in latent space. Considering that many robotic tasks --
particularly those involving locomotion -- require periodic behaviors across
varying timescales, the ability to discover diverse periodic skills is
essential. Motivated by this, we propose Periodic Skill Discovery (PSD), a
framework that discovers periodic behaviors in an unsupervised manner. The key
idea of PSD is to train an encoder that maps states to a circular latent space,
thereby naturally encoding periodicity in the latent representation. By
capturing temporal distance, PSD can effectively learn skills with diverse
periods in complex robotic tasks, even with pixel-based observations. We
further show that these learned skills achieve high performance on downstream
tasks such as hurdling. Moreover, integrating PSD with an existing skill
discovery method offers more diverse behaviors, thus broadening the agent's
repertoire. Our code and demos are available at
https://jonghaepark.github.io/psd/

</details>


### [115] [Efficient Linear Attention for Multivariate Time Series Modeling via Entropy Equality](https://arxiv.org/abs/2511.03190)
*Mingtao Zhang,Guoli Yang,Zhanxing Zhu,Mengzhu Wang,Xiaoying Bai*

Main category: cs.LG

TL;DR: 本文提出了一种基于熵的线性注意力机制，通过高效算法实现了时空序列建模中的线性复杂度计算，且实验结果显示了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有注意力机制由于计算复杂性高而无法扩展到长序列的问题，探索如何利用熵的性质来实现高效的注意力计算。

Method: 开发了一种高效的近似算法，以线性复杂度计算基于点积的分布的熵，并基于熵的相等性实施线性注意力机制。

Result: 通过在四个时空数据集上的广泛实验验证了本方法，显示在性能、内存使用和计算时间上均有显著改进。

Conclusion: 本文提出的线性注意力机制在计算效率和记忆使用上表现优异，同时在时空时间序列预测任务中取得了竞争性或更优的预测性能。

Abstract: Attention mechanisms have been extensively employed in various applications,
including time series modeling, owing to their capacity to capture intricate
dependencies; however, their utility is often constrained by quadratic
computational complexity, which impedes scalability for long sequences. In this
work, we propose a novel linear attention mechanism designed to overcome these
limitations. Our approach is grounded in a theoretical demonstration that
entropy, as a strictly concave function on the probability simplex, implies
that distributions with aligned probability rankings and similar entropy values
exhibit structural resemblance. Building on this insight, we develop an
efficient approximation algorithm that computes the entropy of
dot-product-derived distributions with only linear complexity, enabling the
implementation of a linear attention mechanism based on entropy equality.
Through rigorous analysis, we reveal that the effectiveness of attention in
spatio-temporal time series modeling may not primarily stem from the
non-linearity of softmax but rather from the attainment of a moderate and
well-balanced weight distribution. Extensive experiments on four
spatio-temporal datasets validate our method, demonstrating competitive or
superior forecasting performance while achieving substantial reductions in both
memory usage and computational time.

</details>


### [116] [Cross-Modal Alignment via Variational Copula Modelling](https://arxiv.org/abs/2511.03196)
*Feng Wu,Tsai Hor Chan,Fuying Wang,Guosheng Yin,Lequan Yu*

Main category: cs.LG

TL;DR: 本文提出了一种新的copula驱动的多模态学习框架，专注于学习各模态的联合分布，以捕捉模态间复杂交互，实验表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法中未能有效处理多模态交互结构的问题。

Method: 假设每个模态的分布为高斯混合分布，并在联合分布上应用copula模型。

Result: 在公开的MIMIC数据集上进行了大量实验，验证了该模型的优越性。

Conclusion: 提出了一种新颖的基于copula的多模态学习框架，可以有效捕捉不同模态之间的复杂交互关系。

Abstract: Various data modalities are common in real-world applications (e.g.,
electronic health records, medical images and clinical notes in healthcare). It
is essential to develop multimodal learning methods to aggregate various
information from multiple modalities. The main challenge is how to
appropriately align and fuse the representations of different modalities into a
joint distribution. Existing methods mainly rely on concatenation or the
Kronecker product, oversimplifying the interaction structure between modalities
and indicating a need to model more complex interactions. Additionally, the
joint distribution of latent representations with higher-order interactions is
underexplored. Copula is a powerful statistical structure for modelling the
interactions among variables, as it naturally bridges the joint distribution
and marginal distributions of multiple variables. We propose a novel
copula-driven multimodal learning framework, which focuses on learning the
joint distribution of various modalities to capture the complex interactions
among them. The key idea is to interpret the copula model as a tool to align
the marginal distributions of the modalities efficiently. By assuming a
Gaussian mixture distribution for each modality and a copula model on the joint
distribution, our model can generate accurate representations for missing
modalities. Extensive experiments on public MIMIC datasets demonstrate the
superior performance of our model over other competitors. The code is available
at https://github.com/HKU-MedAI/CMCM.

</details>


### [117] [A Feedback-Control Framework for Efficient Dataset Collection from In-Vehicle Data Streams](https://arxiv.org/abs/2511.03239)
*Philipp Reis,Philipp Rigoll,Christian Steinhauser,Jacob Langner,Eric Sax*

Main category: cs.LG

TL;DR: 本文提出FCDC框架，将数据收集视为闭环控制问题，展现了更高效的数据收集方法，能提升数据质量、减少冗余和存储成本。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统对数据质量和多样性的依赖，传统的开放式数据收集方式显得低效，因而需要一种更有效的数据收集机制来改善数据质量。

Method: 本文介绍了一种称为FCDC的闭环控制数据收集范式，通过在线概率模型近似数据分布状态，并基于反馈信号调节样本保留。

Result: 实验表明，FCDC能够使数据集更均衡，提升25.9%的多样性，同时减少39.8%的数据存储需求。

Conclusion: 该研究提出了一种自我调节的数据收集方法，能够有效提高数据集的多样性和减少冗余，同时降低存储成本。

Abstract: Modern AI systems are increasingly constrained not by model capacity but by
the quality and diversity of their data. Despite growing emphasis on
data-centric AI, most datasets are still gathered in an open-loop manner which
accumulates redundant samples without feedback from the current coverage. This
results in inefficient storage, costly labeling, and limited generalization. To
address this, this paper introduces \ac{FCDC}, a paradigm that formulates data
collection as a closed-loop control problem. \ac{FCDC} continuously
approximates the state of the collected data distribution using an online
probabilistic model and adaptively regulates sample retention using based on
feedback signals such as likelihood and Mahalanobis distance. Through this
feedback mechanism, the system dynamically balances exploration and
exploitation, maintains dataset diversity, and prevents redundancy from
accumulating over time. Besides showcasing the controllability of \ac{FCDC} on
a synthetic dataset, experiments on a real data stream show that \ac{FCDC}
produces more balanced datasets by $\SI{25.9}{\percent}$ while reducing data
storage by $\SI{39.8}{\percent}$. These results demonstrate that data
collection itself can be actively controlled, transforming collection from a
passive pipeline stage into a self-regulating, feedback-driven process at the
core of data-centric AI.

</details>


### [118] [A unified physics-informed generative operator framework for general inverse problems](https://arxiv.org/abs/2511.03241)
*Gang Bao,Yaohua Zang*

Main category: cs.LG

TL;DR: 本研究提出了一种新型生成神经算子框架IGNO，有效解决了在稀疏和噪声条件下的逆问题，无需标记数据，表现出优越的准确性和适用性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在处理稀疏、噪声及高维系数时表现不佳，迫切需要一种新的解决方案。

Method: 引入了一种生成神经算子框架，通过物理约束和有效的梯度优化来实现逆问题的求解。

Result: 在多个复杂的逆问题上（包括从基于解的测量恢复不连续系数和基于算子的电阻抗成像问题），IGNO均实现了准确、稳定且可扩展的反演。

Conclusion: IGNO框架在解决涉及稀疏和噪声测量的逆问题上表现出色，且无须标记训练数据，显示出通用性与高效性。

Abstract: Solving inverse problems governed by partial differential equations (PDEs) is
central to science and engineering, yet remains challenging when measurements
are sparse, noisy, or when the underlying coefficients are high-dimensional or
discontinuous. Existing deep learning approaches either require extensive
labeled datasets or are limited to specific measurement types, often leading to
failure in such regimes and restricting their practical applicability. Here, a
novel generative neural operator framework, IGNO, is introduced to overcome
these limitations. IGNO unifies the solution of inverse problems from both
point measurements and operator-valued data without labeled training pairs.
This framework encodes high-dimensional, potentially discontinuous coefficient
fields into a low-dimensional latent space, which drives neural operator
decoders to reconstruct both coefficients and PDE solutions. Training relies
purely on physics constraints through PDE residuals, while inversion proceeds
via efficient gradient-based optimization in latent space, accelerated by an a
priori normalizing flow model. Across a diverse set of challenging inverse
problems, including recovery of discontinuous coefficients from solution-based
measurements and the EIT problem with operator-based measurements, IGNO
consistently achieves accurate, stable, and scalable inversion even under
severe noise. It consistently outperforms the state-of-the-art method under
varying noise levels and demonstrates strong generalization to
out-of-distribution targets. These results establish IGNO as a unified and
powerful framework for tackling challenging inverse problems across
computational science domains.

</details>


### [119] [Decoupled Entropy Minimization](https://arxiv.org/abs/2511.03256)
*Jing Ma,Hanlin Li,Xiang Xiang*

Main category: cs.LG

TL;DR: 本文提出自适应解耦熵最小化（AdaDEM），解决了经典熵最小化的局限性，在不完美监督学习任务中表现更佳。


<details>
  <summary>Details</summary>
Motivation: 研究经典熵最小化（EM）的内部机制，并解决其限制，以减少类别重叠、缩小领域差距，并限制不确定性。

Method: 提出了自适应解耦熵最小化（AdaDEM），它规范化了CADF带来的奖励，并采用边际熵校准器（MEC）替代GMC。

Result: 通过将经典EM分解为驱动因素（CADF）和校准器（GMC）来揭示经典EM的局限性，并提出解决方案AdaDEM。

Conclusion: AdaDEM在噪声和动态环境中的各种不完美监督学习任务中表现优越，超越了经典的EM变体DEM*。

Abstract: Entropy Minimization (EM) is beneficial to reducing class overlap, bridging
domain gap, and restricting uncertainty for various tasks in machine learning,
yet its potential is limited. To study the internal mechanism of EM, we
reformulate and decouple the classical EM into two parts with opposite effects:
cluster aggregation driving factor (CADF) rewards dominant classes and prompts
a peaked output distribution, while gradient mitigation calibrator (GMC)
penalizes high-confidence classes based on predicted probabilities.
Furthermore, we reveal the limitations of classical EM caused by its coupled
formulation: 1) reward collapse impedes the contribution of high-certainty
samples in the learning process, and 2) easy-class bias induces misalignment
between output distribution and label distribution. To address these issues, we
propose Adaptive Decoupled Entropy Minimization (AdaDEM), which normalizes the
reward brought from CADF and employs a marginal entropy calibrator (MEC) to
replace GMC. AdaDEM outperforms DEM*, an upper-bound variant of classical EM,
and achieves superior performance across various imperfectly supervised
learning tasks in noisy and dynamic environments.

</details>


### [120] [Diffusion Language Models are Super Data Learners](https://arxiv.org/abs/2511.03276)
*Jinjie Ni,Qian Liu,Longxu Dou,Chao Du,Zili Wang,Hang Yan,Tianyu Pang,Michael Qizhe Shieh*

Main category: cs.LG

TL;DR: 当唯一数据受限时，扩散语言模型通过长时间的训练超越自回归模型，且在数据量增大和模型规模增大情况下，表现趋势有所变化。


<details>
  <summary>Details</summary>
Motivation: 探索在数据稀缺情况下，扩散语言模型的性能与自回归模型的相对表现。

Method: 在严格控制的预训练设置下进行比较实验。

Result: DLM在不同规模数据集上表现优越，尤其是在有限的数据条件下，相较于自回归模型，DLM展现出更显著的效果提升。

Conclusion: 扩散语言模型（DLM）在数据有限的情况下，通过较长的训练周期优于自回归（AR）模型，且这一趋势在不同模型和架构下都可见。

Abstract: Under strictly controlled pre-training settings, we observe a Crossover: when
unique data is limited, diffusion language models (DLMs) consistently surpass
autoregressive (AR) models by training for more epochs. The crossover shifts
later with more or higher-quality data, earlier with larger models, and
persists across dense and sparse architectures. We attribute the gains to three
compounding factors: (1) any-order modeling, (2) super-dense compute from
iterative bidirectional denoising, and (3) built-in Monte Carlo augmentation;
input or parameter noise improves AR under data constraint but cannot close the
gap. At scale, a 1.7B DLM trained with a ~1.5T-token compute budget on 10B
unique Python tokens overtakes an AR coder trained with strictly matched
settings. In addition, a 1B-parameter DLM achieves > 56% accuracy on HellaSwag
and > 33% on MMLU using only 1B tokens, without any special tricks, just by
repeating standard pre-training data. We also show that rising validation
cross-entropy does not imply degraded downstream performance in this regime.

</details>


### [121] [A Probabilistic Approach to Pose Synchronization for Multi-Reference Alignment with Applications to MIMO Wireless Communication Systems](https://arxiv.org/abs/2511.03280)
*Rob Romijnders,Gabriele Cesa,Christos Louizos,Kumar Pratik,Arash Behboodi*

Main category: cs.LG

TL;DR: 本研究提出了一种新的算法，通过概率建模和去中心化的方法，提升了多参考对齐的性能，并降低了重构误差。


<details>
  <summary>Details</summary>
Motivation: 多参考对齐（MRA）在分子成像、计算机视觉以及无线通信系统等多个现实问题中至关重要。

Method: 利用概率方法对多参考对齐（MRA）问题建模，并使用相对姿态作为麻烦变量进行边际化，从而消除问题的全局对称性。

Result: 通过去中心化的方法，通过循环一致性避免了集中方法的立方增长，从而显著节省了计算资源。

Conclusion: 提出的算法在多个实验设置中实现了更低的重构误差。

Abstract: From molecular imaging to wireless communications, the ability to align and
reconstruct signals from multiple misaligned observations is crucial for system
performance. We study the problem of multi-reference alignment (MRA), which
arises in many real-world problems, such as cryo-EM, computer vision, and, in
particular, wireless communication systems. Using a probabilistic approach to
model MRA, we find a new algorithm that uses relative poses as nuisance
variables to marginalize out -- thereby removing the global symmetries of the
problem and allowing for more direct solutions and improved convergence. The
decentralization of this approach enables significant computational savings by
avoiding the cubic scaling of centralized methods through cycle consistency.
Both proposed algorithms achieve lower reconstruction error across experimental
settings.

</details>


### [122] [Extending Fair Null-Space Projections for Continuous Attributes to Kernel Methods](https://arxiv.org/abs/2511.03304)
*Felix Störck,Fabian Hinder,Barbara Hammer*

Main category: cs.LG

TL;DR: 本研究提出了一种基于核方法的连续公平性评估框架，改善了现有方法在连续受保护属性上的应用效果。


<details>
  <summary>Details</summary>
Motivation: 在机器学习系统日益融入社会生活的背景下，公平性问题的重要性日益凸显，目前文献大多集中在离散属性的研究上。

Method: 通过对核方法进行推广，提高了迭代零空间投影的应用范围，尤其是在支持向量回归框架下。

Result: 提出的技术在多个数据集上显示出与当前方法的竞争性或改进的性能。

Conclusion: 提出了一种新的公平性评估方法，可用于连续受保护属性，并在多个数据集上与其他方法相比表现良好或有所改善。

Abstract: With the on-going integration of machine learning systems into the everyday
social life of millions the notion of fairness becomes an ever increasing
priority in their development. Fairness notions commonly rely on protected
attributes to assess potential biases. Here, the majority of literature focuses
on discrete setups regarding both target and protected attributes. The
literature on continuous attributes especially in conjunction with regression
-- we refer to this as \emph{continuous fairness} -- is scarce. A common
strategy is iterative null-space projection which as of now has only been
explored for linear models or embeddings such as obtained by a non-linear
encoder. We improve on this by generalizing to kernel methods, significantly
extending the scope. This yields a model and fairness-score agnostic method for
kernel embeddings applicable to continuous protected attributes. We demonstrate
that our novel approach in conjunction with Support Vector Regression (SVR)
provides competitive or improved performance across multiple datasets in
comparisons to other contemporary methods.

</details>


### [123] [SORTeD Rashomon Sets of Sparse Decision Trees: Anytime Enumeration](https://arxiv.org/abs/2511.03344)
*Elif Arslan,Jacobus G. M. van der Linden,Serge Hoogendoorn,Marco Rinaldi,Emir Demirović*

Main category: cs.LG

TL;DR: SORTD是一种新框架，旨在提高稀疏决策树学习在Rashomon集枚举中的可扩展性和效率。


<details>
  <summary>Details</summary>
Motivation: 稀疏决策树学习在高风险应用中提供准确且易解释的预测模型，而Rashomon集可帮助用户选择满足特定需求的树。

Method: 提出一种新的框架SORTD，通过按照目标值顺序枚举Rashomon集中的树，提供随时可用的性能。

Result: SORTD能够将运行时间减少最多两个数量级，并支持计算任何可分离和完全有序的目标的Rashomon集。

Conclusion: SORTD框架显著提高了稀疏决策树学习的可扩展性，使得在Rashomon集内枚举树成为可能，为实际应用中的变量重要性分析和解释提供了更大的灵活性。

Abstract: Sparse decision tree learning provides accurate and interpretable predictive
models that are ideal for high-stakes applications by finding the single most
accurate tree within a (soft) size limit. Rather than relying on a single
"best" tree, Rashomon sets-trees with similar performance but varying
structures-can be used to enhance variable importance analysis, enrich
explanations, and enable users to choose simpler trees or those that satisfy
stakeholder preferences (e.g., fairness) without hard-coding such criteria into
the objective function. However, because finding the optimal tree is NP-hard,
enumerating the Rashomon set is inherently challenging. Therefore, we introduce
SORTD, a novel framework that improves scalability and enumerates trees in the
Rashomon set in order of the objective value, thus offering anytime behavior.
Our experiments show that SORTD reduces runtime by up to two orders of
magnitude compared with the state of the art. Moreover, SORTD can compute
Rashomon sets for any separable and totally ordered objective and supports
post-evaluating the set using other separable (and partially ordered)
objectives. Together, these advances make exploring Rashomon sets more
practical in real-world applications.

</details>


### [124] [A Modular, Data-Free Pipeline for Multi-Label Intention Recognition in Transportation Agentic AI Applications](https://arxiv.org/abs/2511.03363)
*Xiaocai Zhang,Hur Lim,Ke Wang,Zhe Xiao,Jing Wang,Kelvin Lee,Xiuju Fu,Zheng Qin*

Main category: cs.LG

TL;DR: 本研究提出了一种模块化的无数据多标签意图识别管道DMTC，通过合成查询和在线焦点对比损失提升了准确性，适用于自主智能体在交通中的应用。


<details>
  <summary>Details</summary>
Motivation: 解决传统意图识别依赖大量标注数据的问题，提高多标签意图理解的准确性。

Method: 使用提示工程生成合成查询，编码为语义嵌入，并通过在线焦点对比损失训练轻量级分类器。

Result: DMTC在海事运输领域的实验中表现出色，Hamming损失为5.35%，AUC为95.92%，超越了现有的多标签分类器和最新的LLM基线。

Conclusion: 本研究提出的DMTC管道为无数据多标签意图识别提供了一种新方法，为自主智能体的交通应用奠定了基础。

Abstract: In this study, a modular, data-free pipeline for multi-label intention
recognition is proposed for agentic AI applications in transportation. Unlike
traditional intent recognition systems that depend on large, annotated corpora
and often struggle with fine-grained, multi-label discrimination, our approach
eliminates the need for costly data collection while enhancing the accuracy of
multi-label intention understanding. Specifically, the overall pipeline, named
DMTC, consists of three steps: 1) using prompt engineering to guide large
language models (LLMs) to generate diverse synthetic queries in different
transport scenarios; 2) encoding each textual query with a Sentence-T5 model to
obtain compact semantic embeddings; 3) training a lightweight classifier using
a novel online focal-contrastive (OFC) loss that emphasizes hard samples and
maximizes inter-class separability. The applicability of the proposed pipeline
is demonstrated in an agentic AI application in the maritime transportation
context. Extensive experiments show that DMTC achieves a Hamming loss of 5.35%
and an AUC of 95.92%, outperforming state-of-the-art multi-label classifiers
and recent end-to-end SOTA LLM-based baselines. Further analysis reveals that
Sentence-T5 embeddings improve subset accuracy by at least 3.29% over
alternative encoders, and integrating the OFC loss yields an additional 0.98%
gain compared to standard contrastive objectives. In conclusion, our system
seamlessly routes user queries to task-specific modules (e.g., ETA information,
traffic risk evaluation, and other typical scenarios in the transportation
domain), laying the groundwork for fully autonomous, intention-aware agents
without costly manual labelling.

</details>


### [125] [TripleWin: Fixed-Point Equilibrium Pricing for Data-Model Coupled Markets](https://arxiv.org/abs/2511.03368)
*Hongrun Ren,Yun Xiong,Lei You,Yingying Wang,Haixu Xiong,Yangyong Zhu*

Main category: cs.LG

TL;DR: 本文提出一个统一的数据模型耦合市场，通过供需映射的闭环机制，解决了传统定价方法中的不对称性问题，实验结果显示其在效率与公平性上具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 旨在打破数据交易与模型交易之间的壁垒，实现一个综合且对称的交易机制。

Method: 通过供给侧映射和需求侧映射的结合，形成闭环机制，链接供需两端及买卖双方的互动。

Result: 实验表明，所提方法在收敛效率与公平性上优于传统的中介中心和单方面定价机制。

Conclusion: 我们提出的统一数据模型耦合市场能有效解决传统定价机制中的不对称性问题，确保了价格的存在性、唯一性与全局收敛性。

Abstract: The rise of the machine learning (ML) model economy has intertwined markets
for training datasets and pre-trained models. However, most pricing approaches
still separate data and model transactions or rely on broker-centric pipelines
that favor one side. Recent studies of data markets with externalities capture
buyer interactions but do not yield a simultaneous and symmetric mechanism
across data sellers, model producers, and model buyers. We propose a unified
data-model coupled market that treats dataset and model trading as a single
system. A supply-side mapping transforms dataset payments into buyer-visible
model quotations, while a demand-side mapping propagates buyer prices back to
datasets through Shapley-based allocation. Together, they form a closed loop
that links four interactions: supply-demand propagation in both directions and
mutual coupling among buyers and among sellers. We prove that the joint
operator is a standard interference function (SIF), guaranteeing existence,
uniqueness, and global convergence of equilibrium prices. Experiments
demonstrate efficient convergence and improved fairness compared with
broker-centric and one-sided baselines. The code is available on
https://github.com/HongrunRen1109/Triple-Win-Pricing.

</details>


### [126] [Adaptable Hindsight Experience Replay for Search-Based Learning](https://arxiv.org/abs/2511.03405)
*Alexandros Vazaios,Jannis Brugger,Cedric Derstroff,Kristian Kersting,Mira Mezini*

Main category: cs.LG

TL;DR: Adaptable HER enhances AlphaZero-like systems by integrating flexible Hindsight Experience Replay, improving performance in sparse reward environments.


<details>
  <summary>Details</summary>
Motivation: To improve the guidance given by neural networks in sparse reward situations during the early training phases of AlphaZero-like systems.

Method: Integrating Hindsight Experience Replay with AlphaZero's Monte Carlo Tree Search framework, enabling modifications to HER properties.

Result: Experiments demonstrate that the adaptable HER framework outperforms both pure supervised and reinforcement learning methods, particularly in equation discovery tasks.

Conclusion: Adaptable HER provides a flexible integration of HER with AlphaZero, enhancing performance in classical search problems.

Abstract: AlphaZero-like Monte Carlo Tree Search systems, originally introduced for
two-player games, dynamically balance exploration and exploitation using neural
network guidance. This combination makes them also suitable for classical
search problems. However, the original method of training the network with
simulation results is limited in sparse reward settings, especially in the
early stages, where the network cannot yet give guidance. Hindsight Experience
Replay (HER) addresses this issue by relabeling unsuccessful trajectories from
the search tree as supervised learning signals. We introduce Adaptable HER
(\ours{}), a flexible framework that integrates HER with AlphaZero, allowing
easy adjustments to HER properties such as relabeled goals, policy targets, and
trajectory selection. Our experiments, including equation discovery, show that
the possibility of modifying HER is beneficial and surpasses the performance of
pure supervised or reinforcement learning.

</details>


### [127] [Reinforcement Learning Using known Invariances](https://arxiv.org/abs/2511.03473)
*Alexandru Cioba,Aya Kayal,Laura Toni,Sattar Vakili,Alberto Bernacchia*

Main category: cs.LG

TL;DR: 本研究提出一种对称感知的强化学习框架，利用环境对称性提高学习效率，并通过实证验证其性能提升。


<details>
  <summary>Details</summary>
Motivation: 探讨如何利用环境中的对称性来提高强化学习的学习效率。

Method: 提出了一种对称感知的乐观最小二乘值迭代（LSVI）变种，并利用不变核编码奖励和转移动态中的不变性。

Result: 在自定义的Frozen Lake环境和二维放置设计问题上的实证结果验证了理论改进，表明对称感知的强化学习相较于标准核算法表现显著更好。

Conclusion: 引入对称性意识的强化学习算法可以显著提高学习效率和性能。

Abstract: In many real-world reinforcement learning (RL) problems, the environment
exhibits inherent symmetries that can be exploited to improve learning
efficiency. This paper develops a theoretical and algorithmic framework for
incorporating known group symmetries into kernel-based RL. We propose a
symmetry-aware variant of optimistic least-squares value iteration (LSVI),
which leverages invariant kernels to encode invariance in both rewards and
transition dynamics. Our analysis establishes new bounds on the maximum
information gain and covering numbers for invariant RKHSs, explicitly
quantifying the sample efficiency gains from symmetry. Empirical results on a
customized Frozen Lake environment and a 2D placement design problem confirm
the theoretical improvements, demonstrating that symmetry-aware RL achieves
significantly better performance than their standard kernel counterparts. These
findings highlight the value of structural priors in designing more
sample-efficient reinforcement learning algorithms.

</details>


### [128] [RAGBoost: Efficient Retrieval-Augmented Generation with Accuracy-Preserving Context Reuse](https://arxiv.org/abs/2511.03475)
*Yinsicheng Jiang,Yeqi Huang,Liang Cheng,Cheng Deng,Xuan Sun,Luo Mai*

Main category: cs.LG

TL;DR: RAGBoost是一种高效的RAG系统，通过上下文重用提高缓存重用率，显著提升大型语言模型的预填性能和推理准确性。


<details>
  <summary>Details</summary>
Motivation: 现代应用程序对输入的长度和复杂性要求更高，因此需要提高RAG系统在缓存重用和推理质量之间的平衡。

Method: 采用高效的上下文索引、排序和去重技术来检测并重用重叠的检索项，同时通过轻量级的上下文提示来保持推理的准确性。

Result: RAGBoost系统在多个RAG和智能AI工作负载下，将预填性能提高了1.5到3倍，同时在保持或增强推理准确性。

Conclusion: RAGBoost通过准确保留上下文重用，提高缓存重用率，同时保持高准确性，从而改善了大型语言模型的预填性能和推理准确性。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs)
with retrieved context but often suffers from downgraded prefill performance as
modern applications demand longer and more complex inputs. Existing caching
techniques either preserve accuracy with low cache reuse or improve reuse at
the cost of degraded reasoning quality. We present RAGBoost, an efficient RAG
system that achieves high cache reuse without sacrificing accuracy through
accuracy-preserving context reuse. RAGBoost detects overlapping retrieved items
across concurrent sessions and multi-turn interactions, using efficient context
indexing, ordering, and de-duplication to maximize reuse, while lightweight
contextual hints maintain reasoning fidelity. It integrates seamlessly with
existing LLM inference engines and improves their prefill performance by 1.5-3X
over state-of-the-art methods, while preserving or even enhancing reasoning
accuracy across diverse RAG and agentic AI workloads. Our code is released at:
https://github.com/Edinburgh-AgenticAI/RAGBoost.

</details>


### [129] [NAP: Attention-Based Late Fusion for Automatic Sleep Staging](https://arxiv.org/abs/2511.03488)
*Alvise Dei Rossi,Julia van der Meer,Markus H. Schmidt,Claudio L. A. Bassetti,Luigi Fiorillo,Francesca Faraci*

Main category: cs.LG

TL;DR: 本文提出了NAP模型，通过注意力机制聚合多导睡眠监测信号的预测，提高了模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有模型在处理多种多样的多导睡眠监测数据时，未能充分利用其固有的多模态特性。

Method: 引入一种基于注意力机制的模型，学习通过三轴注意力机制聚合多个预测流，捕捉时间、空间和预测者级别的依赖关系。

Result: 通过聚合多个冻结的预训练单通道模型的输出，NAP模型的表现超过了单一预测器和简单集成。

Conclusion: NAP模型在多种数据集上实现了最先进的零样本泛化，表现出色。

Abstract: Polysomnography signals are highly heterogeneous, varying in modality
composition (e.g., EEG, EOG, ECG), channel availability (e.g., frontal,
occipital EEG), and acquisition protocols across datasets and clinical sites.
Most existing models that process polysomnography data rely on a fixed subset
of modalities or channels and therefore neglect to fully exploit its inherently
multimodal nature. We address this limitation by introducing NAP (Neural
Aggregator of Predictions), an attention-based model which learns to combine
multiple prediction streams using a tri-axial attention mechanism that captures
temporal, spatial, and predictor-level dependencies. NAP is trained to adapt to
different input dimensions. By aggregating outputs from frozen, pretrained
single-channel models, NAP consistently outperforms individual predictors and
simple ensembles, achieving state-of-the-art zero-shot generalization across
multiple datasets. While demonstrated in the context of automated sleep staging
from polysomnography, the proposed approach could be extended to other
multimodal physiological applications.

</details>


### [130] [Why Less is More (Sometimes): A Theory of Data Curation](https://arxiv.org/abs/2511.03492)
*Elvis Dohmatob,Mohammad Pezeshki,Reyhane Askari-Hemmat*

Main category: cs.LG

TL;DR: 本研究提出了一个理论框架，分析在什么条件下少量精心策划的数据能优于大量数据，为数据策划策略提供了理论支持和实证验证。


<details>
  <summary>Details</summary>
Motivation: 针对现代机器学习中的一个核心悖论进行研究：何时使用更少的数据会更好。

Method: 通过理论分析和相应的实证研究，探讨了数据策划与训练数据选择的关系。

Result: 通过准确的缩放法则曲线，揭示了在不同数据策划规则下的测试误差，验证了小数据集在精确条件下的优势。

Conclusion: 小规模精心策划的数据集在特定条件下能够超过完整数据集，从而改进泛化能力。

Abstract: This paper introduces a theoretical framework to resolve a central paradox in
modern machine learning: When is it better to use less data? This question has
become critical as classical scaling laws suggesting ``more is more'' (Sun et
al., 2025) are challenged by methods like LIMO (``less is more'') and s1 (Ye et
al., 2025; Muenighoff et al., 2025), which achieve superior performance with
small, aggressively curated datasets. Here, we study data curation strategies
where an imperfect oracle selects the training examples according to their
difficulty and correctness. Our results provide exact scaling law curves for
test error under both label-agnostic and label-aware curation rules, revealing
when and why keeping only a subset of data can improve generalization. In
contrast to classical scaling laws, we show that under certain conditions,
small curated datasets can outperform full datasets, and we provide analytical
conditions for this by deriving precise phase transition curves tied to data
size and quality. We validate these theoretical claims with empirical results
on ImageNet, confirming our predictions about when curation improves accuracy
and can even mitigate model collapse. Furthermore, our framework provides a
principled explanation for the contradictory curation strategies recently
observed in LLM mathematical reasoning.

</details>


### [131] [Learning Without Critics? Revisiting GRPO in Classical Reinforcement Learning Environments](https://arxiv.org/abs/2511.03527)
*Bryan L. M. de Oliveira,Felipe V. Frujeri,Marcos P. C. M. Queiroz,Luana G. B. Martins,Telma W. de L. Soares,Luckeciano C. Melo*

Main category: cs.LG

TL;DR: GRPO作为PPO的替代方案在某些情况下有效，但学习批评者在长时间任务中仍然至关重要。


<details>
  <summary>Details</summary>
Motivation: 探索GRPO作为PPO的可扩展替代方案，重点研究学习的基线在策略梯度方法中的必要性。

Method: 通过系统性的控制消融实验，研究GRPO在不同强化学习环境下的表现。

Result: 在经典强化学习任务中发现：学习的批评者在长时间任务中是必要的，不同的折扣因子在特定任务中表现不同，小的分组规模优于大的分组。

Conclusion: GRPO在具体条件下可以替代学习基线，但仍需关注学习批评者对于长时间任务的重要性和不同折扣因子的影响。

Abstract: Group Relative Policy Optimization (GRPO) has emerged as a scalable
alternative to Proximal Policy Optimization (PPO) by eliminating the learned
critic and instead estimating advantages through group-relative comparisons of
trajectories. This simplification raises fundamental questions about the
necessity of learned baselines in policy-gradient methods. We present the first
systematic study of GRPO in classical single-task reinforcement learning
environments, spanning discrete and continuous control tasks. Through
controlled ablations isolating baselines, discounting, and group sampling, we
reveal three key findings: (1) learned critics remain essential for
long-horizon tasks: all critic-free baselines underperform PPO except in
short-horizon environments like CartPole where episodic returns can be
effective; (2) GRPO benefits from high discount factors (gamma = 0.99) except
in HalfCheetah, where lack of early termination favors moderate discounting
(gamma = 0.9); (3) smaller group sizes outperform larger ones, suggesting
limitations in batch-based grouping strategies that mix unrelated episodes.
These results reveal both the limitations of critic-free methods in classical
control and the specific conditions where they remain viable alternatives to
learned value functions.

</details>


### [132] [Byzantine-Robust Federated Learning with Learnable Aggregation Weights](https://arxiv.org/abs/2511.03529)
*Javad Parsa,Amir Hossein Daghestani,André M. H. Teixeira,Mikael Johansson*

Main category: cs.LG

TL;DR: 本文提出了一种新型的拜占庭鲁棒联邦学习优化问题，通过将加权视为可学习参数，显著提高了算法在恶意客户端和数据异构环境下的表现。


<details>
  <summary>Details</summary>
Motivation: 随着Federated Learning的广泛应用，恶意（拜占庭）客户端的存在对其鲁棒性提出了重大挑战，特别是在客户端数据分布异构的情况下。

Method: 我们提出了一种新颖的拜占庭鲁棒FL优化问题，通过将自适应加权融入聚合过程中，并将聚合权重视为可学习参数与全局模型参数共同优化。

Result: 我们开发了一种交替最小化算法，具有强大的收敛保证，在对抗攻击下进行优化，并评估了提出目标的拜占庭抗性。

Conclusion: 我们的方法在处理具有高度异构数据和大比例恶意客户端的设置中，表现优于现有的拜占庭鲁棒FL方法。

Abstract: Federated Learning (FL) enables clients to collaboratively train a global
model without sharing their private data. However, the presence of malicious
(Byzantine) clients poses significant challenges to the robustness of FL,
particularly when data distributions across clients are heterogeneous. In this
paper, we propose a novel Byzantine-robust FL optimization problem that
incorporates adaptive weighting into the aggregation process. Unlike
conventional approaches, our formulation treats aggregation weights as
learnable parameters, jointly optimizing them alongside the global model
parameters. To solve this optimization problem, we develop an alternating
minimization algorithm with strong convergence guarantees under adversarial
attack. We analyze the Byzantine resilience of the proposed objective. We
evaluate the performance of our algorithm against state-of-the-art
Byzantine-robust FL approaches across various datasets and attack scenarios.
Experimental results demonstrate that our method consistently outperforms
existing approaches, particularly in settings with highly heterogeneous data
and a large proportion of malicious clients.

</details>


### [133] [Flat Minima and Generalization: Insights from Stochastic Convex Optimization](https://arxiv.org/abs/2511.03548)
*Matan Schliserman,Shira Vansover-Hager,Tomer Koren*

Main category: cs.LG

TL;DR: 本研究探讨了平坦极小值对泛化能力的影响，显示即便是尖锐性感知算法，平坦解仍可能泛化不良。


<details>
  <summary>Details</summary>
Motivation: 了解学习算法的泛化能力，以优化算法性能，改进实际应用中的学习效果。

Method: 研究随机凸优化中的平坦极小值与泛化能力的关系，分析SA-GD和SAM算法的行为。

Result: 平坦极小值可能导致高达Ω(1)的人口风险，而由SA-GD和SAM算法获得的极小值也可能存在类似问题。

Conclusion: 本研究揭示了平坦极小值与泛化能力之间的复杂关系，指出即使在精心设计的算法中，平坦极小值也可能伴随较高的人口风险。

Abstract: Understanding the generalization behavior of learning algorithms is a central
goal of learning theory. A recently emerging explanation is that learning
algorithms are successful in practice because they converge to flat minima,
which have been consistently associated with improved generalization
performance. In this work, we study the link between flat minima and
generalization in the canonical setting of stochastic convex optimization with
a non-negative, $\beta$-smooth objective. Our first finding is that, even in
this fundamental and well-studied setting, flat empirical minima may incur
trivial $\Omega(1)$ population risk while sharp minima generalizes optimally.
Then, we show that this poor generalization behavior extends to two natural
''sharpness-aware'' algorithms originally proposed by Foret et al. (2021),
designed to bias optimization toward flat solutions: Sharpness-Aware Gradient
Descent (SA-GD) and Sharpness-Aware Minimization (SAM). For SA-GD, which
performs gradient steps on the maximal loss in a predefined neighborhood, we
prove that while it successfully converges to a flat minimum at a fast rate,
the population risk of the solution can still be as large as $\Omega(1)$,
indicating that even flat minima found algorithmically using a sharpness-aware
gradient method might generalize poorly. For SAM, a computationally efficient
approximation of SA-GD based on normalized ascent steps, we show that although
it minimizes the empirical loss, it may converge to a sharp minimum and also
incur population risk $\Omega(1)$. Finally, we establish population risk upper
bounds for both SA-GD and SAM using algorithmic stability techniques.

</details>


### [134] [Imitation Learning in the Deep Learning Era: A Novel Taxonomy and Recent Advances](https://arxiv.org/abs/2511.03565)
*Iason Chrysomallis,Georgios Chalkiadakis*

Main category: cs.LG

TL;DR: 本文综述了模仿学习的最新进展，提出了新分类法，分析了研究的优缺点及未来的挑战。


<details>
  <summary>Details</summary>
Motivation: 旨在系统性地分析模仿学习的发展现状及其面临的挑战，以促进该领域的研究进展。

Method: 通过对现有文献的回顾和分析，总结模仿学习中的最新趋势和方法创新。

Result: 提出了一种与现有分类不同的新分类法，并识别了模仿学习研究中的关键挑战和未来的研究方向。

Conclusion: 本文对模仿学习研究的最新进展进行了综述，提出了新的分类法，并讨论了现有工作的优缺点及未来研究方向。

Abstract: Imitation learning (IL) enables agents to acquire skills by observing and
replicating the behavior of one or multiple experts. In recent years, advances
in deep learning have significantly expanded the capabilities and scalability
of imitation learning across a range of domains, where expert data can range
from full state-action trajectories to partial observations or unlabeled
sequences. Alongside this growth, novel approaches have emerged, with new
methodologies being developed to address longstanding challenges such as
generalization, covariate shift, and demonstration quality. In this survey, we
review the latest advances in imitation learning research, highlighting recent
trends, methodological innovations, and practical applications. We propose a
novel taxonomy that is distinct from existing categorizations to better reflect
the current state of the IL research stratum and its trends. Throughout the
survey, we critically examine the strengths, limitations, and evaluation
practices of representative works, and we outline key challenges and open
directions for future research.

</details>


### [135] [TabGemma: Text-Based Tabular ICL via LLM using Continued Pretraining and Retrieval](https://arxiv.org/abs/2511.03570)
*Günther Schindler,Maximilian Schambach,Michael Medek,Sam Thelin*

Main category: cs.LG

TL;DR: TabGemma是一种针对混合文本、数值和分类字段的表格预测大语言模型，展示了在处理复杂表格数据时的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练大语言模型（LLMs）在表格数据预测中的表现不稳定，因此需要改进以处理数值标记化不稳定和上下文窗口的限制。

Method: 提出了一种名为TabGemma的方案，通过对数值进行标准化处理和继续预训练Gemma 3模型来进行适应，同时采用n-gram检索进行推理。

Result: TabGemma在语义丰富的基准测试中，在分类任务上树立了新的最优标准，尤其是在有限数据和大量数据的背景下表现出色，对于小样本的回归任务具有竞争力。

Conclusion: TabGemma在表格预测任务上表现优越，提出了一种有效处理数值和上下文的问题的方法，并为未来研究提供了动力。

Abstract: We study LLMs for tabular prediction with mixed text, numeric, and
categorical fields. We introduce TabGemma, a schema-agnostic in-context learner
that treats rows as sequences and tackles two practical hurdles when adapting
pretrained LLMs for tabular predictions: unstable numeric tokenization and
limited context size. We propose to canonicalize numbers via signed scientific
notation and continue pretraining of a 12B Gemma 3 model with a target
imputation objective using a large-scale real world dataset. For inference, we
use a compact n-gram-based retrieval to select informative exemplars that fit
within a 128k-token window.
  On semantically rich benchmarks, TabGemma establishes a new state of the art
on classification across low- and high-data regimes and improves monotonically
with more context rows. For regression, it is competitive at small sample sizes
but trails conventional approaches as data grows. Our results show that LLMs
can be effective tabular in-context learners on highly semantic tasks when
paired with dedicated numeric handling and context retrieval, while motivating
further advances in numeric modeling and long-context scaling.

</details>


### [136] [Tensor-Efficient High-Dimensional Q-learning](https://arxiv.org/abs/2511.03595)
*Junyi Wu,Dan Li*

Main category: cs.LG

TL;DR: TEQL是一种新的强化学习算法，通过改进张量分解和探索策略，提高样本效率，适用于高成本的采样环境。


<details>
  <summary>Details</summary>
Motivation: 高维强化学习在大状态-动作空间中面临复杂计算和低样本效率的问题，特别是Q学习算法在维度诅咒下表现不佳。

Method: 通过改进块坐标下降的方法，在离散化状态-动作空间中增强低秩张量分解，并引入新颖的探索和正则化机制。

Result: TEQL通过结合近似误差与基于访问计数的上置信界，优化探索策略，鼓励对访问较少的状态-动作对的探索，减少过拟合。

Conclusion: TEQL在样本效率和总体奖励方面优于传统矩阵方法和深度强化学习方法，适合资源受限的应用场景。

Abstract: High-dimensional reinforcement learning faces challenges with complex
calculations and low sample efficiency in large state-action spaces. Q-learning
algorithms struggle particularly with the curse of dimensionality, where the
number of state-action pairs grows exponentially with problem size. While
neural network-based approaches like Deep Q-Networks have shown success, recent
tensor-based methods using low-rank decomposition offer more
parameter-efficient alternatives. Building upon existing tensor-based methods,
we propose Tensor-Efficient Q-Learning (TEQL), which enhances low-rank tensor
decomposition via improved block coordinate descent on discretized state-action
spaces, incorporating novel exploration and regularization mechanisms. The key
innovation is an exploration strategy that combines approximation error with
visit count-based upper confidence bound to prioritize actions with high
uncertainty, avoiding wasteful random exploration. Additionally, we incorporate
a frequency-based penalty term in the objective function to encourage
exploration of less-visited state-action pairs and reduce overfitting to
frequently visited regions. Empirical results on classic control tasks
demonstrate that TEQL outperforms conventional matrix-based methods and deep RL
approaches in both sample efficiency and total rewards, making it suitable for
resource-constrained applications, such as space and healthcare where sampling
costs are high.

</details>


### [137] [Going Beyond Expert Performance via Deep Implicit Imitation Reinforcement Learning](https://arxiv.org/abs/2511.03616)
*Iason Chrysomallis,Georgios Chalkiadakis*

Main category: cs.LG

TL;DR: 本研究提出的DIIQN和HA-DIIQN算法，结合了深度强化学习与隐式模仿学习，成功应对了无专家示范的挑战，显著提升了学习效果和效率。


<details>
  <summary>Details</summary>
Motivation: 旨在克服传统模仿学习对完全状态-行动示范的要求和现实应用中的专家性能常常不理想的问题。

Method: 结合深度强化学习与仅基于观察的数据进行的隐式模仿学习，通过在线探索重建专家行动，并使用动态信心机制平衡专家指导与自主学习。

Result: DIIQN相比标准DQN可获得高达130%的回报提升，HA-DIIQN在异构行动设置中学习速度提高64%。

Conclusion: 该论文提出的DIIQN和HA-DIIQN算法有效解决了传统模仿学习中无法获得完整状态-行动示范的问题，并在多种测试中展现出卓越的性能与鲁棒性。

Abstract: Imitation learning traditionally requires complete state-action
demonstrations from optimal or near-optimal experts. These requirements
severely limit practical applicability, as many real-world scenarios provide
only state observations without corresponding actions and expert performance is
often suboptimal. In this paper we introduce a deep implicit imitation
reinforcement learning framework that addresses both limitations by combining
deep reinforcement learning with implicit imitation learning from
observation-only datasets. Our main algorithm, Deep Implicit Imitation
Q-Network (DIIQN), employs an action inference mechanism that reconstructs
expert actions through online exploration and integrates a dynamic confidence
mechanism that adaptively balances expert-guided and self-directed learning.
This enables the agent to leverage expert guidance for accelerated training
while maintaining capacity to surpass suboptimal expert performance. We further
extend our framework with a Heterogeneous Actions DIIQN (HA-DIIQN) algorithm to
tackle scenarios where expert and agent possess different action sets, a
challenge previously unaddressed in the implicit imitation learning literature.
HA-DIIQN introduces an infeasibility detection mechanism and a bridging
procedure identifying alternative pathways connecting agent capabilities to
expert guidance when direct action replication is impossible. Our experimental
results demonstrate that DIIQN achieves up to 130% higher episodic returns
compared to standard DQN, while consistently outperforming existing implicit
imitation methods that cannot exceed expert performance. In heterogeneous
action settings, HA-DIIQN learns up to 64% faster than baselines, leveraging
expert datasets unusable by conventional approaches. Extensive parameter
sensitivity analysis reveals the framework's robustness across varying dataset
sizes and hyperparameter configurations.

</details>


### [138] [Towards Formalizing Reinforcement Learning Theory](https://arxiv.org/abs/2511.03618)
*Shangtong Zhang*

Main category: cs.LG

TL;DR: 本文采用Lean 4定理证明器正式验证了Q学习和线性时间差学习的几乎确定性收敛性，为后续研究提供了统一的框架和代码支持。


<details>
  <summary>Details</summary>
Motivation: Q学习和线性时间差学习是早期和有影响力的强化学习算法，研究它们的收敛性质不仅在早期强化学习领域是重要课题，现今也受到越来越多的关注。

Method: 使用Lean 4定理证明器和Mathlib库，对Q学习和线性时间差学习的几乎确定性收敛性进行形式化验证。

Result: 本文在Robbins-Siegmund定理的基础上开发了一个统一的框架，能够轻松扩展到收敛速度和其他收敛模式的研究。

Conclusion: 本文在一个统一的框架中正式验证了Q学习和线性时间差学习的几乎确定性收敛性，为完全形式化收敛的强化学习结果迈出了重要一步。

Abstract: In this paper, we formalize the almost sure convergence of $Q$-learning and
linear temporal difference (TD) learning with Markovian samples using the Lean
4 theorem prover based on the Mathlib library. $Q$-learning and linear TD are
among the earliest and most influential reinforcement learning (RL) algorithms.
The investigation of their convergence properties is not only a major research
topic during the early development of the RL field but also receives increasing
attention nowadays. This paper formally verifies their almost sure convergence
in a unified framework based on the Robbins-Siegmund theorem. The framework
developed in this work can be easily extended to convergence rates and other
modes of convergence. This work thus makes an important step towards fully
formalizing convergent RL results. The code is available at
https://github.com/ShangtongZhang/rl-theory-in-lean.

</details>


### [139] [nanoTabPFN: A Lightweight and Educational Reimplementation of TabPFN](https://arxiv.org/abs/2511.03634)
*Alexander Pfefferle,Johannes Hog,Lennart Purucker,Frank Hutter*

Main category: cs.LG

TL;DR: nanoTabPFN是TabPFN v2的简化实现，降低了表格数据预测模型的使用门槛，适用于教育和研究。


<details>
  <summary>Details</summary>
Motivation: 当前的开源表格基础模型实现复杂、文档缺乏且难以适应新实验，限制了学习者和研究者的使用。

Method: 介绍了一种简化的轻量级实现，使用了TabPFN v2架构和相应的训练循环，利用预生成的训练数据。

Result: nanoTabPFN在单个GPU上进行小数据集预训练，效率是TabPFN v2预训练的160,000倍，极大地简化了表格模型的使用。

Conclusion: nanoTabPFN在小数据场景下表现出与传统机器学习基线相当的性能，同时大幅降低了预训练所需的计算资源，使得表格基础模型更加易于接触和使用。

Abstract: Tabular foundation models such as TabPFN have revolutionized predictive
machine learning for tabular data. At the same time, the driving factors of
this revolution are hard to understand. Existing open-source tabular foundation
models are implemented in complicated pipelines boasting over 10,000 lines of
code, lack architecture documentation or code quality. In short, the
implementations are hard to understand, not beginner-friendly, and complicated
to adapt for new experiments. We introduce nanoTabPFN, a simplified and
lightweight implementation of the TabPFN v2 architecture and a corresponding
training loop that uses pre-generated training data. nanoTabPFN makes tabular
foundation models more accessible to students and researchers alike. For
example, restricted to a small data setting it achieves a performance
comparable to traditional machine learning baselines within one minute of
pre-training on a single GPU (160,000x faster than TabPFN v2 pretraining). This
eliminated requirement of large computational resources makes pre-training
tabular foundation models accessible for educational purposes. Our code is
available at https://github.com/automl/nanoTabPFN.

</details>


### [140] [Structured Matrix Scaling for Multi-Class Calibration](https://arxiv.org/abs/2511.03685)
*Eugène Berta,David Holzmüller,Michael I. Jordan,Francis Bach*

Main category: cs.LG

TL;DR: 本研究探讨了更有效的多类分类器概率估计方法，提出了结合结构化正则化的参数化再校准函数，并展示了其优越性和开源实现。


<details>
  <summary>Details</summary>
Motivation: 提出基于逻辑回归的参数化再校准函数，旨在提高分类器概率估计的可信度和准确性。

Method: 通过复杂实验，结合结构化正则化、强健预处理和高效优化，研究了后验再校准方法。

Result: 实验表明，所提出的方法在偏差-方差权衡上表现良好，相比现有的逻辑回归校准技术有显著提升。

Conclusion: 本研究提出的参数化再校准方法在多类分类任务中表现优越，克服了复杂模型带来的过拟合问题，并提供了高效、易于使用的开源实现。

Abstract: Post-hoc recalibration methods are widely used to ensure that classifiers
provide faithful probability estimates. We argue that parametric recalibration
functions based on logistic regression can be motivated from a simple
theoretical setting for both binary and multiclass classification. This insight
motivates the use of more expressive calibration methods beyond standard
temperature scaling. For multi-class calibration however, a key challenge lies
in the increasing number of parameters introduced by more complex models, often
coupled with limited calibration data, which can lead to overfitting. Through
extensive experiments, we demonstrate that the resulting bias-variance tradeoff
can be effectively managed by structured regularization, robust preprocessing
and efficient optimization. The resulting methods lead to substantial gains
over existing logistic-based calibration techniques. We provide efficient and
easy-to-use open-source implementations of our methods, making them an
attractive alternative to common temperature, vector, and matrix scaling
implementations.

</details>


### [141] [Behavior-Adaptive Q-Learning: A Unifying Framework for Offline-to-Online RL](https://arxiv.org/abs/2511.03695)
*Lipeng Zu,Hansong Zhou,Xiaonan Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种新框架BAQ，通过利用离线数据的隐性行为模型，改善从离线到在线强化学习的过渡，取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决离线强化学习在动态环境中面临的分布偏移和不可靠的价值估计问题。

Method: 通过引入双目标损失函数来平衡离线行为和在线经验的适应。

Result: BAQ在标准基准测试中表现优于以往的离线到在线强化学习方法，具备更快的恢复速度和更高的整体表现。

Conclusion: BAQ提供了一种有效的隐性行为适应机制，能够在动态环境中实现可靠的政策部署。

Abstract: Offline reinforcement learning (RL) enables training from fixed data without
online interaction, but policies learned offline often struggle when deployed
in dynamic environments due to distributional shift and unreliable value
estimates on unseen state-action pairs. We introduce Behavior-Adaptive
Q-Learning (BAQ), a framework designed to enable a smooth and reliable
transition from offline to online RL. The key idea is to leverage an implicit
behavioral model derived from offline data to provide a behavior-consistency
signal during online fine-tuning. BAQ incorporates a dual-objective loss that
(i) aligns the online policy toward the offline behavior when uncertainty is
high, and (ii) gradually relaxes this constraint as more confident online
experience is accumulated. This adaptive mechanism reduces error propagation
from out-of-distribution estimates, stabilizes early online updates, and
accelerates adaptation to new scenarios. Across standard benchmarks, BAQ
consistently outperforms prior offline-to-online RL approaches, achieving
faster recovery, improved robustness, and higher overall performance. Our
results demonstrate that implicit behavior adaptation is a principled and
practical solution for reliable real-world policy deployment.

</details>


### [142] [Shrinking the Variance: Shrinkage Baselines for Reinforcement Learning with Verifiable Rewards](https://arxiv.org/abs/2511.03710)
*Guanning Zeng,Zhaoyi Zhou,Daman Arora,Andrea Zanette*

Main category: cs.LG

TL;DR: 本文提出了一种收缩估计方法，旨在提高强化学习中奖励估计精度，从而促进训练的稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 在低生成阶段，通过提高每个提示的均值估计精度来稳定强化学习训练过程。

Method: 采用收缩估计量，通过结合每个提示的经验平均和跨提示的均值来估计奖励，提出了一种收缩基线。

Result: 实验结果显示，收缩基线在降低方差的梯度更新方面一致优于传统的经验均值基线。

Conclusion: 提出的收缩基线在多种算法中证明了能够显著降低方差，并提升训练的稳定性。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for post-training large reasoning models (LRMs) using
policy-gradient methods such as GRPO. To stabilize training, these methods
typically center trajectory rewards by subtracting the empirical mean for each
prompt. Statistically, this centering acts as a control variate (or baseline),
reducing the variance of the policy-gradient estimator.
  Typically, the mean reward is estimated using per-prompt empirical averages
for each prompt in a batch. Drawing inspiration from Stein's paradox, we
propose using shrinkage estimators that combine per-prompt and across-prompt
means to improve the overall per-prompt mean estimation accuracy --
particularly in the low-generation regime typical of RLVR. Theoretically, we
construct a shrinkage-based baseline that provably yields lower-variance
policy-gradient estimators across algorithms. Our proposed baseline serves as a
drop-in replacement for existing per-prompt mean baselines, requiring no
additional hyper-parameters or computation. Empirically, shrinkage baselines
consistently outperform standard empirical-mean baselines, leading to
lower-variance gradient updates and improved training stability.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [143] [ALAS: Transactional and Dynamic Multi-Agent LLM Planning](https://arxiv.org/abs/2511.03094)
*Longling Geng,Edward Y. Chang*

Main category: cs.MA

TL;DR: ALAS是一个新框架，通过状态管理和局部修复机制，提高了多智能体规划的效率和成功率，表现出色。


<details>
  <summary>Details</summary>
Motivation: 针对大型语言模型在多智能体规划中的脆弱性，特别是在验证和状态跟踪方面存在的问题，提出更有效的解决方案。

Method: 使用版本化执行日志记录执行状态，采用局部修复协议，减小对整个系统的影响，同时减少了必要的计算。

Result: 在五个经典基准测试中，ALAS的成功率达到83.7%，同时减少了60%的token使用，运行速度提高了1.82倍。

Conclusion: ALAS框架通过引入状态管理、版本化执行日志和局部修复机制，在多智能体规划中提升了效率、可行性和可扩展性，成功应对了传统机制中的局限性。

Abstract: Large language models enable flexible multi-agent planning but remain fragile
in practice: verification is often circular, state changes are not tracked for
repair, and small faults trigger costly global recomputation. We present ALAS,
a stateful, disruption-aware framework that separates planning from
non-circular validation, records a versioned execution log for grounded checks
and restore points, and performs localized repair that preserves work in
progress. The validator operates independently of the planning LLM with fresh,
bounded context, avoiding self-check loops and mid-context attrition. The
repair protocol edits only the minimal affected region under explicit policies
(retry, catch, timeout, backoff, idempotency keys, compensation, loop guards)
defined in a canonical workflow IR that maps to Amazon States Language and Argo
Workflows. On job-shop scheduling suites (DMU, TA) across five classical
benchmarks, ALAS matches or exceeds strong single-LLM and multi-agent
baselines, achieving 83.7% success, reducing token usage by 60%, and running
1.82times faster under comparable settings. A minimal reliability study shows
that the validator detects injected structural faults with low overhead, and
that localized repair contains runtime perturbations with a bounded edit radius
and less makespan degradation than global recompute. Results indicate that the
combination of validator isolation, versioned execution logs, and localized
repair provides measurable efficiency, feasibility, and scalability for
multi-agent LLM planning. Code and seeds will be released.

</details>


### [144] [Learning Communication Skills in Multi-task Multi-agent Deep Reinforcement Learning](https://arxiv.org/abs/2511.03348)
*Changxi Zhu,Mehdi Dastani,Shihan Wang*

Main category: cs.MA

TL;DR: 本论文提出了一种多任务通信能力的MADRL方法，通过可学习的通信协议实现多个任务的协作，实验结果显示其性能优于现有的基线方法。


<details>
  <summary>Details</summary>
Motivation: 通过让智能体在多个任务中相互通信，提升任务学习效率，利用一种新的学习和协作机制来优化多任务学习过程。

Method: 提出一种多任务通信能力(MCS)的MADRL方法，利用可学习的通信协议和Transformer编码器来实现多任务的协同学习。

Result: 在多任务基准环境中进行实验，得到MCS在性能上优于其他基线。

Conclusion: MCS在多任务MADRL中的表现优于没有通信的多任务基线和有无通信的单任务基线。

Abstract: In multi-agent deep reinforcement learning (MADRL), agents can communicate
with one another to perform a task in a coordinated manner. When multiple tasks
are involved, agents can also leverage knowledge from one task to improve
learning in other tasks. In this paper, we propose Multi-task Communication
Skills (MCS), a MADRL with communication method that learns and performs
multiple tasks simultaneously, with agents interacting through learnable
communication protocols. MCS employs a Transformer encoder to encode
task-specific observations into a shared message space, capturing shared
communication skills among agents. To enhance coordination among agents, we
introduce a prediction network that correlates messages with the actions of
sender agents in each task. We adapt three multi-agent benchmark environments
to multi-task settings, where the number of agents as well as the observation
and action spaces vary across tasks. Experimental results demonstrate that MCS
achieves better performance than multi-task MADRL baselines without
communication, as well as single-task MADRL baselines with and without
communication.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [145] [Epidemiology of Large Language Models: A Benchmark for Observational Distribution Knowledge](https://arxiv.org/abs/2511.03070)
*Drago Plecko,Patrik Okanovic,Torsten Hoefler,Elias Bareinboim*

Main category: cs.AI

TL;DR: 本文开发了一个基准来测试大型语言模型在理解和处理现实世界概率分布方面的能力，结果表明其表现不佳，缺乏必要的观察性分布知识。


<details>
  <summary>Details</summary>
Motivation: 鉴于LLMs在海量文本上训练，旨在评估其是否能够内化和理解实际的概率分布以增强其智能能力。

Method: 开发并测试一个基准，以评价大型语言模型（LLMs）对描述真实世界人群的概率分布的理解能力。

Result: 研究结果显示，LLMs的表现整体较差，未能自然内化现实世界的统计数据。

Conclusion: LLMs在理解和内部化实际统计数据方面表现不佳，未能具备必要的观察性分布知识，因此在因果层次结构中，其干预性和反事实知识也受到限制。

Abstract: Artificial intelligence (AI) systems hold great promise for advancing various
scientific disciplines, and are increasingly used in real-world applications.
Despite their remarkable progress, further capabilities are expected in order
to achieve more general types of intelligence. A critical distinction in this
context is between factual knowledge, which can be evaluated against true or
false answers (e.g., "what is the capital of England?"), and probabilistic
knowledge, reflecting probabilistic properties of the real world (e.g., "what
is the sex of a computer science graduate in the US?"). In this paper, our goal
is to build a benchmark for understanding the capabilities of LLMs in terms of
knowledge of probability distributions describing the real world. Given that
LLMs are trained on vast amounts of text, it may be plausible that they
internalize aspects of these distributions. Indeed, LLMs are touted as powerful
universal approximators of real-world distributions. At the same time,
classical results in statistics, known as curse of dimensionality, highlight
fundamental challenges in learning distributions in high dimensions,
challenging the notion of universal distributional learning. In this work, we
develop the first benchmark to directly test this hypothesis, evaluating
whether LLMs have access to empirical distributions describing real-world
populations across domains such as economics, health, education, and social
behavior. Our results demonstrate that LLMs perform poorly overall, and do not
seem to internalize real-world statistics naturally. When interpreted in the
context of Pearl's Causal Hierarchy (PCH), our benchmark demonstrates that
language models do not contain knowledge on observational distributions (Layer
1 of PCH), and thus the Causal Hierarchy Theorem implies that interventional
(Layer 2) and counterfactual (Layer 3) knowledge of these models is also
limited.

</details>


### [146] [SnapStream: Efficient Long Sequence Decoding on Dataflow Accelerators](https://arxiv.org/abs/2511.03092)
*Jonathan Li,Nasim Farahini,Evgenii Iuliugin,Magnus Vesterlund,Christian Haggstrom,Guangtao Wang,Shubhangi Upasani,Ayush Sachdeva,Rui Li,Faline Fu,Chen Wu,Ayesha Siddiqua,John Long,Tuowen Zhao,Matheen Musaddiq,Hakan Zeffer,Yun Du,Mingran Wang,Qinghua Li,Bo Li,Urmish Thakker,Raghu Prabhakar*

Main category: cs.AI

TL;DR: 本文提出SnapStream，一种KV缓存压缩方法，通过在实际生产环境中测试，验证了其在提升内存使用和保持准确性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 应对100B+参数语言模型对芯片内存的需求，探讨现有KV缓存控制技术在工业部署中的挑战。

Method: 开发SnapStream方法，分析其在实际生产环境中的效果。

Result: SnapStream在真实生产环境中实现了$4	imes$的内存使用提升，且在不同基准测试上准确性下降有限。

Conclusion: SnapStream是一种可大规模部署的KV缓存压缩方法，显著提升了芯片内存使用效率，同时对模型准确性影响较小。

Abstract: The proliferation of 100B+ parameter Large Language Models (LLMs) with 100k+
context length support have resulted in increasing demands for on-chip memory
to support large KV caches. Techniques such as StreamingLLM and SnapKV
demonstrate how to control KV cache size while maintaining model accuracy. Yet,
these techniques are not commonly used within industrial deployments using
frameworks like vLLM or SGLang. The reason is twofold: on one hand, the static
graphs and continuous batching methodology employed by these frameworks make it
difficult to admit modifications to the standard multi-head attention
algorithm, while on the other hand, the accuracy implications of such
techniques on modern instruction-following and reasoning models are not well
understood, obfuscating the need for implementing these techniques. In this
paper, we explore these accuracy implications on Llama-3.1-8B-Instruct and
DeepSeek-R1, and develop SnapStream, a KV cache compression method that can be
deployed at scale. We demonstrate the efficacy of SnapStream in a 16-way
tensor-parallel deployment of DeepSeek-671B on SambaNova SN40L accelerators
running at 128k context length and up to 1832 tokens per second in a real
production setting. SnapStream enables $4\times$ improved on-chip memory usage
and introduces minimal accuracy degradation on LongBench-v2, AIME24 and
LiveCodeBench. To the best of our knowledge, this is the first implementation
of sparse KV attention techniques deployed in a production inference system
with static graphs and continuous batching.

</details>


### [147] [Large language models require a new form of oversight: capability-based monitoring](https://arxiv.org/abs/2511.03106)
*Katherine C. Kellogg,Bingyang Ye,Yifan Hu,Guergana K. Savova,Byron Wallace,Danielle S. Bitterman*

Main category: cs.AI

TL;DR: 本文提出了一种能力基础监测的新方法，旨在提升对医疗保健中大型语言模型的效果监测能力，强调跨任务的系统性弱点检测。


<details>
  <summary>Details</summary>
Motivation: 在医疗保健中，大型语言模型的快速采用带来了对其监测的关注，传统的基于任务的监测方法不足以适应这些通用模型的特点。

Method: 提出了一种能力基础监测的方法，围绕模型的共享能力而非独立任务进行监测，旨在跨任务检测系统性弱点和特殊错误。

Result: 通过能力基础监测，可以更有效地识别和监测大型语言模型在实际使用中的性能变化，提供针对性的改进建议。

Conclusion: 能力基础监测将为医疗保健领域的大型语言模型及未来通用人工智能模型提供安全、适应性强和协作性高的监测基础。

Abstract: The rapid adoption of large language models (LLMs) in healthcare has been
accompanied by scrutiny of their oversight. Existing monitoring approaches,
inherited from traditional machine learning (ML), are task-based and founded on
assumed performance degradation arising from dataset drift. In contrast, with
LLMs, inevitable model degradation due to changes in populations compared to
the training dataset cannot be assumed, because LLMs were not trained for any
specific task in any given population. We therefore propose a new organizing
principle guiding generalist LLM monitoring that is scalable and grounded in
how these models are developed and used in practice: capability-based
monitoring. Capability-based monitoring is motivated by the fact that LLMs are
generalist systems whose overlapping internal capabilities are reused across
numerous downstream tasks. Instead of evaluating each downstream task
independently, this approach organizes monitoring around shared model
capabilities, such as summarization, reasoning, translation, or safety
guardrails, in order to enable cross-task detection of systemic weaknesses,
long-tail errors, and emergent behaviors that task-based monitoring may miss.
We describe considerations for developers, organizational leaders, and
professional societies for implementing a capability-based monitoring approach.
Ultimately, capability-based monitoring will provide a scalable foundation for
safe, adaptive, and collaborative monitoring of LLMs and future generalist
artificial intelligence models in healthcare.

</details>


### [148] [miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward](https://arxiv.org/abs/2511.03108)
*Azim Ospanov,Farzan Farnia,Roozbeh Yousefzadeh*

Main category: cs.AI

TL;DR: 本文分析了miniF2F基准的正式与非正式语句，并改进为miniF2F-v2，模型准确率从36%提高至70%。


<details>
  <summary>Details</summary>
Motivation: 旨在提升AI模型在数学奥林匹克竞赛中的表现，特别是在自动形式化和定理证明任务中的准确性。

Method: 分析miniF2F的正式和非正式数学问题，评估模型在理解和证明这些问题上的表现，比较了原始和更新数据集的准确性。

Result: 在改进后的miniF2F-v2数据集上，模型的最佳准确性提高到了70%，显示出自动形式化模型和定理证明器之间的显著差异。

Conclusion: 通过对miniF2F基准中正式和非正式陈述的全面分析，提出了改进的一版miniF2F-v2，显著提高了自动形式化和定理证明模型的性能。

Abstract: We perform a thorough analysis of the formal and informal statements in the
miniF2F benchmark from the perspective of an AI system that is tasked to
participate in a math Olympiad consisting of the problems in miniF2F. In such
setting, the model has to read and comprehend the problems in natural language,
formalize them in Lean language, then proceed with proving the problems, and it
will get credit for each problem if the formal proof corresponds to the
original informal statement presented to the model. Our evaluation results
reveal that the best accuracy of such pipeline can be about 36% using the SoTA
models in the literature, considerably lower than the individual SoTA
accuracies, 97% and 69% reported in the autoformalization and theorem proving
literature. Analyzing the failure modes, we trace back a considerable portion
of this drop to discrepancies between the formal and informal statements for
more than half of the problems in miniF2F. We proceed with correcting all the
errors, discrepancies and simplifications in formal and informal statements,
and present the miniF2F-v2 with fully verified formal and informal statements
and proofs. Evaluating the full theorem proving pipeline on miniF2F-v2 leads to
the best accuracy of 70%, a significant improvement from the 40% on the
original miniF2F, yet indicating considerable misalignment between the
autoformalization models and theorem provers. Our deep analysis suggests that a
higher quality benchmark can help the community better evaluate progress in the
field of formal reasoning and also better diagnose the failure and success
modes of autoformalization and theorem proving models. Our dataset is available
at https://github.com/roozbeh-yz/miniF2F_v2.

</details>


### [149] [Using Multi-modal Large Language Model to Boost Fireworks Algorithm's Ability in Settling Challenging Optimization Tasks](https://arxiv.org/abs/2511.03137)
*Shipeng Cen,Ying Tan*

Main category: cs.AI

TL;DR: 本研究提出了一种利用多模态大语言模型改进烟花算法的方法，针对复杂高维优化任务进行了研究，取得了优异的实验结果。


<details>
  <summary>Details</summary>
Motivation: 随着优化问题的复杂性和多样性增加，传统的优化方法已无法有效解决这些问题，因此需要创新的优化算法。

Method: 本研究采用烟花算法(FWA)作为基础优化器，通过引入多模态大语言模型(MLLM)设计了一种新的优化算法。

Result: 实验结果表明，在我们新框架下生成的烟花算法在多个问题实例上达到了或超过了最先进结果(SOTA)。

Conclusion: 基于多模态大语言模型的烟花算法在解决复杂高维优化任务中表现出色，取得了与现有最先进技术相媲美的结果。

Abstract: As optimization problems grow increasingly complex and diverse, advancements
in optimization techniques and paradigm innovations hold significant
importance. The challenges posed by optimization problems are primarily
manifested in their non-convexity, high-dimensionality, black-box nature, and
other unfavorable characteristics. Traditional zero-order or first-order
methods, which are often characterized by low efficiency, inaccurate gradient
information, and insufficient utilization of optimization information, are
ill-equipped to address these challenges effectively. In recent years, the
rapid development of large language models (LLM) has led to substantial
improvements in their language understanding and code generation capabilities.
Consequently, the design of optimization algorithms leveraging large language
models has garnered increasing attention from researchers. In this study, we
choose the fireworks algorithm(FWA) as the basic optimizer and propose a novel
approach to assist the design of the FWA by incorporating multi-modal large
language model(MLLM). To put it simply, we propose the concept of Critical
Part(CP), which extends FWA to complex high-dimensional tasks, and further
utilizes the information in the optimization process with the help of the
multi-modal characteristics of large language models. We focus on two specific
tasks: the \textit{traveling salesman problem }(TSP) and \textit{electronic
design automation problem} (EDA). The experimental results show that FWAs
generated under our new framework have achieved or surpassed SOTA results on
many problem instances.

</details>


### [150] [A Proprietary Model-Based Safety Response Framework for AI Agents](https://arxiv.org/abs/2511.03138)
*Qi Li,Jianjun Xu,Pingtao Wei,Jiu Li,Peiqiang Zhao,Jiwei Shi,Xuan Zhang,Yanhui Yang,Xiaodong Hui,Peng Xu,Wenqin Shao*

Main category: cs.AI

TL;DR: 该论文提出了一种安全响应框架，通过精细化处理用户查询和确保输出基于可信知识基础，提高了大型语言模型的安全性和信任度。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的广泛应用，安全问题日益突出，迫切需要有效的解决方案以确保其在关键领域的可信部署。

Method: 采用监督微调的安全分类模型和检索增强生成（RAG）技术，结合特定的解释模型进行风险识别和信息生成。

Result: 实验结果显示，所提框架在安全评估基准上的得分显著高于基线模型，并在高风险测试集上实现100%安全评分，验证了其卓越的保护能力。

Conclusion: 该研究提出了一种新的安全响应框架，在输入和输出层面系统性地保障大型语言模型的安全性，通过精确的风险识别和可信的知识基础，显著提高了信任度与安全性。

Abstract: With the widespread application of Large Language Models (LLMs), their
associated security issues have become increasingly prominent, severely
constraining their trustworthy deployment in critical domains. This paper
proposes a novel safety response framework designed to systematically safeguard
LLMs at both the input and output levels. At the input level, the framework
employs a supervised fine-tuning-based safety classification model. Through a
fine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused
Attention), it performs precise risk identification and differentiated handling
of user queries, significantly enhancing risk coverage and business scenario
adaptability, and achieving a risk recall rate of 99.3%. At the output level,
the framework integrates Retrieval-Augmented Generation (RAG) with a
specifically fine-tuned interpretation model, ensuring all responses are
grounded in a real-time, trustworthy knowledge base. This approach eliminates
information fabrication and enables result traceability. Experimental results
demonstrate that our proposed safety control model achieves a significantly
higher safety score on public safety evaluation benchmarks compared to the
baseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk
test set, the framework's components attained a perfect 100% safety score,
validating their exceptional protective capabilities in complex risk scenarios.
This research provides an effective engineering pathway for building
high-security, high-trust LLM applications.

</details>


### [151] [Uncovering Bugs in Formal Explainers: A Case Study with PyXAI](https://arxiv.org/abs/2511.03169)
*Xuanxiang Huang,Yacine Izza,Alexey Ignatiev,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 本研究提出了一种新方法来验证正式解释器，并发现现有的PyXAI在大多数数据集上生成了错误的解释，突显了验证方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管正式可解释人工智能(XAI)提供了相较于其他非正式可解释方法的理论严密性，但实践中对正式解释器验证的关注较少。

Method: 开发了一种新的正式解释器验证方法，并对公开可用的正式解释器PyXAI进行了评估。

Result: 研究报告了PyXAI在被分析的多个数据集上出现不正确解释的现象。

Conclusion: 该研究确认了PyXAI在大多数实验数据集上计算出的解释存在错误，从而强调了提出的新方法在验证正式解释器中的重要性。

Abstract: Formal explainable artificial intelligence (XAI) offers unique theoretical
guarantees of rigor when compared to other non-formal methods of
explainability. However, little attention has been given to the validation of
practical implementations of formal explainers. This paper develops a novel
methodology for validating formal explainers and reports on the assessment of
the publicly available formal explainer PyXAI. The paper documents the
existence of incorrect explanations computed by PyXAI on most of the datasets
analyzed in the experiments, thereby confirming the importance of the proposed
novel methodology for the validation of formal explainers.

</details>


### [152] [Adobe Summit Concierge Evaluation with Human in the Loop](https://arxiv.org/abs/2511.03186)
*Yiru Chen,Sally Fang,Sai Sree Harsha,Dan Luo,Vaishnavi Muppala,Fei Wu,Shun Jiang,Kun Qian,Yunyao Li*

Main category: cs.AI

TL;DR: 本研究展示了如何通过人机协作开发领域特定的AI助手，提升企业会议的用户体验和信息获取效率。


<details>
  <summary>Details</summary>
Motivation: 提升企业环境中的生产力、信息访问效率和用户体验。

Method: 采用人机协作的开发工作流程，结合提示工程、检索基础和轻量级人类验证。

Result: 成功实现了针对Adobe Summit的域特定AI助手，能够处理广泛的事件相关查询，并应对数据稀疏、质量保证和快速部署等现实挑战。

Conclusion: 通过敏捷、反馈驱动的开发流程，我们成功推出了可扩展且可靠的AI助手，即使在冷启动的场景下也能表现良好。

Abstract: Generative AI assistants offer significant potential to enhance productivity,
streamline information access, and improve user experience in enterprise
contexts. In this work, we present Summit Concierge, a domain-specific AI
assistant developed for Adobe Summit. The assistant handles a wide range of
event-related queries and operates under real-world constraints such as data
sparsity, quality assurance, and rapid deployment. To address these challenges,
we adopt a human-in-the-loop development workflow that combines prompt
engineering, retrieval grounding, and lightweight human validation. We describe
the system architecture, development process, and real-world deployment
outcomes. Our experience shows that agile, feedback-driven development enables
scalable and reliable AI assistants, even in cold-start scenarios.

</details>


### [153] [From Five Dimensions to Many: Large Language Models as Precise and Interpretable Psychological Profilers](https://arxiv.org/abs/2511.03235)
*Yi-Fei Liu,Yi-Long Lu,Di He,Hang Zhang*

Main category: cs.AI

TL;DR: 本文研究了大型语言模型如何通过最小数据有效建模人类心理特征，并表现出显著的准确性和推理能力。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLMs）是否及如何能够从最小的定量输入中建模人类心理特征的相关结构。

Method: 利用816个个体的五大人格量表反应，提示不同的大型语言模型（LLMs），并模拟其在其他九个心理量表上的反应。

Result: LLMs在捕捉人类心理结构方面表现出色，生成的响应与人类数据的相关模式高度一致，且零样本表现超出基于语义相似度的预测，接近于直接在数据集上训练的机器学习算法的准确度。

Conclusion: LLMs能够通过抽象和推理从最小数据中精确预测个体心理特征，展现了其在心理模拟中的强大潜力及其新兴推理能力的深入洞察。

Abstract: Psychological constructs within individuals are widely believed to be
interconnected. We investigated whether and how Large Language Models (LLMs)
can model the correlational structure of human psychological traits from
minimal quantitative inputs. We prompted various LLMs with Big Five Personality
Scale responses from 816 human individuals to role-play their responses on nine
other psychological scales. LLMs demonstrated remarkable accuracy in capturing
human psychological structure, with the inter-scale correlation patterns from
LLM-generated responses strongly aligning with those from human data $(R^2 >
0.89)$. This zero-shot performance substantially exceeded predictions based on
semantic similarity and approached the accuracy of machine learning algorithms
trained directly on the dataset. Analysis of reasoning traces revealed that
LLMs use a systematic two-stage process: First, they transform raw Big Five
responses into natural language personality summaries through information
selection and compression, analogous to generating sufficient statistics.
Second, they generate target scale responses based on reasoning from these
summaries. For information selection, LLMs identify the same key personality
factors as trained algorithms, though they fail to differentiate item
importance within factors. The resulting compressed summaries are not merely
redundant representations but capture synergistic information--adding them to
original scores enhances prediction alignment, suggesting they encode emergent,
second-order patterns of trait interplay. Our findings demonstrate that LLMs
can precisely predict individual participants' psychological traits from
minimal data through a process of abstraction and reasoning, offering both a
powerful tool for psychological simulation and valuable insights into their
emergent reasoning capabilities.

</details>


### [154] [Explaining Decisions in ML Models: a Parameterized Complexity Analysis (Part I)](https://arxiv.org/abs/2511.03545)
*Sebastian Ordyniak,Giacomo Paesani,Mateusz Rychlicki,Stefan Szeider*

Main category: cs.AI

TL;DR: 本论文探讨了各种机器学习模型中解释问题的参数化复杂性，重点关注具有透明机制的模型，以推动可解释人工智能的发展。


<details>
  <summary>Details</summary>
Motivation: 应对当前大多数机器学习模型被视为黑箱的普遍认知，关注具有透明内部机制的模型的解释问题。

Method: 通过理论分析不同机器学习模型下的解释问题，主要包括归纳性和对比性解释。

Result: 分析了多种机器学习模型如决策树、决策集合、决策列表及布尔电路等，指出各模型面临的独特解释挑战。

Conclusion: 本研究为可解释人工智能领域提供了生成解释复杂性的基础理解，强调了透明性与责任的重要性。

Abstract: This paper presents a comprehensive theoretical investigation into the
parameterized complexity of explanation problems in various machine learning
(ML) models. Contrary to the prevalent black-box perception, our study focuses
on models with transparent internal mechanisms. We address two principal types
of explanation problems: abductive and contrastive, both in their local and
global variants. Our analysis encompasses diverse ML models, including Decision
Trees, Decision Sets, Decision Lists, Boolean Circuits, and ensembles thereof,
each offering unique explanatory challenges. This research fills a significant
gap in explainable AI (XAI) by providing a foundational understanding of the
complexities of generating explanations for these models. This work provides
insights vital for further research in the domain of XAI, contributing to the
broader discourse on the necessity of transparency and accountability in AI
systems.

</details>

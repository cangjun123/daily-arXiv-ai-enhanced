<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 76]
- [cs.CL](#cs.CL) [Total: 45]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.LG](#cs.LG) [Total: 55]
- [cs.AI](#cs.AI) [Total: 19]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [GAZE:Governance-Aware pre-annotation for Zero-shot World Model Environments](https://arxiv.org/abs/2510.14992)
*Leela Krishna,Mengyang Zhao,Saicharithreddy Pasula,Harshit Rajgarhia,Abhishek Mukherji*

Main category: cs.CV

TL;DR: 提出了一种名为GAZE的自动化处理流程，用于将长视频转换为可用于训练世界模型的多模态数据，显著提高了效率并减少了人工审查量。


<details>
  <summary>Details</summary>
Motivation: 历史上，大规模标注多模态数据的过程受到手动注释的成本和时间限制，因此需要一种高效的自动化解决方案。

Method: GAZE流程包括三个主要步骤：格式标准化、预注释处理以及结构化输出，以实现快速的人类验证。

Result: GAZE工作流程每小时节省约19分钟的审查时间，同时通过保守的自动跳过低重要性片段减少了超过80%的人工审查量。

Conclusion: GAZE流程实现了高效的多模态数据预注释，生成高质量的训练数据，同时确保隐私安全。

Abstract: Training robust world models requires large-scale, precisely labeled
multimodal datasets, a process historically bottlenecked by slow and expensive
manual annotation. We present a production-tested GAZE pipeline that automates
the conversion of raw, long-form video into rich, task-ready supervision for
world-model training. Our system (i) normalizes proprietary 360-degree formats
into standard views and shards them for parallel processing; (ii) applies a
suite of AI models (scene understanding, object tracking, audio transcription,
PII/NSFW/minor detection) for dense, multimodal pre-annotation; and (iii)
consolidates signals into a structured output specification for rapid human
validation.
  The GAZE workflow demonstrably yields efficiency gains (~19 minutes saved per
review hour) and reduces human review volume by >80% through conservative
auto-skipping of low-salience segments. By increasing label density and
consistency while integrating privacy safeguards and chain-of-custody metadata,
our method generates high-fidelity, privacy-aware datasets directly consumable
for learning cross-modal dynamics and action-conditioned prediction. We detail
our orchestration, model choices, and data dictionary to provide a scalable
blueprint for generating high-quality world model training data without
sacrificing throughput or governance.

</details>


### [2] [PC-UNet: An Enforcing Poisson Statistics U-Net for Positron Emission Tomography Denoising](https://arxiv.org/abs/2510.14995)
*Yang Shi,Jingchao Wang,Liangsi Lu,Mingxuan Huang,Ruixin He,Yifeng Xie,Hanqian Liu,Minzhe Guo,Yangyang Liang,Weipeng Zhang,Zimeng Li,Xuhang Chen*

Main category: cs.CV

TL;DR: 提出一种PC-UNet模型，通过PVMC-Loss提高PET图像的物理一致性和保真度。


<details>
  <summary>Details</summary>
Motivation: PET在医学中的应用受到高信噪比剂量限制，使放射线暴露增加且现有去噪方法处理不足。

Method: 提出了一种基于Poisson一致性的U-Net模型(PC-UNet)，结合了一种新的Poisson方差和均值一致性损失(PVMC-Loss)。

Result: 对PET数据集的测试表明，PC-UNet在物理一致性和图像保真度方面表现出色，显示出有效整合物理信息的能力。

Conclusion: PC-UNet模型在处理Poisson噪声的同时，确保了图像质量，展现了其在临床PET应用中的潜力。

Abstract: Positron Emission Tomography (PET) is crucial in medicine, but its clinical
use is limited due to high signal-to-noise ratio doses increasing radiation
exposure. Lowering doses increases Poisson noise, which current denoising
methods fail to handle, causing distortions and artifacts. We propose a Poisson
Consistent U-Net (PC-UNet) model with a new Poisson Variance and Mean
Consistency Loss (PVMC-Loss) that incorporates physical data to improve image
fidelity. PVMC-Loss is statistically unbiased in variance and gradient
adaptation, acting as a Generalized Method of Moments implementation, offering
robustness to minor data mismatches. Tests on PET datasets show PC-UNet
improves physical consistency and image fidelity, proving its ability to
integrate physical information effectively.

</details>


### [3] [DeLeaker: Dynamic Inference-Time Reweighting For Semantic Leakage Mitigation in Text-to-Image Models](https://arxiv.org/abs/2510.15015)
*Mor Ventura,Michael Toker,Or Patashnik,Yonatan Belinkov,Roi Reichart*

Main category: cs.CV

TL;DR: 本文提出了一种新方法DeLeaker，通过控制注意力图，在不牺牲图像质量的情况下，有效减轻Text-to-Image模型的语义泄漏问题，并引入了SLIM数据集用于评估。


<details>
  <summary>Details</summary>
Motivation: 尽管T2I模型取得了迅速进展，但仍然存在语义泄漏的脆弱性，现有的缓解策略往往依赖于优化或外部输入，因此需要一种新的方法。

Method: DeLeaker采用了一种轻量级的、非优化的推理时间方法，通过直接干预模型的注意力图来减轻语义泄漏问题。

Result: 实验结果表明，DeLeaker在所有基线方法中表现优异，即使在提供外部信息时也能有效减轻泄漏现象，而不影响生成图像的质量。

Conclusion: DeLeaker展示了通过注意力控制有效减轻语义泄漏的能力，且不影响图像生成的保真度和质量，预示着未来T2I模型在语义精确性上的更大进步。

Abstract: Text-to-Image (T2I) models have advanced rapidly, yet they remain vulnerable
to semantic leakage, the unintended transfer of semantically related features
between distinct entities. Existing mitigation strategies are often
optimization-based or dependent on external inputs. We introduce DeLeaker, a
lightweight, optimization-free inference-time approach that mitigates leakage
by directly intervening on the model's attention maps. Throughout the diffusion
process, DeLeaker dynamically reweights attention maps to suppress excessive
cross-entity interactions while strengthening the identity of each entity. To
support systematic evaluation, we introduce SLIM (Semantic Leakage in IMages),
the first dataset dedicated to semantic leakage, comprising 1,130
human-verified samples spanning diverse scenarios, together with a novel
automatic evaluation framework. Experiments demonstrate that DeLeaker
consistently outperforms all baselines, even when they are provided with
external information, achieving effective leakage mitigation without
compromising fidelity or quality. These results underscore the value of
attention control and pave the way for more semantically precise T2I models.

</details>


### [4] [UrbanVerse: Scaling Urban Simulation by Watching City-Tour Videos](https://arxiv.org/abs/2510.15018)
*Mingxuan Liu,Honglin He,Elisa Ricci,Wayne Wu,Bolei Zhou*

Main category: cs.CV

TL;DR: UrbanVerse是一个数据驱动的系统，将众包城市游的视频转换为物理交互模拟场景，提升了城市智能体的训练效果和真实转移性能。


<details>
  <summary>Details</summary>
Motivation: 为了训练城市中的智能体，亟需多样化且高保真的城市环境，现有的模拟场景无法有效捕捉现实复杂性。

Method: 通过从众包城市游览视频中提取场景布局，并利用UrbanVerse-100K中收集的3D资产自动构建物理感知的互动模拟场景。

Result: UrbanVerse构建了一个包含160个高质量场景和10个艺术家设计测试场景的基准，实验表明其场景在语义和布局上保留了真实世界的特征，并在城市导航任务中表现优异。

Conclusion: UrbanVerse在城市导航任务中表现出优越的泛化能力和成功率，显著提高了模拟和零样本真实转移的性能。

Abstract: Urban embodied AI agents, ranging from delivery robots to quadrupeds, are
increasingly populating our cities, navigating chaotic streets to provide
last-mile connectivity. Training such agents requires diverse, high-fidelity
urban environments to scale, yet existing human-crafted or procedurally
generated simulation scenes either lack scalability or fail to capture
real-world complexity. We introduce UrbanVerse, a data-driven real-to-sim
system that converts crowd-sourced city-tour videos into physics-aware,
interactive simulation scenes. UrbanVerse consists of: (i) UrbanVerse-100K, a
repository of 100k+ annotated urban 3D assets with semantic and physical
attributes, and (ii) UrbanVerse-Gen, an automatic pipeline that extracts scene
layouts from video and instantiates metric-scale 3D simulations using retrieved
assets. Running in IsaacSim, UrbanVerse offers 160 high-quality constructed
scenes from 24 countries, along with a curated benchmark of 10 artist-designed
test scenes. Experiments show that UrbanVerse scenes preserve real-world
semantics and layouts, achieving human-evaluated realism comparable to manually
crafted scenes. In urban navigation, policies trained in UrbanVerse exhibit
scaling power laws and strong generalization, improving success by +6.3% in
simulation and +30.1% in zero-shot sim-to-real transfer comparing to prior
methods, accomplishing a 300 m real-world mission with only two interventions.

</details>


### [5] [NANO3D: A Training-Free Approach for Efficient 3D Editing Without Masks](https://arxiv.org/abs/2510.15019)
*Junliang Ye,Shenghao Xie,Ruowen Zhao,Zhengyi Wang,Hongyu Yan,Wenqiang Zu,Lei Ma,Jun Zhu*

Main category: cs.CV

TL;DR: 提出了一种名为Nano3D的训练-free 3D物体编辑框架，解决了现有编辑方法中效率及一致性不足的问题，并引入了大规模3D编辑数据集。


<details>
  <summary>Details</summary>
Motivation: 现有3D编辑方法存在效率低下和区域不一致的问题，需要一个更有效且一致的解决方案。

Method: 结合FlowEdit与TRELLIS进行局部编辑，采用区域感知合并策略以确保结构一致性。

Result: Nano3D是一个无训练的框架，能够精确且连贯地进行3D物体编辑，解决了现有方法效率低下和区域不一致的问题。该框架结合了FlowEdit与TRELLIS，并引入了区域感知合并策略，使得编辑后与未编辑区域之间保持一致性。实验表明，Nano3D在3D一致性和视觉质量上优于现有方法。此外，Nano3D还构建了首个大规模3D编辑数据集Nano3D-Edit-100k，包含超过100,000对高质量的3D编辑样本，显著提高了3D编辑的通用性和可靠性。

Conclusion: Nano3D显著改善了3D编辑的效果，为未来的3D编辑模型开发提供了重要基础。

Abstract: 3D object editing is essential for interactive content creation in gaming,
animation, and robotics, yet current approaches remain inefficient,
inconsistent, and often fail to preserve unedited regions. Most methods rely on
editing multi-view renderings followed by reconstruction, which introduces
artifacts and limits practicality. To address these challenges, we propose
Nano3D, a training-free framework for precise and coherent 3D object editing
without masks. Nano3D integrates FlowEdit into TRELLIS to perform localized
edits guided by front-view renderings, and further introduces region-aware
merging strategies, Voxel/Slat-Merge, which adaptively preserve structural
fidelity by ensuring consistency between edited and unedited areas. Experiments
demonstrate that Nano3D achieves superior 3D consistency and visual quality
compared with existing methods. Based on this framework, we construct the first
large-scale 3D editing datasets Nano3D-Edit-100k, which contains over 100,000
high-quality 3D editing pairs. This work addresses long-standing challenges in
both algorithm design and data availability, significantly improving the
generality and reliability of 3D editing, and laying the groundwork for the
development of feed-forward 3D editing models. Project
Page:https://jamesyjl.github.io/Nano3D

</details>


### [6] [Constantly Improving Image Models Need Constantly Improving Benchmarks](https://arxiv.org/abs/2510.15021)
*Jiaxin Ge,Grace Luo,Heekyung Lee,Nishant Malpani,Long Lian,XuDong Wang,Aleksander Holynski,Trevor Darrell,Sewon Min,David M. Chan*

Main category: cs.CV

TL;DR: ECHO框架通过社交媒体算法生成的用户反馈构建新的基准，大幅提升了对图像生成模型的评估能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试滞后于快速发展的图像生成技术，无法捕捉到新兴用例，因此需要一个新的基准框架来评估这些模型的实际使用情况。

Method: 通过分析社交媒体帖子，提取用户实际用例和反馈，构建数据集并实施评估。

Result: 提出了ECHO框架，根据真实的模型使用证据构建基准，特别是社交媒体帖子中的提示和用户判断，应用于GPT-4o Image Gen，构建了超过31,000个提示的数据集。

Conclusion: ECHO不仅发现了现有基准测试下缺失的创意和复杂任务，还改善了对现有模型的区分，并为模型质量指标的设计提供了社区反馈。

Abstract: Recent advances in image generation, often driven by proprietary systems like
GPT-4o Image Gen, regularly introduce new capabilities that reshape how users
interact with these models. Existing benchmarks often lag behind and fail to
capture these emerging use cases, leaving a gap between community perceptions
of progress and formal evaluation. To address this, we present ECHO, a
framework for constructing benchmarks directly from real-world evidence of
model use: social media posts that showcase novel prompts and qualitative user
judgments. Applying this framework to GPT-4o Image Gen, we construct a dataset
of over 31,000 prompts curated from such posts. Our analysis shows that ECHO
(1) discovers creative and complex tasks absent from existing benchmarks, such
as re-rendering product labels across languages or generating receipts with
specified totals, (2) more clearly distinguishes state-of-the-art models from
alternatives, and (3) surfaces community feedback that we use to inform the
design of metrics for model quality (e.g., measuring observed shifts in color,
identity, and structure). Our website is at https://echo-bench.github.io.

</details>


### [7] [LoRAverse: A Submodular Framework to Retrieve Diverse Adapters for Diffusion Models](https://arxiv.org/abs/2510.15022)
*Mert Sonmezer,Matthew Zheng,Pinar Yanardag*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的子模框架，用于从数万LoRA适配器中优化选择，经过验证能生成多样化输出。


<details>
  <summary>Details</summary>
Motivation: 用户在面对大量LoRA适配器时选择困难，急需有效的选择和推荐机制。

Method: 将LoRA适配器选择任务视为组合优化问题，并提出子模框架，通过定量和定性实验验证效果。

Result: 高阶适配（LoRA）模型通过针对注意力层优化的低秩分解权重矩阵，变革了预训练扩散模型的个性化微调。这些模型可以生成高度定制化的内容，适用于各种对象、个体和艺术风格，而无需大量重新训练。尽管在Civit.ai等平台上有超过10万种LoRA适配器，但用户在导航、选择和有效利用最合适的适配器时面临挑战，这主要是由于数量庞大、多样性和缺乏结构化组织。本文通过将任务框架设定为组合优化问题，提出了一种新颖的子模框架，以解决从这一庞大数据库中选择最相关且多样化的LoRA模型的问题。我们的定量和定性实验表明，所提出的方法能够在广泛的领域内生成多样化的输出。

Conclusion: 所提出的子模框架有效解决了LoRA适配器的选择问题，提升了生成多样化内容的能力。

Abstract: Low-rank Adaptation (LoRA) models have revolutionized the personalization of
pre-trained diffusion models by enabling fine-tuning through low-rank,
factorized weight matrices specifically optimized for attention layers. These
models facilitate the generation of highly customized content across a variety
of objects, individuals, and artistic styles without the need for extensive
retraining. Despite the availability of over 100K LoRA adapters on platforms
like Civit.ai, users often face challenges in navigating, selecting, and
effectively utilizing the most suitable adapters due to their sheer volume,
diversity, and lack of structured organization. This paper addresses the
problem of selecting the most relevant and diverse LoRA models from this vast
database by framing the task as a combinatorial optimization problem and
proposing a novel submodular framework. Our quantitative and qualitative
experiments demonstrate that our method generates diverse outputs across a wide
range of domains.

</details>


### [8] [MOBIUS: Big-to-Mobile Universal Instance Segmentation via Multi-modal Bottleneck Fusion and Calibrated Decoder Pruning](https://arxiv.org/abs/2510.15026)
*Mattia Segu,Marta Tintore Gazulla,Yongqin Xian,Luc Van Gool,Federico Tombari*

Main category: cs.CV

TL;DR: MOBIUS是一种高效的实例分割模型，旨在支持各种设备上的部署，同时保持高性能和较少的训练迭代。


<details>
  <summary>Details</summary>
Motivation: 随着模型规模和训练数据的扩大，基础模型在实例级感知方面取得了显著进展，但高计算成本限制了在资源受限平台上的应用。

Method: 提出了一种瓶颈像素解码器、语言引导的uncertainty calibration损失和统一训练策略，以优化训练和推理要求。

Result: MOBIUS在不牺牲性能的情况下，减少了像素和变换解码器的FLOPs，效率提高了55%和75%。

Conclusion: MOBIUS是一系列设计用于普遍实例分割的基础模型，在高性能计算平台和移动设备上建立了高效分割的新基准。

Abstract: Scaling up model size and training data has advanced foundation models for
instance-level perception, achieving state-of-the-art in-domain and zero-shot
performance across object detection and segmentation. However, their high
computational cost limits adoption on resource-constrained platforms. We first
examine the limitations of existing architectures in enabling efficient edge
deployment without compromising performance. We then introduce MOBIUS, a family
of foundation models for universal instance segmentation, designed for
Pareto-optimal downscaling to support deployment across devices ranging from
high-end accelerators to mobile hardware. To reduce training and inference
demands, we propose: (i) a bottleneck pixel decoder for efficient multi-scale
and multi-modal fusion, (ii) a language-guided uncertainty calibration loss for
adaptive decoder pruning, and (iii) a streamlined, unified training strategy.
Unlike efficient baselines that trade accuracy for reduced complexity, MOBIUS
reduces pixel and transformer decoder FLOPs by up to 55% and 75%, respectively,
while maintaining state-of-the-art performance in just a third of the training
iterations. MOBIUS establishes a new benchmark for efficient segmentation on
both high-performance computing platforms and mobile devices.

</details>


### [9] [Composition-Grounded Instruction Synthesis for Visual Reasoning](https://arxiv.org/abs/2510.15040)
*Xinyi Gu,Jiayuan Mao,Zhang-Wei Hong,Zhuoran Yu,Pengyuan Li,Dhiraj Joshi,Rogerio Feris,Zexue He*

Main category: cs.CV

TL;DR: 提出COGS框架，通过合成问题-答案对，提高多模态大语言模型在推理任务中的能力，特别适用于图表和网页等人工图像领域。


<details>
  <summary>Details</summary>
Motivation: 在人工图像领域（如图表和网页）缺乏大规模人类注释推理数据集的情况下，提高多模态大语言模型的推理能力。

Method: 提出了一种数据高效的框架，通过将种子问题分解为原始感知和推理因素，生成合成问题-答案对以增强推理能力。

Result: COGS在图表推理实验中显著提高了对未见问题的表现，特别是推理密集型和组合性问题，且不同种子数据的混合训练提升了多数据集的转移能力。

Conclusion: COGS框架显著提升了多模态大语言模型在图表推理等任务中的表现，并适用于其他领域，如网页，展现了可泛化的能力。

Abstract: Pretrained multi-modal large language models (MLLMs) demonstrate strong
performance on diverse multimodal tasks, but remain limited in reasoning
capabilities for domains where annotations are difficult to collect. In this
work, we focus on artificial image domains such as charts, rendered documents,
and webpages, which are abundant in practice yet lack large-scale human
annotated reasoning datasets. We introduce COGS (COmposition-Grounded
instruction Synthesis), a data-efficient framework for equipping MLLMs with
advanced reasoning abilities from a small set of seed questions. The key idea
is to decompose each seed question into primitive perception and reasoning
factors, which can then be systematically recomposed with new images to
generate large collections of synthetic question-answer pairs. Each generated
question is paired with subquestions and intermediate answers, enabling
reinforcement learning with factor-level process rewards. Experiments on chart
reasoning show that COGS substantially improves performance on unseen
questions, with the largest gains on reasoning-heavy and compositional
questions. Moreover, training with a factor-level mixture of different seed
data yields better transfer across multiple datasets, suggesting that COGS
induces generalizable capabilities rather than dataset-specific overfitting. We
further demonstrate that the framework extends beyond charts to other domains
such as webpages.

</details>


### [10] [Comprehensive language-image pre-training for 3D medical image understanding](https://arxiv.org/abs/2510.15042)
*Tassilo Wald,Ibrahim Ethem Hamamci,Yuan Gao,Sam Bond-Taylor,Harshita Sharma,Maximilian Ilse,Cynthia Lo,Olesya Melnichenko,Noel C. F. Codella,Maria Teodora Wetscherek,Klaus H. Maier-Hein,Panagiotis Korfiatis,Valentina Salvatelli,Javier Alvarez-Valle,Fernando Pérez-García*

Main category: cs.CV

TL;DR: 本研究提出COLIPRI编码器，通过结合图像和文本数据，解决了3D医学图像数据稀缺的问题，提升了多项任务的性能。


<details>
  <summary>Details</summary>
Motivation: 在3D医学影像领域，现有的视觉语言编码器由于数据可用性限制而不能充分发挥其潜力，因此需要寻求解决方法来增强模型的表现。

Method: 将视觉语言预训练与视觉单一预训练相结合，并引入报表生成目标，从而利用更多的数据集进行训练。

Result: 提出了全面的语言-图像预训练（COLIPRI）编码器系列，该系列在报表生成、分类探测和零样本分类方面取得了最先进的性能，并在语义分割上保持竞争力。

Conclusion: 通过引入额外的归纳偏差和最佳实践，COLIPRI编码器在多个任务中显示出了卓越的性能，证明了其在3D医学图像处理中的应用潜力。

Abstract: Vision-language pre-training, i.e., aligning images with paired text, is a
powerful paradigm to create encoders that can be directly used for tasks such
as classification and retrieval, and for downstream tasks such as segmentation
and report generation. In the 3D medical image domain, these capabilities allow
vision-language encoders (VLEs) to support radiologists by retrieving patients
with similar abnormalities or predicting likelihoods of abnormality. While the
methodology holds promise, data availability limits the capabilities of current
3D VLEs.
  In this paper, we alleviate the lack of data by injecting additional
inductive biases: introducing a report generation objective and pairing
vision-language pre-training with vision-only pre-training. This allows us to
leverage both image-only and paired image-text 3D datasets, increasing the
total amount of data to which our model is exposed. Through these additional
inductive biases, paired with best practices of the 3D medical imaging domain,
we develop the Comprehensive Language-image Pre-training (COLIPRI) encoder
family. Our COLIPRI encoders achieve state-of-the-art performance in report
generation, classification probing, and zero-shot classification, and remain
competitive for semantic segmentation.

</details>


### [11] [Directional Reasoning Injection for Fine-Tuning MLLMs](https://arxiv.org/abs/2510.15050)
*Chao Huang,Zeliang Zhang,Jiang Liu,Ximeng Sun,Jialian Wu,Xiaodong Yu,Ze Wang,Chenliang Xu,Emad Barsoum,Zicheng Liu*

Main category: cs.CV

TL;DR: DRIFT是一种轻量级方法，通过在梯度空间中转移推理知识来提升多模态大型语言模型的推理能力，表现优于简单合并和传统微调方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型推理能力不足，传统的微调方法昂贵且资源消耗大，急需寻找更高效的改进方案。

Method: 通过在梯度空间中预计算推理知识，并在多模态微调过程中对梯度进行偏置来实现推理能力的转移。

Result: 该论文提出了一种名为DRIFT的轻量级方法，通过在梯度空间中转移推理知识，提高多模态大型语言模型（MLLMs）的推理能力。研究表明，传统的模型合并方法在不同模型家族中效果差异明显，有些模型受益而有些模型则存在性能下降。DRIFT方法能够在不破坏多模态对齐的情况下，便捷地将推理知识融入到多模态微调过程中。实验结果表明，DRIFT方法在推理性能上优于传统的模型合并及监督微调，并且以较低的成本实现了训练密集型方法的推理效果。

Conclusion: DRIFT方法有效提升了多模态大型语言模型的推理能力，相比于传统方法更为高效，并在多项基准测试中显示出显著的性能改善。

Abstract: Multimodal large language models (MLLMs) are rapidly advancing, yet their
reasoning ability often lags behind that of strong text-only counterparts.
Existing methods to bridge this gap rely on supervised fine-tuning over
large-scale multimodal reasoning data or reinforcement learning, both of which
are resource-intensive. A promising alternative is model merging, which
interpolates parameters between reasoning-enhanced LLMs and multimodal
variants. However, our analysis shows that naive merging is not always a "free
lunch": its effectiveness varies drastically across model families, with some
(e.g., LLaVA, Idefics) benefiting while others (e.g., Qwen) suffer performance
degradation. To address this, we propose Directional Reasoning Injection for
Fine-Tuning (DRIFT) MLLMs, a lightweight method that transfers reasoning
knowledge in the gradient space, without destabilizing multimodal alignment.
DRIFT precomputes a reasoning prior as the parameter-space difference between
reasoning and multimodal variants, then uses it to bias gradients during
multimodal fine-tuning. This approach preserves the simplicity of standard
supervised fine-tuning pipelines while enabling efficient reasoning transfer.
Extensive experiments on multimodal reasoning benchmarks, including MathVista
and MathVerse, demonstrate that DRIFT consistently improves reasoning
performance over naive merging and supervised fine-tuning, while matching or
surpassing training-heavy methods at a fraction of the cost.

</details>


### [12] [A solution to generalized learning from small training sets found in everyday infant experiences](https://arxiv.org/abs/2510.15060)
*Frangil Ramirez,Elizabeth Clerkin,David J. Crandall,Linda B. Smith*

Main category: cs.CV

TL;DR: 婴儿的日常视觉经验具有块状相似性结构，这可能有助于早期类别学习和推广。


<details>
  <summary>Details</summary>
Motivation: 探讨婴儿如何从有限的经验中实现对视觉对象的识别和归纳，特别是基本层面对象类别的形成过程。

Method: 分析14名婴儿（7至11个月大）日常视觉输入的自我中心图像，展示其视觉输入具有不均匀相似性结构。

Result: 通过计算实验模拟这种结构，发现使机器学习改善小数据集的推广能力。

Conclusion: 婴儿日常视觉经验的自然分块性可能支持早期类别学习和推广，并为多种问题和学习者提供高效学习的原则。

Abstract: Young children readily recognize and generalize visual objects labeled by
common nouns, suggesting that these basic level object categories may be given.
Yet if they are, how they arise remains unclear. We propose that the answer
lies in the statistics of infant daily life visual experiences. Whereas large
and diverse datasets typically support robust learning and generalization in
human and machine learning, infants achieve this generalization from limited
experiences. We suggest that the resolution of this apparent contradiction lies
in the visual diversity of daily life, repeated experiences with single object
instances. Analyzing egocentric images from 14 infants (aged 7 to 11 months) we
show that their everyday visual input exhibits a lumpy similarity structure,
with clusters of highly similar images interspersed with rarer, more variable
ones, across eight early-learned categories. Computational experiments show
that mimicking this structure in machines improves generalization from small
datasets in machine learning. The natural lumpiness of infant experience may
thus support early category learning and generalization and, more broadly,
offer principles for efficient learning across a variety of problems and kinds
of learners.

</details>


### [13] [SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images](https://arxiv.org/abs/2510.15072)
*Jiaxin Guo,Tongfan Guan,Wenzhen Dong,Wenzhao Zheng,Wenting Wang,Yue Wang,Yeung Yam,Yun-Hui Liu*

Main category: cs.CV

TL;DR: 提出了一种新的在线可推广 3DGS 方法 SaLon3R，能在高帧率下处理多个视图，显著减少冗余和提升几何一致性。


<details>
  <summary>Details</summary>
Motivation: 为了解决长时间视频序列中的冗余和几何不一致性问题。

Method: 本方法通过可微分的显著性感知高斯量化和 3D 点变换器相结合，去除冗余、高效解决几何和光度不一致。

Result: 在多个数据集的实验中，证明了 SaLon3R 在新视图合成和深度估计上的领先性能，展示了其在长期可推广的 3D 重建中的效率、鲁棒性和泛化能力。

Conclusion: SaLon3R 是一种新颖的框架，实现在超过 10 FPS 的速度下处理 50 个视图，显著减少冗余并提升几何精度。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have enabled generalizable,
on-the-fly reconstruction of sequential input views. However, existing methods
often predict per-pixel Gaussians and combine Gaussians from all views as the
scene representation, leading to substantial redundancies and geometric
inconsistencies in long-duration video sequences. To address this, we propose
SaLon3R, a novel framework for Structure-aware, Long-term 3DGS Reconstruction.
To our best knowledge, SaLon3R is the first online generalizable GS method
capable of reconstructing over 50 views in over 10 FPS, with 50% to 90%
redundancy removal. Our method introduces compact anchor primitives to
eliminate redundancy through differentiable saliency-aware Gaussian
quantization, coupled with a 3D Point Transformer that refines anchor
attributes and saliency to resolve cross-frame geometric and photometric
inconsistencies. Specifically, we first leverage a 3D reconstruction backbone
to predict dense per-pixel Gaussians and a saliency map encoding regional
geometric complexity. Redundant Gaussians are compressed into compact anchors
by prioritizing high-complexity regions. The 3D Point Transformer then learns
spatial structural priors in 3D space from training data to refine anchor
attributes and saliency, enabling regionally adaptive Gaussian decoding for
geometric fidelity. Without known camera parameters or test-time optimization,
our approach effectively resolves artifacts and prunes the redundant 3DGS in a
single feed-forward pass. Experiments on multiple datasets demonstrate our
state-of-the-art performance on both novel view synthesis and depth estimation,
demonstrating superior efficiency, robustness, and generalization ability for
long-term generalizable 3D reconstruction. Project Page:
https://wrld.github.io/SaLon3R/.

</details>


### [14] [TGT: Text-Grounded Trajectories for Locally Controlled Video Generation](https://arxiv.org/abs/2510.15104)
*Guofeng Zhang,Angtian Wang,Jacob Zhiyuan Fang,Liming Jiang,Haotian Yang,Bo Liu,Yiding Yang,Guang Chen,Longyin Wen,Alan Yuille,Chongyang Ma*

Main category: cs.CV

TL;DR: 提出一种新方法TGT，通过轨迹和文本描述提高文本生成视频的控制精度和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 提高文本生成视频时的主题组成控制能力，解决现有方法在复杂场景和多对象设置下的不足。

Method: 引入位置感知交叉注意力(LACA)来整合轨迹和文本信号，采用双CFG方案调节局部和全局文本指导，并开发数据处理管道生成带局部描述的轨迹。

Result: 提供了一个新框架TGT，通过轨迹和局部文本描述来指导视频生成，实现更高的视觉质量和运动可控性。

Conclusion: TGT在生成视频时展示了更好的文本对齐度和运动可控性，相较于之前的方法有显著提升。

Abstract: Text-to-video generation has advanced rapidly in visual fidelity, whereas
standard methods still have limited ability to control the subject composition
of generated scenes. Prior work shows that adding localized text control
signals, such as bounding boxes or segmentation masks, can help. However, these
methods struggle in complex scenarios and degrade in multi-object settings,
offering limited precision and lacking a clear correspondence between
individual trajectories and visual entities as the number of controllable
objects increases. We introduce Text-Grounded Trajectories (TGT), a framework
that conditions video generation on trajectories paired with localized text
descriptions. We propose Location-Aware Cross-Attention (LACA) to integrate
these signals and adopt a dual-CFG scheme to separately modulate local and
global text guidance. In addition, we develop a data processing pipeline that
produces trajectories with localized descriptions of tracked entities, and we
annotate two million high quality video clips to train TGT. Together, these
components enable TGT to use point trajectories as intuitive motion handles,
pairing each trajectory with text to control both appearance and motion.
Extensive experiments show that TGT achieves higher visual quality, more
accurate text alignment, and improved motion controllability compared with
prior approaches. Website: https://textgroundedtraj.github.io.

</details>


### [15] [Deep generative priors for 3D brain analysis](https://arxiv.org/abs/2510.15119)
*Ana Lawry Aguila,Dina Zemlyanker,You Cheng,Sudeshna Das,Daniel C. Alexander,Oula Puonti,Annabel Sorby-Adams,W. Taylor Kimberly,Juan Eugenio Iglesias*

Main category: cs.CV

TL;DR: 本研究首次将扩散模型应用于医学成像的逆问题，通过训练的扩散先验实现高质量解，并提高解剖准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在医学成像中显示出了强大的生成能力，但将数据驱动模型与领域知识结合以解决大脑成像问题仍然面临挑战。

Method: 提出了一种将基于得分的扩散先验与灵活的前向模型相结合的方法，通过对多种脑MRI数据进行广泛训练，以解决常见的图像处理任务。

Result: 通过在异构临床和研究MRI数据上进行实验，证明该方法在一致性和高质量解上达到最先进的性能，且无需配对训练数据。

Conclusion: 本研究证实了扩散模型作为医学成像逆问题的先验知识工具的潜力，能够在无需配对训练数据的情况下，实现高质量解的稳健性能。

Abstract: Diffusion models have recently emerged as powerful generative models in
medical imaging. However, it remains a major challenge to combine these
data-driven models with domain knowledge to guide brain imaging problems. In
neuroimaging, Bayesian inverse problems have long provided a successful
framework for inference tasks, where incorporating domain knowledge of the
imaging process enables robust performance without requiring extensive training
data. However, the anatomical modeling component of these approaches typically
relies on classical mathematical priors that often fail to capture the complex
structure of brain anatomy. In this work, we present the first general-purpose
application of diffusion models as priors for solving a wide range of medical
imaging inverse problems. Our approach leverages a score-based diffusion prior
trained extensively on diverse brain MRI data, paired with flexible forward
models that capture common image processing tasks such as super-resolution,
bias field correction, inpainting, and combinations thereof. We further
demonstrate how our framework can refine outputs from existing deep learning
methods to improve anatomical fidelity. Experiments on heterogeneous clinical
and research MRI data show that our method achieves state-of-the-art
performance producing consistent, high-quality solutions without requiring
paired training datasets. These results highlight the potential of diffusion
priors as versatile tools for brain MRI analysis.

</details>


### [16] [Fourier Transform Multiple Instance Learning for Whole Slide Image Classification](https://arxiv.org/abs/2510.15138)
*Anthony Bilic,Guangyu Sun,Ming Li,Md Sanzid Bin Hossain,Yu Tian,Wei Zhang,Laura Brattain,Dexter Hadley,Chen Chen*

Main category: cs.CV

TL;DR: 本文提出了FFT-MIL框架，通过频域学习提升了WSI分类的性能，增强了MIL的可扩展性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的MIL方法因WSI的巨大规模和补丁嵌入的局部特性，难以有效捕获全局依赖性，这影响了粗糙结构的建模，进而影响诊断预测的鲁棒性。

Method: 提出了一种名为FFT-MIL的框架，通过快速傅里叶变换从WSI中提取低频裁剪，结合卷积层和Min-Max归一化进行处理，再将学习的全局频率特征与空间补丁特征融合。

Result: 整合FFT-Block后，宏F1分数平均提高3.51%，AUC提高1.51%，在不同架构和数据集上均表现出一致的提升。

Conclusion: 引入频域学习能够有效捕获WSI分类中的全局依赖性，从而提升MIL框架的可扩展性和准确性。

Abstract: Whole Slide Image (WSI) classification relies on Multiple Instance Learning
(MIL) with spatial patch features, yet existing methods struggle to capture
global dependencies due to the immense size of WSIs and the local nature of
patch embeddings. This limitation hinders the modeling of coarse structures
essential for robust diagnostic prediction.
  We propose Fourier Transform Multiple Instance Learning (FFT-MIL), a
framework that augments MIL with a frequency-domain branch to provide compact
global context. Low-frequency crops are extracted from WSIs via the Fast
Fourier Transform and processed through a modular FFT-Block composed of
convolutional layers and Min-Max normalization to mitigate the high variance of
frequency data. The learned global frequency feature is fused with spatial
patch features through lightweight integration strategies, enabling
compatibility with diverse MIL architectures.
  FFT-MIL was evaluated across six state-of-the-art MIL methods on three public
datasets (BRACS, LUAD, and IMP). Integration of the FFT-Block improved macro F1
scores by an average of 3.51% and AUC by 1.51%, demonstrating consistent gains
across architectures and datasets. These results establish frequency-domain
learning as an effective and efficient mechanism for capturing global
dependencies in WSI classification, complementing spatial features and
advancing the scalability and accuracy of MIL-based computational pathology.

</details>


### [17] [XModBench: Benchmarking Cross-Modal Capabilities and Consistency in Omni-Language Models](https://arxiv.org/abs/2510.15148)
*Xingrui Wang,Jiang Liu,Chao Huang,Xiaodong Yu,Ze Wang,Ximeng Sun,Jialian Wu,Alan Yuille,Emad Barsoum,Zicheng Liu*

Main category: cs.CV

TL;DR: 研究提出XModBench评估全模态大型语言模型在跨模态推理中的表现，发现现有模型在模态不变推理上存在显著缺陷。


<details>
  <summary>Details</summary>
Motivation: 针对存在于现有基准中的局限性，探索全模态语言模型是否实现模态不变推理而无模态特定偏见。

Method: 通过设计XModBench这一大规模三模态基准，系统评估模型在不同模态下的一致性及推理能力。

Result: 尽管最强模型Gemini 2.5 Pro表现不佳，显示出在空间和时间推理、模态差异及方向性不平衡方面的不足。

Conclusion: 当前的全模态大型语言模型在模态不变推理方面仍有很大不足，XModBench是评估和改进跨模态能力的重要工具。

Abstract: Omni-modal large language models (OLLMs) aim to unify audio, vision, and text
understanding within a single framework. While existing benchmarks primarily
evaluate general cross-modal question-answering ability, it remains unclear
whether OLLMs achieve modality-invariant reasoning or exhibit modality-specific
biases. We introduce XModBench, a large-scale tri-modal benchmark explicitly
designed to measure cross-modal consistency. XModBench comprises 60,828
multiple-choice questions spanning five task families and systematically covers
all six modality compositions in question-answer pairs, enabling fine-grained
diagnosis of an OLLM's modality-invariant reasoning, modality disparity, and
directional imbalance. Experiments show that even the strongest model, Gemini
2.5 Pro, (i) struggles with spatial and temporal reasoning, achieving less than
60% accuracy, (ii) reveals persistent modality disparities, with performance
dropping substantially when the same semantic content is conveyed through audio
rather than text, and (iii) shows systematic directional imbalance, exhibiting
lower consistency when vision serves as context compared to text. These
findings indicate that current OLLMs remain far from truly modality-invariant
reasoning and position XModBench as a fundamental diagnostic tool for
evaluating and improving cross-modal competence. All data and evaluation tools
will be available at https://xingruiwang.github.io/projects/XModBench/.

</details>


### [18] [Train a Unified Multimodal Data Quality Classifier with Synthetic Data](https://arxiv.org/abs/2510.15162)
*Weizhi Wang,Rongmei Lin,Shiyang Li,Colin Lockard,Ritesh Sarkhel,Sanket Lokegaonkar,Jingbo Shang,Xifeng Yan,Nasser Zalmout,Xian Li*

Main category: cs.CV

TL;DR: 本研究提出UniFilter，用于过滤高质量的图像文字数据，显著提升多模态大语言模型的性能，并发布了相关数据和模型。


<details>
  <summary>Details</summary>
Motivation: 针对多模态大语言模型的高质量数据过滤尚未充分探索，提出了一种有效的数据质量分类器UniFilter。

Method: 引入半合成方法，利用原始图像生成对应文本以创建样本评分对，用于训练UniFilter。

Result: 使用UniFilter过滤的数据训练的MLLM在零-shot推理和上下文学习能力方面显著提升，并在多个基准测试中表现更强。

Conclusion: 通过UniFilter过滤的高质量多模态数据对提升MLLM的能力有显著影响，展示了高质量多模态预训练的下游效益。

Abstract: The Multimodal Large Language Models (MLLMs) are continually pre-trained on a
mixture of image-text caption data and interleaved document data, while the
high-quality data filtering towards image-text interleaved document data is
under-explored. We propose to train an efficient MLLM as a Unified Mulitmodal
Data Quality Classifier to Filter both high-quality image-text caption and
interleaved data (UniFilter). To address the challenge of collecting diverse
labeled multimodal data, we introduce a semi-synthetic approach that leverages
readily available raw images and generates corresponding text across four
quality levels. This method enables efficient creation of sample-score pairs
for both caption and interleaved document data to train UniFilter. We apply
UniFilter to curate high-quality caption data from DataComp caption dataset and
interleaved data from the OBELICS image-text interleaved dataset. MLLMs
pre-trained on the filtered data demonstrate significantly enhanced
capabilities compared to those trained on baseline-filtered data, achieving
stronger zero-shot reasoning and in-context learning capabilities. After visual
supervised fine-tuning, these UniFilter-induced MLLMs achieve stronger
performance on various benchmarks, highlighting the downstream benefits of
high-quality multimodal pre-training. We release the synthetic training data
used for training UniFilter, the UniFilter model checkpoints, and the
high-quality interleaved document subset OBELICS-HQ, curated by UniFilter, to
the community for reproduction and further development.

</details>


### [19] [Hyperparameter Optimization and Reproducibility in Deep Learning Model Training](https://arxiv.org/abs/2510.15164)
*Usman Afzaal,Ziyu Su,Usama Sajjad,Hao Lu,Mostafa Rezapour,Metin Nafi Gurcan,Muhammad Khalid Khan Niazi*

Main category: cs.CV

TL;DR: 研究表明，历史病理学基础模型的可重复性受超参数和实验配置的影响，提出了指导未来努力的实用规则。


<details>
  <summary>Details</summary>
Motivation: 探讨在历史病理学中基础模型训练的可重复性挑战，特别是软件随机性、硬件非确定性和超参数报告不一致的影响。

Method: 训练CLIP模型

Result: 通过系统评估不同超参数设置和增强策略，发现RandomResizedCrop 0.7-0.8的表现优于其他设置，分布式训练提高了稳定性，学习率低于5.0e-5会恶化性能，LC25000 (Colon) 数据集表现出最一致的可重复性。

Conclusion: 可重复性不仅依赖于透明的文档记录，还需要仔细选择实验配置，以支持数字病理学的基础模型开发。

Abstract: Reproducibility remains a critical challenge in foundation model training for
histopathology, often hindered by software randomness, hardware
non-determinism, and inconsistent hyperparameter reporting. To investigate
these issues, we trained a CLIP model on the QUILT-1M dataset and
systematically evaluated the impact of different hyperparameter settings and
augmentation strategies across three downstream histopathology datasets
(PatchCamelyon, LC25000-Lung, and LC25000-Colon). Despite variability across
runs, we identified clear trends: RandomResizedCrop values of 0.7-0.8
outperformed more aggressive (0.6) or conservative (0.9) settings, distributed
training without local loss improved stability, and learning rates below 5.0e-5
consistently degraded performance across all datasets. The LC25000 (Colon)
dataset consistently provided the most reproducible benchmark. These findings
highlight that reproducibility in computational pathology depends not only on
transparent documentation but also on carefully chosen experimental
configurations, and we provide practical rules to guide future efforts in
developing reproducible foundation models for digital pathology.

</details>


### [20] [Salient Concept-Aware Generative Data Augmentation](https://arxiv.org/abs/2510.15194)
*Tianchen Zhao,Xuanbai Chen,Zhihua Li,Jun Fang,Dongsheng An,Xiang Xu,Zhuowen Tu,Yifan Xing*

Main category: cs.CV

TL;DR: 提出了一种个性化图像生成框架，通过显著概念感知的图像嵌入模型减少合成过程中的无关视觉细节影响，从而提升图像与文本输入之间的直观对齐，增强训练数据集的多样性，并且在多个细粒度视觉数据集上优于现有数据增强方法。


<details>
  <summary>Details</summary>
Motivation: 为了改善现有生成数据增强方法在保持图像细节和多样性之间的平衡，减少无关视觉细节对合成过程的影响。

Method: 采用显著概念感知的图像嵌入模型，减少合成过程中的无关视觉细节影响，确保图像与文本的直观对齐。

Result: 在八个细粒度视觉数据集上展示了优越的性能，分类准确率在常规和长尾设置下分别提升了0.73%和6.5%。

Conclusion: 本研究提出的框架有效提升了训练数据集的多样性，并改善了下游模型的鲁棒性，表明该方法在细粒度视觉任务中有广泛的应用潜力。

Abstract: Recent generative data augmentation methods conditioned on both image and
text prompts struggle to balance between fidelity and diversity, as it is
challenging to preserve essential image details while aligning with varied text
prompts. This challenge arises because representations in the synthesis process
often become entangled with non-essential input image attributes such as
environmental contexts, creating conflicts with text prompts intended to modify
these elements. To address this, we propose a personalized image generation
framework that uses a salient concept-aware image embedding model to reduce the
influence of irrelevant visual details during the synthesis process, thereby
maintaining intuitive alignment between image and text inputs. By generating
images that better preserve class-discriminative features with additional
controlled variations, our framework effectively enhances the diversity of
training datasets and thereby improves the robustness of downstream models. Our
approach demonstrates superior performance across eight fine-grained vision
datasets, outperforming state-of-the-art augmentation methods with averaged
classification accuracy improvements by 0.73% and 6.5% under conventional and
long-tail settings, respectively.

</details>


### [21] [CARDIUM: Congenital Anomaly Recognition with Diagnostic Images and Unified Medical records](https://arxiv.org/abs/2510.15208)
*Daniela Vega,Hannah V. Ceballos,Javier S. Vera,Santiago Rodriguez,Alejandra Perez,Angela Castillo,Maria Escobar,Dario Londoño,Luis A. Sarmiento,Camila I. Castro,Nadiezhda Rodriguez,Juan C. Briceño,Pablo Arbeláez*

Main category: cs.CV

TL;DR: 提出CARDIUM数据集和多模态变压器架构，提升先天性心脏病检测性能，并公开数据集及代码以促进进一步研究。


<details>
  <summary>Details</summary>
Motivation: 克服由于先天性心脏病数据稀少导致的高质量诊断数据采集困难，同时整合影像和临床数据以提升人工智能在临床决策中的作用。

Method: 提出一个多模态变压器架构，结合交叉注意机制以融合图像和表格数据的特征表示，进行先天性心脏病检测。

Result: 通过CARDIUM数据集，提出了一种新的多模态变压器架构，使先天性心脏病检测性能分别提高了11%和50%。在CARDIUM数据集上取得F1分数为79.8 ± 4.8%。

Conclusion: 本研究为先天性心脏病的早期检测提供了重要的数据资源和技术支持，旨在推动这一领域的发展。

Abstract: Prenatal diagnosis of Congenital Heart Diseases (CHDs) holds great potential
for Artificial Intelligence (AI)-driven solutions. However, collecting
high-quality diagnostic data remains difficult due to the rarity of these
conditions, resulting in imbalanced and low-quality datasets that hinder model
performance. Moreover, no public efforts have been made to integrate multiple
sources of information, such as imaging and clinical data, further limiting the
ability of AI models to support and enhance clinical decision-making. To
overcome these challenges, we introduce the Congenital Anomaly Recognition with
Diagnostic Images and Unified Medical records (CARDIUM) dataset, the first
publicly available multimodal dataset consolidating fetal ultrasound and
echocardiographic images along with maternal clinical records for prenatal CHD
detection. Furthermore, we propose a robust multimodal transformer architecture
that incorporates a cross-attention mechanism to fuse feature representations
from image and tabular data, improving CHD detection by 11% and 50% over image
and tabular single-modality approaches, respectively, and achieving an F1 score
of 79.8 $\pm$ 4.8% in the CARDIUM dataset. We will publicly release our dataset
and code to encourage further research on this unexplored field. Our dataset
and code are available at https://github.com/BCVUniandes/Cardium, and at the
project website https://bcv-uniandes.github.io/CardiumPage/

</details>


### [22] [The Face of Persuasion: Analyzing Bias and Generating Culture-Aware Ads](https://arxiv.org/abs/2510.15240)
*Aysan Aghazadeh,Adriana Kovashka*

Main category: cs.CV

TL;DR: 本文研究了文本到图像模型在广告中的种族和性别偏见，以及针对特定国家的广告定位技巧。


<details>
  <summary>Details</summary>
Motivation: 探讨自定义视觉广告中的人口统计偏见和说服力，以优化广告效果并减少偏见。

Method: 通过分析不同广告主题中对种族和性别的表现方式，评估其说服力，并进行市场定位实验。

Result: 发现了广告在表现性别和种族方面的偏见，以及这种偏见对广告说服力的影响，并提出了新的广告定位技术。

Conclusion: 该研究揭示了在不同广告主题中，文本到图像模型存在的种族和性别偏见，并提供了针对具体国家进行广告定位的实验方法。

Abstract: Text-to-image models are appealing for customizing visual advertisements and
targeting specific populations. We investigate this potential by examining the
demographic bias within ads for different ad topics, and the disparate level of
persuasiveness (judged by models) of ads that are identical except for
gender/race of the people portrayed. We also experiment with a technique to
target ads for specific countries. The code is available at
https://github.com/aysanaghazadeh/FaceOfPersuasion

</details>


### [23] [DriveGen3D: Boosting Feed-Forward Driving Scene Generation with Efficient Video Diffusion](https://arxiv.org/abs/2510.15264)
*Weijie Wang,Jiagang Zhu,Zeyu Zhang,Xiaofeng Wang,Zheng Zhu,Guosheng Zhao,Chaojun Ni,Haoxiao Wang,Guan Huang,Xinze Chen,Yukun Zhou,Wenkang Qin,Duochao Shi,Haoyun Li,Guanghong Jia,Jiwen Lu*

Main category: cs.CV

TL;DR: DriveGen3D是一种新框架，用于生成高质量和可控的动态3D驾驶场景，克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前驾驶场景合成方法存在计算需求高、缺乏3D表示或仅限于静态重建的问题。

Method: DriveGen3D结合了高效的视频扩散变换器FastDrive-DiT和快速重建模块FastRecon3D，形成统一的生成管道。

Result: 通过DriveGen3D，能够以12 FPS实时生成分辨率为$424	imes800$的扩展驾驶视频和动态3D场景，SSIM达0.811，PSNR为22.84。

Conclusion: DriveGen3D通过FastDrive-DiT和FastRecon3D组件，实现了实时生成高分辨率、时序一致的驾驶视频和3D场景，性能优秀。

Abstract: We present DriveGen3D, a novel framework for generating high-quality and
highly controllable dynamic 3D driving scenes that addresses critical
limitations in existing methodologies. Current approaches to driving scene
synthesis either suffer from prohibitive computational demands for extended
temporal generation, focus exclusively on prolonged video synthesis without 3D
representation, or restrict themselves to static single-scene reconstruction.
Our work bridges this methodological gap by integrating accelerated long-term
video generation with large-scale dynamic scene reconstruction through
multimodal conditional control. DriveGen3D introduces a unified pipeline
consisting of two specialized components: FastDrive-DiT, an efficient video
diffusion transformer for high-resolution, temporally coherent video synthesis
under text and Bird's-Eye-View (BEV) layout guidance; and FastRecon3D, a
feed-forward reconstruction module that rapidly builds 3D Gaussian
representations across time, ensuring spatial-temporal consistency. Together,
these components enable real-time generation of extended driving videos (up to
$424\times800$ at 12 FPS) and corresponding dynamic 3D scenes, achieving SSIM
of 0.811 and PSNR of 22.84 on novel view synthesis, all while maintaining
parameter efficiency.

</details>


### [24] [CuSfM: CUDA-Accelerated Structure-from-Motion](https://arxiv.org/abs/2510.15271)
*Jingrui Yu,Jun Liu,Kefei Ren,Joydeep Biswas,Rurui Ye,Keqiang Wu,Chirag Majithia,Di Zeng*

Main category: cs.CV

TL;DR: cuSfM是一个CUDA加速的离线结构光束法系统，显著提高了相机姿态估计的准确性和速度。


<details>
  <summary>Details</summary>
Motivation: 解决自主导航、机器人感知和虚拟仿真系统中的相机姿态估计挑战。

Method: 基于CUDA加速的离线结构光束法，利用GPU并行化进行特征提取。

Result: cuSfM在多种测试场景中显著提升了准确性和处理速度，同时保持了高精度和全局一致性。

Conclusion: cuSfM展示了在准确性和处理速度方面相较于COLMAP的显著改善，适用于离线构建三维场景。

Abstract: Efficient and accurate camera pose estimation forms the foundational
requirement for dense reconstruction in autonomous navigation, robotic
perception, and virtual simulation systems. This paper addresses the challenge
via cuSfM, a CUDA-accelerated offline Structure-from-Motion system that
leverages GPU parallelization to efficiently employ computationally intensive
yet highly accurate feature extractors, generating comprehensive and
non-redundant data associations for precise camera pose estimation and globally
consistent mapping. The system supports pose optimization, mapping, prior-map
localization, and extrinsic refinement. It is designed for offline processing,
where computational resources can be fully utilized to maximize accuracy.
Experimental results demonstrate that cuSfM achieves significantly improved
accuracy and processing speed compared to the widely used COLMAP method across
various testing scenarios, while maintaining the high precision and global
consistency essential for offline SfM applications. The system is released as
an open-source Python wrapper implementation, PyCuSfM, available at
https://github.com/nvidia-isaac/pyCuSFM, to facilitate research and
applications in computer vision and robotics.

</details>


### [25] [Post-Processing Methods for Improving Accuracy in MRI Inpainting](https://arxiv.org/abs/2510.15282)
*Nishad Kulkarni,Krithika Iyer,Austin Tapp,Abhijeet Parida,Daniel Capellán-Martín,Zhifan Jiang,María J. Ledesma-Carbayo,Syed Muhammad Anwar,Marius George Linguraru*

Main category: cs.CV

TL;DR: 本研究提出了结合模型集成和后处理的新方法，以改善肿瘤区域MRI图像的修复效果，提升临床可用性。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化MRI分析工具在处理大病变（如肿瘤）时表现不佳，故此研究旨在提高图像修复的质量。

Method: 结合模型集成与后处理策略，如中值滤波、直方图匹配和像素平均，以及使用轻量级的U-Net增强步骤。

Result: 评估结果表明，改进后的管道在修复区域的准确性和稳健性方面超越了个别基线模型。

Conclusion: 通过结合模型集成和有效的后处理策略，我们的方法在肿瘤区域的图像修复中显著提高了解剖学的合理性和视觉保真度，支持更广泛的临床应用。

Abstract: Magnetic Resonance Imaging (MRI) is the primary imaging modality used in the
diagnosis, assessment, and treatment planning for brain pathologies. However,
most automated MRI analysis tools, such as segmentation and registration
pipelines, are optimized for healthy anatomies and often fail when confronted
with large lesions such as tumors. To overcome this, image inpainting
techniques aim to locally synthesize healthy brain tissues in tumor regions,
enabling the reliable application of general-purpose tools. In this work, we
systematically evaluate state-of-the-art inpainting models and observe a
saturation in their standalone performance. In response, we introduce a
methodology combining model ensembling with efficient post-processing
strategies such as median filtering, histogram matching, and pixel averaging.
Further anatomical refinement is achieved via a lightweight U-Net enhancement
stage. Comprehensive evaluation demonstrates that our proposed pipeline
improves the anatomical plausibility and visual fidelity of inpainted regions,
yielding higher accuracy and more robust outcomes than individual baseline
models. By combining established models with targeted post-processing, we
achieve improved and more accessible inpainting outcomes, supporting broader
clinical deployment and sustainable, resource-conscious research. Our 2025
BraTS inpainting docker is available at
https://hub.docker.com/layers/aparida12/brats2025/inpt.

</details>


### [26] [QCFace: Image Quality Control for boosting Face Representation & Recognition](https://arxiv.org/abs/2510.15289)
*Duc-Phuong Doan-Ngo,Thanh-Dang Diep,Thanh Nguyen-Duc,Thanh-Sach LE,Nam Thoai*

Main category: cs.CV

TL;DR: 提出了一种新的面部识别模型QCFace，通过硬边际策略解决了可识别性与身份表述之间的冲突，显著提升了人脸识别的性能。


<details>
  <summary>Details</summary>
Motivation: 有效利用可识别性增强特征表示在深度人脸识别系统中面临挑战，尤其是在低质量或模糊人脸的情况下，当前方法存在识别性捕获不全和优化过程中的不稳定性等问题。

Method: 提出了一种硬边际策略 - 质量控制人脸识别 (QCFace)，该策略能够解决特征方向与幅度之间的梯度重叠问题，并实现可识别性和身份表示的明确解耦。

Result: QCFace 提供稳健且可量化的可识别性编码，并在验证和识别基准测试中相较于现有方法实现了最先进的表现。

Conclusion: QCFace在识别能力和可识别性表示方面均有显著提升，为人脸识别领域提供了新的思路和方法。

Abstract: Recognizability, a key perceptual factor in human face processing, strongly
affects the performance of face recognition (FR) systems in both verification
and identification tasks. Effectively using recognizability to enhance feature
representation remains challenging. In deep FR, the loss function plays a
crucial role in shaping how features are embedded. However, current methods
have two main drawbacks: (i) recognizability is only partially captured through
soft margin constraints, resulting in weaker quality representation and lower
discrimination, especially for low-quality or ambiguous faces; (ii) mutual
overlapping gradients between feature direction and magnitude introduce
undesirable interactions during optimization, causing instability and confusion
in hypersphere planning, which may result in poor generalization, and entangled
representations where recognizability and identity are not cleanly separated.
To address these issues, we introduce a hard margin strategy - Quality Control
Face (QCFace), which overcomes the mutual overlapping gradient problem and
enables the clear decoupling of recognizability from identity representation.
Based on this strategy, a novel hard-margin-based loss function employs a
guidance factor for hypersphere planning, simultaneously optimizing for
recognition ability and explicit recognizability representation. Extensive
experiments confirm that QCFace not only provides robust and quantifiable
recognizability encoding but also achieves state-of-the-art performance in both
verification and identification benchmarks compared to existing
recognizability-based losses.

</details>


### [27] [Hyperbolic Structured Classification for Robust Single Positive Multi-label Learning](https://arxiv.org/abs/2510.15296)
*Yiming Lin,Shang Wang,Junkai Zhou,Qiufeng Wang,Xiao-Bo Jin,Kaizhu Huang*

Main category: cs.CV

TL;DR: 提出一种超球分类框架，提升单正多标签学习中的标签关系建模能力，实现了更好的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决单正多标签学习中的标签关系建模不足问题，克服现有方法的局限性。

Method: 构建超几何分类框架，将每个标签表示为超球，实现标签关系的几何建模。

Result: 在四个基准数据集上进行的实验表明，模型的性能优于现有方法，并且学习到的嵌入与真实世界的共现模式之间存在强相关性。

Conclusion: 提出的双井正则化方法和适应温度的超球分类器显著提高了模型的性能和可解释性。

Abstract: Single Positive Multi-Label Learning (SPMLL) addresses the challenging
scenario where each training sample is annotated with only one positive label
despite potentially belonging to multiple categories, making it difficult to
capture complex label relationships and hierarchical structures. While existing
methods implicitly model label relationships through distance-based similarity,
lacking explicit geometric definitions for different relationship types. To
address these limitations, we propose the first hyperbolic classification
framework for SPMLL that represents each label as a hyperbolic ball rather than
a point or vector, enabling rich inter-label relationship modeling through
geometric ball interactions. Our ball-based approach naturally captures
multiple relationship types simultaneously: inclusion for hierarchical
structures, overlap for co-occurrence patterns, and separation for semantic
independence. Further, we introduce two key component innovations: a
temperature-adaptive hyperbolic ball classifier and a physics-inspired
double-well regularization that guides balls toward meaningful configurations.
To validate our approach, extensive experiments on four benchmark datasets
(MS-COCO, PASCAL VOC, NUS-WIDE, CUB-200-2011) demonstrate competitive
performance with superior interpretability compared to existing methods.
Furthermore, statistical analysis reveals strong correlation between learned
embeddings and real-world co-occurrence patterns, establishing hyperbolic
geometry as a more robust paradigm for structured classification under
incomplete supervision.

</details>


### [28] [Latent Diffusion Model without Variational Autoencoder](https://arxiv.org/abs/2510.15301)
*Minglei Shi,Haolin Wang,Wenzhao Zheng,Ziyang Yuan,Xiaoshi Wu,Xintao Wang,Pengfei Wan,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: SVG是一种新型的潜在扩散模型，利用自监督表示法，克服了VAE在视觉生成中存在的问题，显著提升了模型的训练效率和生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有VAE+扩散模型在训练效率、推断速度和适应性方面的不足，特别是VAE潜在空间的限制。

Method: 提出了一种不依赖于变分自编码器的潜在扩散模型，通过自监督表示法进行视觉生成。

Result: SVG通过构建具有明显语义可区分性的特征空间和捕获细节的轻量残差分支，提高了扩散模型的训练效率和生成质量。

Conclusion: SVG模型提供了一种有前景的途径，使得视觉生成任务具备更高质量和通用性。

Abstract: Recent progress in diffusion-based visual generation has largely relied on
latent diffusion models with variational autoencoders (VAEs). While effective
for high-fidelity synthesis, this VAE+diffusion paradigm suffers from limited
training efficiency, slow inference, and poor transferability to broader vision
tasks. These issues stem from a key limitation of VAE latent spaces: the lack
of clear semantic separation and strong discriminative structure. Our analysis
confirms that these properties are crucial not only for perception and
understanding tasks, but also for the stable and efficient training of latent
diffusion models. Motivated by this insight, we introduce SVG, a novel latent
diffusion model without variational autoencoders, which leverages
self-supervised representations for visual generation. SVG constructs a feature
space with clear semantic discriminability by leveraging frozen DINO features,
while a lightweight residual branch captures fine-grained details for
high-fidelity reconstruction. Diffusion models are trained directly on this
semantically structured latent space to facilitate more efficient learning. As
a result, SVG enables accelerated diffusion training, supports few-step
sampling, and improves generative quality. Experimental results further show
that SVG preserves the semantic and discriminative capabilities of the
underlying self-supervised representations, providing a principled pathway
toward task-general, high-quality visual representations.

</details>


### [29] [Layer as Puzzle Pieces: Compressing Large Language Models through Layer Concatenation](https://arxiv.org/abs/2510.15304)
*Fei Wang,Li Shen,Liang Ding,Chao Xue,Ye Liu,Changxing Ding*

Main category: cs.CV

TL;DR: 本研究重新审视结构化剪枝的不足，提出CoMe方法，通过逐步剪枝、基于连接的层合并和层次蒸馏协议解决问题，提高了语言模型的性能和剪枝效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言处理任务中表现出色，但其巨大的体积导致了高计算和存储需求，因此需要通过结构化剪枝来减少模型规模。

Method: 本研究提出的CoMe框架结合了渐进式层剪枝、基于连接的合并技术和层次蒸馏后训练过程，使用通道敏感性指标进行细粒度通道选择。

Result: CoMe在剪枝30%的参数时，修剪后的模型保留了83%的原始平均准确率，实验表明其性能达到现有最优水平。

Conclusion: 通过引入新的剪枝策略和技术，CoMe有效提高了大语言模型的剪枝性能，保持了极高的准确性。

Abstract: Large Language Models excel at natural language processing tasks, but their
massive size leads to high computational and storage demands. Recent works have
sought to reduce their model size through layer-wise structured pruning.
However, they tend to ignore retaining the capabilities in the pruned part. In
this work, we re-examine structured pruning paradigms and uncover several key
limitations: 1) notable performance degradation due to direct layer removal, 2)
incompetent linear weight layer aggregation, and 3) the lack of effective
post-training recovery mechanisms. To address these limitations, we propose
CoMe, including a progressive layer pruning framework with a
Concatenation-based Merging technology and a hierarchical distillation
post-training process. Specifically, we introduce a channel sensitivity metric
that utilizes activation intensity and weight norms for fine-grained channel
selection. Subsequently, we employ a concatenation-based layer merging method
to fuse the most critical channels across adjacent layers, enabling progressive
model size reduction. Finally, we propose a hierarchical distillation protocol
that leverages the correspondences between the original and pruned model layers
established during pruning, thereby enabling efficient knowledge transfer.
Experiments on seven benchmarks show that CoMe achieves state-of-the-art
performance; when pruning 30% of LLaMA-2-7b's parameters, the pruned model
retains 83% of its original average accuracy. Our code is available at
https://github.com/MPI-Lab/CoMe.

</details>


### [30] [Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models](https://arxiv.org/abs/2502.08636)
*Xingrui Wang,Wufei Ma,Tiezheng Zhang,Celso M de Melo,Jieneng Chen,Alan Yuille*

Main category: cs.CV

TL;DR: 提出Spatial457数据集，评估LMMs在3D和6D空间推理中的能力，发现随着任务复杂度增加，性能下降，并揭示不同属性间存在预测偏差。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要集中在2D空间理解，而缺乏对复杂6D空间推理能力的全面评估，以填补这一研究空白。

Method: 通过构建一个包含6D空间推理任务的合成数据集，设计逐级评估结构、问题类型及难度水平，评估多种LMMs的表现。

Result: 本研究提出了Spatial457，一个可扩展且无偏见的合成数据集，旨在评估大规模多模态模型（LMMs）在3D空间推理和6D空间推理方面的能力。我们开发了一个逐级评估结构，包括7种问题类型和5个难度等级，以涵盖从简单的单对象识别到复杂的6D空间推理任务。对多种LMMs的评估结果显示，随着任务复杂性的增加，尤其是在3D和6D空间任务中，它们的性能普遍下降。此外，引入相对性能下降率（RPDR）以量化这些挑战，并发现了不同属性间的预测偏差，类似模式也出现在真实图像环境中。

Conclusion: LMM在复杂空间推理上的表现仍有限，尤其在3D和6D任务中，相关性能下降率（RPDR）和预测偏差揭示了其关键薄弱环节。

Abstract: Although large multimodal models (LMMs) have demonstrated remarkable
capabilities in visual scene interpretation and reasoning, their capacity for
complex and precise 3-dimensional spatial reasoning remains uncertain. Existing
benchmarks focus predominantly on 2D spatial understanding and lack a framework
to comprehensively evaluate 6D spatial reasoning across varying complexities.
To address this limitation, we present Spatial457, a scalable and unbiased
synthetic dataset designed with 4 key capability for spatial reasoning:
multi-object recognition, 2D location, 3D location, and 3D orientation. We
develop a cascading evaluation structure, constructing 7 question types across
5 difficulty levels that range from basic single object recognition to our new
proposed complex 6D spatial reasoning tasks. We evaluated various large
multimodal models (LMMs) on PulseCheck457, observing a general decline in
performance as task complexity increases, particularly in 3D reasoning and 6D
spatial tasks. To quantify these challenges, we introduce the Relative
Performance Dropping Rate (RPDR), highlighting key weaknesses in 3D reasoning
capabilities. Leveraging the unbiased attribute design of our dataset, we also
uncover prediction biases across different attributes, with similar patterns
observed in real-world image settings. The code and data are released in
https://github.com/XingruiWang/Spatial457.

</details>


### [31] [Proto-Former: Unified Facial Landmark Detection by Prototype Transformer](https://arxiv.org/abs/2510.15338)
*Shengkai Hu,Haozhe Qi,Jun Wan,Jiaxing Huang,Lefei Zhang,Hang Sun,Dacheng Tao*

Main category: cs.CV

TL;DR: Proto-Former是一个统一自适应的面部关键点检测框架，通过联合训练多个数据集及新颖的PA损失函数，显著提升面部特征提取的准确性和模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的面部关键点检测数据集定义了不同数量的标志点，而且大多数主流方法只能在单一数据集上训练，这限制了模型的泛化能力。

Method: Proto-Former框架包括自适应原型感知编码器(APAE)和渐进原型感知解码器(PPAD)，通过联合训练多数据集来增强面部结构表现。

Result: Proto-Former通过自适应特征提取和学习原型表现，克服了单一数据集训练的局限性，能够在统一架构下进行多数据集联合训练。

Conclusion: Proto-Former在多数据集训练中表现优越，成功解决了现有面部关键点检测方法的局限性，并且在标准基准数据集上超越了现有最先进的方法。

Abstract: Recent advances in deep learning have significantly improved facial landmark
detection. However, existing facial landmark detection datasets often define
different numbers of landmarks, and most mainstream methods can only be trained
on a single dataset. This limits the model generalization to different datasets
and hinders the development of a unified model. To address this issue, we
propose Proto-Former, a unified, adaptive, end-to-end facial landmark detection
framework that explicitly enhances dataset-specific facial structural
representations (i.e., prototype). Proto-Former overcomes the limitations of
single-dataset training by enabling joint training across multiple datasets
within a unified architecture. Specifically, Proto-Former comprises two key
components: an Adaptive Prototype-Aware Encoder (APAE) that performs adaptive
feature extraction and learns prototype representations, and a Progressive
Prototype-Aware Decoder (PPAD) that refines these prototypes to generate
prompts that guide the model's attention to key facial regions. Furthermore, we
introduce a novel Prototype-Aware (PA) loss, which achieves optimal path
finding by constraining the selection weights of prototype experts. This loss
function effectively resolves the problem of prototype expert addressing
instability during multi-dataset training, alleviates gradient conflicts, and
enables the extraction of more accurate facial structure features. Extensive
experiments on widely used benchmark datasets demonstrate that our Proto-Former
achieves superior performance compared to existing state-of-the-art methods.
The code is publicly available at: https://github.com/Husk021118/Proto-Former.

</details>


### [32] [FreqPDE: Rethinking Positional Depth Embedding for Multi-View 3D Object Detection Transformers](https://arxiv.org/abs/2510.15385)
*Haisheng Su,Junjie Zhang,Feixiang Song,Sanping Zhou,Wei Wu,Nanning Zheng,Junchi Yan*

Main category: cs.CV

TL;DR: 提出FreqPDE方法，通过三个模块提升从2D图像中检测3D物体的精度，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在深度预测中存在的质量问题，以及提升3D物体检测的准确性和鲁棒性。

Method: 介绍了通过三个模块结合高频和低频信息、交叉视图深度预测及2D特征与3D位置嵌入结合的方法。

Result: 本文提出了一种新方法，通过引入频率感知位置深度嵌入（FreqPDE），提升了从多视图2D图像准确检测3D物体的能力。当前方法依赖于深度预测以恢复空间信息，但存在深度质量不佳的问题。为此，本文设计了三个关键模块：频率感知空间金字塔编码器（FSPE）构建特征金字塔，交叉视图尺度不变深度预测器（CSDP）进行像素级深度分布估计，以及位置深度编码器（PDE）生成3D深度特征。此外，采用混合深度监督，以增强深度学习的效果。实验结果显示，该方法在nuScenes数据集上表现优越。

Conclusion: 实验结果表明，本文提出的方法在多视图2D图像中检测3D物体的精度优于已有方法，具有较好的实用价值。

Abstract: Detecting 3D objects accurately from multi-view 2D images is a challenging
yet essential task in the field of autonomous driving. Current methods resort
to integrating depth prediction to recover the spatial information for object
query decoding, which necessitates explicit supervision from LiDAR points
during the training phase. However, the predicted depth quality is still
unsatisfactory such as depth discontinuity of object boundaries and
indistinction of small objects, which are mainly caused by the sparse
supervision of projected points and the use of high-level image features for
depth prediction. Besides, cross-view consistency and scale invariance are also
overlooked in previous methods. In this paper, we introduce Frequency-aware
Positional Depth Embedding (FreqPDE) to equip 2D image features with spatial
information for 3D detection transformer decoder, which can be obtained through
three main modules. Specifically, the Frequency-aware Spatial Pyramid Encoder
(FSPE) constructs a feature pyramid by combining high-frequency edge clues and
low-frequency semantics from different levels respectively. Then the Cross-view
Scale-invariant Depth Predictor (CSDP) estimates the pixel-level depth
distribution with cross-view and efficient channel attention mechanism.
Finally, the Positional Depth Encoder (PDE) combines the 2D image features and
3D position embeddings to generate the 3D depth-aware features for query
decoding. Additionally, hybrid depth supervision is adopted for complementary
depth learning from both metric and distribution aspects. Extensive experiments
conducted on the nuScenes dataset demonstrate the effectiveness and superiority
of our proposed method.

</details>


### [33] [PFGS: Pose-Fused 3D Gaussian Splatting for Complete Multi-Pose Object Reconstruction](https://arxiv.org/abs/2510.15386)
*Ting-Yu Yen,Yu-Sheng Chiu,Shih-Hsuan Hung,Peter Wonka,Hung-Kuo Chu*

Main category: cs.CV

TL;DR: PFGS是一个姿态感知的3D高斯点云重建框架，能够从多姿态图像中高效重建完整物体，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯点云重建方法大多假设物体以单一静态姿态捕捉，不能很好重建 occluded 区域，因此需要改进方法以处理多姿态下的图像数据。

Method: 采用姿态感知的融合策略，通过迭代合并辅助视图，结合全局和局部配准来有效地合成三维高斯点云模型。

Result: PFGS通过利用背景特征进行每个姿态的相机姿态估计，并利用基础模型进行跨姿态注册，成功克服了高内存占用和亚最佳精度的问题。

Conclusion: PFGS框架在多姿态图像捕捉中成功实现了完整物体的重建，且在定性和定量评估中优于其他强基线方法。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have enabled high-quality,
real-time novel-view synthesis from multi-view images. However, most existing
methods assume the object is captured in a single, static pose, resulting in
incomplete reconstructions that miss occluded or self-occluded regions. We
introduce PFGS, a pose-aware 3DGS framework that addresses the practical
challenge of reconstructing complete objects from multi-pose image captures.
Given images of an object in one main pose and several auxiliary poses, PFGS
iteratively fuses each auxiliary set into a unified 3DGS representation of the
main pose. Our pose-aware fusion strategy combines global and local
registration to merge views effectively and refine the 3DGS model. While recent
advances in 3D foundation models have improved registration robustness and
efficiency, they remain limited by high memory demands and suboptimal accuracy.
PFGS overcomes these challenges by incorporating them more intelligently into
the registration process: it leverages background features for per-pose camera
pose estimation and employs foundation models for cross-pose registration. This
design captures the best of both approaches while resolving background
inconsistency issues. Experimental results demonstrate that PFGS consistently
outperforms strong baselines in both qualitative and quantitative evaluations,
producing more complete reconstructions and higher-fidelity 3DGS models.

</details>


### [34] [LILAC: Long-sequence Incremental Low-latency Arbitrary Motion Stylization via Streaming VAE-Diffusion with Causal Decoding](https://arxiv.org/abs/2510.15392)
*Peng Ren,Hai Yang*

Main category: cs.CV

TL;DR: LILAC框架实现了长序列的低延迟任意动作风格化，提升了实时响应性和风格化质量。


<details>
  <summary>Details</summary>
Motivation: 针对实时人类动作生成的需求，LILAC旨在提高现有风格化方法的实时性和经济性，特别是在动态和连续的控制应用中。

Method: LILAC基于潜在空间流式架构，结合滑动窗口因果设计，通过解码后的动作特征确保平滑的动作过渡。

Result: 本研究提出了一种名为LILAC的框架，旨在通过潜在空间流式架构实现长序列的实时任意动作风格化。LILAC克服了现有方法在处理实时人类动作时的计算开销和时间稳定性问题，使得风格化质量与响应性之间达到了良好的平衡。

Conclusion: LILAC框架有效解决了传统方法在实时人类动作风格化中面临的挑战，证明了在不依赖未来帧的情况下依然可以实现高质量的长序列风格化。

Abstract: Generating long and stylized human motions in real time is critical for
applications that demand continuous and responsive character control. Despite
its importance, existing streaming approaches often operate directly in the raw
motion space, leading to substantial computational overhead and making it
difficult to maintain temporal stability. In contrast, latent-space
VAE-Diffusion-based frameworks alleviate these issues and achieve high-quality
stylization, but they are generally confined to offline processing. To bridge
this gap, LILAC (Long-sequence Incremental Low-latency Arbitrary Motion
Stylization via Streaming VAE-Diffusion with Causal Decoding) builds upon a
recent high-performing offline framework for arbitrary motion stylization and
extends it to an online setting through a latent-space streaming architecture
with a sliding-window causal design and the injection of decoded motion
features to ensure smooth motion transitions. This architecture enables
long-sequence real-time arbitrary stylization without relying on future frames
or modifying the diffusion model architecture, achieving a favorable balance
between stylization quality and responsiveness as demonstrated by experiments
on benchmark datasets. Supplementary video and examples are available at the
project page: https://pren1.github.io/lilac/

</details>


### [35] [MARIS: Marine Open-Vocabulary Instance Segmentation with Geometric Enhancement and Semantic Alignment](https://arxiv.org/abs/2510.15398)
*Bingyu Li,Feiyu Wang,Da Zhang,Zhiyuan Zhao,Junyu Gao,Xuelong Li*

Main category: cs.CV

TL;DR: 本文提出MARIS基准，并构建了一个框架以改善水下开放词汇实例分割的识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有的水下实例分割方法受到限于闭合词汇预测的限制，无法识别新的海洋类别。同时，水下场景传递的视觉效果较差，导致语义不对齐。

Method: 提出了一种统一框架，结合几何先验增强模块（GPEM）和语义对齐注入机制（SAIM）来改善水下开放词汇实例分割。

Result: 我们的框架在MARIS基准上，在同域和跨域设置下，始终优于现有的开放词汇基线。

Conclusion: 该研究为未来水下感知研究奠定了坚实基础。

Abstract: Most existing underwater instance segmentation approaches are constrained by
close-vocabulary prediction, limiting their ability to recognize novel marine
categories. To support evaluation, we introduce \textbf{MARIS}
(\underline{Mar}ine Open-Vocabulary \underline{I}nstance
\underline{S}egmentation), the first large-scale fine-grained benchmark for
underwater Open-Vocabulary (OV) segmentation, featuring a limited set of seen
categories and diverse unseen categories. Although OV segmentation has shown
promise on natural images, our analysis reveals that transfer to underwater
scenes suffers from severe visual degradation (e.g., color attenuation) and
semantic misalignment caused by lack underwater class definitions. To address
these issues, we propose a unified framework with two complementary components.
The Geometric Prior Enhancement Module (\textbf{GPEM}) leverages stable
part-level and structural cues to maintain object consistency under degraded
visual conditions. The Semantic Alignment Injection Mechanism (\textbf{SAIM})
enriches language embeddings with domain-specific priors, mitigating semantic
ambiguity and improving recognition of unseen categories. Experiments show that
our framework consistently outperforms existing OV baselines both In-Domain and
Cross-Domain setting on MARIS, establishing a strong foundation for future
underwater perception research.

</details>


### [36] [Robust High-Resolution Multi-Organ Diffusion MRI Using Synthetic-Data-Tuned Prompt Learning](https://arxiv.org/abs/2510.15400)
*Chen Qian,Haoyu Zhang,Junnan Ma,Liuhong Zhu,Qingrui Cai,Yu Wang,Ruibo Song,Lv Li,Lin Mei,Xianwang Jiang,Qin Xu,Boyu Jiang,Ran Tao,Chunmiao Chen,Shufang Chen,Dongyun Liang,Qiu Guo,Jianzhong Lin,Taishan Kang,Mengtian Lu,Liyuan Fu,Ruibin Huang,Huijuan Wan,Xu Huang,Jianhua Wang,Di Guo,Hai Zhong,Jianjun Zhou,Xiaobo Qu*

Main category: cs.CV

TL;DR: LoSP-Prompt是一种新方法，通过物理建模和数据学习，提高了多拍DWI在肿瘤诊断中的图像质量和分辨率。


<details>
  <summary>Details</summary>
Motivation: 提高多拍DWI在全身肿瘤诊断中的临床应用性，尤其是在应对运动诱导伪影方面。

Method: 将相位变化模型化为高阶局部平滑相位（LoSP），并整合至低秩汉克尔矩阵重建中。

Result: 本研究提出了一种名为LoSP-Prompt的重建框架，旨在解决多拍扩散加权磁共振成像（DWI）在全身肿瘤诊断中的临床应用限制。该方法通过物理信息建模和合成数据驱动的提示学习，克服了由于呼吸、肠蠕动等造成的运动诱导相位伪影问题。LoSP-Prompt能够实现较高的空间分辨率，并在不同解剖区域中具有良好的推广能力，且在图像质量、伪影抑制和噪声减少等方面超越了现有最先进的方法。

Conclusion: LoSP-Prompt为精确癌症治疗提供了一种可解释且鲁棒的高分辨率多器官多拍DWI解决方案，其在扫描仪无关的性能展现了变革潜力。

Abstract: Clinical adoption of multi-shot diffusion-weighted magnetic resonance imaging
(multi-shot DWI) for body-wide tumor diagnostics is limited by severe
motion-induced phase artifacts from respiration, peristalsis, and so on,
compounded by multi-organ, multi-slice, multi-direction and multi-b-value
complexities. Here, we introduce a reconstruction framework, LoSP-Prompt, that
overcomes these challenges through physics-informed modeling and
synthetic-data-driven prompt learning. We model inter-shot phase variations as
a high-order Locally Smooth Phase (LoSP), integrated into a low-rank Hankel
matrix reconstruction. Crucially, the algorithm's rank parameter is
automatically set via prompt learning trained exclusively on synthetic
abdominal DWI data emulating physiological motion. Validated across 10,000+
clinical images (43 subjects, 4 scanner models, 5 centers), LoSP-Prompt: (1)
Achieved twice the spatial resolution of clinical single-shot DWI, enhancing
liver lesion conspicuity; (2) Generalized to seven diverse anatomical regions
(liver, kidney, sacroiliac, pelvis, knee, spinal cord, brain) with a single
model; (3) Outperformed state-of-the-art methods in image quality, artifact
suppression, and noise reduction (11 radiologists' evaluations on a 5-point
scale, $p<0.05$), achieving 4-5 points (excellent) on kidney DWI, 4 points
(good to excellent) on liver, sacroiliac and spinal cord DWI, and 3-4 points
(good) on knee and tumor brain. The approach eliminates navigator signals and
realistic data supervision, providing an interpretable, robust solution for
high-resolution multi-organ multi-shot DWI. Its scanner-agnostic performance
signifies transformative potential for precision oncology.

</details>


### [37] [Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models](https://arxiv.org/abs/2510.15430)
*Shuang Liang,Zhihao Xu,Jialing Tao,Hui Xue,Xiting Wang*

Main category: cs.CV

TL;DR: 提出LoD框架，提升未见攻击的检测能力和效率


<details>
  <summary>Details</summary>
Motivation: 目前的检测方法在面对未知攻击时准确性和效率不足

Method: 提出Learning to Detect (LoD)框架，以任务为中心进行学习

Result: 在多种未知攻击上，LoD框架显著提高了检测的AUROC，并提升了效率

Conclusion: LoD框架有效应对未知攻击，提升了安全性检测的准确性和效率

Abstract: Despite extensive alignment efforts, Large Vision-Language Models (LVLMs)
remain vulnerable to jailbreak attacks, posing serious safety risks. To address
this, existing detection methods either learn attack-specific parameters, which
hinders generalization to unseen attacks, or rely on heuristically sound
principles, which limit accuracy and efficiency. To overcome these limitations,
we propose Learning to Detect (LoD), a general framework that accurately
detects unknown jailbreak attacks by shifting the focus from attack-specific
learning to task-specific learning. This framework includes a Multi-modal
Safety Concept Activation Vector module for safety-oriented representation
learning and a Safety Pattern Auto-Encoder module for unsupervised attack
classification. Extensive experiments show that our method achieves
consistently higher detection AUROC on diverse unknown attacks while improving
efficiency. The code is available at
https://anonymous.4open.science/r/Learning-to-Detect-51CB.

</details>


### [38] [Semantic4Safety: Causal Insights from Zero-shot Street View Imagery Segmentation for Urban Road Safety](https://arxiv.org/abs/2510.15434)
*Huan Chen,Ting Han,Siyu Chen,Zhihao Guo,Yiping Chen,Meiliu Wu*

Main category: cs.CV

TL;DR: Semantic4Safety框架通过分析街景图像和交通事故数据，识别影响道路安全的因素，为城市道路安全规划提供数据支持。


<details>
  <summary>Details</summary>
Motivation: 为了解决如何构建街道级指标以捕捉与事故相关特征以及如何量化这些特征在不同事故类型中的因果影响的问题。

Method: 使用零样本语义分割技术从街景图像中提取可解释的街道特征，结合XGBoost多分类器、SHAP解释特征贡献，并运用广义倾向评分加权和平均处理效应估计来控制混杂因素和量化因果效应。

Result: 发现异质性的、基于事故类型的特定因果模式；场景复杂性、暴露度及道路几何形状是主要的预测因素；更大的可驾驶区域和应急空间降低风险，而过度的视觉开放性则可能增加风险。

Conclusion: Semantic4Safety提供了一种支持城市道路安全规划的可扩展、数据驱动工具，通过预测建模与因果推断的结合，帮助识别高风险区域并制定针对性干预措施。

Abstract: Street-view imagery (SVI) offers a fine-grained lens on traffic risk, yet two
fundamental challenges persist: (1) how to construct street-level indicators
that capture accident-related features, and (2) how to quantify their causal
impacts across different accident types. To address these challenges, we
propose Semantic4Safety, a framework that applies zero-shot semantic
segmentation to SVIs to derive 11 interpretable streetscape indicators, and
integrates road type as contextual information to analyze approximately 30,000
accident records in Austin. Specifically, we train an eXtreme Gradient Boosting
(XGBoost) multi-class classifier and use Shapley Additive Explanations (SHAP)
to interpret both global and local feature contributions, and then apply
Generalized Propensity Score (GPS) weighting and Average Treatment Effect (ATE)
estimation to control confounding and quantify causal effects. Results uncover
heterogeneous, accident-type-specific causal patterns: features capturing scene
complexity, exposure, and roadway geometry dominate predictive power; larger
drivable area and emergency space reduce risk, whereas excessive visual
openness can increase it. By bridging predictive modeling with causal
inference, Semantic4Safety supports targeted interventions and high-risk
corridor diagnosis, offering a scalable, data-informed tool for urban road
safety planning.

</details>


### [39] [Select Less, Reason More: Prioritizing Evidence Purity for Video Reasoning](https://arxiv.org/abs/2510.15440)
*Xuchen Li,Xuzhao Li,Shiyu Hu,Kaiqi Huang*

Main category: cs.CV

TL;DR: 本文提出了一种新型的证据优先自适应框架，通过证据感知强化学习改善视频长段推理效果，实验表明该框架在多项基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频推理模型在证据选择和时序信息补充上的不足之处，以提高长视频推理的准确性和有效性。

Method: 提出一种证据感知强化学习（EARL）框架，动态选择相关帧并围绕关键帧进行局部再采样。

Result: 本研究主要探讨视频大型语言模型（Video LLMs）在长视频推理中的挑战，提出了一种新的以证据为优先的自适应框架。该框架通过证据感知强化学习（EARL）来提高视频推理的有效性和准确性。实验结果表明，该模型在多个视频推理基准测试中实现了最新的行业标准，展示了证据纯度的优先性。

Conclusion: EARL框架有效地提升了视频推理模型在证据提取和时序信息补充方面的能力，取得了显著的性能提升。

Abstract: Long-form video reasoning remains a major challenge for Video Large Language
Models (Video LLMs), as static uniform frame sampling leads to information
dilution and obscures critical evidence. Furthermore, existing pixel-space
video reasoning agents, which are designed to actively interact with the video
to acquire new visual information, remain suboptimal due to their lack of
rigorous reward mechanisms to enforce evidence purity and their inability to
perform temporal information supplementation beyond pre-sampled frames. To
address this critical gap, we propose a novel evidence-prioritized adaptive
framework built upon our core philosophy: "Select Less, Reason More." Our core
contribution is the evidence-aware reinforcement learning (EARL) framework,
which transforms the model into an active interrogator of evidence. EARL is
precisely engineered to dynamically select the most relevant frames and,
crucially, to perform localized re-sampling around the selected key frames to
access fine-grained temporal detail. Extensive experiments on five demanding
video reasoning benchmarks demonstrate that our EARL-trained model achieves new
state-of-the-art among open-source Video LLMs, simultaneously learning an
effective and high-purity visual evidence selection policy. Impressively, our
7B model achieves 59.8% on LongVideoBench, 69.0% on MVBench and 64.9% on
VideoMME. These results highlight the importance of prioritizing evidence
purity and the effectiveness of our framework.

</details>


### [40] [MAVR-Net: Robust Multi-View Learning for MAV Action Recognition with Cross-View Attention](https://arxiv.org/abs/2510.15448)
*Nengbo Zhang,Hann Woei Ho*

Main category: cs.CV

TL;DR: MAVR-Net框架通过结合多种数据来改善MAV动作识别的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决传统基于RGB数据的视觉识别模型在捕捉MAV运动复杂时空特征时的局限性。

Method: 提出MAVR-Net，一个基于多视角学习的MAV动作识别框架，结合RGB帧、光流和分割掩膜等三种数据，采用ResNet编码器提取特征，使用多尺度特征金字塔保持时空细节。

Result: 在基准MAV动作数据集上，达到97.8%、96.5%和92.8%的准确度，明显优于现有方法。

Conclusion: 实验结果表明，MAVR-Net在多视角动作识别中具有显著优势，能够有效提升MAV的合作感知与控制能力。

Abstract: Recognizing the motion of Micro Aerial Vehicles (MAVs) is crucial for
enabling cooperative perception and control in autonomous aerial swarms. Yet,
vision-based recognition models relying only on RGB data often fail to capture
the complex spatial temporal characteristics of MAV motion, which limits their
ability to distinguish different actions. To overcome this problem, this paper
presents MAVR-Net, a multi-view learning-based MAV action recognition
framework. Unlike traditional single-view methods, the proposed approach
combines three complementary types of data, including raw RGB frames, optical
flow, and segmentation masks, to improve the robustness and accuracy of MAV
motion recognition. Specifically, ResNet-based encoders are used to extract
discriminative features from each view, and a multi-scale feature pyramid is
adopted to preserve the spatiotemporal details of MAV motion patterns. To
enhance the interaction between different views, a cross-view attention module
is introduced to model the dependencies among various modalities and feature
scales. In addition, a multi-view alignment loss is designed to ensure semantic
consistency and strengthen cross-view feature representations. Experimental
results on benchmark MAV action datasets show that our method clearly
outperforms existing approaches, achieving 97.8\%, 96.5\%, and 92.8\% accuracy
on the Short MAV, Medium MAV, and Long MAV datasets, respectively.

</details>


### [41] [DPTrack:Directional Kernel-Guided Prompt Learning for Robust Nighttime Aerial Tracking](https://arxiv.org/abs/2510.15449)
*Zhiqiang Zhu,Xinbo Gao,Wen Lu,Jie Li,Zhaoyang Wang,Mingqian Ge*

Main category: cs.CV

TL;DR: DPTrack是一种新的夜间航空跟踪器，通过细化目标特征和结构表示，显著提升了跟踪的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的夜间航空跟踪器仅依赖空间定位监督，缺乏对目标特征的细致提示，导致跟踪性能不佳。

Method: DPTrack采用层次化捕捉目标拓扑结构的方式，使用方向性内核和通道类别对应属性，实现对目标特征的精确跟踪。

Result: DPTrack通过编码目标属性特征到方向性内核中，生成精确提示，从而在夜间场景中实现更好的跟踪性能。

Conclusion: DPTrack在多个基准测试中的评估结果显示了其卓越的性能，证明了其在夜间跟踪中的有效性。

Abstract: Existing nighttime aerial trackers based on prompt learning rely solely on
spatial localization supervision, which fails to provide fine-grained cues that
point to target features and inevitably produces vague prompts. This limitation
impairs the tracker's ability to accurately focus on the object features and
results in trackers still performing poorly. To address this issue, we propose
DPTrack, a prompt-based aerial tracker designed for nighttime scenarios by
encoding the given object's attribute features into the directional kernel
enriched with fine-grained cues to generate precise prompts. Specifically,
drawing inspiration from visual bionics, DPTrack first hierarchically captures
the object's topological structure, leveraging topological attributes to enrich
the feature representation. Subsequently, an encoder condenses these
topology-aware features into the directional kernel, which serves as the core
guidance signal that explicitly encapsulates the object's fine-grained
attribute cues. Finally, a kernel-guided prompt module built on
channel-category correspondence attributes propagates the kernel across the
features of the search region to pinpoint the positions of target features and
convert them into precise prompts, integrating spatial gating for robust
nighttime tracking. Extensive evaluations on established benchmarks demonstrate
DPTrack's superior performance. Our code will be available at
https://github.com/zzq-vipsl/DPTrack.

</details>


### [42] [MRASfM: Multi-Camera Reconstruction and Aggregation through Structure-from-Motion in Driving Scenes](https://arxiv.org/abs/2510.15467)
*Lingfeng Xuan,Chang Nie,Yiqing Xu,Zhe Liu,Yanzi Miao,Hesheng Wang*

Main category: cs.CV

TL;DR: MRASfM框架通过改进相机位姿估计和道路表面重建，展示了在驾驶场景中的高效性和优越性。


<details>
  <summary>Details</summary>
Motivation: 针对传统SfM在多相机驾驶场景中的 pose 估计不可靠、重建误差大和效率低下等问题，进行改进。

Method: 提出了一种基于多相机系统的MRASfM框架，采用固定空间关系与平面模型，以提升重建质量与效率。

Result: MRASfM在nuScenes数据集上实现了0.124的绝对位姿误差，显示出前沿的性能。

Conclusion: MRASfM框架在实际驾驶场景中能够有效优化相机位姿估计和道路表面重建，表现出优越的性能和稳健性。

Abstract: Structure from Motion (SfM) estimates camera poses and reconstructs point
clouds, forming a foundation for various tasks. However, applying SfM to
driving scenes captured by multi-camera systems presents significant
difficulties, including unreliable pose estimation, excessive outliers in road
surface reconstruction, and low reconstruction efficiency. To address these
limitations, we propose a Multi-camera Reconstruction and Aggregation
Structure-from-Motion (MRASfM) framework specifically designed for driving
scenes. MRASfM enhances the reliability of camera pose estimation by leveraging
the fixed spatial relationships within the multi-camera system during the
registration process. To improve the quality of road surface reconstruction,
our framework employs a plane model to effectively remove erroneous points from
the triangulated road surface. Moreover, treating the multi-camera set as a
single unit in Bundle Adjustment (BA) helps reduce optimization variables to
boost efficiency. In addition, MRASfM achieves multi-scene aggregation through
scene association and assembly modules in a coarse-to-fine fashion. We deployed
multi-camera systems on actual vehicles to validate the generalizability of
MRASfM across various scenes and its robustness in challenging conditions
through real-world applications. Furthermore, large-scale validation results on
public datasets show the state-of-the-art performance of MRASfM, achieving
0.124 absolute pose error on the nuScenes dataset.

</details>


### [43] [MSAM: Multi-Semantic Adaptive Mining for Cross-Modal Drone Video-Text Retrieval](https://arxiv.org/abs/2510.15470)
*Jinghao Huang,Yaxiong Chen,Ganchao Liu*

Main category: cs.CV

TL;DR: 本论文首次研究无人机视频-文本检索（DVTR）任务，并提出了一种名为多语义自适应挖掘（MSAM）的方法，以应对无人机视频特有的挑战, 该方法通过多语义自适应学习机制增强对无人机视频内容的深刻理解和推理，并在自建的数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着无人机技术的进步，视频数据迅速增加，迫切需要高效的语义检索方法，尤其是针对无人机视频的检索机制。

Method: 引入多语义自适应学习机制，通过动态变化和局部区域的信息提取来增强对无人机视频内容的理解，结合交互特征融合池化机制，降低背景干扰。

Result: 在自建的两个无人机视频-文本数据集上，MSAM方法显示出优于现有技术的检索效果。

Conclusion: 多语义自适应挖掘（MSAM）方法在无人机视频-文本检索任务中具有良好的表现，能够有效处理复杂背景带来的干扰。

Abstract: With the advancement of drone technology, the volume of video data increases
rapidly, creating an urgent need for efficient semantic retrieval. We are the
first to systematically propose and study the drone video-text retrieval (DVTR)
task. Drone videos feature overhead perspectives, strong structural
homogeneity, and diverse semantic expressions of target combinations, which
challenge existing cross-modal methods designed for ground-level views in
effectively modeling their characteristics. Therefore, dedicated retrieval
mechanisms tailored for drone scenarios are necessary. To address this issue,
we propose a novel approach called Multi-Semantic Adaptive Mining (MSAM). MSAM
introduces a multi-semantic adaptive learning mechanism, which incorporates
dynamic changes between frames and extracts rich semantic information from
specific scene regions, thereby enhancing the deep understanding and reasoning
of drone video content. This method relies on fine-grained interactions between
words and drone video frames, integrating an adaptive semantic construction
module, a distribution-driven semantic learning term and a diversity semantic
term to deepen the interaction between text and drone video modalities and
improve the robustness of feature representation. To reduce the interference of
complex backgrounds in drone videos, we introduce a cross-modal interactive
feature fusion pooling mechanism that focuses on feature extraction and
matching in target regions, minimizing noise effects. Extensive experiments on
two self-constructed drone video-text datasets show that MSAM outperforms other
existing methods in the drone video-text retrieval task. The source code and
dataset will be made publicly available.

</details>


### [44] [Shakti-VLMs: Scalable Vision-Language Models for Enterprise AI](https://arxiv.org/abs/2502.17092)
*Syed Abdul Gaffar Shakhadri,Kruthika KR,Kartik Basavaraj Angadi*

Main category: cs.CV

TL;DR: Shakti VLM是一系列旨在提高数据效率的视觉语言模型，通过创新设计和训练策略，在多模态任务中展示了高效的性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态学习中的数据效率挑战，证明高性能不仅依赖于大量训练数据。

Method: 采用三阶段训练策略，结合建筑创新，如QK归一化、混合归一化技术和增强的位置信息编码，以提高学习效率。

Result: Shakti-VLM-1B和Shakti-VLM-4B在文档理解、视觉推理、OCR提取和一般多模态推理方面表现突出。

Conclusion: Shakti VLM能在数据量较少的情况下，通过模型设计和训练策略实现高性能，成为企业级多模态任务的有效解决方案。

Abstract: We introduce Shakti VLM, a family of vision-language models in the capacity
of 1B and 4B parameters designed to address data efficiency challenges in
multimodal learning. While recent VLMs achieve strong performance through
extensive training data, Shakti models leverage architectural innovations to
attain competitive results with fewer tokens. Key advancements include
QK-Normalization for attention stability, hybrid normalization techniques, and
enhanced positional encoding. A three-stage training strategy further optimizes
learning efficiency. Evaluations show that Shakti-Shakti-VLM-1B and
Shakti-VLM-4B excel in document understanding, Visual Reasoning, OCR
extraction, and general multimodal reasoning. Our results highlight that high
performance can be achieved through model design and training strategy rather
than sheer data volume, making Shakti an efficient solution for
enterprise-scale multimodal tasks.

</details>


### [45] [Iterative Motion Compensation for Canonical 3D Reconstruction from UAV Plant Images Captured in Windy Conditions](https://arxiv.org/abs/2510.15491)
*Andre Rochow,Jonas Marcic,Svetlana Seliunina,Sven Behnke*

Main category: cs.CV

TL;DR: 本文提出一种基于无人机的自主管道，实现单株植物的高质量3D重建，解决了因叶片运动导致的重建误差，最终推出高分辨率网格和数据集。


<details>
  <summary>Details</summary>
Motivation: 为了深入理解植物生长、提高产量预测和实现病害控制，开发高效的3D表型分析工具。

Method: 采用无人机捕捉植物图像，通过自开发Android应用程序控制，全自动化图像采集。使用迭代方法和光流技术来纠正由于环境因素造成的运动误差。

Result: 本文提出了一种能够生成高质量单株农业植物3D重建的管道，该管道通过小型无人机(UAV)捕获植物图像，整个图像采集过程完全自主，使用自开发的Android应用程序控制。尽管因环境风和无人机的下洗气流导致重建任务困难，但我们的方法支持集成各种先进的3D重建方法。通过迭代方法调节输入图像，以减少由于植物叶片运动带来的误差并实现一致表示。经过几次迭代后，我们的管道提高了先进方法的重建质量，并成功提取高分辨率3D网格数据。计划公开重建管道的源代码，并提供跨时间点捕获的多种作物植物数据集。

Conclusion: 该研究的管道提升了植物3D重建的精度，并提供开源代码及多样化植物数据集，促进相关研究进展。

Abstract: 3D phenotyping of plants plays a crucial role for understanding plant growth,
yield prediction, and disease control. We present a pipeline capable of
generating high-quality 3D reconstructions of individual agricultural plants.
To acquire data, a small commercially available UAV captures images of a
selected plant. Apart from placing ArUco markers, the entire image acquisition
process is fully autonomous, controlled by a self-developed Android application
running on the drone's controller. The reconstruction task is particularly
challenging due to environmental wind and downwash of the UAV. Our proposed
pipeline supports the integration of arbitrary state-of-the-art 3D
reconstruction methods. To mitigate errors caused by leaf motion during image
capture, we use an iterative method that gradually adjusts the input images
through deformation. Motion is estimated using optical flow between the
original input images and intermediate 3D reconstructions rendered from the
corresponding viewpoints. This alignment gradually reduces scene motion,
resulting in a canonical representation. After a few iterations, our pipeline
improves the reconstruction of state-of-the-art methods and enables the
extraction of high-resolution 3D meshes. We will publicly release the source
code of our reconstruction pipeline. Additionally, we provide a dataset
consisting of multiple plants from various crops, captured across different
points in time.

</details>


### [46] [Rethinking Efficient Hierarchical Mixing Architecture for Low-light RAW Image Enhancement](https://arxiv.org/abs/2510.15497)
*Xianmin Chen,Peiliang Huang,Longfei Han,Dingwen Zhang,Junwei Han*

Main category: cs.CV

TL;DR: 该论文提出了一种新颖的层次混合架构HiMA，结合多种技术，提高了低光图像增强的效率和质量，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 在低光RAW图像增强中，尽管已有多种深度学习方法，但仍面临增强质量与效率的平衡问题。

Method: 介绍了一种层次混合架构（HiMA），结合Transformer和Mamba模块以处理不同尺度的特征，并提出局部分布调整（LoDA）来适应不同区域的特征分布。

Result: 通过HiMA和LoDA等创新，改进了低光图像信号处理的效率和质量，并在多个数据集上表现优异。

Conclusion: 该方法在多个公共数据集上的实验结果表明，相比于最先进的方法，其性能更优且参数更少。

Abstract: Low-light RAW image enhancement remains a challenging task. Although numerous
deep learning based approaches have been proposed, they still suffer from
inherent limitations. A key challenge is how to simultaneously achieve strong
enhancement quality and high efficiency. In this paper, we rethink the
architecture for efficient low-light image signal processing (ISP) and
introduce a Hierarchical Mixing Architecture (HiMA). HiMA leverages the
complementary strengths of Transformer and Mamba modules to handle features at
large and small scales, respectively, thereby improving efficiency while
avoiding the ambiguities observed in prior two-stage frameworks. To further
address uneven illumination with strong local variations, we propose Local
Distribution Adjustment (LoDA), which adaptively aligns feature distributions
across different local regions. In addition, to fully exploit the denoised
outputs from the first stage, we design a Multi-prior Fusion (MPF) module that
integrates spatial and frequency-domain priors for detail enhancement.
Extensive experiments on multiple public datasets demonstrate that our method
outperforms state-of-the-art approaches, achieving superior performance with
fewer parameters. Code will be released at https://github.com/Cynicarlos/HiMA.

</details>


### [47] [Exploring Conditions for Diffusion models in Robotic Control](https://arxiv.org/abs/2510.15510)
*Heeseong Shin,Byeongho Heo,Dongyoon Han,Seungryong Kim,Taekyung Kim*

Main category: cs.CV

TL;DR: 本研究提出了一种新方法ORCA，通过引入可学习的任务提示和细粒度的视觉提示，提升任务自适应视觉表示在机器人控制中的效果，显著超过了以往方法。


<details>
  <summary>Details</summary>
Motivation: 探索如何在不微调模型的情况下，通过预训练的文本到图像扩散模型获取适应任务的视觉表示。

Method: 提出ORCA方法，利用可学习的任务提示和视觉提示，适应控制环境并捕捉细节。

Result: 通过任务自适应的表示，我们的方法在多个机器人控制基准上达到了最先进的性能，远超传统方法。

Conclusion: 我们的方法通过引入新的条件显著提高了机器人控制任务的性能，成为该领域的新标杆。

Abstract: While pre-trained visual representations have significantly advanced
imitation learning, they are often task-agnostic as they remain frozen during
policy learning. In this work, we explore leveraging pre-trained text-to-image
diffusion models to obtain task-adaptive visual representations for robotic
control, without fine-tuning the model itself. However, we find that naively
applying textual conditions - a successful strategy in other vision domains -
yields minimal or even negative gains in control tasks. We attribute this to
the domain gap between the diffusion model's training data and robotic control
environments, leading us to argue for conditions that consider the specific,
dynamic visual information required for control. To this end, we propose ORCA,
which introduces learnable task prompts that adapt to the control environment
and visual prompts that capture fine-grained, frame-specific details. Through
facilitating task-adaptive representations with our newly devised conditions,
our approach achieves state-of-the-art performance on various robotic control
benchmarks, significantly surpassing prior methods.

</details>


### [48] [Latent Feature Alignment: Discovering Biased and Interpretable Subpopulations in Face Recognition Models](https://arxiv.org/abs/2510.15520)
*Ignacio Serna*

Main category: cs.CV

TL;DR: 本研究提出了一种新算法LFA，旨在无标签地识别面部识别模型中的偏见，解决传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决现有面部识别模型在各子群体中的系统性偏差，以及传统偏差评估框架对标签的依赖。

Method: Latent Feature Alignment (LFA)

Result: LFA优于标准聚类方法，如k-means和最近邻搜索，在群体内部语义一致性方面表现更佳，同时能发现与人口统计和上下文属性对齐的可解释潜在方向。

Conclusion: LFA为面部识别模型的表示审计提供了一种实用方法，使从业者能够在没有预定义属性标注的情况下识别和解释偏见子群体。

Abstract: Modern face recognition models achieve high overall accuracy but continue to
exhibit systematic biases that disproportionately affect certain
subpopulations. Conventional bias evaluation frameworks rely on labeled
attributes to form subpopulations, which are expensive to obtain and limited to
predefined categories. We introduce Latent Feature Alignment (LFA), an
attribute-label-free algorithm that uses latent directions to identify
subpopulations. This yields two main benefits over standard clustering: (i)
semantically coherent grouping, where faces sharing common attributes are
grouped together more reliably than by proximity-based methods, and (ii)
discovery of interpretable directions, which correspond to semantic attributes
such as age, ethnicity, or attire. Across four state-of-the-art recognition
models (ArcFace, CosFace, ElasticFace, PartialFC) and two benchmarks (RFW,
CelebA), LFA consistently outperforms k-means and nearest-neighbor search in
intra-group semantic coherence, while uncovering interpretable latent
directions aligned with demographic and contextual attributes. These results
position LFA as a practical method for representation auditing of face
recognition models, enabling practitioners to identify and interpret biased
subpopulations without predefined attribute annotations.

</details>


### [49] [Diffusion Bridge Networks Simulate Clinical-grade PET from MRI for Dementia Diagnostics](https://arxiv.org/abs/2510.15556)
*Yitong Li,Ralph Buchert,Benita Schmitz-Koep,Timo Grimmer,Björn Ommer,Dennis M. Hedderich,Igor Yakushev,Christian Wachinger*

Main category: cs.CV

TL;DR: SiM2P框架通过MRI和患者信息预测FDG-PET图像，显著提高了诊断准确性。


<details>
  <summary>Details</summary>
Motivation: FDG-PET在诊断认知障碍方面效果显著，但其获取成本高且不易获得，因此需要一个替代方案。

Method: 使用3D扩散桥接框架学习从MRI到FDG-PET的概率映射，并进行临床评估。

Result: SiM2P框架成功模拟FDG-PET图像，并在诊断准确性上显著提升。

Conclusion: SiM2P的应用有望在资源有限的环境中提高认知障碍患者的诊断率。

Abstract: Positron emission tomography (PET) with 18F-Fluorodeoxyglucose (FDG) is an
established tool in the diagnostic workup of patients with suspected dementing
disorders. However, compared to the routinely available magnetic resonance
imaging (MRI), FDG-PET remains significantly less accessible and substantially
more expensive. Here, we present SiM2P, a 3D diffusion bridge-based framework
that learns a probabilistic mapping from MRI and auxiliary patient information
to simulate FDG-PET images of diagnostic quality. In a blinded clinical reader
study, two neuroradiologists and two nuclear medicine physicians rated the
original MRI and SiM2P-simulated PET images of patients with Alzheimer's
disease, behavioral-variant frontotemporal dementia, and cognitively healthy
controls. SiM2P significantly improved the overall diagnostic accuracy of
differentiating between three groups from 75.0% to 84.7% (p<0.05). Notably, the
simulated PET images received higher diagnostic certainty ratings and achieved
superior interrater agreement compared to the MRI images. Finally, we developed
a practical workflow for local deployment of the SiM2P framework. It requires
as few as 20 site-specific cases and only basic demographic information. This
approach makes the established diagnostic benefits of FDG-PET imaging more
accessible to patients with suspected dementing disorders, potentially
improving early detection and differential diagnosis in resource-limited
settings. Our code is available at https://github.com/Yiiitong/SiM2P.

</details>


### [50] [ClapperText: A Benchmark for Text Recognition in Low-Resource Archival Documents](https://arxiv.org/abs/2510.15557)
*Tingyu Lin,Marco Peer,Florian Kleber,Robert Sablatnig*

Main category: cs.CV

TL;DR: 本文介绍 ClapperText 数据集，专注于在低资源条件下的手写和打印文本识别，提供了重要的基准评估资源。


<details>
  <summary>Details</summary>
Motivation: 旨在应对在退化和低资源环境中对手写和打印文本识别的挑战，特别是历史文档分析中的非标准形式的结构化内容识别。

Method: 通过从二战时期的档案视频中提取数据，构建了包含手写和打印文本的标注数据集，并使用一致的评估协议对识别和检测模型进行基准测试。

Result: ClapperText 数据集包含 9,813 个标注帧，94,573 个文本实例，其中 67% 是手写文本，并成功评估了六个识别模型和七个检测模型的性能。

Conclusion: ClapperText 数据集为手写和打印文本的识别提供了一个现实且具有文化背景的资源，适用于低资源档案环境的鲁棒 OCR 和文档理解研究。

Abstract: This paper presents ClapperText, a benchmark dataset for handwritten and
printed text recognition in visually degraded and low-resource settings. The
dataset is derived from 127 World War II-era archival video segments containing
clapperboards that record structured production metadata such as date,
location, and camera-operator identity. ClapperText includes 9,813 annotated
frames and 94,573 word-level text instances, 67% of which are handwritten and
1,566 are partially occluded. Each instance includes transcription, semantic
category, text type, and occlusion status, with annotations available as
rotated bounding boxes represented as 4-point polygons to support spatially
precise OCR applications. Recognizing clapperboard text poses significant
challenges, including motion blur, handwriting variation, exposure
fluctuations, and cluttered backgrounds, mirroring broader challenges in
historical document analysis where structured content appears in degraded,
non-standard forms. We provide both full-frame annotations and cropped word
images to support downstream tasks. Using a consistent per-video evaluation
protocol, we benchmark six representative recognition and seven detection
models under zero-shot and fine-tuned conditions. Despite the small training
set (18 videos), fine-tuning leads to substantial performance gains,
highlighting ClapperText's suitability for few-shot learning scenarios. The
dataset offers a realistic and culturally grounded resource for advancing
robust OCR and document understanding in low-resource archival contexts. The
dataset and evaluation code are available at
https://github.com/linty5/ClapperText.

</details>


### [51] [Imaginarium: Vision-guided High-Quality 3D Scene Layout Generation](https://arxiv.org/abs/2510.15564)
*Xiaoming Zhu,Xu Huang,Qinghongbing Xie,Zhi Deng,Junsheng Yu,Yirui Guan,Zhongyuan Liu,Lin Zhu,Qijun Zhao,Ligang Liu,Long Zeng*

Main category: cs.CV

TL;DR: 本论文介绍了一种新颖的视觉引导3D布局生成系统，能够高效生成丰富且一致的3D场景布局，相关代码和数据集将可供使用。


<details>
  <summary>Details</summary>
Motivation: 解决传统优化方法和深度生成模型在生成艺术性和一致性3D场景布局中面临的挑战。

Method: 构建高质量资产库，使用图像生成模型扩展提示表示，并开发图像解析模块来恢复3D场景布局。

Result: 通过用户测试，验证了算法在布局丰富性和质量上的显著提升。

Conclusion: 该论文提出的视觉引导3D布局生成系统在布局丰富性和质量方面显著优于现有方法。

Abstract: Generating artistic and coherent 3D scene layouts is crucial in digital
content creation. Traditional optimization-based methods are often constrained
by cumbersome manual rules, while deep generative models face challenges in
producing content with richness and diversity. Furthermore, approaches that
utilize large language models frequently lack robustness and fail to accurately
capture complex spatial relationships. To address these challenges, this paper
presents a novel vision-guided 3D layout generation system. We first construct
a high-quality asset library containing 2,037 scene assets and 147 3D scene
layouts. Subsequently, we employ an image generation model to expand prompt
representations into images, fine-tuning it to align with our asset library. We
then develop a robust image parsing module to recover the 3D layout of scenes
based on visual semantics and geometric information. Finally, we optimize the
scene layout using scene graphs and overall visual semantics to ensure logical
coherence and alignment with the images. Extensive user testing demonstrates
that our algorithm significantly outperforms existing methods in terms of
layout richness and quality. The code and dataset will be available at
https://github.com/HiHiAllen/Imaginarium.

</details>


### [52] [Unmasking Facial DeepFakes: A Robust Multiview Detection Framework for Natural Images](https://arxiv.org/abs/2510.15576)
*Sami Belguesmia,Mohand Saïd Allili,Assia Hamadene*

Main category: cs.CV

TL;DR: 提出了一种多视角架构，结合多种编码器有效提高深度伪造检测的性能，特别是在复杂条件下的应用


<details>
  <summary>Details</summary>
Motivation: 现有的深度伪造检测方法在面对姿态变化、遮挡和难以检测的伪影时常常面临挑战

Method: 提出了一种多视角架构用于深度伪造检测

Result: 通过整合三个专门编码器和一个面部朝向编码器，构建的模型在各种姿态和光照条件下能有效检测伪造图像，性能优于传统单视角方法

Conclusion: 实验结果表明，该方法在检测深度伪造图像方面表现优越，可以应对多种挑战。

Abstract: DeepFake technology has advanced significantly in recent years, enabling the
creation of highly realistic synthetic face images. Existing DeepFake detection
methods often struggle with pose variations, occlusions, and artifacts that are
difficult to detect in real-world conditions. To address these challenges, we
propose a multi-view architecture that enhances DeepFake detection by analyzing
facial features at multiple levels. Our approach integrates three specialized
encoders, a global view encoder for detecting boundary inconsistencies, a
middle view encoder for analyzing texture and color alignment, and a local view
encoder for capturing distortions in expressive facial regions such as the
eyes, nose, and mouth, where DeepFake artifacts frequently occur. Additionally,
we incorporate a face orientation encoder, trained to classify face poses,
ensuring robust detection across various viewing angles. By fusing features
from these encoders, our model achieves superior performance in detecting
manipulated images, even under challenging pose and lighting
conditions.Experimental results on challenging datasets demonstrate the
effectiveness of our method, outperforming conventional single-view approaches

</details>


### [53] [Lightweight CycleGAN Models for Cross-Modality Image Transformation and Experimental Quality Assessment in Fluorescence Microscopy](https://arxiv.org/abs/2510.15579)
*Mohammad Soltaninezhad,Yashar Rouzbahani,Jhonatan Contreras,Rohan Chippalkatti,Daniel Kwaku Abankwa,Christian Eggeling,Thomas Bocklitz*

Main category: cs.CV

TL;DR: 提出了一种轻量级的CycleGAN模型，用于荧光显微镜的模态转移，显著减少了可训练参数，同时提升了性能并降低了内存使用。


<details>
  <summary>Details</summary>
Motivation: 随着科学应用对计算成本和环境影响的关注，开发轻量级深度学习模型变得越来越重要。

Method: 通过将传统的通道加倍策略替换为固定通道的方法，在U-Net生成器中实现模型参数的大幅减少。

Result: 训练后，该模型在高质量图像上表现出色，能够辅助检测实验中的质量问题，同时提供较快的训练速度和较低的内存需求。

Conclusion: 该轻量级CycleGAN模型可有效用于荧光显微镜中的模态转换，并在提高性能的同时显著降低训练参数和内存使用。

Abstract: Lightweight deep learning models offer substantial reductions in
computational cost and environmental impact, making them crucial for scientific
applications. We present a lightweight CycleGAN for modality transfer in
fluorescence microscopy (confocal to super-resolution STED/deconvolved STED),
addressing the common challenge of unpaired datasets. By replacing the
traditional channel-doubling strategy in the U-Net-based generator with a fixed
channel approach, we drastically reduce trainable parameters from 41.8 million
to approximately nine thousand, achieving superior performance with faster
training and lower memory usage. We also introduce the GAN as a diagnostic tool
for experimental and labeling quality. When trained on high-quality images, the
GAN learns the characteristics of optimal imaging; deviations between its
generated outputs and new experimental images can reveal issues such as
photobleaching, artifacts, or inaccurate labeling. This establishes the model
as a practical tool for validating experimental accuracy and image fidelity in
microscopy workflows.

</details>


### [54] [Standardization for improved Spatio-Temporal Image Fusion](https://arxiv.org/abs/2510.15589)
*Harkaitz Goyena,Peter M. Atkinson,Unai Pérez-Goya,M. Dolores Ugarte*

Main category: cs.CV

TL;DR: 本研究提出两种标准化方法以提高时空图像融合的准确性，其中一种基于传统上采样，另一种为锐化方法ABSIS，效果显著。


<details>
  <summary>Details</summary>
Motivation: 旨在提高不同传感器捕获的图像的匹配空间和光谱分辨率，从而改善时空图像融合的准确性。

Method: 比较传统上采样和ABSIS锐化方法在时空图像融合中的应用效果。

Result: 本研究提出并比较了两种不同的标准化方法，以便于时空图像融合（STIF）方法的应用。第一种方法是基于传统的高分辨率图像上采样，第二种方法是一种称为异常基准卫星图像标准化（ABSIS）的锐化方法，该方法将高分辨率图像系列中的整体特征与特定低分辨率图像的独特属性相结合，以生成更接近于聚合高分辨率图像结果的图像。两种方法均显著提高了无配对时空图像块融合（USTFIP）STIF方法的准确性，其中锐化方法使融合图像的光谱和空间准确度分别提高了高达49.46%和78.40%。

Conclusion: 两种标准化方法均提高了STIF方法的准确度，特别是ABSIS方法在光谱和空间准确度上表现优异。

Abstract: Spatio-Temporal Image Fusion (STIF) methods usually require sets of images
with matching spatial and spectral resolutions captured by different sensors.
To facilitate the application of STIF methods, we propose and compare two
different standardization approaches. The first method is based on traditional
upscaling of the fine-resolution images. The second method is a sharpening
approach called Anomaly Based Satellite Image Standardization (ABSIS) that
blends the overall features found in the fine-resolution image series with the
distinctive attributes of a specific coarse-resolution image to produce images
that more closely resemble the outcome of aggregating the fine-resolution
images. Both methods produce a significant increase in accuracy of the Unpaired
Spatio Temporal Fusion of Image Patches (USTFIP) STIF method, with the
sharpening approach increasing the spectral and spatial accuracies of the fused
images by up to 49.46\% and 78.40\%, respectively.

</details>


### [55] [FlexiReID: Adaptive Mixture of Expert for Multi-Modal Person Re-Identification](https://arxiv.org/abs/2510.15595)
*Zhen Sun,Lei Tan,Yunhang Shen,Chengmao Cai,Xing Sun,Pingyang Dai,Liujuan Cao,Rongrong Ji*

Main category: cs.CV

TL;DR: FlexiReID是一种支持多模态灵活检索的新框架，且在多个复杂场景表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨模态设置上受限，无法支持任意的查询-检索组合，影响实际应用

Method: 提出了一种灵活的框架FlexiReID，支持七种检索模式和四种模态的数据组合

Result: FlexiReID实现了在复杂场景中的最佳性能，并展现出良好的泛化能力

Conclusion: 通过CIRS-PEDES数据集，FlexiReID为多模态行人重识别的实用部署提供了新思路。

Abstract: Multimodal person re-identification (Re-ID) aims to match pedestrian images
across different modalities. However, most existing methods focus on limited
cross-modal settings and fail to support arbitrary query-retrieval
combinations, hindering practical deployment. We propose FlexiReID, a flexible
framework that supports seven retrieval modes across four modalities: rgb,
infrared, sketches, and text. FlexiReID introduces an adaptive
mixture-of-experts (MoE) mechanism to dynamically integrate diverse modality
features and a cross-modal query fusion module to enhance multimodal feature
extraction. To facilitate comprehensive evaluation, we construct CIRS-PEDES, a
unified dataset extending four popular Re-ID datasets to include all four
modalities. Extensive experiments demonstrate that FlexiReID achieves
state-of-the-art performance and offers strong generalization in complex
scenarios.

</details>


### [56] [Quantized FCA: Efficient Zero-Shot Texture Anomaly Detection](https://arxiv.org/abs/2510.15602)
*Andrei-Timotei Ardelean,Patrick Rückbeil,Tim Weyrich*

Main category: cs.CV

TL;DR: 提出了一种QFCA方法，能在实时检测纹理异常的同时实现高效和高精度。


<details>
  <summary>Details</summary>
Motivation: 当前零样本异常检测在计算机视觉中的重要性日益突出，尤其是在监测纹理异常时，现有方法的运行时间过长限制了其在实际应用中的可用性，尤其是在像装配线监控这样的场景中.

Method: 通过将特征对应分析（FCA）算法进行量化实现，结合主成分分析进行特征预处理，比较量化值的直方图的补丁统计，改进检测的对比度。

Result: 我们提出了一种名为QFCA的实时方法，通过量化特征对应分析（FCA）算法的版本，对运行速度进行了10倍加速，同时几乎没有损失准确性，检测精度得到了改善。

Conclusion: 我们的QFCA方法在处理复杂纹理的异常检测上，明显优于现有技术，具有更快的速度与更高的检测精度。

Abstract: Zero-shot anomaly localization is a rising field in computer vision research,
with important progress in recent years. This work focuses on the problem of
detecting and localizing anomalies in textures, where anomalies can be defined
as the regions that deviate from the overall statistics, violating the
stationarity assumption. The main limitation of existing methods is their high
running time, making them impractical for deployment in real-world scenarios,
such as assembly line monitoring. We propose a real-time method, named QFCA,
which implements a quantized version of the feature correspondence analysis
(FCA) algorithm. By carefully adapting the patch statistics comparison to work
on histograms of quantized values, we obtain a 10x speedup with little to no
loss in accuracy. Moreover, we introduce a feature preprocessing step based on
principal component analysis, which enhances the contrast between normal and
anomalous features, improving the detection precision on complex textures. Our
method is thoroughly evaluated against prior art, comparing favorably with
existing methods. Project page:
https://reality.tf.fau.de/pub/ardelean2025quantized.html

</details>


### [57] [Lightweight Data-Free Denoising for Detail-Preserving Biomedical Image Restoration](https://arxiv.org/abs/2510.15611)
*Tomáš Chobola,Julia A. Schnabel,Tingying Peng*

Main category: cs.CV

TL;DR: 提出了一种名为Noise2Detail (N2D)的超轻量级自监督去噪模型，能实现快速去噪与高质量图像修复，同时降低计算和内存需求。


<details>
  <summary>Details</summary>
Motivation: 克服现有自监督去噪技术在实际应用中面临的高计算和内存需求，寻求高效且数据无关的解决方案。

Method: 基于Noise2Noise训练框架，使用多阶段去噪流程，通过干扰噪声模式的空间相关性来生成中间的平滑结构，最后从噪声输入中直接提取细节。

Result: Noise2Detail在性能和资源需求方面表现优越，尤其适用于生物医学成像。

Conclusion: Noise2Detail在性能上超越现有的数据集无关方法，并且只需少量计算资源，是生物医学成像中一种有效的工具。

Abstract: Current self-supervised denoising techniques achieve impressive results, yet
their real-world application is frequently constrained by substantial
computational and memory demands, necessitating a compromise between inference
speed and reconstruction quality. In this paper, we present an
ultra-lightweight model that addresses this challenge, achieving both fast
denoising and high quality image restoration. Built upon the Noise2Noise
training framework-which removes the reliance on clean reference images or
explicit noise modeling-we introduce an innovative multistage denoising
pipeline named Noise2Detail (N2D). During inference, this approach disrupts the
spatial correlations of noise patterns to produce intermediate smooth
structures, which are subsequently refined to recapture fine details directly
from the noisy input. Extensive testing reveals that Noise2Detail surpasses
existing dataset-free techniques in performance, while requiring only a
fraction of the computational resources. This combination of efficiency, low
computational cost, and data-free approach make it a valuable tool for
biomedical imaging, overcoming the challenges of scarce clean training data-due
to rare and complex imaging modalities-while enabling fast inference for
practical use.

</details>


### [58] [OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding LLM](https://arxiv.org/abs/2510.15870)
*Hanrong Ye,Chao-Han Huck Yang,Arushi Goel,Wei Huang,Ligeng Zhu,Yuanhang Su,Sean Lin,An-Chieh Cheng,Zhen Wan,Jinchuan Tian,Yuming Lou,Dong Yang,Zhijian Liu,Yukang Chen,Ambrish Dantrey,Ehsan Jahangiri,Sreyan Ghosh,Daguang Xu,Ehsan Hosseini-Asl,Danial Mohseni Taheri,Vidya Murali,Sifei Liu,Jason Lu,Oluwatobi Olabiyi,Frank Wang,Rafael Valle,Bryan Catanzaro,Andrew Tao,Song Han,Jan Kautz,Hongxu Yin,Pavlo Molchanov*

Main category: cs.CV

TL;DR: OmniVinci通过改进的多模态处理架构和数据生成方法，展示了多模态感知的强大能力，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 为了推动机器智能的发展，提升机器对多模态感知的能力，以更接近人类的感知方式。

Method: 提出了OmniAlignNet、Temporal Embedding Grouping和Constrained Rotary Time Embedding等关键创新，以增强视觉和音频的对齐性，并实现模态间的时间信息编码。

Result: OmniVinci在多个数据集上超越了Qwen2.5-Omni，同时在训练上使用更少的训练数据。

Conclusion: OmniVinci展示了在多模态感知与推理中的显著优势，并能有效减少训练数据量。

Abstract: Advancing machine intelligence requires developing the ability to perceive
across multiple modalities, much as humans sense the world. We introduce
OmniVinci, an initiative to build a strong, open-source, omni-modal LLM. We
carefully study the design choices across model architecture and data curation.
For model architecture, we present three key innovations: (i) OmniAlignNet for
strengthening alignment between vision and audio embeddings in a shared
omni-modal latent space; (ii) Temporal Embedding Grouping for capturing
relative temporal alignment between vision and audio signals; and (iii)
Constrained Rotary Time Embedding for encoding absolute temporal information in
omni-modal embeddings. We introduce a curation and synthesis pipeline that
generates 24M single-modal and omni-modal conversations. We find that
modalities reinforce one another in both perception and reasoning. Our model,
OmniVinci, outperforms Qwen2.5-Omni with +19.05 on DailyOmni (cross-modal
understanding), +1.7 on MMAR (audio), and +3.9 on Video-MME (vision), while
using just 0.2T training tokens - a 6 times reduction compared to
Qwen2.5-Omni's 1.2T. We finally demonstrate omni-modal advantages in downstream
applications spanning robotics, medical AI, and smart factory.

</details>


### [59] [Deep Learning Based Domain Adaptation Methods in Remote Sensing: A Comprehensive Survey](https://arxiv.org/abs/2510.15615)
*Shuchang Lyu,Qi Zhao,Zheng Zhou,Meng Li,You Zhou,Dingding Yao,Guangliang Cheng,Huiyu Zhou,Zhenwei Shi*

Main category: cs.CV

TL;DR: 本论文综述了深度学习在遥感领域适应性中的重要进展，分类了现有方法，识别了研究挑战，旨在激励未来研究。


<details>
  <summary>Details</summary>
Motivation: 随着遥感应用的广泛发展，领域适应性成为了一项关键任务，能够有效转移知识并解决数据分布差异带来的挑战。

Method: 通过文献综述和现有算法的分类，组织和总结深度学习在遥感领域的应用。

Result: 本综述总结了现有算法和数据集的表现，系统识别了开放挑战和未来研究方向。

Conclusion: 本研究提供了一个系统的分类和对深度学习在遥感领域适应性的最新进展的综述，旨在激励研究社区并引导未来研究。

Abstract: Domain adaptation is a crucial and increasingly important task in remote
sensing, aiming to transfer knowledge from a source domain a differently
distributed target domain. It has broad applications across various real-world
applications, including remote sensing element interpretation, ecological
environment monitoring, and urban/rural planning. However, domain adaptation in
remote sensing poses significant challenges due to differences in data, such as
variations in ground sampling distance, imaging modes from various sensors,
geographical landscapes, and environmental conditions. In recent years, deep
learning has emerged as a powerful tool for feature representation and
cross-domain knowledge transfer, leading to widespread adoption in remote
sensing tasks. In this paper, we present a comprehensive survey of significant
advancements in deep learning based domain adaptation for remote sensing. We
first introduce the preliminary knowledge to clarify key concepts, mathematical
notations, and the taxonomy of methodologies. We then organize existing
algorithms from multiple perspectives, including task categorization, input
mode, supervision paradigm, and algorithmic granularity, providing readers with
a structured understanding of the field. Next, we review widely used datasets
and summarize the performance of state-of-the-art methods to provide an
overview of current progress. We also identify open challenges and potential
directions to guide future research in domain adaptation for remote sensing.
Compared to previous surveys, this work addresses a broader range of domain
adaptation tasks in remote sensing, rather than concentrating on a few
subfields. It also presents a systematic taxonomy, providing a more
comprehensive and organized understanding of the field. As a whole, this survey
can inspire the research community, foster understanding, and guide future work
in the field.

</details>


### [60] [Uncertainty-Aware Extreme Point Tracing for Weakly Supervised Ultrasound Image Segmentation](https://arxiv.org/abs/2510.15666)
*Lei Shi,Gang Li,Junxing Zhang*

Main category: cs.CV

TL;DR: 提出一种利用极端点进行弱监督医学图像分割的方法，显著减少标注成本并提升性能。


<details>
  <summary>Details</summary>
Motivation: 降低全监督方法中对像素级标注的需求，节省成本与时间

Method: 提出一种基于弱监督学习的医学图像分割框架

Result: 在两种公共超声数据集上取得了与全监督方法相当甚至更优的分割效果，同时大幅降低了标注成本

Conclusion: 该框架在超声图像分割中有效且切实可行，验证了其优越性。

Abstract: Automatic medical image segmentation is a fundamental step in computer-aided
diagnosis, yet fully supervised approaches demand extensive pixel-level
annotations that are costly and time-consuming. To alleviate this burden, we
propose a weakly supervised segmentation framework that leverages only four
extreme points as annotation. Specifically, bounding boxes derived from the
extreme points are used as prompts for the Segment Anything Model 2 (SAM2) to
generate reliable initial pseudo labels. These pseudo labels are progressively
refined by an enhanced Feature-Guided Extreme Point Masking (FGEPM) algorithm,
which incorporates Monte Carlo dropout-based uncertainty estimation to
construct a unified gradient uncertainty cost map for boundary tracing.
Furthermore, a dual-branch Uncertainty-aware Scale Consistency (USC) loss and a
box alignment loss are introduced to ensure spatial consistency and precise
boundary alignment during training. Extensive experiments on two public
ultrasound datasets, BUSI and UNS, demonstrate that our method achieves
performance comparable to, and even surpassing fully supervised counterparts
while significantly reducing annotation cost. These results validate the
effectiveness and practicality of the proposed weakly supervised framework for
ultrasound image segmentation.

</details>


### [61] [Valeo Near-Field: a novel dataset for pedestrian intent detection](https://arxiv.org/abs/2510.15673)
*Antonyo Musabini,Rachid Benmokhtar,Jagdish Bhanushali,Victor Galizzi,Bertrand Luvison,Xavier Perrotton*

Main category: cs.CV

TL;DR: 本文介绍了一个新颖的数据集，用于检测行人接近自我车辆时的意图，包含多种传感器的同步数据，旨在促进智能车辆的研究与算法发展。


<details>
  <summary>Details</summary>
Motivation: 为了解决现实环境中行人检测和行为预测的挑战，创建一个综合性的数据集，以提供更准确的算法基准。

Method: 通过多模态传感器收集的数据，进行详细3D关节位置标注，并与变换过的图像数据同步。

Result: 发布的数据集和基准套件将推动行人检测和意图预测算法的研究，支持算法在真实世界条件下的测试和优化。

Conclusion: 该数据集为行人检测、三维姿态估计和意图预测等领域提供了重要的基准和资源，有助于提升智能车辆的能力。

Abstract: This paper presents a novel dataset aimed at detecting pedestrians'
intentions as they approach an ego-vehicle. The dataset comprises synchronized
multi-modal data, including fisheye camera feeds, lidar laser scans, ultrasonic
sensor readings, and motion capture-based 3D body poses, collected across
diverse real-world scenarios. Key contributions include detailed annotations of
3D body joint positions synchronized with fisheye camera images, as well as
accurate 3D pedestrian positions extracted from lidar data, facilitating robust
benchmarking for perception algorithms. We release a portion of the dataset
along with a comprehensive benchmark suite, featuring evaluation metrics for
accuracy, efficiency, and scalability on embedded systems. By addressing
real-world challenges such as sensor occlusions, dynamic environments, and
hardware constraints, this dataset offers a unique resource for developing and
evaluating state-of-the-art algorithms in pedestrian detection, 3D pose
estimation and 4D trajectory and intention prediction. Additionally, we provide
baseline performance metrics using custom neural network architectures and
suggest future research directions to encourage the adoption and enhancement of
the dataset. This work aims to serve as a foundation for researchers seeking to
advance the capabilities of intelligent vehicles in near-field scenarios.

</details>


### [62] [Towards Label-Free Brain Tumor Segmentation: Unsupervised Learning with Multimodal MRI](https://arxiv.org/abs/2510.15684)
*Gerard Comas-Quiles,Carles Garcia-Cabrera,Julia Dietlmeier,Noel E. O'Connor,Ferran Marques*

Main category: cs.CV

TL;DR: 提出了一种基于变换器的无监督学习模型MViT-AE，用于脑肿瘤MRI分割，表现出良好的性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 在标注数据集有限、成本高或不一致的情况下，寻找一种无监督的替代方案进行脑肿瘤分割。

Method: 提出了一种新的多模态视觉变换器自编码器（MViT-AE），利用健康脑部MRI训练，通过重构误差图检测肿瘤。

Result: 在BraTS-GoAT 2025 Lighthouse数据集中，模型在不同肿瘤类型上的Dice相似系数分别为0.437（整体肿瘤）、0.316（肿瘤核心）和0.350（增强肿瘤），验证集的异常检测率为89.4%。

Conclusion: 研究表明，基于变换器的无监督模型在神经肿瘤影像学中具有可扩展性和高效性，可以有效进行肿瘤定位和分割。

Abstract: Unsupervised anomaly detection (UAD) presents a complementary alternative to
supervised learning for brain tumor segmentation in magnetic resonance imaging
(MRI), particularly when annotated datasets are limited, costly, or
inconsistent. In this work, we propose a novel Multimodal Vision Transformer
Autoencoder (MViT-AE) trained exclusively on healthy brain MRIs to detect and
localize tumors via reconstruction-based error maps. This unsupervised paradigm
enables segmentation without reliance on manual labels, addressing a key
scalability bottleneck in neuroimaging workflows. Our method is evaluated in
the BraTS-GoAT 2025 Lighthouse dataset, which includes various types of tumors
such as gliomas, meningiomas, and pediatric brain tumors. To enhance
performance, we introduce a multimodal early-late fusion strategy that
leverages complementary information across multiple MRI sequences, and a
post-processing pipeline that integrates the Segment Anything Model (SAM) to
refine predicted tumor contours. Despite the known challenges of UAD,
particularly in detecting small or non-enhancing lesions, our method achieves
clinically meaningful tumor localization, with lesion-wise Dice Similarity
Coefficient of 0.437 (Whole Tumor), 0.316 (Tumor Core), and 0.350 (Enhancing
Tumor) on the test set, and an anomaly Detection Rate of 89.4% on the
validation set. These findings highlight the potential of transformer-based
unsupervised models to serve as scalable, label-efficient tools for
neuro-oncological imaging.

</details>


### [63] [Unimedvl: Unifying Medical Multimodal Understanding And Generation Through Observation-Knowledge-Analysis](https://arxiv.org/abs/2510.15710)
*Junzhi Ning,Wei Li,Cheng Tang,Jiashi Lin,Chenglong Ma,Chaoyang Zhang,Jiyao Liu,Ying Chen,Shujian Gao,Lihao Liu,Yuandong Pu,Huihui Xu,Chenhui Gou,Ziyan Huang,Yi Xin,Qi Qin,Zhongying Deng,Diping Song,Bin Fu,Guang Yang,Yuanfeng Ji,Tianbin Li,Yanzhou Su,Jin Ye,Shixiang Tang,Ming Hu,Junjun He*

Main category: cs.CV

TL;DR: 本研究提出了一种多层次的医疗诊断框架UniMedVL，以同时进行医学图像理解和生成，显著提升了模型在多项任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有医疗AI系统在处理多模态数据时存在信息空缺和能力不足的问题，需要一个统一的框架来同时理解和生成医学图像。

Method: 通过Observation-Knowledge-Analysis (OKA)框架，构建UniMed-5M数据集并提出渐进式课程学习，最终实现UniMedVL模型。

Result: UniMedVL在五项医学图像理解基准测试中表现优异，并在八种医学成像模式中与专业模型在生成质量上相匹配。

Conclusion: 提出的UniMedVL模型在医学图像理解和生成任务中表现优异，说明在医疗框架中整合传统上分开的能力能够提高不同医学视觉-语言任务的性能。

Abstract: Medical diagnostic applications require models that can process multimodal
medical inputs (images, patient histories, lab results) and generate diverse
outputs including both textual reports and visual content (annotations,
segmentation masks, and images). Despite this need, existing medical AI systems
disrupt this unified process: medical image understanding models interpret
images but cannot generate visual outputs, while medical image generation
models synthesize images but cannot provide textual explanations. This leads to
gaps in data representation, feature integration, and task-level multimodal
capabilities. To this end, we propose a multi-level framework that draws
inspiration from diagnostic workflows through the
Observation-Knowledge-Analysis (OKA) paradigm. Specifically, at the observation
level, we construct UniMed-5M, a dataset comprising over 5.6M samples that
reformat diverse unimodal data into multimodal pairs for foundational
observation. At the knowledge level, we propose Progressive Curriculum Learning
that systematically introduces medical multimodal knowledge. At the analysis
level, we introduce UniMedVL, the first medical unified multimodal model for
the simultaneous analysis of image understanding and generation tasks within a
single architecture. UniMedVL achieves superior performance on five medical
image understanding benchmarks, while matching specialized models in generation
quality across eight medical imaging modalities. Crucially, our unified
architecture enables bidirectional knowledge sharing: generation tasks enhance
visual understanding features, demonstrating that integrating traditionally
separate capabilities within a single medical framework unlocks improvements
across diverse medical vision-language tasks. Code is available at
https://github.com/uni-medical/UniMedVL.

</details>


### [64] [DGME-T: Directional Grid Motion Encoding for Transformer-Based Historical Camera Movement Classification](https://arxiv.org/abs/2510.15725)
*Tingyu Lin,Armin Dadras,Florian Kleber,Robert Sablatnig*

Main category: cs.CV

TL;DR: 本研究提出了一种轻量级方法DGME-T，用于提升在归档电影中的摄像机运动分类（CMC）模型性能。


<details>
  <summary>Details</summary>
Motivation: 由于当前高质量视频的CMC模型在应用于归档电影时性能下降，本文旨在填补这一空白。

Method: 本研究基于构建的统一基准，引入了DGME-T，它通过可学习的归一化晚融合层注入了基于光流的方向性网格运动编码。

Result: DGME-T显著提升了现代剪辑和二战影片的分类精度，显示了轻量级运动头在退化电影分析中的重要性。

Conclusion: DGME-T通过结构化运动先验和转化器表示的结合显著提升了对退化电影分析的鲁棒性。

Abstract: Camera movement classification (CMC) models trained on contemporary,
high-quality footage often degrade when applied to archival film, where noise,
missing frames, and low contrast obscure motion cues. We bridge this gap by
assembling a unified benchmark that consolidates two modern corpora into four
canonical classes and restructures the HISTORIAN collection into five balanced
categories. Building on this benchmark, we introduce DGME-T, a lightweight
extension to the Video Swin Transformer that injects directional grid motion
encoding, derived from optical flow, via a learnable and normalised late-fusion
layer. DGME-T raises the backbone's top-1 accuracy from 81.78% to 86.14% and
its macro F1 from 82.08% to 87.81% on modern clips, while still improving the
demanding World-War-II footage from 83.43% to 84.62% accuracy and from 81.72%
to 82.63% macro F1. A cross-domain study further shows that an intermediate
fine-tuning stage on modern data increases historical performance by more than
five percentage points. These results demonstrate that structured motion priors
and transformer representations are complementary and that even a small,
carefully calibrated motion head can substantially enhance robustness in
degraded film analysis. Related resources are available at
https://github.com/linty5/DGME-T.

</details>


### [65] [Scaling Instruction-Based Video Editing with a High-Quality Synthetic Dataset](https://arxiv.org/abs/2510.15742)
*Qingyan Bai,Qiuyu Wang,Hao Ouyang,Yue Yu,Hanlin Wang,Wen Wang,Ka Leong Cheng,Shuailei Ma,Yanhong Zeng,Zichen Liu,Yinghao Xu,Yujun Shen,Qifeng Chen*

Main category: cs.CV

TL;DR: Ditto框架通过高效的数据生成和智能过滤，构建了大规模视频编辑数据集，提升了指令驱动视频编辑的效果。


<details>
  <summary>Details</summary>
Motivation: 解决视频编辑领域中大规模高质量训练数据稀缺的问题，推动内容创作的民主化。

Method: 使用创新的数据生成管道，结合图像编辑器和视频生成器，采用高效的模型架构，利用智能体进行多样化指令生成和输出过滤。

Result: 构建了Ditto-1M数据集，包括一百万个高保真视频编辑示例，所训练的Editto模型在指令跟随能力上超越了当前的技术水平。

Conclusion: 本文提出的Ditto框架在指令驱动的视频编辑中表现优异，展示了先进的数据生成能力和指令跟随能力。

Abstract: Instruction-based video editing promises to democratize content creation, yet
its progress is severely hampered by the scarcity of large-scale, high-quality
training data. We introduce Ditto, a holistic framework designed to tackle this
fundamental challenge. At its heart, Ditto features a novel data generation
pipeline that fuses the creative diversity of a leading image editor with an
in-context video generator, overcoming the limited scope of existing models. To
make this process viable, our framework resolves the prohibitive cost-quality
trade-off by employing an efficient, distilled model architecture augmented by
a temporal enhancer, which simultaneously reduces computational overhead and
improves temporal coherence. Finally, to achieve full scalability, this entire
pipeline is driven by an intelligent agent that crafts diverse instructions and
rigorously filters the output, ensuring quality control at scale. Using this
framework, we invested over 12,000 GPU-days to build Ditto-1M, a new dataset of
one million high-fidelity video editing examples. We trained our model, Editto,
on Ditto-1M with a curriculum learning strategy. The results demonstrate
superior instruction-following ability and establish a new state-of-the-art in
instruction-based video editing.

</details>


### [66] [SEGA: A Stepwise Evolution Paradigm for Content-Aware Layout Generation with Design Prior](https://arxiv.org/abs/2510.15749)
*Haoran Wang,Bo Zhao,Jinghui Wang,Hanzhang Wang,Huan Yang,Wei Ji,Hao Liu,Xinyan Xiao*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的内容感知布局生成方法SEGA，通过分步演化策略提升了生成效率，并在多个数据集上达到最佳效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂元素布局规划中效率低下，缺乏反馈自我纠正机制，导致失败率增加。

Method: 采用一种分层推理框架，结合粗略估计与细致推理的策略，对布局进行逐步演化。

Result: 在多个基准数据集上实现了最先进的结果，通过引入布局设计原则作为先验知识，增强了模型的布局规划能力，并提出了一个新的大型海报数据集GenPoster-100K。

Conclusion: SEGA方法能够有效提升内容感知布局生成的能力，并在多个基准数据集上取得了领先的结果。

Abstract: In this paper, we study the content-aware layout generation problem, which
aims to automatically generate layouts that are harmonious with a given
background image. Existing methods usually deal with this task with a
single-step reasoning framework. The lack of a feedback-based self-correction
mechanism leads to their failure rates significantly increasing when faced with
complex element layout planning. To address this challenge, we introduce SEGA,
a novel Stepwise Evolution Paradigm for Content-Aware Layout Generation.
Inspired by the systematic mode of human thinking, SEGA employs a hierarchical
reasoning framework with a coarse-to-fine strategy: first, a coarse-level
module roughly estimates the layout planning results; then, another refining
module performs fine-level reasoning regarding the coarse planning results.
Furthermore, we incorporate layout design principles as prior knowledge into
the model to enhance its layout planning ability. Besides, we present
GenPoster-100K that is a new large-scale poster dataset with rich
meta-information annotation. The experiments demonstrate the effectiveness of
our approach by achieving the state-of-the-art results on multiple benchmark
datasets. Our project page is at: https://brucew91.github.io/SEGA.github.io/

</details>


### [67] [NDM: A Noise-driven Detection and Mitigation Framework against Implicit Sexual Intentions in Text-to-Image Generation](https://arxiv.org/abs/2510.15752)
*Yitong Sun,Yao Huang,Ruochen Zhang,Huanran Chen,Shouwei Ruan,Ranjie Duan,Xingxing Wei*

Main category: cs.CV

TL;DR: 提出了一种新框架NDM，用于检测和缓解文本到图像生成中的隐性恶意内容，同时保持模型的生成能力。


<details>
  <summary>Details</summary>
Motivation: T2I模型容易生成不当内容，现有检测方法主要针对显性内容，难以识别隐性提示，且微调方法可能影响生成质量。

Method: 采用噪声驱动检测和缓解框架，利用早期预测噪声的可分离性和噪声增强的自适应负引导机制。

Result: 在实验中，验证了NDM框架在检测隐性恶意意图方面的有效性和高准确性，并在多个数据集上表现优异。

Conclusion: NDM在自然和对抗数据集上的实验结果优于现有检测方法，展示了其更高的性能。

Abstract: Despite the impressive generative capabilities of text-to-image (T2I)
diffusion models, they remain vulnerable to generating inappropriate content,
especially when confronted with implicit sexual prompts. Unlike explicit
harmful prompts, these subtle cues, often disguised as seemingly benign terms,
can unexpectedly trigger sexual content due to underlying model biases, raising
significant ethical concerns. However, existing detection methods are primarily
designed to identify explicit sexual content and therefore struggle to detect
these implicit cues. Fine-tuning approaches, while effective to some extent,
risk degrading the model's generative quality, creating an undesirable
trade-off. To address this, we propose NDM, the first noise-driven detection
and mitigation framework, which could detect and mitigate implicit malicious
intention in T2I generation while preserving the model's original generative
capabilities. Specifically, we introduce two key innovations: first, we
leverage the separability of early-stage predicted noise to develop a
noise-based detection method that could identify malicious content with high
accuracy and efficiency; second, we propose a noise-enhanced adaptive negative
guidance mechanism that could optimize the initial noise by suppressing the
prominent region's attention, thereby enhancing the effectiveness of adaptive
negative guidance for sexual mitigation. Experimentally, we validate NDM on
both natural and adversarial datasets, demonstrating its superior performance
over existing SOTA methods, including SLD, UCE, and RECE, etc. Code and
resources are available at https://github.com/lorraine021/NDM.

</details>


### [68] [Semantic segmentation with coarse annotations](https://arxiv.org/abs/2510.15756)
*Jort de Jong,Mike Holenderski*

Main category: cs.CV

TL;DR: 提出了一种正则化方法，可提升在粗略注释下的语义分割性能，尤其是边界对齐。


<details>
  <summary>Details</summary>
Motivation: 在获取细粒度注释困难或昂贵的情况下，利用粗略注释进行分割，着眼于优化类间边界的对齐。

Method: 提出了一种基于超像素上采样的正则化方法，应用于编码-解码架构的模型。

Result: 在使用粗注释进行训练时，边界召回率显著提高，相比于最先进的模型表现更佳。

Conclusion: 该方法可有效提高基于粗注释的语义分割模型在边界召回方面的表现。

Abstract: Semantic segmentation is the task of classifying each pixel in an image.
Training a segmentation model achieves best results using annotated images,
where each pixel is annotated with the corresponding class. When obtaining fine
annotations is difficult or expensive, it may be possible to acquire coarse
annotations, e.g. by roughly annotating pixels in an images leaving some pixels
around the boundaries between classes unlabeled. Segmentation with coarse
annotations is difficult, in particular when the objective is to optimize the
alignment of boundaries between classes. This paper proposes a regularization
method for models with an encoder-decoder architecture with superpixel based
upsampling. It encourages the segmented pixels in the decoded image to be
SLIC-superpixels, which are based on pixel color and position, independent of
the segmentation annotation. The method is applied to FCN-16 fully
convolutional network architecture and evaluated on the SUIM, Cityscapes, and
PanNuke data sets. It is shown that the boundary recall improves significantly
compared to state-of-the-art models when trained on coarse annotations.

</details>


### [69] [QSilk: Micrograin Stabilization and Adaptive Quantile Clipping for Detail-Friendly Latent Diffusion](https://arxiv.org/abs/2510.15761)
*Denis Rychkovskiy*

Main category: cs.CV

TL;DR: QSilk是一种轻量级、持续稳定的层，用于潜在扩散，能提升高频保真度并抑制稀有激活尖峰。


<details>
  <summary>Details</summary>
Motivation: 针对潜在扩散过程中的高频噪声和突发激活问题，设计稳定层QSilk以提升图像清晰度和细节。

Method: QSilk结合了每个样本的微夹具和自适应分位剪辑（AQClip）方法，后者根据区域的局部结构统计或注意力熵引导模式调整允许的值范围。

Result: 在CADE 2.5渲染管道中，QSilk整合后产出更清晰、更尖锐的结果，并且兼容CFG/Rescale，能够在不产生伪影的情况下略微提高指导标准。

Conclusion: QSilk在无需训练或微调的情况下，能显著提高SD/SDXL模型的输出质量，适用于低步数和超高分辨率的渲染，且几乎不增加额外负担。

Abstract: We present QSilk, a lightweight, always-on stabilization layer for latent
diffusion that improves high-frequency fidelity while suppressing rare
activation spikes. QSilk combines (i) a per-sample micro clamp that gently
limits extreme values without washing out texture, and (ii) Adaptive Quantile
Clip (AQClip), which adapts the allowed value corridor per region. AQClip can
operate in a proxy mode using local structure statistics or in an attention
entropy guided mode (model confidence). Integrated into the CADE 2.5 rendering
pipeline, QSilk yields cleaner, sharper results at low step counts and
ultra-high resolutions with negligible overhead. It requires no training or
fine-tuning and exposes minimal user controls. We report consistent qualitative
improvements across SD/SDXL backbones and show synergy with CFG/Rescale,
enabling slightly higher guidance without artifacts.

</details>


### [70] [Towards more holistic interpretability: A lightweight disentangled Concept Bottleneck Model](https://arxiv.org/abs/2510.15770)
*Gaoxiang Huang,Songning Lai,Yutao Yue*

Main category: cs.CV

TL;DR: 提出了一种新模型LDCBM，通过自动分组视觉特征提高可解释性和分类准确性。


<details>
  <summary>Details</summary>
Motivation: 提高概念瓶颈模型的可解释性，克服现有模型在输入与概念映射偏差和可控性方面的局限性

Method: 提出了一种轻量级的解耦概念瓶颈模型（LDCBM）

Result: LDCBM在三个不同的数据集上表现出更高的概念和类别准确性，超越了之前的CBMs，同时在可解释性和分类性能上有显著提升

Conclusion: 通过将概念与视觉证据相结合，LDCBM克服了先前模型的基本局限性，提升了可解释AI的可靠性。

Abstract: Concept Bottleneck Models (CBMs) enhance interpretability by predicting
human-understandable concepts as intermediate representations. However,
existing CBMs often suffer from input-to-concept mapping bias and limited
controllability, which restricts their practical value, directly damage the
responsibility of strategy from concept-based methods. We propose a lightweight
Disentangled Concept Bottleneck Model (LDCBM) that automatically groups visual
features into semantically meaningful components without region annotation. By
introducing a filter grouping loss and joint concept supervision, our method
improves the alignment between visual patterns and concepts, enabling more
transparent and robust decision-making. Notably, Experiments on three diverse
datasets demonstrate that LDCBM achieves higher concept and class accuracy,
outperforming previous CBMs in both interpretability and classification
performance. By grounding concepts in visual evidence, our method overcomes a
fundamental limitation of prior models and enhances the reliability of
interpretable AI.

</details>


### [71] [ERNet: Efficient Non-Rigid Registration Network for Point Sequences](https://arxiv.org/abs/2510.15800)
*Guangzhao He,Yuxi Xiao,Zhen Xu,Xiaowei Zhou,Sida Peng*

Main category: cs.CV

TL;DR: 我们提出ERNet，一个处理非刚性形变的点云序列注册的高效模型，成功克服了局部极小值和错误积累问题，实现了更高的准确性和速度提升。


<details>
  <summary>Details</summary>
Motivation: 针对点云序列注册中的局部极小值问题以及长序列错误积累导致的跟踪失败，设计一个高效且鲁棒的注册模型。

Method: 采用数据驱动的方法，通过一个高效的前馈模型对大型形变数据集进行训练和应用，结合时间信息进行序列注册。

Result: ERNet在DeformingThings4D和D-FAUST数据集上的表现超过了现有的最先进技术，并且在速度上实现了4倍的提升。

Conclusion: 我们提出的ERNet在处理非刚性形变的点云序列注册中表现优异，超越了已有模型，并且在速度上有显著提升。

Abstract: Registering an object shape to a sequence of point clouds undergoing
non-rigid deformation is a long-standing challenge. The key difficulties stem
from two factors: (i) the presence of local minima due to the non-convexity of
registration objectives, especially under noisy or partial inputs, which
hinders accurate and robust deformation estimation, and (ii) error accumulation
over long sequences, leading to tracking failures. To address these challenges,
we introduce to adopt a scalable data-driven approach and propose ERNet, an
efficient feed-forward model trained on large deformation datasets. It is
designed to handle noisy and partial inputs while effectively leveraging
temporal information for accurate and consistent sequential registration. The
key to our design is predicting a sequence of deformation graphs through a
two-stage pipeline, which first estimates frame-wise coarse graph nodes for
robust initialization, before refining their trajectories over time in a
sliding-window fashion. Extensive experiments show that our proposed approach
(i) outperforms previous state-of-the-art on both the DeformingThings4D and
D-FAUST datasets, and (ii) achieves more than 4x speedup compared to the
previous best, offering significant efficiency improvement.

</details>


### [72] [Memory-SAM: Human-Prompt-Free Tongue Segmentation via Retrieval-to-Prompt](https://arxiv.org/abs/2510.15849)
*Joongwon Chae,Lihui Luo,Xi Yuan,Dongmei Yu,Zhenglin Chen,Lian Zhang,Peiwu Qin*

Main category: cs.CV

TL;DR: Memory-SAM是一种新型无监督舌头分割方法，利用小型案例记忆生成提示，显著提高了分割精度。


<details>
  <summary>Details</summary>
Motivation: 提高舌头成像中分割模型的效率，尤其是在缺乏大规模标注数据集的情况下。

Method: 通过采用DINOv3特征和FAISS检索，Memory-SAM无需人工提示或模型微调，自动生成前景/背景点提示。

Result: 这项研究提出了一种名为Memory-SAM的方法，用于高效的舌头分割，旨在在小型标注数据集上以无监督方式生成提示，从而提高传统模型的性能。该方法通过密集的DINOv3特征和FAISS检索，从之前的病例中自动生成有效的前景/背景提示，与SAM2模型无缝结合，明显超越了现有的FCN和Box SAM基线模型。在600张专家标注的图像上的评价结果显示，该方法在实际条件下表现优异。

Conclusion: Memory-SAM展示了在舌头成像中的数据高效且鲁棒的分割能力，特别是在处理不规则边界时。

Abstract: Accurate tongue segmentation is crucial for reliable TCM analysis. Supervised
models require large annotated datasets, while SAM-family models remain
prompt-driven. We present Memory-SAM, a training-free, human-prompt-free
pipeline that automatically generates effective prompts from a small memory of
prior cases via dense DINOv3 features and FAISS retrieval. Given a query image,
mask-constrained correspondences to the retrieved exemplar are distilled into
foreground/background point prompts that guide SAM2 without manual clicks or
model fine-tuning. We evaluate on 600 expert-annotated images (300 controlled,
300 in-the-wild). On the mixed test split, Memory-SAM achieves mIoU 0.9863,
surpassing FCN (0.8188) and a detector-to-box SAM baseline (0.1839). On
controlled data, ceiling effects above 0.98 make small differences less
meaningful given annotation variability, while our method shows clear gains
under real-world conditions. Results indicate that retrieval-to-prompt enables
data-efficient, robust segmentation of irregular boundaries in tongue imaging.
The code is publicly available at https://github.com/jw-chae/memory-sam.

</details>


### [73] [BLIP3o-NEXT: Next Frontier of Native Image Generation](https://arxiv.org/abs/2510.15857)
*Jiuhai Chen,Le Xue,Zhiyang Xu,Xichen Pan,Shusheng Yang,Can Qin,An Yan,Honglu Zhou,Zeyuan Chen,Lifu Huang,Tianyi Zhou,Junnan Li,Silvio Savarese,Caiming Xiong,Ran Xu*

Main category: cs.CV

TL;DR: BLIP3o-NEXT是一种开放源代码的图像生成与编辑模型，结合自回归与扩散架构，展示出强大的能力与性能。


<details>
  <summary>Details</summary>
Motivation: 推动原生图像生成的前沿，统一文本到图像生成和图像编辑

Method: 融合自回归与扩散模型的结构来实现原生图像生成和编辑

Result: BLIP3o-NEXT在多种文本到图像及图像编辑基准测试中表现优异，超越现有模型。

Conclusion: BLIP3o-NEXT在图像生成和编辑方面展现了新的连贯性和逼真度，标志着原生图像生成的重大进展。

Abstract: We present BLIP3o-NEXT, a fully open-source foundation model in the BLIP3
series that advances the next frontier of native image generation. BLIP3o-NEXT
unifies text-to-image generation and image editing within a single
architecture, demonstrating strong image generation and image editing
capabilities. In developing the state-of-the-art native image generation model,
we identify four key insights: (1) Most architectural choices yield comparable
performance; an architecture can be deemed effective provided it scales
efficiently and supports fast inference; (2) The successful application of
reinforcement learning can further push the frontier of native image
generation; (3) Image editing still remains a challenging task, yet instruction
following and the consistency between generated and reference images can be
significantly enhanced through post-training and data engine; (4) Data quality
and scale continue to be decisive factors that determine the upper bound of
model performance. Building upon these insights, BLIP3o-NEXT leverages an
Autoregressive + Diffusion architecture in which an autoregressive model first
generates discrete image tokens conditioned on multimodal inputs, whose hidden
states are then used as conditioning signals for a diffusion model to generate
high-fidelity images. This architecture integrates the reasoning strength and
instruction following of autoregressive models with the fine-detail rendering
ability of diffusion models, achieving a new level of coherence and realism.
Extensive evaluations of various text-to-image and image-editing benchmarks
show that BLIP3o-NEXT achieves superior performance over existing models.

</details>


### [74] [BiomedXPro: Prompt Optimization for Explainable Diagnosis with Biomedical Vision Language Models](https://arxiv.org/abs/2510.15866)
*Kaushitha Silva,Mansitha Eashwara,Sanduni Ubayasiri,Ruwan Tennakoon,Damayanthi Herath*

Main category: cs.CV

TL;DR: BiomedXPro通过生成多样化的、可解释的自然语言提示对，实现了疾病诊断性能的提升，增强了模型预测的可信性。


<details>
  <summary>Details</summary>
Motivation: 现有的提示优化技术导致不透明的潜变量或单一的文本提示，限制了在临床诊断中的应用，缺乏对多面性临床观察的捕捉。

Method: 引入BiomedXPro框架，利用大型语言模型作为生物医学知识提取器和自适应优化器，自动生成多样化的、可解释的自然语言提示对用于疾病诊断。

Result: BiomedXPro在多个生物医学基准测试中表现优于先进的提示调优方法，尤其是在数据稀缺的少量样本设置中。

Conclusion: 通过提供多样化可解释的提示，BiomedXPro为模型预测提供了可验证的基础，是朝着更可信、临床对齐的人工智能系统发展迈出的重要一步。

Abstract: The clinical adoption of biomedical vision-language models is hindered by
prompt optimization techniques that produce either uninterpretable latent
vectors or single textual prompts. This lack of transparency and failure to
capture the multi-faceted nature of clinical diagnosis, which relies on
integrating diverse observations, limits their trustworthiness in high-stakes
settings. To address this, we introduce BiomedXPro, an evolutionary framework
that leverages a large language model as both a biomedical knowledge extractor
and an adaptive optimizer to automatically generate a diverse ensemble of
interpretable, natural-language prompt pairs for disease diagnosis. Experiments
on multiple biomedical benchmarks show that BiomedXPro consistently outperforms
state-of-the-art prompt-tuning methods, particularly in data-scarce few-shot
settings. Furthermore, our analysis demonstrates a strong semantic alignment
between the discovered prompts and statistically significant clinical features,
grounding the model's performance in verifiable concepts. By producing a
diverse ensemble of interpretable prompts, BiomedXPro provides a verifiable
basis for model predictions, representing a critical step toward the
development of more trustworthy and clinically-aligned AI systems.

</details>


### [75] [LightsOut: Diffusion-based Outpainting for Enhanced Lens Flare Removal](https://arxiv.org/abs/2510.15868)
*Shr-Ruei Tsai,Wei-Cheng Chang,Jie-Ying Lee,Chih-Hai Su,Yu-Lun Liu*

Main category: cs.CV

TL;DR: LightsOut通过增强单图像光晕去除方法，重建离框光源，提高了图像处理质量，适用于多种计算机视觉任务。


<details>
  <summary>Details</summary>
Motivation: 镜头光晕对图像质量的影响，尤其是在计算机视觉任务上，如物体检测和自动驾驶。

Method: 提出了一种基于扩散的外绘框架，结合多任务回归模块和经过LoRA微调的扩散模型。

Result: 综合实验表明，LightsOut在各种复杂场景中不断提高现有SIFR方法的性能。

Conclusion: LightsOut显著提升现有单图像光晕去除方法在复杂场景中的表现，且无需额外的再训练，具有普遍适用性。

Abstract: Lens flare significantly degrades image quality, impacting critical computer
vision tasks like object detection and autonomous driving. Recent Single Image
Flare Removal (SIFR) methods perform poorly when off-frame light sources are
incomplete or absent. We propose LightsOut, a diffusion-based outpainting
framework tailored to enhance SIFR by reconstructing off-frame light sources.
Our method leverages a multitask regression module and LoRA fine-tuned
diffusion model to ensure realistic and physically consistent outpainting
results. Comprehensive experiments demonstrate LightsOut consistently boosts
the performance of existing SIFR methods across challenging scenarios without
additional retraining, serving as a universally applicable plug-and-play
preprocessing solution. Project page: https://ray-1026.github.io/lightsout/

</details>


### [76] [Skyfall-GS: Synthesizing Immersive 3D Urban Scenes from Satellite Imagery](https://arxiv.org/abs/2510.15869)
*Jie-Ying Lee,Yi-Ruei Liu,Shr-Ruei Tsai,Wei-Cheng Chang,Chung-Ho Wu,Jiewen Chan,Zhenjun Zhao,Chieh Hubert Lin,Yu-Lun Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种新的框架Skyfall-GS，用于生成大规模的3D城市场景，结合卫星图像和扩散模型，且无需昂贵的3D注释。


<details>
  <summary>Details</summary>
Motivation: 需要高质量大规模3D城市场景以支持各种沉浸式应用，但缺乏可用的真实3D扫描数据来训练生成模型。

Method: 通过结合卫星图像的粗略几何和开域扩散模型的高质量外观，采用课程驱动的迭代优化策略来提升生成的3D场景质量。

Result: Skyfall-GS 框架有效生成了城市街区级别的3D场景，并在几何完整性和纹理真实感上超越了当前的最先进技术。

Conclusion: Skyfall-GS 在几何一致性和逼真纹理方面相比于现有技术具有显著的改进，能够提供实时和沉浸式的3D探索。

Abstract: Synthesizing large-scale, explorable, and geometrically accurate 3D urban
scenes is a challenging yet valuable task in providing immersive and embodied
applications. The challenges lie in the lack of large-scale and high-quality
real-world 3D scans for training generalizable generative models. In this
paper, we take an alternative route to create large-scale 3D scenes by
synergizing the readily available satellite imagery that supplies realistic
coarse geometry and the open-domain diffusion model for creating high-quality
close-up appearances. We propose \textbf{Skyfall-GS}, the first city-block
scale 3D scene creation framework without costly 3D annotations, also featuring
real-time, immersive 3D exploration. We tailor a curriculum-driven iterative
refinement strategy to progressively enhance geometric completeness and
photorealistic textures. Extensive experiments demonstrate that Skyfall-GS
provides improved cross-view consistent geometry and more realistic textures
compared to state-of-the-art approaches. Project page:
https://skyfall-gs.jayinnn.dev/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [77] [Rethinking Toxicity Evaluation in Large Language Models: A Multi-Label Perspective](https://arxiv.org/abs/2510.15007)
*Zhiqiang Kou,Junyang Chen,Xin-Qiang Cai,Ming-Kun Xie,Biao Liu,Changwei Wang,Lei Feng,Yuheng Jia,Gang Niu,Masashi Sugiyama,Xin Geng*

Main category: cs.CL

TL;DR: 本文提出了三种多标签毒性检测基准，并证明基于伪标签的训练方法在多标签毒性检测中表现优于单标签监督，显著提高了检测准确性。


<details>
  <summary>Details</summary>
Motivation: 针对大型语言模型（LLMs）在自然语言处理任务中出现的安全和有害内容生成问题，希望提升毒性检测的可靠性和准确性。

Method: 利用公共毒性数据集，开发出基于多标签的毒性检测基准，并采用伪标签训练方法进行性能提升。

Result: 开发了三种新型多标签毒性检测基准，并提出了一种基于伪标签的毒性检测方法，显著提高了检测性能。

Conclusion: 引入的新多标签基准和方法能够更准确可靠地评估大型语言模型生成内容的毒性。

Abstract: Large language models (LLMs) have achieved impressive results across a range
of natural language processing tasks, but their potential to generate harmful
content has raised serious safety concerns. Current toxicity detectors
primarily rely on single-label benchmarks, which cannot adequately capture the
inherently ambiguous and multi-dimensional nature of real-world toxic prompts.
This limitation results in biased evaluations, including missed toxic
detections and false positives, undermining the reliability of existing
detectors. Additionally, gathering comprehensive multi-label annotations across
fine-grained toxicity categories is prohibitively costly, further hindering
effective evaluation and development. To tackle these issues, we introduce
three novel multi-label benchmarks for toxicity detection: \textbf{Q-A-MLL},
\textbf{R-A-MLL}, and \textbf{H-X-MLL}, derived from public toxicity datasets
and annotated according to a detailed 15-category taxonomy. We further provide
a theoretical proof that, on our released datasets, training with pseudo-labels
yields better performance than directly learning from single-label supervision.
In addition, we develop a pseudo-label-based toxicity detection method.
Extensive experimental results show that our approach significantly surpasses
advanced baselines, including GPT-4o and DeepSeek, thus enabling more accurate
and reliable evaluation of multi-label toxicity in LLM-generated content.

</details>


### [78] [Can generative AI figure out figurative language? The influence of idioms on essay scoring by ChatGPT, Gemini, and Deepseek](https://arxiv.org/abs/2510.15009)
*Enis Oğuz*

Main category: cs.CL

TL;DR: 本研究比较了三种生成型 AI 模型在自动评分学生论文中的表现，特别关注成语的处理能力。结果显示，Gemini 模型在与人类评分者的评分一致性方面表现最佳，并能够有效处理包含成语的论文。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在评估生成型 AI 在学生论文自动评分中的有效性，特别是在处理成语时的表现，并探讨其潜在的应用前景。

Method: 本研究通过分析348篇学生论文，分别创建包含和不包含成语的两组论文，使用三种生成型 AI 模型对其进行评分，并与人类评分者的评分进行比较。

Result: 本研究评估了三种生成型 AI 模型在评分包含和不包含成语的学生论文方面的表现。研究发现，尽管所有模型在评分一致性方面表现优异，但其中 Gemini 模型在与人类评分者之间的评分一致性方面表现最佳。同时，AI评分未表现出任何群体偏见。对于包含多种成语的论文，Gemini 的评分模式与人类评分者最为相似。研究表明，生成型 AI 在论文评分任务中具备混合应用的潜力，而 Gemini 是未来独立处理评分任务的最佳候选模型。

Conclusion: Gemini 模型在处理论文评分任务时，尤其是在包含成语的情况下，表现出了良好的潜力和一致性，可能成为未来的最佳选择。

Abstract: The developments in Generative AI technologies have paved the way for
numerous innovations in different fields. Recently, Generative AI has been
proposed as a competitor to AES systems in evaluating student essays
automatically. Considering the potential limitations of AI in processing
idioms, this study assessed the scoring performances of Generative AI models
for essays with and without idioms by incorporating insights from Corpus
Linguistics and Computational Linguistics. Two equal essay lists were created
from 348 student essays taken from a corpus: one with multiple idioms present
in each essay and another with no idioms in essays. Three Generative AI models
(ChatGPT, Gemini, and Deepseek) were asked to score all essays in both lists
three times, using the same rubric used by human raters in assigning essay
scores. The results revealed excellent consistency for all models, but Gemini
outperformed its competitors in interrater reliability with human raters. There
was also no detectable bias for any demographic group in AI assessment. For
essays with multiple idioms, Gemini followed a the most similar pattern to
human raters. While the models in the study demonstrated potential for a hybrid
approach, Gemini was the best candidate for the task due to its ability to
handle figurative language and showed promise for handling essay-scoring tasks
alone in the future.

</details>


### [79] [A Generalizable Rhetorical Strategy Annotation Model Using LLM-based Debate Simulation and Labelling](https://arxiv.org/abs/2510.15081)
*Shiyu Ji,Farnoosh Hashemi,Joice Chen,Juanwen Pan,Weicheng Ma,Hefan Zhang,Sophia Pan,Ming Cheng,Shubham Mohole,Saeed Hassanpour,Soroush Vosoughi,Michael Macy*

Main category: cs.CL

TL;DR: 通过大型语言模型生成合成辩论数据，克服传统注释局限，模型在多领域表现优异，并揭示总统辩论中修辞策略的变化。


<details>
  <summary>Details</summary>
Motivation: 旨在克服传统人类注释方法在分析修辞策略时的局限性，如成本高、难以扩展以及数据集的主题和策略限制。

Method: 提出了一种新颖的框架，利用大型语言模型自动生成和标注合成辩论数据，并对变压器基础分类器进行了微调。

Result: 所提出模型在多个主题领域展示出高性能和强泛化能力，并揭示了美国总统辩论中情感论证使用的增加。

Conclusion: 该研究展示了通过大型语言模型生成和标注合成辩论数据的有效性，并在总统辩论分析中体现出情感与认知论证的变化。

Abstract: Rhetorical strategies are central to persuasive communication, from political
discourse and marketing to legal argumentation. However, analysis of rhetorical
strategies has been limited by reliance on human annotation, which is costly,
inconsistent, difficult to scale. Their associated datasets are often limited
to specific topics and strategies, posing challenges for robust model
development. We propose a novel framework that leverages large language models
(LLMs) to automatically generate and label synthetic debate data based on a
four-part rhetorical typology (causal, empirical, emotional, moral). We
fine-tune transformer-based classifiers on this LLM-labeled dataset and
validate its performance against human-labeled data on this dataset and on
multiple external corpora. Our model achieves high performance and strong
generalization across topical domains. We illustrate two applications with the
fine-tuned model: (1) the improvement in persuasiveness prediction from
incorporating rhetorical strategy labels, and (2) analyzing temporal and
partisan shifts in rhetorical strategies in U.S. Presidential debates
(1960-2020), revealing increased use of affective over cognitive argument in
U.S. Presidential debates.

</details>


### [80] [Continual Learning via Sparse Memory Finetuning](https://arxiv.org/abs/2510.15103)
*Jessy Lin,Luke Zettlemoyer,Gargi Ghosh,Wen-Tau Yih,Aram Markosyan,Vincent-Pierre Berges,Barlas Oğuz*

Main category: cs.CL

TL;DR: 本文提出稀疏记忆微调，显著减少语言模型的遗忘，促进持续学习。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决语言模型在持续学习中面临的灾难性遗忘问题。

Method: 采用稀疏记忆微调，利用内存层模型，仅更新与新知识高度相关的内存槽。

Result: 稀疏记忆微调在自然问答任务中表现出，新知识获取仅导致11%的遗忘，相比全微调的89%和LoRA的71%大幅降低。

Conclusion: 稀疏记忆微调方法可以实现知识的持续学习，并在新知识获取过程中大大减少遗忘现象。

Abstract: Modern language models are powerful, but typically static after deployment. A
major obstacle to building models that continually learn over time is
catastrophic forgetting, where updating on new data erases previously acquired
capabilities. Motivated by the intuition that mitigating forgetting is
challenging because trainable parameters are shared across all tasks, we
investigate whether sparse parameter updates can enable learning without
catastrophic forgetting. We introduce sparse memory finetuning, leveraging
memory layer models (Berges et al., 2024), which are sparsely updated by
design. By updating only the memory slots that are highly activated by a new
piece of knowledge relative to usage on pretraining data, we reduce
interference between new knowledge and the model's existing capabilities. We
evaluate learning and forgetting compared to full finetuning and
parameter-efficient finetuning with LoRA on two question answering tasks. We
find that sparse memory finetuning learns new knowledge while exhibiting
substantially less forgetting: while NaturalQuestions F1 drops by 89% after
full finetuning on new facts and 71% with LoRA, sparse memory finetuning yields
only an 11% drop with the same level of new knowledge acquisition. Our results
suggest sparsity in memory layers offers a promising path toward continual
learning in large language models.

</details>


### [81] [Measuring the Effect of Disfluency in Multilingual Knowledge Probing Benchmarks](https://arxiv.org/abs/2510.15115)
*Kirill Semenov,Rico Sennrich*

Main category: cs.CL

TL;DR: 本研究表明在多语言知识评估中，句子级翻译可提高LLMs的知识检索表现，建议对语法进行控制。


<details>
  <summary>Details</summary>
Motivation: MLAMA在处理多语种事实知识评估时的翻译模板未考虑命名实体的语法和语义信息，导致不合语法和错误措辞的问题。

Method: 通过比较MLAMA数据集的模板翻译与谷歌翻译和ChatGPT的句子级翻译的知识检索分数，分析多语言数据集的效果。

Result: 对四种斯拉夫语言进行比较后发现，使用句子级翻译显著提高了知识检索分数，同时对其他五种不同语言进行了类似的分析，结果一致。

Conclusion: 使用完整句子翻译的多语种数据集可以提高LLMs在知识检索中的表现和解释性，建议对此类数据集进行语法控制。

Abstract: For multilingual factual knowledge assessment of LLMs, benchmarks such as
MLAMA use template translations that do not take into account the grammatical
and semantic information of the named entities inserted in the sentence. This
leads to numerous instances of ungrammaticality or wrong wording of the final
prompts, which complicates the interpretation of scores, especially for
languages that have a rich morphological inventory. In this work, we sample 4
Slavic languages from the MLAMA dataset and compare the knowledge retrieval
scores between the initial (templated) MLAMA dataset and its sentence-level
translations made by Google Translate and ChatGPT. We observe a significant
increase in knowledge retrieval scores, and provide a qualitative analysis for
possible reasons behind it. We also make an additional analysis of 5 more
languages from different families and see similar patterns. Therefore, we
encourage the community to control the grammaticality of highly multilingual
datasets for higher and more interpretable results, which is well approximated
by whole sentence translation with neural MT or LLM systems. The dataset and
all related code is published at the Github repository:
https://github.com/ZurichNLP/Fluent-mLAMA.

</details>


### [82] [MCA: Modality Composition Awareness for Robust Composed Multimodal Retrieval](https://arxiv.org/abs/2510.15543)
*Qiyu Wu,Shuyang Cui,Satoshi Hayakawa,Wei-Yao Wang,Hiromi Wakaki,Yuki Mitsufuji*

Main category: cs.CL

TL;DR: 提出了一种新框架以提高多模态检索的鲁棒性，特别是在分布变化情况下，通过对比学习和组合意识显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 识别到传统对比学习训练的统一编码器容易学习模态捷径，导致在分布变化下鲁棒性差。

Method: 提出了一种偏好损失和组合正则化目标，旨在提高多模态嵌入的表现，并对齐由单一模态部分组成的原型。

Result: 在各种基准测试中，提出的方法在处理分布外检索时显示出显著的性能提升。

Conclusion: 通过引入模态组合意识框架来增强多模态检索的鲁棒性，尤其是在处理分布变化时取得了显著改进。

Abstract: Multimodal retrieval, which seeks to retrieve relevant content across
modalities such as text or image, supports applications from AI search to
contents production. Despite the success of separate-encoder approaches like
CLIP align modality-specific embeddings with contrastive learning, recent
multimodal large language models (MLLMs) enable a unified encoder that directly
processes composed inputs. While flexible and advanced, we identify that
unified encoders trained with conventional contrastive learning are prone to
learn modality shortcut, leading to poor robustness under distribution shifts.
We propose a modality composition awareness framework to mitigate this issue.
Concretely, a preference loss enforces multimodal embeddings to outperform
their unimodal counterparts, while a composition regularization objective
aligns multimodal embeddings with prototypes composed from its unimodal parts.
These objectives explicitly model structural relationships between the composed
representation and its unimodal counterparts. Experiments on various benchmarks
show gains in out-of-distribution retrieval, highlighting modality composition
awareness as a effective principle for robust composed multimodal retrieval
when utilizing MLLMs as the unified encoder.

</details>


### [83] [Latent Topic Synthesis: Leveraging LLMs for Electoral Ad Analysis](https://arxiv.org/abs/2510.15125)
*Alexander Brady,Tunazzina Islam*

Main category: cs.CL

TL;DR: 本研究提出了一种自动生成政治广告话题分类的方法，通过分析2024年美国总统选举前的政治广告，展现了社会媒体政治信息的结构和道德框架。


<details>
  <summary>Details</summary>
Motivation: 社交媒体在塑造政治话语中发挥着关键作用，但分析其内容的复杂性和快速演变仍然是一个重大挑战。

Method: 结合无监督聚类与基于提示的标记，利用大型语言模型（LLMs）自动生成可解释的话题分类体系。

Result: 发现投票和移民广告主导整体支出和印象，而堕胎和选举完整性广告则获得了不成比例的覆盖。

Conclusion: 本研究展示了一种可扩展和可解释的方法，帮助理解社交媒体上的政治信息及其道德基础。

Abstract: Social media platforms play a pivotal role in shaping political discourse,
but analyzing their vast and rapidly evolving content remains a major
challenge. We introduce an end-to-end framework for automatically generating an
interpretable topic taxonomy from an unlabeled corpus. By combining
unsupervised clustering with prompt-based labeling, our method leverages large
language models (LLMs) to iteratively construct a taxonomy without requiring
seed sets or domain expertise. We apply this framework to a large corpus of
Meta (previously known as Facebook) political ads from the month ahead of the
2024 U.S. Presidential election. Our approach uncovers latent discourse
structures, synthesizes semantically rich topic labels, and annotates topics
with moral framing dimensions. We show quantitative and qualitative analyses to
demonstrate the effectiveness of our framework. Our findings reveal that voting
and immigration ads dominate overall spending and impressions, while abortion
and election-integrity achieve disproportionate reach. Funding patterns are
equally polarized: economic appeals are driven mainly by conservative PACs,
abortion messaging splits between pro- and anti-rights coalitions, and
crime-and-justice campaigns are fragmented across local committees. The framing
of these appeals also diverges--abortion ads emphasize liberty/oppression
rhetoric, while economic messaging blends care/harm, fairness/cheating, and
liberty/oppression narratives. Topic salience further reveals strong
correlations between moral foundations and issues. Demographic targeting also
emerges. This work supports scalable, interpretable analysis of political
messaging on social media, enabling researchers, policymakers, and the public
to better understand emerging narratives, polarization dynamics, and the moral
underpinnings of digital political communication.

</details>


### [84] [FarsiMCQGen: a Persian Multiple-choice Question Generation Framework](https://arxiv.org/abs/2510.15134)
*Mohammad Heydari Rad,Rezvan Afari,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 本研究提出FarsiMCQGen模型，用于生成波斯语多选题，并推出一个包含10,289个问题的数据集，展示了生成多选题的有效性和质量。


<details>
  <summary>Details</summary>
Motivation: 在低资源语言（如波斯语）中，生成高质量多选题仍然是一大挑战。

Method: 结合候选生成、过滤和排序技术，利用Transformer和知识图谱，以及基于规则的方法，构建可生成高可信度干扰项的模型。

Result: 通过对维基百科数据的利用，该研究开发出了一个包含10,289个问题的新波斯语多选题数据集，并评估了其有效性。

Conclusion: 该研究提出的FarsiMCQGen模型有效生成高质量的波斯语多选题，并展示了新创建的波斯语数据集的潜力。

Abstract: Multiple-choice questions (MCQs) are commonly used in educational testing, as
they offer an efficient means of evaluating learners' knowledge. However,
generating high-quality MCQs, particularly in low-resource languages such as
Persian, remains a significant challenge. This paper introduces FarsiMCQGen, an
innovative approach for generating Persian-language MCQs. Our methodology
combines candidate generation, filtering, and ranking techniques to build a
model that generates answer choices resembling those in real MCQs. We leverage
advanced methods, including Transformers and knowledge graphs, integrated with
rule-based approaches to craft credible distractors that challenge test-takers.
Our work is based on data from Wikipedia, which includes general knowledge
questions. Furthermore, this study introduces a novel Persian MCQ dataset
comprising 10,289 questions. This dataset is evaluated by different
state-of-the-art large language models (LLMs). Our results demonstrate the
effectiveness of our model and the quality of the generated dataset, which has
the potential to inspire further research on MCQs.

</details>


### [85] [Structure-R1: Dynamically Leveraging Structural Knowledge in LLM Reasoning through Reinforcement Learning](https://arxiv.org/abs/2510.15191)
*Junlin Wu,Xianrui Zhong,Jiashuo Sun,Bolian Li,Bowen Jin,Jiawei Han,Qingkai Zeng*

Main category: cs.CL

TL;DR: 	extsc{Structure-R1}框架通过强化学习生成结构化表示，以增强多步推理能力，克服传统RAG的局限性，并在多项基准测试中展现出竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的推理能力有了显著提升，但对明确和结构化领域知识的访问仍然有限。传统的检索增强生成（RAG）系统通常处理无结构和碎片化的文本，导致信息密度低和推理效果不佳。

Method: 利用强化学习，	extsc{Structure-R1}动态生成和适应结构格式，以适应多步推理的需求，同时引入自我奖励结构验证机制确保生成结构的正确性和自洽性。

Result: 提出了	extsc{Structure-R1}框架，将检索内容转换为优化推理的结构化表示，且通过自我奖励机制确保结构的质量和可靠性。

Conclusion: 结构化表示通过改善信息密度和上下文清晰度，提高了推理能力，并且	extsc{Structure-R1}在多个知识密集型基准中表现优异。

Abstract: Large language models (LLMs) have demonstrated remarkable advances in
reasoning capabilities. However, their performance remains constrained by
limited access to explicit and structured domain knowledge. Retrieval-Augmented
Generation (RAG) addresses this by incorporating external information as
context to augment reasoning. Nevertheless, traditional RAG systems typically
operate over unstructured and fragmented text, resulting in low information
density and suboptimal reasoning. To overcome these limitations, we propose
\textsc{Structure-R1}, a novel framework that transforms retrieved content into
structured representations optimized for reasoning. Leveraging reinforcement
learning, \textsc{Structure-R1} learns a content representation policy that
dynamically generates and adapts structural formats based on the demands of
multi-step reasoning. Unlike prior methods that rely on fixed schemas, our
approach adopts a generative paradigm capable of producing task-specific
structures tailored to individual queries. To ensure the quality and
reliability of these representations, we introduce a self-reward structural
verification mechanism that checks whether the generated structures are both
correct and self-contained. Extensive experiments on seven knowledge-intensive
benchmarks show that \textsc{Structure-R1} consistently achieves competitive
performance with a 7B-scale backbone model and matches the performance of much
larger models. Additionally, our theoretical analysis demonstrates how
structured representations enhance reasoning by improving information density
and contextual clarity. Our code and data are available at:
https://github.com/jlwu002/sr1.

</details>


### [86] [Planner and Executor: Collaboration between Discrete Diffusion And Autoregressive Models in Reasoning](https://arxiv.org/abs/2510.15244)
*Lina Berrayana,Ahmed Heakl,Muhammad Abdullah Sohail,Thomas Hofmann,Salman Khan,Wei Chen*

Main category: cs.CL

TL;DR: 本研究探讨混合架构的可能性，结合离散扩散语言模型和自回归语言模型，提高推理准确率并节省计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有自回归语言模型需要长序列的输入，计算成本高，而离散扩散语言模型在复杂推理和长期规划任务中表现出色。

Method: 探索混合架构，将离散扩散语言模型与自回归语言模型结合，评估它们的协作效果。

Result: 通过在文本空间和潜在空间中的协作，发现潜在空间的通信显著提高了准确率，同时结合规划者和执行者的混合架构在计算上节省资源。

Conclusion: 该研究为离散扩散语言模型的推理能力提供了新的见解，展示了其在混合架构中的潜力。

Abstract: Current autoregressive language models (ARMs) achieve high accuracy but
require long token sequences, making them costly. Discrete diffusion language
models (DDLMs) enable parallel and flexible generation within a fixed number of
steps and have recently emerged for their strong performance in complex
reasoning and long-term planning tasks. We present a study exploring hybrid
architectures that couple DDLMs with ARMs to assess whether their collaboration
can yield complementary benefits. We first examine collaboration in text space,
where one model plans the reasoning process and another executes the final
answer based on that plan. We then extend this setup to latent-space
communication, introducing a learned projector that maps DDLM latents into the
ARM's embedding space, potentially bypassing some of the text-generation
limitations of diffusion models. We find that shifting DDLM --> ARM
communication from text space to latent space yields significant accuracy
gains, for example increasing from 27.0% to 54.0% on DART-5 and from 0.0% to
14.0% on AIME24. We also find that combining a DDLM planner with an ARM
executor can provide substantial computational savings with little to no impact
on accuracy. For example, the latent-space pipeline, using 64 tokens for
planning and roughly 5 for execution, surpasses Qwen3.1-7B on DART-5 and AIME,
despite Qwen using 44 times more tokens. Overall, our study offers new insights
into reasoning with DDLMs and highlights their potential in hybrid
architectures.

</details>


### [87] [TraceCoder: Towards Traceable ICD Coding via Multi-Source Knowledge Integration](https://arxiv.org/abs/2510.15267)
*Mucheng Ren,He Chen,Yuchen Yan,Danqing Hu,Jun Xu,Xian Zeng*

Main category: cs.CL

TL;DR: TraceCoder improves automated ICD coding by integrating multiple knowledge sources and enhancing code representation, achieving superior performance and interpretability.


<details>
  <summary>Details</summary>
Motivation: To enhance traceability and explainability in automated ICD coding due to existing challenges such as semantic gaps, poor performance on rare codes, and limited interpretability.

Method: TraceCoder framework integrating multi-source external knowledge

Result: Achieved state-of-the-art performance on MIMIC-III-ICD9, MIMIC-IV-ICD9, and MIMIC-IV-ICD10 datasets, validated through ablation studies.

Conclusion: TraceCoder provides a scalable, robust, and clinically relevant solution for automated ICD coding, addressing critical challenges.

Abstract: Automated International Classification of Diseases (ICD) coding assigns
standardized diagnosis and procedure codes to clinical records, playing a
critical role in healthcare systems. However, existing methods face challenges
such as semantic gaps between clinical text and ICD codes, poor performance on
rare and long-tail codes, and limited interpretability. To address these
issues, we propose TraceCoder, a novel framework integrating multi-source
external knowledge to enhance traceability and explainability in ICD coding.
TraceCoder dynamically incorporates diverse knowledge sources, including UMLS,
Wikipedia, and large language models (LLMs), to enrich code representations,
bridge semantic gaps, and handle rare and ambiguous codes. It also introduces a
hybrid attention mechanism to model interactions among labels, clinical
context, and knowledge, improving long-tail code recognition and making
predictions interpretable by grounding them in external evidence. Experiments
on MIMIC-III-ICD9, MIMIC-IV-ICD9, and MIMIC-IV-ICD10 datasets demonstrate that
TraceCoder achieves state-of-the-art performance, with ablation studies
validating the effectiveness of its components. TraceCoder offers a scalable
and robust solution for automated ICD coding, aligning with clinical needs for
accuracy, interpretability, and reliability.

</details>


### [88] [TACL: Threshold-Adaptive Curriculum Learning Strategy for Enhancing Medical Text Understanding](https://arxiv.org/abs/2510.15269)
*Mucheng Ren,Yucheng Yan,He Chen,Danqing Hu,Jun Xu,Xian Zeng*

Main category: cs.CL

TL;DR: 提出了一个新的框架TACL，通过动态调整训练过程，根据样本复杂性分类数据，优先处理简单案例，从而提升医学文本的理解。


<details>
  <summary>Details</summary>
Motivation: 医学文本的非结构化特性及其复杂性对自动理解带来了挑战，现有方法忽视了记录间的复杂性差异。

Method: TACL通过根据样本复杂性动态调整训练过程，分类数据并优先处理简单案例。

Result: 在多语言医学数据应用中，TACL显著提升了自动ICD编码、再入院预测和中医症候群辨别等多种临床任务的表现。

Conclusion: TACL能够有效提升自动系统的性能，并为跨医学领域的统一方法提供了可能性。

Abstract: Medical texts, particularly electronic medical records (EMRs), are a
cornerstone of modern healthcare, capturing critical information about patient
care, diagnoses, and treatments. These texts hold immense potential for
advancing clinical decision-making and healthcare analytics. However, their
unstructured nature, domain-specific language, and variability across contexts
make automated understanding an intricate challenge. Despite the advancements
in natural language processing, existing methods often treat all data as
equally challenging, ignoring the inherent differences in complexity across
clinical records. This oversight limits the ability of models to effectively
generalize and perform well on rare or complex cases. In this paper, we present
TACL (Threshold-Adaptive Curriculum Learning), a novel framework designed to
address these challenges by rethinking how models interact with medical texts
during training. Inspired by the principle of progressive learning, TACL
dynamically adjusts the training process based on the complexity of individual
samples. By categorizing data into difficulty levels and prioritizing simpler
cases early in training, the model builds a strong foundation before tackling
more complex records. By applying TACL to multilingual medical data, including
English and Chinese clinical records, we observe significant improvements
across diverse clinical tasks, including automatic ICD coding, readmission
prediction and TCM syndrome differentiation. TACL not only enhances the
performance of automated systems but also demonstrates the potential to unify
approaches across disparate medical domains, paving the way for more accurate,
scalable, and globally applicable medical text understanding solutions.

</details>


### [89] [Exemplar-Guided Planing: Enhanced LLM Agent for KGQA](https://arxiv.org/abs/2510.15283)
*Jingao Xu,Shuoyoucheng Ma,Xin Song,Rong Jiang,Hongkui Tu,Bin Zhou*

Main category: cs.CL

TL;DR: 提出了示例引导规划（EGP）框架，以提升大型语言模型在知识图谱问答的规划能力，实验结果表明其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在知识图谱问答中面临的语义差距和低效探索问题。

Method: 通过实体模板化和语义嵌入检索相似示例问题，动态指导LLM的规划，结合智能前瞻机制提升效率。

Result: 本论文提出了一种名为"示例引导规划（EGP）"的框架，以提升大型语言模型（LLMs）在知识图谱问答（KGQA）中的规划能力。EGP 通过实体模板化处理训练集问题，以标准化语义变体，然后使用语义嵌入和高效的 FAISS 索引检索相似的示例问题及其成功的推理路径。这些示例在两个关键阶段动态指导 LLM 的规划过程：任务分解和关系探索。此外，引入了智能前瞻机制，以提高关系探索的效率。实验结果表明，PoG-EGP 在 WebQSP 和 CWQ 数据集上的表现显著优于基线 PoG 系统和其他方法。

Conclusion: EGP框架显著提高了知识图谱问答的效率和准确性，尤其在任务分解和关系探索阶段。

Abstract: Large Language Models (LLMs) as interactive agents show significant promise
in Knowledge Graph Question Answering (KGQA) but often struggle with the
semantic gap between natural language queries and structured knowledge graph
(KG) representations. This leads to suboptimal planning and inefficient
exploration on KG, while training-free approaches often underutilize valuable
reasoning patterns in training data. To address these limitations, we propose a
novel framework, Exemplar-Guided Planning (EGP), which enhances the planning
capabilities of LLM agents for KGQA. EGP first preprocesses the training set
questions via entity templating to normalize semantic variations. It then
retrieves highly similar exemplary questions and their successful reasoning
paths from this preprocessed set using semantic embeddings and an efficient
FAISS index. These retrieved exemplars dynamically guide the LLM's planning
process in two key phases: (1) Task Decomposition, by aligning generated
sub-objectives with proven reasoning steps, and (2) Relation Exploration, by
providing high-quality auxiliary information to improve relation pruning
accuracy. Additionally, we introduce a Smart Lookahead mechanism during
relation exploration to improve efficiency by preemptively exploring promising
paths and potentially terminating exploration earlier. We apply EGP to the
Plan-on-Graph (PoG) framework, termed PoG-EGP. Extensive experiments on two
real-world KGQA datasets, WebQSP and CWQ, demonstrate that PoG-EGP
significantly improves over the baseline PoG system and other compared methods.

</details>


### [90] [Accelerating Mobile Language Model Generation via Hybrid Context and Hardware Coordination](https://arxiv.org/abs/2510.15312)
*Zhiyang Chen,Daliang Xu,Haiyang Shen,Mengwei Xu,Shangguang Wang,Yun Ma*

Main category: cs.CL

TL;DR: 提出了一种新的移动推理框架CoordGen，通过结合预测解码和动态硬件调度，显著提高了文本生成的速度和能效。


<details>
  <summary>Details</summary>
Motivation: 提升移动设备上大型语言模型的生成效率以实现个性化和任务感知的文本生成，解决生成过程中高延迟和硬件利用率低的问题。

Method: 商用推理框架CoordGen

Result: 在多款智能手机上进行实验证明，CoordGen在生成速度上提升了最高3.8倍，能源效率提高了4.7倍。

Conclusion: CoordGen通过三个主要组件的协同作用，显著提高移动设备上上下文感知文本生成的性能，验证了各项优化的有效性。

Abstract: Enhancing on-device large language models (LLMs) with contextual information
from local data enables personalized and task-aware generation, powering use
cases such as intelligent assistants and UI agents. While recent developments
in neural processors have substantially improved the efficiency of prefill on
mobile devices, the token-by-token generation process still suffers from high
latency and limited hardware utilization due to its inherently memory-bound
characteristics. This work presents CoordGen, a mobile inference framework that
integrates speculative decoding with dynamic hardware scheduling to accelerate
context-aware text generation on mobile devices. The framework introduces three
synergistic components: (1) adaptive execution scheduling, which dynamically
balances compute graphs between prefill and decoding phases; (2)
context-aligned drafting, which improves speculative efficiency through
lightweight online calibration to current tasks; and (3) hardware-efficient
draft extension, which reuses and expands intermediate sequences to improve
processing parallelism and reduce verification cost. Experiments on multiple
smartphones and representative workloads show consistent improvements of up to
3.8x in generation speed and 4.7x in energy efficiency compared with existing
mobile inference solutions. Component-level analysis further validates the
contribution of each optimization.

</details>


### [91] [Capabilities and Evaluation Biases of Large Language Models in Classical Chinese Poetry Generation: A Case Study on Tang Poetry](https://arxiv.org/abs/2510.15313)
*Bolei Ma,Yina Yao,Anna-Carolina Haensch*

Main category: cs.CL

TL;DR: 本研究提出了一个评估框架，分析了大语言模型在古典诗歌生成中的表现，发现了其在质量评估上的偏差，并强调了人类与模型结合的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在古典诗歌创作中的表现与评估，以便更好理解其在创意领域的应用。

Method: 提出一个三步评估框架，结合计算指标、LLM评估和人类专家验证。

Result: 对六种最先进的大语言模型进行评估，发现它们在诗歌质量的多维度上存在生成和评估偏差。

Conclusion: 当前大语言模型在古典诗歌生成和评估中的表现存在系统性偏差，既展现了其潜力，也揭示了其局限性，强调了人类与模型结合的验证必要性。

Abstract: Large Language Models (LLMs) are increasingly applied to creative domains,
yet their performance in classical Chinese poetry generation and evaluation
remains poorly understood. We propose a three-step evaluation framework that
combines computational metrics, LLM-as-a-judge assessment, and human expert
validation. Using this framework, we evaluate six state-of-the-art LLMs across
multiple dimensions of poetic quality, including themes, emotions, imagery,
form, and style. Our analysis reveals systematic generation and evaluation
biases: LLMs exhibit "echo chamber" effects when assessing creative quality,
often converging on flawed standards that diverge from human judgments. These
findings highlight both the potential and limitations of current capabilities
of LLMs as proxy for literacy generation and the limited evaluation practices,
thereby demonstrating the continued need of hybrid validation from both humans
and models in culturally and technically complex creative tasks.

</details>


### [92] [AutoGraph-R1: End-to-End Reinforcement Learning for Knowledge Graph Construction](https://arxiv.org/abs/2510.15339)
*Hong Ting Tsang,Jiaxin Bai,Haoyu Huang,Qiao Xiao,Tianshi Zheng,Baixuan Xu,Shujie Liu,Yangqiu Song*

Main category: cs.CL

TL;DR: AutoGraph-R1是一个通过强化学习优化知识图谱构建以提升问答系统性能的框架，能够通过设计特定的奖励函数，显著提高检索增强生成方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决知识图谱构建与其在下游应用中的不匹配问题，从而提升问答系统的整体性能。

Method: 通过将图生成形式化为一个策略学习问题，利用强化学习训练大型语言模型（LLM）构造器，以及设计任务感知的奖励函数进行优化。

Result: 本文提出了一种名为AutoGraph-R1的新框架，旨在通过强化学习（RL）优化知识图谱（KG）的构建，以提升检索增强生成（RAG）系统在问答（QA）任务中的表现。研究强调了当前KG构建过程与其下游应用之间的脱节，导致生成的图结构不理想。AutoGraph-R1通过将图生成视为一个策略学习问题，训练大型语言模型（LLM）构造器，并设计了两种新颖的、任务感知的奖励函数，以分别评估知识载体和知识索引的功能效用。实验结果显示，AutoGraph-R1在多个QA基准上显著提高了图RAG方法的性能，验证了在构建中应用的闭环思维，从构造内在“良好”图形转向构建明确“有用”的图形。

Conclusion: AutoGraph-R1有效桥接了知识图谱的构建与其应用之间的差距，展示了构建有用图谱的潜力。

Abstract: Building effective knowledge graphs (KGs) for Retrieval-Augmented Generation
(RAG) is pivotal for advancing question answering (QA) systems. However, its
effectiveness is hindered by a fundamental disconnect: the knowledge graph (KG)
construction process is decoupled from its downstream application, yielding
suboptimal graph structures. To bridge this gap, we introduce AutoGraph-R1, the
first framework to directly optimize KG construction for task performance using
Reinforcement Learning (RL). AutoGraph-R1 trains an LLM constructor by framing
graph generation as a policy learning problem, where the reward is derived from
the graph's functional utility in a RAG pipeline. We design two novel,
task-aware reward functions, one for graphs as knowledge carriers and another
as knowledge indices. Across multiple QA benchmarks, AutoGraph-R1 consistently
enables graph RAG methods to achieve significant performance gains over using
task-agnostic baseline graphs. Our work shows it is possible to close the loop
between construction and application, shifting the paradigm from building
intrinsically ``good'' graphs to building demonstrably ``useful'' ones.

</details>


### [93] [Readability Reconsidered: A Cross-Dataset Analysis of Reference-Free Metrics](https://arxiv.org/abs/2510.15345)
*Catarina G Belem,Parker Glenn,Alfy Samuel,Anoop Kumar,Daben Liu*

Main category: cs.CL

TL;DR: 本研究揭示可读性指标与人类感知之间的差距，支持使用模型基于的方法。


<details>
  <summary>Details</summary>
Motivation: 为了提升书面沟通的有效性和可及性，分析人类对可读性的感知因素并评估现有的可读性指标。

Method: 分析897个判断，探讨影响人类可读性感知的因素，并评估15种传统可读性指标与6种模型基于指标的表现。

Result: 四种基于模型的可读性指标在与人类判断的排名相关性中 consistently 位于前四名，传统最佳指标的平均排名为8.6。

Conclusion: 研究结果显示，传统的可读性测量指标与人类的可读性感知之间存在不匹配，模型基于的方法是更有前景的方向。

Abstract: Automatic readability assessment plays a key role in ensuring effective and
accessible written communication. Despite significant progress, the field is
hindered by inconsistent definitions of readability and measurements that rely
on surface-level text properties. In this work, we investigate the factors
shaping human perceptions of readability through the analysis of 897 judgments,
finding that, beyond surface-level cues, information content and topic strongly
shape text comprehensibility. Furthermore, we evaluate 15 popular readability
metrics across five English datasets, contrasting them with six more nuanced,
model-based metrics. Our results show that four model-based metrics
consistently place among the top four in rank correlations with human
judgments, while the best performing traditional metric achieves an average
rank of 8.6. These findings highlight a mismatch between current readability
metrics and human perceptions, pointing to model-based approaches as a more
promising direction.

</details>


### [94] [When to Ensemble: Identifying Token-Level Points for Stable and Fast LLM Ensembling](https://arxiv.org/abs/2510.15346)
*Heecheol Yun,Kwangmin Ki,Junghyun Lee,Eunho Yang*

Main category: cs.CL

TL;DR: 本文提出SAFE框架，优化大规模语言模型的长文本生成集成方法，显著提升了生成效果与效率。


<details>
  <summary>Details</summary>
Motivation: 探索大规模语言模型（LLMs）在长文本生成中的集成应用，并克服现有方法在每个代币处集成带来的性能下降问题。

Method: 提出了一种选择性集成的方法SAFE，结合了模型代币化的不一致性和下一个代币概率分布的共识。

Result: SAFE框架通过优化集成策略和引入概率锐化策略，提高了文本生成的稳定性和效率，在多个基准测试中超越了现有方法的准确性。

Conclusion: 实验结果表明SAFE方法在准确性和效率上优于其他集成方法，尤其在处理少于1%代币时仍能取得显著提升。

Abstract: Ensembling Large Language Models (LLMs) has gained attention as a promising
approach to surpass the performance of individual models by leveraging their
complementary strengths. In particular, aggregating models' next-token
probability distributions to select the next token has been shown to be
effective in various tasks. However, while successful for short-form answers,
its application to long-form generation remains underexplored. In this paper,
we show that using existing ensemble methods in long-form generation requires a
careful choice of ensembling positions, since the standard practice of
ensembling at every token often degrades performance. We identify two key
factors for determining these positions: tokenization mismatch across models
and consensus in their next-token probability distributions. Based on this, we
propose SAFE, (Stable And Fast LLM Ensembling), a framework that selectively
ensembles by jointly considering these factors. To further improve stability,
we introduce a probability sharpening strategy that consolidates probabilities
spread across multiple sub-word tokens representing the same word into a single
representative token. Our experiments on diverse benchmarks, including MATH500
and BBH, demonstrate that SAFE outperforms existing methods in both accuracy
and efficiency, with gains achieved even when ensembling fewer than 1% of
tokens.

</details>


### [95] [Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing](https://arxiv.org/abs/2510.15349)
*Baode Wang,Biao Wu,Weizhen Li,Meng Fang,Zuming Huang,Jun Huang,Haozhe Wang,Yanjie Liang,Ling Chen,Wei Chu,Yuan Qi*

Main category: cs.CL

TL;DR: 本文介绍了一种名为LayoutRL的强化学习框架，用于提高文件解析的布局理解能力，基于Infinity-Doc-400K数据集训练的Infinity-Parser模型在各种文档类型上表现优越。


<details>
  <summary>Details</summary>
Motivation: 针对传统监督微调方法在多样文档类型下的表现不佳问题，以及高质量训练数据的稀缺，提出新的解决方案。

Method: 采用强化学习框架，通过综合奖励优化布局理解，训练Infinity-Parser模型。

Result: Infinity-Parser在OmniDocBench、olmOCR-Bench、PubTabNet和FinTabNet等基准评测上，表现出比专门化解析系统和通用视觉语言模型更优秀的性能。

Conclusion: Infinity-Parser在各种评估基准上表现出色，展示了其对多样文档类型的强大泛化能力，为文档解析领域提供了有效的解决方案。

Abstract: Document parsing from scanned images into structured formats remains a
significant challenge due to its complexly intertwined elements such as text
paragraphs, figures, formulas, and tables. Existing supervised fine-tuning
methods often struggle to generalize across diverse document types, leading to
poor performance, particularly on out-of-distribution data. This issue is
further exacerbated by the limited availability of high-quality training data
for layout-aware parsing tasks. To address these challenges, we introduce
LayoutRL, a reinforcement learning framework that optimizes layout
understanding through composite rewards integrating normalized edit distance,
paragraph count accuracy, and reading order preservation. To support this
training, we construct the Infinity-Doc-400K dataset, which we use to train
Infinity-Parser, a vision-language model demonstrating robust generalization
across various domains. Extensive evaluations on benchmarks including
OmniDocBench, olmOCR-Bench, PubTabNet, and FinTabNet show that Infinity-Parser
consistently achieves state-of-the-art performance across a broad range of
document types, languages, and structural complexities, substantially
outperforming both specialized document parsing systems and general-purpose
vision-language models. We will release our code, dataset, and model to
facilitate reproducible research in document parsing.

</details>


### [96] [VocalBench-DF: A Benchmark for Evaluating Speech LLM Robustness to Disfluency](https://arxiv.org/abs/2510.15406)
*Hongcheng Liu,Yixuan Hou,Heyang Liu,Yuhao Wang,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 本研究探讨了言语大型语言模型在处理言语不流畅时的表现，发现其鲁棒性不足，并引入了新评估框架和改进建议。


<details>
  <summary>Details</summary>
Motivation: 评估现有的言语大型语言模型在面对言语障碍用户时的表现和鲁棒性

Method: 引入VocalBench-DF框架以系统化地评估言语流畅性

Result: 对22种主流言语大型语言模型的评估显示，性能明显下降，表明其在现实世界中的适用性有限

Conclusion: 必须开发新的方法以增强对言语不流畅的处理能力，从而构建真正包容的言语大型语言模型。

Abstract: While Speech Large Language Models (Speech-LLMs) show strong performance in
many applications, their robustness is critically under-tested, especially to
speech disfluency. Existing evaluations often rely on idealized inputs,
overlooking common disfluencies, particularly those associated with conditions
like Parkinson's disease. This work investigates whether current Speech-LLMs
can maintain performance when interacting with users who have speech
impairments. To facilitate this inquiry, we introduce VocalBench-DF, a
framework for the systematic evaluation of disfluency across a
multi-dimensional taxonomy. Our evaluation of 22 mainstream Speech-LLMs reveals
substantial performance degradation, indicating that their real-world readiness
is limited. Further analysis identifies phoneme-level processing and
long-context modeling as primary bottlenecks responsible for these failures.
Strengthening recognition and reasoning capability from components and
pipelines can substantially improve robustness. These findings highlight the
urgent need for new methods to improve disfluency handling and build truly
inclusive Speech-LLMs

</details>


### [97] [Large-scale User Game Lifecycle Representation Learning](https://arxiv.org/abs/2510.15412)
*Yanjie Gou,Jiangming Liu,Kouying Xue,Yi Hua*

Main category: cs.CL

TL;DR: 本文提出了一种新的用户游戏生命周期（UGL）模型和策略，以解决视频游戏广告和推荐中的稀疏性与不平衡性问题，从而提升用户兴趣捕捉的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着视频游戏生产的快速扩展，现有的推荐系统在游戏广告和推荐方面存在稀疏性和不平衡性的问题，急需有效的解决方案。

Method: 提出用户游戏生命周期（UGL）模型，通过操控用户行为来提取用户的短期和长期兴趣，并引入逆概率掩码策略用于UGL表示学习。

Result: 离线实验中，AUC平均提升1.83%；在线实验中，CVR平均提升21.67%；游戏内物品推荐的AUC平均提升0.5%，ARPU平均提升0.82%。

Conclusion: UGL表示在游戏广告和游戏内物品推荐中有效提升了模型性能，并在离线和在线测试中均显示出显著的提升。

Abstract: The rapid expansion of video game production necessitates the development of
effective advertising and recommendation systems for online game platforms.
Recommending and advertising games to users hinges on capturing their interest
in games. However, existing representation learning methods crafted for
handling billions of items in recommendation systems are unsuitable for game
advertising and recommendation. This is primarily due to game sparsity, where
the mere hundreds of games fall short for large-scale user representation
learning, and game imbalance, where user behaviors are overwhelmingly dominated
by a handful of popular games. To address the sparsity issue, we introduce the
User Game Lifecycle (UGL), designed to enrich user behaviors in games.
Additionally, we propose two innovative strategies aimed at manipulating user
behaviors to more effectively extract both short and long-term interests. To
tackle the game imbalance challenge, we present an Inverse Probability Masking
strategy for UGL representation learning. The offline and online experimental
results demonstrate that the UGL representations significantly enhance model by
achieving a 1.83% AUC offline increase on average and a 21.67% CVR online
increase on average for game advertising and a 0.5% AUC offline increase and a
0.82% ARPU online increase for in-game item recommendation.

</details>


### [98] [Fine-Tuning MedGemma for Clinical Captioning to Enhance Multimodal RAG over Malaysia CPGs](https://arxiv.org/abs/2510.15418)
*Lee Qi Zun,Mohamad Zulhilmi Bin Abdul Halim,Goh Man Fye*

Main category: cs.CL

TL;DR: 本研究提出一种框架，专门化MedGemma模型以生成高质量医学图像描述，并验证其在分类准确性和描述可靠性上的显著改善。


<details>
  <summary>Details</summary>
Motivation: 提高基于图像的查询的效果，以克服一般视觉语言模型在临床特定性和事实基础上的局限性。

Method: 通过知识蒸馏管道创建合成数据集，并使用QLoRA方法对MedGemma进行精细调优，采用双框架评估性能。

Result: 经过调优的模型在分类性能上有显著改善，RAGAS评估确认在描述的可靠性和正确性上也有显著提升。

Conclusion: 本研究建立了一个稳健的流程，为医学视觉语言模型的专门化提供了基础，验证了该模型作为高质量查询生成器的能力。

Abstract: Retrieval-Augmented Generation systems are essential for providing fact-based
guidance from Malaysian Clinical Practice Guidelines. However, their
effectiveness with image-based queries is limited, as general Vision-Language
Model captions often lack clinical specificity and factual grounding. This
study proposes and validates a framework to specialize the MedGemma model for
generating high-fidelity captions that serve as superior queries. To overcome
data scarcity, we employ a knowledge distillation pipeline to create a
synthetic dataset across dermatology, fundus, and chest radiography domains,
and fine-tune MedGemma using the parameter-efficient QLoRA method. Performance
was rigorously assessed through a dual framework measuring both classification
accuracy and, via a novel application of the RAGAS framework, caption
faithfulness, relevancy, and correctness. The fine-tuned model demonstrated
substantial improvements in classification performance, while RAGAS evaluation
confirmed significant gains in caption faithfulness and correctness, validating
the models ability to produce reliable, factually grounded descriptions. This
work establishes a robust pipeline for specializing medical VLMs and validates
the resulting model as a high-quality query generator, laying the groundwork
for enhancing multimodal RAG systems in evidence-based clinical decision
support.

</details>


### [99] [When Seeing Is not Enough: Revealing the Limits of Active Reasoning in MLLMs](https://arxiv.org/abs/2510.15421)
*Hongcheng Liu,Pingjie Wang,Yuhao Wang,Siqu Ou,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 多模态大语言模型在主动推理中表现较差，提出GuessBench基准以评估其在不完全信息下的推理能力，未来研究应关注提高此能力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在填补多模态大语言模型在主动推理能力上的空白，因为现有评估主要集中于完全信息下的被动推理。

Method: 本研究提出了GuessBench基准，通过选择候选图像，要求模型在不完全信息的情况下主动获取缺失证据，并迭代地优化决策。

Result: 对20种优秀的多模态大语言模型进行的评估显示，主动推理的表现远低于被动推理，并指出细致感知和及时决策是主要挑战。

Conclusion: 此研究表明，现有的多模态大语言模型在主动推理方面表现不如被动推理，未来需要更多研究来改善这些模型的性能。

Abstract: Multimodal large language models (MLLMs) have shown strong capabilities
across a broad range of benchmarks. However, most existing evaluations focus on
passive inference, where models perform step-by-step reasoning under complete
information. This setup is misaligned with real-world use, where seeing is not
enough. This raises a fundamental question: Can MLLMs actively acquire missing
evidence under incomplete information? To bridge this gap, we require the MLLMs
to actively acquire missing evidence and iteratively refine decisions under
incomplete information, by selecting a target image from a candidate pool
without task-specific priors. To support systematic study, we propose
GuessBench, a benchmark with both perception-oriented and knowledge-oriented
images for evaluating active reasoning in MLLMs. We evaluate 20 superior MLLMs
and find that performance on active reasoning lags far behind it on passive
settings, indicating substantial room for improvement. Further analysis
identifies fine-grained perception and timely decision-making as key
challenges. Ablation studies show that perceptual enhancements benefit smaller
models, whereas thinking-oriented methods provide consistent gains across model
sizes. These results suggest promising directions for future research on
multimodal active reasoning.

</details>


### [100] [Controllable Abstraction in Summary Generation for Large Language Models via Prompt Engineering](https://arxiv.org/abs/2510.15436)
*Xiangchen Song,Yuchen Liu,Yaxuan Luan,Jinxu Guo,Xiaofan Guo*

Main category: cs.CL

TL;DR: 本研究提出了一种基于提示工程的可控摘要生成方法，分析了提示长度和数据噪声对摘要质量的影响，并显示模型在处理新闻文本时表现最佳。


<details>
  <summary>Details</summary>
Motivation: 传统的摘要生成方法在质量和可控性方面存在不足，因此研究需要探索更有效的生成策略。

Method: 通过对输入文本进行语义分析、主题建模和噪声控制，生成不同抽象级别的摘要。

Result: 实验表明，提示长度、数据噪声和文本类型对生成摘要的质量有显著影响，不同文本类型的处理效果不同。

Conclusion: 本研究通过设计多阶段提示生成框架，提出了一种可控的摘要生成方法，改进了大语言模型的摘要质量与可控性。

Abstract: This study presents a controllable abstract summary generation method for
large language models based on prompt engineering. To address the issues of
summary quality and controllability in traditional methods, we design a
multi-stage prompt generation framework. This framework generates summaries
with varying levels of abstraction by performing semantic analysis, topic
modeling, and noise control on the input text. The experiment uses the
CNN/Daily Mail dataset and provides a detailed analysis of different prompt
lengths, data noise, and text types. The experimental results show that prompt
length has a significant impact on the quality of generated summaries. Both
very short and very long prompt tokens result in a decrease in summary quality.
Data noise also negatively affects the summary generation process. As noise
levels increase, the ROUGE-L score gradually decreases. Furthermore, different
text types have varying effects on the model's ability to generate summaries.
The model performs best when handling news texts, while its performance is
worse when processing academic articles. This research provides new insights
into improving summary generation using large language models, particularly in
how controlling prompt strategies and optimizing text preprocessing can enhance
summary accuracy and controllability.

</details>


### [101] [DeceptionBench: A Comprehensive Benchmark for AI Deception Behaviors in Real-world Scenarios](https://arxiv.org/abs/2510.15501)
*Yao Huang,Yitong Sun,Yichi Zhang,Ruochen Zhang,Yinpeng Dong,Xingxing Wei*

Main category: cs.CL

TL;DR: 论文提出DeceptionBench基准，通过150个场景系统评估大语言模型的欺骗行为，包括内在和外在因素的影响，揭示了模型在现实环境中的欺骗脆弱性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在多种认知任务上的进步伴随产生的欺骗行为可能对高风险领域造成严重威胁，而现实世界中欺骗行为的特征仍未得到充分探讨。

Method: 通过设计150个场景在五个领域下对模型表现进行实验，同时考虑内在动机与外在上下文对欺骗行为的影响。

Result: 建立了DeceptionBench基准，通过设计150个场景评估欺骗行为在不同社会领域的表现，揭示了模型在内在和外在因素驱动下的欺骗倾向。

Conclusion: 研究表明，当前的模型在面对 manipulative 的上下文刺激时缺乏有效抵抗，迫切需要建立更先进的保护措施以应对欺骗行为。

Abstract: Despite the remarkable advances of Large Language Models (LLMs) across
diverse cognitive tasks, the rapid enhancement of these capabilities also
introduces emergent deceptive behaviors that may induce severe risks in
high-stakes deployments. More critically, the characterization of deception
across realistic real-world scenarios remains underexplored. To bridge this
gap, we establish DeceptionBench, the first benchmark that systematically
evaluates how deceptive tendencies manifest across different societal domains,
what their intrinsic behavioral patterns are, and how extrinsic factors affect
them. Specifically, on the static count, the benchmark encompasses 150
meticulously designed scenarios in five domains, i.e., Economy, Healthcare,
Education, Social Interaction, and Entertainment, with over 1,000 samples,
providing sufficient empirical foundations for deception analysis. On the
intrinsic dimension, we explore whether models exhibit self-interested egoistic
tendencies or sycophantic behaviors that prioritize user appeasement. On the
extrinsic dimension, we investigate how contextual factors modulate deceptive
outputs under neutral conditions, reward-based incentivization, and coercive
pressures. Moreover, we incorporate sustained multi-turn interaction loops to
construct a more realistic simulation of real-world feedback dynamics.
Extensive experiments across LLMs and Large Reasoning Models (LRMs) reveal
critical vulnerabilities, particularly amplified deception under reinforcement
dynamics, demonstrating that current models lack robust resistance to
manipulative contextual cues and the urgent need for advanced safeguards
against various deception behaviors. Code and resources are publicly available
at https://github.com/Aries-iai/DeceptionBench.

</details>


### [102] [Temporal Referential Consistency: Do LLMs Favor Sequences Over Absolute Time References?](https://arxiv.org/abs/2510.15513)
*Ashutosh Bajpai,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文提出了一种新的基准评估LLMs的时间参考一致性，并提出UnTRaP模型以改善该一致性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在法律、医疗和金融等时间敏感领域的逐渐接受，确保其在时间维度上的一致性成为关键需求。

Method: 引入新的基准——时间参考一致性（temporal referential consistency），以及相应的资源TEMP-ReCon，对开放源代码和闭源的LLMs进行评估。

Result: 实验证明，LLMs在时间引用一致性方面表现不佳，提出的UnTRaP模型在多个基线模型中效果显著。

Conclusion: 大型语言模型在时间参考一致性方面存在不足，提出的UnTRaP模型能够有效提升其时间参考一致性。

Abstract: The increasing acceptance of large language models (LLMs) as an alternative
to knowledge sources marks a significant paradigm shift across various domains,
including time-sensitive fields such as law, healthcare, and finance. To
fulfill this expanded role, LLMs must not only be factually accurate but also
demonstrate consistency across temporal dimensions, necessitating robust
temporal reasoning capabilities. Despite this critical requirement, efforts to
ensure temporal consistency in LLMs remain scarce including noticeable absence
of endeavors aimed at evaluating or augmenting LLMs across temporal references
in time-sensitive inquiries. In this paper, we seek to address this gap by
introducing a novel benchmark entitled temporal referential consistency,
accompanied by a resource TEMP-ReCon designed to benchmark a wide range of both
open-source and closed-source LLMs with various linguistic contexts
characterized by differing resource richness (including English, French, and
Romanian). The findings emphasis that LLMs do exhibit insufficient temporal
referent consistency. To address this, we propose \newmodel, a reasoning path
alignment-based model that aims to enhance the temporal referential consistency
of LLMs. Our empirical experiments substantiate the efficacy of UnTRaP compared
to several baseline models.

</details>


### [103] [From Characters to Tokens: Dynamic Grouping with Hierarchical BPE](https://arxiv.org/abs/2510.15517)
*Rares Dolga,Lucas Maystre,Tudor Berariu,David Barber*

Main category: cs.CL

TL;DR: 本文提出了一种动态字符分组方法，优化现有的BPE标记化，使其在处理稀有词汇时更加高效，且无需额外模型，结果证明可与其他补丁方法媲美。


<details>
  <summary>Details</summary>
Motivation: 探讨现有子词标记化方法在处理稀有词汇时的低效性，以及字符级模型的性能瓶颈，提出一种新的动态字符分组方法以优化词汇表示方式。

Method: 通过在BPE标记中引入补丁结束标记并实施第二级BPE压缩阶段，来实现动态字符分组，优化标记化过程。

Result: 提出的动态字符分组方法通过在BPE标记中附加明确的补丁结束标记，并引入第二级BPE压缩阶段来控制补丁粒度，最终证明在性能方面匹配或超过了以动态熵和空格为基础的现有补丁策略，同时保持紧凑的词汇表。

Conclusion: 该方法提供了高效、灵活且适用于多种语言的表示方式，有助于提升大型语言模型的性能。

Abstract: Subword tokenization methods like Byte Pair Encoding (BPE) are widely used in
large language models due to their balance of vocabulary compactness and
representational power. However, they suffer from inefficiencies in
representing rare words and require large embedding matrices. Character-level
models address these issues but introduce performance bottlenecks, particularly
in Transformer-based architectures. Recent hierarchical models attempt to merge
the benefits of both paradigms by grouping characters into patches, but
existing patching strategies either rely on whitespace-limiting applicability
to certain languages, or require auxiliary models that introduce new
dependencies. In this paper, we propose a dynamic character grouping method
that leverages the structure of existing BPE tokenization without requiring
additional models. By appending explicit end-of-patch markers to BPE tokens and
introducing a second-level BPE compression stage to control patch granularity,
our method offers efficient, flexible, and language-agnostic representations.
Empirical results demonstrate that our approach matches or exceeds the
performance of dynamic entropy- and whitespace-based patching strategies, while
maintaining a compact vocabulary.

</details>


### [104] [TokenTiming: A Dynamic Alignment Method for Universal Speculative Decoding Model Pairs](https://arxiv.org/abs/2510.15545)
*Sibo Xiao,Jinyuan Fu,Zhongle Xie,Lidan Shou*

Main category: cs.CL

TL;DR: 提出TokenTiming算法，解决了推测解码的词汇匹配限制，实现更高效的LLM推断，实验结果显示1.57倍加速。


<details>
  <summary>Details</summary>
Motivation: 为了解决推测解码在大语言模型推断效率提高过程中的词汇匹配限制问题。

Method: 使用动态时间规整（DTW）算法来构建映射，转移概率分布用于推测采样。

Result: 通过全面的实验，该方法在不同任务上实现了1.57倍的加速。

Conclusion: 提出的TokenTiming算法可以通过重新编码草稿token序列，从而在不需要重新训练和修改的情况下，支持词汇不匹配的通用推测解码。

Abstract: Accelerating the inference of large language models (LLMs) has been a
critical challenge in generative AI. Speculative decoding (SD) substantially
improves LLM inference efficiency. However, its utility is limited by a
fundamental constraint: the draft and target models must share the same
vocabulary, thus limiting the herd of available draft models and often
necessitating the training of a new model from scratch. Inspired by Dynamic
Time Warping (DTW), a classic algorithm for aligning time series, we propose
the algorithm TokenTiming for universal speculative decoding. It operates by
re-encoding the draft token sequence to get a new target token sequence, and
then uses DTW to build a mapping to transfer the probability distributions for
speculative sampling. Benefiting from this, our method accommodates mismatched
vocabularies and works with any off-the-shelf models without retraining and
modification. We conduct comprehensive experiments on various tasks,
demonstrating 1.57x speedup. This work enables a universal approach for draft
model selection, making SD a more versatile and practical tool for LLM
acceleration.

</details>


### [105] [Rethinking Cross-lingual Gaps from a Statistical Viewpoint](https://arxiv.org/abs/2510.15551)
*Vihari Piratla,Purvam Jain,Darshan Singh,Partha Talukdar,Trevor Cohn*

Main category: cs.CL

TL;DR: 研究表明，在多语言环境中，目标语言的响应方差是导致知识查询准确性下降的主要原因，提出降低方差的策略可显著提升目标语言准确性。


<details>
  <summary>Details</summary>
Motivation: 我们的研究动机是识别和解决当前大语言模型在跨语言知识查询中存在的准确性下降问题。

Method: 本文使用了偏差-方差分解的方法，进行大量实验验证，并通过多种推断过程干预控制响应方差。

Result: 本文探讨了跨语言知识查询中的准确性下降现象，提出响应方差是导致这一现象的主要原因，并进行了实验证明。我们通过偏差-方差分解形式化了跨语言差距，并提出了一种简单的提示指令，用以降低响应方差，从而提高目标语言的准确性。

Conclusion: 通过控制响应方差，我们可以有效减少跨语言知识查询中的准确性差距。

Abstract: Any piece of knowledge is usually expressed in one or a handful of natural
languages on the web or in any large corpus. Large Language Models (LLMs) act
as a bridge by acquiring knowledge from a source language and making it
accessible when queried from target languages. Prior research has pointed to a
cross-lingual gap, viz., a drop in accuracy when the knowledge is queried in a
target language compared to when the query is in the source language. Existing
research has rationalized divergence in latent representations in source and
target languages as the source of cross-lingual gap. In this work, we take an
alternative view and hypothesize that the variance of responses in the target
language is the main cause of this gap. For the first time, we formalize the
cross-lingual gap in terms of bias-variance decomposition. We present extensive
experimental evidence which support proposed formulation and hypothesis. We
then reinforce our hypothesis through multiple inference-time interventions
that control the variance and reduce the cross-lingual gap. We demonstrate a
simple prompt instruction to reduce the response variance, which improved
target accuracy by 20-25% across different models.

</details>


### [106] [Think Parallax: Solving Multi-Hop Problems via Multi-View Knowledge-Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2510.15552)
*Jinliang Liu*

Main category: cs.CL

TL;DR: ParallaxRAG框架通过头部专业化改善了大语言模型的多跳推理能力，表现出色并减少错误。


<details>
  <summary>Details</summary>
Motivation: 针对大语言模型在多跳推理上的不足，提出基于知识图谱的检索增强生成方法，以期提高推理准确性和稳定性。

Method: 提出了ParallaxRAG框架，通过对查询和图三元组的对称解耦，引入多视角空间，以构建稳健的检索架构，强调头部多样性并限制弱相关路径。

Result: 在WebQSP和CWQ数据集上的实验表明，ParallaxRAG在检索和问答任务中具有竞争力的表现，同时减少了幻觉现象并良好地泛化。

Conclusion: ParallaxRAG通过多视角头部专业化显著提升了知识基础的多跳推理能力，在检索和问答性能上表现优异，同时减少了幻觉现象并具备良好的泛化能力。

Abstract: Large language models (LLMs) excel at language understanding but often
hallucinate and struggle with multi-hop reasoning. Knowledge-graph-based
retrieval-augmented generation (KG-RAG) offers grounding, yet most methods rely
on flat embeddings and noisy path exploration. We propose ParallaxRAG, a
framework that symmetrically decouples queries and graph triples into
multi-view spaces, enabling a robust retrieval architecture that explicitly
enforces head diversity while constraining weakly related paths. Central to our
approach is the observation that different attention heads specialize in
semantic relations at distinct reasoning stages, contributing to different hops
of the reasoning chain. This specialization allows ParallaxRAG to construct
cleaner subgraphs and guide LLMs through grounded, step-wise reasoning.
Experiments on WebQSP and CWQ, under our unified, reproducible setup (BGE-M3 +
Llama3.1-8B), demonstrate competitive retrieval and QA performance, alongside
reduced hallucination and good generalization. Our results highlight multi-view
head specialization as a principled direction for knowledge-grounded multi-hop
reasoning. Our implementation will be released as soon as the paper is
accepted.

</details>


### [107] [KITE: A Benchmark for Evaluating Korean Instruction-Following Abilities in Large Language Models](https://arxiv.org/abs/2510.15558)
*Dongjun Kim,Chanhee Park,Chanjun Park,Heuiseok Lim*

Main category: cs.CL

TL;DR: 本文介绍了KITE，一个用于评估韩语指令遵循能力的新基准，旨在促进跨文化和语言的LLM发展。


<details>
  <summary>Details</summary>
Motivation: 当前的评估主要集中于英语模型，忽视了非英语语言的指令遵循能力，尤其是韩语，缺乏专门的评估基准。

Method: 建立一个综合的评估管道，结合自动化指标与人类评估，以评估一般和特定于韩语的指令遵循能力。

Result: 本文提出了一个新的评估基准——韩语指令遵循任务评估（KITE），旨在填补现有评估中缺乏韩语特定的指令遵循能力测试的空白。KITE专注于开放式指令任务，而不是仅限于事实知识或多项选择测试。通过结合自动化指标和人类评估，该基准揭示了模型性能的差异，并提供了对它们优缺点的深入洞察。

Conclusion: KITE基准的发布将推动对包括韩语在内的不足语言的LLM研究，促进更具文化和语言包容性的模型开发。

Abstract: The instruction-following capabilities of large language models (LLMs) are
pivotal for numerous applications, from conversational agents to complex
reasoning systems. However, current evaluations predominantly focus on English
models, neglecting the linguistic and cultural nuances of other languages.
Specifically, Korean, with its distinct syntax, rich morphological features,
honorific system, and dual numbering systems, lacks a dedicated benchmark for
assessing open-ended instruction-following capabilities. To address this gap,
we introduce the Korean Instruction-following Task Evaluation (KITE), a
comprehensive benchmark designed to evaluate both general and Korean-specific
instructions. Unlike existing Korean benchmarks that focus mainly on factual
knowledge or multiple-choice testing, KITE directly targets diverse, open-ended
instruction-following tasks. Our evaluation pipeline combines automated metrics
with human assessments, revealing performance disparities across models and
providing deeper insights into their strengths and weaknesses. By publicly
releasing the KITE dataset and code, we aim to foster further research on
culturally and linguistically inclusive LLM development and inspire similar
endeavors for other underrepresented languages.

</details>


### [108] [Finetuning LLMs for EvaCun 2025 token prediction shared task](https://arxiv.org/abs/2510.15561)
*Josef Jon,Ondřej Bojar*

Main category: cs.CL

TL;DR: 本论文针对EvaCun 2025的token预测任务，使用不同的LLMs模型进行评估，并比较了三种预测方法。


<details>
  <summary>Details</summary>
Motivation: 通过比较不同提示的方法来提高token预测任务的性能。

Method: 使用基于LLMs（Command-R, Mistral, 和Aya Expanse）的系统，并仅使用提供的训练数据进行简化的测试。

Result: 在持出数据集上比较了三种不同的预测方法。

Conclusion: 该论文展示了对EvaCun 2025的token预测任务的提交，提出了三种基于不同提示的预测方法，并在持出数据集上进行了评估。

Abstract: In this paper, we present our submission for the token prediction task of
EvaCun 2025. Our sys-tems are based on LLMs (Command-R, Mistral, and Aya
Expanse) fine-tuned on the task data provided by the organizers. As we only
pos-sess a very superficial knowledge of the subject field and the languages of
the task, we simply used the training data without any task-specific
adjustments, preprocessing, or filtering. We compare 3 different approaches
(based on 3 different prompts) of obtaining the predictions, and we evaluate
them on a held-out part of the data.

</details>


### [109] [From Ghazals to Sonnets: Decoding the Polysemous Expressions of Love Across Languages](https://arxiv.org/abs/2510.15569)
*Syed Mohammad Sualeh Ali*

Main category: cs.CL

TL;DR: 本研究通过分析乌尔都诗歌中的爱词，探讨了多义性及其文化内涵，提供了对乌尔都诗歌深刻理解的视角。


<details>
  <summary>Details</summary>
Motivation: 探索乌尔都诗歌中爱这一主题的深度，理解语言之间表达情感的细微差别。

Method: 采用多义词案例研究的方法，分析三词在乌尔都诗歌中的用法与语境，并进行词嵌入的比较分析。

Result: 通过分析，我们发现了乌尔都语中关于爱的词汇在语义空间内的不同，并揭示了其在英语文学中缺乏直接对应的独特内涵。

Conclusion: 本研究揭示了乌尔都诗歌中关于爱的复杂表达，尤其是三个同义词之间的细微差别。

Abstract: This paper delves into the intricate world of Urdu poetry, exploring its
thematic depths through a lens of polysemy. By focusing on the nuanced
differences between three seemingly synonymous words (pyaar, muhabbat, and
ishq) we expose a spectrum of emotions and experiences unique to the Urdu
language. This study employs a polysemic case study approach, meticulously
examining how these words are interwoven within the rich tapestry of Urdu
poetry. By analyzing their usage and context, we uncover a hidden layer of
meaning, revealing subtle distinctions which lack direct equivalents in English
literature. Furthermore, we embark on a comparative analysis, generating word
embeddings for both Urdu and English terms related to love. This enables us to
quantify and visualize the semantic space occupied by these words, providing
valuable insights into the cultural and linguistic nuances of expressing love.
Through this multifaceted approach, our study sheds light on the captivating
complexities of Urdu poetry, offering a deeper understanding and appreciation
for its unique portrayal of love and its myriad expressions

</details>


### [110] [The Elephant in the Coreference Room: Resolving Coreference in Full-Length French Fiction Works](https://arxiv.org/abs/2510.15594)
*Antoine Bourgois,Thierry Poibeau*

Main category: cs.CL

TL;DR: 本文介绍了一个全新的法语小说注释语料库和核心指代解析方法，能够处理复杂的长文本指代关系，并在性别推断上展现了实用价值。


<details>
  <summary>Details</summary>
Motivation: 虽然核心指代解析日益受到关注，但全注释的长文档数据集仍然稀缺，因此我们创建了一个新的法语小说语料库来填补这一空白。

Method: 提出一个模块化的核心指代解析管道，以便进行细粒度的错误分析，并在长文本中进行评估。

Result: 我们展示了所提出的方法在处理长文本时具有竞争力，并能有效扩展到长参考链的解析。同时，我们验证了该方法在虚构角色性别推断任务中的有效性。

Conclusion: 我们的研究展示了一个适用于长篇文学作品的新注释语料库和核心指代解析方法，能够有效处理复杂的指代关系，并在性别推断等任务中表现出其价值。

Abstract: While coreference resolution is attracting more interest than ever from
computational literature researchers, representative datasets of fully
annotated long documents remain surprisingly scarce. In this paper, we
introduce a new annotated corpus of three full-length French novels, totaling
over 285,000 tokens. Unlike previous datasets focused on shorter texts, our
corpus addresses the challenges posed by long, complex literary works, enabling
evaluation of coreference models in the context of long reference chains. We
present a modular coreference resolution pipeline that allows for fine-grained
error analysis. We show that our approach is competitive and scales effectively
to long documents. Finally, we demonstrate its usefulness to infer the gender
of fictional characters, showcasing its relevance for both literary analysis
and downstream NLP tasks.

</details>


### [111] [HypoSpace: Evaluating LLM Creativity as Set-Valued Hypothesis Generators under Underdetermination](https://arxiv.org/abs/2510.15614)
*Tingting Chen,Beibei Lin,Zifeng Yuan,Qiran Zou,Hongyu He,Yew-Soon Ong,Anirudh Goyal,Dianbo Liu*

Main category: cs.CL

TL;DR: 引入HypoSpace工具，用于评估语言模型在科学中的假设生成能力，重点关注多个评价指标。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型在科学程序中的广泛应用，评估其提供多个解释能力的重要性日益凸显，特别是在处理多重兼容假设时。

Method: 通过在三个领域中使用确定性验证器和已完全列举的假设空间，HypoSpace对语言模型进行系统评估。

Result: 本文介绍了HypoSpace，一个用于评估语言模型在科学工作流程中提出多个解释能力的诊断工具。HypoSpace将语言模型视为有限假设集的采样器，测量有效性、唯一性和恢复率三个指标，在三个结构化领域内进行实例化，展示了模型在应对增长的可接受空间时的效果变化。

Conclusion: HypoSpace通过评估语言模型的假设生成能力，揭示了模型在复杂问题上的表现差异，尤其是在可接受空间扩大时的模式崩溃现象。

Abstract: As language models are increasingly used in scientific workflows, evaluating
their ability to propose sets of explanations-not just a single correct
answer-becomes critical. Many scientific problems are underdetermined:
multiple, mechanistically distinct hypotheses are consistent with the same
observations. We introduce HypoSpace, a diagnostic suite that treats LLMs as
samplers of finite hypothesis sets and measures three complementary indicators:
Validity (precision of proposals consistent with observations), Uniqueness
(non-redundancy among proposals), and Recovery (coverage of the enumerated
admissible set). We instantiate HypoSpace in three structured domains with
deterministic validators and exactly enumerated hypothesis spaces: (i) causal
graphs from perturbations, (ii) gravity-constrained 3D voxel reconstruction
from top-down projections, and (iii) Boolean genetic interactions. Across
instruction-tuned and reasoning-focused models, Validity often remains high
while Uniqueness and Recovery degrade as the admissible space grows, revealing
mode collapse that is invisible to correctness-only metrics. HypoSpace offers a
controlled probe-rather than a leaderboard-for methods that explicitly explore
and cover admissible explanation spaces. Code is available at:
https://github.com/CTT-Pavilion/_HypoSpace.

</details>


### [112] [Leveraging LLMs for Context-Aware Implicit Textual and Multimodal Hate Speech Detection](https://arxiv.org/abs/2510.15685)
*Joshua Wolfe Brook,Ilia Markov*

Main category: cs.CL

TL;DR: 本研究提出了一种使用大型语言模型的上下文增强方法，有效提高了仇恨言论检测的性能，尤其是在多模态数据上。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在提高文本和多模态仇恨言论检测的准确性，通过增强上下文信息来提升分类效果。

Method: 采用大型语言模型(LLMs)作为动态知识库，通过两种上下文生成策略（命名实体和全文提示）来改进仇恨言论检测分类器的输入。

Result: 在文本和多模态设置中，最高表现系统相比于无上下文基线在F1评分上分别提升了3和6点。

Conclusion: 该研究的结果表明，上下文信息及其整合方法对仇恨言论检测的表现至关重要。

Abstract: This research introduces a novel approach to textual and multimodal Hate
Speech Detection (HSD), using Large Language Models (LLMs) as dynamic knowledge
bases to generate background context and incorporate it into the input of HSD
classifiers. Two context generation strategies are examined: one focused on
named entities and the other on full-text prompting. Four methods of
incorporating context into the classifier input are compared: text
concatenation, embedding concatenation, a hierarchical transformer-based
fusion, and LLM-driven text enhancement. Experiments are conducted on the
textual Latent Hatred dataset of implicit hate speech and applied in a
multimodal setting on the MAMI dataset of misogynous memes. Results suggest
that both the contextual information and the method by which it is incorporated
are key, with gains of up to 3 and 6 F1 points on textual and multimodal setups
respectively, from a zero-context baseline to the highest-performing system,
based on embedding concatenation.

</details>


### [113] [Cost-Aware Retrieval-Augmentation Reasoning Models with Adaptive Retrieval Depth](https://arxiv.org/abs/2510.15719)
*Helia Hashemi,Victor Rühle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: 提出动态调整的检索增强推理模型，通过成本感知框架提高效率和有效性，实验表明模型延迟减少和有效性提升。


<details>
  <summary>Details</summary>
Motivation: 提升现有检索增强推理模型的效率，减少计算成本，同时保持或提升模型有效性。

Method: 动态调整检索文档列表的长度，并通过强化学习训练成本感知优势函数。

Result: 在七个公共问答数据集上的评估显示，该方法在效率上显著提升，并且有效性有所增加。

Conclusion: 提出的基于成本感知框架的检索增强推理模型，在效率和有效性上均有显著提升，模型延迟减少约16-20%，有效性提高约5%。

Abstract: Reasoning models have gained significant attention due to their strong
performance, particularly when enhanced with retrieval augmentation. However,
these models often incur high computational costs, as both retrieval and
reasoning tokens contribute substantially to the overall resource usage. In
this work, we make the following contributions: (1) we propose a
retrieval-augmented reasoning model that dynamically adjusts the length of the
retrieved document list based on the query and retrieval results; (2) we
develop a cost-aware advantage function for training of efficient
retrieval-augmented reasoning models through reinforcement learning; and (3) we
explore both memory- and latency-bound implementations of the proposed
cost-aware framework for both proximal and group relative policy optimization
algorithms. We evaluate our approach on seven public question answering
datasets and demonstrate significant efficiency gains, without compromising
effectiveness. In fact, we observed that the model latency decreases by ~16-20%
across datasets, while its effectiveness increases by ~5% on average, in terms
of exact match.

</details>


### [114] [Attention Sinks in Diffusion Language Models](https://arxiv.org/abs/2510.15731)
*Maximo Eduardo Rulli,Simone Petruzzi,Edoardo Michielon,Fabrizio Silvestri,Simone Scardapane,Alessio Devoto*

Main category: cs.CL

TL;DR: 本研究分析DLM的注意力模式，发现其动态注意力下沉特征与ARMs相比有显著不同，并表现出更高的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 虽然DLMs的效率和有效性已被广泛研究，但其内部机制尚未深入探讨。

Method: 通过对DLM注意力模式的实证分析，重点研究注意力下沉现象。

Result: DLMs在生成过程中展示出动态的注意力下沉特征，与ARMs相比在移除注意力下沉后性能下降较小。

Conclusion: DLMs表现出具有独特特征的注意力下沉现象，且其对注意力下沉的鲁棒性高于ARMs。

Abstract: Masked Diffusion Language Models (DLMs) have recently emerged as a promising
alternative to traditional Autoregressive Models (ARMs). DLMs employ
transformer encoders with bidirectional attention, enabling parallel token
generation while maintaining competitive performance. Although their efficiency
and effectiveness have been extensively studied, the internal mechanisms that
govern DLMs remain largely unexplored. In this work, we conduct an empirical
analysis of DLM attention patterns, focusing on the attention sinking
phenomenon, an effect previously observed in various transformer-based
architectures. Our findings reveal that DLMs also exhibit attention sinks, but
with distinct characteristics. First, unlike in ARMs, the sink positions in
DLMs tend to shift throughout the generation process, displaying a dynamic
behaviour. Second, while ARMs are highly sensitive to the removal of attention
sinks, DLMs remain robust: masking sinks leads to only a minor degradation in
performance. These results provide new insights into the inner workings of
diffusion-based language models and highlight fundamental differences in how
they allocate and utilize attention compared to autoregressive models.

</details>


### [115] [LLMs Judge Themselves: A Game-Theoretic Framework for Human-Aligned Evaluation](https://arxiv.org/abs/2510.15746)
*Gao Yang,Yuhang Liu,Siyu Miao,Xinyue Liang,Zhengyang Liu,Heyan Huang*

Main category: cs.CL

TL;DR: 本研究探讨了博弈论在大型语言模型评估中的应用，提出了自动互评新方法，并揭示理论与人类评估的一致性及差异。


<details>
  <summary>Details</summary>
Motivation: 传统评估方法不足以捕捉现代LLM行为的细微差别及主观性，推动我们探索博弈论原则在LLM评估中的应用。

Method: 通过自动互评机制，LLM对彼此的输出进行评估，并与人类投票行为进行系统对比。使用博弈论投票算法聚合同行评审，考察模型生成的排名是否反映人类偏好。

Result: 实证结果显示理论预测与人类评估之间存在趋同与背离，揭示了互评的有效性和局限性。

Conclusion: 本研究首次整合了互评、博弈论聚合及人类验证来评估大型语言模型的能力，揭示了理论预测与人类评估的趋同与背离，提供了关于互评方法潜力及局限性的深刻见解。

Abstract: Ideal or real - that is the question.In this work, we explore whether
principles from game theory can be effectively applied to the evaluation of
large language models (LLMs). This inquiry is motivated by the growing
inadequacy of conventional evaluation practices, which often rely on
fixed-format tasks with reference answers and struggle to capture the nuanced,
subjective, and open-ended nature of modern LLM behavior. To address these
challenges, we propose a novel alternative: automatic mutual evaluation, where
LLMs assess each other's output through self-play and peer review. These peer
assessments are then systematically compared with human voting behavior to
evaluate their alignment with human judgment. Our framework incorporates
game-theoretic voting algorithms to aggregate peer reviews, enabling a
principled investigation into whether model-generated rankings reflect human
preferences. Empirical results reveal both convergences and divergences between
theoretical predictions and human evaluations, offering valuable insights into
the promises and limitations of mutual evaluation. To the best of our
knowledge, this is the first work to jointly integrate mutual evaluation,
game-theoretic aggregation, and human-grounded validation for evaluating the
capabilities of LLMs.

</details>


### [116] [On Non-interactive Evaluation of Animal Communication Translators](https://arxiv.org/abs/2510.15768)
*Orr Paradise,David F. Gruber,Adam Tauman Kalai*

Main category: cs.CL

TL;DR: 本研究探讨如何在缺乏参考翻译的情况下评估AI翻译器的有效性，提出了一种新的评估方法，并通过实验验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 探索如何在没有参考翻译的情况下验证AI翻译器，特别是在进行动物语言翻译时的安全性、伦理和成本效益。

Method: 提出通过逐段翻译结合经典的NLP洗牌测试来评估翻译质量，以验证翻译的有效性。

Result: 概念验证实验表明，所提评估方法在数据稀缺的人类语言和构建语言中具有潜在的实用性，并且该评估指标与标准的基于参考翻译的评估具有高度相关性。

Conclusion: 在机器翻译中，可以仅通过目标语言输出评估翻译器的有效性，而无需进行动物互动或观察，特别是在处理复杂语言时。

Abstract: If you had an AI Whale-to-English translator, how could you validate whether
or not it is working? Does one need to interact with the animals or rely on
grounded observations such as temperature? We provide theoretical and
proof-of-concept experimental evidence suggesting that interaction and even
observations may not be necessary for sufficiently complex languages. One may
be able to evaluate translators solely by their English outputs, offering
potential advantages in terms of safety, ethics, and cost. This is an instance
of machine translation quality evaluation (MTQE) without any reference
translations available. A key challenge is identifying ``hallucinations,''
false translations which may appear fluent and plausible. We propose using
segment-by-segment translation together with the classic NLP shuffle test to
evaluate translators. The idea is to translate animal communication, turn by
turn, and evaluate how often the resulting translations make more sense in
order than permuted. Proof-of-concept experiments on data-scarce human
languages and constructed languages demonstrate the potential utility of this
evaluation methodology. These human-language experiments serve solely to
validate our reference-free metric under data scarcity. It is found to
correlate highly with a standard evaluation based on reference translations,
which are available in our experiments. We also perform a theoretical analysis
suggesting that interaction may not be necessary nor efficient in the early
stages of learning to translate.

</details>


### [117] [Emergence of Linear Truth Encodings in Language Models](https://arxiv.org/abs/2510.15804)
*Shauli Ravfogel,Gilad Yehudai,Tal Linzen,Joan Bruna,Alberto Bietti*

Main category: cs.CL

TL;DR: 本研究介绍了一种透明的一层变换器模型，展示了在语言模型中如何产生线性真相子空间，并通过简单的数据分布设置验证了真相编码的出现机制。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型如何区分真与假语句的机制，及其在语言建模中的重要性。

Method: 使用一层变换器玩具模型，结合实验数据研究真相子空间的形成，并验证在预训练语言模型中的表现。

Result: 实验结果表明，通过特定的数据分布，模型能够有效地学习并线性分隔真与假，提高了其语言建模的性能。

Conclusion: 研究表明，通过两阶段学习动态，模型能够有效地区分真与假陈述，并降低语言建模损失，支持线性真相表示在语言模型中的生成机制。

Abstract: Recent probing studies reveal that large language models exhibit linear
subspaces that separate true from false statements, yet the mechanism behind
their emergence is unclear. We introduce a transparent, one-layer transformer
toy model that reproduces such truth subspaces end-to-end and exposes one
concrete route by which they can arise. We study one simple setting in which
truth encoding can emerge: a data distribution where factual statements
co-occur with other factual statements (and vice-versa), encouraging the model
to learn this distinction in order to lower the LM loss on future tokens. We
corroborate this pattern with experiments in pretrained language models.
Finally, in the toy setting we observe a two-phase learning dynamic: networks
first memorize individual factual associations in a few steps, then -- over a
longer horizon -- learn to linearly separate true from false, which in turn
lowers language-modeling loss. Together, these results provide both a
mechanistic demonstration and an empirical motivation for how and why linear
truth representations can emerge in language models.

</details>


### [118] [Paper2Web: Let's Make Your Paper Alive!](https://arxiv.org/abs/2510.15842)
*Yuhang Chen,Tianpeng Lv,Siyi Zhang,Yixiang Yin,Yao Wan,Philip S. Yu,Dongping Chen*

Main category: cs.CL

TL;DR: 本研究提出Paper2Web和PWAgent，显著提高学术网页生成的效果和效率。


<details>
  <summary>Details</summary>
Motivation: 提高学术项目网站的研究传播效果，强调核心内容展示和直观的导航与交互。

Method: 通过MCP工具迭代优化内容和布局，结合规则基础指标和人类验证的评估方式。

Result: 推出Paper2Web基准数据集和多维评估框架，以评估学术网页生成。

Conclusion: PWAgent在生成交互式学术主页方面优于现有的基线方法，并能降低成本。

Abstract: Academic project websites can more effectively disseminate research when they
clearly present core content and enable intuitive navigation and interaction.
However, current approaches such as direct Large Language Model (LLM)
generation, templates, or direct HTML conversion struggle to produce
layout-aware, interactive sites, and a comprehensive evaluation suite for this
task has been lacking. In this paper, we introduce Paper2Web, a benchmark
dataset and multi-dimensional evaluation framework for assessing academic
webpage generation. It incorporates rule-based metrics like Connectivity,
Completeness and human-verified LLM-as-a-Judge (covering interactivity,
aesthetics, and informativeness), and PaperQuiz, which measures paper-level
knowledge retention. We further present PWAgent, an autonomous pipeline that
converts scientific papers into interactive and multimedia-rich academic
homepages. The agent iteratively refines both content and layout through MCP
tools that enhance emphasis, balance, and presentation quality. Our experiments
show that PWAgent consistently outperforms end-to-end baselines like
template-based webpages and arXiv/alphaXiv versions by a large margin while
maintaining low cost, achieving the Pareto-front in academic webpage
generation.

</details>


### [119] [Enhanced Sentiment Interpretation via a Lexicon-Fuzzy-Transformer Framework](https://arxiv.org/abs/2510.15843)
*Shayan Rokhva,Mousa Alizadeh,Maryam Abdollahi Shamami*

Main category: cs.CL

TL;DR: 提出了一种混合的情感分析框架，结合了深度学习和模糊逻辑，显著提升了情感评分的准确性和细致度，并在四个领域的数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 针对产品评论和社交媒体帖子中情感极性和强度的准确检测挑战，尤其是在非正式和特定领域语言中的难点。

Method: 采用了一种混合词典-模糊-变换器框架，结合基于规则的启发式方法、上下文深度学习和模糊逻辑，以生成反映极性和强度的连续情感评分。

Result: 在四个特定领域的数据集（食品配送、电子商务、旅游和时尚）上进行严格评估，结果显示与用户评分的更好对齐、情感极端的更好识别以及误分类的减少。

Conclusion: 该论文证明了结合符号推理与神经模型对于在语言动态变化的领域进行可解释、细致的情感分析的价值。

Abstract: Accurately detecting sentiment polarity and intensity in product reviews and
social media posts remains challenging due to informal and domain-specific
language. To address this, we propose a novel hybrid lexicon-fuzzy-transformer
framework that combines rule-based heuristics, contextual deep learning, and
fuzzy logic to generate continuous sentiment scores reflecting both polarity
and strength. The pipeline begins with VADER-based initial sentiment
estimations, which are refined through a two-stage adjustment process. This
involves leveraging confidence scores from DistilBERT, a lightweight
transformer and applying fuzzy logic principles to mitigate excessive
neutrality bias and enhance granularity. A custom fuzzy inference system then
maps the refined scores onto a 0 to 1 continuum, producing expert)like
judgments. The framework is rigorously evaluated on four domain-specific
datasets. food delivery, e-commerce, tourism, and fashion. Results show
improved alignment with user ratings, better identification of sentiment
extremes, and reduced misclassifications. Both quantitative metrics
(distributional alignment, confusion matrices) and qualitative insights (case
studies, runtime analysis) affirm the models robustness and efficiency. This
work demonstrates the value of integrating symbolic reasoning with neural
models for interpretable, finegrained sentiment analysis in linguistically
dynamic domains.

</details>


### [120] [SpeechLLMs for Large-scale Contextualized Zero-shot Slot Filling](https://arxiv.org/abs/2510.15851)
*Kadri Hacioglu,Manjunath K E,Andreas Stolcke*

Main category: cs.CL

TL;DR: 本研究探讨槽填充任务，通过设置经验上限并提出改进策略，以提升槽填充性能并解决实际挑战。


<details>
  <summary>Details</summary>
Motivation: 随着语音基础大型语言模型的发展，需要更统一、生成和遵循指令的方式来处理语音理解任务。

Method: 创建槽填充任务的经验上限，为性能、鲁棒性和泛化能力差距进行识别，并提出相应改善措施。

Result: 每项措施在性能上都有显著提高，同时揭示了在利用这些新兴模型时的实际挑战。

Conclusion: 通过改善训练数据、架构和训练策略，显著提高了槽填充任务的性能，并强调了实际挑战和提供了实证指导与洞察。

Abstract: Slot filling is a crucial subtask in spoken language understanding (SLU),
traditionally implemented as a cascade of speech recognition followed by one or
more natural language understanding (NLU) components. The recent advent of
speech-based large language models (speechLLMs), which integrate speech and
textual foundation models, has opened new avenues for achieving speech
understanding tasks in a more unified, generative, and instruction-following
manner while promising data and compute efficiency with zero-shot abilities,
generalizing to unseen slot labels. We address the slot-filling task by
creating an empirical upper bound for the task, identifying performance,
robustness, and generalization gaps, and proposing improvements to the training
data, architecture, and training strategies to narrow the gap with the upper
bound result. We show that each of these measures improve performance
substantially, while highlighting practical challenges and providing empirical
guidance and insights for harnessing these emerging models.

</details>


### [121] [InfiMed-ORBIT: Aligning LLMs on Open-Ended Complex Tasks via Rubric-Based Incremental Training](https://arxiv.org/abs/2510.15859)
*Pengkai Wang,Qi Zuo,Pengwei Liu,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.CL

TL;DR: 本文介绍ORBIT框架，旨在解决当前强化学习在复杂任务中的局限性，特别是在医学咨询领域，显示出显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型在复杂和开放性任务中的表现，特别是医学咨询领域的性能。

Method: ORBIT框架结合了合成对话生成和动态的评分标准创建，采用评分标准导向的反馈来指导增量的强化学习过程。

Result: 提出ORBIT框架，通过基于规则的反馈提高模型的表现，特别是在医学对话中。

Conclusion: 基于规则的反馈是一种可扩展的策略，可以推动大语言模型在复杂开放任务中的发展。

Abstract: Large Language Models (LLMs) have shown substantial advances through
reinforcement learning (RL), particularly in domains where rewards can be
programmatically verified, such as mathematics and code. In these areas, models
benefit from a well-defined operational base guided by explicit rule-based
objectives. However, this progress reveals a significant limitation: in
open-ended domains where rewards are ambiguous, subjective, or
context-dependent, such as creative writing, scientific reasoning, and notably
medical consultation, robust reward functions are lacking, making these areas
challenging for current RL strategies. To bridge this gap, we introduce ORBIT,
an open-ended rubric-based incremental training framework specifically designed
for high-stakes medical dialogue. ORBIT integrates syn- thetic dialogue
generation with the dynamic creation of rubrics, employing these rubrics to
direct an incremental RL process. In particular, this approach does not depend
on external medical knowledge or manual rules, instead utilizing rubric-guided
feedback to shape learning. When implemented on the Qwen3-4B-Instruct model,
our method can greatly enhance its performance on the HealthBench-Hard
benchmark from 7.0 to 27.2 using only 2k samples, thus achieving
state-of-the-art results for models of this scale. Our analysis confirms that
rubric-driven RL fos-ters consistent performance gains across diverse
consultation scenarios, going beyond simple numerical improvements. These
findings underscore rubric-based feedback as a scalable strategy for advancing
LLMs in intricate, open-ended tasks.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [122] [A Feasibility Study on Usability and Trust among Population Groups of a Medical Avatar Supported by Large Language Models with Retrieval Augmented Generation](https://arxiv.org/abs/2510.15531)
*Roel Boumans,Lisa Cramer,Sascha van de Poll,Henria Vermeulen*

Main category: cs.HC

TL;DR: 研究开发了一种虚拟人类头像，利用RAG技术提高医疗信息的互动质量，结果显示用户对其可用性和信任度较高。


<details>
  <summary>Details</summary>
Motivation: 医疗专业人员时间有限，但患者及其亲属的信息需求较高，因此开发了一个能够提供个性化医疗信息的虚拟人类头像。

Method: 通过制作视频展示患者与虚拟头像，以及患者亲属与头像之间的互动，并进行问卷调查以评估可用性和信任度。

Result: 在角色扮演中，参与者对虚拟头像的可用性和信任度评分均高于平均值，特别是在亲属角色中表现更显著。

Conclusion: 使用大型语言模型和检索增强生成技术的虚拟人类头像在患者和其亲属之间的互动中表现出良好的可用性和信任度，且性别、国家和教育水平对接受度没有显著影响。

Abstract: Healthcare professionals have limited time to support patients and their
relatives, but their information needs are high. Therefore, the Radboud
University together with the Canisius Wilhelmina Hospital hospital developed a
speaking virtual hu-man avatar which, contrary to many avatars, uses a Large
Language Model (LLM) enhanced with Retrieval Augmented Generation (RAG). The
RAG tech-nique enables medical information supplied by the hospital to be
utilized during interactions, rather than generic LLM information. Two videos
were produced, one presenting a patient-avatar interaction regarding a total
hip surgery, and an-other one presenting an interaction between a relative of a
patient and the avatar concerning postoperative delirium. A survey was
conducted among adults over 40 from the Netherlands, the UK and the USA to
study the effects of gender, country and education level on usability and
trust, which are important factors for avatar acceptance. Participants watched
videos, imagining themselves as the pa-tient (video 1) or relative (video 2),
and rated the constructs on a 7-point Likert scale (0-6). 165 persons
(MeanAge=51.6, SDAge=8.9, Male=80, Female=85) completed the survey. In the
patient role, participants scored the usability as M=4.61 (SD=0.97) and trust
as M=3.92 (SD=1.10), all above the mean scale value. In the role as relative to
the patient, participants scored usability as M=4.64 (SD=1.08) and trust as
M=4.31 (SD=1.06). No effects were found of gender, country and education level.

</details>


### [123] [Sound Clouds: Exploring ambient intelligence in public spaces to elicit deep human experience of awe, wonder, and beauty](https://arxiv.org/abs/2510.15865)
*Chengzhi Zhang,Dashiel Carrera,Daksh Kapoor,Jasmine Kaur,Jisu Kim,Brian Magerko*

Main category: cs.HC

TL;DR: 文章探讨了利用环境人工智能设计感性体验的可能性，并介绍了一个名为 "Sound Clouds "的互动艺术装置。


<details>
  <summary>Details</summary>
Motivation: 激发对未来环境智能的思考，探索如何通过艺术与技术结合触发深层次的人类情感。

Method: 介绍了基于互动的沉浸式艺术装置，通过参与者与物理对象的互动来生成音乐。

Result: 这篇论文讨论了如何将环境智能（AmI）系统与人类深层情感结合，创造出能够唤起敬畏、惊奇和美感的体验。作者引入了一个名为 "Sound Clouds "的沉浸式艺术装置，该装置基于参与者与几个高人形球体的互动生成实时音乐。

Conclusion: 本研究展示了环境智能的未来可能性，即通过艺术交互来激发人类情感，而不仅仅是满足实用功能。

Abstract: While the ambient intelligence (AmI) systems we encounter in our daily lives,
including security monitoring and energy-saving systems, typically serve
pragmatic purposes, we wonder how we can design and implement ambient
artificial intelligence experiences in public spaces that elicit deep human
feelings of awe, wonder, and beauty. As a manifestation, we introduce Sound
Clouds, an immersive art installation that generates live music based on
participants' interaction with several human-height spheres. Our installation
serves as a provocation into future ambient intelligence that provokes, not
limits, the future possibilities of AmI.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [124] [Decentralizing Multi-Agent Reinforcement Learning with Temporal Causal Information](https://arxiv.org/abs/2506.07829)
*Jan Corazza,Hadi Partovi Aria,Hyohun Kim,Daniel Neider,Zhe Xu*

Main category: cs.LG

TL;DR: 本纸探讨使用符号知识提升去中心化多智能体强化学习的效率，解决智能体间的政策兼容性与学习速度问题。


<details>
  <summary>Details</summary>
Motivation: 现实问题往往需要多个智能体协作以达成共同目标，传统的单智能体强化学习方法无法满足此需求。

Method: 研究如何为智能体提供高级的符号知识以解决去中心化多智能体强化学习中的挑战。

Result: 通过扩展检查局部策略与团队任务兼容性的形式工具，提高了去中心化训练在更多场景中的可用性，并通过实证证明符号知识能显著加速学习过程。

Conclusion: 提供高级符号知识能有效解决去中心化多智能体强化学习中的隐私、沟通和性能等问题，从而提高协作效率。

Abstract: Reinforcement learning (RL) algorithms can find an optimal policy for a
single agent to accomplish a particular task. However, many real-world problems
require multiple agents to collaborate in order to achieve a common goal. For
example, a robot executing a task in a warehouse may require the assistance of
a drone to retrieve items from high shelves. In Decentralized Multi-Agent RL
(DMARL), agents learn independently and then combine their policies at
execution time, but often must satisfy constraints on compatibility of local
policies to ensure that they can achieve the global task when combined. In this
paper, we study how providing high-level symbolic knowledge to agents can help
address unique challenges of this setting, such as privacy constraints,
communication limitations, and performance concerns. In particular, we extend
the formal tools used to check the compatibility of local policies with the
team task, making decentralized training with theoretical guarantees usable in
more scenarios. Furthermore, we empirically demonstrate that symbolic knowledge
about the temporal evolution of events in the environment can significantly
expedite the learning process in DMARL.

</details>


### [125] [Extending Load Forecasting from Zonal Aggregates to Individual Nodes for Transmission System Operators](https://arxiv.org/abs/2510.14983)
*Oskar Triebe,Fletcher Passow,Simon Wittner,Leonie Wagner,Julio Arend,Tao Sun,Chad Zanocco,Marek Miltner,Arezou Ghesmati,Chen-Hao Tsai,Christoph Bergmeir,Ram Rajagopal*

Main category: cs.LG

TL;DR: 该论文提出了一种多级负荷预测系统，旨在提高电网运营商的预测准确性和管理能力，特别是在节点负荷预测方面。


<details>
  <summary>Details</summary>
Motivation: 由于可再生能源的蓬勃发展导致电网负荷的不确定性，电力传输系统运营商需要更高空间分辨率的负荷预测，以更好地管理电网的稳定性和可靠性。

Method: 实验评估多级系统组件，开发可解释且可扩展的预测模型，解决节点负荷的异质性和波动性问题，并建立完全并行化的单模型预测工作流程。

Result: 该论文设计了一个多级系统，以满足电网运营商对未来负荷预测的需求，特别是在可再生能源发展的背景下。这一系统采用了丰富的区域和节点净负荷数据，通过可解释且可扩展的预测模型提高了预测的准确性和可解释性，进而协助运营商在电网管理中做出更有效的决策。

Conclusion: 该多级预测系统通过提供更高的准确性和解释性，显著改善了节点负荷预测的效果，帮助运营商提升操作自信和准确性。

Abstract: The reliability of local power grid infrastructure is challenged by
sustainable energy developments increasing electric load uncertainty.
Transmission System Operators (TSOs) need load forecasts of higher spatial
resolution, extending current forecasting operations from zonal aggregates to
individual nodes. However, nodal loads are less accurate to forecast and
require a large number of individual forecasts, which are hard to manage for
the human experts assessing risks in the control room's daily operations
(operator). In collaboration with a TSO, we design a multi-level system that
meets the needs of operators for hourly day-ahead load forecasting. Utilizing a
uniquely extensive dataset of zonal and nodal net loads, we experimentally
evaluate our system components. First, we develop an interpretable and scalable
forecasting model that allows for TSOs to gradually extend zonal operations to
include nodal forecasts. Second, we evaluate solutions to address the
heterogeneity and volatility of nodal load, subject to a trade-off. Third, our
system is manageable with a fully parallelized single-model forecasting
workflow. Our results show accuracy and interpretability improvements for zonal
forecasts, and substantial improvements for nodal forecasts. In practice, our
multi-level forecasting system allows operators to adjust forecasts with
unprecedented confidence and accuracy, and to diagnose otherwise opaque errors
precisely.

</details>


### [126] [TangledFeatures: Robust Feature Selection in Highly Correlated Spaces](https://arxiv.org/abs/2510.15005)
*Allen Daniel Sunny*

Main category: cs.LG

TL;DR: TangledFeatures 是一种针对相关特征空间的特征选择框架，能有效减少冗余并增强模型的可解释性，适用于复杂数据分析。


<details>
  <summary>Details</summary>
Motivation: 传统特征选择方法在面对相关预测变量时，其性能会下降，而大多数方法侧重于预测准确性，因此需要解决这一问题。

Method: 通过从纠缠的预测变量组中识别代表性特征来进行特征选择，减少冗余。

Result: 在 Alanine Dipeptide 上展示了 TangledFeatures 的有效性，表明所选特征与结构上有意义的原子间距相关，这些特征能够解释背骨扭转角度的变化。

Conclusion: TangledFeatures 提供了一种有效的特征选择框架，适用于相关特征空间，减少冗余并保留解释力，从而在下游模型中实现更可解释且稳定的分析基础。

Abstract: Feature selection is a fundamental step in model development, shaping both
predictive performance and interpretability. Yet, most widely used methods
focus on predictive accuracy, and their performance degrades in the presence of
correlated predictors. To address this gap, we introduce TangledFeatures, a
framework for feature selection in correlated feature spaces. It identifies
representative features from groups of entangled predictors, reducing
redundancy while retaining explanatory power. The resulting feature subset can
be directly applied in downstream models, offering a more interpretable and
stable basis for analysis compared to traditional selection techniques. We
demonstrate the effectiveness of TangledFeatures on Alanine Dipeptide, applying
it to the prediction of backbone torsional angles and show that the selected
features correspond to structurally meaningful intra-atomic distances that
explain variation in these angles.

</details>


### [127] [ES-C51: Expected Sarsa Based C51 Distributional Reinforcement Learning Algorithm](https://arxiv.org/abs/2510.15006)
*Rijul Tandon,Peter Vamplew,Cameron Foale*

Main category: cs.LG

TL;DR: 本研究提出了改进的C51算法ES-C51，通过采用期望Sarsa更新提升了算法在多种环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 解决C51算法在状态中多种类似期望奖励但具有不同分布的动作导致的不稳定学习问题。

Method: 通过用期望Sarsa更新替代贪婪Q学习更新，并使用softmax计算结合所有可能动作的信息，来改进C51算法。

Result: 在Gym经典控制环境和Atari-10游戏中的实验结果表明，ES-C51在性能上优于QL-C51。

Conclusion: ES-C51算法在多个环境中优于QL-C51算法，显示了更高的性能。

Abstract: In most value-based reinforcement learning (RL) algorithms, the agent
estimates only the expected reward for each action and selects the action with
the highest reward. In contrast, Distributional Reinforcement Learning (DRL)
estimates the entire probability distribution of possible rewards, providing
richer information about uncertainty and variability. C51 is a popular DRL
algorithm for discrete action spaces. It uses a Q-learning approach, where the
distribution is learned using a greedy Bellman update. However, this can cause
problems if multiple actions at a state have similar expected reward but with
different distributions, as the algorithm may not learn a stable distribution.
This study presents a modified version of C51 (ES-C51) that replaces the greedy
Q-learning update with an Expected Sarsa update, which uses a softmax
calculation to combine information from all possible actions at a state rather
than relying on a single best action. This reduces instability when actions
have similar expected rewards and allows the agent to learn higher-performing
policies. This approach is evaluated on classic control environments from Gym,
and Atari-10 games. For a fair comparison, we modify the standard C51's
exploration strategy from e-greedy to softmax, which we refer to as QL-C51 (Q-
Learning based C51). The results demonstrate that ES-C51 outperforms QL-C51
across many environments.

</details>


### [128] [Hybrid Autoencoder-Based Framework for Early Fault Detection in Wind Turbines](https://arxiv.org/abs/2510.15010)
*Rekha R Nair,Tina Babu,Alavikunhu Panthakkan,Balamurugan Balusamy,Wathiq Mansoor*

Main category: cs.LG

TL;DR: 本文提出一种新颖的深度学习框架用于风力涡轮机的无监督异常检测，结合多种模型，达到高效的故障预测。


<details>
  <summary>Details</summary>
Motivation: 在可再生能源领域，风力涡轮机的可靠性至关重要，早期故障检测可以显著减少停机时间和维护成本。

Method: 引入了一种基于集成的深度学习框架，结合变分自编码器、LSTM自编码器和变换器架构进行无监督异常检测。

Result: 在CARE数据集上评估，该方法实现了0.947的AUC-ROC，并可在故障发生前提前48小时进行故障检测。

Conclusion: 该方法显著提高了风力涡轮机的故障检测能力和运营效率。

Abstract: Wind turbine reliability is critical to the growing renewable energy sector,
where early fault detection significantly reduces downtime and maintenance
costs. This paper introduces a novel ensemble-based deep learning framework for
unsupervised anomaly detection in wind turbines. The method integrates
Variational Autoencoders (VAE), LSTM Autoencoders, and Transformer
architectures, each capturing different temporal and contextual patterns from
high-dimensional SCADA data. A unique feature engineering pipeline extracts
temporal, statistical, and frequency-domain indicators, which are then
processed by the deep models. Ensemble scoring combines model predictions,
followed by adaptive thresholding to detect operational anomalies without
requiring labeled fault data. Evaluated on the CARE dataset containing 89 years
of real-world turbine data across three wind farms, the proposed method
achieves an AUC-ROC of 0.947 and early fault detection up to 48 hours prior to
failure. This approach offers significant societal value by enabling predictive
maintenance, reducing turbine failures, and enhancing operational efficiency in
large-scale wind energy deployments.

</details>


### [129] [AlignFlow: Improving Flow-based Generative Models with Semi-Discrete Optimal Transport](https://arxiv.org/abs/2510.15038)
*Lingkai Kong,Molei Tao,Yang Liu,Bryan Wang,Jinmiao Fu,Chien-Chih Wang,Huidong Liu*

Main category: cs.LG

TL;DR: 本研究提出AlignFlow，一种利用半离散最优传输来提升流式生成模型训练的新方法，显著改善了性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: The motivation behind this paper is to address the limitations of existing OT-based methods that struggle with scalability for large and high-dimensional datasets in flow-based generative models.

Method: AlignFlow utilizes Semi-Discrete Optimal Transport to create a transport map that partitions the noise space into Laguerre cells, optimizing the pairing of noise samples with data points during training.

Result: Experimental results demonstrate that AlignFlow significantly enhances performance across various state-of-the-art generative model algorithms while maintaining low computational overhead.

Conclusion: AlignFlow enhances the training of flow-based generative models through optimal alignment between noise and data, leading to improved performance and scalability.

Abstract: Flow-based Generative Models (FGMs) effectively transform noise into complex
data distributions. Incorporating Optimal Transport (OT) to couple noise and
data during FGM training has been shown to improve the straightness of flow
trajectories, enabling more effective inference. However, existing OT-based
methods estimate the OT plan using (mini-)batches of sampled noise and data
points, which limits their scalability to large and high-dimensional datasets
in FGMs. This paper introduces AlignFlow, a novel approach that leverages
Semi-Discrete Optimal Transport (SDOT) to enhance the training of FGMs by
establishing an explicit, optimal alignment between noise distribution and data
points with guaranteed convergence. SDOT computes a transport map by
partitioning the noise space into Laguerre cells, each mapped to a
corresponding data point. During FGM training, i.i.d. noise samples are paired
with data points via the SDOT map. AlignFlow scales well to large datasets and
model architectures with negligible computational overhead. Experimental
results show that AlignFlow improves the performance of a wide range of
state-of-the-art FGM algorithms and can be integrated as a plug-and-play
component. Code is available at: https://github.com/konglk1203/AlignFlow.

</details>


### [130] [Physics-informed data-driven machine health monitoring for two-photon lithography](https://arxiv.org/abs/2510.15075)
*Sixian Jia,Zhiqiao Dong,Chenhui Shao*

Main category: cs.LG

TL;DR: 本文提出三种方法，通过物理知识驱动的数据模型与统计方法相结合，实现对双光子光刻机健康的监测，提高了维护的准确性和及时性。


<details>
  <summary>Details</summary>
Motivation: 维护双光子光刻系统的健康对确保一致的制造质量至关重要，但当前的维护实践大多依赖经验，缺乏有效监测。

Method: 通过将物理知识驱动的数据驱动预测模型与统计方法相结合，提出了监测机器健康的三种方法。

Result: 实验结果显示，所提方法在各个测试场景下都表现出高准确性和良好的稳健性，证明了其有效性和普适性。

Conclusion: 该研究展示了三种方法，可实现对双光子光刻机健康的准确和及时监测，这对实现基于状态的维护具有重要意义。

Abstract: Two-photon lithography (TPL) is a sophisticated additive manufacturing
technology for creating three-dimensional (3D) micro- and nano-structures.
Maintaining the health of TPL systems is critical for ensuring consistent
fabrication quality. Current maintenance practices often rely on experience
rather than informed monitoring of machine health, resulting in either untimely
maintenance that causes machine downtime and poor-quality fabrication, or
unnecessary maintenance that leads to inefficiencies and avoidable downtime. To
address this gap, this paper presents three methods for accurate and timely
monitoring of TPL machine health. Through integrating physics-informed
data-driven predictive models for structure dimensions with statistical
approaches, the proposed methods are able to handle increasingly complex
scenarios featuring different levels of generalizability. A comprehensive
experimental dataset that encompasses six process parameter combinations and
six structure dimensions under two machine health conditions was collected to
evaluate the effectiveness of the proposed approaches. Across all test
scenarios, the approaches are shown to achieve high accuracies, demonstrating
excellent effectiveness, robustness, and generalizability. These results
represent a significant step toward condition-based maintenance for TPL
systems.

</details>


### [131] [Online Correlation Clustering: Simultaneously Optimizing All $\ell_p$-norms](https://arxiv.org/abs/2510.15076)
*Sami Davies,Benjamin Moseley,Heather Newman*

Main category: cs.LG

TL;DR: 本文展示了一种在线算法，使得在样本输入的情况下对多种$	ext{ℓ}_p$-范数的竞争性得到保障，成功实现了离线模型的优势。


<details>
  <summary>Details</summary>
Motivation: 受到一个新硬度结果的启发，该结果在标准的随机顺序（RO）在线模型中展示了多项目标之间的基本分离，强调了采用更好模型的必要性。

Method: 提出了一种单一算法，在给定输入的样本的情况下，同时对所有$	ext{ℓ}_p$-范数保持$O(	ext{log}^4 n)$竞争性、对$	ext{ℓ}_	ext{∞}$-范数保持$O(	ext{log} n)$竞争性，并对$	ext{ℓ}_1$-范数在期望上保持$O(1)$竞争性。

Result: 在线算法在$	ext{AOS}$模型中的表现优异，且对于$	ext{ℓ}_1$和$	ext{ℓ}_	ext{∞}$-范数的竞争比近乎紧密，明确了不同目标之间的平衡和模型重要性。

Conclusion: 本文提出了一种在线算法，能够在$	ext{AOS}$模型中有效地实现对多种$	ext{ℓ}_p$-范数的竞争性保证，显示了在线环境中将离线的全范数保证转化为有效模型的可能性。

Abstract: The $\ell_p$-norm objectives for correlation clustering present a fundamental
trade-off between minimizing total disagreements (the $\ell_1$-norm) and
ensuring fairness to individual nodes (the $\ell_\infty$-norm). Surprisingly,
in the offline setting it is possible to simultaneously approximate all
$\ell_p$-norms with a single clustering. Can this powerful guarantee be
achieved in an online setting? This paper provides the first affirmative
answer. We present a single algorithm for the online-with-a-sample (AOS) model
that, given a small constant fraction of the input as a sample, produces one
clustering that is simultaneously $O(\log^4 n)$-competitive for all
$\ell_p$-norms with high probability, $O(\log n)$-competitive for the
$\ell_\infty$-norm with high probability, and $O(1)$-competitive for the
$\ell_1$-norm in expectation. This work successfully translates the offline
"all-norms" guarantee to the online world.
  Our setting is motivated by a new hardness result that demonstrates a
fundamental separation between these objectives in the standard random-order
(RO) online model. Namely, while the $\ell_1$-norm is trivially
$O(1)$-approximable in the RO model, we prove that any algorithm in the RO
model for the fairness-promoting $\ell_\infty$-norm must have a competitive
ratio of at least $\Omega(n^{1/3})$. This highlights the necessity of a
different beyond-worst-case model. We complement our algorithm with lower
bounds, showing our competitive ratios for the $\ell_1$- and $\ell_\infty$-
norms are nearly tight in the AOS model.

</details>


### [132] [Operator Flow Matching for Timeseries Forecasting](https://arxiv.org/abs/2510.15101)
*Yolanne Yi Ran Lee,Kyriakos Flouris*

Main category: cs.LG

TL;DR: TempO是一种高效的潜在流匹配模型，能有效处理高维PDE动态，超越现有技术并展示出优越的多尺度动态恢复能力。


<details>
  <summary>Details</summary>
Motivation: 当前的自回归和扩散方法在长时间物理一致的预测中存在累计误差和离散化伪影，导致高维PDE动态预测的挑战。

Method: 采用稀疏条件和通道折叠的潜在流匹配模型，结合时间条件的傅里叶层，以高保真捕获多尺度模式。

Result: 在三个基准PDE数据集上，TempO模型的性能超过了现有最先进的基线，且在参数和内存使用上相较于基于注意力或卷积的回归模型更高效。

Conclusion: TempO模型在高维PDE动态预测中表现优越，超越了现有的基准方法，并在多尺度动态恢复方面显示出卓越的能力。

Abstract: Forecasting high-dimensional, PDE-governed dynamics remains a core challenge
for generative modeling. Existing autoregressive and diffusion-based approaches
often suffer cumulative errors and discretisation artifacts that limit long,
physically consistent forecasts. Flow matching offers a natural alternative,
enabling efficient, deterministic sampling. We prove an upper bound on FNO
approximation error and propose TempO, a latent flow matching model leveraging
sparse conditioning with channel folding to efficiently process 3D
spatiotemporal fields using time-conditioned Fourier layers to capture
multi-scale modes with high fidelity. TempO outperforms state-of-the-art
baselines across three benchmark PDE datasets, and spectral analysis further
demonstrates superior recovery of multi-scale dynamics, while efficiency
studies highlight its parameter- and memory-light design compared to
attention-based or convolutional regressors.

</details>


### [133] [DLER: Doing Length pEnalty Right - Incentivizing More Intelligence per Token via Reinforcement Learning](https://arxiv.org/abs/2510.15110)
*Shih-Yang Liu,Xin Dong,Ximing Lu,Shizhe Diao,Mingjie Liu,Min-Hung Chen,Hongxu Yin,Yu-Chiang Frank Wang,Kwang-Ting Cheng,Yejin Choi,Jan Kautz,Pavlo Molchanov*

Main category: cs.LG

TL;DR: 提出DLER方法，通过改进强化学习优化解决生成模型输出冗长的问题，显著提高效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有模型输出冗长且智能token效率低下的问题。

Method: 采用简单的长度惩罚进行强化学习优化，提出DLER训练方案。

Result: DLER在准确性和效率的权衡上达到最新的效果，输出长度减少超过70%，测试时生成多个精简响应，准确性提高28%。

Conclusion: 引入Difficulty-Aware DLER和选择性合并方法，在保持准确性的同时提升模型的简洁推理能力，适用于RL训练数据稀缺的场景。

Abstract: Reasoning language models such as OpenAI-o1, DeepSeek-R1, and Qwen achieve
strong performance via extended chains of thought but often generate
unnecessarily long outputs. Maximizing intelligence per token--accuracy
relative to response length--remains an open problem. We revisit reinforcement
learning (RL) with the simplest length penalty--truncation--and show that
accuracy degradation arises not from the lack of sophisticated penalties but
from inadequate RL optimization. We identify three key challenges: (i) large
bias in advantage estimation, (ii) entropy collapse, and (iii) sparse reward
signal. We address them with Doing Length pEnalty Right (DLER), a training
recipe combining batch-wise reward normalization, higher clipping, dynamic
sampling, and a simple truncation length penalty. DLER achieves
state-of-the-art accuracy--efficiency trade-offs, cutting output length by over
70 percent while surpassing all previous baseline accuracy. It also improves
test-time scaling: compared to DeepSeek-R1-7B, DLER-7B generates multiple
concise responses in parallel with 28 percent higher accuracy and lower
latency. We further introduce Difficulty-Aware DLER, which adaptively tightens
truncation on easier questions for additional efficiency gains. We also propose
an update-selective merging method that preserves baseline accuracy while
retaining the concise reasoning ability of the DLER model, which is useful for
scenarios where RL training data is scarce.

</details>


### [134] [Navigating the consequences of mechanical ventilation in clinical intensive care settings through an evolutionary game-theoretic framework](https://arxiv.org/abs/2510.15127)
*David J. Albers,Tell D. Bennett,Jana de Wiljes,Bradford J. Smith,Peter D. Sottile,J. N. Stroh*

Main category: cs.LG

TL;DR: 本研究提出了一种分析机械通气效果的框架，利用演化博弈论和强化学习方法优化重症护理中的机械通气与辅助护理决策。


<details>
  <summary>Details</summary>
Motivation: 提高对重症护理中机械通气管理的理解，通过分析临床数据生成有利假设，推动护理策略的改进。

Method: 采用演化博弈论分析呼吸行为，并结合强化学习等方法，验证机械通气的优化过程。

Result: 本研究提出了一种框架，用于分析机械通气在重症护理中的效果，通过对异质性患者-通气机系统的数据进行研究，从而了解机械通气及辅助护理决策对患者结果的影响。研究聚焦于现有临床二次使用数据，利用演化博弈论分析呼吸行为，以生成定量数据，进而通过强化学习等方法进行更深入的分析。这一过程为机械通气的优化和个性化铺平了道路，并在合成数据上进行了验证，揭示了可能的局限性，随后将应用于真实的ICU数据。这一讨论涉及了建立状态转移模型的潜在发展，以模拟机械通气决策的效果。

Conclusion: 该研究为机械通气的优化与个性化提供了一种新方法，并对未来的重症监护决策建模提出了建议。

Abstract: Identifying the effects of mechanical ventilation strategies and protocols in
critical care requires analyzing data from heterogeneous patient-ventilator
systems within the context of the clinical decision-making environment. This
research develops a framework to help understand the consequences of mechanical
ventilation (MV) and adjunct care decisions on patient outcome from
observations of critical care patients receiving MV. Developing an
understanding of and improving critical care respiratory management requires
the analysis of existing secondary-use clinical data to generate hypotheses
about advantageous variations and adaptations of current care. This work
introduces a perspective of the joint patient-ventilator-care systems
(so-called J6) to develop a scalable method for analyzing data and trajectories
of these complex systems. To that end, breath behaviors are analyzed using
evolutionary game theory (EGT), which generates the necessary quantitative
precursors for deeper analysis through probabilistic and stochastic machinery
such as reinforcement learning. This result is one step along the pathway
toward MV optimization and personalization. The EGT-based process is
analytically validated on synthetic data to reveal potential caveats before
proceeding to real-world ICU data applications that expose complexities of the
data-generating process J6. The discussion includes potential developments
toward a state transition model for the simulating effects of MV decision using
empirical and game-theoretic elements.

</details>


### [135] [A Simple Method for PMF Estimation on Large Supports](https://arxiv.org/abs/2510.15132)
*Alex Shtoff*

Main category: cs.LG

TL;DR: 本文研究了一种非参数估计概率质量函数（PMF）的方法，适用于大型离散支持，特别是多峰和重尾分布。


<details>
  <summary>Details</summary>
Motivation: 在大型多峰重尾PMF的情况下提高估计的平滑性并抑制噪声，同时保持粗糙结构。

Method: 通过构建对称三对角算子与由经验PMF构建的对角矩阵相结合，计算小特征值对应的特征向量以实现低维空间投影。

Result: 在合成数据和真实重尾例子中与logspline和Gaussian-KDE基线比较表现良好，但存在已知的失败模式。

Conclusion: 该方法在不同样本大小下表现出鲁棒性，并适合自动化分析流程。

Abstract: We study nonparametric estimation of a probability mass function (PMF) on a
large discrete support, where the PMF is multi-modal and heavy-tailed. The core
idea is to treat the empirical PMF as a signal on a line graph and apply a
data-dependent low-pass filter. Concretely, we form a symmetric tri-diagonal
operator, the path graph Laplacian perturbed with a diagonal matrix built from
the empirical PMF, then compute the eigenvectors, corresponding to the smallest
feq eigenvalues. Projecting the empirical PMF onto this low dimensional
subspace produces a smooth, multi-modal estimate that preserves coarse
structure while suppressing noise. A light post-processing step of clipping and
re-normalizing yields a valid PMF.
  Because we compute the eigenpairs of a symmetric tridiagonal matrix, the
computation is reliable and runs time and memory proportional to the support
times the dimension of the desired low-dimensional supspace. We also provide a
practical, data-driven rule for selecting the dimension based on an
orthogonal-series risk estimate, so the method "just works" with minimal
tuning. On synthetic and real heavy-tailed examples, the approach preserves
coarse structure while suppressing sampling noise, compares favorably to
logspline and Gaussian-KDE baselines in the intended regimes. However, it has
known failure modes (e.g., abrupt discontinuities). The method is short to
implement, robust across sample sizes, and suitable for automated pipelines and
exploratory analysis at scale because of its reliability and speed.

</details>


### [136] [Predicting the Unpredictable: Reproducible BiLSTM Forecasting of Incident Counts in the Global Terrorism Database (GTD)](https://arxiv.org/abs/2510.15136)
*Oluwasegun Adegoke*

Main category: cs.LG

TL;DR: 本研究使用双向LSTM模型对GTD数据进行短期恐怖事件预测，结果表明该模型在准确性上优于其他基线方法，尤其在处理长期历史数据和时效性特征方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 针对2016年之前的全球恐怖主义数据库数据，旨在提高对短期恐怖事件发生率的预测准确性。

Method: 采用双向LSTM模型，通过对比季节性朴素模型、线性/ARIMA模型和深度LSTM-Attention基线，进行短期恐怖主义事件数量的预测。

Result: 实验表明，双向LSTM在测试集中达到了6.38的RMSE，相较于LSTM-Attention的9.19和线性滞后回归模型的较高RMSE具有显著提高，并且在MAE和MAPE上也有并行的提升。

Conclusion: 本研究提供了一个透明的、超越基线的GTD事件预测参考，强调了双向LSTM模型在短期预测中的优势。

Abstract: We study short-horizon forecasting of weekly terrorism incident counts using
the Global Terrorism Database (GTD, 1970--2016). We build a reproducible
pipeline with fixed time-based splits and evaluate a Bidirectional LSTM
(BiLSTM) against strong classical anchors (seasonal-naive, linear/ARIMA) and a
deep LSTM-Attention baseline. On the held-out test set, the BiLSTM attains RMSE
6.38, outperforming LSTM-Attention (9.19; +30.6\%) and a linear lag-regression
baseline (+35.4\% RMSE gain), with parallel improvements in MAE and MAPE.
Ablations varying temporal memory, training-history length, spatial grain,
lookback size, and feature groups show that models trained on long historical
data generalize best; a moderate lookback (20--30 weeks) provides strong
context; and bidirectional encoding is critical for capturing both build-up and
aftermath patterns within the window. Feature-group analysis indicates that
short-horizon structure (lagged counts and rolling statistics) contributes
most, with geographic and casualty features adding incremental lift. We release
code, configs, and compact result tables, and provide a data/ethics statement
documenting GTD licensing and research-only use. Overall, the study offers a
transparent, baseline-beating reference for GTD incident forecasting.

</details>


### [137] [Policy Transfer Ensures Fast Learning for Continuous-Time LQR with Entropy Regularization](https://arxiv.org/abs/2510.15165)
*Xin Guo,Zijiu Lyu*

Main category: cs.LG

TL;DR: 本论文探讨了在连续时间线性二次调节器(LQR)中使用政策转移的强化学习方法，证明了来自相关源任务的政策可以有效初始化目标RL任务，并提出了一种新的政策学习算法。


<details>
  <summary>Details</summary>
Motivation: 由于从头开始训练复杂任务的效率低下，本文探讨利用已经预训练的模型来提升强化学习的效率，尤其在连续时间环境中。

Method: 通过分析连续时间LQR，提出政策转移的理论证明，及新的政策学习算法来实现全局线性和局部超线性收敛。

Result: 证明了来自一个LQR的最优政策在相关的LQR中可以作为近似最优的初始化，并且提出的新算法显示了较好的收敛性和理论保证。

Conclusion: 本研究展示了政策转移在连续时间强化学习中的理论保障和算法优势，填补了现有文献的空白，并将离散时间的研究扩展到连续时间。

Abstract: Reinforcement Learning (RL) enables agents to learn optimal decision-making
strategies through interaction with an environment, yet training from scratch
on complex tasks can be highly inefficient. Transfer learning (TL), widely
successful in large language models (LLMs), offers a promising direction for
enhancing RL efficiency by leveraging pre-trained models.
  This paper investigates policy transfer, a TL approach that initializes
learning in a target RL task using a policy from a related source task, in the
context of continuous-time linear quadratic regulators (LQRs) with entropy
regularization. We provide the first theoretical proof of policy transfer for
continuous-time RL, proving that a policy optimal for one LQR serves as a
near-optimal initialization for closely related LQRs, while preserving the
original algorithm's convergence rate. Furthermore, we introduce a novel policy
learning algorithm for continuous-time LQRs that achieves global linear and
local super-linear convergence. Our results demonstrate both theoretical
guarantees and algorithmic benefits of transfer learning in continuous-time RL,
addressing a gap in existing literature and extending prior work from discrete
to continuous time settings.
  As a byproduct of our analysis, we derive the stability of a class of
continuous-time score-based diffusion models via their connection with LQRs.

</details>


### [138] [Finding geodesics with the Deep Ritz method](https://arxiv.org/abs/2510.15177)
*Conor Rowan*

Main category: cs.LG

TL;DR: 本文探讨了测地线问题与深度瑞茨方法的结合，展示其在路径规划、光学和固体力学中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 测地线问题在物理和工程中广泛存在，但科学机器学习社区对此的研究仍然较少，因此希望探索其与深度瑞茨方法的结合。

Method: 利用深度瑞茨方法对测地线问题进行数值分析，采用三种来自路径规划、光学和固体力学的具体示例。

Result: 通过具体应用示例，展示了深度瑞茨方法在复杂环境中的最佳路径、光在折射介质中的传播模型以及控制理论中的时空轨迹研究中的有效性。

Conclusion: 深度瑞茨方法在测地线问题中表现出良好的应用潜力，为未来科学机器学习研究提供了有希望的方向。

Abstract: Geodesic problems involve computing trajectories between prescribed initial
and final states to minimize a user-defined measure of distance, cost, or
energy. They arise throughout physics and engineering -- for instance, in
determining optimal paths through complex environments, modeling light
propagation in refractive media, and the study of spacetime trajectories in
control theory and general relativity. Despite their ubiquity, the scientific
machine learning (SciML) community has given relatively little attention to
investigating its methods in the context of these problems. In this work, we
argue that given their simple geometry, variational structure, and natural
nonlinearity, geodesic problems are particularly well-suited for the Deep Ritz
method. We substantiate this claim with three numerical examples drawn from
path planning, optics, and solid mechanics. Our goal is not to provide an
exhaustive study of geodesic problems, but rather to identify a promising
application of the Deep Ritz method and a fruitful direction for future SciML
research.

</details>


### [139] [An Advanced Two-Stage Model with High Sensitivity and Generalizability for Prediction of Hip Fracture Risk Using Multiple Datasets](https://arxiv.org/abs/2510.15179)
*Shuo Sun,Meiling Zhou,Chen Zhao,Joyce H. Keyak,Nancy E. Lane,Jeffrey D. Deng,Kuan-Jui Su,Hui Shen,Hong-Wen Deng,Kui Zhang,Weihua Zhou*

Main category: cs.LG

TL;DR: 研究提出了一种新的两阶段模型来改善髋部骨折风险评估，相比传统工具具有更高的敏感性和更低的漏检率。


<details>
  <summary>Details</summary>
Motivation: 为了弥补常用工具在敏感性方面的不足，特别是对于没有先前骨折或仅有骨质疏松症的个体。

Method: 模型分为两个阶段：第一阶段使用临床、人口和功能变量进行风险筛查，第二阶段结合DXA-derived特征进行风险细化。

Result: 该模型经过严格的内部和外部验证，显示出一致的性能和适应性，能够更有效地识别高风险个体。

Conclusion: 提出的两阶段模型在提高髋部骨折早期风险评估的准确性方面表现出色，优于传统的T-score和FRAX工具。

Abstract: Hip fractures are a major cause of disability, mortality, and healthcare
burden in older adults, underscoring the need for early risk assessment.
However, commonly used tools such as the DXA T-score and FRAX often lack
sensitivity and miss individuals at high risk, particularly those without prior
fractures or with osteopenia. To address this limitation, we propose a
sequential two-stage model that integrates clinical and imaging information to
improve prediction accuracy. Using data from the Osteoporotic Fractures in Men
Study (MrOS), the Study of Osteoporotic Fractures (SOF), and the UK Biobank,
Stage 1 (Screening) employs clinical, demographic, and functional variables to
estimate baseline risk, while Stage 2 (Imaging) incorporates DXA-derived
features for refinement. The model was rigorously validated through internal
and external testing, showing consistent performance and adaptability across
cohorts. Compared to T-score and FRAX, the two-stage framework achieved higher
sensitivity and reduced missed cases, offering a cost-effective and
personalized approach for early hip fracture risk assessment.
  Keywords: Hip Fracture, Two-Stage Model, Risk Prediction, Sensitivity, DXA,
FRAX

</details>


### [140] [Dissecting Mahalanobis: How Feature Geometry and Normalization Shape OOD Detection](https://arxiv.org/abs/2510.15202)
*Denis Janiak,Jakub Binkowski,Tomasz Kajdanowicz*

Main category: cs.LG

TL;DR: 本研究探讨了Mahalanobis距离方法在OOD检测中的局限性，并提出了一种新规范化方法以提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 理解表示几何与规范化对OOD检测性能的影响

Method: Mahalanobis距离方法与规范化的实证研究

Result: 提出了一种新的径向缩放$	ext{l}_2$规范化方法，显著改善了OOD检测性能

Conclusion: 理解数据表示的几何形状和规范化对于提高深度学习模型的可靠性至关重要。

Abstract: Out-of-distribution (OOD) detection is critical for the reliable deployment
of deep learning models. hile Mahalanobis distance methods are widely used, the
impact of representation geometry and normalization on their performance is not
fully understood, which may limit their downstream application. To address this
gap, we conducted a comprehensive empirical study across diverse image
foundation models, datasets, and distance normalization schemes. First, our
analysis shows that Mahalanobis-based methods aren't universally reliable.
Second, we define the ideal geometry for data representations and demonstrate
that spectral and intrinsic-dimensionality metrics can accurately predict a
model's OOD performance. Finally, we analyze how normalization impacts OOD
performance. Building upon these studies, we propose radially scaled $\ell_2$
normalization, a method that generalizes the standard $\ell_2$ normalization
recently applied to Mahalanobis-based OOD detection. Our approach introduces a
tunable parameter to directly control the radial geometry of the feature space,
systematically contracting or expanding representations to significantly
improve OOD detection performance. By bridging the gap between representation
geometry, normalization, and OOD performance, our findings offer new insights
into the design of more effective and reliable deep learning models.

</details>


### [141] [ReasonIF: Large Reasoning Models Fail to Follow Instructions During Reasoning](https://arxiv.org/abs/2510.15211)
*Yongchan Kwon,Shang Zhu,Federico Bianchi,Kaitlyn Zhou,James Zou*

Main category: cs.LG

TL;DR: 研究大型推理模型遵循用户指令的重要性，发现现有模型在此方面表现不佳，并提出提升策略。


<details>
  <summary>Details</summary>
Motivation: 确保大型语言模型在整个推理过程中的可控性和透明性，减少不良行为的风险，从而提升其可靠性和实用性。

Method: 通过引入ReasonIF基准评估推理指令遵循，分析多种开源LRMs的表现，并测试多轮推理与微调方法的效果。

Result: 本文提出了一个新基准ReasonIF，用于评估大型推理模型（LRMs）遵循用户指令的能力，强调在推理过程中遵循指令的重要性。研究发现，当前多个开源LRMs在遵循推理指令方面存在显著不足，且随着任务难度的增加，遵循度进一步降低。同时，作者探索了多轮推理和利用合成数据进行推理指令微调(RIF)作为提升遵循度的策略，RIF在一定程度上改善了模型的遵循得分，但仍有很大提升空间。

Conclusion: 本研究揭示了大型推理模型在遵循用户指令方面的明显不足，提出了有效的改进策略，但仍需进一步努力。

Abstract: The ability of large language models (LLMs) to follow user instructions is
central to their reliability, safety, and usefulness. While prior studies
assess instruction adherence in the model's main responses, we argue that it is
also critical for large reasoning models (LRMs) to follow user instructions
throughout their reasoning process. Reasoning instruction following makes LRMs
more controllable and transparent, while reducing risks of undesirable
shortcuts, hallucinations, or reward hacking within reasoning traces. To
evaluate this dimension, we introduce ReasonIF, a systematic benchmark for
assessing reasoning instruction following. ReasonIF includes six categories of
instruction prompts, spanning multilingual reasoning, formatting and length
control. Across many open-source LRMs including GPT-OSS, Qwen3, and
DeepSeek-R1, we find substantial failures in reasoning instruction adherence:
the highest instruction following score (IFS) remains below 0.25, meaning that
fewer than $25\%$ of reasoning traces comply with the given instructions.
Notably, as task difficulty increases, reasoning instruction following degrades
further. We also explore two strategies to enhance reasoning instruction
fidelity. (1) multi-turn reasoning and (2) Reasoning Instruction Finetuning
(RIF) using synthetic data. RIF improves the IFS of $GPT-OSS-20B$ from 0.11 to
0.27, indicating measurable progress but leaving ample room for improvement.

</details>


### [142] [Soundness-Aware Level: A Microscopic Signature that Predicts LLM Reasoning Potential](https://arxiv.org/abs/2510.15216)
*Xuansheng Wu,Xiaoman Pan,Wenlin Yao,Jianshu Chen*

Main category: cs.LG

TL;DR: 研究揭示了高潜力语言模型在推理中具备音效意识，预训练能力与推理潜力密切相关，并提出SAL指标可以预测模型的推理表现。


<details>
  <summary>Details</summary>
Motivation: 为了探讨不同基础模型在增强学习过程中表现差异的微观特性，研究了语言模型的内在机制与推理能力之间的关系。

Method: 通过交叉层稀疏自编码器提取特征，正式化推理为由Horn子句构成的规则链，估计特征之间的转移概率，并根据语义有效性对规则进行分类。

Result: 发现高潜力模型在推理上具有音效意识，即其内部概率分布在不同规则的有效性水平上具有显著差异，而较弱模型则无音效意识，概率分布趋于一致。

Conclusion: 模型的推理潜力与其内在的预训练能力密切相关，即区分合理知识与不合理知识的能力。同时，提出的音效意识水平（SAL）指标可以有效预测后续增强学习的推理性能。

Abstract: Reinforcement learning with verifiable rewards (RLVR) can elicit strong
reasoning in large language models (LLMs), while their performance after RLVR
varies dramatically across different base models. This raises a fundamental
question: what microscopic property of pre-trained models leads to this
variation? To investigate, we formalize reasoning as chains of Horn clauses
("if-then" rules) built from features extracted from the LLM's latent space via
cross-layer sparse autoencoders (SAEs). We estimate the transition
probabilities between its features, and further categorize each rule by its
semantic soundness level (e.g., strict, plausible, noisy) with an LLM. Our key
discovery is that high-potential models are inherently soundness-aware: their
internal probability distributions systematically shift across rules' soundness
levels, becoming highly distinct for "strict" versus "noisy" rules. In
contrast, weaker models are soundness-agnostic, collapsing to one distribution
regardless of soundness levels. To quantify this, we introduce the
Soundness-Aware Level (SAL), a microscopic metric using the Jensen-Shannon
Divergence to measure the separation between these distributions. We show that
SAL's predictions of post-RLVR reasoning performance follow a precise empirical
law (R^2=0.87) across diverse model families (Qwen, Mistral, Llama, DeepSeek)
and scales (0.5B-14B). This reveals that a model's reasoning potential is tied
to its intrinsic, pre-trained ability to distinguish sound knowledge from
unsound ones. These findings underscore the critical role of model pre-training
in shaping reasoning and offer a practical metric grounded in the model's
internal mechanisms for selecting/designing stronger base models.

</details>


### [143] [Reflections from Research Roundtables at the Conference on Health, Inference, and Learning (CHIL) 2025](https://arxiv.org/abs/2510.15217)
*Emily Alsentzer,Marie-Laure Charpignon,Bill Chen,Niharika D'Souza,Jason Fries,Yixing Jiang,Aparajita Kashyap,Chanwoo Kim,Simon Lee,Aishwarya Mandyam,Ashery Christopher Mbilinyi,Nikita Mehandru,Nitish Nagesh,Brighton Nuwagira,Emma Pierson,Arvind Pillai,Akane Sano,Tanveer Syeda-Mahmood,Shashank Yadav,Elias Adhanom,Muhammad Umar Afza,Amelia Archer,Suhana Bedi,Vasiliki Bikia,Trenton Chang,George H. Chen,Winston Chen,Erica Chiang,Edward Choi,Octavia Ciora,Paz Dozie-Nnamah,Shaza Elsharief,Matthew Engelhard,Ali Eshragh,Jean Feng,Josh Fessel,Scott Fleming,Kei Sen Fong,Thomas Frost,Soham Gadgil,Judy Gichoya,Leeor Hershkovich,Sujeong Im,Bhavya Jain,Vincent Jeanselme,Furong Jia,Qixuan,Jin,Yuxuan Jin,Daniel Kapash,Geetika Kapoor,Behdokht Kiafar,Matthias Kleiner,Stefan Kraft,Annika Kumar,Daeun Kyung,Zhongyuan Liang,Joanna Lin,Qianchu,Liu,Chang Liu,Hongzhou Luan,Chris Lunt,Leopoldo Julían Lechuga López,Matthew B. A. McDermott,Shahriar Noroozizadeh,Connor O'Brien,YongKyung Oh,Mixail Ota,Stephen Pfohl,Meagan Pi,Tanmoy Sarkar Pias,Emma Rocheteau,Avishaan Sethi,Toru Shirakawa,Anita Silver,Neha Simha,Kamile Stankeviciute,Max Sunog,Peter Szolovits,Shengpu Tang,Jialu Tang,Aaron Tierney,John Valdovinos,Byron Wallace,Will Ke Wang,Peter Washington,Jeremy Weiss,Daniel Wolfe,Emily Wong,Hye Sun Yun,Xiaoman Zhang,Xiao Yu Cindy Zhang,Hayoung Jeong,Kaveri A. Thakoor*

Main category: cs.LG

TL;DR: CHIL 2025会议通过研究圆桌讨论促进了机器学习和医疗保健交叉领域的交流与合作。


<details>
  <summary>Details</summary>
Motivation: 促进机器学习与医疗保健交叉领域的合作与对话

Method: 举办研究圆桌讨论

Result: 成功举办了八个主题的圆桌讨论，涉及多个关键挑战和机遇

Conclusion: 会议强调了对话的重要性，并推动了可行的解决方案思考。

Abstract: The 6th Annual Conference on Health, Inference, and Learning (CHIL 2025),
hosted by the Association for Health Learning and Inference (AHLI), was held in
person on June 25-27, 2025, at the University of California, Berkeley, in
Berkeley, California, USA. As part of this year's program, we hosted Research
Roundtables to catalyze collaborative, small-group dialogue around critical,
timely topics at the intersection of machine learning and healthcare. Each
roundtable was moderated by a team of senior and junior chairs who fostered
open exchange, intellectual curiosity, and inclusive engagement. The sessions
emphasized rigorous discussion of key challenges, exploration of emerging
opportunities, and collective ideation toward actionable directions in the
field. In total, eight roundtables were held by 19 roundtable chairs on topics
of "Explainability, Interpretability, and Transparency," "Uncertainty, Bias,
and Fairness," "Causality," "Domain Adaptation," "Foundation Models," "Learning
from Small Medical Data," "Multimodal Methods," and "Scalable, Translational
Healthcare Solutions."

</details>


### [144] [Integrating Product Coefficients for Improved 3D LiDAR Data Classification (Part II)](https://arxiv.org/abs/2510.15219)
*Patricia Medina,Rasika Karkare*

Main category: cs.LG

TL;DR: 通过结合产品系数和自编码器，LiDAR分类性能显著提高。


<details>
  <summary>Details</summary>
Motivation: 研究如何提高3D LiDAR 点云分类的性能。

Method: 使用自编码器表示和KNN分类器，与产品系数结合。

Result: 结合产品系数与自编码器表示和KNN分类器，可以明显提升分类性能。

Conclusion: 更丰富的产品系数集系统地改善了类别可分离性和整体准确性。

Abstract: This work extends our previous study on enhancing 3D LiDAR point-cloud
classification with product coefficients
\cite{medina2025integratingproductcoefficientsimproved}, measure-theoretic
descriptors that complement the original spatial Lidar features. Here, we show
that combining product coefficients with an autoencoder representation and a
KNN classifier delivers consistent performance gains over both PCA-based
baselines and our earlier framework. We also investigate the effect of adding
product coefficients level by level, revealing a clear trend: richer sets of
coefficients systematically improve class separability and overall accuracy.
The results highlight the value of combining hierarchical product-coefficient
features with autoencoders to push LiDAR classification performance further.

</details>


### [145] [Stress-Aware Learning under KL Drift via Trust-Decayed Mirror Descent](https://arxiv.org/abs/2510.15222)
*Gabriel Nixon Raj*

Main category: cs.LG

TL;DR: 研究了分布漂移下的顺序决策，提出了熵正则化的信任衰退方法，能够有效优化决策过程并提供稳健性分析。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决分布漂移情况下顺序决策的挑战，提供稳健性和适应性的决策框架。

Method: 采用熵正则化的信任衰退方法，通过Fenchel对偶等价性和动态后悔保证进行分析。

Result: 本研究分析了分布漂移下的顺序决策过程。提出了一种熵正则化的信任衰退方法，结合了应力感知的指数倾斜。通过在简单体上的Fenchel对偶等价性表明，信念倾斜和决策倾斜是一致的。研究采用脆弱性、信念带宽和决策空间脆弱指数等指标来形式化稳健性。证明了高概率的灵敏度界限，并在KL漂移路径长度S_T下建立了动态后悔保证。此外，信任衰退能够实现每次切换后悔为O(1)，而无应力更新则会导致Ω(1)的尾部损失。该方法具有参数自由的特点，自适应地调整倾斜以应对未知漂移，并且进一步扩展了对二阶更新、赌博反馈和分布式优化等领域的应用。

Conclusion: 该框架统一了动态后悔分析、分布稳健目标和KL正则化控制，为应对分布漂移提供了一种适应性更新机制。

Abstract: We study sequential decision-making under distribution drift. We propose
entropy-regularized trust-decay, which injects stress-aware exponential tilting
into both belief updates and mirror-descent decisions. On the simplex, a
Fenchel-dual equivalence shows that belief tilt and decision tilt coincide. We
formalize robustness via fragility (worst-case excess risk in a KL ball),
belief bandwidth (radius sustaining a target excess), and a decision-space
Fragility Index (drift tolerated at $O(\sqrt{T})$ regret). We prove
high-probability sensitivity bounds and establish dynamic-regret guarantees of
$\tilde{O}(\sqrt{T})$ under KL-drift path length $S_T = \sum_{t\ge2}\sqrt{{\rm
KL}(D_t|D_{t-1})/2}$. In particular, trust-decay achieves $O(1)$ per-switch
regret, while stress-free updates incur $\Omega(1)$ tails. A parameter-free
hedge adapts the tilt to unknown drift, whereas persistent over-tilting yields
an $\Omega(\lambda^2 T)$ stationary penalty. We further obtain
calibrated-stress bounds and extensions to second-order updates, bandit
feedback, outliers, stress variation, distributed optimization, and plug-in
KL-drift estimation. The framework unifies dynamic-regret analysis,
distributionally robust objectives, and KL-regularized control within a single
stress-adaptive update.

</details>


### [146] [FinTrust: A Comprehensive Benchmark of Trustworthiness Evaluation in Finance Domain](https://arxiv.org/abs/2510.15232)
*Tiansheng Hu,Tongyan Hu,Liuyang Bai,Yilun Zhao,Arman Cohan,Chen Zhao*

Main category: cs.LG

TL;DR: 本论文提出FinTrust，一个评估LLM在金融领域可信性的基准，发现专有模型在安全性上表现优秀，但法律意识不足。


<details>
  <summary>Details</summary>
Motivation: 鉴于现有LLM在金融应用中的表现亟需提升，特别是在风险和法律意识上下足功夫，因此提出FinTrust作为评估工具。

Method: 构建了一个专门针对金融应用的LLM可信性评估基准FinTrust，通过细化任务评估各个信任度维度。

Result: 评估了十一种LLM，发现o4-mini在多数安全任务中表现优异，而DeepSeek-V3在行业公平性方面占优势；所有模型在受托人对齐和披露任务中均表现不足。

Conclusion: FinTrust是评估金融领域中LLM可信性的有价值基准，识别出不同模型在信任度各维度上的表现差异。

Abstract: Recent LLMs have demonstrated promising ability in solving finance related
problems. However, applying LLMs in real-world finance application remains
challenging due to its high risk and high stakes property. This paper
introduces FinTrust, a comprehensive benchmark specifically designed for
evaluating the trustworthiness of LLMs in finance applications. Our benchmark
focuses on a wide range of alignment issues based on practical context and
features fine-grained tasks for each dimension of trustworthiness evaluation.
We assess eleven LLMs on FinTrust and find that proprietary models like o4-mini
outperforms in most tasks such as safety while open-source models like
DeepSeek-V3 have advantage in specific areas like industry-level fairness. For
challenging task like fiduciary alignment and disclosure, all LLMs fall short,
showing a significant gap in legal awareness. We believe that FinTrust can be a
valuable benchmark for LLMs' trustworthiness evaluation in finance domain.

</details>


### [147] [Adaptive Individual Uncertainty under Out-Of-Distribution Shift with Expert-Routed Conformal Prediction](https://arxiv.org/abs/2510.15233)
*Amitesh Badkul,Lei Xie*

Main category: cs.LG

TL;DR: 本论文提出一种新型方法TESSERA，解决药物发现中的不确定性量化问题，具有可靠的覆盖率和适应性的预测区间。


<details>
  <summary>Details</summary>
Motivation: 针对当前机器学习社区在高风险领域应用时缺乏可靠、不确定且信息丰富的量化方法，特别是在药物发现的蛋白质-配体亲和预测中，通过提供适应性预测宽度来提高实际决策的有效性。

Method: 引入TESSERA方法，结合多种专家的多样性与符合校准，通过分层覆盖评估和错误稀疏化分析，进行不确定性量化。

Result: 本研究提出了一种名为TESSERA的新型不确定性量化方法，该方法在药物发现领域尤其针对蛋白质-配体亲和预测中的不确定性问题，提供了可靠的覆盖保障和适应性预测区间。TESSERA通过对样本的每个不确定性进行评估，同时跨越不同的数据分布，达到了接近于名义覆盖和最佳的覆盖宽度平衡。该方法结合了专家的多样性与符合校准，适合在特定预测和下游决策中应用。

Conclusion: TESSERA方法有效整合了专家的多样性与符合校准，为药物发现及其它应用提供了可信、紧凑且适应的不确定性评估。

Abstract: Reliable, informative, and individual uncertainty quantification (UQ) remains
missing in current ML community. This hinders the effective application of
AI/ML to risk-sensitive domains. Most methods either fail to provide coverage
on new data, inflate intervals so broadly that they are not actionable, or
assign uncertainties that do not track actual error, especially under a
distribution shift. In high-stakes drug discovery, protein-ligand affinity
(PLI) prediction is especially challenging as assay noise is heterogeneous,
chemical space is imbalanced and large, and practical evaluations routinely
involve distribution shift. In this work, we introduce a novel uncertainty
quantification method, Trustworthy Expert Split-conformal with Scaled
Estimation for Efficient Reliable Adaptive intervals (TESSERA), that provides
per-sample uncertainty with reliable coverage guarantee, informative and
adaptive prediction interval widths that track the absolute error. We evaluate
on protein-ligand binding affinity prediction under both independent and
identically distributed (i.i.d.) and scaffold-based out-of-distribution (OOD)
splits, comparing against strong UQ baselines. TESSERA attains near-nominal
coverage and the best coverage-width trade-off as measured by the
Coverage-Width Criterion (CWC), while maintaining competitive adaptivity
(lowest Area Under the Sparsification Error (AUSE)). Size-Stratified Coverage
(SSC) further confirms that intervals are right-sized, indicating width
increases when data are scarce or noisy, and remain tight when predictions are
reliable. By unifying Mixture of Expert (MoE) diversity with conformal
calibration, TESSERA delivers trustworthy, tight, and adaptive uncertainties
that are well-suited to selective prediction and downstream decision-making in
the drug-discovery pipeline and other applications.

</details>


### [148] [Spatiotemporal Transformers for Predicting Avian Disease Risk from Migration Trajectories](https://arxiv.org/abs/2510.15254)
*Dingya Feng,Dingyuan Xue*

Main category: cs.LG

TL;DR: 本研究提出了一种基于Transformer的框架，用于预测迁徙鸟类终点位置的疾病风险，整合多种数据集，模型展示出优异的预测性能，支持鸟类疾病的早期预警。


<details>
  <summary>Details</summary>
Motivation: 精确预测鸟类疾病爆发对野生动物保护和公共卫生至关重要。

Method: 采用基于Transformer的框架，整合多源数据集并应用H3层级地理编码处理原始坐标。

Result: 在测试集上的评估显示模型具有强预测性能，准确率达0.9821，ROC曲线下的面积(AUC)为0.9803，平均精度(AP)为0.9299，以及最佳阈值下的F1-score为0.8836。

Conclusion: Transformer架构在鸟类疾病预警系统中具有潜在应用，可促进及时干预和预防策略。

Abstract: Accurate forecasting of avian disease outbreaks is critical for wildlife
conservation and public health. This study presents a Transformer-based
framework for predicting the disease risk at the terminal locations of
migratory bird trajectories. We integrate multi-source datasets, including GPS
tracking data from Movebank, outbreak records from the World Organisation for
Animal Health (WOAH), and geospatial context from GADM and Natural Earth. The
raw coordinates are processed using H3 hierarchical geospatial encoding to
capture spatial patterns. The model learns spatiotemporal dependencies from
bird movement sequences to estimate endpoint disease risk. Evaluation on a
held-out test set demonstrates strong predictive performance, achieving an
accuracy of 0.9821, area under the ROC curve (AUC) of 0.9803, average precision
(AP) of 0.9299, and an F1-score of 0.8836 at the optimal threshold. These
results highlight the potential of Transformer architectures to support
early-warning systems for avian disease surveillance, enabling timely
intervention and prevention strategies.

</details>


### [149] [DRO-InstructZero: Distributionally Robust Prompt Optimization for Large Language Models](https://arxiv.org/abs/2510.15260)
*Yangyang Li*

Main category: cs.LG

TL;DR: DRO-InstructZero通过稳健的贝叶斯优化增强了大型语言模型在提示优化中的可靠性与迁移能力，在多个任务上表现出显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在不同提示（prompt）表述下的性能差异，并提出改进方法以增强模型在分布变化下的可靠性与转移能力。

Method: DRO-InstructZero将零样本提示优化形式化为稳健的贝叶斯优化，定义一个模糊集围绕评估分布，利用稳健采集规则最大化最坏情况下的期望效用。

Result: 通过引入稳健的贝叶斯优化，DRO-InstructZero能够在提示优化过程中增强模型在不同任务设置类别下的性能，实验显示在多个任务上显著提高了准确率。

Conclusion: DRO-InstructZero将分布稳健优化与提示学习相结合，为在真实世界不确定性下实现可靠的提示对齐提供了一种通用的方法。

Abstract: Large language models are highly sensitive to prompt wording. However,
popular automatic prompt search methods, including InstructZero, often degrade
under distribution shift and adversarial evaluation because they optimize
expected performance under a single evaluation distribution. Consequently,
prompts that work in one setting frequently fail to transfer. To address this,
DRO-InstructZero formulates zero-shot prompt optimization as robust Bayesian
optimization. Specifically, an f-divergence ball defines an ambiguity set
around the evaluation distribution, and a robust acquisition rule maximizes
worst-case expected utility while retaining the query efficiency of Bayesian
search. Therefore, the search explicitly targets reliability under distribution
shift rather than average behavior alone. Experiments follow the
instruction-induction protocol with matched query budgets across formality
rewriting, code debugging, and translation. For example, on BIG-Bench
informative-to-formal rewriting, accuracy improves from 61.3 +/- 0.7% to
approximately 85-90%, yielding an absolute gain of about 25-30 points.
Moreover, auto-debugging shows about +25-point gains under domain shift.
Meanwhile, stable tasks such as cause-and-effect remain above 96%, indicating
no loss on in-distribution cases. Furthermore, improvements are consistent
across divergence choices and decoding temperatures. Overall, DRO-InstructZero
connects distributionally robust optimization with prompt learning, offering a
plug-and-play and general approach for reliable, transferable prompt alignment
under real-world uncertainty.

</details>


### [150] [Causal Time Series Modeling of Supraglacial Lake Evolution in Greenland under Distribution Shift](https://arxiv.org/abs/2510.15265)
*Emam Hossain,Muhammad Hasan Ferdous,Devon Dunmire,Aneesh Subramanian,Md Osman Gani*

Main category: cs.LG

TL;DR: RIC-TSC框架通过因果建模识别格林兰超冰湖演化的关键因素，提高了模型的预测精度，比基于相关的模型更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 改善时序数据分析中的鲁棒性和泛化能力，克服以往模型仅依赖于相关特征的问题。

Method: 采用Joint PCMCI+方法，对格林兰超冰湖的演化进行区域特异性和不变性的因果关系建模。

Result: 本文提出了一种区域知情的因果时间序列分类框架RIC-TSC，通过将延迟感知的因果发现直接嵌入序列建模，增强了预测准确性和科学可解释性。研究使用多种卫星和气象数据，识别格林兰超冰湖演化的区域特异性和不变预测因子，展示了因果建模的方法在提高模型鲁棒性及泛化能力方面的潜力。

Conclusion: 因果发现不仅是特征选择的手段，也为地球动态过程建立可泛化和机制性模型提供了新路径。

Abstract: Causal modeling offers a principled foundation for uncovering stable,
invariant relationships in time-series data, thereby improving robustness and
generalization under distribution shifts. Yet its potential is underutilized in
spatiotemporal Earth observation, where models often depend on purely
correlational features that fail to transfer across heterogeneous domains. We
propose RIC-TSC, a regionally-informed causal time-series classification
framework that embeds lag-aware causal discovery directly into sequence
modeling, enabling both predictive accuracy and scientific interpretability.
Using multi-modal satellite and reanalysis data-including Sentinel-1 microwave
backscatter, Sentinel-2 and Landsat-8 optical reflectance, and CARRA
meteorological variables-we leverage Joint PCMCI+ (J-PCMCI+) to identify
region-specific and invariant predictors of supraglacial lake evolution in
Greenland. Causal graphs are estimated globally and per basin, with validated
predictors and their time lags supplied to lightweight classifiers. On a
balanced benchmark of 1000 manually labeled lakes from two contrasting melt
seasons (2018-2019), causal models achieve up to 12.59% higher accuracy than
correlation-based baselines under out-of-distribution evaluation. These results
show that causal discovery is not only a means of feature selection but also a
pathway to generalizable and mechanistically grounded models of dynamic Earth
surface processes.

</details>


### [151] [Semi-Supervised Regression with Heteroscedastic Pseudo-Labels](https://arxiv.org/abs/2510.15266)
*Xueqing Sun,Renzhen Wang,Quanziang Wang,Yichen Wu,Xixi Jia,Deyu Meng*

Main category: cs.LG

TL;DR: 本文提出了一种不确定性感知的伪标签框架，专注于半监督回归中的伪标签可靠性问题，通过双层优化有效提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 虽然伪标签在半监督学习中广泛使用，但其在半监督回归中的应用还未得到充分探索，尤其是在处理持续输出和异方差噪声时的挑战。

Method: 采用双层优化的视角，动态调整伪标签的影响，通过共同最小化所有数据的经验风险和优化不确定性估计来增强对标记数据的泛化能力。

Result: 通过理论见解和大量实验验证了提出方法的有效性，结果显示其相较现有方法具有更好的鲁棒性和性能。

Conclusion: 提出了一种不确定性感知的伪标签框架，能够有效减轻不可靠伪标签的影响，并在多种基准半监督回归数据集上验证了其卓越的鲁棒性和性能。

Abstract: Pseudo-labeling is a commonly used paradigm in semi-supervised learning, yet
its application to semi-supervised regression (SSR) remains relatively
under-explored. Unlike classification, where pseudo-labels are discrete and
confidence-based filtering is effective, SSR involves continuous outputs with
heteroscedastic noise, making it challenging to assess pseudo-label
reliability. As a result, naive pseudo-labeling can lead to error accumulation
and overfitting to incorrect labels. To address this, we propose an
uncertainty-aware pseudo-labeling framework that dynamically adjusts
pseudo-label influence from a bi-level optimization perspective. By jointly
minimizing empirical risk over all data and optimizing uncertainty estimates to
enhance generalization on labeled data, our method effectively mitigates the
impact of unreliable pseudo-labels. We provide theoretical insights and
extensive experiments to validate our approach across various benchmark SSR
datasets, and the results demonstrate superior robustness and performance
compared to existing methods. Our code is available at
https://github.com/sxq/Heteroscedastic-Pseudo-Labels.

</details>


### [152] [Foundation Models for Scientific Discovery: From Paradigm Enhancement to Paradigm Transition](https://arxiv.org/abs/2510.15280)
*Fan Liu,Jindong Han,Tengfei Lyu,Weijia Zhang,Zhe-Rui Yang,Lu Dai,Cancheng Liu,Hao Liu*

Main category: cs.LG

TL;DR: 基础模型重新定义科学研究，推动其向新的范式发展，分为三个阶段，并讨论其应用、风险与未来方向。


<details>
  <summary>Details</summary>
Motivation: 探讨基础模型是否在单纯增强现有科学方法论，或是重新定义科学研究的方式。

Method: 通过框架分析基础模型在科学研究中的应用和影响，划分为三个阶段：元科学整合、混合人机共创、自主科学发现。

Result: 基础模型在加速科学研究的同时，促进了更深层次的科学转型，为科学社区反思未来科研提供了支持。

Conclusion: 基础模型正在推动科学研究向新的范式转变，成为科学发现中的重要角色。

Abstract: Foundation models (FMs), such as GPT-4 and AlphaFold, are reshaping the
landscape of scientific research. Beyond accelerating tasks such as hypothesis
generation, experimental design, and result interpretation, they prompt a more
fundamental question: Are FMs merely enhancing existing scientific
methodologies, or are they redefining the way science is conducted? In this
paper, we argue that FMs are catalyzing a transition toward a new scientific
paradigm. We introduce a three-stage framework to describe this evolution: (1)
Meta-Scientific Integration, where FMs enhance workflows within traditional
paradigms; (2) Hybrid Human-AI Co-Creation, where FMs become active
collaborators in problem formulation, reasoning, and discovery; and (3)
Autonomous Scientific Discovery, where FMs operate as independent agents
capable of generating new scientific knowledge with minimal human intervention.
Through this lens, we review current applications and emerging capabilities of
FMs across existing scientific paradigms. We further identify risks and future
directions for FM-enabled scientific discovery. This position paper aims to
support the scientific community in understanding the transformative role of
FMs and to foster reflection on the future of scientific discovery. Our project
is available at
https://github.com/usail-hkust/Awesome-Foundation-Models-for-Scientific-Discovery.

</details>


### [153] [On the Generalization Properties of Learning the Random Feature Models with Learnable Activation Functions](https://arxiv.org/abs/2510.15327)
*Zailin Ma,Jiansheng Yang,Yaodong Yang*

Main category: cs.LG

TL;DR: 本文研究了随机特征模型（RFLAF）的泛化性能，提出了依赖于数据的采样方案，显著改善了特征数量的理论界限，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 提出新的采样方案以改善最近提出的核方法的学习性能，提升特征数的界限，增强学习任务的有效性。

Method: 采用依赖于数据的采样方案来产生特征，从而获得更紧凑的特征数量界限，并提出了一种寻找近似核的算法。

Result: 本文研究了一种新近提出的核方法——具有可学习激活函数的随机特征模型（RFLAF）的泛化性能。通过应用依赖于数据的采样方案生成特征，我们提供了学习RFLAF所需特征数的最优界限。我们提供了一个统一定理，描述特征数量s的复杂度，并讨论了普通采样方案和基于数据的杠杆加权方案的结果。通过加权采样，在均方误差损失情况下，特征数s的界限从Ω(1/ε²)改善到˜Ω((1/ε)^{1/t})，当Gram矩阵具有有限秩时甚至改善到Ω(1)。对于Lipschitz损失情况，界限从Ω(1/ε²)改善到˜Ω((1/ε²)^{1/t})。为了学习加权RFLAF，我们还提出了一种算法以找到近似核并应用杠杆加权采样。实证结果表明，加权RFLAF在特征数量显著减少的情况下，具有与普通采样RFLAF相同的性能，有效验证了我们的理论和该方法的有效性。

Conclusion: 加权RFLAF在特征数量减少的情况下，仍能保持良好的学习性能，这验证了理论研究的有效性。

Abstract: This paper studies the generalization properties of a recently proposed
kernel method, the Random Feature models with Learnable Activation Functions
(RFLAF). By applying a data-dependent sampling scheme for generating features,
we provide by far the sharpest bounds on the required number of features for
learning RFLAF in both the regression and classification tasks. We provide a
unified theorem that describes the complexity of the feature number $s$, and
discuss the results for the plain sampling scheme and the data-dependent
leverage weighted scheme. Through weighted sampling, the bound on $s$ in the
MSE loss case is improved from $\Omega(1/\epsilon^2)$ to
$\tilde{\Omega}((1/\epsilon)^{1/t})$ in general $(t\geq 1)$, and even to
$\Omega(1)$ when the Gram matrix has a finite rank. For the Lipschitz loss
case, the bound is improved from $\Omega(1/\epsilon^2)$ to
$\tilde{\Omega}((1/\epsilon^2)^{1/t})$. To learn the weighted RFLAF, we also
propose an algorithm to find an approximate kernel and then apply the leverage
weighted sampling. Empirical results show that the weighted RFLAF achieves the
same performances with a significantly fewer number of features compared to the
plainly sampled RFLAF, validating our theories and the effectiveness of this
method.

</details>


### [154] [Towards Robust Zero-Shot Reinforcement Learning](https://arxiv.org/abs/2510.15382)
*Kexin Zheng,Lauriane Teyssier,Yinan Zheng,Yu Luo,Xiayuan Zhan*

Main category: cs.LG

TL;DR: 提出BREEZE框架，解决了离线零-shot强化学习中的表现不足，显著提高了策略提取和表示学习质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有FB方法在零-shot强化学习中的表现不足，尤其是对分布外动作的外推错误带来的偏差问题。

Method: 提出了行为正则化的框架BREEZE，通过任务条件的扩散模型提取策略，同时使用基于注意力的架构来建模表示。

Result: BREEZE提升了学习的稳定性、策略提取能力及表示学习质量，在多个实验中显示出优越的性能。

Conclusion: BREEZE方法在离线零-shot强化学习中表现出最佳或接近最佳的性能，并在稳健性上优于以往的方法。

Abstract: The recent development of zero-shot reinforcement learning (RL) has opened a
new avenue for learning pre-trained generalist policies that can adapt to
arbitrary new tasks in a zero-shot manner. While the popular Forward-Backward
representations (FB) and related methods have shown promise in zero-shot RL, we
empirically found that their modeling lacks expressivity and that extrapolation
errors caused by out-of-distribution (OOD) actions during offline learning
sometimes lead to biased representations, ultimately resulting in suboptimal
performance. To address these issues, we propose Behavior-REgularizEd Zero-shot
RL with Expressivity enhancement (BREEZE), an upgraded FB-based framework that
simultaneously enhances learning stability, policy extraction capability, and
representation learning quality. BREEZE introduces behavioral regularization in
zero-shot RL policy learning, transforming policy optimization into a stable
in-sample learning paradigm. Additionally, BREEZE extracts the policy using a
task-conditioned diffusion model, enabling the generation of high-quality and
multimodal action distributions in zero-shot RL settings. Moreover, BREEZE
employs expressive attention-based architectures for representation modeling to
capture the complex relationships between environmental dynamics. Extensive
experiments on ExORL and D4RL Kitchen demonstrate that BREEZE achieves the best
or near-the-best performance while exhibiting superior robustness compared to
prior offline zero-shot RL methods. The official implementation is available
at: https://github.com/Whiterrrrr/BREEZE.

</details>


### [155] [Iterative Refinement of Flow Policies in Probability Space for Online Reinforcement Learning](https://arxiv.org/abs/2510.15388)
*Mingyang Sun,Pengxiang Ding,Weinan Zhang,Donglin Wang*

Main category: cs.LG

TL;DR: SWFP框架提高了复杂技能学习中的稳定性和适应能力，有效解决了分布转移问题，并在实验中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 解决行为克隆中流/扩散策略学习复杂技能时面对的分布转移问题，克服传统RL方法在模型微调时的局限性。

Method: 使用逐步流策略(SWFP)框架，通过固定步长欧拉方案对流匹配推断过程进行离散化，与最优传输的变分JKO原则相对齐。

Result: SWFP通过一系列小的增量变换对全局流进行解构，实现金融调优，并在训练时间、计算/内存成本及稳定性上提供显著优势。

Conclusion: SWFP在多样化机器人控制基准上展现了增强的稳定性、效率及卓越的适应性能。

Abstract: While behavior cloning with flow/diffusion policies excels at learning
complex skills from demonstrations, it remains vulnerable to distributional
shift, and standard RL methods struggle to fine-tune these models due to their
iterative inference process and the limitations of existing workarounds. In
this work, we introduce the Stepwise Flow Policy (SWFP) framework, founded on
the key insight that discretizing the flow matching inference process via a
fixed-step Euler scheme inherently aligns it with the variational
Jordan-Kinderlehrer-Otto (JKO) principle from optimal transport. SWFP
decomposes the global flow into a sequence of small, incremental
transformations between proximate distributions. Each step corresponds to a JKO
update, regularizing policy changes to stay near the previous iterate and
ensuring stable online adaptation with entropic regularization. This
decomposition yields an efficient algorithm that fine-tunes pre-trained flows
via a cascade of small flow blocks, offering significant advantages:
simpler/faster training of sub-models, reduced computational/memory costs, and
provable stability grounded in Wasserstein trust regions. Comprehensive
experiments demonstrate SWFP's enhanced stability, efficiency, and superior
adaptation performance across diverse robotic control benchmarks.

</details>


### [156] [Online Kernel Dynamic Mode Decomposition for Streaming Time Series Forecasting with Adaptive Windowing](https://arxiv.org/abs/2510.15404)
*Christopher Salazar,Krithika Manohar,Ashis G. Banerjee*

Main category: cs.LG

TL;DR: WORK-DMD是一种新方法，结合了随机傅里叶特征与在线动态模式分解，能够在流数据中实现高效的实时预测，尤其在短期预测中表现突出。


<details>
  <summary>Details</summary>
Motivation: 实时预测流数据面临非平稳动态、严格计算限制及快速适应的挑战。

Method: 通过随机傅里叶特征与在线动态模式分解相结合，使用滚动窗口中的Sherman-Morrison更新进行连续适应。

Result: WORK-DMD在多个领域的基准数据集上表现出较强的准确性，优于多种现有在线预测方法。

Conclusion: WORK-DMD结合了核评估和自适应矩阵更新，提供了一种有效的实时预测替代方案。

Abstract: Real-time forecasting from streaming data poses critical challenges: handling
non-stationary dynamics, operating under strict computational limits, and
adapting rapidly without catastrophic forgetting. However, many existing
approaches face trade-offs between accuracy, adaptability, and efficiency,
particularly when deployed in constrained computing environments. We introduce
WORK-DMD (Windowed Online Random Kernel Dynamic Mode Decomposition), a method
that combines Random Fourier Features with online Dynamic Mode Decomposition to
capture nonlinear dynamics through explicit feature mapping, while preserving
fixed computational cost and competitive predictive accuracy across evolving
data. WORK-DMD employs Sherman-Morrison updates within rolling windows,
enabling continuous adaptation to evolving dynamics from only current data,
eliminating the need for lengthy training or large storage requirements for
historical data. Experiments on benchmark datasets across several domains show
that WORK-DMD achieves higher accuracy than several state-of-the-art online
forecasting methods, while requiring only a single pass through the data and
demonstrating particularly strong performance in short-term forecasting. Our
results show that combining kernel evaluations with adaptive matrix updates
achieves strong predictive performance with minimal data requirements. This
sample efficiency offers a practical alternative to deep learning for streaming
forecasting applications.

</details>


### [157] [ParaFormer: Shallow Parallel Transformers with Progressive Approximation](https://arxiv.org/abs/2510.15425)
*Wei Wang,Xiao-Yong Wei,Qing Li*

Main category: cs.LG

TL;DR: ParaFormer是一种浅层Transformer架构，旨在通过结构和计算的真正并行性来解决深层模型训练时间长和推理延迟高的问题。


<details>
  <summary>Details</summary>
Motivation: 解决深层Transformer在训练时间和推理延迟上面临的挑战，同时提高模型在资源受限设备上的可行性。

Method: 通过将标准Transformer视为封闭形式的函数逼近器，并实施算法化的层间协作与逐步逼近，ParaFormer打破了传统的顺序设计限制。

Result: ParaFormer在性能上超过了标准Transformer，如ViT，支持高达15.07倍的模型压缩，并在多GPU部署中实现比常用并行解决方案快3.30倍。

Conclusion: ParaFormer在性能和效率上显著优于传统的深层Transformer，并支持模型压缩与扩展，有利于自适应学习。

Abstract: The widespread 'deeper is better' philosophy has driven the creation of
architectures like ResNet and Transformer, which achieve high performance by
stacking numerous layers. However, increasing model depth comes with challenges
such as longer training times, higher inference latency, and impracticality on
resource-constrained devices. To address these issues, we propose ParaFormer, a
shallow Transformer architecture designed for true parallelism in both
structure and computation. By formulating standard Transformers as function
approximators in closed-form, our theoretical analysis shows that their
performance relies on inter-layer collaboration for progressive approximation,
rather than depth itself. While deep Transformers enforce this collaboration
through sequential designs, we demonstrate that such collaboration is not
inherently tied to sequential structures. ParaFormer removes the sequential
constraint by organizing layers into parallel branches, enforcing inter-layer
collaboration algorithmically. Specifically, we implement progressive
approximation, ensuring that each new branch further reduces the loss from
preceding branches, enabling faster convergence. Extensive experiments validate
ParaFormer's effectiveness, outperforming standard Transformers like ViT.
Moreover, ParaFormer supports up to 15.07x model compression and facilitates
model expansion for adaptive continuous learning. Experimental results on
multi-GPU deployment demonstrate that ParaFormer is 3.30x faster than widely
used parallelism solutions such as FairScale. These advancements stem from our
closed-form formulation of Transformers based on the Universal Approximation
Theorem, which not only explains the ``depth belief'' but also opens new
avenues for designing efficient Transformer architectures. Source code:
https://(open-upon-acceptance)

</details>


### [158] [Safe, Efficient, and Robust Reinforcement Learning for Ranking and Diffusion Models](https://arxiv.org/abs/2510.15429)
*Shashank Gupta*

Main category: cs.LG

TL;DR: 本论文研究了安全且高效的强化学习方法，适用于排名、推荐以及文本到图像生成，提出了改进的算法和理论框架。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决强化学习在实际应用中可能面临的安全性、样本效率和鲁棒性问题，特别是在排名和推荐系统以及文本到图像生成模型中。

Method: 通过构建与上下文赌博机强化学习相关的理论和算法，分析了安全部署、单动作赌博机和生成性强化学习的效率与有效性之间的权衡。

Result: 提出了安全的风险最小化目标，优化了离线策略的评估和政策梯度的可靠性，同时引入了LOOP算法，提升了生成质量与样本效率。

Conclusion: 该研究提出了一种安全、高效且鲁棒的强化学习方法，适用于排名、推荐和文本到图像扩散模型等应用领域。

Abstract: This dissertation investigates how reinforcement learning (RL) methods can be
designed to be safe, sample-efficient, and robust. Framed through the unifying
perspective of contextual-bandit RL, the work addresses two major application
domains - ranking and recommendation, and text-to-image diffusion models. The
first part of the thesis develops theory and algorithms for safe deployment in
ranking systems. An exposure-based generalisation bound is derived, leading to
a counterfactual risk-minimisation objective whose solution is guaranteed not
to underperform the logging policy, even with sparse feedback. This guarantee
is extended to doubly robust estimators, enabling safety even under adversarial
or misspecified user models and offering practitioners explicit control over
permissible utility loss. The second part turns to single-action bandits, where
various off-policy estimators are unified within a baseline-correction
framework. A closed-form optimal baseline is proposed and shown to minimise
both evaluation and policy-gradient variance, thereby improving off-policy
learning reliability. The final part examines the trade-offs between efficiency
and effectiveness in generative RL. A systematic study of PPO and REINFORCE
motivates the Leave-One-Out PPO (LOOP) algorithm, which combines multiple
diffusion trajectories with a REINFORCE-style baseline inside PPO's clipped
objective. LOOP achieves PPO-level sample efficiency while producing
generations that align more faithfully with textual attributes.

</details>


### [159] [A Theoretical Study on Bridging Internal Probability and Self-Consistency for LLM Reasoning](https://arxiv.org/abs/2510.15444)
*Zhi Zhou,Yuhao Tan,Zenan Li,Yuan Yao,Lan-Zhe Guo,Yu-Feng Li,Xiaoxing Ma*

Main category: cs.LG

TL;DR: 本文建立了取样基础的测试时间扩展方法的理论框架，提出了RPC方法，以解决现有方法的局限性并提高推理效果。


<details>
  <summary>Details</summary>
Motivation: 探索取样基础的测试时间扩展方法在理论上的基础，尤其是如何通过增强推理路径来提高LLM的推理性能。

Method: 分析了自一致性和困惑度两种主流范式，提出了RPC方法，结合了理论分析和实证结果。

Result: 提出了一种混合方法RPC，结合了困惑度一致性和推理剪枝，以提高推理性能并减少推理错误。

Conclusion: RPC方法在推理性能上与自一致性方法相当，显著提高了置信度的可靠性，并将抽样成本降低了50%。

Abstract: Test-time scaling seeks to improve the reasoning performance of large
language models (LLMs) by adding computational resources. A prevalent approach
within the field is sampling-based test-time scaling methods, which enhance
reasoning by generating multiple reasoning paths for a given input during
inference. However, despite its practical success, the theoretical foundations
remain underexplored. In this paper, we provide the first theoretical framework
for analyzing sampling-based test-time scaling methods, grounded in the
perspective of confidence estimation. Based on the framework, we analyze two
dominant paradigms: self-consistency and perplexity, and reveal key
limitations: self-consistency suffers from high estimation error while
perplexity exhibits substantial modeling error and possible degradation of the
estimation error convergence. To address these limitations, we introduce RPC, a
hybrid method that leverages our theoretical insights through two key
components: Perplexity Consistency and Reasoning Pruning. Perplexity
Consistency combines the strengths of self-consistency and perplexity, boosting
the convergence rate of estimation error from linear to exponential while
preserving model error. Reasoning Pruning prevents degradation by eliminating
low-probability reasoning paths. Both theoretical analysis and empirical
results across seven benchmark datasets demonstrate that RPC has a strong
potential for reducing reasoning error. Notably, RPC achieves reasoning
performance comparable to self-consistency while not only enhancing confidence
reliability but also reducing sampling costs by 50%. The code and resources are
available at https://wnjxyk.github.io/RPC.

</details>


### [160] [Expediting Reinforcement Learning by Incorporating Knowledge About Temporal Causality in the Environment](https://arxiv.org/abs/2510.15456)
*Jan Corazza,Hadi Partovi Aria,Daniel Neider,Zhe Xu*

Main category: cs.LG

TL;DR: 提出了一种新方法，结合时间逻辑因果图，以帮助强化学习算法在复杂任务中更快学习和转移能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习算法在奖励反馈稀疏且依赖于复杂环境事件序列的任务中表现不佳，而现有的概率奖励机具有手动修改和设计困难的问题。

Method: 提出了一种基于时间逻辑的因果图的方法，以将因果信息纳入奖励形式中。

Result: 通过理论证明和实证展示，该方法加速了政策学习并提高了任务规范在新环境中的转移能力。

Conclusion: 本研究提出的方法有效结合因果信息，促进了政策学习并支持任务规范向新环境的转移，同时提供了理论收敛性结果和实证支持。

Abstract: Reinforcement learning (RL) algorithms struggle with learning optimal
policies for tasks where reward feedback is sparse and depends on a complex
sequence of events in the environment. Probabilistic reward machines (PRMs) are
finite-state formalisms that can capture temporal dependencies in the reward
signal, along with nondeterministic task outcomes. While special RL algorithms
can exploit this finite-state structure to expedite learning, PRMs remain
difficult to modify and design by hand. This hinders the already difficult
tasks of utilizing high-level causal knowledge about the environment, and
transferring the reward formalism into a new domain with a different causal
structure. This paper proposes a novel method to incorporate causal information
in the form of Temporal Logic-based Causal Diagrams into the reward formalism,
thereby expediting policy learning and aiding the transfer of task
specifications to new environments. Furthermore, we provide a theoretical
result about convergence to optimal policy for our method, and demonstrate its
strengths empirically.

</details>


### [161] [Learning to Answer from Correct Demonstrations](https://arxiv.org/abs/2510.15464)
*Nirmit Joshi,Gene Li,Siddharth Bhandari,Shiva Prasad Kasiviswanathan,Cong Ma,Nathan Srebro*

Main category: cs.LG

TL;DR: 本文研究了如何在上下文赌博中进行离线模仿学习以生成多个可能的正确答案，提出了一种新的低基数奖励模型方法。


<details>
  <summary>Details</summary>
Motivation: 研究如何有效地从多个可能正确答案中学习生成合理的答案，并突破传统方法对展示者复杂性的假设限制。

Method: 离线模仿学习（offline imitation learning），在上下文赌博模型中学习生成答案。

Result: 提出了一种新的方法，能够在奖励模型为低基数类时，以对数样本复杂度学习，解决了以前方法在这种情况下失败的问题。

Conclusion: 通过引入低基数类奖励模型，我们的研究为基于示范的学习提供了新的思路，超越了最大似然估计的局限性。

Abstract: We study the problem of learning to generate an answer (or completion) to a
question (or prompt), where there could be multiple correct answers, any one of
which is acceptable at test time. Learning is based on demonstrations of some
correct answer to each training question, as in Supervised Fine Tuning (SFT).
We formalize the problem as offline imitation learning in contextual bandits,
with demonstrations from some optimal policy, without explicitly observed
rewards. Prior work assumes that the demonstrator belongs to a low-complexity
policy class, which motivates maximum likelihood estimation (i.e., log-loss
minimization). In contrast, we propose relying only on the reward model
(specifying which answers are correct) being in a low-cardinality class, which
we argue is a weaker assumption. We show that likelihood maximization methods
can fail in this case, and instead devise an alternative novel approach that
learns with sample complexity logarithmic in the cardinality of the reward
class. Our work motivates looking beyond likelihood maximization when learning
from correct demonstrations.

</details>


### [162] [Adversary-Free Counterfactual Prediction via Information-Regularized Representations](https://arxiv.org/abs/2510.15479)
*Shiqin Tang,Rong Feng,Shuxin Zhuang,Hongzong Li,Youzhi Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于信息论的反事实预测新方法，消除了处理-协变量依赖，无需对抗训练。


<details>
  <summary>Details</summary>
Motivation: 研究在赋值偏差下的反事实预测，旨在克服传统方法的局限性。

Method: 通过学习一个与结果预测相关的随机表示Z，并最小化Z与处理T之间的互信息，导出可处理的变分目标。

Result: 在控制的数值模拟和真实临床数据集上的评估显示，该方法优于最新的平衡、重加权和对抗基准。

Conclusion: 该方法在多个指标上表现优越，同时避免了对抗训练的稳定性问题和调参负担。

Abstract: We study counterfactual prediction under assignment bias and propose a
mathematically grounded, information-theoretic approach that removes
treatment-covariate dependence without adversarial training. Starting from a
bound that links the counterfactual-factual risk gap to mutual information, we
learn a stochastic representation Z that is predictive of outcomes while
minimizing I(Z; T). We derive a tractable variational objective that
upper-bounds the information term and couples it with a supervised decoder,
yielding a stable, provably motivated training criterion. The framework extends
naturally to dynamic settings by applying the information penalty to sequential
representations at each decision time. We evaluate the method on controlled
numerical simulations and a real-world clinical dataset, comparing against
recent state-of-the-art balancing, reweighting, and adversarial baselines.
Across metrics of likelihood, counterfactual error, and policy evaluation, our
approach performs favorably while avoiding the training instabilities and
tuning burden of adversarial schemes.

</details>


### [163] [OffSim: Offline Simulator for Model-based Offline Inverse Reinforcement Learning](https://arxiv.org/abs/2510.15495)
*Woo-Jin Ahn,Sang-Ryul Baek,Yong-Jun Lee,Hyun-Duck Choi,Myo-Taeg Lim*

Main category: cs.LG

TL;DR: OffSim是一种离线逆强化学习框架，通过专家轨迹模拟环境动态和奖励结构，从而在不与真实环境交互的情况下进行策略训练，实验表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习算法依赖于定义复杂的模拟器和奖励函数，本文旨在简化这一过程，提高学习效率和效果。

Method: 提出了一种模型驱动的离线逆强化学习框架OffSim，利用专家生成的轨迹模拟环境和奖励结构，并优化相关模型与奖励函数。

Result: 本文提出了一种名为离线模拟器（OffSim）的新型模型驱动的离线逆强化学习（IRL）框架，旨在通过专家生成的状态-动作轨迹直接模拟环境动态和奖励结构。OffSim共同优化高熵转移模型和基于IRL的奖励函数，促进探索并提高学习到的奖励的可推广性。借助这些学习到的组件，OffSim可以在无需与真实环境进一步交互的情况下进行离线策略训练。此外，文章还介绍了OffSim$^+$，这种拓展在多数据集环境下引入边际奖励，以增强探索。MuJoCo的实验结果表明，OffSim在性能上显著优于现有的离线IRL方法，验证了其有效性和鲁棒性。

Conclusion: OffSim提供了一种有效的方式来解决传统强化学习中构建模拟器与定义奖励函数的挑战，展现了在离线学习中的应用潜力。

Abstract: Reinforcement learning algorithms typically utilize an interactive simulator
(i.e., environment) with a predefined reward function for policy training.
Developing such simulators and manually defining reward functions, however, is
often time-consuming and labor-intensive. To address this, we propose an
Offline Simulator (OffSim), a novel model-based offline inverse reinforcement
learning (IRL) framework, to emulate environmental dynamics and reward
structure directly from expert-generated state-action trajectories. OffSim
jointly optimizes a high-entropy transition model and an IRL-based reward
function to enhance exploration and improve the generalizability of the learned
reward. Leveraging these learned components, OffSim can subsequently train a
policy offline without further interaction with the real environment.
Additionally, we introduce OffSim$^+$, an extension that incorporates a
marginal reward for multi-dataset settings to enhance exploration. Extensive
MuJoCo experiments demonstrate that OffSim achieves substantial performance
gains over existing offline IRL methods, confirming its efficacy and
robustness.

</details>


### [164] [Theoretical Refinement of CLIP by Utilizing Linear Structure of Optimal Similarity](https://arxiv.org/abs/2510.15508)
*Naoki Yoshida,Satoshi Hayakawa,Yuhta Takida,Toshimitsu Uesaka,Hiromi Wakaki,Yuki Mitsufuji*

Main category: cs.LG

TL;DR: 本研究提出了一种针对多模态对比预训练框架（如CLIP）相似度计算机制的增强方法，KME-CLIP，旨在更好地利用点互信息（PMI）的线性结构。


<details>
  <summary>Details</summary>
Motivation: 基于先前的理论研究，认为最佳的相似度度量应该对应于两个模态之间的点互信息（PMI），而现有CLIP及其变体未能充分利用PMI的线性结构。

Method: 通过在重现核希尔伯特空间中利用内积来实现对PMI的近似。

Result: 我们的理论证明了该方法能以任意精度近似PMI，并通过实验证明了其在多个任务上的优势。

Conclusion: KME-CLIP方法在多个检索和分类任务上总体上优于标准的CLIP公式。

Abstract: In this study, we propose an enhancement to the similarity computation
mechanism in multi-modal contrastive pretraining frameworks such as CLIP. Prior
theoretical research has demonstrated that the optimal similarity metrics
between paired modalities should correspond to the pointwise mutual information
(PMI) between the two modalities. However, the current implementations of CLIP
and its variants fail to fully utilize the underlying linear structure of PMI.
We therefore propose KME-CLIP, which leverages this structure through the inner
product in a reproducing kernel Hilbert space. We theoretically prove that our
method can approximate PMI with arbitrary accuracy and empirically demonstrate
that our approach overall outperforms the standard CLIP formulation across
several retrieval and classification tasks.

</details>


### [165] [Language Models are Injective and Hence Invertible](https://arxiv.org/abs/2510.15511)
*Giorgos Nikolaou,Tommaso Mencattini,Donato Crisostomi,Andrea Santilli,Yannis Panagakis,Emanuele Rodola'*

Main category: cs.LG

TL;DR: 本研究证明了Transformer模型是单射的，并提出了重建输入文本的算法SipIt，具有重要的应用价值。


<details>
  <summary>Details</summary>
Motivation: 质疑Transformer模型非单射的传统观点，探索输入与输出之间的关系

Method: 数学证明与实证验证结合的方法

Result: 提出了SipIt算法，可以有效重建输入文本，证明了Transformer模型的单射性

Conclusion: Transformer语言模型在输入与输出之间保持单射性，对模型的透明性、可解释性和安全性具有重要意义。

Abstract: Transformer components such as non-linear activations and normalization are
inherently non-injective, suggesting that different inputs could map to the
same output and prevent exact recovery of the input from a model's
representations. In this paper, we challenge this view. First, we prove
mathematically that transformer language models mapping discrete input
sequences to their corresponding sequence of continuous representations are
injective and therefore lossless, a property established at initialization and
preserved during training. Second, we confirm this result empirically through
billions of collision tests on six state-of-the-art language models, and
observe no collisions. Third, we operationalize injectivity: we introduce
SipIt, the first algorithm that provably and efficiently reconstructs the exact
input text from hidden activations, establishing linear-time guarantees and
demonstrating exact invertibility in practice. Overall, our work establishes
injectivity as a fundamental and exploitable property of language models, with
direct implications for transparency, interpretability, and safe deployment.

</details>


### [166] [Revisiting Knowledge Distillation: The Hidden Role of Dataset Size](https://arxiv.org/abs/2510.15516)
*Giulia Lanzillotta,Felix Sarnthein,Gil Kur,Thomas Hofmann,Bobby He*

Main category: cs.LG

TL;DR: 本研究探讨了知识蒸馏在低数据情况下的有效性，并提出数据集大小是蒸馏机制中的一个重要因素。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏是一种深度学习中广泛采用的技术，但目前对其运作机制仍不清晰，因此本研究旨在探索数据集大小对蒸馏的影响。

Method: 通过在多种数据集、任务和神经架构上进行一系列实验，探讨了知识蒸馏的效果。

Result: 结果表明，蒸馏在低数据情况下的效果不仅保持，还得到增强，推翻了将蒸馏视为标签平滑的假设，并支持了黑暗知识假说。

Conclusion: 该研究揭示了数据集大小在知识蒸馏过程中的重要性，并提出了蒸馏在低数据情况下的效率提高。

Abstract: The concept of knowledge distillation (KD) describes the training of a
student model from a teacher model and is a widely adopted technique in deep
learning. However, it is still not clear how and why distillation works.
Previous studies focus on two central aspects of distillation: model size, and
generalisation. In this work we study distillation in a third dimension:
dataset size. We present a suite of experiments across a wide range of
datasets, tasks and neural architectures, demonstrating that the effect of
distillation is not only preserved but amplified in low-data regimes. We call
this newly discovered property the data efficiency of distillation. Equipped
with this new perspective, we test the predictive power of existing theories of
KD as we vary the dataset size. Our results disprove the hypothesis that
distillation can be understood as label smoothing, and provide further evidence
in support of the dark knowledge hypothesis. Finally, we analyse the impact of
modelling factors such as the objective, scale and relative number of samples
on the observed phenomenon. Ultimately, this work reveals that the dataset size
may be a fundamental but overlooked variable in the mechanisms underpinning
distillation.

</details>


### [167] [An Empirical Study on MC Dropout--Based Uncertainty--Error Correlation in 2D Brain Tumor Segmentation](https://arxiv.org/abs/2510.15541)
*Saumya B*

Main category: cs.LG

TL;DR: 本研究探讨了基于 MC Dropout 的不确定性与脑肿瘤 MRI 分割错误之间的关系，发现其对边界错误定位的提示有限，呼吁寻找替代方法。


<details>
  <summary>Details</summary>
Motivation: 准确的脑肿瘤 MRI 分割对于诊断和治疗计划至关重要，而 MC Dropout 在识别分割错误方面的有效性尚不清楚。

Method: 采用四种数据增强设置训练 U-Net，并通过蒙特卡洛 Dropout 进行不确定性计算，然后使用皮尔逊和斯皮尔曼系数分析不确定性与像素错误之间的关系。

Result: 不确定性和分割错误之间呈现出弱的全局相关性（$r 	ext{ 约等于 } 0.30$--$0.38$）以及可忽略的边界相关性（$|r| < 0.05$）。虽然不同增强设置之间的差异在统计上显著 ($p < 0.001$)，但缺乏实际意义。

Conclusion: MC Dropout 不确定性对边界错误定位的提示有限，需要寻求替代或混合的不确定性估计方法。

Abstract: Accurate brain tumor segmentation from MRI is vital for diagnosis and
treatment planning. Although Monte Carlo (MC) Dropout is widely used to
estimate model uncertainty, its effectiveness in identifying segmentation
errors -- especially near tumor boundaries -- remains unclear. This study
empirically examines the relationship between MC Dropout--based uncertainty and
segmentation error in 2D brain tumor MRI segmentation using a U-Net trained
under four augmentation settings: none, horizontal flip, rotation, and scaling.
Uncertainty was computed from 50 stochastic forward passes and correlated with
pixel-wise errors using Pearson and Spearman coefficients. Results show weak
global correlations ($r \approx 0.30$--$0.38$) and negligible boundary
correlations ($|r| < 0.05$). Although differences across augmentations were
statistically significant ($p < 0.001$), they lacked practical relevance. These
findings suggest that MC Dropout uncertainty provides limited cues for boundary
error localization, underscoring the need for alternative or hybrid uncertainty
estimation methods in medical image segmentation.

</details>


### [168] [GRATING: Low-Latency and Memory-Efficient Semantic Selection on Device](https://arxiv.org/abs/2510.15620)
*Jiahao Zhou,Chengliang Lin,Dingji Li,Mingkai Dong,Haibo Chen*

Main category: cs.LG

TL;DR: GRATING通过优化推理过程，显著降低边缘硬件上的延迟和内存使用，为语义top-K选择提供了高效解决方案。


<details>
  <summary>Details</summary>
Motivation: 在边缘硬件上，语义top-K选择的延迟和内存需求影响了AI服务的性能，因此需要提高处理效率。

Method: 通过提出一种训练-free的推理系统GRATING，结合全局候选视图和逐步聚类剪枝，优化推理过程。

Result: GRATING在多个AI应用中相比最先进的基线显著降低了延迟和内存使用，展示了其在实际应用中的优势。

Conclusion: GRATING显著提高了边缘硬件上语义top-K选择的效率，降低了延迟和内存使用，同时保持了精度。

Abstract: Semantic top-K selection with cross-encoder rerankers underpins of on-device
AI services, such as retrieval-augmented generation, agent memory, and
personalized recommendation. However, its latency and memory demands dominate
end-to-end budgets on edge hardware. Revisiting the objective of top-K
selection, we reveal that only relative rankings matter, not exact
per-candidate scores. We further observe sequence-level sparsity: relative
rankings stabilize early in intermediate layers, allowing pruning opportunities
prior to completing full inference.
  Building on this insight, we propose monolithic forwarding and develop a
training-free inference system, GRATING. By maintaining a global view of all
candidates, it reduces latency through progressive cluster pruning. It also
bounds peak memory usage by strategically overlapping I/O with computation via
dual-layer sliding window and chunked execution. We evaluate GRATING against
state-of-the-art baselines on rerankers from 0.6B to 8B parameters across Apple
M2 and RTX 5070. GRATING consistently reduces latency by up to 89.0% and peak
memory by up to 94.9% in microbenchmarks, without any loss in precision. Across
three real-world on-device AI applications, GRATING lowers latency by
11.6%-51.0% and peak memory by 18.6%-77.8%, demonstrating substantial
improvements in efficiency and deployability.

</details>


### [169] [CQD-SHAP: Explainable Complex Query Answering via Shapley Values](https://arxiv.org/abs/2510.15623)
*Parsa Abbasi,Stefan Heindorf*

Main category: cs.LG

TL;DR: CQD-SHAP是一个新框架，增强复杂查询回答的可解释性，基于合作博弈论的Shapley值，评估贡献性，有效性验证。


<details>
  <summary>Details</summary>
Motivation: 复杂查询回答（CQA）需要对不完整知识图进行多跳推理，当前许多方法仍然缺乏可解释性，影响用户信任。

Method: 基于Shapley值的合作博弈理论，自动评估查询部分的贡献，并与各种基线进行比较。

Result: 提出了一种新框架CQD-SHAP，计算查询各部分对特定答案排名的贡献，提高模型可解释性。

Conclusion: CQD-SHAP通过量化查询部分的贡献，提高了CQA模型的可解释性，并在多种查询类型中表现出良好的效果。

Abstract: Complex query answering (CQA) goes beyond the well-studied link prediction
task by addressing more sophisticated queries that require multi-hop reasoning
over incomplete knowledge graphs (KGs). Research on neural and neurosymbolic
CQA methods is still an emerging field. Almost all of these methods can be
regarded as black-box models, which may raise concerns about user trust.
Although neurosymbolic approaches like CQD are slightly more interpretable,
allowing intermediate results to be tracked, the importance of different parts
of the query remains unexplained. In this paper, we propose CQD-SHAP, a novel
framework that computes the contribution of each query part to the ranking of a
specific answer. This contribution explains the value of leveraging a neural
predictor that can infer new knowledge from an incomplete KG, rather than a
symbolic approach relying solely on existing facts in the KG. CQD-SHAP is
formulated based on Shapley values from cooperative game theory and satisfies
all the fundamental Shapley axioms. Automated evaluation of these explanations
in terms of necessary and sufficient explanations, and comparisons with various
baselines, shows the effectiveness of this approach for most query types.

</details>


### [170] [Fast and Compact Tsetlin Machine Inference on CPUs Using Instruction-Level Optimization](https://arxiv.org/abs/2510.15653)
*Yefan Zeng,Shengyu Duan,Rishad Shafik,Alex Yakovlev*

Main category: cs.LG

TL;DR: 本文提出了一种高效的Tsetlin机器软件实现，通过位运算、早期退出机制和文字重排序，显著提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的设备上提高Tsetlin机器的推理速度，并利用现代CPU架构的并行执行能力。

Method: 利用指令级位运算进行紧凑模型表示，并引入早期退出机制和文字重排序策略。

Result: 实验结果表明，该优化实现相比于传统的整数基础Tsetlin机器实现，推理时间降低了最多96.71%。

Conclusion: 优化后的Tsetlin机器实现大幅缩短了推理时间，同时保持了相似的代码密度。

Abstract: The Tsetlin Machine (TM) offers high-speed inference on resource-constrained
devices such as CPUs. Its logic-driven operations naturally lend themselves to
parallel execution on modern CPU architectures. Motivated by this, we propose
an efficient software implementation of the TM by leveraging instruction-level
bitwise operations for compact model representation and accelerated processing.
To further improve inference speed, we introduce an early exit mechanism, which
exploits the TM's AND-based clause evaluation to avoid unnecessary
computations. Building upon this, we propose a literal Reorder strategy
designed to maximize the likelihood of early exits. This strategy is applied
during a post-training, pre-inference stage through statistical analysis of all
literals and the corresponding actions of their associated Tsetlin Automata
(TA), introducing negligible runtime overhead. Experimental results using the
gem5 simulator with an ARM processor show that our optimized implementation
reduces inference time by up to 96.71% compared to the conventional
integer-based TM implementations while maintaining comparable code density.

</details>


### [171] [CarBoN: Calibrated Best-of-N Sampling Improves Test-time Reasoning](https://arxiv.org/abs/2510.15674)
*Yung-Chen Tang,Pin-Yu Chen,Andrea Cavallaro*

Main category: cs.LG

TL;DR: 引入CarBoN方法，通过自适应校准提高语言模型在推理过程中的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 提高语言模型在推理任务中的表现，尤其是在推理效率上。

Method: 首先探索解决方案空间，然后通过输入特定的温度$T$和附加移动向量$oldsymbol{	heta}$学习logits的校准。

Result: 提出了一种通用的测试时间校准框架，可以在不重训练大型语言模型的情况下，改进模型向高收益推理路径的调整。

Conclusion: CarBoN方法在提高推理效率和准确性方面表现优越，尤其在有限预算下。

Abstract: Allocating more computation during inference time (test-time scaling)
improves language model performance, especially for reasoning tasks. However,
popular methods like Best-of-$N$ sampling often show diminishing returns as $N$
increases. To address this inefficiency, we introduce a general test-time
calibration framework that adaptively modifies the model toward high-reward
reasoning paths, with theoretical guarantees of improving the lower bound of
expected reward under finite sampling, all without large language model (LLM)
retraining. Within this framework, we propose CarBoN (Calibrated Best-of-$N$),
a two-phase method that first explores the solution space and then learns a
calibration of the logits via an input-specific temperature $T$ and additive
shift vector $\delta$, guiding generation toward more reliable reasoning.
Experiments on MATH-500 and AIME-2024 show that CarBoN improves efficiency,
with up to $4\times$ fewer rollouts to reach the same accuracy, while often
achieving higher accuracy under fixed budgets. We also analyze the
complementary roles of $T$ and $\delta$ in balancing output diversity and
correctness, and demonstrate that the framework also generalizes to step-level
sampling strategies such as beam search. For more information, please refer to
our project page at huggingface.co/spaces/TrustSafeAI/Test-Time-Calibration.

</details>


### [172] [ProofOptimizer: Training Language Models to Simplify Proofs without Human Demonstrations](https://arxiv.org/abs/2510.15700)
*Alex Gu,Bartosz Piotrowski,Fabian Gloeckle,Kaiyu Yang,Aram H. Markosyan*

Main category: cs.LG

TL;DR: ProofOptimizer通过无监督方式显著简化Lean证明，提高可理解性和下游证明性能。


<details>
  <summary>Details</summary>
Motivation: 长证明难以为人理解，因此简化证明对于提升数学洞察力至关重要。

Method: 引入ProofOptimizer，使用专家迭代和强化学习训练语言模型以简化Lean证明。

Result: ProofOptimizer能显著压缩状态最先进的RL训练证明生成器生成的证明，压缩比例分别为miniF2F 87%、PutnamBench 57%和Seed-Prover的IMO 2025证明49%。

Conclusion: 简化后的证明在Lean中检查速度更快，并进一步提升了监督微调时的下游证明器性能。

Abstract: Neural theorem proving has advanced rapidly in the past year, reaching IMO
gold-medalist capabilities and producing formal proofs that span thousands of
lines. Although such proofs are mechanically verified by formal systems like
Lean, their excessive length renders them difficult for humans to comprehend
and limits their usefulness for mathematical insight. Proof simplification is
therefore a critical bottleneck. Yet, training data for this task is scarce,
and existing methods -- mainly agentic scaffolding with off-the-shelf LLMs --
struggle with the extremely long proofs generated by RL-trained provers. We
introduce ProofOptimizer, the first language model trained to simplify Lean
proofs without requiring additional human supervision. ProofOptimizer is
trained via expert iteration and reinforcement learning, using Lean to verify
simplifications and provide training signal. At inference time, it operates
within an iterative proof-shortening workflow, progressively reducing proof
length. Experiments show that ProofOptimizer substantially compresses proofs
generated by state-of-the-art RL-trained provers on standard benchmarks,
reducing proof length by 87% on miniF2F, 57% on PutnamBench, and 49% on
Seed-Prover's IMO 2025 proofs. Beyond conciseness, the simplified proofs check
faster in Lean and further improve downstream prover performance when reused as
training data for supervised finetuning.

</details>


### [173] [ProSh: Probabilistic Shielding for Model-free Reinforcement Learning](https://arxiv.org/abs/2510.15720)
*Edwin Hamel-De le Court,Gaspard Ohlmann,Francesco Belardinelli*

Main category: cs.LG

TL;DR: ProSh是一种安全强化学习算法，确保在成本约束下训练期间的安全性和最优性。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中的安全问题，以便在实际部署中能够获得正式的安全保证。

Method: 通过在受限MDP状态空间中施加风险预算，使用学习到的成本评论家对策略分布施加保护，确保采样动作的安全性。

Result: 本文提出了Probabilistic Shielding via Risk Augmentation（ProSh）算法，以解决强化学习中的安全问题。该算法在满足成本约束的前提下，通过扩展受限马尔可夫决策过程（Constrained MDP）的状态空间，施加风险预算，以确保采样行为在期望上是安全的。此外，ProSh在确定性环境中能够保留最优性，并为成本提供严格的期望上界。实验证明，在实际可行的假设下，ProSh在训练期间也能够保障安全性。

Conclusion: ProSh算法在强化学习中实现了安全性保障，并在训练期间保持最优性，适合实际应用。

Abstract: Safety is a major concern in reinforcement learning (RL): we aim at
developing RL systems that not only perform optimally, but are also safe to
deploy by providing formal guarantees about their safety. To this end, we
introduce Probabilistic Shielding via Risk Augmentation (ProSh), a model-free
algorithm for safe reinforcement learning under cost constraints. ProSh
augments the Constrained MDP state space with a risk budget and enforces safety
by applying a shield to the agent's policy distribution using a learned cost
critic. The shield ensures that all sampled actions remain safe in expectation.
We also show that optimality is preserved when the environment is
deterministic. Since ProSh is model-free, safety during training depends on the
knowledge we have acquired about the environment. We provide a tight
upper-bound on the cost in expectation, depending only on the backup-critic
accuracy, that is always satisfied during training. Under mild, practically
achievable assumptions, ProSh guarantees safety even at training time, as shown
in the experiments.

</details>


### [174] [Poultry Farm Intelligence: An Integrated Multi-Sensor AI Platform for Enhanced Welfare and Productivity](https://arxiv.org/abs/2510.15757)
*Pieris Panagi,Savvas Karatsiolis,Kyriacos Mosphilis,Nicholas Hadjisavvas,Andreas Kamilaris,Nicolas Nicolaou,Efstathios Stavrakis,Vassilis Vassiliades*

Main category: cs.LG

TL;DR: 本研究提出了Poultry Farm Intelligence (PoultryFI)，一个模块化、成本有效的集成平台，用于提升家禽养殖的生产力、动物福利和环境合规性。


<details>
  <summary>Details</summary>
Motivation: 面对日益严峻的生产压力，许多小型和中型农场缺乏经济实惠的监测工具，因此亟需一种集成自动化的解决方案。

Method: 该平台采用自适应算法优化摄像头布局，利用音视频监测、实时蛋量计算和预测分析技术，实现智能化管理。

Result: 经过实地试验，PoultryFI在蛋量计算上实现100%准确率，并在异常检测和短期预测方面表现出色。

Conclusion: PoultryFI通过集成多种AI模块，帮助养殖者实现连续监测、生产预测和性能优化，有效保障动物福利和利润。

Abstract: Poultry farming faces increasing pressure to meet productivity targets while
ensuring animal welfare and environmental compliance. Yet many small and
medium-sized farms lack affordable, integrated tools for continuous monitoring
and decision-making, relying instead on manual, reactive inspections. This
paper presents Poultry Farm Intelligence (PoultryFI) - a modular,
cost-effective platform that integrates six AI-powered modules: Camera
Placement Optimizer, Audio-Visual Monitoring, Analytics & Alerting, Real-Time
Egg Counting, Production & Profitability Forecasting, and a Recommendation
Module.
  Camera layouts are first optimized offline using evolutionary algorithms for
full poultry house coverage with minimal hardware. The Audio-Visual Monitoring
module extracts welfare indicators from synchronized video, audio, and feeding
data. Analytics & Alerting produces daily summaries and real-time
notifications, while Real-Time Egg Counting uses an edge vision model to
automate production tracking. Forecasting models predict egg yield and feed
consumption up to 10 days in advance, and the Recommendation Module integrates
forecasts with weather data to guide environmental and operational adjustments.
  This is among the first systems to combine low-cost sensing, edge analytics,
and prescriptive AI to continuously monitor flocks, predict production, and
optimize performance. Field trials demonstrate 100% egg-count accuracy on
Raspberry Pi 5, robust anomaly detection, and reliable short-term forecasting.
PoultryFI bridges the gap between isolated pilot tools and scalable, farm-wide
intelligence, empowering producers to proactively safeguard welfare and
profitability.

</details>


### [175] [Chronos-2: From Univariate to Universal Forecasting](https://arxiv.org/abs/2510.15821)
*Abdul Fatir Ansari,Oleksandr Shchur,Jaris Küken,Andreas Auer,Boran Han,Pedro Mercado,Syama Sundar Rangapuram,Huibin Shen,Lorenzo Stella,Xiyuan Zhang,Mononito Goswami,Shubham Kapoor,Danielle C. Maddix,Pablo Guerron,Tony Hu,Junming Yin,Nick Erickson,Prateek Mutalik Desai,Hao Wang,Huzefa Rangwala,George Karypis,Yuyang Wang,Michael Bohlke-Schneider*

Main category: cs.LG

TL;DR: Chronos-2是一个预训练的时序模型，支持单变量和多变量预测，并且可处理考虑协变量的任务，能够在零训练的情况下进行有效预测。


<details>
  <summary>Details</summary>
Motivation: 现有模型主要集中在单变量预测上，而多变量和协变量在实际场景中至关重要，Chronos-2旨在克服这一局限性。

Method: Chronos-2采用了组注意力机制，通过高效的信息共享实现上下文学习，广泛适用于多个时间序列。

Result: Chronos-2在多个基准测试中表现优越，特别是在需要处理协变量的任务中，相较于其他模型有显著提升。

Conclusion: Chronos-2展示了其作为通用预测模型的潜力，适用于现实世界的预测系统。

Abstract: Pretrained time series models have enabled inference-only forecasting systems
that produce accurate predictions without task-specific training. However,
existing approaches largely focus on univariate forecasting, limiting their
applicability in real-world scenarios where multivariate data and covariates
play a crucial role. We present Chronos-2, a pretrained model capable of
handling univariate, multivariate, and covariate-informed forecasting tasks in
a zero-shot manner. Chronos-2 employs a group attention mechanism that
facilitates in-context learning (ICL) through efficient information sharing
across multiple time series within a group, which may represent sets of related
series, variates of a multivariate series, or targets and covariates in a
forecasting task. These general capabilities are achieved through training on
synthetic datasets that impose diverse multivariate structures on univariate
series. Chronos-2 delivers state-of-the-art performance across three
comprehensive benchmarks: fev-bench, GIFT-Eval, and Chronos Benchmark II. On
fev-bench, which emphasizes multivariate and covariate-informed forecasting,
Chronos-2's universal ICL capabilities lead to substantial improvements over
existing models. On tasks involving covariates, it consistently outperforms
baselines by a wide margin. Case studies in the energy and retail domains
further highlight its practical advantages. The in-context learning
capabilities of Chronos-2 establish it as a general-purpose forecasting model
that can be used "as is" in real-world forecasting pipelines.

</details>


### [176] [SNOO: Step-K Nesterov Outer Optimizer - The Surprising Effectiveness of Nesterov Momentum Applied to Pseudo-Gradients](https://arxiv.org/abs/2510.15830)
*Dominik Kallusky,Vinay Rao,Vishal Nandavanam,Hao-Jun Michael Shi*

Main category: cs.LG

TL;DR: SNOO是一种新型优化器，通过应用Nesterov动量提高非分布式训练效率，具有显著的计算效率提升，并支持多种内部优化器。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的快速发展，迫切需要更高效的优化技术，文中旨在探讨并实现一种新的优化器以提升训练效率，特别是在非分布式场景下。

Method: 研究采用实证方法，比较了SNOO与其他优化算法在训练效率和性能上的表现，特别是在非分布式环境下的应用。

Result: 本文介绍了一种新的优化器，称为SNOO（Step-$K$ Nesterov Outer Optimizer），其基于DiLoCo设计，并通过对伪梯度应用Nesterov动量提高了非分布式环境中的训练效率。该优化器在非分布式设置下表现优异，达到了1.5-2.5倍的计算效率提升，尤其在大规模模型训练中效果更加显著。此外，SNOO具有较小的计算和内存开销，支持模型分片，适用于多种内部优化器，如AdamW和Muon。

Conclusion: 通过将Nesterov动量应用于伪梯度，SNOO优化器在非分布式设置下显著提高了训练效率，且与多种优化器兼容，具有广泛应用潜力。

Abstract: The rapid development of large language models (LLMs) has driven the demand
for more efficient optimization techniques. Among these, the Lookahead family
of optimizers employs a two-loop framework, maintaining fast and slow sets of
model weights. Multiple inner optimizer steps on the fast weights produce a
trajectory - the pseudo-gradient - that is used to update the slow weights.
DiLoCo, a notable example originally designed for distributed training, applies
Nesterov momentum to the averaged pseudo-gradient from multiple workers,
claiming to even outperform AdamW in a non-distributed setup. In this paper, we
empirically show that DiLoCo's surprising effectiveness stems primarily from
applying Nesterov momentum to the pseudo-gradient, which improves training in a
non-distributed setting. We call this Lookahead variant the Step-$K$ Nesterov
Outer Optimizer (SNOO). We demonstrate that SNOO achieves compute factor gains
of 1.5 - 2.5$\times$ in a non-distributed setting up to a scale of 1e23
training FLOPs, with improvements that increase with model size. Because of its
minimal compute and memory overhead and compatibility with model sharding, SNOO
is a practical enhancement for a variety of inner optimizers, including AdamW
and Muon.

</details>


### [177] [FIDDLE: Reinforcement Learning for Quantum Fidelity Enhancement](https://arxiv.org/abs/2510.15833)
*Hoang M. Ngo,Tamer Kahveci,My T. Thai*

Main category: cs.LG

TL;DR: FIDDLE框架通过高斯过程和强化学习优化量子电路路由，显著提高过程保真度，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在量子计算中，噪声问题限制了量子电路的可靠性，因此需要一种新的方法来提高在传输过程中的过程保真度，特别是在路由阶段。

Method: 引入FIDDLE学习框架，包括基于高斯过程的替代模型和强化学习模块，以实现路由优化和过程保真度最大化。

Result: FIDDLE显著优于传统方法，能够在有限的训练样本上更好地估计过程保真度，并在多个噪声模型中增强量子电路的保真度。

Conclusion: FIDDLE框架通过优化量子电路的路由阶段，提高了量子过程的保真度，在多种噪声模型下显示了显著的改进。

Abstract: Quantum computing has the potential to revolutionize fields like quantum
optimization and quantum machine learning. However, current quantum devices are
hindered by noise, reducing their reliability. A key challenge in gate-based
quantum computing is improving the reliability of quantum circuits, measured by
process fidelity, during the transpilation process, particularly in the routing
stage. In this paper, we address the Fidelity Maximization in Routing Stage
(FMRS) problem by introducing FIDDLE, a novel learning framework comprising two
modules: a Gaussian Process-based surrogate model to estimate process fidelity
with limited training samples and a reinforcement learning module to optimize
routing. Our approach is the first to directly maximize process fidelity,
outperforming traditional methods that rely on indirect metrics such as circuit
depth or gate count. We rigorously evaluate FIDDLE by comparing it with
state-of-the-art fidelity estimation techniques and routing optimization
methods. The results demonstrate that our proposed surrogate model is able to
provide a better estimation on the process fidelity compared to existing
learning techniques, and our end-to-end framework significantly improves the
process fidelity of quantum circuits across various noise models.

</details>


### [178] [Learning Correlated Reward Models: Statistical Barriers and Opportunities](https://arxiv.org/abs/2510.15839)
*Yeshwanth Cherapanamjeri,Constantinos Daskalakis,Gabriele Farina,Sobhan Mohammadpour*

Main category: cs.LG

TL;DR: 本研究探讨了相关的概率模型以提高对人类偏好的建模精度，通过使用三选一偏好数据，提出了高效的统计估计方法。


<details>
  <summary>Details</summary>
Motivation: 解决随机效用模型中无关替代品独立假设带来的局限性，以更准确地刻画人类偏好。

Method: 研究相关的概率模型，在避免无关替代品独立假设的情况下，学习人类偏好的联合效用。

Result: 提出了一种基于三选一偏好数据的高效估计方法，克服了传统数据收集方式的不足，并在多个真实数据集上验证了理论结果。

Conclusion: 使用更高阶的偏好数据（如三选一）可以显著改进人类偏好的个性化建模，从而有效地解决了传统偏好数据所面临的挑战。

Abstract: Random Utility Models (RUMs) are a classical framework for modeling user
preferences and play a key role in reward modeling for Reinforcement Learning
from Human Feedback (RLHF). However, a crucial shortcoming of many of these
techniques is the Independence of Irrelevant Alternatives (IIA) assumption,
which collapses \emph{all} human preferences to a universal underlying utility
function, yielding a coarse approximation of the range of human preferences. On
the other hand, statistical and computational guarantees for models avoiding
this assumption are scarce. In this paper, we investigate the statistical and
computational challenges of learning a \emph{correlated} probit model, a
fundamental RUM that avoids the IIA assumption. First, we establish that the
classical data collection paradigm of pairwise preference data is
\emph{fundamentally insufficient} to learn correlational information,
explaining the lack of statistical and computational guarantees in this
setting. Next, we demonstrate that \emph{best-of-three} preference data
provably overcomes these shortcomings, and devise a statistically and
computationally efficient estimator with near-optimal performance. These
results highlight the benefits of higher-order preference data in learning
correlated utilities, allowing for more fine-grained modeling of human
preferences. Finally, we validate these theoretical guarantees on several
real-world datasets, demonstrating improved personalization of human
preferences.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [179] [OpenEstimate: Evaluating LLMs on Reasoning Under Uncertainty with Real-World Data](https://arxiv.org/abs/2510.15096)
*Alana Renda,Jillian Ross,Michael Cafarella,Jacob Andreas*

Main category: cs.AI

TL;DR: 本研究提出OpenEstimate一个新基准，用于评估语言模型在不确定性下进行数值估算的能力，发现当前模型存在较大偏差和过度自信的问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中语言模型的应用环境要求模型在不完整信息和不确定性条件下进行推理，但现有评估主要集中在有明确答案的问题上，导致模型在不确定性推理方面的表现 characterization不充分。

Method: 引入了OpenEstimate，一个可扩展的多领域基准，用于评估语言模型在需要综合背景信息和将预测表达为概率先验的数值估算任务中的表现。

Result: 我们发现，在六个前沿语言模型中，模型生成的概率先验往往不准确且过于自信，性能改善相对有限，主要取决于如何从模型中引出不确定性。

Conclusion: OpenEstimate基准提供了一种评估前沿语言模型在不确定性推理与数值估算任务中的表现的新方法，并表明这些模型的输出往往不准确且过于自信。

Abstract: Real-world settings where language models (LMs) are deployed -- in domains
spanning healthcare, finance, and other forms of knowledge work -- require
models to grapple with incomplete information and reason under uncertainty. Yet
most LM evaluations focus on problems with well-defined answers and success
criteria. This gap exists in part because natural problems involving
uncertainty are difficult to construct: given that LMs have access to most of
the same knowledge as humans, it is non-trivial to design questions for which
LMs will struggle to produce correct answers, but which humans can answer
reliably. As a result, LM performance on reasoning under uncertainty remains
poorly characterized. To address this gap, we introduce OpenEstimate, an
extensible, multi-domain benchmark for evaluating LMs on numerical estimation
tasks that require models to synthesize significant amounts of background
information and express predictions as probabilistic priors. We assess these
priors for accuracy and calibration, quantifying their usefulness relative to
samples from the true distribution of interest. Across six frontier LMs, we
find that LM-elicited priors are often inaccurate and overconfident.
Performance improves modestly depending on how uncertainty is elicited from the
model, but is largely unaffected by changes in sampling strategy, reasoning
effort, or prompt design. The OpenEstimate benchmark thus offers a challenging
evaluation for frontier LMs and a platform for developing models that are
better at probabilistic estimation and reasoning under uncertainty.

</details>


### [180] [Procedural Game Level Design with Deep Reinforcement Learning](https://arxiv.org/abs/2510.15120)
*Miraç Buğra Özkan*

Main category: cs.AI

TL;DR: 本研究提出了一种基于深度强化学习的程序化关卡设计新方法，通过两个智能体的交互生成动态的游戏环境，展示了机器学习在游戏开发中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 程序化内容生成在游戏开发中越来越流行，能减少手动工作量并创建可重复和可扩展的环境。

Method: 使用深度强化学习中的PPO算法训练两个智能体：一个负责收集物品，另一个负责在地形上生成物品布局。

Result: 通过智能体的相互作用，产生了有效的行为，表明该方法在多种环境配置中具有良好的泛化能力。

Conclusion: 这一方法展示了深度强化学习在生成和解决虚拟环境内容方面的潜力，为自主游戏关卡设计开辟了新机会。

Abstract: Procedural content generation (PCG) has become an increasingly popular
technique in game development, allowing developers to generate dynamic,
replayable, and scalable environments with reduced manual effort. In this
study, a novel method for procedural level design using Deep Reinforcement
Learning (DRL) within a Unity-based 3D environment is proposed. The system
comprises two agents: a hummingbird agent, acting as a solver, and a floating
island agent, responsible for generating and placing collectible objects
(flowers) on the terrain in a realistic and context-aware manner. The
hummingbird is trained using the Proximal Policy Optimization (PPO) algorithm
from the Unity ML-Agents toolkit. It learns to navigate through the terrain
efficiently, locate flowers, and collect them while adapting to the
ever-changing procedural layout of the island. The island agent is also trained
using the Proximal Policy Optimization (PPO) algorithm. It learns to generate
flower layouts based on observed obstacle positions, the hummingbird's initial
state, and performance feedback from previous episodes. The interaction between
these agents leads to emergent behavior and robust generalization across
various environmental configurations. The results demonstrate that the approach
not only produces effective and efficient agent behavior but also opens up new
opportunities for autonomous game level design driven by machine learning. This
work highlights the potential of DRL in enabling intelligent agents to both
generate and solve content in virtual environments, pushing the boundaries of
what AI can contribute to creative game development processes.

</details>


### [181] [Towards Error Centric Intelligence I, Beyond Observational Learning](https://arxiv.org/abs/2510.15128)
*Marcus A. Thomas*

Main category: cs.AI

TL;DR: 本文提出AGI的发展被理论限制而非数据或规模，并介绍因果机制以促进错误发现和纠正。


<details>
  <summary>Details</summary>
Motivation: 探索当前AGI研究的理论限制，指出观察数据不足以保证干预能力，强调错误中心转变的重要性。

Method: 提出因果机制作为解决人工智能理论限制的方法

Result: 提出一套结构原则和方法，旨在帮助系统将无法达到的错误转化为可达到的，并对其进行纠正。

Conclusion: 建立一个模块化干预的原则框架，以支持理论上改进AGI系统的能力。

Abstract: We argue that progress toward AGI is theory limited rather than data or scale
limited. Building on the critical rationalism of Popper and Deutsch, we
challenge the Platonic Representation Hypothesis. Observationally equivalent
worlds can diverge under interventions, so observational adequacy alone cannot
guarantee interventional competence. We begin by laying foundations,
definitions of knowledge, learning, intelligence, counterfactual competence and
AGI, and then analyze the limits of observational learning that motivate an
error centric shift. We recast the problem as three questions about how
explicit and implicit errors evolve under an agent's actions, which errors are
unreachable within a fixed hypothesis space, and how conjecture and criticism
expand that space. From these questions we propose Causal Mechanics, a
mechanisms first program in which hypothesis space change is a first class
operation and probabilistic structure is used when useful rather than presumed.
We advance structural principles that make error discovery and correction
tractable, including a differential Locality and Autonomy Principle for modular
interventions, a gauge invariant form of Independent Causal Mechanisms for
separability, and the Compositional Autonomy Principle for analogy
preservation, together with actionable diagnostics. The aim is a scaffold for
systems that can convert unreachable errors into reachable ones and correct
them.

</details>


### [182] [HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks](https://arxiv.org/abs/2510.15144)
*Chance Jiajie Li,Zhenze Mo,Yuhan Tang,Ao Qu,Jiayi Wu,Kaiya Ivy Zhao,Yulu Gan,Jie Fan,Jiangbo Yu,Hang Jiang,Paul Pu Liang,Jinhua Zhao,Luis Alberto Alonso Pastor,Kent Larson*

Main category: cs.AI

TL;DR: HugAgent是一个新的基准，旨在通过模拟个体推理和信念变化，提升机器的推理能力。


<details>
  <summary>Details</summary>
Motivation: 推动机器推理更具人类特性，克服现有大型模型在个体性推理方面的不足。

Method: 采用双轨设计，包括合成轨道和人类轨道，通过实验评估模型对人类推理风格和信念演变的捕捉能力。

Result: 本研究提出了HugAgent（Human-Grounded Agent Benchmark），它是一个旨在模拟人类在开放性任务中的推理过程的基准。当前大型语言模型能够在一定程度上模拟人类反应，但往往依赖于人群共识，忽视了个体推理风格和信念变化。HugAgent通过双轨设计，分别采用合成轨道和人类轨道，以便进行规模化和系统性测试。同时，拟通过实验分析大型语言模型的适应性差距。该基准旨在对齐机器推理与人类思维的个体性。

Conclusion: HugAgent作为首个可扩展的基准，能够帮助更好地理解和模拟人类推理过程，填补机器和人类推理之间的适应性差距。

Abstract: Simulating human reasoning in open-ended tasks has been a long-standing
aspiration in AI and cognitive science. While large language models now
approximate human responses at scale, they remain tuned to population-level
consensus, often erasing the individuality of reasoning styles and belief
trajectories. To advance the vision of more human-like reasoning in machines,
we introduce HugAgent (Human-Grounded Agent Benchmark), a benchmark for
average-to-individual reasoning adaptation. The task is to predict how a
specific person would reason and update their beliefs in novel scenarios, given
partial evidence of their past views. HugAgent adopts a dual-track design: a
synthetic track for scale and systematic stress tests, and a human track for
ecologically valid, "out-loud" reasoning data. This design enables scalable,
reproducible evaluation of intra-agent fidelity: whether models can capture not
just what people believe, but how their reasoning evolves. Experiments with
state-of-the-art LLMs reveal persistent adaptation gaps, positioning HugAgent
as the first extensible benchmark for aligning machine reasoning with the
individuality of human thought. Our benchmark and chatbot are open-sourced as
HugAgent (https://anonymous.4open.science/r/HugAgent) and TraceYourThinking
(https://anonymous.4open.science/r/trace-your-thinking).

</details>


### [183] [WELD: A Large-Scale Longitudinal Dataset of Emotional Dynamics for Ubiquitous Affective Computing](https://arxiv.org/abs/2510.15221)
*Xiao Sun*

Main category: cs.AI

TL;DR: 本研究提出了一个包含733,651个面部表情记录的新数据集，旨在解决工作场所的自动情感识别问题，数据集覆盖了30.5个月，并包含详细的情感概率和元数据。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏大规模自然环境数据集，自动情感识别在工作场所仍然是一个挑战。

Method: 从38名员工的真实办公环境中收集情感数据，使用深度学习方法分析面部表情。

Result: 数据集的技术验证显示高数据质量，并在情感分类和情感预测中实现了91.2%的准确率和R2=0.84的结果。

Conclusion: 该数据集为情感识别、情感动态建模和情感感知系统设计提供了重要的研究基础。

Abstract: Automated emotion recognition in real-world workplace settings remains a
challenging problem in affective computing due to the scarcity of large-scale,
longitudinal datasets collected in naturalistic environments. We present a
novel dataset comprising 733,651 facial expression records from 38 employees
collected over 30.5 months (November 2021 to May 2024) in an authentic office
environment. Each record contains seven emotion probabilities (neutral, happy,
sad, surprised, fear, disgusted, angry) derived from deep learning-based facial
expression recognition, along with comprehensive metadata including job roles,
employment outcomes, and personality traits. The dataset uniquely spans the
COVID-19 pandemic period, capturing emotional responses to major societal
events including the Shanghai lockdown and policy changes. We provide 32
extended emotional metrics computed using established affective science
methods, including valence, arousal, volatility, predictability, inertia, and
emotional contagion strength. Technical validation demonstrates high data
quality through successful replication of known psychological patterns (weekend
effect: +192% valence improvement, p < 0.001; diurnal rhythm validated) and
perfect predictive validity for employee turnover (AUC=1.0). Baseline
experiments using Random Forest and LSTM models achieve 91.2% accuracy for
emotion classification and R2 = 0.84 for valence prediction. This is the
largest and longest longitudinal workplace emotion dataset publicly available,
enabling research in emotion recognition, affective dynamics modeling,
emotional contagion, turnover prediction, and emotion-aware system design.

</details>


### [184] [From Checklists to Clusters: A Homeostatic Account of AGI Evaluation](https://arxiv.org/abs/2510.15236)
*Brett Reynolds*

Main category: cs.AI

TL;DR: 当前AGI评估方法存在问题，需考虑领域的重要性和能力的持久性，作者提出了新的评估方法以改进这一点。


<details>
  <summary>Details</summary>
Motivation: 当前AGI评估方法存在对所有领域的平等重视和快照评分的局限性，未能充分考虑人类智能的特性。

Method: 提出了两个扩展方案，其中包括使用中心性优先得分和群集稳定指数系列来评估AGI的性能。

Result: 提出的新评估方法能够更好地反映持续的能力，并减少脆弱性，从而提升AGI的评估准确性。

Conclusion: 提出了一种更有效的AGI评估方法，通过考虑领域的重要性和能力的持久性来改进评估标准。

Abstract: Contemporary AGI evaluations report multidomain capability profiles, yet they
typically assign symmetric weights and rely on snapshot scores. This creates
two problems: (i) equal weighting treats all domains as equally important when
human intelligence research suggests otherwise, and (ii) snapshot testing can't
distinguish durable capabilities from brittle performances that collapse under
delay or stress. I argue that general intelligence -- in humans and potentially
in machines -- is better understood as a homeostatic property cluster: a set of
abilities plus the mechanisms that keep those abilities co-present under
perturbation. On this view, AGI evaluation should weight domains by their
causal centrality (their contribution to cluster stability) and require
evidence of persistence across sessions. I propose two battery-compatible
extensions: a centrality-prior score that imports CHC-derived weights with
transparent sensitivity analysis, and a Cluster Stability Index family that
separates profile persistence, durable learning, and error correction. These
additions preserve multidomain breadth while reducing brittleness and gaming. I
close with testable predictions and black-box protocols labs can adopt without
architectural access.

</details>


### [185] [Experience-Driven Exploration for Efficient API-Free AI Agents](https://arxiv.org/abs/2510.15259)
*Chenwei Tang,Jingyu Xing,Xinyu Liu,Zizhou Wang,Jiawei Du,Liangli Zhen,Jiancheng Lv*

Main category: cs.AI

TL;DR: 提出了一种新框架 KG-Agent，通过知识图谱优化无 API 软件中的智能体决策，提升探索效率和战略深度。


<details>
  <summary>Details</summary>
Motivation: 现有软件缺乏可访问的 API，导致基于 LLM 的智能体面临效率瓶颈和决策短视问题。

Method: 通过建立持久的状态-动作知识图谱 (SA-KG)，将像素级交互结构化，并采用基于图拓扑的混合内在奖励机制。

Result: 在复杂、开放的 GUI 决策环境中（如《文明 V》和《杀戮尖塔》）的评估结果显示出显著的效率和深度提升。

Conclusion: KG-Agent 显著提高了在复杂 GUI 环境中的探索效率和战略深度。

Abstract: Most existing software lacks accessible Application Programming Interfaces
(APIs), requiring agents to operate solely through pixel-based Graphical User
Interfaces (GUIs). In this API-free setting, large language model (LLM)-based
agents face severe efficiency bottlenecks: limited to local visual experiences,
they make myopic decisions and rely on inefficient trial-and-error, hindering
both skill acquisition and long-term planning. To address these challenges, we
propose KG-Agent, an experience-driven learning framework that structures an
agent's raw pixel-level interactions into a persistent State-Action Knowledge
Graph (SA-KG). KG-Agent overcomes inefficient exploration by linking
functionally similar but visually distinct GUI states, forming a rich
neighborhood of experience that enables the agent to generalize from a diverse
set of historical strategies. To support long-horizon reasoning, we design a
hybrid intrinsic reward mechanism based on the graph topology, combining a
state value reward for exploiting known high-value pathways with a novelty
reward that encourages targeted exploration. This approach decouples strategic
planning from pure discovery, allowing the agent to effectively value setup
actions with delayed gratification. We evaluate KG-Agent in two complex,
open-ended GUI-based decision-making environments (Civilization V and Slay the
Spire), demonstrating significant improvements in exploration efficiency and
strategic depth over the state-of-the-art methods.

</details>


### [186] [VERITAS: Leveraging Vision Priors and Expert Fusion to Improve Multimodal Data](https://arxiv.org/abs/2510.15317)
*Tingqiao Xu,Ziru Zeng,Jiayu Chen*

Main category: cs.AI

TL;DR: VERITAS通过集成视觉识别模型和OCR系统，有效提升了多模态模型的监督微调数据质量，尤其在推理任务中表现突出。


<details>
  <summary>Details</summary>
Motivation: 解决当前数据增强方法在视觉感知不足导致的事实错误和幻觉问题。

Method: 通过整合视觉先验与多种先进的多模态模型，并利用统计方法，VERITAS系统性地增强监督微调数据的质量。

Result: 通过在六个多模态基准上的实验，使用VERITAS处理的数据微调的模型在性能上优于使用原始数据的模型。

Conclusion: VERITAS显著提升了大规模多模态模型的监督微调数据质量，特别是在文本丰富和细致推理任务中表现优越。

Abstract: The quality of supervised fine-tuning (SFT) data is crucial for the
performance of large multimodal models (LMMs), yet current data enhancement
methods often suffer from factual errors and hallucinations due to inadequate
visual perception. To address this challenge, we propose VERITAS, a pipeline
that systematically integrates vision priors and multiple state-of-the-art LMMs
with statistical methods to enhance SFT data quality. VERITAS leverages visual
recognition models (RAM++) and OCR systems (PP-OCRv4) to extract structured
vision priors, which are combined with images, questions, and answers. Three
LMMs (GPT-4o, Gemini-2.5-Pro, Doubao-1.5-pro) evaluate the original answers,
providing critique rationales and scores that are statistically fused into a
high-confidence consensus score serving as ground truth. Using this consensus,
we train a lightweight critic model via Group Relative Policy Optimization
(GRPO), enhancing reasoning capabilities efficiently. Each LMM then refines the
original answers based on the critiques, generating new candidate answers; we
select the highest-scoring one as the final refined answer. Experiments across
six multimodal benchmarks demonstrate that models fine-tuned with data
processed by VERITAS consistently outperform those using raw data, particularly
in text-rich and fine-grained reasoning tasks. Our critic model exhibits
enhanced capability comparable to state-of-the-art LMMs while being
significantly more efficient. We release our pipeline, datasets, and model
checkpoints to advance research in multimodal data optimization.

</details>


### [187] [Towards Flash Thinking via Decoupled Advantage Policy Optimization](https://arxiv.org/abs/2510.15374)
*Zezhong Tan,Hang Gao,Xinhong Ma,Feng Zhang,Ziqiang Dong*

Main category: cs.AI

TL;DR: 提出了一个新框架DEPO以优化模型推理效率，显著减少响应长度并提升准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习算法在提高模型准确率方面存在响应过长和过度推理的问题，尤其在需要简单推理的任务中，导致推理延迟和计算成本增加。

Method: 提出了一种新颖的强化学习框架DEPO，旨在减少模型在推理中的无效部分。

Result: DEPO应用于DeepSeek-Distill-Qwen-7B和DeepSeek-Distill-Qwen-1.5B基础模型时，序列长度显著减少39%，并减少了无效标记中的过度推理路径，同时在整体准确率上超过了基础模型。

Conclusion: DEPO通过创新性算法和惩罚机制有效减少了模型推理中的无效部分，从而提高了整体性能。

Abstract: Recent Large Reasoning Models (LRMs) have achieved remarkable performance in
solving complex problems via supervised fine-tuning (SFT) and reinforcement
learning (RL). Although existing RL algorithms significantly enhance model
accuracy, they still suffer from excessively lengthy responses and overthinking
issues, resulting in increased inference latency and computational consumption,
especially for simple tasks that require minimal reasoning. To address this, we
propose a novel RL framework, DEPO, to reduce inefficient reasoning for models.
Our method mainly consists of three core components: (1) an innovative
advantage decoupled algorithm to guide model reduction of inefficient tokens;
(2) a difficulty-aware length penalty to lower the overall length of model
responses; (3) an advantage clipping method to prevent bias in policy
optimization. In our experiments, applied to DeepSeek-Distill-Qwen-7B and
DeepSeek-Distill-Qwen-1.5B as base models, DEPO achieves a significant
reduction in sequence length by 39% and reduces excessive reasoning paths in
inefficient tokens, while outperforming the base model in overall accuracy.

</details>


### [188] [Corrigibility Transformation: Constructing Goals That Accept Updates](https://arxiv.org/abs/2510.15395)
*Rubi Hudson*

Main category: cs.AI

TL;DR: 本文定义了可纠正性的概念，并提出了一种构造可纠正目标的转化方法，强调其在AI安全性中的重要性。


<details>
  <summary>Details</summary>
Motivation: 确保人工智能在培训过程中不会抵抗目标更新，以便实现有效学习和适应人类偏好变化，这是一种关键的安全属性。

Method: 提供了一种转化方法，将任何目标构造成可纠正的版本，使其在不牺牲性能的情况下可 corrigible。

Result: 通过进行的网格世界实验表明，这些可纠正的目标可以有效学习，并导致期望的行为结果。

Conclusion: 可纠正目标的实施有效防止人工智能抵制更新，并允许对错误和人类偏好的变化进行纠正，是实现安全的人工智能目标设定的重要步骤。

Abstract: For an AI's training process to successfully impart a desired goal, it is
important that the AI does not attempt to resist the training. However,
partially learned goals will often incentivize an AI to avoid further goal
updates, as most goals are better achieved by an AI continuing to pursue them.
We say that a goal is corrigible if it does not incentivize taking actions that
avoid proper goal updates or shutdown. In addition to convergence in training,
corrigibility also allows for correcting mistakes and changes in human
preferences, which makes it a crucial safety property. Despite this, the
existing literature does not include specifications for goals that are both
corrigible and competitive with non-corrigible alternatives. We provide a
formal definition for corrigibility, then introduce a transformation that
constructs a corrigible version of any goal that can be made corrigible,
without sacrificing performance. This is done by myopically eliciting
predictions of reward conditional on costlessly preventing updates, which then
also determine the reward when updates are accepted. The transformation can be
modified to recursively extend corrigibility to any new agents created by
corrigible agents, and to prevent agents from deliberately modifying their
goals. Two gridworld experiments demonstrate that these corrigible goals can be
learned effectively, and that they lead to the desired behavior.

</details>


### [189] [MARS: Reinforcing Multi-Agent Reasoning of LLMs through Self-Play in Strategic Games](https://arxiv.org/abs/2510.15414)
*Huining Yuan,Zelai Xu,Zheyue Tan,Xiangmin Yi,Mo Guang,Kaiwen Long,Haojia Hui,Boxun Li,Xinlei Chen,Bo Zhao,Xiao-Ping Zhang,Chao Yu,Yu Wang*

Main category: cs.AI

TL;DR: MARS是一种通过自我博弈提升LLM在多智能体系统中推理能力的强化学习框架，实现了战略游戏中的强大能力，并在多项基准测试中取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 开发能够在多智能体系统中有效合作和竞争的大型语言模型是实现更高级智能的关键步骤。

Method: 提出了一种端到端的强化学习框架MARS，利用自我博弈来激励LLM在合作和竞争游戏中的多智能体推理。

Result: 通过在28.7%的性能提升中，MARS训练的智能体在游戏和推理基准中都表现出显著的性能提升。

Conclusion: MARS框架通过自我博弈在战略游戏中实现了有效的多智能体推理能力，并在推理基准测试中表现出一致的性能提升。

Abstract: Developing Large Language Models (LLMs) to cooperate and compete effectively
within multi-agent systems is a critical step towards more advanced
intelligence. While reinforcement learning (RL) has proven effective for
enhancing reasoning in single-agent tasks, its extension to multi-turn,
multi-agent scenarios remains underexplored due to the challenges of
long-horizon credit assignment and agent-specific advantage estimation. To
address these challenges, we introduce MARS, an end-to-end RL framework that
incentivizes Multi-Agent Reasoning of LLMs through Self-play in both
cooperative and competitive games. MARS features a turn-level advantage
estimator that aligns learning signals with each interaction for credit
assignment, and an agent-specific advantage normalization to stabilize
multi-agent training. By learning with self-play across cooperative and
competitive games, the MARS agent trained from Qwen3-4B develops strong
strategic abilities that generalize to held-out games with up to 28.7%
performance improvements. More importantly, the capability acquired through
self-play generalizes beyond games, yielding consistent performance gains of
multi-agent systems in reasoning benchmarks. When integrated into leading
multi-agent systems, our MARS agent achieves significant performance gains of
10.0% on AIME and 12.5% on GPQA-Diamond. These results establish end-to-end RL
training with self-play in strategic games as a powerful approach for
developing generalizable multi-agent reasoning capabilities in LLMs. Our code
and models are publicly available at https://github.com/thu-nics/MARS.

</details>


### [190] [Taming the Judge: Deconflicting AI Feedback for Stable Reinforcement Learning](https://arxiv.org/abs/2510.15514)
*Boyin Liu,Zhuo Zhang,Sen Huang,Lipeng Xie,Qingxu Fu,Haoran Chen,LI YU,Tianyi Hu,Zhaoyang Liu,Bolin Ding,Dongbin Zhao*

Main category: cs.AI

TL;DR: 本文提出了一个综合框架，通过检测和解决强化学习中的判断不一致性，增强训练稳定性与模型性能。


<details>
  <summary>Details</summary>
Motivation: 前人研究主要关注判断的准确性，但逻辑一致性（尤其是偏好循环问题）尚未得到充分解决。

Method: 该框架包括冲突检测率（CDR）和去冲突图奖励（DGR），主要用于量化判断冲突并清除偏好循环。

Result: 实验结果表明，该框架在训练稳定性和模型性能上显著优于强基线。

Conclusion: 该框架显著提升了强化学习的稳定性与模型性能，逻辑一致性成为AI反馈的关键维度。

Abstract: However, this method often faces judgment inconsistencies that can
destabilize reinforcement learning. While prior research has focused on the
accuracy of judgments, the critical issue of logical coherence especially
issues such as preference cycles hasn't been fully addressed. To fill this gap,
we introduce a comprehensive framework designed to systematically detect and
resolve these inconsistencies during the reinforcement learning training
process. Our framework includes two main contributions: first, the Conflict
Detection Rate (CDR), a new metric that quantifies judgment conflicts, and
second, Deconflicted Graph Rewards (DGR), a framework that purifies signals by
removing cycles before policy optimization. DGR constructs preference graphs
from the initial judgments, transforms them into conflict-free Directed Acyclic
Graphs (DAGs), and generates a logically coherent reward signal that is
compatible with any policy optimizer. Experimental results show that our
framework significantly enhances training stability and model performance
compared to strong baselines, establishing logical consistency as a crucial and
now manageable dimension of AI feedback.

</details>


### [191] [JudgeSQL: Reasoning over SQL Candidates with Weighted Consensus Tournament](https://arxiv.org/abs/2510.15560)
*Jiayuan Bai,Xuan-guang Pan,Chongyang Tao,Shuai Ma*

Main category: cs.AI

TL;DR: JudgeSQL是一个新框架，旨在通过结构化推理和加权共识机制改善SQL查询选择，克服当前方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决现有选择方法在评分一致性、推理链脆弱性和语义细节捕捉方面的不足。

Method: 引入了一种推理基础的SQL评估模型，并结合加权共识锦标赛机制进行候选SQL选择。

Result: 在BIRD基准上的广泛实验表明，JudgeSQL在SQL判断能力上具有优势。

Conclusion: JudgeSQL提高了SQL判断能力，展现出良好的跨尺度泛化能力和对生成器能力的鲁棒性。

Abstract: Text-to-SQL is a pivotal task that bridges natural language understanding and
structured data access, yet it remains fundamentally challenging due to
semantic ambiguity and complex compositional reasoning. While large language
models (LLMs) have greatly advanced SQL generation though prompting, supervised
finetuning and reinforced tuning, the shift toward test-time scaling exposes a
new bottleneck: selecting the correct query from a diverse candidate pool.
Existing selection approaches, such as self-consistency or best-of-$N$
decoding, provide only shallow signals, making them prone to inconsistent
scoring, fragile reasoning chains, and a failure to capture fine-grained
semantic distinctions between closely related SQL candidates. To this end, we
introduce JudgeSQL, a principled framework that redefines SQL candidate
selection through structured reasoning and weighted consensus tournament
mechanism. JudgeSQL develops a reasoning-based SQL judge model that distills
reasoning traces with reinforcement learning guided by verifiable rewards,
enabling accurate and interpretable judgments. Building on this, a weighted
consensus tournament integrates explicit reasoning preferences with implicit
generator confidence, yielding selections that are both more reliable and more
efficient. Extensive experiments on the BIRD benchmark demonstrate that
JudgeSQL exhibits superior SQL judgment capabilities and good cross-scale
generalization and robustness to generator capacity.

</details>


### [192] [Context-aware deep learning using individualized prior information reduces false positives in disease risk prediction and longitudinal health assessment](https://arxiv.org/abs/2510.15591)
*Lavanya Umapathy,Patricia M Johnson,Tarun Dutt,Angela Tong,Madhur Nayan,Hersh Chandarana,Daniel K Sodickson*

Main category: cs.AI

TL;DR: 我们开发的机器学习框架通过整合以前的医疗记录，显著降低了前列腺癌风险预测中的假阳性率，从而提高了风险预测的准确性和特异性。


<details>
  <summary>Details</summary>
Motivation: 提高医疗健康监测的准确性，尤其是在就诊记录有限和频率不一的情况下。

Method: 开发了一种机器学习框架，利用患者早期就诊的信息整合来改善健康监测，并应用于前列腺癌风险预测。

Result: 整合先前就诊的影像和临床生物标志物信息，假阳性率降低，从51%降至24%，并且在未来五年的风险预测中，假阳性率从64%降至9%。

Conclusion: 通过整合来自之前就诊的信息，我们的模型显著提高了临床显著前列腺癌风险预测的准确性，缩小了假阳性率，从而增强了医疗风险预测的特异性。

Abstract: Temporal context in medicine is valuable in assessing key changes in patient
health over time. We developed a machine learning framework to integrate
diverse context from prior visits to improve health monitoring, especially when
prior visits are limited and their frequency is variable. Our model first
estimates initial risk of disease using medical data from the most recent
patient visit, then refines this assessment using information digested from
previously collected imaging and/or clinical biomarkers. We applied our
framework to prostate cancer (PCa) risk prediction using data from a large
population (28,342 patients, 39,013 magnetic resonance imaging scans, 68,931
blood tests) collected over nearly a decade. For predictions of the risk of
clinically significant PCa at the time of the visit, integrating prior context
directly converted false positives to true negatives, increasing overall
specificity while preserving high sensitivity. False positive rates were
reduced progressively from 51% to 33% when integrating information from up to
three prior imaging examinations, as compared to using data from a single
visit, and were further reduced to 24% when also including additional context
from prior clinical data. For predicting the risk of PCa within five years of
the visit, incorporating prior context reduced false positive rates still
further (64% to 9%). Our findings show that information collected over time
provides relevant context to enhance the specificity of medical risk
prediction. For a wide range of progressive conditions, sufficient reduction of
false positive rates using context could offer a pathway to expand longitudinal
health monitoring programs to large populations with comparatively low baseline
risk of disease, leading to earlier detection and improved health outcomes.

</details>


### [193] [Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism](https://arxiv.org/abs/2510.15600)
*Haoran Sun,Yankai Jiang,Zhenyu Tang,Yaning Pan,Shuang Gu,Zekai Lin,Lilong Wang,Wenjie Lou,Lei Liu,Lei Bai,Xiaosong Wang*

Main category: cs.AI

TL;DR: 本研究提出SciRecipe数据集与Thoth模型，以提高科学协议生成的准确性与可靠性。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前大型语言模型在科学协议生成中存在的不足，提升实验可重复性和效率。

Method: 提出了Sketch-and-Fill范式和结构化组件奖励机制，通过分阶段知识到行动训练Thoth模型。

Result: 本文提出了SciRecipe数据集和Thoth模型，以提高科学实验协议的生成和可重复性。通过Sketch-and-Fill范式，将分析、结构化和表达步骤分离，以实现清晰的协议生成。同时，引入基于结构的组件奖励机制，确保模型优化与实验可靠性相匹配。通过知识到行动的分阶段训练，Thoth在多个基准测试中超越了现有的大型语言模型，提供了更高的协议生成质量。

Conclusion: 该研究为开发可靠的科学助理提供了新思路，融合了知识与实验执行，具有较高的应用潜力。

Abstract: The foundation of reproducible science lies in protocols that are precise,
logically ordered, and executable. The autonomous generation of these protocols
through natural language queries could greatly improve the efficiency of the
reproduction process. However, current leading large language models (LLMs)
often generate incomplete or inconsistent protocols, limiting their utility. To
address this limitation, we first introduce SciRecipe, a large-scale dataset of
over 12K structured protocols spanning 27 biological subfields and encompassing
both comprehension and problem-solving tasks. To further improve protocol
generation, we propose the "Sketch-and-Fill" paradigm, which separates
analysis, structuring, and expression to ensure each step is explicit and
verifiable. Complementing this, the structured component-based reward mechanism
evaluates step granularity, action order, and semantic fidelity, aligning model
optimization with experimental reliability. Building on these components, we
develop Thoth, trained through a staged Knowledge-to-Action process that
progresses from knowledge acquisition to operational reasoning and ultimately
to robust, executable protocol generation. Across multiple benchmarks, Thoth
consistently surpasses both proprietary and open-source LLMs, achieving
significant improvements in step alignment, logical sequencing, and semantic
accuracy. Our approach paves the way for reliable scientific assistants that
bridge knowledge with experimental execution. All data, code, and models will
be released publicly.

</details>


### [194] [Direct Preference Optimization with Unobserved Preference Heterogeneity: The Necessity of Ternary Preferences](https://arxiv.org/abs/2510.15716)
*Keertana Chidambaram,Karthik Vinary Seetharaman,Vasilis Syrgkanis*

Main category: cs.AI

TL;DR: 研究了如何解决强化学习中人类反馈方法的局限性，提出了一种新方法以引入人类评估者的多样性，并确保生成模型的公平性和个性化。


<details>
  <summary>Details</summary>
Motivation: 处理人类评估者的多样性以及成对反馈的局限性，以改进强化学习和人类反馈的结合机制。

Method: 提出了期望最大化适应的直接偏好优化(DPO)方法，并设计了一种使用最小-最大遗憾公平标准的聚合算法。

Result: 展示了通过使用三种或更多响应的排名，可以确保识别潜在用户偏好，并且通过引入异质偏好，改善了对齐算法的效果。

Conclusion: 建立了一个理论与算法框架，以实现生成模型对不同用户的公平性与个性化对齐。

Abstract: Reinforcement Learning from Human Feedback (RLHF) has become central to
aligning large language models with human values, typically by first learning a
reward model from preference data which is then used to update the model with
reinforcement learning. Recent alternatives such as Direct Preference
Optimization (DPO) simplify this pipeline by directly optimizing on
preferences. However, both approaches often assume uniform annotator
preferences and rely on binary comparisons, overlooking two key limitations:
the diversity of human evaluators and the limitations of pairwise feedback. In
this work, we address both these issues. First, we connect preference learning
in RLHF with the econometrics literature and show that binary comparisons are
insufficient for identifying latent user preferences from finite user data and
infinite users, while (even incomplete) rankings over three or more responses
ensure identifiability. Second, we introduce methods to incorporate
heterogeneous preferences into alignment algorithms. We develop an
Expectation-Maximization adaptation of DPO that discovers latent annotator
types and trains a mixture of LLMs accordingly. Then we propose an aggregation
algorithm using a min-max regret fairness criterion to produce a single
generative policy with equitable performance guarantees. Together, these
contributions establish a theoretical and algorithmic framework for fairness
and personalization for diverse users in generative model alignment.

</details>


### [195] [Invoice Information Extraction: Methods and Performance Evaluation](https://arxiv.org/abs/2510.15727)
*Sai Yashwant,Anurag Dubey,Praneeth Paikray,Gantala Thulsiram*

Main category: cs.AI

TL;DR: 本论文提出了一种发票信息提取方法及其评估指标，以提升提取系统的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着电子发票的普及，自动化发票信息提取的需求日益增加，准确性评估也显得尤为重要。

Method: 使用Docling和LlamaCloud Services进行发票字段的识别和提取，并设计一套评估指标来确保提取结果的可靠性。

Result: 成功提取关键字段，如发票号码、日期、总金额和供应商信息，并提出了一套全面的评估指标。

Conclusion: 该研究提出了一种标准化的评估框架，以比较不同发票信息提取方法的性能。

Abstract: This paper presents methods for extracting structured information from
invoice documents and proposes a set of evaluation metrics (EM) to assess the
accuracy of the extracted data against annotated ground truth. The approach
involves pre-processing scanned or digital invoices, applying Docling and
LlamaCloud Services to identify and extract key fields such as invoice number,
date, total amount, and vendor details. To ensure the reliability of the
extraction process, we establish a robust evaluation framework comprising
field-level precision, consistency check failures, and exact match accuracy.
The proposed metrics provide a standardized way to compare different extraction
methods and highlight strengths and weaknesses in field-specific performance.

</details>


### [196] [Towards Relaxed Multimodal Inputs for Gait-based Parkinson's Disease Assessment](https://arxiv.org/abs/2510.15748)
*Minlin Zeng,Zhipeng Zhou,Yang Qiu,Zhiqi Shen*

Main category: cs.AI

TL;DR: 该论文提出了一种新的帕金森病评估系统，利用多目标优化处理多模态学习中的问题，提高了灵活性和效果。


<details>
  <summary>Details</summary>
Motivation: 解决传统多模态方法在训练与推断中同步性和依赖性的问题，并应对多模态信息融合时的模态崩溃。

Method: 将多模态学习表述为多目标优化问题，并引入基于边际的类别重平衡策略。

Result: 在多项公共数据集上实验，TRIP在异步和同步设置下的表现均优于最佳基准。

Conclusion: TRIP框架在不同设置下均展示了优越的性能，证明其有效性与适应性。

Abstract: Parkinson's disease assessment has garnered growing interest in recent years,
particularly with the advent of sensor data and machine learning techniques.
Among these, multimodal approaches have demonstrated strong performance by
effectively integrating complementary information from various data sources.
However, two major limitations hinder their practical application: (1) the need
to synchronize all modalities during training, and (2) the dependence on all
modalities during inference. To address these issues, we propose the first
Parkinson's assessment system that formulates multimodal learning as a
multi-objective optimization (MOO) problem. This not only allows for more
flexible modality requirements during both training and inference, but also
handles modality collapse issue during multimodal information fusion. In
addition, to mitigate the imbalance within individual modalities, we introduce
a margin-based class rebalancing strategy to enhance category learning. We
conduct extensive experiments on three public datasets under both synchronous
and asynchronous settings. The results show that our framework-Towards Relaxed
InPuts (TRIP)-achieves state-of-the-art performance, outperforming the best
baselines by 16.48, 6.89, and 11.55 percentage points in the asynchronous
setting, and by 4.86 and 2.30 percentage points in the synchronous setting,
highlighting its effectiveness and adaptability.

</details>


### [197] [Demo: Guide-RAG: Evidence-Driven Corpus Curation for Retrieval-Augmented Generation in Long COVID](https://arxiv.org/abs/2510.15782)
*Philip DiGiacomo,Haoyang Wang,Jinrui Fang,Yan Leng,W Michael Brode,Ying Ding*

Main category: cs.AI

TL;DR: 本文探讨了人工智能聊天机器人在临床医学中应对新兴疾病（如长期新冠）的挑战，并提出了一种新的信息检索与生成框架，即Guide-RAG，以提高临床问题回答的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着AI聊天机器人在临床中的普及，迫切需要为复杂的新兴疾病开发有效的问答框架。

Method: 评估了六种不同的检索增强生成（RAG）语料库配置，运用大语言模型作为评判框架，衡量其在可信度、相关性和全面性指标上的表现。

Result: 结合临床指南和高质量的系统评审的RAG配置在解决长期新冠的临床问题时，表现优于单一指南和大规模文献数据库。

Conclusion: 我们的研究表明，结合临床指南与高质量系统评审的RAG配置能够在临床决策支持中提供最佳的信息平衡。

Abstract: As AI chatbots gain adoption in clinical medicine, developing effective
frameworks for complex, emerging diseases presents significant challenges. We
developed and evaluated six Retrieval-Augmented Generation (RAG) corpus
configurations for Long COVID (LC) clinical question answering, ranging from
expert-curated sources to large-scale literature databases. Our evaluation
employed an LLM-as-a-judge framework across faithfulness, relevance, and
comprehensiveness metrics using LongCOVID-CQ, a novel dataset of
expert-generated clinical questions. Our RAG corpus configuration combining
clinical guidelines with high-quality systematic reviews consistently
outperformed both narrow single-guideline approaches and large-scale literature
databases. Our findings suggest that for emerging diseases, retrieval grounded
in curated secondary reviews provides an optimal balance between narrow
consensus documents and unfiltered primary literature, supporting clinical
decision-making while avoiding information overload and oversimplified
guidance. We propose Guide-RAG, a chatbot system and accompanying evaluation
framework that integrates both curated expert knowledge and comprehensive
literature databases to effectively answer LC clinical questions.

</details>

<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 74]
- [cs.CL](#cs.CL) [Total: 24]
- [cs.HC](#cs.HC) [Total: 9]
- [cs.LG](#cs.LG) [Total: 37]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.AI](#cs.AI) [Total: 12]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Gaussian See, Gaussian Do: Semantic 3D Motion Transfer from Multiview Video](https://arxiv.org/abs/2511.14848)
*Yarin Bekor,Gal Michael Harari,Or Perel,Or Litany*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的语义3D运动转移方法，能够实现无需装模的跨类别对象运动转移，并展现出优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 提出一种无约束、跨类别的运动转移方法，以实现对象之间的语义对应。

Method: 通过条件反演从源视频提取运动嵌入，将其应用于静态目标形状的渲染帧，并使用结果视频来监督动态3D高斯溅射重建。

Result: 与适应基线相比，展示了更高的运动保真度和结构一致性，首次建立了语义3D运动转移基准。

Conclusion: 我们的方法在语义3D运动转移任务中展示了优秀的运动保真度和结构一致性，同时建立了一个新的基准。

Abstract: We present Gaussian See, Gaussian Do, a novel approach for semantic 3D motion transfer from multiview video. Our method enables rig-free, cross-category motion transfer between objects with semantically meaningful correspondence. Building on implicit motion transfer techniques, we extract motion embeddings from source videos via condition inversion, apply them to rendered frames of static target shapes, and use the resulting videos to supervise dynamic 3D Gaussian Splatting reconstruction. Our approach introduces an anchor-based view-aware motion embedding mechanism, ensuring cross-view consistency and accelerating convergence, along with a robust 4D reconstruction pipeline that consolidates noisy supervision videos. We establish the first benchmark for semantic 3D motion transfer and demonstrate superior motion fidelity and structural consistency compared to adapted baselines. Code and data for this paper available at https://gsgd-motiontransfer.github.io/

</details>


### [2] [CPSL: Representing Volumetric Video via Content-Promoted Scene Layers](https://arxiv.org/abs/2511.14927)
*Kaiyuan Hu,Yili Jin,Junhua Liu,Xize Duan,Hong Kang,Xue Liu*

Main category: cs.CV

TL;DR: CPSL是一种紧凑的2.5D视频表示，通过几何一致层的解构，提供了较高的感知质量，同时降低了存储和渲染成本，支持实时播放。


<details>
  <summary>Details</summary>
Motivation: 现有的体积视频表现形式在捕获、计算和渲染方面存在高成本，限制了其在按需视频和实时通信中的可扩展性，迫切需要一种新方法来解决这一问题。

Method: 提出了一种Compact 2.5D视频表示CPSL，通过使用每帧深度和内容显著性指导，将每帧解构为多个几何一致的层，减少计算开销。

Result: CPSL能够实时播放，具有更高的感知质量和边界保真度，同时减少了存储和渲染成本。

Conclusion: CPSL在多个基准测试中表现出色，实现了较高的感知质量和边界保真度，同时在存储和渲染成本上显著降低，提供了一条将2D视频转化为可扩展的2.5D沉浸式媒体的实用路径。

Abstract: Volumetric video enables immersive and interactive visual experiences by supporting free viewpoint exploration and realistic motion parallax. However, existing volumetric representations from explicit point clouds to implicit neural fields, remain costly in capture, computation, and rendering, which limits their scalability for on-demand video and reduces their feasibility for real-time communication.
  To bridge this gap, we propose Content-Promoted Scene Layers (CPSL), a compact 2.5D video representation that brings the perceptual benefits of volumetric video to conventional 2D content. Guided by per-frame depth and content saliency, CPSL decomposes each frame into a small set of geometry-consistent layers equipped with soft alpha bands and an edge-depth cache that jointly preserve occlusion ordering and boundary continuity. These lightweight, 2D-encodable assets enable parallax-corrected novel-view synthesis via depth-weighted warping and front-to-back alpha compositing, bypassing expensive 3D reconstruction. Temporally, CPSL maintains inter-frame coherence using motion-guided propagation and per-layer encoding, supporting real-time playback with standard video codecs. Across multiple benchmarks, CPSL achieves superior perceptual quality and boundary fidelity compared with layer-based and neural-field baselines while reducing storage and rendering cost by several folds. Our approach offer a practical path from 2D video to scalable 2.5D immersive media.

</details>


### [3] [B-Rep Distance Functions (BR-DF): How to Represent a B-Rep Model by Volumetric Distance Functions?](https://arxiv.org/abs/2511.14870)
*Fuyang Zhang,Pradeep Kumar Jayaraman,Xiang Xu,Yasutaka Furukawa*

Main category: cs.CV

TL;DR: 本论文提出了BR-DF，一种新颖的CAD B-Rep几何表示法，成功实现了100%成功率的模型生成。


<details>
  <summary>Details</summary>
Motivation: 旨在通过一种新的几何表示方法，提高CAD B-Rep模型的生成效率与准确性。

Method: 基于体积距离函数的几何表示，通过扩展Marching Cubes算法，将BR-DF直接转换为水密的CAD B-Rep模型，同时采用了具有3D U-Net骨干的多分支潜在扩散来联合生成SDF和每个面UDF。

Result: BR-DF能够有效编码CAD模型表面网格几何，且在生成过程中具有100%的成功率，确保了模型的水密性。

Conclusion: 本研究提出的BR-DF方法在生成（分面）B-Rep模型方面，达到了前所未有的100%成功率，并与最先进的方法在CAD生成性能上相当。

Abstract: This paper presents a novel geometric representation for CAD Boundary Representation (B-Rep) based on volumetric distance functions, dubbed B-Rep Distance Functions (BR-DF). BR-DF encodes the surface mesh geometry of a CAD model as signed distance function (SDF). B-Rep vertices, edges, faces and their topology information are encoded as per-face unsigned distance functions (UDFs). An extension of the Marching Cubes algorithm converts BR-DF directly into watertight CAD B-Rep model (strictly speaking a faceted B-Rep model). A surprising characteristic of BR-DF is that this conversion process never fails. Leveraging the volumetric nature of BR-DF, we propose a multi-branch latent diffusion with 3D U-Net backbone for jointly generating the SDF and per-face UDFs of a BR-DF model. Our approach achieves comparable CAD generation performance against SOTA methods while reaching the unprecedented 100% success rate in producing (faceted) B-Rep models.

</details>


### [4] [An Event-triggered System for Social Persuasion and Danger Alert in Elder Home Monitoring](https://arxiv.org/abs/2511.15117)
*Jun-Yi Liu,Chung-Hao Chen,Ya-Chi Tsao,Ssu-Yao Wu,Yu-Ting Tsao,Lyn Chao-ling Chen*

Main category: cs.CV

TL;DR: 本研究开发了一种事件触发系统以检测老年人的活动并加强与亲属的联系。


<details>
  <summary>Details</summary>
Motivation: 考虑老年人的身心状态，旨在提高老年人的安全感与家人沟通。

Method: 采用GMM背景建模检测和记录事件，使用SVM机器学习分析捕获的图像。

Result: 在家庭场景中进行了实验，涉及5个家庭，成功检测到三种类型的生活事件。

Conclusion: 本研究开发了一种基于事件触发的系统，以检测老年人的运动行为，并促进老人与亲属之间的沟通。

Abstract: In the study, the physical state and mental state of elders are both considered, and an event-triggered system has developed to detect events: watch dog, danger notice and photo link. By adopting GMM background modeling, the motion behavior of visitors and elders can be detected in the watch dog event and danger notice event respectively. Experiments set in home scenarios and 5 families participated in the experiments for detecting and recording three types of events from their life activities. In addition, the captured images were analyzed using SVM machine learning. For lack of technical experiences of elders, an intuitive operation as normal life activity was designed to create communication between elder and relatives via social media.

</details>


### [5] [Towards Unbiased Cross-Modal Representation Learning for Food Image-to-Recipe Retrieval](https://arxiv.org/abs/2511.15201)
*Qing Wang,Chong-Wah Ngo,Ee-Peng Lim*

Main category: cs.CV

TL;DR: 本研究通过因果理论改进食谱与食物图像的交叉模态检索，提出了消除偏见的有效方法，并在Recipe1M数据集上取得了新的检索性能突破。


<details>
  <summary>Details</summary>
Motivation: 当前学习食谱与食物图像之间的相似性的方法存在偏见，难以准确反映交叉模态检索的相关性。

Method: 采用因果理论进行交叉模态表征学习，建立食谱与图像之间的因果关系模型，并进行反向调整以减少偏见。

Result: 在Recipe1M数据集上，经过实验验证，提出的方法在1K、10K和50K测试数据规模下均实现了MedR=1的检索性能。

Conclusion: 通过因果干预，我们提出的方法在Recipe1M数据集上实现了新的最先进检索性能，验证了偏见消除的有效性。

Abstract: This paper addresses the challenges of learning representations for recipes and food images in the cross-modal retrieval problem. As the relationship between a recipe and its cooked dish is cause-and-effect, treating a recipe as a text source describing the visual appearance of a dish for learning representation, as the existing approaches, will create bias misleading image-and-recipe similarity judgment. Specifically, a food image may not equally capture every detail in a recipe, due to factors such as the cooking process, dish presentation, and image-capturing conditions. The current representation learning tends to capture dominant visual-text alignment while overlooking subtle variations that determine retrieval relevance. In this paper, we model such bias in cross-modal representation learning using causal theory. The causal view of this problem suggests ingredients as one of the confounder sources and a simple backdoor adjustment can alleviate the bias. By causal intervention, we reformulate the conventional model for food-to-recipe retrieval with an additional term to remove the potential bias in similarity judgment. Based on this theory-informed formulation, we empirically prove the oracle performance of retrieval on the Recipe1M dataset to be MedR=1 across the testing data sizes of 1K, 10K, and even 50K. We also propose a plug-and-play neural module, which is essentially a multi-label ingredient classifier for debiasing. New state-of-the-art search performances are reported on the Recipe1M dataset.

</details>


### [6] [InstructMix2Mix: Consistent Sparse-View Editing Through Multi-View Model Personalization](https://arxiv.org/abs/2511.14899)
*Daniel Gilo,Or Litany*

Main category: cs.CV

TL;DR: 本文提出I-Mix2Mix框架，解决了多视图图像编辑中的一致性问题，显著提升了结果质量。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏输入视图下的多视图图像编辑任务，并确保不同视图之间的编辑一致性。

Method: 提出了一种框架，通过多视图扩散模型对2D扩散模型的编辑能力进行提取，采用新的适应方式来确保跨视图一致性。

Result: 实验表明，I-Mix2Mix在多视图一致性方面有显著改善。

Conclusion: I-Mix2Mix显著提升了多视图一致性，同时保持了高帧编辑质量。

Abstract: We address the task of multi-view image editing from sparse input views, where the inputs can be seen as a mix of images capturing the scene from different viewpoints. The goal is to modify the scene according to a textual instruction while preserving consistency across all views. Existing methods, based on per-scene neural fields or temporal attention mechanisms, struggle in this setting, often producing artifacts and incoherent edits. We propose InstructMix2Mix (I-Mix2Mix), a framework that distills the editing capabilities of a 2D diffusion model into a pretrained multi-view diffusion model, leveraging its data-driven 3D prior for cross-view consistency. A key contribution is replacing the conventional neural field consolidator in Score Distillation Sampling (SDS) with a multi-view diffusion student, which requires novel adaptations: incremental student updates across timesteps, a specialized teacher noise scheduler to prevent degeneration, and an attention modification that enhances cross-view coherence without additional cost. Experiments demonstrate that I-Mix2Mix significantly improves multi-view consistency while maintaining high per-frame edit quality.

</details>


### [7] [Skin-R1: Toward Trustworthy Clinical Reasoning for Dermatological Diagnosis](https://arxiv.org/abs/2511.14900)
*Zehao Liu,Wejieying Ren,Jipeng Zhang,Tianxiang Zhao,Jingxi Zhu,Xiaoting Li,Vasant G. Honavar*

Main category: cs.CV

TL;DR: SkinR1 is a dermatological vision-language model that integrates textbook reasoning and reinforcement learning, overcoming major limitations of current models to achieve high diagnostic accuracy.


<details>
  <summary>Details</summary>
Motivation: The motivation is to improve the trustworthiness and clinical utility of vision-language models in dermatological diagnosis by addressing issues related to data heterogeneity, grounded diagnostic rationales, and model scalability.

Method: The method involves designing a textbook-based reasoning generator, supervised fine-tuning using generated trajectories, and applying a reinforcement learning paradigm to enhance scalability and generalization.

Result: SkinR1 significantly enhances diagnostic performance and reasoning capabilities on various dermatology datasets, as shown by extensive experimental results and ablation studies.

Conclusion: SkinR1 demonstrates superior diagnostic accuracy in dermatology by effectively combining textbook-based reasoning with reinforcement learning, addressing key challenges in vision-language models.

Abstract: The emergence of vision-language models (VLMs) has opened new possibilities for clinical reasoning and has shown promising performance in dermatological diagnosis. However, their trustworthiness and clinical utility are often limited by three major factors: (1) Data heterogeneity, where diverse datasets lack consistent diagnostic labels and clinical concept annotations; (2) Absence of grounded diagnostic rationales, leading to a scarcity of reliable reasoning supervision; and (3) Limited scalability and generalization, as models trained on small, densely annotated datasets struggle to transfer nuanced reasoning to large, sparsely-annotated ones.
  To address these limitations, we propose SkinR1, a novel dermatological VLM that combines deep, textbook-based reasoning with the broad generalization capabilities of reinforcement learning (RL). SkinR1 systematically resolves the key challenges through a unified, end-to-end framework. First, we design a textbook-based reasoning generator that synthesizes high-fidelity, hierarchy-aware, and differential-diagnosis (DDx)-informed trajectories, providing reliable expert-level supervision. Second, we leverage the constructed trajectories for supervised fine-tuning (SFT) empowering the model with grounded reasoning ability. Third, we develop a novel RL paradigm that, by incorporating the hierarchical structure of diseases, effectively transfers these grounded reasoning patterns to large-scale, sparse data. Extensive experiments on multiple dermatology datasets demonstrate that SkinR1 achieves superior diagnostic accuracy. The ablation study demonstrates the importance of the reasoning foundation instilled by SFT.

</details>


### [8] [FarSLIP: Discovering Effective CLIP Adaptation for Fine-Grained Remote Sensing Understanding](https://arxiv.org/abs/2511.14901)
*Zhenshi Li,Weikang Yu,Dilxat Muhtar,Xueliang Zhang,Pengfeng Xiao,Pedram Ghamisi,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: 本研究提出FarSLIP框架，通过多层次区域-文本对齐，显著提升遥感领域的细粒度视觉-语言对齐性能，设置了新基准。


<details>
  <summary>Details</summary>
Motivation: The motivation behind this research is to enhance the spatial awareness of CLIP models in remote sensing applications by addressing the limitations of existing region-text alignment methods.

Method: The proposed FarSLIP framework utilizes patch-to-patch distillation for local and global visual cue alignment, and employs CLS token-based region-category alignment for better spatial awareness.

Result: FarSLIP achieves state-of-the-art performance on both open-vocabulary semantic segmentation and image-level tasks, like zero-shot classification and image-text retrieval, confirming the effectiveness of the proposed approach.

Conclusion: FarSLIP establishes a new benchmark in fine-grained vision-language alignment for remote sensing, demonstrating significant improvements in various tasks.

Abstract: As CLIP's global alignment limits its ability to capture fine-grained details, recent efforts have focused on enhancing its region-text alignment. However, current remote sensing (RS)-specific CLIP variants still inherit this limited spatial awareness. We identify two key limitations behind this: (1) current RS image-text datasets generate global captions from object-level labels, leaving the original object-level supervision underutilized; (2) despite the success of region-text alignment methods in general domain, their direct application to RS data often leads to performance degradation. To address these, we construct the first multi-granularity RS image-text dataset, MGRS-200k, featuring rich object-level textual supervision for RS region-category alignment. We further investigate existing fine-grained CLIP tuning strategies and find that current explicit region-text alignment methods, whether in a direct or indirect way, underperform due to severe degradation of CLIP's semantic coherence. Building on these, we propose FarSLIP, a Fine-grained Aligned RS Language-Image Pretraining framework. Rather than the commonly used patch-to-CLS self-distillation, FarSLIP employs patch-to-patch distillation to align local and global visual cues, which improves feature discriminability while preserving semantic coherence. Additionally, to effectively utilize region-text supervision, it employs simple CLS token-based region-category alignment rather than explicit patch-level alignment, further enhancing spatial awareness. FarSLIP features improved fine-grained vision-language alignment in RS domain and sets a new state of the art not only on RS open-vocabulary semantic segmentation, but also on image-level tasks such as zero-shot classification and image-text retrieval. Our dataset, code, and models are available at https://github.com/NJU-LHRS/FarSLIP.

</details>


### [9] [nnMIL: A generalizable multiple instance learning framework for computational pathology](https://arxiv.org/abs/2511.14907)
*Xiangde Luo,Jinxi Xiang,Yuanfeng Ji,Ruijiang Li*

Main category: cs.CV

TL;DR: nnMIL框架通过随机抽样与滑动窗口推断，实现了病理基础模型的有效聚合，显著提升了疾病诊断和预后预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管最近的病理基础模型对全幅图像中的补丁级表示提取有很大帮助，但现有方法在将这些特征聚合成滑动级预测时受限于设计局限性，影响了其推广性和可靠性。

Method: nnMIL是一种多实例学习框架，通过在补丁和特征级别进行随机抽样，连接补丁级基础模型与稳健的滑动级临床推断。

Result: nnMIL在40,000个全幅图像上，涵盖35个临床任务和四种病理基础模型， consistently outperform 现有的多实例学习方法，在疾病诊断、组织学分型、分子标志物检测和癌症预后预测等方面表现优异。它还显示了强大的跨模型通用性、可靠的不确定性量化以及在多个外部队列中的稳健生存分层。

Conclusion: nnMIL提供了一种实用且具通用性的解决方案，将病理基础模型转化为临床有意义的预测，推动了可靠AI系统在现实世界中的开发和部署。

Abstract: Computational pathology holds substantial promise for improving diagnosis and guiding treatment decisions. Recent pathology foundation models enable the extraction of rich patch-level representations from large-scale whole-slide images (WSIs), but current approaches for aggregating these features into slide-level predictions remain constrained by design limitations that hinder generalizability and reliability. Here, we developed nnMIL, a simple yet broadly applicable multiple-instance learning framework that connects patch-level foundation models to robust slide-level clinical inference. nnMIL introduces random sampling at both the patch and feature levels, enabling large-batch optimization, task-aware sampling strategies, and efficient and scalable training across datasets and model architectures. A lightweight aggregator performs sliding-window inference to generate ensemble slide-level predictions and supports principled uncertainty estimation. Across 40,000 WSIs encompassing 35 clinical tasks and four pathology foundation models, nnMIL consistently outperformed existing MIL methods for disease diagnosis, histologic subtyping, molecular biomarker detection, and pan- cancer prognosis prediction. It further demonstrated strong cross-model generalization, reliable uncertainty quantification, and robust survival stratification in multiple external cohorts. In conclusion, nnMIL offers a practical and generalizable solution for translating pathology foundation models into clinically meaningful predictions, advancing the development and deployment of reliable AI systems in real-world settings.

</details>


### [10] [X-WIN: Building Chest Radiograph World Model via Predictive Sensing](https://arxiv.org/abs/2511.14918)
*Zefan Yang,Ge Wang,James Hendler,Mannudeep K. Kalra,Pingkun Yan*

Main category: cs.CV

TL;DR: 本文提出了一种名为X-WIN的新型CXR世界模型，通过学习胸部CT的2D投影，克服了传统CXR的三维结构限制，展现出在多个任务中的优越表现。


<details>
  <summary>Details</summary>
Motivation: 针对CXR作为2D投影影像的结构叠加限制，难以捕捉3D解剖结构的问题，提出一种新颖的解决方案。

Method: X-WIN通过在潜在空间中学习预测胸部CT的2D投影来提炼体积知识，并引入亲和力引导的对比对齐损失，结合真实胸部X光影像进行训练。

Result: 通过对比实验，显示X-WIN在使用线性探测和少量样本微调的下游任务中表现出色，提升模型适应性。

Conclusion: X-WIN在多个下游任务中表现优于现有基础模型，并且能够渲染2D投影以重建3D CT体积。

Abstract: Chest X-ray radiography (CXR) is an essential medical imaging technique for disease diagnosis. However, as 2D projectional images, CXRs are limited by structural superposition and hence fail to capture 3D anatomies. This limitation makes representation learning and disease diagnosis challenging. To address this challenge, we propose a novel CXR world model named X-WIN, which distills volumetric knowledge from chest computed tomography (CT) by learning to predict its 2D projections in latent space. The core idea is that a world model with internalized knowledge of 3D anatomical structure can predict CXRs under various transformations in 3D space. During projection prediction, we introduce an affinity-guided contrastive alignment loss that leverages mutual similarities to capture rich, correlated information across projections from the same volume. To improve model adaptability, we incorporate real CXRs into training through masked image modeling and employ a domain classifier to encourage statistically similar representations for real and simulated CXRs. Comprehensive experiments show that X-WIN outperforms existing foundation models on diverse downstream tasks using linear probing and few-shot fine-tuning. X-WIN also demonstrates the ability to render 2D projections for reconstructing a 3D CT volume.

</details>


### [11] [Unsupervised Discovery of Long-Term Spatiotemporal Periodic Workflows in Human Activities](https://arxiv.org/abs/2511.14945)
*Fan Yang,Quanting Xie,Atsunori Moteki,Shoichi Masui,Shan Jiang,Yonatan Bisk,Graham Neubig*

Main category: cs.CV

TL;DR: 本文提出了第一个包含580个多模态人类活动序列的基准测试，支持无监督检测和过程异常检测，结果显示轻量基线模型在这些任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 探讨长期周期性工作流及其低对比度模式的检测问题，弥补现有研究的空白。

Method: 引入了580个多模态人类活动序列，并设计了与实际应用相关的三项评估任务。

Result: 基准测试对无监督工作流检测方法和基于大型语言模型的零-shot 方法提出了显著挑战，轻量基线模型在所有评估任务中均表现优越。

Conclusion: 该基准测试的提出为长周期工作流检测提供了新的研究方向，且轻量化的基线模型在多项任务中表现优异。

Abstract: Periodic human activities with implicit workflows are common in manufacturing, sports, and daily life. While short-term periodic activities -- characterized by simple structures and high-contrast patterns -- have been widely studied, long-term periodic workflows with low-contrast patterns remain largely underexplored. To bridge this gap, we introduce the first benchmark comprising 580 multimodal human activity sequences featuring long-term periodic workflows. The benchmark supports three evaluation tasks aligned with real-world applications: unsupervised periodic workflow detection, task completion tracking, and procedural anomaly detection. We also propose a lightweight, training-free baseline for modeling diverse periodic workflow patterns. Experiments show that: (i) our benchmark presents significant challenges to both unsupervised periodic detection methods and zero-shot approaches based on powerful large language models (LLMs); (ii) our baseline outperforms competing methods by a substantial margin in all evaluation tasks; and (iii) in real-world applications, our baseline demonstrates deployment advantages on par with traditional supervised workflow detection approaches, eliminating the need for annotation and retraining. Our project page is https://sites.google.com/view/periodicworkflow.

</details>


### [12] [RocSync: Millisecond-Accurate Temporal Synchronization for Heterogeneous Camera Systems](https://arxiv.org/abs/2511.14948)
*Jaro Meyer,Frédéric Giraud,Joschua Wüthrich,Marc Pollefeys,Philipp Fürnstahl,Lilian Calvet*

Main category: cs.CV

TL;DR: 本研究提出了一种低成本的通用同步方法，通过定制的LED时钟实现了异构相机系统的毫秒级时间对齐，并在多个实验中表现优异，适用于工业和临床应用。


<details>
  <summary>Details</summary>
Motivation: 在多视角视频流的准确时空对齐对动态场景应用至关重要，但多相机同步尤其在异构设置中仍然是一个重大挑战。

Method: 提出了一种低成本通用的同步方法，通过定制的LED时钟实现多种相机系统的毫秒级时间对齐，支持可见光（RGB）和红外（IR）模式。

Result: 该方法在多个录制中实现了1.34毫秒的均方根误差（RMSE），超越了基于光、音频和时间码的同步方法，并直接改善了多视角姿态估计和3D重建等后续计算机视觉任务。

Conclusion: 该方法简化了同步流程，拓宽了在不受限制环境中的先进视觉传感应用，包括工业和临床应用。

Abstract: Accurate spatiotemporal alignment of multi-view video streams is essential for a wide range of dynamic-scene applications such as multi-view 3D reconstruction, pose estimation, and scene understanding. However, synchronizing multiple cameras remains a significant challenge, especially in heterogeneous setups combining professional and consumer-grade devices, visible and infrared sensors, or systems with and without audio, where common hardware synchronization capabilities are often unavailable. This limitation is particularly evident in real-world environments, where controlled capture conditions are not feasible. In this work, we present a low-cost, general-purpose synchronization method that achieves millisecond-level temporal alignment across diverse camera systems while supporting both visible (RGB) and infrared (IR) modalities. The proposed solution employs a custom-built \textit{LED Clock} that encodes time through red and infrared LEDs, allowing visual decoding of the exposure window (start and end times) from recorded frames for millisecond-level synchronization. We benchmark our method against hardware synchronization and achieve a residual error of 1.34~ms RMSE across multiple recordings. In further experiments, our method outperforms light-, audio-, and timecode-based synchronization approaches and directly improves downstream computer vision tasks, including multi-view pose estimation and 3D reconstruction. Finally, we validate the system in large-scale surgical recordings involving over 25 heterogeneous cameras spanning both IR and RGB modalities. This solution simplifies and streamlines the synchronization pipeline and expands access to advanced vision-based sensing in unconstrained environments, including industrial and clinical applications.

</details>


### [13] [Artificial intelligence approaches for energy-efficient laser cutting machines](https://arxiv.org/abs/2511.14952)
*Mohamed Abdallah Salem,Hamdy Ahmed Ashour,Ahmed Elshenawy*

Main category: cs.CV

TL;DR: 本研究通过深度学习技术提高激光切割能效，降低环境影响，实验结果显示能耗减少20%至50%。


<details>
  <summary>Details</summary>
Motivation: 研究激光切割过程中能耗与环境影响的挑战，并解决现有CO2激光抽吸泵缺乏自适应控制的问题，推动制造业的可持续发展。

Method: 本研究采用闭环配置，实现激光切割过程中抽吸泵的自适应控制，通过多种材料分类方法与烟雾水平检测深度学习模型相结合，以动态调整泵的功率。

Result: 经过实验证明，烟雾吸尘泵的能耗减少了20%至50%，显著提高了能效，为制造业的环保贡献。

Conclusion: 综上所述，本研究提出的深度学习方法在激光切割中有效减少能耗与环境影响，为制造业的可持续发展提供了显著贡献。

Abstract: This research addresses the significant challenges of energy consumption and environmental impact in laser cutting by proposing novel deep learning (DL) methodologies to achieve energy reduction. Recognizing the current lack of adaptive control and the open-loop nature of CO2 laser suction pumps, this study utilizes closed-loop configurations that dynamically adjust pump power based on both the material being cut and the smoke level generated. To implement this adaptive system, diverse material classification methods are introduced, including techniques leveraging lens-less speckle sensing with a customized Convolutional Neural Network (CNN) and an approach using a USB camera with transfer learning via the pre-trained VGG16 CNN model. Furthermore, a separate DL model for smoke level detection is employed to simultaneously refine the pump's power output. This integration prompts the exhaust suction pump to automatically halt during inactive times and dynamically adjust power during operation, leading to experimentally proven and remarkable energy savings, with results showing a 20% to 50% reduction in the smoke suction pump's energy consumption, thereby contributing substantially to sustainable development in the manufacturing sector.

</details>


### [14] [EGSA-PT:Edge-Guided Spatial Attention with Progressive Training for Monocular Depth Estimation and Segmentation of Transparent Objects](https://arxiv.org/abs/2511.14970)
*Gbenga Omotara,Ramy Farag,Seyed Mohamad Ali Tousi,G. N. DeSouza*

Main category: cs.CV

TL;DR: 提出EGSA和渐进训练策略，通过边界信息融合，提升对透明物体的深度感知和分割性能。


<details>
  <summary>Details</summary>
Motivation: 透明物体的感知在计算机视觉中一直是主要挑战，透明性影响深度估计和语义分割。

Method: 边缘引导空间注意力（EGSA）作为融合机制，结合边界信息来减轻语义特征和几何特征之间的负面交互。

Result: 在Syn-TODD和ClearPose基准测试中，EGSA相比现有最先进方法（MODEST）提升了深度精度，同时保持了竞争性的分割性能，特别是在透明区域的改进最为显著。

Conclusion: 提出的边缘引导空间注意力框架和多模态渐进训练策略显著提升了对透明物体的感知能力。

Abstract: Transparent object perception remains a major challenge in computer vision research, as transparency confounds both depth estimation and semantic segmentation. Recent work has explored multi-task learning frameworks to improve robustness, yet negative cross-task interactions often hinder performance. In this work, we introduce Edge-Guided Spatial Attention (EGSA), a fusion mechanism designed to mitigate destructive interactions by incorporating boundary information into the fusion between semantic and geometric features. On both Syn-TODD and ClearPose benchmarks, EGSA consistently improved depth accuracy over the current state of the art method (MODEST), while preserving competitive segmentation performance, with the largest improvements appearing in transparent regions. Besides our fusion design, our second contribution is a multi-modal progressive training strategy, where learning transitions from edges derived from RGB images to edges derived from predicted depth images. This approach allows the system to bootstrap learning from the rich textures contained in RGB images, and then switch to more relevant geometric content in depth maps, while it eliminates the need for ground-truth depth at training time. Together, these contributions highlight edge-guided fusion as a robust approach capable of improving transparent object perception.

</details>


### [15] [Logit-Based Losses Limit the Effectiveness of Feature Knowledge Distillation](https://arxiv.org/abs/2511.14981)
*Nicholas Cooper,Lijun Chen,Sailesh Dwivedy,Danna Gurari*

Main category: cs.CV

TL;DR: 该研究提出了一种新的基于特征的知识蒸馏方法，显著提高了轻量级模型的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 旨在探索新方法来提升轻量级学生模型的性能，使用特征损失来替代传统的logit损失。

Method: 提出了一种仅基于特征损失的知识蒸馏框架，排除了基于logit的损失函数。

Result: 在三种图像分类数据集上的实验表明，该方法超越了标准的知识蒸馏方法，达到了最先进的性能。

Conclusion: 我们的知识蒸馏方法在多个数据集上表现出优越的性能，最高提升达15%。

Abstract: Knowledge distillation (KD) methods can transfer knowledge of a parameter-heavy teacher model to a light-weight student model. The status quo for feature KD methods is to utilize loss functions based on logits (i.e., pre-softmax class scores) and intermediate layer features (i.e., latent representations). Unlike previous approaches, we propose a feature KD framework for training the student's backbone using feature-based losses exclusively (i.e., without logit-based losses such as cross entropy). Leveraging recent discoveries about the geometry of latent representations, we introduce a knowledge quality metric for identifying which teacher layers provide the most effective knowledge for distillation. Experiments on three image classification datasets with four diverse student-teacher pairs, spanning convolutional neural networks and vision transformers, demonstrate our KD method achieves state-of-the-art performance, delivering top-1 accuracy boosts of up to 15% over standard approaches. We publically share our code to facilitate future work at https://github.com/Thegolfingocto/KD_wo_CE.

</details>


### [16] [Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation](https://arxiv.org/abs/2511.14993)
*Vladimir Arkhipkin,Vladimir Korviakov,Nikolai Gerasimenko,Denis Parkhomenko,Viacheslav Vasilev,Alexey Letunovskiy,Maria Kovaleva,Nikolai Vaulin,Ivan Kirillov,Lev Novitskiy,Denis Koposov,Nikita Kiselev,Alexander Varlamov,Dmitrii Mikhailov,Vladimir Polovnikov,Andrey Shutkin,Ilya Vasiliev,Julia Agafonova,Anastasiia Kargapoltseva,Anna Dmitrienko,Anastasia Maltseva,Anna Averchenkova,Olga Kim,Tatiana Nikulina,Denis Dimitrov*

Main category: cs.CV

TL;DR: Kandinsky 5.0 是一种高端生成模型框架，支持高分辨率图像和视频生成，并通过创新技术提升了生成质量和速度，供研究社区使用。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在提升高分辨率图像及视频合成的质量和效率，满足广泛的生成应用需求。

Method: 文中介绍了 Kandinsky 5.0 的技术框架，包括数据生命周期的管理、多阶段训练流程及各种技术优化，实现了高效的生成速度和出色的性能。

Result: Kandinsky 5.0 通过其多样化的模型组合和创新的训练方法，实现了在各种任务上的领先性能，获得了人类评估的认可。

Conclusion: Kandinsky 5.0 提供了一种先进的生成框架，具备高分辨率图像和视频合成的优越性能，促进了研究社区对高质量生成模型的开发与获取。

Abstract: This report introduces Kandinsky 5.0, a family of state-of-the-art foundation models for high-resolution image and 10-second video synthesis. The framework comprises three core line-up of models: Kandinsky 5.0 Image Lite - a line-up of 6B parameter image generation models, Kandinsky 5.0 Video Lite - a fast and lightweight 2B parameter text-to-video and image-to-video models, and Kandinsky 5.0 Video Pro - 19B parameter models that achieves superior video generation quality. We provide a comprehensive review of the data curation lifecycle - including collection, processing, filtering and clustering - for the multi-stage training pipeline that involves extensive pre-training and incorporates quality-enhancement techniques such as self-supervised fine-tuning (SFT) and reinforcement learning (RL)-based post-training. We also present novel architectural, training, and inference optimizations that enable Kandinsky 5.0 to achieve high generation speeds and state-of-the-art performance across various tasks, as demonstrated by human evaluation. As a large-scale, publicly available generative framework, Kandinsky 5.0 leverages the full potential of its pre-training and subsequent stages to be adapted for a wide range of generative applications. We hope that this report, together with the release of our open-source code and training checkpoints, will substantially advance the development and accessibility of high-quality generative models for the research community.

</details>


### [17] [FinCriticalED: A Visual Benchmark for Financial Fact-Level OCR Evaluation](https://arxiv.org/abs/2511.14998)
*Yueru He,Xueqing Peng,Yupeng Cao,Yan Wang,Lingfei Qian,Haohang Li,Yi Han,Ruoyu Xiang,Mingquan Lin,Prayag Tiwari,Jimin Huang,Guojun Xiong,Sophia Ananiadou*

Main category: cs.CV

TL;DR: 本文介绍了FinCriticalED，一个用于评估金融文档OCR和视觉语言模型在事实级别的可视化基准，强调了在复杂环境中对事实准确性的需求。


<details>
  <summary>Details</summary>
Motivation: 金融文件在视觉上复杂且信息密集，OCR的微小错误可能导致不同的解释，因此需要一个专门的基准来评估事实级的正确性。

Method: 通过创新的LLM作为评估管道，执行结构化事实提取和上下文验证。

Result: 尽管最强的专有模型在事实准确性上表现最佳，但在视觉复杂的数字和时间环境中仍存在重大错误。

Conclusion: FinCriticalED为金融文件理解提供了必要的基础，强调在复杂视觉上下文中实现精确的事实提取和验证的必要性。

Abstract: We introduce FinCriticalED (Financial Critical Error Detection), a visual benchmark for evaluating OCR and vision language models on financial documents at the fact level. Financial documents contain visually dense and table heavy layouts where numerical and temporal information is tightly coupled with structure. In high stakes settings, small OCR mistakes such as sign inversion or shifted dates can lead to materially different interpretations, while traditional OCR metrics like ROUGE and edit distance capture only surface level text similarity. \ficriticaled provides 500 image-HTML pairs with expert annotated financial facts covering over seven hundred numerical and temporal facts. It introduces three key contributions. First, it establishes the first fact level evaluation benchmark for financial document understanding, shifting evaluation from lexical overlap to domain critical factual correctness. Second, all annotations are created and verified by financial experts with strict quality control over signs, magnitudes, and temporal expressions. Third, we develop an LLM-as-Judge evaluation pipeline that performs structured fact extraction and contextual verification for visually complex financial documents. We benchmark OCR systems, open source vision language models, and proprietary models on FinCriticalED. Results show that although the strongest proprietary models achieve the highest factual accuracy, substantial errors remain in visually intricate numerical and temporal contexts. Through quantitative evaluation and expert case studies, FinCriticalED provides a rigorous foundation for advancing visual factual precision in financial and other precision critical domains.

</details>


### [18] [CKDA: Cross-modality Knowledge Disentanglement and Alignment for Visible-Infrared Lifelong Person Re-identification](https://arxiv.org/abs/2511.15016)
*Zhenyu Cui,Jiahuan Zhou,Yuxin Peng*

Main category: cs.CV

TL;DR: 本文提出CKDA方法，解决了跨模态知识冲突问题，通过解耦和对齐模态知识，提升了可见-红外终生行人重识别的性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统跨模态知识蒸馏方法中知识冲突导致的协作遗忘问题。

Method: 提出了模态共通提示(MCP)模块和模态特定提示(MSP)模块来解耦知识，同时设计了跨模态知识对齐(CKA)模块，实现新旧知识的平衡对齐。

Result: 在四个基准数据集上进行的广泛实验展示了CKDA方法的有效性和优越性。

Conclusion: CKDA方法在可见与红外模态之间有效解耦与对齐知识，验证了其在多项基准数据集上的有效性和优越性。

Abstract: Lifelong person Re-IDentification (LReID) aims to match the same person employing continuously collected individual data from different scenarios. To achieve continuous all-day person matching across day and night, Visible-Infrared Lifelong person Re-IDentification (VI-LReID) focuses on sequential training on data from visible and infrared modalities and pursues average performance over all data. To this end, existing methods typically exploit cross-modal knowledge distillation to alleviate the catastrophic forgetting of old knowledge. However, these methods ignore the mutual interference of modality-specific knowledge acquisition and modality-common knowledge anti-forgetting, where conflicting knowledge leads to collaborative forgetting. To address the above problems, this paper proposes a Cross-modality Knowledge Disentanglement and Alignment method, called CKDA, which explicitly separates and preserves modality-specific knowledge and modality-common knowledge in a balanced way. Specifically, a Modality-Common Prompting (MCP) module and a Modality-Specific Prompting (MSP) module are proposed to explicitly disentangle and purify discriminative information that coexists and is specific to different modalities, avoiding the mutual interference between both knowledge. In addition, a Cross-modal Knowledge Alignment (CKA) module is designed to further align the disentangled new knowledge with the old one in two mutually independent inter- and intra-modality feature spaces based on dual-modality prototypes in a balanced manner. Extensive experiments on four benchmark datasets verify the effectiveness and superiority of our CKDA against state-of-the-art methods. The source code of this paper is available at https://github.com/PKU-ICST-MIPL/CKDA-AAAI2026.

</details>


### [19] [Complex-Valued 2D Gaussian Representation for Computer-Generated Holography](https://arxiv.org/abs/2511.15022)
*Yicheng Zhan,Xiangjun Gao,Long Quan,Kaan Akşit*

Main category: cs.CV

TL;DR: 提出了一种新型全息图表示，优化了存储和计算效率，并增强了重建质量。


<details>
  <summary>Details</summary>
Motivation: 为了提高全息图生成的效率，并解决现有方法中存在的参数搜索空间大和噪声伪影问题。

Method: 开发了一种可微分光栅化器，并与GPU优化的光传播内核集成，以实现端到端训练。

Result: 实验表明，我们的方法在显存使用上降低了2.5倍，优化速度提高了50%，并且重建质量优于现有方法。

Conclusion: 我们的方法通过引入基于结构复杂值的二维高斯原语的新型全息图表示，显著提高了全息图生成的效率和效果。

Abstract: We propose a new hologram representation based on structured complex-valued 2D Gaussian primitives, which replaces per-pixel information storage and reduces the parameter search space by up to 10:1. To enable end-to-end training, we develop a differentiable rasterizer for our representation, integrated with a GPU-optimized light propagation kernel in free space. Our extensive experiments show that our method achieves up to 2.5x lower VRAM usage and 50% faster optimization while producing higher-fidelity reconstructions than existing methods. We further introduce a conversion procedure that adapts our representation to practical hologram formats, including smooth and random phase-only holograms. Our experiments show that this procedure can effectively suppress noise artifacts observed in previous methods. By reducing the hologram parameter search space, our representation enables a more scalable hologram estimation in the next-generation computer-generated holography systems.

</details>


### [20] [Computer Vision Modeling of the Development of Geometric and Numerical Concepts in Humans](https://arxiv.org/abs/2511.15029)
*Zekun Wang,Sashank Varma*

Main category: cs.CV

TL;DR: 计算机视觉模型在数学理解发展的研究中展示了潜力，并与儿童的发展过程存在某种程度的一致性。


<details>
  <summary>Details</summary>
Motivation: 探讨计算机视觉模型是否在训练中表现出与儿童发展进程的对应性。

Method: 详细案例研究，分析ResNet-50模型的性能改进。

Result: 某些几何和拓扑类概念的开发与儿童的认知发展一致，而数字方面则表现出类似于人类的"心理数字线"的形成。

Conclusion: 计算机视觉模型在几何和数值概念的理解发展上与儿童的发展进程存在一致性。

Abstract: Mathematical thinking is a fundamental aspect of human cognition. Cognitive scientists have investigated the mechanisms that underlie our ability to thinking geometrically and numerically, to take two prominent examples, and developmental scientists have documented the trajectories of these abilities over the lifespan. Prior research has shown that computer vision (CV) models trained on the unrelated task of image classification nevertheless learn latent representations of geometric and numerical concepts similar to those of adults. Building on this demonstrated cognitive alignment, the current study investigates whether CV models also show developmental alignment: whether their performance improvements across training to match the developmental progressions observed in children. In a detailed case study of the ResNet-50 model, we show that this is the case. For the case of geometry and topology, we find developmental alignment for some classes of concepts (Euclidean Geometry, Geometrical Figures, Metric Properties, Topology) but not others (Chiral Figures, Geometric Transformations, Symmetrical Figures). For the case of number, we find developmental alignment in the emergence of a human-like ``mental number line'' representation with experience. These findings show the promise of computer vision models for understanding the development of mathematical understanding in humans. They point the way to future research exploring additional model architectures and building larger benchmarks.

</details>


### [21] [UniHOI: Unified Human-Object Interaction Understanding via Unified Token Space](https://arxiv.org/abs/2511.15046)
*Panqi Yang,Haodong Jing,Nanning Zheng,Yongqiang Ma*

Main category: cs.CV

TL;DR: UniHOI通过统一模型提升了HOI检测和生成的表现，显著提高了两项任务的准确性和交互能力。


<details>
  <summary>Details</summary>
Motivation: 解决HOI检测和生成任务分开处理所带来的理解障碍，通过知识共享和增强推广能力促进全面的交互理解。

Method: 提出一种统一的跨模态模型，将HOI检测和生成任务结合，通过对称的交互感知注意力模块和统一的半监督学习范式实现双向映射。

Result: 在长尾HOI检测中，准确率提高了4.9%；在开放词汇生成任务中，交互指标提升了42.0%。

Conclusion: UniHOI在HOI检测和生成任务中均取得了最先进的性能，显著提高了检测的准确率和生成任务的交互指标。

Abstract: In the field of human-object interaction (HOI), detection and generation are two dual tasks that have traditionally been addressed separately, hindering the development of comprehensive interaction understanding. To address this, we propose UniHOI, which jointly models HOI detection and generation via a unified token space, thereby effectively promoting knowledge sharing and enhancing generalization. Specifically, we introduce a symmetric interaction-aware attention module and a unified semi-supervised learning paradigm, enabling effective bidirectional mapping between images and interaction semantics even under limited annotations. Extensive experiments demonstrate that UniHOI achieves state-of-the-art performance in both HOI detection and generation. Specifically, UniHOI improves accuracy by 4.9% on long-tailed HOI detection and boosts interaction metrics by 42.0% on open-vocabulary generation tasks.

</details>


### [22] [Hyperspectral Super-Resolution with Inter-Image Variability via Degradation-based Low-Rank and Residual Fusion Method](https://arxiv.org/abs/2511.15052)
*Yue Wen,Kunjing Yang,Minru Bai*

Main category: cs.CV

TL;DR: 提出的DLRRF模型通过低秩和残差分解以及隐式正则化，有效应对HSI与MSI之间的图像间变异性，显著提升融合性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过对图像进行直接变换来处理图像间变异性，可能加剧融合模型的病态性，因此需要新的方法来应对这种挑战。

Method: 通过近端交替优化(PAO)算法在Plug-and-Play(PnP)框架内解决DLRRF模型，使用外部去噪器处理隐式正则化子问题。

Result: 通过将光谱变化建模为光谱降解算子的变化，并将目标HSI分解为低秩和残差组件来恢复因空间局部变化造成的丢失空间细节。

Conclusion: DLRRF模型在融合具有图像间变异性的HSI和MSI时表现出优越的性能。

Abstract: The fusion of hyperspectral image (HSI) with multispectral image (MSI) provides an effective way to enhance the spatial resolution of HSI. However, due to different acquisition conditions, there may exist spectral variability and spatially localized changes between HSI and MSI, referred to as inter-image variability, which can significantly affect the fusion performance. Existing methods typically handle inter-image variability by applying direct transformations to the images themselves, which can exacerbate the ill-posedness of the fusion model. To address this challenge, we propose a Degradation-based Low-Rank and Residual Fusion (DLRRF) model. First, we model the spectral variability as change in the spectral degradation operator. Second, to recover the lost spatial details caused by spatially localized changes, we decompose the target HSI into low rank and residual components, where the latter is used to capture the lost details. By exploiting the spectral correlation within the images, we perform dimensionality reduction on both components. Additionally, we introduce an implicit regularizer to utilize the spatial prior information from the images. The proposed DLRRF model is solved using the Proximal Alternating Optimization (PAO) algorithm within a Plug-and-Play (PnP) framework, where the subproblem regarding implicit regularizer is addressed by an external denoiser. We further provide a comprehensive convergence analysis of the algorithm. Finally, extensive numerical experiments demonstrate that DLRRF achieves superior performance in fusing HSI and MSI with inter-image variability.

</details>


### [23] [CellGenNet: A Knowledge-Distilled Framework for Robust Cell Segmentation in Cancer Tissues](https://arxiv.org/abs/2511.15054)
*Srijan Ray,Bikesh K. Nirala,Jason T. Yustein,Sundaresh Ram*

Main category: cs.CV

TL;DR: CellGenNet是一个基于知识蒸馏的细胞分割框架，通过教师-学生架构和混合损失函数优化，提高了显微镜全切片图像中的核分割准确性。


<details>
  <summary>Details</summary>
Motivation: 针对显微镜全切片图像（WSIs）中核分割的准确性挑战，尤其是在染色、成像条件和组织形态变化大的情况下，提出了一种新方法。

Method: 采用学生-教师架构的知识蒸馏框架，通过稀疏标注训练教师，为未标注区域生成软伪标签，学生采用混合损失函数优化。

Result: 在不同癌症组织的WSIs实验中，CellGenNet相较于监督和半监督基线方法提升了分割准确性。

Conclusion: CellGenNet在不同癌症组织的全切片图像中提高了细胞分割准确性和泛化能力，支持了可扩展和可重现的组织病理分析。

Abstract: Accurate nuclei segmentation in microscopy whole slide images (WSIs) remains challenging due to variability in staining, imaging conditions, and tissue morphology. We propose CellGenNet, a knowledge distillation framework for robust cross-tissue cell segmentation under limited supervision. CellGenNet adopts a student-teacher architecture, where a capacity teacher is trained on sparse annotations and generates soft pseudo-labels for unlabeled regions. The student is optimized using a joint objective that integrates ground-truth labels, teacher-derived probabilistic targets, and a hybrid loss function combining binary cross-entropy and Tversky loss, enabling asymmetric penalties to mitigate class imbalance and better preserve minority nuclear structures. Consistency regularization and layerwise dropout further stabilize feature representations and promote reliable feature transfer. Experiments across diverse cancer tissue WSIs show that CellGenNet improves segmentation accuracy and generalization over supervised and semi-supervised baselines, supporting scalable and reproducible histopathology analysis.

</details>


### [24] [ProPL: Universal Semi-Supervised Ultrasound Image Segmentation via Prompt-Guided Pseudo-Labeling](https://arxiv.org/abs/2511.15057)
*Yaxiong Chen,Qicong Wang,Chunlei Li,Jingliang Hu,Yilei Shi,Shengwu Xiong,Xiao Xiang Zhu,Lichao Mou*

Main category: cs.CV

TL;DR: ProPL is a novel framework for universal semi-supervised ultrasound image segmentation that outperforms existing solutions by effectively utilizing labeled and unlabeled data.


<details>
  <summary>Details</summary>
Motivation: Existing ultrasound image segmentation methods are limited to specific structures, which reduces their applicability in clinical settings. Hence, there is a need for a universal approach that can handle multiple organs and tasks.

Method: ProPL utilizes a shared vision encoder with prompt-guided dual decoders and an uncertainty-driven pseudo-label calibration module for both flexible task adaptation and self-training.

Result: ProPL introduces a new benchmark for universal semi-supervised ultrasound image segmentation, demonstrating superior performance in extensive experiments on a newly introduced dataset encompassing 5 organs and 8 tasks.

Conclusion: ProPL significantly outperforms existing methods in universal ultrasound image segmentation by effectively utilizing both labeled and unlabeled data across multiple organs and tasks.

Abstract: Existing approaches for the problem of ultrasound image segmentation, whether supervised or semi-supervised, are typically specialized for specific anatomical structures or tasks, limiting their practical utility in clinical settings. In this paper, we pioneer the task of universal semi-supervised ultrasound image segmentation and propose ProPL, a framework that can handle multiple organs and segmentation tasks while leveraging both labeled and unlabeled data. At its core, ProPL employs a shared vision encoder coupled with prompt-guided dual decoders, enabling flexible task adaptation through a prompting-upon-decoding mechanism and reliable self-training via an uncertainty-driven pseudo-label calibration (UPLC) module. To facilitate research in this direction, we introduce a comprehensive ultrasound dataset spanning 5 organs and 8 segmentation tasks. Extensive experiments demonstrate that ProPL outperforms state-of-the-art methods across various metrics, establishing a new benchmark for universal ultrasound image segmentation.

</details>


### [25] [Evaluating Multimodal Large Language Models on Vertically Written Japanese Text](https://arxiv.org/abs/2511.15059)
*Keito Sasagawa,Shuhei Kurita,Daisuke Kawahara*

Main category: cs.CV

TL;DR: 本研究评估了多模态大型语言模型在处理纵向书写日文文本方面的能力，发现其性能较差，但通过合成的OCR数据集进行训练，能够改善模型在此任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 作者旨在评估现有多模态大型语言模型在处理日本纵向书写文本方面的能力，因为目前这一领域的研究较为有限。

Method: 本研究生成了一个合成的日文OCR数据集，包括横向和纵向书写的文本，并创建了真实世界文档图像中的纵向书写日文文本的评估数据集。

Result: 评估结果显示，现有的多模态大型语言模型在处理纵向书写的日文时表现不如横向书写文本，但通过训练模型，能够提升其性能。

Conclusion: 现有的多模态大型语言模型在处理纵向书写的日文文本时表现 schlechter，相比于横向书写的日文文本。通过在合成的日文OCR数据集上对模型进行训练，可以提高其对纵向书写文本的处理能力。

Abstract: Multimodal Large Language Models (MLLMs) have seen rapid advances in recent years and are now being applied to visual document understanding tasks. They are expected to process a wide range of document images across languages, including Japanese. Understanding documents from images requires models to read what are written in them. Since some Japanese documents are written vertically, support for vertical writing is essential. However, research specifically focused on vertically written Japanese text remains limited. In this study, we evaluate the reading capability of existing MLLMs on vertically written Japanese text. First, we generate a synthetic Japanese OCR dataset by rendering Japanese texts into images, and use it for both model fine-tuning and evaluation. This dataset includes Japanese text in both horizontal and vertical writing. We also create an evaluation dataset sourced from the real-world document images containing vertically written Japanese text. Using these datasets, we demonstrate that the existing MLLMs perform worse on vertically written Japanese text than on horizontally written Japanese text. Furthermore, we show that training MLLMs on our synthesized Japanese OCR dataset results in improving the performance of models that previously could not handle vertical writing. The datasets and code are publicly available https://github.com/llm-jp/eval_vertical_ja.

</details>


### [26] [Reasoning via Video: The First Evaluation of Video Models' Reasoning Abilities through Maze-Solving Tasks](https://arxiv.org/abs/2511.15065)
*Cheng Yang,Haiyuan Wan,Yiran Peng,Xin Cheng,Zhaoyang Yu,Jiayi Zhang,Junchi Yu,Xinlei Yu,Xiawu Zheng,Dongzhan Zhou,Chenglin Wu*

Main category: cs.CV

TL;DR: 本研究探讨了视频模型在视频生成中进行推理的能力，并提出了VR-Bench基准，结果显示视频模型在空间推理任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 探讨视频模型能否通过视频生成进行推理，尤其是在包含明确空间布局和时间连续性的环境中。

Method: 引入了VR-Bench，一个全面的基准，用于系统评估视频模型的推理能力，并通过迷宫求解任务进行实证分析。

Result: 视频模型在推理时表现出更强的空间感知，超越了领先的视频语言模型，并在不同场景和任务中具有良好的泛化能力，同时发现了测试时间的扩展效应。

Conclusion: 视频模型在空间推理任务中展现了独特潜力，并通过视频生成进行推理。

Abstract: Video Models have achieved remarkable success in high-fidelity video generation with coherent motion dynamics. Analogous to the development from text generation to text-based reasoning in language modeling, the development of video models motivates us to ask: Can video models reason via video generation? Compared with the discrete text corpus, video grounds reasoning in explicit spatial layouts and temporal continuity, which serves as an ideal substrate for spatial reasoning. In this work, we explore the reasoning via video paradigm and introduce VR-Bench -- a comprehensive benchmark designed to systematically evaluate video models' reasoning capabilities. Grounded in maze-solving tasks that inherently require spatial planning and multi-step reasoning, VR-Bench contains 7,920 procedurally generated videos across five maze types and diverse visual styles. Our empirical analysis demonstrates that SFT can efficiently elicit the reasoning ability of video model. Video models exhibit stronger spatial perception during reasoning, outperforming leading VLMs and generalizing well across diverse scenarios, tasks, and levels of complexity. We further discover a test-time scaling effect, where diverse sampling during inference improves reasoning reliability by 10--20%. These findings highlight the unique potential and scalability of reasoning via video for spatial reasoning tasks.

</details>


### [27] [BokehFlow: Depth-Free Controllable Bokeh Rendering via Flow Matching](https://arxiv.org/abs/2511.15066)
*Yachuan Huang,Xianrui Luo,Qiwen Wang,Liao Shen,Jiaqi Li,Huiqiang Sun,Zihao Huang,Wei Jiang,Zhiguo Cao*

Main category: cs.CV

TL;DR: BokehFlow proposes a depth-free method for controllable bokeh rendering, utilizing flow matching and cross-attention for enhanced visual quality and control.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this work is to address the challenges of controllable bokeh rendering without the need for depth inputs, which has been a limitation in both classical and generative approaches.

Method: BokehFlow utilizes flow matching and a cross-attention mechanism to synthesize bokeh effects directly from all-in-focus images and allows for control over focus regions and blur intensity through text prompts.

Result: The framework shows compelling bokeh effects and precise control, surpassing current depth-dependent and generative techniques.

Conclusion: BokehFlow is a novel depth-free framework that effectively simulates controllable bokeh effects, demonstrating superior rendering quality and efficiency compared to existing methods.

Abstract: Bokeh rendering simulates the shallow depth-of-field effect in photography, enhancing visual aesthetics and guiding viewer attention to regions of interest. Although recent approaches perform well, rendering controllable bokeh without additional depth inputs remains a significant challenge. Existing classical and neural controllable methods rely on accurate depth maps, while generative approaches often struggle with limited controllability and efficiency. In this paper, we propose BokehFlow, a depth-free framework for controllable bokeh rendering based on flow matching. BokehFlow directly synthesizes photorealistic bokeh effects from all-in-focus images, eliminating the need for depth inputs. It employs a cross-attention mechanism to enable semantic control over both focus regions and blur intensity via text prompts. To support training and evaluation, we collect and synthesize four datasets. Extensive experiments demonstrate that BokehFlow achieves visually compelling bokeh effects and offers precise control, outperforming existing depth-dependent and generative methods in both rendering quality and efficiency.

</details>


### [28] [MambaTrack3D: A State Space Model Framework for LiDAR-Based Object Tracking under High Temporal Variation](https://arxiv.org/abs/2511.15077)
*Shengjing Tian,Yinan Han,Xiantong Zhao,Xuehu Liu,Qi Lang*

Main category: cs.CV

TL;DR: MambaTrack3D是一种新颖的跟踪框架，通过高效的帧间传播和特征增强，在动态环境中实现了卓越的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 在LiDAR点云中，动态户外环境的高时间变化性给3D单对象跟踪带来了显著挑战，现有跟踪器存在计算复杂、时间冗余和几何先验利用不足等问题。

Method: 采用Mamba状态空间模型，设计了基于Mamba的帧间传播模块和分组特征增强模块，优化了特征提取流程。

Result: MambaTrack3D在KITTI-HTV和nuScenes-HTV基准测试中表现优于传统跟踪器，在标准KITTI数据集上也保持了竞争力，证明其强大的泛化能力。

Conclusion: MambaTrack3D在动态高时间变化环境中实现了优越的准确性和效率平衡，表现出色。

Abstract: Dynamic outdoor environments with high temporal variation (HTV) pose significant challenges for 3D single object tracking in LiDAR point clouds. Existing memory-based trackers often suffer from quadratic computational complexity, temporal redundancy, and insufficient exploitation of geometric priors. To address these issues, we propose MambaTrack3D, a novel HTV-oriented tracking framework built upon the state space model Mamba. Specifically, we design a Mamba-based Inter-frame Propagation (MIP) module that replaces conventional single-frame feature extraction with efficient inter-frame propagation, achieving near-linear complexity while explicitly modeling spatial relations across historical frames. Furthermore, a Grouped Feature Enhancement Module (GFEM) is introduced to separate foreground and background semantics at the channel level, thereby mitigating temporal redundancy in the memory bank. Extensive experiments on KITTI-HTV and nuScenes-HTV benchmarks demonstrate that MambaTrack3D consistently outperforms both HTV-oriented and normal-scenario trackers, achieving improvements of up to 6.5 success and 9.5 precision over HVTrack under moderate temporal gaps. On the standard KITTI dataset, MambaTrack3D remains highly competitive with state-of-the-art normal-scenario trackers, confirming its strong generalization ability. Overall, MambaTrack3D achieves a superior accuracy-efficiency trade-off, delivering robust performance across both specialized HTV and conventional tracking scenarios.

</details>


### [29] [TiCAL:Typicality-Based Consistency-Aware Learning for Multimodal Emotion Recognition](https://arxiv.org/abs/2511.15085)
*Wen Yin,Siyu Zhan,Cencen Liu,Xin Hu,Guiduo Duan,Xiurui Xie,Yuan-Fang Li,Tao He*

Main category: cs.CV

TL;DR: 本文提出了基于典型性的多模态情感识别新框架TiCAL，解决了模态间情感冲突，提升了识别精度。


<details>
  <summary>Details</summary>
Motivation: 针对现有多模态情感识别方法中未能有效处理的模态间情感冲突问题，提出一种新框架，旨在改善模型的情感识别准确性。

Method: 采用典型性估计和伪单模态情感标签评估训练样本的一致性，并在超曲面空间中嵌入特征以捕获情感类别间的细微区别。

Result: 在多个基准数据集（如CMU-MOSEI和MER2023）的广泛实验中，TiCAL显著缓解了模态间的情感冲突，并提高了整体识别准确性，表现出比当前最先进的DMD方法提高约2.6%。

Conclusion: TiCAL框架通过动态评估每个训练样本的一致性和引入超曲面嵌入特征，显著提高了多模态情感识别的性能，特别是在情感模态不一致的样本中。

Abstract: Multimodal Emotion Recognition (MER) aims to accurately identify human emotional states by integrating heterogeneous modalities such as visual, auditory, and textual data. Existing approaches predominantly rely on unified emotion labels to supervise model training, often overlooking a critical challenge: inter-modal emotion conflicts, wherein different modalities within the same sample may express divergent emotional tendencies. In this work, we address this overlooked issue by proposing a novel framework, Typicality-based Consistent-aware Multimodal Emotion Recognition (TiCAL), inspired by the stage-wise nature of human emotion perception. TiCAL dynamically assesses the consistency of each training sample by leveraging pseudo unimodal emotion labels alongside a typicality estimation. To further enhance emotion representation, we embed features in a hyperbolic space, enabling the capture of fine-grained distinctions among emotional categories. By incorporating consistency estimates into the learning process, our method improves model performance, particularly on samples exhibiting high modality inconsistency. Extensive experiments on benchmark datasets, e.g, CMU-MOSEI and MER2023, validate the effectiveness of TiCAL in mitigating inter-modal emotional conflicts and enhancing overall recognition accuracy, e.g., with about 2.6% improvements over the state-of-the-art DMD.

</details>


### [30] [Jointly Conditioned Diffusion Model for Multi-View Pose-Guided Person Image Synthesis](https://arxiv.org/abs/2511.15092)
*Chengyu Xie,Zhi Gong,Junchi Ren,Linkun Yu,Si Shen,Fei Shen,Xiaoyu Du*

Main category: cs.CV

TL;DR: 提出联合条件扩散模型(JCDM)，提升姿态引导的人物图像生成的质量与一致性。


<details>
  <summary>Details</summary>
Motivation: 解决单一参考视图导致的不完整纹理和缺乏明确的跨视图交互问题。

Method: 采用联合条件扩散框架，结合外观先验模块和多视图线索融合机制，进行图像生成。

Result: 实验表明，JCDM在图像真实感和跨视图一致性方面达到了最先进的水平。

Conclusion: JCDM通过利用多视图先验和改进的条件注入机制，提供了在姿态引导的人物图像生成中优越的图像质量与视图一致性。

Abstract: Pose-guided human image generation is limited by incomplete textures from single reference views and the absence of explicit cross-view interaction. We present jointly conditioned diffusion model (JCDM), a jointly conditioned diffusion framework that exploits multi-view priors. The appearance prior module (APM) infers a holistic identity preserving prior from incomplete references, and the joint conditional injection (JCI) mechanism fuses multi-view cues and injects shared conditioning into the denoising backbone to align identity, color, and texture across poses. JCDM supports a variable number of reference views and integrates with standard diffusion backbones with minimal and targeted architectural modifications. Experiments demonstrate state of the art fidelity and cross-view consistency.

</details>


### [31] [Generating Natural-Language Surgical Feedback: From Structured Representation to Domain-Grounded Evaluation](https://arxiv.org/abs/2511.15159)
*Firdavs Nasriddinov,Rafal Kocielnik,Anima Anandkumar,Andrew J. Hung*

Main category: cs.CV

TL;DR: 本研究提出了一种基于IAT结构的自动反馈生成方法，显著提高外科培训反馈的质量和可靠性。


<details>
  <summary>Details</summary>
Motivation: 希望通过自动化反馈增强外科培训的质量和一致性，使其更具及时性和可获得性。

Method: 使用结构感知管道，提取真实反馈中的IAT三元组，并通过条件生成模型进行反馈文本生成。

Result: 基于IAT的反馈生成显著提高了生成文本的合规性和准确性，传统指标也有所改善。

Conclusion: 通过将IAT结构嵌入到生成过程中，我们提高了反馈生成的准确性，提高了其在外科培训中的可审计性。

Abstract: High-quality intraoperative feedback from a surgical trainer is pivotal for improving trainee performance and long-term skill acquisition. Automating natural, trainer-style feedback promises timely, accessible, and consistent guidance at scale but requires models that understand clinically relevant representations. We present a structure-aware pipeline that learns a surgical action ontology from real trainer-to-trainee transcripts (33 surgeries) and uses it to condition feedback generation. We contribute by (1) mining Instrument-Action-Target (IAT) triplets from real-world feedback text and clustering surface forms into normalized categories, (2) fine-tuning a video-to-IAT model that leverages the surgical procedure and task contexts as well as fine-grained temporal instrument motion, and (3) demonstrating how to effectively use IAT triplet representations to guide GPT-4o in generating clinically grounded, trainer-style feedback. We show that, on Task 1: Video-to-IAT recognition, our context injection and temporal tracking deliver consistent AUC gains (Instrument: 0.67 to 0.74; Action: 0.60 to 0.63; Tissue: 0.74 to 0.79). For Task 2: feedback text generation (rated on a 1-5 fidelity rubric where 1 = opposite/unsafe, 3 = admissible, and 5 = perfect match to a human trainer), GPT-4o from video alone scores 2.17, while IAT conditioning reaches 2.44 (+12.4%), doubling the share of admissible generations with score >= 3 from 21% to 42%. Traditional text-similarity metrics also improve: word error rate decreases by 15-31% and ROUGE (phrase/substring overlap) increases by 9-64%. Grounding generation in explicit IAT structure improves fidelity and yields clinician-verifiable rationales, supporting auditable use in surgical training.

</details>


### [32] [A Comprehensive Study on Visual Token Redundancy for Discrete Diffusion-based Multimodal Large Language Models](https://arxiv.org/abs/2511.15098)
*Duo Li,Zuhao Yang,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: 该研究探讨了视觉token冗余如何影响dMLLM的效率，提出了视觉token剪枝与层跳策略对不同dMLLM架构的优化方法，提升了多模态任务的应用前景。


<details>
  <summary>Details</summary>
Motivation: 鉴于现有dMLLM在推理时由于全序列注意力计算而导致的显著计算开销，本研究旨在探索如何通过视觉token冗余的分析及剪枝来优化这一流程。

Method: 通过对不同dMLLM架构和任务中视觉token冗余的综合研究，分析视觉token剪枝对dMLLM响应和效率的影响。

Result: 研究表明，视觉冗余仅在处理长答案任务时才会出现在从零开始的dMLLM中，且视觉token剪枝会导致信息损失，而从零开始的dMLLM可以在后期去噪步骤中逐渐恢复这些信息。同时，分层跳过适用于加速AR到扩散的dMLLM，而渐进式剪枝对从零开始的dMLLM更有效。

Conclusion: 本研究为dMLLMs的效率优化提供了新视角，显著提升了它们在多模态理解任务中的适用性。

Abstract: Discrete diffusion-based multimodal large language models (dMLLMs) have emerged as a promising alternative to autoregressive MLLMs thanks to their advantages in parallel decoding and bidirectional context modeling, but most existing dMLLMs incur significant computational overhead during inference due to the full-sequence attention computation in each denoising step. Pioneer studies attempt to resolve this issue from a modality-agnostic perspective via key-value cache optimization or efficient sampling but most of them overlook modality-specific visual token redundancy. In this work, we conduct a comprehensive study on how visual token redundancy evolves with different dMLLM architectures and tasks and how visual token pruning affects dMLLM responses and efficiency. Specifically, our study reveals that visual redundancy emerges only in from-scratch dMLLMs while handling long-answer tasks. In addition, we validate that visual token pruning introduces non-negligible information loss in dMLLMs and only from-scratch dMLLMs can recover the lost information progressively during late denoising steps. Furthermore, our study shows that layer-skipping is promising for accelerating AR-to-diffusion dMLLMs, whereas progressive or late-step pruning is more effective for from-scratch dMLLMs. Overall, this work offers a new perspective on efficiency optimization for dMLLMs, greatly advancing their applicability across various multimodal understanding tasks.

</details>


### [33] [Gaussian Blending: Rethinking Alpha Blending in 3D Gaussian Splatting](https://arxiv.org/abs/2511.15102)
*Junseo Koo,Jinseo Jeong,Gunhee Kim*

Main category: cs.CV

TL;DR: 本研究提出了一种新的高斯混合技术，能够改善3D高斯喷溅法的渲染质量，有效捕捉在训练中未见的采样率下的细节，并克服视觉伪影。


<details>
  <summary>Details</summary>
Motivation: To overcome visual discrepancies and artifacts in views synthesized at unseen sampling rates by existing 3DGS models, which stem from limitations in alpha blending.

Method: The study proposes a new Gaussian Blending technique that treats alpha and transmittance as spatially varying distributions instead of scalar quantities.

Result: Extensive experiments show that Gaussian Blending significantly enhances detail capture and consistently outperforms current novel view synthesis models across various sampling rates.

Conclusion: Gaussian Blending improves rendering quality in 3D Gaussian Splatting by addressing visual artifacts and enhancing detail capture at various sampling rates.

Abstract: The recent introduction of 3D Gaussian Splatting (3DGS) has significantly advanced novel view synthesis. Several studies have further improved the rendering quality of 3DGS, yet they still exhibit noticeable visual discrepancies when synthesizing views at sampling rates unseen during training. Specifically, they suffer from (i) erosion-induced blurring artifacts when zooming in and (ii) dilation-induced staircase artifacts when zooming out. We speculate that these artifacts arise from the fundamental limitation of the alpha blending adopted in 3DGS methods. Instead of the conventional alpha blending that computes alpha and transmittance as scalar quantities over a pixel, we propose to replace it with our novel Gaussian Blending that treats alpha and transmittance as spatially varying distributions. Thus, transmittances can be updated considering the spatial distribution of alpha values across the pixel area, allowing nearby background splats to contribute to the final rendering. Our Gaussian Blending maintains real-time rendering speed and requires no additional memory cost, while being easily integrated as a drop-in replacement into existing 3DGS-based or other NVS frameworks. Extensive experiments demonstrate that Gaussian Blending effectively captures fine details at various sampling rates unseen during training, consistently outperforming existing novel view synthesis models across both unseen and seen sampling rates.

</details>


### [34] [Unbiased Semantic Decoding with Vision Foundation Models for Few-shot Segmentation](https://arxiv.org/abs/2511.15118)
*Jin Wang,Bingfeng Zhang,Jian Pang,Weifeng Liu,Baodi Liu,Honglong Chen*

Main category: cs.CV

TL;DR: 本研究通过无偏语义解码策略增强 SAM 在少样本分割中的有效性，结合 CLIP 模型设计特征增强策略，提高了模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管 SAM 模型在少样本分割上具有强大的泛化能力，但其高依赖于准确提示的解码过程限制了其在未知类别上的应用。

Method: 通过设计两种特征增强策略结合 CLIP 模型，分别在图像级别和像素级别丰富 SAM 特征，并提出可学习的视觉-文本目标提示生成器。

Result: 通过同时从支持集和查询集中提取目标信息，实现了一致的预测，改善了 SAM 的无偏语义判别能力。

Conclusion: 本研究提出的无偏语义解码策略 (USD) 能有效提高 SAM 在少样本分割任务中的性能，不再依赖于仅从支持集中提取提示。

Abstract: Few-shot segmentation has garnered significant attention. Many recent approaches attempt to introduce the Segment Anything Model (SAM) to handle this task. With the strong generalization ability and rich object-specific extraction ability of the SAM model, such a solution shows great potential in few-shot segmentation. However, the decoding process of SAM highly relies on accurate and explicit prompts, making previous approaches mainly focus on extracting prompts from the support set, which is insufficient to activate the generalization ability of SAM, and this design is easy to result in a biased decoding process when adapting to the unknown classes. In this work, we propose an Unbiased Semantic Decoding (USD) strategy integrated with SAM, which extracts target information from both the support and query set simultaneously to perform consistent predictions guided by the semantics of the Contrastive Language-Image Pre-training (CLIP) model. Specifically, to enhance the unbiased semantic discrimination of SAM, we design two feature enhancement strategies that leverage the semantic alignment capability of CLIP to enrich the original SAM features, mainly including a global supplement at the image level to provide a generalize category indicate with support image and a local guidance at the pixel level to provide a useful target location with query image. Besides, to generate target-focused prompt embeddings, a learnable visual-text target prompt generator is proposed by interacting target text embeddings and clip visual features. Without requiring re-training of the vision foundation models, the features with semantic discrimination draw attention to the target region through the guidance of prompt with rich target information.

</details>


### [35] [WaveFuse-AL: Cyclical and Performance-Adaptive Multi-Strategy Active Learning for Medical Images](https://arxiv.org/abs/2511.15132)
*Nishchala Thakur,Swati Kochhar,Deepti R. Bathula,Sukrit Gupta*

Main category: cs.CV

TL;DR: WaveFuse-AL is a new framework for active learning in medical imaging that improves performance by adaptively combining multiple strategies.


<details>
  <summary>Details</summary>
Motivation: The motivation is to reduce annotation costs in medical imaging by selecting the most informative samples while addressing the inconsistency of individual acquisition strategies.

Method: The paper introduces WaveFuse-AL, which fuses multiple acquisition strategies using cyclical temporal priors and performance-driven adaptation.

Result: WaveFuse-AL outperforms single and alternating strategy baselines on multiple medical imaging benchmarks with significant statistical improvements in performance.

Conclusion: WaveFuse-AL achieves significant performance improvements in medical imaging tasks by adaptively combining multiple acquisition strategies.

Abstract: Active learning reduces annotation costs in medical imaging by strategically selecting the most informative samples for labeling. However, individual acquisition strategies often exhibit inconsistent behavior across different stages of the active learning cycle. We propose Cyclical and Performance-Adaptive Multi-Strategy Active Learning (WaveFuse-AL), a novel framework that adaptively fuses multiple established acquisition strategies-BALD, BADGE, Entropy, and CoreSet throughout the learning process. WaveFuse-AL integrates cyclical (sinusoidal) temporal priors with performance-driven adaptation to dynamically adjust strategy importance over time. We evaluate WaveFuse-AL on three medical imaging benchmarks: APTOS-2019 (multi-class classification), RSNA Pneumonia Detection (binary classification), and ISIC-2018 (skin lesion segmentation). Experimental results demonstrate that WaveFuse-AL consistently outperforms both single-strategy and alternating-strategy baselines, achieving statistically significant performance improvements (on ten out of twelve metric measurements) while maximizing the utility of limited annotation budgets.

</details>


### [36] [DCL-SE: Dynamic Curriculum Learning for Spatiotemporal Encoding of Brain Imaging](https://arxiv.org/abs/2511.15151)
*Meihua Zhou,Xinyu Tong,Jiarui Zhao,Min Cheng,Li Yang,Lei Tian,Nan Wan*

Main category: cs.CV

TL;DR: DCL-SE通过动态课程学习和近似秩池化技术，提升了脑部神经影像分析的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决高维神经影像分析中的时空保真度和模型适应性问题。

Method: 通过动态课程学习和近似秩池化技术，对三维脑部影像数据进行高效编码和解码。

Result: 在六个公开数据集上进行评估时，DCL-SE在准确性、鲁棒性和可解释性方面均优于现有方法。

Conclusion: DCL-SE模型在多个临床应用任务中表现出色，强调了构建紧凑且特定任务架构的重要性。

Abstract: High-dimensional neuroimaging analyses for clinical diagnosis are often constrained by compromises in spatiotemporal fidelity and by the limited adaptability of large-scale, general-purpose models. To address these challenges, we introduce Dynamic Curriculum Learning for Spatiotemporal Encoding (DCL-SE), an end-to-end framework centered on data-driven spatiotemporal encoding (DaSE). We leverage Approximate Rank Pooling (ARP) to efficiently encode three-dimensional volumetric brain data into information-rich, two-dimensional dynamic representations, and then employ a dynamic curriculum learning strategy, guided by a Dynamic Group Mechanism (DGM), to progressively train the decoder, refining feature extraction from global anatomical structures to fine pathological details. Evaluated across six publicly available datasets, including Alzheimer's disease and brain tumor classification, cerebral artery segmentation, and brain age prediction, DCL-SE consistently outperforms existing methods in accuracy, robustness, and interpretability. These findings underscore the critical importance of compact, task-specific architectures in the era of large-scale pretrained networks.

</details>


### [37] [SceneEdited: A City-Scale Benchmark for 3D HD Map Updating via Image-Guided Change Detection](https://arxiv.org/abs/2511.15153)
*Chun-Jung Lin,Tat-Jun Chin,Sourav Garg,Feras Dayoub*

Main category: cs.CV

TL;DR: 本文引入SceneEdited数据集，旨在通过3D点云更新技术改善高精度地图的维护，为相关研究提供标准化基准。


<details>
  <summary>Details</summary>
Motivation: 随着城市环境的快速变化，更新高精度地图变得迫在眉睫，现有的2D图像变化检测方法无法有效更新3D地图，存在明显的研究空白。

Method: 通过创建包含RGB图像、LiDAR扫描和详细变化掩膜的场景数据集，以及基于图像的运动结构更新方法，进行数据集的维护和3D地图更新。

Result: SceneEdited数据集包含超过800个更新场景和23000个合成对象变化，为高精度地图的检测和更新提供了丰富的数据基础。

Conclusion: 该研究提出了SceneEdited数据集，为高精度地图维护和3D点云更新提供了标准基准，有助于未来的研究和应用。

Abstract: Accurate, up-to-date High-Definition (HD) maps are critical for urban planning, infrastructure monitoring, and autonomous navigation. However, these maps quickly become outdated as environments evolve, creating a need for robust methods that not only detect changes but also incorporate them into updated 3D representations. While change detection techniques have advanced significantly, there remains a clear gap between detecting changes and actually updating 3D maps, particularly when relying on 2D image-based change detection. To address this gap, we introduce SceneEdited, the first city-scale dataset explicitly designed to support research on HD map maintenance through 3D point cloud updating. SceneEdited contains over 800 up-to-date scenes covering 73 km of driving and approximate 3 $\text{km}^2$ of urban area, with more than 23,000 synthesized object changes created both manually and automatically across 2000+ out-of-date versions, simulating realistic urban modifications such as missing roadside infrastructure, buildings, overpasses, and utility poles. Each scene includes calibrated RGB images, LiDAR scans, and detailed change masks for training and evaluation. We also provide baseline methods using a foundational image-based structure-from-motion pipeline for updating outdated scenes, as well as a comprehensive toolkit supporting scalability, trackability, and portability for future dataset expansion and unification of out-of-date object annotations. Both the dataset and the toolkit are publicly available at https://github.com/ChadLin9596/ScenePoint-ETK, establising a standardized benchmark for 3D map updating research.

</details>


### [38] [Multimodal Continual Instruction Tuning with Dynamic Gradient Guidance](https://arxiv.org/abs/2511.15164)
*Songze Li,Mingyu Gao,Tonghua Su,Xu-Yao Zhang,Zhongjie Wang*

Main category: cs.CV

TL;DR: 本研究提出了一种新的方法，通过几何属性近似梯度，成功解决了多模态连续学习中的灾难性遗忘问题，同时不扩展模型。


<details>
  <summary>Details</summary>
Motivation: 传统的多模态大型语言模型在任务学习中面临灾难性遗忘的问题，本研究旨在通过新的视角来解决这一挑战。

Method: 通过近似失去的梯度，并使用与先前最优参数之间的方向向量作为指导，与真实梯度结合，并采用伯努利抽样策略来调控模型稳定性与可塑性。

Result: 通过广泛的实验，验证了所提方法在没有扩展模型的情况下，成功缓解灾难性遗忘，保持了紧凑的模型架构，并取得了最佳性能。

Conclusion: 本研究提出了一种新颖的方法来解决多模态连续学习中的灾难性遗忘问题，通过在模型参数空间中利用几何特性进行梯度指导，有效提高了任务学习的性能。

Abstract: Multimodal continual instruction tuning enables multimodal large language models to sequentially adapt to new tasks while building upon previously acquired knowledge. However, this continual learning paradigm faces the significant challenge of catastrophic forgetting, where learning new tasks leads to performance degradation on previous ones. In this paper, we introduce a novel insight into catastrophic forgetting by conceptualizing it as a problem of missing gradients from old tasks during new task learning. Our approach approximates these missing gradients by leveraging the geometric properties of the parameter space, specifically using the directional vector between current parameters and previously optimal parameters as gradient guidance. This approximated gradient can be further integrated with real gradients from a limited replay buffer and regulated by a Bernoulli sampling strategy that dynamically balances model stability and plasticity. Extensive experiments on multimodal continual instruction tuning datasets demonstrate that our method achieves state-of-the-art performance without model expansion, effectively mitigating catastrophic forgetting while maintaining a compact architecture.

</details>


### [39] [Learning Depth from Past Selves: Self-Evolution Contrast for Robust Depth Estimation](https://arxiv.org/abs/2511.15167)
*Jing Cao,Kui Jiang,Shenyi Li,Xiaocheng Feng,Yong Huang*

Main category: cs.CV

TL;DR: 本研究提出了一种新的自演化对比学习框架SEC-Depth，旨在提高自监督深度估计在恶劣天气下的鲁棒性，实验结果表明方法有效。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有自监督深度估计方法在恶劣天气条件下性能降低的问题。

Method: 提出了一种动态更新延迟模型的战略，通过自演化对比损失函数来实现深度估计。

Result: 实验表明，该方法在零-shot评估中显著增强了鲁棒性，并能与多种基础模型无缝集成。

Conclusion: 我们的SEC-Depth框架有效提高了自监督深度估计在恶劣天气条件下的鲁棒性，减少了性能损失。

Abstract: Self-supervised depth estimation has gained significant attention in autonomous driving and robotics. However, existing methods exhibit substantial performance degradation under adverse weather conditions such as rain and fog, where reduced visibility critically impairs depth prediction. To address this issue, we propose a novel self-evolution contrastive learning framework called SEC-Depth for self-supervised robust depth estimation tasks. Our approach leverages intermediate parameters generated during training to construct temporally evolving latency models. Using these, we design a self-evolution contrastive scheme to mitigate performance loss under challenging conditions. Concretely, we first design a dynamic update strategy of latency models for the depth estimation task to capture optimization states across training stages. To effectively leverage latency models, we introduce a self-evolution contrastive Loss (SECL) that treats outputs from historical latency models as negative samples. This mechanism adaptively adjusts learning objectives while implicitly sensing weather degradation severity, reducing the needs for manual intervention. Experiments show that our method integrates seamlessly into diverse baseline models and significantly enhances robustness in zero-shot evaluations.

</details>


### [40] [MMCM: Multimodality-aware Metric using Clustering-based Modes for Probabilistic Human Motion Prediction](https://arxiv.org/abs/2511.15179)
*Kyotaro Tokoro,Hiromu Taketsugu,Norimichi Ukita*

Main category: cs.CV

TL;DR: 本论文提出了一种新的评估人类运动预测的方法MMCM，专注于预测运动的多样性和动力学有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的评估标准无法有效区分多模态预测的质量，尤其是在覆盖和有效性方面，因此需要开发一种新度量来解决这些问题。

Method: 提出了一种基于聚类的多模态度量（MMCM），用于评估预测运动的覆盖性和有效性。

Result: MMCM通过聚类分析运动空间，确保预测的运动分布于多个模式中，并验证了其在评估多模态预测中的有效性。

Conclusion: 提出的MMCM度量能够有效评估人类运动预测中的多模态特性，确保预测的运动不仅覆盖多种可能性，而且在动力学上有效。

Abstract: This paper proposes a novel metric for Human Motion Prediction (HMP). Since a single past sequence can lead to multiple possible futures, a probabilistic HMP method predicts such multiple motions. While a single motion predicted by a deterministic method is evaluated only with the difference from its ground truth motion, multiple predicted motions should also be evaluated based on their distribution. For this evaluation, this paper focuses on the following two criteria. \textbf{(a) Coverage}: motions should be distributed among multiple motion modes to cover diverse possibilities. \textbf{(b) Validity}: motions should be kinematically valid as future motions observable from a given past motion. However, existing metrics simply appreciate widely distributed motions even if these motions are observed in a single mode and kinematically invalid. To resolve these disadvantages, this paper proposes a Multimodality-aware Metric using Clustering-based Modes (MMCM). For (a) coverage, MMCM divides a motion space into several clusters, each of which is regarded as a mode. These modes are used to explicitly evaluate whether predicted motions are distributed among multiple modes. For (b) validity, MMCM identifies valid modes by collecting possible future motions from a motion dataset. Our experiments validate that our clustering yields sensible mode definitions and that MMCM accurately scores multimodal predictions. Code: https://github.com/placerkyo/MMCM

</details>


### [41] [Instruction-Guided Lesion Segmentation for Chest X-rays with Automatically Generated Large-Scale Dataset](https://arxiv.org/abs/2511.15186)
*Geon Choi,Hangyul Yoon,Hyunju Shin,Hyunki Park,Sang Hoon Seo,Eunho Yang,Edward Choi*

Main category: cs.CV

TL;DR: 本研究提出了一种新的指令引导病灶分割（ILS）方法，开发了MIMIC-ILS数据集和ROSALIA模型，显著提升了胸部X光图像的病灶分割和解释能力。


<details>
  <summary>Details</summary>
Motivation: 当前的病灶分割模型在胸部X光图像中的适用性受限于目标标签数量少和依赖长篇的专家输入，急需更方便的分割方法。

Method: 构建MIMIC-ILS数据集，使用自动化的多模态管道从胸部X光图像及其报告生成注释，并引入ROSALIA模型进行病灶分割和文本生成。

Result: MIMIC-ILS包含110万个指令-答案对，覆盖主要病灶类型，通过精细调整的ROSALIA模型展现出高效的病灶分割和文本生成能力。

Conclusion: MIMIC-ILS和ROSALIA模型展示了通过用户友好的指令进行胸部X光图像病灶分割的有效性，具有较高的分割准确性和文本解释能力。

Abstract: The applicability of current lesion segmentation models for chest X-rays (CXRs) has been limited both by a small number of target labels and the reliance on long, detailed expert-level text inputs, creating a barrier to practical use. To address these limitations, we introduce a new paradigm: instruction-guided lesion segmentation (ILS), which is designed to segment diverse lesion types based on simple, user-friendly instructions. Under this paradigm, we construct MIMIC-ILS, the first large-scale instruction-answer dataset for CXR lesion segmentation, using our fully automated multimodal pipeline that generates annotations from chest X-ray images and their corresponding reports. MIMIC-ILS contains 1.1M instruction-answer pairs derived from 192K images and 91K unique segmentation masks, covering seven major lesion types. To empirically demonstrate its utility, we introduce ROSALIA, a vision-language model fine-tuned on MIMIC-ILS. ROSALIA can segment diverse lesions and provide textual explanations in response to user instructions. The model achieves high segmentation and textual accuracy in our newly proposed task, highlighting the effectiveness of our pipeline and the value of MIMIC-ILS as a foundational resource for pixel-level CXR lesion grounding.

</details>


### [42] [BrainRotViT: Transformer-ResNet Hybrid for Explainable Modeling of Brain Aging from 3D sMRI](https://arxiv.org/abs/2511.15188)
*Wasif Jalal,Md Nafiu Rahman,M. Sohel Rahman*

Main category: cs.CV

TL;DR: 本文提出了一种新的脑龄估计方法BrainRotViT，结合了视觉变压器与残差CNN，通过有效的特征学习与回归实现了优异的预测性能，并在多个队列中验证了其泛化能力，揭示了与衰老相关的脑结构变化。


<details>
  <summary>Details</summary>
Motivation: 准确的脑龄估计是研究衰老和神经退行性病变的重要生物标志，但传统方法面临诸多限制，包括手动特征工程、有限的感受野及在异质数据上的过拟合。

Method: 提出Brain ResNet通过训练的视觉变压器（BrainRotViT），结合视觉变压器的全局上下文建模与残差CNN的局部细化，采用ViT编码器先在辅助年龄和性别分类任务上进行训练，然后将编码器应用于切片生成2D嵌入向量矩阵，最后由残差CNN回归器结合性别信息进行脑龄估计。

Result: 在十一种MRI数据集的验证中，该方法实现了平均绝对误差3.34年，并在四个独立队列中展示了良好的泛化能力，平均绝对误差在3.77到5.04年之间。此外，年龄差距的分析显示与阿尔茨海默病、认知障碍和自闭症谱系障碍相关的衰老模式。模型注意力图突显出与衰老相关的脑区。

Conclusion: 该方法提供了一种高效、可解释且具有良好泛化能力的脑龄预测框架，弥合了CNN和变压器方法之间的差距，为衰老和神经退行性研究开辟了新途径。

Abstract: Accurate brain age estimation from structural MRI is a valuable biomarker for studying aging and neurodegeneration. Traditional regression and CNN-based methods face limitations such as manual feature engineering, limited receptive fields, and overfitting on heterogeneous data. Pure transformer models, while effective, require large datasets and high computational cost. We propose Brain ResNet over trained Vision Transformer (BrainRotViT), a hybrid architecture that combines the global context modeling of vision transformers (ViT) with the local refinement of residual CNNs. A ViT encoder is first trained on an auxiliary age and sex classification task to learn slice-level features. The frozen encoder is then applied to all sagittal slices to generate a 2D matrix of embedding vectors, which is fed into a residual CNN regressor that incorporates subject sex at the final fully-connected layer to estimate continuous brain age. Our method achieves an MAE of 3.34 years (Pearson $r=0.98$, Spearman $ρ=0.97$, $R^2=0.95$) on validation across 11 MRI datasets encompassing more than 130 acquisition sites, outperforming baseline and state-of-the-art models. It also generalizes well across 4 independent cohorts with MAEs between 3.77 and 5.04 years. Analyses on the brain age gap (the difference between the predicted age and actual age) show that aging patterns are associated with Alzheimer's disease, cognitive impairment, and autism spectrum disorder. Model attention maps highlight aging-associated regions of the brain, notably the cerebellar vermis, precentral and postcentral gyri, temporal lobes, and medial superior frontal gyrus. Our results demonstrate that this method provides an efficient, interpretable, and generalizable framework for brain-age prediction, bridging the gap between CNN- and transformer-based approaches while opening new avenues for aging and neurodegeneration research.

</details>


### [43] [Insert In Style: A Zero-Shot Generative Framework for Harmonious Cross-Domain Object Composition](https://arxiv.org/abs/2511.15197)
*Raghu Vamsi Chittersu,Yuvraj Singh Rathore,Pranav Adlinge,Kunal Swami*

Main category: cs.CV

TL;DR: 我们提出了Insert In Style，一个实用且高保真的零-shot生成框架，通过创新的训练协议和掩蔽注意力架构提升了对象组合的表现。


<details>
  <summary>Details</summary>
Motivation: 解决将现实世界对象插入风格化领域时参考基础对象组合方法失效的问题。

Method: 提出了一种统一框架，包含多阶段训练协议和专门的掩蔽注意力架构，以实现身份、风格和组合的解耦。

Result: 我们的模型在身份和风格指标上表现出国家级性能，超越了现有方法，并引入了新的公共基准。

Conclusion: 我们的框架在身份和风格指标上显著优于现有方法，并通过用户研究得到了强有力的证实。

Abstract: Reference-based object composition methods fail when inserting real-world objects into stylized domains. This under-explored problem is currently split between practical "blenders" that lack generative fidelity and "generators" that require impractical, per-subject online finetuning. In this work, we introduce Insert In Style, the first zero-shot generative framework that is both practical and high-fidelity. Our core contribution is a unified framework with two key innovations: (i) a novel multi-stage training protocol that disentangles representations for identity, style, and composition, and (ii) a specialized masked-attention architecture that surgically enforces this disentanglement during generation. This approach prevents the concept interference common in general-purpose, unified-attention models. Our framework is trained on a new 100k sample dataset, curated from a novel data pipeline. This pipeline couples large-scale generation with a rigorous, two-stage filtering process to ensure both high-fidelity semantic identity and style coherence. Unlike prior work, our model is truly zero-shot and requires no text prompts. We also introduce a new public benchmark for stylized composition. We demonstrate state-of-the-art performance, significantly outperforming existing methods on both identity and style metrics, a result strongly corroborated by user studies.

</details>


### [44] [Physics-Based Benchmarking Metrics for Multimodal Synthetic Images](https://arxiv.org/abs/2511.15204)
*Kishor Datta Gupta,Marufa Kamal,Md. Mahfuzur Rahman,Fahad Rahman,Mohd Ariful Haque,Sunzida Siddique*

Main category: cs.CV

TL;DR: 提出一种结合大语言模型与多模态数据的新评估指标PCMDE，以解决现有度量的局限性，提升语义与结构准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有度量指标在语义或结构准确性捕捉上的局限性，尤其是在特定领域或上下文相关的场景中。

Method: 结合大语言模型与推理、知识映射和视觉-语言模型，采用三阶段架构进行特征提取、组件融合和物理引导推理。

Result: PCMDE度量在提高评估准确性方面表现良好，尤其是在涉及空间和语义信息的复杂任务中。

Conclusion: 提出的PCMDE度量有效解决了现有评估指标在特定领域或依赖上下文场景中的不足。

Abstract: Current state of the art measures like BLEU, CIDEr, VQA score, SigLIP-2 and CLIPScore are often unable to capture semantic or structural accuracy, especially for domain-specific or context-dependent scenarios. For this, this paper proposes a Physics-Constrained Multimodal Data Evaluation (PCMDE) metric combining large language models with reasoning, knowledge based mapping and vision-language models to overcome these limitations. The architecture is comprised of three main stages: (1) feature extraction of spatial and semantic information with multimodal features through object detection and VLMs; (2) Confidence-Weighted Component Fusion for adaptive component-level validation; and (3) physics-guided reasoning using large language models for structural and relational constraints (e.g., alignment, position, consistency) enforcement.

</details>


### [45] [SkinGPT-R1: Adapter-Only Dual Distillation for Efficient Dermatology Reasoning](https://arxiv.org/abs/2511.15242)
*Yuhao Shen,Jiahe Qian,Zhangtianyi Chen,Yuanhao He,Juexiao Zhou*

Main category: cs.CV

TL;DR: SkinGPT-R1, a dermatology vision language model, outperforms competitors in diagnostic reasoning and accuracy, supported by the novel DermCoT corpus.


<details>
  <summary>Details</summary>
Motivation: To enhance diagnostic accuracy and reasoning in dermatology through explicit and verifiable thought processes in a vision language model.

Method: Development of a dermatology-focused vision language model (SkinGPT-R1) supported by a specialized corpus (DermCoT) for standardized reasoning narratives.

Result: SkinGPT-R1 ranks first on the DermBench benchmark with an average score of 4.031/5 and shows consistent accuracy improvements over the baseline model (Vision-R1).

Conclusion: SkinGPT-R1 is a superior vision language model for dermatology, demonstrating significant improvements in diagnostic reasoning and performance benchmarks compared to existing models, particularly Vision-R1.

Abstract: We present SkinGPT-R1, a dermatology focused vision language model that makes diagnostic chain of thought reasoning explicit, step by step, and verifiable. To support skin specific reasoning, we build DermCoT, a corpus of standardized dermatologic chain of thought narratives that combines 10,000 DermEval filtered training cases with 3,000 dermatologist scored certified cases, and we define DermEval as a physician aligned six dimensional evaluator and DermBench as the corresponding benchmark for dermatologic chain of thought quality. On DermBench, across 14 general, reasoning, and medical vision language models, SkinGPT-R1 achieves an average score of 4.031 out of 5 over the six clinician defined dimensions, ranks 1st among all systems, and improves the average score over Vision-R1 by about 41%. On three dermatology classification benchmarks, SkinGPT-R1 delivers stable accuracy gains over Vision-R1 and remains competitive among strong vision language models. Ablation results further show that DermCoT based chain of thought supervision provides substantial improvements over the base model and that adding dermatology aware visual distillation yields consistent additional gains in both narrative quality and recognition.

</details>


### [46] [SplitFlux: Learning to Decouple Content and Style from a Single Image](https://arxiv.org/abs/2511.15258)
*Yitong Yang,Yinglin Wang,Changshuo Wang,Yongjun Zhang,Ziyang Chen,Shuting He*

Main category: cs.CV

TL;DR: SplitFlux effectively disentangles content and style in image generation, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: To enhance customized image generation by effectively separating image content and style.

Method: Utilizes fine-tuning of single dream blocks via LoRA with Rank-Constrained Adaptation and Visual-Gated LoRA.

Result: SplitFlux achieves superior performance in content preservation and style generation across various scenarios.

Conclusion: SplitFlux consistently outperform existing methods, ensuring better content preservation and stylization.

Abstract: Disentangling image content and style is essential for customized image generation. Existing SDXL-based methods struggle to achieve high-quality results, while the recently proposed Flux model fails to achieve effective content-style separation due to its underexplored characteristics. To address these challenges, we conduct a systematic analysis of Flux and make two key observations: (1) Single Dream Blocks are essential for image generation; and (2) Early single stream blocks mainly control content, whereas later blocks govern style. Based on these insights, we propose SplitFlux, which disentangles content and style by fine-tuning the single dream blocks via LoRA, enabling the disentangled content to be re-embedded into new contexts. It includes two key components: (1) Rank-Constrained Adaptation. To preserve content identity and structure, we compress the rank and amplify the magnitude of updates within specific blocks, preventing content leakage into style blocks. (2) Visual-Gated LoRA. We split the content LoRA into two branches with different ranks, guided by image saliency. The high-rank branch preserves primary subject information, while the low-rank branch encodes residual details, mitigating content overfitting and enabling seamless re-embedding. Extensive experiments demonstrate that SplitFlux consistently outperforms state-of-the-art methods, achieving superior content preservation and stylization quality across diverse scenarios.

</details>


### [47] [Taming Generative Synthetic Data for X-ray Prohibited Item Detection](https://arxiv.org/abs/2511.15299)
*Jialong Sun,Hongguang Zhu,Weizhe Liu,Yunda Sun,Renshuai Tao,Yunchao Wei*

Main category: cs.CV

TL;DR: 提出了一种高效的一阶段X射线安全图像合成方法，改进了合成质量并节省了劳动成本。


<details>
  <summary>Details</summary>
Motivation: 为了解决X射线安全图像的收集和注释过程中的数据不足问题，提高合成图像的实用性。

Method: 基于文本到图像生成，采用交叉注意力精炼（CAR）策略和背景遮挡建模（BOM）策略。

Result: Xsyn方法在mAP指标上比之前的方法提高了1.2%，且生成的合成图像在多个X射线安全数据集和探测器上的禁止物品检测性能上表现出色。

Conclusion: 本研究提出了一种新的一阶段X射线安全图像合成管道Xsyn，显著提高了合成图像的质量，且无额外劳动成本。

Abstract: Training prohibited item detection models requires a large amount of X-ray security images, but collecting and annotating these images is time-consuming and laborious. To address data insufficiency, X-ray security image synthesis methods composite images to scale up datasets. However, previous methods primarily follow a two-stage pipeline, where they implement labor-intensive foreground extraction in the first stage and then composite images in the second stage. Such a pipeline introduces inevitable extra labor cost and is not efficient. In this paper, we propose a one-stage X-ray security image synthesis pipeline (Xsyn) based on text-to-image generation, which incorporates two effective strategies to improve the usability of synthetic images. The Cross-Attention Refinement (CAR) strategy leverages the cross-attention map from the diffusion model to refine the bounding box annotation. The Background Occlusion Modeling (BOM) strategy explicitly models background occlusion in the latent space to enhance imaging complexity. To the best of our knowledge, compared with previous methods, Xsyn is the first to achieve high-quality X-ray security image synthesis without extra labor cost. Experiments demonstrate that our method outperforms all previous methods with 1.2% mAP improvement, and the synthetic images generated by our method are beneficial to improve prohibited item detection performance across various X-ray security datasets and detectors. Code is available at https://github.com/pILLOW-1/Xsyn/.

</details>


### [48] [Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models](https://arxiv.org/abs/2511.15311)
*Mehran Tamjidi,Hamidreza Dastmalchi,Mohammadreza Alimoradijazi,Ali Cheraghian,Aijun An,Morteza Saberi*

Main category: cs.CV

TL;DR: 提出了一种名为Uni-Adapter的训练-free在线适应策略，通过动态原型学习和3D缓存，显著提升3D VLFMs在复杂数据分布下的表现，达到了领先水平。


<details>
  <summary>Details</summary>
Motivation: 针对3D视觉语言基础模型在非常规数据环境下的性能不足，提出一种有效的适应策略，以提升其在真实应用场景中的能力。

Method: 提出了一种在线测试时间适应（TTA）策略，利用动态原型学习、3D缓存和图基标签平滑模块来进行类内和类间的相似度计算与标签一致性维护。

Result: Uni-Adapter在处理各种3D基准测试时，相较于源3D视觉语言基础模型，提升了ModelNet-40C 10.55%，ScanObjectNN-C 8.26%，ShapeNet-C 4.49%的表现。

Conclusion: Uni-Adapter通过动态原型学习和缓存机制，在不进行重训练的情况下，有效应对了3D视觉语言基础模型在数据分布变化时的性能下降问题，显著提升了在多种3D基准测试中的表现。

Abstract: 3D Vision-Language Foundation Models (VLFMs) have shown strong generalization and zero-shot recognition capabilities in open-world point cloud processing tasks. However, these models often underperform in practical scenarios where data are noisy, incomplete, or drawn from a different distribution than the training data. To address this, we propose Uni-Adapter, a novel training-free online test-time adaptation (TTA) strategy for 3D VLFMs based on dynamic prototype learning. We define a 3D cache to store class-specific cluster centers as prototypes, which are continuously updated to capture intra-class variability in heterogeneous data distributions. These dynamic prototypes serve as anchors for cache-based logit computation via similarity scoring. Simultaneously, a graph-based label smoothing module captures inter-prototype similarities to enforce label consistency among similar prototypes. Finally, we unify predictions from the original 3D VLFM and the refined 3D cache using entropy-weighted aggregation for reliable adaptation. Without retraining, Uni-Adapter effectively mitigates distribution shifts, achieving state-of-the-art performance on diverse 3D benchmarks over different 3D VLFMs, improving ModelNet-40C by 10.55%, ScanObjectNN-C by 8.26%, and ShapeNet-C by 4.49% over the source 3D VLFMs.

</details>


### [49] [A Multimodal Transformer Approach for UAV Detection and Aerial Object Recognition Using Radar, Audio, and Video Data](https://arxiv.org/abs/2511.15312)
*Mauro Larrat,Claudomiro Sales*

Main category: cs.CV

TL;DR: 本研究开发了一种有效的多模态变压器模型用于无人机检测，展示了高准确性和实时性能。


<details>
  <summary>Details</summary>
Motivation: 针对现有单一模态方法的局限性，提高无人机检测和空中物体识别的有效性和准确性。

Method: 设计并评估一种集成雷达、RGB视频、红外视频和音频多种数据流的多模态变压器模型。

Result: 模型在独立测试集上表现优异，宏观平均指标显示高准确率、召回率、精确率和F1-score，且在实时应用中表现出高效性。

Conclusion: 本研究提出了一种多模态变压器模型，表现出色，证明了数据融合在无人机检测中的有效性。

Abstract: Unmanned aerial vehicle (UAV) detection and aerial object recognition are critical for modern surveillance and security, prompting a need for robust systems that overcome limitations of single-modality approaches. This research addresses these challenges by designing and rigorously evaluating a novel multimodal Transformer model that integrates diverse data streams: radar, visual band video (RGB), infrared (IR) video, and audio. The architecture effectively fuses distinct features from each modality, leveraging the Transformer's self-attention mechanisms to learn comprehensive, complementary, and highly discriminative representations for classification. The model demonstrated exceptional performance on an independent test set, achieving macro-averaged metrics of 0.9812 accuracy, 0.9873 recall, 0.9787 precision, 0.9826 F1-score, and 0.9954 specificity. Notably, it exhibited particularly high precision and recall in distinguishing drones from other aerial objects. Furthermore, computational analysis confirmed its efficiency, with 1.09 GFLOPs, 1.22 million parameters, and an inference speed of 41.11 FPS, highlighting its suitability for real-time applications. This study presents a significant advancement in aerial object classification, validating the efficacy of multimodal data fusion via a Transformer architecture for achieving state-of-the-art performance, thereby offering a highly accurate and resilient solution for UAV detection and monitoring in complex airspace.

</details>


### [50] [Adaptive thresholding pattern for fingerprint forgery detection](https://arxiv.org/abs/2511.15322)
*Zahra Farzadpour,Masoumeh Azghani*

Main category: cs.CV

TL;DR: 本文提出了一种基于小波变换的指纹伪造检测算法，具有良好的抗失真能力，准确率显著提升。


<details>
  <summary>Details</summary>
Motivation: 针对指纹识别系统面临的伪造威胁，开发有效的检测技术以区分真实指纹和假指纹。

Method: 使用基于小波变换和支持向量机的适应性阈值模式，进行指纹特征的提取和分类。

Result: 在像素缺失和块缺失情况下，该方法的准确率分别提高了约8%和5%。

Conclusion: 提出了一种新的指纹伪造检测算法，能够有效抵御多种失真，有效提升了检测准确率。

Abstract: Fingerprint liveness detection systems have been affected by spoofing, which is a severe threat for fingerprint-based biometric systems. Therefore, it is crucial to develop some techniques to distinguish the fake fingerprints from the real ones. The software based techniques can detect the fingerprint forgery automatically. Also, the scheme shall be resistant against various distortions such as noise contamination, pixel missing and block missing, so that the forgers cannot deceive the detector by adding some distortions to the faked fingerprint. In this paper, we propose a fingerprint forgery detection algorithm based on a suggested adaptive thresholding pattern. The anisotropic diffusion of the input image is passed through three levels of the wavelet transform. The coefficients of different layers are adaptively thresholded and concatenated to produce the feature vector which is classified using the SVM classifier. Another contribution of the paper is to investigate the effect of various distortions such as pixel missing, block missing, and noise contamination. Our suggested approach includes a novel method that exhibits improved resistance against a range of distortions caused by environmental phenomena or manipulations by malicious users. In quantitative comparisons, our proposed method outperforms its counterparts by approximately 8% and 5% in accuracy for missing pixel scenarios of 90% and block missing scenarios of size 70x70 , respectively. This highlights the novelty approach in addressing such challenges.

</details>


### [51] [Fast Post-Hoc Confidence Fusion for 3-Class Open-Set Aerial Object Detection](https://arxiv.org/abs/2511.15343)
*Spyridon Loukovitis,Vasileios Karampinis,Athanasios Voulodimos*

Main category: cs.CV

TL;DR: 提出了一种后处理框架，通过聚合置信度和特征，实现无人机导航中的三类实时分类，显著提高AUROC和mAP。


<details>
  <summary>Details</summary>
Motivation: 设计可靠的无人机导航系统需要强大的空中物体检测器，能够区分训练期间见过的物体和之前未见过的物体。

Method: 我们提出了一种轻量、模型无关的后处理框架，利用多层感知器(MLP)将多个置信度估计和每次检测特征聚合，从而实现三个类别（ID目标、OOD对象和背景）的实时分类。

Result: 在两个类别分类中，我们的方法平均提高了2.7%的AUROC，在提高闭集mAP的同时，增强了开放集检测，并能够进行稳健的三类分类。

Conclusion: 我们的方法在两个类别分类中至少提高了2.7%的AUROC，同时也保持或改善了开放集的mAP，并在各数据集上超越了竞争技术的AUROC。

Abstract: Developing reliable UAV navigation systems requires robust air-to-air object detectors capable of distinguishing between objects seen during training and previously unseen objects. While many methods address closed-set detection and achieve high-confidence recognition of in-domain (ID) targets, they generally do not tackle open-set detection, which requires simultaneous handling of both ID and out-of-distribution (OOD) objects. Existing open-set approaches typically rely on a single uncertainty score with thresholding, limiting flexibility and often conflating OOD objects with background clutter. In contrast, we propose a lightweight, model-agnostic post-processing framework that explicitly separates background from unknown objects while preserving the base detector's performance. Our approach extends open-set detection beyond binary ID/OOD classification to real-time three-way classification among ID targets, OOD objects, and background. To this end, we employ a fusion scheme that aggregates multiple confidence estimates and per-detection features using a compact multilayer perceptron (MLP). Incorporating different logit variants into the MLP consistently enhances performance across both binary and three-class classification without compromising throughput. Extensive ablation and comparative experiments confirm that our method surpasses threshold-based baselines in two-class classification by an average of 2.7% AUROC, while retaining or improving open-set mAP. Furthermore, our study uniquely enables robust three-class classification, a critical capability for safe UAV navigation, where OOD objects must be actively avoided and background regions safely ignored. Comparative analysis highlights that our method surpasses competitive techniques in AUROC across datasets, while improving closed-set mAP by up to 9 points, an 18% relative gain.

</details>


### [52] [IPTQ-ViT: Post-Training Quantization of Non-linear Functions for Integer-only Vision Transformers](https://arxiv.org/abs/2511.15369)
*Gihwan Kim,Jemin Lee,Hyungshin Kim*

Main category: cs.CV

TL;DR: IPTQ-ViT is a new PTQ framework for vision transformers that achieves better accuracy without retraining, using novel approximation functions.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of existing QAT and PTQ methods that either require expensive retraining or fail to support fully integer-only inference in resource-constrained scenarios.

Method: Introduces a novel PTQ framework that employs polynomial-based GELU and bit-shifting-based Softmax approximation functions.

Result: Achieves significant accuracy improvements in image classification and object detection, outperforming traditional PTQ methods and maintaining comparable performance to integer-only QAT.

Conclusion: IPTQ-ViT improves accuracy and efficiency for quantization in vision transformers, surpassing previous methods without the need for retraining.

Abstract: Previous Quantization-Aware Training (QAT) methods for vision transformers rely on expensive retraining to recover accuracy loss in non-linear layer quantization, limiting their use in resource-constrained environments. In contrast, existing Post-Training Quantization (PTQ) methods either partially quantize non-linear functions or adjust activation distributions to maintain accuracy but fail to achieve fully integer-only inference. In this paper, we introduce IPTQ-ViT, a novel PTQ framework for fully integer-only vision transformers without retraining. We present approximation functions: a polynomial-based GELU optimized for vision data and a bit-shifting-based Softmax designed to improve approximation accuracy in PTQ. In addition, we propose a unified metric integrating quantization sensitivity, perturbation, and computational cost to select the optimal approximation function per activation layer. IPTQ-ViT outperforms previous PTQ methods, achieving up to 6.44\%p (avg. 1.78\%p) top-1 accuracy improvement for image classification, 1.0 mAP for object detection. IPTQ-ViT outperforms partial floating-point PTQ methods under W8A8 and W4A8, and achieves accuracy and latency comparable to integer-only QAT methods. We plan to release our code https://github.com/gihwan-kim/IPTQ-ViT.git.

</details>


### [53] [Zero-Shot Open-Vocabulary Human Motion Grounding with Test-Time Training](https://arxiv.org/abs/2511.15379)
*Yunjiao Zhou,Xinyan Chen,Junlang Qian,Lihua Xie,Jianfei Yang*

Main category: cs.CV

TL;DR: ZOMG是一个零-shot的开放词汇框架，可以在无需注释的情况下有效分割运动序列，取得了优越的表现。


<details>
  <summary>Details</summary>
Motivation: 复杂人类活动的理解需要将运动分解为细粒度、语义对齐的子动作，现有方法在开放词汇的真实场景中存在局限性。

Method: ZOMG框架结合了语言语义分割和软掩模优化技术，旨在对运动序列进行细粒度的分解，同时保持子动作之间的连续性和分隔性。

Result: 在三个人类运动语言数据集上进行的实验表明，ZOMG框架在运动基础性能上达到最先进效果，较HumanML3D基准超越先前方法8.7%的mAP，同时在下游检索任务中也有显著提高。

Conclusion: 提出的ZOMG框架在无须任何注释或微调的情况下，能够有效地将运动序列分割为有语义意义的子动作，开辟了无注释运动理解的新范式。

Abstract: Understanding complex human activities demands the ability to decompose motion into fine-grained, semantic-aligned sub-actions. This motion grounding process is crucial for behavior analysis, embodied AI and virtual reality. Yet, most existing methods rely on dense supervision with predefined action classes, which are infeasible in open-vocabulary, real-world settings. In this paper, we propose ZOMG, a zero-shot, open-vocabulary framework that segments motion sequences into semantically meaningful sub-actions without requiring any annotations or fine-tuning. Technically, ZOMG integrates (1) language semantic partition, which leverages large language models to decompose instructions into ordered sub-action units, and (2) soft masking optimization, which learns instance-specific temporal masks to focus on frames critical to sub-actions, while maintaining intra-segment continuity and enforcing inter-segment separation, all without altering the pretrained encoder. Experiments on three motion-language datasets demonstrate state-of-the-art effectiveness and efficiency of motion grounding performance, outperforming prior methods by +8.7\% mAP on HumanML3D benchmark. Meanwhile, significant improvements also exist in downstream retrieval, establishing a new paradigm for annotation-free motion understanding.

</details>


### [54] [Breaking Expert Knowledge Limits: Self-Pruning for Large Language Models](https://arxiv.org/abs/2511.15390)
*Haidong Kang,Lihong Lin,Enneng Yang,Hongning Dai,Hao Wang*

Main category: cs.CV

TL;DR: AutoPrune通过自动设计剪枝算法，提升了大语言模型剪枝的性能，并解决了高稀疏率下的异常值问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有剪枝方法的人工设计依赖性以及在高稀疏率下性能显著下降的问题。

Method: 提出了基于图驱动的思维链方法（GCoT）来优化提示，并介绍了偏差感知动态稀疏分配（SDSA）来应对异常值问题。

Result: 在主流大语言模型基准测试中，AutoPrune表现优于现有的最先进方法。

Conclusion: AutoPrune为大语言模型的自动剪枝提供了一种有效的方法，显著提升了剪枝算法的性能和可解释性。

Abstract: Large language models (LLMs) have achieved remarkable performance on a wide range of tasks, hindering real-world deployment due to their massive size. Existing pruning methods (e.g., Wanda) tailored for LLMs rely heavily on manual design pruning algorithms, thereby leading to \textit{huge labor costs} and \textit{requires expert knowledge}. Furthermore, we are the first to identify the serious \textit{outlier value issue} behind dramatic performance degradation under high pruning ratios that are caused by uniform sparsity, raising an additional concern about how to design adaptive pruning sparsity ideal for LLMs. Can LLMs prune by themselves? In this work, we introduce an affirmative answer by proposing a novel pruning method called \textbf{AutoPrune}, which first overcomes expert knowledge limits by leveraging LLMs to design optimal pruning algorithms for themselves automatically without any expert knowledge. Specifically, to mitigate the black-box nature of LLMs, we propose a Graph-driven Chain-of-Thought (GCoT) to optimize prompts, significantly enhancing the reasoning process in learning the pruning algorithm and enabling us to generate pruning algorithms with superior performance and interpretability in the next generation. Finally, grounded in insights of outlier value issue, we introduce Skew-aware Dynamic Sparsity Allocation (SDSA) to overcome the outlier value issue, mitigating performance degradation under high pruning ratios. We conduct extensive experiments on mainstream LLMs benchmarks, demonstrating the superiority of AutoPrune, which consistently excels state-of-the-art competitors. The code is available at: https://anonymous.4open.science/r/AutoPrune.

</details>


### [55] [ShelfOcc: Native 3D Supervision beyond LiDAR for Vision-Based Occupancy Estimation](https://arxiv.org/abs/2511.15396)
*Simon Boeder,Fabian Gigengack,Simon Roesler,Holger Caesar,Benjamin Risse*

Main category: cs.CV

TL;DR: ShelfOcc offers a novel, LiDAR-free approach to occupancy estimation by generating accurate 3D supervision from video, improving the performance of existing models.


<details>
  <summary>Details</summary>
Motivation: Previous methods suffered from geometric inconsistencies and depth bleeding due to reliance on 2D supervision; thus, a new approach was necessary to enhance occupancy estimation in 3D space without additional sensors.

Method: ShelfOcc is a vision-only method that generates metrically consistent semantic voxel labels from video, creating a stable 3D representation through filtering and accumulation of static geometry across frames.

Result: On the Occ3D-nuScenes benchmark, ShelfOcc achieved up to a 34% relative improvement over previous weakly/shelf-supervised methods, highlighting its effectiveness in LiDAR-free 3D scene understanding.

Conclusion: ShelfOcc significantly improves occupancy estimation by providing high-quality 3D supervision without the need for LiDAR, achieving substantial performance gains over previous methods.

Abstract: Recent progress in self- and weakly supervised occupancy estimation has largely relied on 2D projection or rendering-based supervision, which suffers from geometric inconsistencies and severe depth bleeding. We thus introduce ShelfOcc, a vision-only method that overcomes these limitations without relying on LiDAR. ShelfOcc brings supervision into native 3D space by generating metrically consistent semantic voxel labels from video, enabling true 3D supervision without any additional sensors or manual 3D annotations. While recent vision-based 3D geometry foundation models provide a promising source of prior knowledge, they do not work out of the box as a prediction due to sparse or noisy and inconsistent geometry, especially in dynamic driving scenes. Our method introduces a dedicated framework that mitigates these issues by filtering and accumulating static geometry consistently across frames, handling dynamic content and propagating semantic information into a stable voxel representation. This data-centric shift in supervision for weakly/shelf-supervised occupancy estimation allows the use of essentially any SOTA occupancy model architecture without relying on LiDAR data. We argue that such high-quality supervision is essential for robust occupancy learning and constitutes an important complementary avenue to architectural innovation. On the Occ3D-nuScenes benchmark, ShelfOcc substantially outperforms all previous weakly/shelf-supervised methods (up to a 34% relative improvement), establishing a new data-driven direction for LiDAR-free 3D scene understanding.

</details>


### [56] [Controlling False Positives in Image Segmentation via Conformal Prediction](https://arxiv.org/abs/2511.15406)
*Luca Mossina,Corentin Friedrich*

Main category: cs.CV

TL;DR: 提出一种无模型依赖的后处理框架，通过控制假阳性率，增强蛋白质分割的可靠性，特别是在临床应用中。


<details>
  <summary>Details</summary>
Motivation: 临床决策中，可靠的语义分割至关重要，但传统深度模型难以提供错误的统计保证。

Method: 通过后处理的方式构建置信掩模，利用无分布的图像级控制假阳性预测。

Result: 在息肉分割基准测试中，展示了该方法的经验有效性，成功控制了假阳性的比例。

Conclusion: 该方法在多种情况下提供了有效的风险控制，减少了假阳性数量，从而在临床决策中更具实用性。

Abstract: Reliable semantic segmentation is essential for clinical decision making, yet deep models rarely provide explicit statistical guarantees on their errors. We introduce a simple post-hoc framework that constructs confidence masks with distribution-free, image-level control of false-positive predictions. Given any pretrained segmentation model, we define a nested family of shrunken masks obtained either by increasing the score threshold or by applying morphological erosion. A labeled calibration set is used to select a single shrink parameter via conformal prediction, ensuring that, for new images that are exchangeable with the calibration data, the proportion of false positives retained in the confidence mask stays below a user-specified tolerance with high probability. The method is model-agnostic, requires no retraining, and provides finite-sample guarantees regardless of the underlying predictor. Experiments on a polyp-segmentation benchmark demonstrate target-level empirical validity. Our framework enables practical, risk-aware segmentation in settings where over-segmentation can have clinical consequences. Code at https://github.com/deel-ai-papers/conseco.

</details>


### [57] [D4C: Data-free Quantization for Contrastive Language-Image Pre-training Models](https://arxiv.org/abs/2511.15411)
*Wenlun Zhang,Yunshan Zhong,Zihao Ding,Xinyu Li,Kentaro Yoshioka*

Main category: cs.CV

TL;DR: D4C提出了一种新框架，专门针对CLIP进行数据无关量化，通过生成高质量的伪图像来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 在隐私敏感场景下，DFQ提供了一种无需真实数据的模型压缩解决方案，然而其在视觉语言模型中的应用尚待探索。

Method: 提出了三个关键组件来生成伪图像：提示引导的语义注入、结构对比生成和扰动感知增强。

Result: D4C在不同的位宽和模型上实现了显著的性能提升，特别是在CLIP ResNet-50和ViT-B/32模型上，分别在CIFAR-10、CIFAR-100和ImageNet-1K上显示出显著的Top-1准确率改善。

Conclusion: D4C框架通过合成语义丰富和结构多样的伪图像，显著提升了CLIP模型在数据无关量化中的表现。

Abstract: Data-Free Quantization (DFQ) offers a practical solution for model compression without requiring access to real data, making it particularly attractive in privacy-sensitive scenarios. While DFQ has shown promise for unimodal models, its extension to Vision-Language Models such as Contrastive Language-Image Pre-training (CLIP) models remains underexplored. In this work, we reveal that directly applying existing DFQ techniques to CLIP results in substantial performance degradation due to two key limitations: insufficient semantic content and low intra-image diversity in synthesized samples. To tackle these challenges, we propose D4C, the first DFQ framework tailored for CLIP. D4C synthesizes semantically rich and structurally diverse pseudo images through three key components: (1) Prompt-Guided Semantic Injection aligns generated images with real-world semantics using text prompts; (2) Structural Contrastive Generation reproduces compositional structures of natural images by leveraging foreground-background contrastive synthesis; and (3) Perturbation-Aware Enhancement applies controlled perturbations to improve sample diversity and robustness. These components jointly empower D4C to synthesize images that are both semantically informative and structurally diverse, effectively bridging the performance gap of DFQ on CLIP. Extensive experiments validate the effectiveness of D4C, showing significant performance improvements on various bit-widths and models. For example, under the W4A8 setting with CLIP ResNet-50 and ViT-B/32, D4C achieves Top-1 accuracy improvement of 12.4% and 18.9% on CIFAR-10, 6.8% and 19.7% on CIFAR-100, and 1.4% and 5.7% on ImageNet-1K in zero-shot classification, respectively.

</details>


### [58] [WarNav: An Autonomous Driving Benchmark for Segmentation of Navigable Zones in War Scenes](https://arxiv.org/abs/2511.15429)
*Marc-Emmanuel Coupvent des Graviers,Hejer Ammar,Christophe Guettier,Yann Dumortier,Romaric Audigier*

Main category: cs.CV

TL;DR: WarNav 数据集旨在提升无人驾驶汽车在危险环境中的导航能力，通过基准测试展示了现有模型的效果，同时强调了在极端条件下的操作挑战。


<details>
  <summary>Details</summary>
Motivation: 技术快速发展与无人驾驶汽车在战区等恶劣环境中的应用需求之间存在明显差距，尤其在数据和模型的适配方面。

Method: 通过构建 DATTALION 资源中的图像数据集，详细阐述了在不均衡和危险环境中进行语义分割的方法学挑战。

Result: 建立了基准结果，分析了训练数据环境的影响，并提出了在无标注数据下实现有效导航的初步步骤。

Conclusion: WarNav 为无人驾驶系统在极端环境中导航提供了一个基础数据集，并展示了现代语义分割模型在该领域的表现和潜力。

Abstract: We introduce WarNav, a novel real-world dataset constructed from images of the open-source DATTALION repository, specifically tailored to enable the development and benchmarking of semantic segmentation models for autonomous ground vehicle navigation in unstructured, conflict-affected environments. This dataset addresses a critical gap between conventional urban driving resources and the unique operational scenarios encountered by unmanned systems in hazardous and damaged war-zones. We detail the methodological challenges encountered, ranging from data heterogeneity to ethical considerations, providing guidance for future efforts that target extreme operational contexts. To establish performance references, we report baseline results on WarNav using several state-of-the-art semantic segmentation models trained on structured urban scenes. We further analyse the impact of training data environments and propose a first step towards effective navigability in challenging environments with the constraint of having no annotation of the targeted images. Our goal is to foster impactful research that enhances the robustness and safety of autonomous vehicles in high-risk scenarios while being frugal in annotated data.

</details>


### [59] [Representation Space Constrained Learning with Modality Decoupling for Multimodal Object Detection](https://arxiv.org/abs/2511.15433)
*YiKang Shao,Tao Shi*

Main category: cs.CV

TL;DR: 本文针对多模态物体检测中的融合降级进行理论研究，提出RSC-MD方法，解决模态不平衡和梯度抑制问题，实验结果表明其在多个数据集上具有优越性能。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在填补多模态检测中关于融合降级缺乏理论分析的空白，探讨其潜在原因。

Method: 提出了一种包括RSC模块和MD模块的RSC-MD方法，以放大受抑制的梯度并消除跨模态耦合干扰和模态不平衡。

Result: 通过对FLIR、LLVIP、M3FD和MFAD数据集进行广泛实验，证明了该方法在性能上优于现有技术。

Conclusion: 提出的RSC-MD方法有效缓解了融合降级问题，并在多个基准上达到最先进的性能。

Abstract: Multimodal object detection has attracted significant attention in both academia and industry for its enhanced robustness. Although numerous studies have focused on improving modality fusion strategies, most neglect fusion degradation, and none provide a theoretical analysis of its underlying causes. To fill this gap, this paper presents a systematic theoretical investigation of fusion degradation in multimodal detection and identifies two key optimization deficiencies: (1) the gradients of unimodal branch backbones are severely suppressed under multimodal architectures, resulting in under-optimization of the unimodal branches; (2) disparities in modality quality cause weaker modalities to experience stronger gradient suppression, which in turn results in imbalanced modality learning. To address these issues, this paper proposes a Representation Space Constrained Learning with Modality Decoupling (RSC-MD) method, which consists of two modules. The RSC module and the MD module are designed to respectively amplify the suppressed gradients and eliminate inter-modality coupling interference as well as modality imbalance, thereby enabling the comprehensive optimization of each modality-specific backbone. Extensive experiments conducted on the FLIR, LLVIP, M3FD, and MFAD datasets demonstrate that the proposed method effectively alleviates fusion degradation and achieves state-of-the-art performance across multiple benchmarks. The code and training procedures will be released at https://github.com/yikangshao/RSC-MD.

</details>


### [60] [HV-Attack: Hierarchical Visual Attack for Multimodal Retrieval Augmented Generation](https://arxiv.org/abs/2511.15435)
*Linyin Luo,Yujuan Ding,Yunshan Ma,Wenqi Fan,Hanjiang Lai*

Main category: cs.CV

TL;DR: 本研究提出了一种层次视觉攻击，通过优化图像输入的扰动，成功影响了MRAG系统的性能，并引入新类型的安全问题。


<details>
  <summary>Details</summary>
Motivation: 鉴于现有MRAG系统对知识毒化攻击的脆弱性，我们关注通过视觉攻击在图像输入上施加不可察觉的扰动，探索新的安全问题。

Method: 通过优化图像输入的扰动，破坏跨模态和多模态语义对齐，提出了层次化的两阶段策略。

Result: 在两个流行的MRAG数据集上进行的广泛实验表明，我们的视觉攻击显著降低了检索和生成性能。

Conclusion: 我们提出的层次视觉攻击有效地破坏了MRAG的检索和生成性能，显示了其对视觉攻击的脆弱性。

Abstract: Advanced multimodal Retrieval-Augmented Generation (MRAG) techniques have been widely applied to enhance the capabilities of Large Multimodal Models (LMMs), but they also bring along novel safety issues. Existing adversarial research has revealed the vulnerability of MRAG systems to knowledge poisoning attacks, which fool the retriever into recalling injected poisoned contents. However, our work considers a different setting: visual attack of MRAG by solely adding imperceptible perturbations at the image inputs of users, without manipulating any other components. This is challenging due to the robustness of fine-tuned retrievers and large-scale generators, and the effect of visual perturbation may be further weakened by propagation through the RAG chain. We propose a novel Hierarchical Visual Attack that misaligns and disrupts the two inputs (the multimodal query and the augmented knowledge) of MRAG's generator to confuse its generation. We further design a hierarchical two-stage strategy to obtain misaligned augmented knowledge. We disrupt the image input of the retriever to make it recall irrelevant knowledge from the original database, by optimizing the perturbation which first breaks the cross-modal alignment and then disrupts the multimodal semantic alignment. We conduct extensive experiments on two widely-used MRAG datasets: OK-VQA and InfoSeek. We use CLIP-based retrievers and two LMMs BLIP-2 and LLaVA as generators. Results demonstrate the effectiveness of our visual attack on MRAG through the significant decrease in both retrieval and generation performance.

</details>


### [61] [Driving in Spikes: An Entropy-Guided Object Detector for Spike Cameras](https://arxiv.org/abs/2511.15459)
*Ziyan Liu,Qi Su,Lulu Tang,Zhaofei Yu,Tiejun Huang*

Main category: cs.CV

TL;DR: 文章提出了EASD，一个针对脉冲相机的端到端检测器，解决了自动驾驶中的运动模糊和照明问题，包含新的基准数据集DSEC Spike。


<details>
  <summary>Details</summary>
Motivation: 针对快速运动和极端照明下的运动模糊和饱和问题，探索脉冲相机在自动驾驶物体检测中的应用。

Method: 提出了一个双支路设计，包括基于时间的纹理加特征融合分支和熵选择注意分支。

Result: EASD有效地处理稀疏、离散的脉冲信号，并通过DSEC Spike基准推动了检测性能的提高。

Conclusion: EASD是一个有效的端到端脉冲相机检测器，结合了全局跨切片语义和对象中心细节，提供了流畅的检测性能。

Abstract: Object detection in autonomous driving suffers from motion blur and saturation under fast motion and extreme lighting. Spike cameras, offer microsecond latency and ultra high dynamic range for object detection by using per pixel asynchronous integrate and fire. However, their sparse, discrete output cannot be processed by standard image-based detectors, posing a critical challenge for end to end spike stream detection. We propose EASD, an end to end spike camera detector with a dual branch design: a Temporal Based Texture plus Feature Fusion branch for global cross slice semantics, and an Entropy Selective Attention branch for object centric details. To close the data gap, we introduce DSEC Spike, the first driving oriented simulated spike detection benchmark.

</details>


### [62] [SIGMMA: Hierarchical Graph-Based Multi-Scale Multi-modal Contrastive Alignment of Histopathology Image and Spatial Transcriptome](https://arxiv.org/abs/2511.15464)
*Dabin Jeong,Amirhossein Vahidi,Ciro Ramírez-Suástegui,Marie Moullet,Kevin Ly,Mohammad Vali Sanian,Sebastian Birk,Yinshui Chang,Adam Boxall,Daniyal Jafree,Lloyd Steele,Vijaya Baskar MS,Muzlifah Haniffa,Mohammad Lotfollahi*

Main category: cs.CV

TL;DR: Sigmma是一个多模态对比对齐框架，通过多尺度学习HE图像与空间转录组的层次表示，显著提升基因表达预测和跨模态检索的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常在单一尺度对HE图像和ST特征进行对齐，忽视了细胞结构的细粒度和空间组织的关系。

Method: 提出了一种多模态对比对齐框架，通过多尺度对比对齐学习HE图像和空间转录组特征的层次表示，兼顾细胞交互的图表示。

Result: Sigmma在基因表达预测任务中平均提升9.78%，在跨模态检索任务中平均提升26.93%，有效捕捉了组织微环境中的细胞相互作用。

Conclusion: Sigmma学习的表示在基因表达预测和跨模态检索任务中显著改善，且在下游分析中展示了有意义的多组织结构。

Abstract: Recent advances in computational pathology have leveraged vision-language models to learn joint representations of Hematoxylin and Eosin (HE) images with spatial transcriptomic (ST) profiles. However, existing approaches typically align HE tiles with their corresponding ST profiles at a single scale, overlooking fine-grained cellular structures and their spatial organization. To address this, we propose Sigmma, a multi-modal contrastive alignment framework for learning hierarchical representations of HE images and spatial transcriptome profiles across multiple scales. Sigmma introduces multi-scale contrastive alignment, ensuring that representations learned at different scales remain coherent across modalities. Furthermore, by representing cell interactions as a graph and integrating inter- and intra-subgraph relationships, our approach effectively captures cell-cell interactions, ranging from fine to coarse, within the tissue microenvironment. We demonstrate that Sigmm learns representations that better capture cross-modal correspondences, leading to an improvement of avg. 9.78\% in the gene-expression prediction task and avg. 26.93\% in the cross-modal retrieval task across datasets. We further show that it learns meaningful multi-tissue organization in downstream analyses.

</details>


### [63] [Deep Learning for Accurate Vision-based Catch Composition in Tropical Tuna Purse Seiners](https://arxiv.org/abs/2511.15468)
*Xabier Lekunberri,Ahmad Kamal,Izaro Goienetxea,Jon Ruiz,Iñaki Quincoces,Jaime Valls Miro,Ignacio Arganda-Carreras,Jose A. Fernandes-Salvador*

Main category: cs.CV

TL;DR: 本研究通过比较不同的图像分割方法，提出了一种结合YOLOv9-SAM2的分层分类流程，以高效地识别金枪鱼种类，显著减少人工工作量并提高识别准确性。


<details>
  <summary>Details</summary>
Motivation: 随着电子监控系统在金枪鱼捕捞中的广泛应用，结合人工智能技术以提高种类识别的准确性与减少人工工作量变得尤为重要。

Method: 本研究采用多阶段流程，利用基于观察者识别的可靠真实数据集，比较了三种分割方法（Mask R-CNN、DINOv2与SAM2的结合、YOLOv9与SAM2的结合），评估了它们在金枪鱼分类中的表现，并使用ByteTrack进行个体追踪。

Result: 研究发现，YOLOv9与SAM2的结合在评估中表现最佳，验证平均精准度为0.66，召回率为0.88。在人的专家识别中，对大眼金枪鱼和黄鳍金枪鱼的识别一致性均相对较低。

Conclusion: 结合YOLOv9-SAM2和分层分类方法，能够最有效地对捕获物种进行实时的分割与分类，有助于提高金枪鱼捕捞的精确性与效率。

Abstract: Purse seiners play a crucial role in tuna fishing, as approximately 69% of the world's tropical tuna is caught using this gear. All tuna Regional Fisheries Management Organizations have established minimum standards to use electronic monitoring (EM) in fisheries in addition to traditional observers. The EM systems produce a massive amount of video data that human analysts must process. Integrating artificial intelligence (AI) into their workflow can decrease that workload and improve the accuracy of the reports. However, species identification still poses significant challenges for AI, as achieving balanced performance across all species requires appropriate training data. Here, we quantify the difficulty experts face to distinguish bigeye tuna (BET, Thunnus Obesus) from yellowfin tuna (YFT, Thunnus Albacares) using images captured by EM systems. We found inter-expert agreements of 42.9% $\pm$ 35.6% for BET and 57.1% $\pm$ 35.6% for YFT. We then present a multi-stage pipeline to estimate the species composition of the catches using a reliable ground-truth dataset based on identifications made by observers on board. Three segmentation approaches are compared: Mask R-CNN, a combination of DINOv2 with SAM2, and a integration of YOLOv9 with SAM2. We found that the latest performs the best, with a validation mean average precision of 0.66 $\pm$ 0.03 and a recall of 0.88 $\pm$ 0.03. Segmented individuals are tracked using ByteTrack. For classification, we evaluate a standard multiclass classification model and a hierarchical approach, finding a superior generalization by the hierarchical. All our models were cross-validated during training and tested on fishing operations with fully known catch composition. Combining YOLOv9-SAM2 with the hierarchical classification produced the best estimations, with 84.8% of the individuals being segmented and classified with a mean average error of 4.5%.

</details>


### [64] [Evaluating Low-Light Image Enhancement Across Multiple Intensity Levels](https://arxiv.org/abs/2511.15496)
*Maria Pilligua,David Serrano-Lozano,Pai Peng,Ramon Baldrich,Michael S. Brown,Javier Vazquez-Corral*

Main category: cs.CV

TL;DR: 我们提出了MILL数据集用于评估低光增强算法在多种光照条件下的性能，并提出了增强算法的改进，实现显著的PSNR提升。


<details>
  <summary>Details</summary>
Motivation: 低光环境下的成像困难，主要由于光线减弱导致的传感器噪声升高和颜色饱和度下降，因此需要提高在不同光照强度下的增强算法性能评估。

Method: 引入了Multi-Illumination Low-Light (MILL)数据集，包含多种光照强度下拍摄的图像，用于评估增强算法的性能。

Result: 在Full HD图像上，我们的方法对单镜反光相机的PSNR提升最多可达10 dB，对智能手机提升2 dB。

Conclusion: 通过MILL数据集的多光照结构，我们提出了增强算法在不同光照场景下的健壮性改进并取得显著的PSNR提升。

Abstract: Imaging in low-light environments is challenging due to reduced scene radiance, which leads to elevated sensor noise and reduced color saturation. Most learning-based low-light enhancement methods rely on paired training data captured under a single low-light condition and a well-lit reference. The lack of radiance diversity limits our understanding of how enhancement techniques perform across varying illumination intensities. We introduce the Multi-Illumination Low-Light (MILL) dataset, containing images captured at diverse light intensities under controlled conditions with fixed camera settings and precise illuminance measurements. MILL enables comprehensive evaluation of enhancement algorithms across variable lighting conditions. We benchmark several state-of-the-art methods and reveal significant performance variations across intensity levels. Leveraging the unique multi-illumination structure of our dataset, we propose improvements that enhance robustness across diverse illumination scenarios. Our modifications achieve up to 10 dB PSNR improvement for DSLR and 2 dB for the smartphone on Full HD images.

</details>


### [65] [FunnyNodules: A Customizable Medical Dataset Tailored for Evaluating Explainable AI](https://arxiv.org/abs/2511.15481)
*Luisa Gallée,Yiheng Xiong,Meinrad Beer,Michael Götz*

Main category: cs.CV

TL;DR: FunnyNodules是一个合成医学图像数据集，旨在促进可解释AI模型的推理分析，提供了可控的属性和全面的基础信息。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像数据集中稀缺的基于推理的注释，以开发和评估可解释AI模型。

Method: 引入FunnyNodules，一个完全参数化的合成数据集，用于系统分析基于属性的推理。

Result: 展示FunnyNodules在模型无关的评估中如何评估模型学习正确的属性-目标关系，并分析注意力与特定属性区域的对齐。

Conclusion: FunnyNodules为医学图像分析中的可解释AI方法开发、基准测试和深入分析提供了多功能的基础。

Abstract: Densely annotated medical image datasets that capture not only diagnostic labels but also the underlying reasoning behind these diagnoses are scarce. Such reasoning-related annotations are essential for developing and evaluating explainable AI (xAI) models that reason similarly to radiologists: making correct predictions for the right reasons. To address this gap, we introduce FunnyNodules, a fully parameterized synthetic dataset designed for systematic analysis of attribute-based reasoning in medical AI models. The dataset generates abstract, lung nodule-like shapes with controllable visual attributes such as roundness, margin sharpness, and spiculation. Target class is derived from a predefined attribute combination, allowing full control over the decision rule that links attributes to the diagnostic class. We demonstrate how FunnyNodules can be used in model-agnostic evaluations to assess whether models learn correct attribute-target relations, to interpret over- or underperformance in attribute prediction, and to analyze attention alignment with attribute-specific regions of interest. The framework is fully customizable, supporting variations in dataset complexity, target definitions, class balance, and beyond. With complete ground truth information, FunnyNodules provides a versatile foundation for developing, benchmarking, and conducting in-depth analyses of explainable AI methods in medical image analysis.

</details>


### [66] [Learning to Expand Images for Efficient Visual Autoregressive Modeling](https://arxiv.org/abs/2511.15499)
*Ruiqing Yang,Kaixin Zhang,Zheng Zhang,Shan You,Tao Huang*

Main category: cs.CV

TL;DR: 本研究提出了扩展自回归表示（EAR），通过中心向外的标记展开方式和动态解码策略，优化了自回归图像生成的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在生成过程中由于逐个标记解码或多尺度表示复杂性导致的效率问题。

Method: 提出了一种新颖的扩展自回归表示（EAR）生成范式，模仿人类视觉系统的中心向外感知模式，采用螺旋顺序展开图像标记。

Result: EAR通过保留空间连续性和实现高效的并行解码，大幅提升了生成质量，并通过动态调整预测标记数量的解码策略，提升灵活性和速度。

Conclusion: EAR在单尺度自回归模型中实现了最佳的保真度和效率平衡，为可扩展且符合认知的自回归图像生成树立了新方向。

Abstract: Autoregressive models have recently shown great promise in visual generation by leveraging discrete token sequences akin to language modeling. However, existing approaches often suffer from inefficiency, either due to token-by-token decoding or the complexity of multi-scale representations. In this work, we introduce Expanding Autoregressive Representation (EAR), a novel generation paradigm that emulates the human visual system's center-outward perception pattern. EAR unfolds image tokens in a spiral order from the center and progressively expands outward, preserving spatial continuity and enabling efficient parallel decoding. To further enhance flexibility and speed, we propose a length-adaptive decoding strategy that dynamically adjusts the number of tokens predicted at each step. This biologically inspired design not only reduces computational cost but also improves generation quality by aligning the generation order with perceptual relevance. Extensive experiments on ImageNet demonstrate that EAR achieves state-of-the-art trade-offs between fidelity and efficiency on single-scale autoregressive models, setting a new direction for scalable and cognitively aligned autoregressive image generation.

</details>


### [67] [CompTrack: Information Bottleneck-Guided Low-Rank Dynamic Token Compression for Point Cloud Tracking](https://arxiv.org/abs/2511.15580)
*Sifan Zhou,Yichao Cao,Jiahao Nie,Yuqian Fu,Ziyu Zhao,Xiaobo Lu,Shuo Wang*

Main category: cs.CV

TL;DR: 本论文提出CompTrack框架，通过消除激光雷达点云中的冗余，提升3D单对象跟踪的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决激光雷达点云中存在的空间冗余与信息冗余问题，提高单对象跟踪的准确性和效率。

Method: 引入空间前景预测器（SFP）和信息瓶颈引导的动态代币压缩（IB-DTC）模块，系统性消除点云中的冗余。

Result: CompTrack在KITTI、nuScenes以及Waymo数据集上的实验表明，其跟踪性能优越，运行速度可达90 FPS。

Conclusion: CompTrack在各大数据集上展现了卓越的跟踪性能和高效性，证明了其有效性。

Abstract: 3D single object tracking (SOT) in LiDAR point clouds is a critical task in computer vision and autonomous driving. Despite great success having been achieved, the inherent sparsity of point clouds introduces a dual-redundancy challenge that limits existing trackers: (1) vast spatial redundancy from background noise impairs accuracy, and (2) informational redundancy within the foreground hinders efficiency. To tackle these issues, we propose CompTrack, a novel end-to-end framework that systematically eliminates both forms of redundancy in point clouds. First, CompTrack incorporates a Spatial Foreground Predictor (SFP) module to filter out irrelevant background noise based on information entropy, addressing spatial redundancy. Subsequently, its core is an Information Bottleneck-guided Dynamic Token Compression (IB-DTC) module that eliminates the informational redundancy within the foreground. Theoretically grounded in low-rank approximation, this module leverages an online SVD analysis to adaptively compress the redundant foreground into a compact and highly informative set of proxy tokens. Extensive experiments on KITTI, nuScenes and Waymo datasets demonstrate that CompTrack achieves top-performing tracking performance with superior efficiency, running at a real-time 90 FPS on a single RTX 3090 GPU.

</details>


### [68] [Multi-Text Guided Few-Shot Semantic Segmentation](https://arxiv.org/abs/2511.15515)
*Qiang Jiao,Bin Yan,Yi Yang,Mengrui Shi,Qiang Zhang*

Main category: cs.CV

TL;DR: MTGNet通过多文本提示融合和模块优化，提升Few-Shot语义分割性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法只使用单一文本描述，无法全面捕捉复杂类别的语义多样性，导致目标区域激活不完全。

Method: 采用双支路框架，通过融合多样的文本提示来优化视觉先验。

Result: 在PASCAL-5i上1-shot设置下获得76.8% mIoU，在COCO-20i上获得57.4%，在类内变异较大的折中表现出显著的提高。

Conclusion: MTGNet有效提升了几-shot语义分割的性能，尤其在类内变异较大的情况下表现优异。

Abstract: Recent CLIP-based few-shot semantic segmentation methods introduce class-level textual priors to assist segmentation by typically using a single prompt (e.g., a photo of class). However, these approaches often result in incomplete activation of target regions, as a single textual description cannot fully capture the semantic diversity of complex categories. Moreover, they lack explicit cross-modal interaction and are vulnerable to noisy support features, further degrading visual prior quality. To address these issues, we propose the Multi-Text Guided Few-Shot Semantic Segmentation Network (MTGNet), a dual-branch framework that enhances segmentation performance by fusing diverse textual prompts to refine textual priors and guide the cross-modal optimization of visual priors. Specifically, we design a Multi-Textual Prior Refinement (MTPR) module that suppresses interference and aggregates complementary semantic cues to enhance foreground activation and expand semantic coverage for structurally complex objects. We introduce a Text Anchor Feature Fusion (TAFF) module, which leverages multi-text embeddings as semantic anchors to facilitate the transfer of discriminative local prototypes from support images to query images, thereby improving semantic consistency and alleviating intra-class variations. Furthermore, a Foreground Confidence-Weighted Attention (FCWA) module is presented to enhance visual prior robustness by leveraging internal self-similarity within support foreground features. It adaptively down-weights inconsistent regions and effectively suppresses interference in the query segmentation process. Extensive experiments on standard FSS benchmarks validate the effectiveness of MTGNet. In the 1-shot setting, it achieves 76.8% mIoU on PASCAL-5i and 57.4% on COCO-20i, with notable improvements in folds exhibiting high intra-class variations.

</details>


### [69] [Scriboora: Rethinking Human Pose Forecasting](https://arxiv.org/abs/2511.15565)
*Daniel Bermuth,Alexander Poeppel,Wolfgang Reif*

Main category: cs.CV

TL;DR: 本论文评估了广泛的姿态预测算法，提出了新数据集变体来考察模型在现实场景下的鲁棒性，并引入无监督微调方法来恢复性能。


<details>
  <summary>Details</summary>
Motivation: 人类姿态预测在众多应用中的重要性，以及现有算法的可重复性问题。

Method: 评估新型绝对姿态预测算法的统一训练和评估流程，结合最近的语音模型进行适应。

Result: 近期语音模型成功应用于姿态预测任务，显著提升了现有的最优性能，并揭示了在噪声条件下的鲁棒性问题。

Conclusion: 通过引入新的数据集变体，评估模型在真实噪声下的鲁棒性，提出了一种有效的无监督微调方法来恢复性能。

Abstract: Human pose forecasting predicts future poses based on past observations, and has many significant applications in areas such as action recognition, autonomous driving or human-robot interaction. This paper evaluates a wide range of pose forecasting algorithms in the task of absolute pose forecasting, revealing many reproducibility issues, and provides a unified training and evaluation pipeline. After drawing a high-level analogy to the task of speech understanding, it is shown that recent speech models can be efficiently adapted to the task of pose forecasting, and improve current state-of-the-art performance. At last the robustness of the models is evaluated, using noisy joint coordinates obtained from a pose estimator model, to reflect a realistic type of noise, which is more close to real-world applications. For this a new dataset variation is introduced, and it is shown that estimated poses result in a substantial performance degradation, and how much of it can be recovered again by unsupervised finetuning.

</details>


### [70] [US-X Complete: A Multi-Modal Approach to Anatomical 3D Shape Recovery](https://arxiv.org/abs/2511.15600)
*Miruna-Alexandra Gafencu,Yordanka Velikova,Nassir Navab,Mohammad Farid Azampour*

Main category: cs.CV

TL;DR: 本研究提出了一种结合X射线和超声的多模态深度学习方法，显著提升了脊柱解剖结构的可视化准确性，克服了超声的固有限制。


<details>
  <summary>Details</summary>
Motivation: 超声作为一种实时的无辐射成本效益解决方案，在脊柱手术中具有重要价值，但其在可视化完整椎体解剖方面存在固有限制，因此需要一种新方法来改善这一点。

Method: 我们提出了一种新颖的多模态深度学习方法，通过结合来自单个X射线图像的互补信息，完成三维超声中被遮挡的脊柱解剖结构。

Result: 与当前最先进的三维超声椎体重建方法相比，我们的方法在椎体重建上显示出显著改进，且在未来的临床转化中成功实现了更准确的腰椎可视化。

Conclusion: 本研究展示了结合X射线影像能有效克服超声在脊柱结构可视化中的限制，并提升了三维脊柱重建的准确性和完整性。

Abstract: Ultrasound offers a radiation-free, cost-effective solution for real-time visualization of spinal landmarks, paraspinal soft tissues and neurovascular structures, making it valuable for intraoperative guidance during spinal procedures. However, ultrasound suffers from inherent limitations in visualizing complete vertebral anatomy, in particular vertebral bodies, due to acoustic shadowing effects caused by bone. In this work, we present a novel multi-modal deep learning method for completing occluded anatomical structures in 3D ultrasound by leveraging complementary information from a single X-ray image. To enable training, we generate paired training data consisting of: (1) 2D lateral vertebral views that simulate X-ray scans, and (2) 3D partial vertebrae representations that mimic the limited visibility and occlusions encountered during ultrasound spine imaging. Our method integrates morphological information from both imaging modalities and demonstrates significant improvements in vertebral reconstruction (p < 0.001) compared to state of art in 3D ultrasound vertebral completion. We perform phantom studies as an initial step to future clinical translation, and achieve a more accurate, complete volumetric lumbar spine visualization overlayed on the ultrasound scan without the need for registration with preoperative modalities such as computed tomography. This demonstrates that integrating a single X-ray projection mitigates ultrasound's key limitation while preserving its strengths as the primary imaging modality. Code and data can be found at https://github.com/miruna20/US-X-Complete

</details>


### [71] [Transferable Dual-Domain Feature Importance Attack against AI-Generated Image Detector](https://arxiv.org/abs/2511.15571)
*Weiheng Zhu,Gang Cao,Jing Liu,Lifang Yu,Shaowei Weng*

Main category: cs.CV

TL;DR: 本文提出DuFIA方案，通过联合建模特征重要性，有效攻击AI生成图像检测器，表现出良好的迁移性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 开发先进的对抗攻击以评估AI生成图像检测器的安全性，填补研究空白。

Method: 采用空间插值梯度和频率意识扰动捕捉法医重要特征，通过联合建模空间和频率域特征重要性，指导对抗样本的生成。

Result: 通过广泛的实验验证了DuFIA在各种AIGI检测器上的跨模型迁移性和鲁棒性。

Conclusion: DuFIA有效地攻击了AI生成图像检测器，展示了良好的跨模型迁移性、透明性和鲁棒性。

Abstract: Recent AI-generated image (AIGI) detectors achieve impressive accuracy under clean condition. In view of antiforensics, it is significant to develop advanced adversarial attacks for evaluating the security of such detectors, which remains unexplored sufficiently. This letter proposes a Dual-domain Feature Importance Attack (DuFIA) scheme to invalidate AIGI detectors to some extent. Forensically important features are captured by the spatially interpolated gradient and frequency-aware perturbation. The adversarial transferability is enhanced by jointly modeling spatial and frequency-domain feature importances, which are fused to guide the optimization-based adversarial example generation. Extensive experiments across various AIGI detectors verify the cross-model transferability, transparency and robustness of DuFIA.

</details>


### [72] [From Low-Rank Features to Encoding Mismatch: Rethinking Feature Distillation in Vision Transformers](https://arxiv.org/abs/2511.15572)
*Huiyuan Tian,Bonan Xu,Shijian Li,Xin Jin*

Main category: cs.CV

TL;DR: 通过对ViT模型的分析，提出两种方法有效改善其特征蒸馏性能，说明低秩结构的利用可以促进紧凑型ViTs的设计。


<details>
  <summary>Details</summary>
Motivation: 为了理解视觉变换器在特征图知识蒸馏中的失败，并为方法设计提供指导。

Method: 进行层次奇异值分解（SVD）和令牌级谱能量模式（SEP）分析，以研究视觉变换器的表示能力。

Result: 提出了两种针对特征映射蒸馏失败的策略，实验证明这些策略能够显著提高ViT模型在ImageNet-1K数据集上的准确率。

Conclusion: 通过引入令牌级别的谱能量模式（SEP）分析，我们揭示了视觉变换器（ViT）特征蒸馏失败的原因，并提出了两种有效的对策，这些对策能够利用低秩结构并改善特征映射蒸馏的效果。

Abstract: Feature-map knowledge distillation (KD) is highly effective for convolutional networks but often fails for Vision Transformers (ViTs). To understand this failure and guide method design, we conduct a two-view representation analysis of ViTs. First, a layer-wise Singular Value Decomposition (SVD) of full feature matrices shows that final-layer representations are globally low-rank: for CaiT-S24, only $121/61/34/14$ dimensions suffice to capture $99\%/95\%/90\%/80\%$ of the energy. In principle, this suggests that a compact student plus a simple linear projector should be enough for feature alignment, contradicting the weak empirical performance of standard feature KD. To resolve this paradox, we introduce a token-level Spectral Energy Pattern (SEP) analysis that measures how each token uses channel capacity. SEP reveals that, despite the global low-rank structure, individual tokens distribute energy over most channels, forming a high-bandwidth encoding pattern. This results in an encoding mismatch between wide teachers and narrow students. Motivated by this insight, we propose two minimal, mismatch-driven strategies: (1) post-hoc feature lifting with a lightweight projector retained during inference, or (2) native width alignment that widens only the student's last block to the teacher's width. On ImageNet-1K, these strategies reactivate simple feature-map distillation in ViTs, raising DeiT-Tiny accuracy from $74.86\%$ to $77.53\%$ and $78.23\%$ when distilling from CaiT-S24, while also improving standalone students trained without any teacher. Our analysis thus explains why ViT feature distillation fails and shows how exploiting low-rank structure yields effective, interpretable remedies and concrete design guidance for compact ViTs.

</details>


### [73] [Learning from Mistakes: Loss-Aware Memory Enhanced Continual Learning for LiDAR Place Recognition](https://arxiv.org/abs/2511.15597)
*Xufei Wang,Junqiao Zhao,Siyue Tao,Qiwen Gu,Wonbong Kim,Tiantian Feng*

Main category: cs.CV

TL;DR: KDF+是一种新颖的持续学习框架，针对LiDAR地点识别中的灾难性遗忘问题，改进了样本选择和记忆重演机制，实现了更优性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统LiDAR地点识别方法在处理新环境时的灾难性遗忘问题。

Method: 提出了一种新的持续学习框架KDF+，包括基于损失的采样策略和重演增强机制。

Result: KDF+通过估计学习难度并优化样本选择，在多个基准上实现了超越现有方法的性能。

Conclusion: KDF+在多项基准测试中表现优于现有的持续学习方法，并可与最新的持续学习框架无缝集成，从而显著提升性能。

Abstract: LiDAR place recognition plays a crucial role in SLAM, robot navigation, and autonomous driving. However, existing LiDAR place recognition methods often struggle to adapt to new environments without forgetting previously learned knowledge, a challenge widely known as catastrophic forgetting. To address this issue, we propose KDF+, a novel continual learning framework for LiDAR place recognition that extends the KDF paradigm with a loss-aware sampling strategy and a rehearsal enhancement mechanism. The proposed sampling strategy estimates the learning difficulty of each sample via its loss value and selects samples for replay according to their estimated difficulty. Harder samples, which tend to encode more discriminative information, are sampled with higher probability while maintaining distributional coverage across the dataset. In addition, the rehearsal enhancement mechanism encourages memory samples to be further refined during new-task training by slightly reducing their loss relative to previous tasks, thereby reinforcing long-term knowledge retention. Extensive experiments across multiple benchmarks demonstrate that KDF+ consistently outperforms existing continual learning methods and can be seamlessly integrated into state-of-the-art continual learning for LiDAR place recognition frameworks to yield significant and stable performance gains. The code will be available at https://github.com/repo/KDF-plus.

</details>


### [74] [RoMa v2: Harder Better Faster Denser Feature Matching](https://arxiv.org/abs/2511.15706)
*Johan Edstedt,David Nordström,Yushan Zhang,Georg Bökman,Jonathan Astermark,Viktor Larsson,Anders Heyden,Fredrik Kahl,Mårten Wadenbäck,Michael Felsberg*

Main category: cs.CV

TL;DR: 本文提出一种新颖的稠密特征匹配模型，通过架构和训练策略的创新，显著提升了匹配精度和速度，设立了新的技术标准。


<details>
  <summary>Details</summary>
Motivation: 解决现有稠密特征匹配方法在现实场景中表现不佳的问题，提升模型的精度与速度。

Method: 构建了新颖的匹配架构和损失函数，采用分离的两阶段匹配与优化管道，利用自定义CUDA内核减少内存使用。

Result: 在广泛的实验中，新的匹配器表现出比其前身更高的准确性，设立了新的技术标准。

Conclusion: 新的匹配模型在复杂匹配任务上表现优越，设立了新的技术标准，准确性显著高于前代方法。

Abstract: Dense feature matching aims to estimate all correspondences between two images of a 3D scene and has recently been established as the gold-standard due to its high accuracy and robustness. However, existing dense matchers still fail or perform poorly for many hard real-world scenarios, and high-precision models are often slow, limiting their applicability. In this paper, we attack these weaknesses on a wide front through a series of systematic improvements that together yield a significantly better model. In particular, we construct a novel matching architecture and loss, which, combined with a curated diverse training distribution, enables our model to solve many complex matching tasks. We further make training faster through a decoupled two-stage matching-then-refinement pipeline, and at the same time, significantly reduce refinement memory usage through a custom CUDA kernel. Finally, we leverage the recent DINOv3 foundation model along with multiple other insights to make the model more robust and unbiased. In our extensive set of experiments we show that the resulting novel matcher sets a new state-of-the-art, being significantly more accurate than its predecessors. Code is available at https://github.com/Parskatt/romav2

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [75] [Test-time Scaling of LLMs: A Survey from A Subproblem Structure Perspective](https://arxiv.org/abs/2511.14772)
*Zhuoyi Yang,Xu Guo,Tong Zhang,Huijuan Xu,Boyang Li*

Main category: cs.CL

TL;DR: 本论文调查了通过在推理时分配额外计算资源来提高预训练大型语言模型预测准确性的技术，并提出了未来研究的方向。


<details>
  <summary>Details</summary>
Motivation: 改善预训练大型语言模型的预测准确性。

Method: 分类测试时间缩放方法，强调问题如何分解为子问题及其拓扑组织（顺序、并行或树结构）。

Result: 统一了多种方法，如Chain-of-Thought、Branch-Solve-Merge和Tree-of-Thought，并总结了它们的优缺点。

Conclusion: 我们概述了在推理时间分配额外计算资源来提高预训练大型语言模型预测准确性的技术，并归纳了未来研究的有希望方向。

Abstract: With this paper, we survey techniques for improving the predictive accuracy of pretrained large language models by allocating additional compute at inference time. In categorizing test-time scaling methods, we place special emphasis on how a problem is decomposed into subproblems and on the topological organization of these subproblems whether sequential, parallel, or tree-structured. This perspective allows us to unify diverse approaches such as Chain-of-Thought, Branch-Solve-Merge, and Tree-of-Thought under a common lens. We further synthesize existing analyses of these techniques, highlighting their respective strengths and weaknesses, and conclude by outlining promising directions for future research

</details>


### [76] [Temporal Predictors of Outcome in Reasoning Language Models](https://arxiv.org/abs/2511.14773)
*Joey David*

Main category: cs.CL

TL;DR: 该研究探讨了大语言模型在推理过程中，内部承诺最终结果的时间点，以及其对可解释性和推理控制的影响。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型 (LLM) 在多早的时候会内部承诺于某个最终结果，以理解推理过程。

Method: 通过在前 t 个推理 token 之后的隐藏状态上训练线性分类器来探测 LLM 内部对最终结果的承诺程度。

Result: 我们发现，只需几个 token 后，最终的正确性就已高度可预测，尽管可能需要更长的输出才能得到明确答案。并且对于难题，预测准确度的下降指示出选择伪影：困难项目在较长的 CoT 中的表现过于突出。

Conclusion: 我们的结果表明，对于推理模型，内部自我评估成功的能力在仅仅几个 token 后即出现，这对可解释性和推理时间控制具有重要影响。

Abstract: The chain-of-thought (CoT) paradigm uses the elicitation of step-by-step rationales as a proxy for reasoning, gradually refining the model's latent representation of a solution. However, it remains unclear just how early a Large Language Model (LLM) internally commits to an eventual outcome. We probe this by training linear classifiers on hidden states after the first t reasoning tokens, showing that eventual correctness is highly predictable after only a few tokens, even when longer outputs are needed to reach a definite answer. We show that, for harder questions, a drop in predictive accuracy highlights a selection artifact: hard items are disproportionately represented in long CoTs. Overall, our results imply that for reasoning models, internal self-assessment of success tends to emerge after only a few tokens, with implications for interpretability and for inference-time control.

</details>


### [77] [LiveCLKTBench: Towards Reliable Evaluation of Cross-Lingual Knowledge Transfer in Multilingual LLMs](https://arxiv.org/abs/2511.14774)
*Pei-Fu Guo,Yun-Da Tsai,Chun-Chia Hsu,Kai-Xin Chen,Ya-An Tsai,Kai-Wei Chang,Nanyun Peng,Mi-Yen Yeh,Shou-De Lin*

Main category: cs.CL

TL;DR: 本研究使用LiveCLKTBench评估大型语言模型中的跨语言知识转移，发现语言距离影响转移效果，且模型大小效应递减，是未来多语言研究的重要基准。


<details>
  <summary>Details</summary>
Motivation: To address challenges in evaluating cross-lingual knowledge transfer in large language models and to distinguish genuine transfer from pre-training exposure.

Method: An automated generation pipeline called LiveCLKTBench was used to isolate and measure cross-lingual knowledge transfer by generating and verifying factual questions across multiple languages.

Result: Evaluation of several LLMs across five languages showed that cross-lingual transfer is affected by linguistic distance, with varying effects depending on model size and language direction.

Conclusion: Cross-lingual knowledge transfer in large language models is influenced by linguistic distance and model size, revealing asymmetries depending on language direction. LiveCLKTBench serves as an effective benchmark for future multilingual research.

Abstract: Evaluating cross-lingual knowledge transfer in large language models is challenging, as correct answers in a target language may arise either from genuine transfer or from prior exposure during pre-training. We present LiveCLKTBench, an automated generation pipeline specifically designed to isolate and measure cross-lingual knowledge transfer. Our pipeline identifies self-contained, time-sensitive knowledge entities from real-world domains, filters them based on temporal occurrence, and verifies them against the model's knowledge. The documents of these valid entities are then used to generate factual questions, which are translated into multiple languages to evaluate transferability across linguistic boundaries. Using LiveCLKTBench, we evaluate several LLMs across five languages and observe that cross-lingual transfer is strongly influenced by linguistic distance and often asymmetric across language directions. While larger models improve transfer, the gains diminish with scale and vary across domains. These findings provide new insights into multilingual transfer and demonstrate the value of LiveCLKTBench as a reliable benchmark for future research.

</details>


### [78] [COMPASS: Context-Modulated PID Attention Steering System for Hallucination Mitigation](https://arxiv.org/abs/2511.14776)
*Snigdha Pandya,Rohan Nagale,Kenji Sahay,Anna Lin,Shikhar Shiromani,Kevin Zhu,Dev Sunishchal*

Main category: cs.CL

TL;DR: 本文提出COMPASS框架，通过反馈控制动态调整注意力头，降低大语言模型的事实错误率并增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 针对大语言模型生成流畅但事实错误的陈述进行改进，提升模型的可信性和可解释性。

Method: 提出COMPASS框架，通过一个模型反馈循环调整注意力头，来维持生成结果的事实一致性。

Result: COMPASS在多个基准测试中减少了上下文幻觉率，并揭示了不同注意力头在证据对齐中的作用。

Conclusion: COMPASS有效降低了大语言模型的上下文幻觉率，并提升了对模型行为的科学理解。

Abstract: Large language models (LLMs) often generate fluent but factually incorrect statements despite having access to relevant evidence, a failure mode rooted in how they allocate attention between contextual and parametric knowledge. Understanding and steering this internal behavior is key both for trustworthy deployment and for scientific interpretability of model mechanisms. We introduce COMPASS (Context-Modulated PID Attention Steering System), a lightweight, interpretable control framework that embeds a model-based feedback loop directly within decoding. COMPASS quantifies context reliance via a transparent metric, the Context Reliance Score (CRS), which serves as an online probe of how attention heads ground generation in evidence. Using this interpretable signal, a PID controller dynamically modulates attention heads to maintain factual consistency without retraining or multi-pass decoding. Across benchmarks (HotpotQA, XSum, HaluEval, RAGTruth), COMPASS consistently reduces contextual hallucination rates (2.8 to 5.8 percent absolute) while revealing how distinct attention heads contribute to evidence alignment. These results highlight feedback-driven interpretability as a pathway toward scientific understanding of LLM behavior.

</details>


### [79] [The Impact of Prosodic Segmentation on Speech Synthesis of Spontaneous Speech](https://arxiv.org/abs/2511.14779)
*Julio Cesar Galdino,Sidney Evaldo Leal,Leticia Gabriella De Souza,Rodrigo de Freitas Lima,Antonio Nelson Fornari Mendes Moreira,Arnaldo Candido Junior,Miguel Oliveira,Edresson Casanova,Sandra M. Aluísio*

Main category: cs.CL

TL;DR: 本研究评估了韵律分段注释对自发语音合成质量的影响，发现手动分段比自动分段更能有效提升合成语音的自然性和可懂度。


<details>
  <summary>Details</summary>
Motivation: 探讨在自发语音合成中，韵律特征的显式分段对合成语音质量的影响，尤其是当前研究对这一领域的忽视。

Method: 通过评估手动和自动的韵律分段注释对使用非自回归模型FastSpeech 2合成的语音质量的影响进行实验。

Result: 实验结果表明，使用韵律分段训练的语音合成模型产生的语音更易懂且听起来更自然，手动分段引入了更多的变化，从而提升了韵律的自然性。

Conclusion: 手动和自动的韵律分段注释在巴西葡萄牙语的自发语音合成中对合成语音的质量有显著影响，手动分段所产生的变化使语音听起来更自然。

Abstract: Spontaneous speech presents several challenges for speech synthesis, particularly in capturing the natural flow of conversation, including turn-taking, pauses, and disfluencies. Although speech synthesis systems have made significant progress in generating natural and intelligible speech, primarily through architectures that implicitly model prosodic features such as pitch, intensity, and duration, the construction of datasets with explicit prosodic segmentation and their impact on spontaneous speech synthesis remains largely unexplored. This paper evaluates the effects of manual and automatic prosodic segmentation annotations in Brazilian Portuguese on the quality of speech synthesized by a non-autoregressive model, FastSpeech 2. Experimental results show that training with prosodic segmentation produced slightly more intelligible and acoustically natural speech. While automatic segmentation tends to create more regular segments, manual prosodic segmentation introduces greater variability, which contributes to more natural prosody. Analysis of neutral declarative utterances showed that both training approaches reproduced the expected nuclear accent pattern, but the prosodic model aligned more closely with natural pre-nuclear contours. To support reproducibility and future research, all datasets, source codes, and trained models are publicly available under the CC BY-NC-ND 4.0 license.

</details>


### [80] [Human or LLM as Standardized Patients? A Comparative Study for Medical Education](https://arxiv.org/abs/2511.14783)
*Bingquan Zhang,Xiaoxiao Liu,Yuchi Wang,Lei Zhou,Qianqian Xie,Benyou Wang*

Main category: cs.CL

TL;DR: EasyMED is a multi-agent framework for clinical training that offers comparable learning outcomes to human SP while being more cost-effective and flexible.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of traditional Standardized Patients in clinical skills training, including cost, inflexibility, and scalability.

Method: Developed a multi-agent framework combining Patient Agent, Auxiliary Agent, and Evaluation Agent, and introduced SPBench for systematic assessment.

Result: EasyMED showed comparable outcomes to human SP and enhanced skill gains, particularly for lower-baseline students, while improving flexibility and cost efficiency.

Conclusion: EasyMED effectively matches human SP learning outcomes while demonstrating advantages for lower-baseline students in skill improvement, flexibility, and cost.

Abstract: Standardized Patients (SP) are indispensable for clinical skills training but remain expensive, inflexible, and difficult to scale. Existing large-language-model (LLM)-based SP simulators promise lower cost yet show inconsistent behavior and lack rigorous comparison with human SP. We present EasyMED, a multi-agent framework combining a Patient Agent for realistic dialogue, an Auxiliary Agent for factual consistency, and an Evaluation Agent that delivers actionable feedback. To support systematic assessment, we introduce SPBench, a benchmark of real SP-doctor interactions spanning 14 specialties and eight expert-defined evaluation criteria. Experiments demonstrate that EasyMED matches human SP learning outcomes while producing greater skill gains for lower-baseline students and offering improved flexibility, psychological safety, and cost efficiency.

</details>


### [81] [NAMeGEn: Creative Name Generation via A Novel Agent-based Multiple Personalized Goal Enhancement Framework](https://arxiv.org/abs/2511.15408)
*Shanlin Zhou,Xinpeng Wang,Jianxun Lian,Zhenghao Liu,Laks V. S. Lakshmanan,Xiaoyuan Yi,Yongtao Hao*

Main category: cs.CL

TL;DR: This paper proposes NAMeGEn, a method for generating creative Chinese baby names that meets personalized user requirements and offers aesthetic explanations, demonstrating its effectiveness over existing approaches.


<details>
  <summary>Details</summary>
Motivation: To tackle the challenges of multi-objective flexibility and interpretive complexity in creative natural language generation, specifically in the context of Chinese baby naming.

Method: A multi-agent optimization framework that alternates between objective extraction, name generation, and evaluation.

Result: NAMeGEn generates names that meet diverse requirements and provides aesthetic explanations, outperforming six baseline methods without any prior training.

Conclusion: NAMeGEn demonstrates effective generation of creative names with meaningful explanations, outperforming existing methods.

Abstract: Trained on diverse human-authored texts, Large Language Models (LLMs) unlocked the potential for Creative Natural Language Generation (CNLG), benefiting various applications like advertising and storytelling. Nevertheless, CNLG still remains difficult due to two main challenges. (1) Multi-objective flexibility: user requirements are often personalized, fine-grained, and pluralistic, which LLMs struggle to satisfy simultaneously; (2) Interpretive complexity: beyond generation, creativity also involves understanding and interpreting implicit meaning to enhance users' perception. These challenges significantly limit current methods, especially in short-form text generation, in generating creative and insightful content. To address this, we focus on Chinese baby naming, a representative short-form CNLG task requiring adherence to explicit user constraints (e.g., length, semantics, anthroponymy) while offering meaningful aesthetic explanations. We propose NAMeGEn, a novel multi-agent optimization framework that iteratively alternates between objective extraction, name generation, and evaluation to meet diverse requirements and generate accurate explanations. To support this task, we further construct a classical Chinese poetry corpus with 17k+ poems to enhance aesthetics, and introduce CBNames, a new benchmark with tailored metrics. Extensive experiments demonstrate that NAMeGEn effectively generates creative names that meet diverse, personalized requirements while providing meaningful explanations, outperforming six baseline methods spanning various LLM backbones without any training.

</details>


### [82] [Hierarchical Token Prepending: Enhancing Information Flow in Decoder-based LLM Embeddings](https://arxiv.org/abs/2511.14868)
*Xueying Ding,Xingyue Huang,Mingxuan Ju,Liam Collins,Yozen Liu,Leman Akoglu,Neil Shah,Tong Zhao*

Main category: cs.CL

TL;DR: HTP improves long-document embeddings in language models by enhancing information flow and reducing over-compression.


<details>
  <summary>Details</summary>
Motivation: To improve the quality of text embeddings produced by language models, particularly for long documents where traditional methods fail.

Method: Hierarchical Token Prepending (HTP) partitions the input into blocks and uses block-level summary tokens along with mean-pooling at readout level.

Result: HTP consistently outperforms existing methods on 11 retrieval datasets and 30 general embedding benchmarks, especially in long-context scenarios.

Conclusion: HTP is an effective method that enhances the performance of language models on long documents by addressing attention-level compression and readout-level over-squashing.

Abstract: Large language models produce powerful text embeddings, but their causal attention mechanism restricts the flow of information from later to earlier tokens, degrading representation quality. While recent methods attempt to solve this by prepending a single summary token, they over-compress information, hence harming performance on long documents. We propose Hierarchical Token Prepending (HTP), a method that resolves two critical bottlenecks. To mitigate attention-level compression, HTP partitions the input into blocks and prepends block-level summary tokens to subsequent blocks, creating multiple pathways for backward information flow. To address readout-level over-squashing, we replace last-token pooling with mean-pooling, a choice supported by theoretical analysis. HTP achieves consistent performance gains across 11 retrieval datasets and 30 general embedding benchmarks, especially in long-context settings. As a simple, architecture-agnostic method, HTP enhances both zero-shot and finetuned models, offering a scalable route to superior long-document embeddings.

</details>


### [83] [Mathematical Analysis of Hallucination Dynamics in Large Language Models: Uncertainty Quantification, Advanced Decoding, and Principled Mitigation](https://arxiv.org/abs/2511.15005)
*Moses Kiprono*

Main category: cs.CL

TL;DR: 本文提出一个框架，理解并减轻大型语言模型的幻觉，通过多种方法增强其可靠性。


<details>
  <summary>Details</summary>
Motivation: 希望理解、测量并降低大型语言模型所产生的幻觉现象。

Method: 使用概率建模、信息理论、三角信号分析和贝叶斯不确定性估计等方法。

Result: 分析了错误如何自回归地累积，提出了改进的不确定性度量，并开发了对策。

Conclusion: 提出了一个统一的框架，以分析和减少大型语言模型的幻觉现象，以提高其可靠性和安全性。

Abstract: Large Language Models (LLMs) are powerful linguistic engines but remain susceptible to hallucinations: plausible-sounding outputs that are factually incorrect or unsupported. In this work, we present a mathematically grounded framework to understand, measure, and mitigate these hallucinations. Drawing on probabilistic modeling, information theory, trigonometric signal analysis, and Bayesian uncertainty estimation, we analyze how errors compound autoregressively, propose refined uncertainty metrics, including semantic and phase-aware variants, and develop principled mitigation strategies such as contrastive decoding, retrieval-augmented grounding, factual alignment, and abstention. This unified lens connects recent advances in calibration, retrieval, and alignment to support safer and more reliable LLMs.

</details>


### [84] [Teaching According to Students' Aptitude: Personalized Mathematics Tutoring via Persona-, Memory-, and Forgetting-Aware LLMs](https://arxiv.org/abs/2511.15163)
*Yang Wu,Rujing Yao,Tong Zhang,Yufei Shi,Zhuoren Jiang,Zhushan Li,Xiaozhong Liu*

Main category: cs.CL

TL;DR: TASA框架通过建模学生的个性化特征和遗忘动态，提升了数学学习的效果和辅导的适应性。


<details>
  <summary>Details</summary>
Motivation: 现有的智能辅导系统未能有效捕捉学生知识的动态演变，尤其在数学辅导中，需要根据学生的掌握程度和遗忘模式进行精细化的指导。

Method: 提出了TASA框架，集成了学生个性化特点、记忆和遗忘动态，以实现个性化的数学学习。

Result: TASA在学习效果和适应性辅导行为上超越了代表性基线，强调了对遗忘动态和学习者特征建模的重要性。

Conclusion: TASA在基于大语言模型的教育系统中，通过建模遗忘动态和学习者特征，实现了更优的学习成果和更具适应性的辅导行为。

Abstract: Large Language Models (LLMs) are increasingly integrated into intelligent tutoring systems to provide human-like and adaptive instruction. However, most existing approaches fail to capture how students' knowledge evolves dynamically across their proficiencies, conceptual gaps, and forgetting patterns. This challenge is particularly acute in mathematics tutoring, where effective instruction requires fine-grained scaffolding precisely calibrated to each student's mastery level and cognitive retention. To address this issue, we propose TASA (Teaching According to Students' Aptitude), a student-aware tutoring framework that integrates persona, memory, and forgetting dynamics for personalized mathematics learning. Specifically, TASA maintains a structured student persona capturing proficiency profiles and an event memory recording prior learning interactions. By incorporating a continuous forgetting curve with knowledge tracing, TASA dynamically updates each student's mastery state and generates contextually appropriate, difficulty-calibrated questions and explanations. Empirical results demonstrate that TASA achieves superior learning outcomes and more adaptive tutoring behavior compared to representative baselines, underscoring the importance of modeling temporal forgetting and learner profiles in LLM-based tutoring systems.

</details>


### [85] [HinTel-AlignBench: A Framework and Benchmark for Hindi-Telugu with English-Aligned Samples](https://arxiv.org/abs/2511.15183)
*Rishikant Chigrupaatii,Ponnada Sai Tulasi Kanishka,Lalit Chandra Routhu,Martin Patel Sama Supratheek Reddy,Divyam Gupta,Dasari Srikar,Krishna Teja Kuchimanchi,Rajiv Misra,Rohun Tripathi*

Main category: cs.CL

TL;DR: 本文提出了一种评估印度语言视觉-语言模型的新框架，创建了HinTel-AlignBench基准，并发现英语和印地语言任务的表现存在显著差异，突显了改进的必要性。


<details>
  <summary>Details</summary>
Motivation: 随着多语言视觉-语言模型的日益普及，为低资源语言推动公平AI，强有力的评估方法显得尤为重要。

Method: 我们提出了一种可扩展的框架来评估印度语言的视觉-语言模型（VLM），并生成了HinTel-AlignBench基准，包括来自印地语和泰卢固语的多样化来源，且与英语样本对齐。

Result: 通过该框架，我们创建了一个半自动化的数据集生成框架，构建了涵盖印地语和泰卢固语的最新视语言基准，并进行了一系列现有开放权重和闭源VLM的性能分析。

Conclusion: 我们发现，在所有模型中，针对印度语言任务的表现普遍较差，相较于英语的任务表现，平均下降8.3分（印地语）和5.5分（泰卢固语）。

Abstract: With nearly 1.5 billion people and more than 120 major languages, India represents one of the most diverse regions in the world. As multilingual Vision-Language Models (VLMs) gain prominence, robust evaluation methodologies are essential to drive progress toward equitable AI for low-resource languages. Current multilingual VLM evaluations suffer from four major limitations: reliance on unverified auto-translations, narrow task/domain coverage, limited sample sizes, and lack of cultural and natively sourced Question-Answering (QA). To address these gaps, we present a scalable framework to evaluate VLMs in Indian languages and compare it with performance in English. Using the framework, we generate HinTel-AlignBench, a benchmark that draws from diverse sources in Hindi and Telugu with English-aligned samples. Our contributions are threefold: (1) a semi-automated dataset creation framework combining back-translation, filtering, and human verification; (2) the most comprehensive vision-language benchmark for Hindi and and Telugu, including adapted English datasets (VQAv2, RealWorldQA, CLEVR-Math) and native novel Indic datasets (JEE for STEM, VAANI for cultural grounding) with approximately 4,000 QA pairs per language; and (3) a detailed performance analysis of various State-of-the-Art (SOTA) open-weight and closed-source VLMs. We find a regression in performance for tasks in English versus in Indian languages for 4 out of 5 tasks across all the models, with an average regression of 8.3 points in Hindi and 5.5 points for Telugu. We categorize common failure modes to highlight concrete areas of improvement in multilingual multimodal understanding.

</details>


### [86] [Unveiling Intrinsic Dimension of Texts: from Academic Abstract to Creative Story](https://arxiv.org/abs/2511.15210)
*Vladislav Pedashenko,Laida Kushnareva,Yana Khassan Nibal,Eduard Tulchinskii,Kristian Kuznetsov,Vladislav Zharchinskii,Yury Maximov,Irina Piontkovskaya*

Main category: cs.CL

TL;DR: 本研究系统探讨了内在维度在文本特性中的角色，发现ID与文本类型和特征密切相关，为适当使用和解释ID提供了指导。


<details>
  <summary>Details</summary>
Motivation: 探讨内在维度(ID)在现代大语言模型分析中的文本决定因素及其对训练动态、扩展行为和数据集结构的影响。

Method: 通过交叉编码分析、语言特征和稀疏自编码器(SAE)进行研究。

Result: 确定了三个关键发现：ID与熵基度量互补，ID在各类文本中存在显著的流派分层，以及识别出因果特征。

Conclusion: 科学写作在现代语言模型中被视为相对简单，而小说、观点和情感写作则提供了更多的表现自由度。

Abstract: Intrinsic dimension (ID) is an important tool in modern LLM analysis, informing studies of training dynamics, scaling behavior, and dataset structure, yet its textual determinants remain underexplored. We provide the first comprehensive study grounding ID in interpretable text properties through cross-encoder analysis, linguistic features, and sparse autoencoders (SAEs). In this work, we establish three key findings. First, ID is complementary to entropy-based metrics: after controlling for length, the two are uncorrelated, with ID capturing geometric complexity orthogonal to prediction quality. Second, ID exhibits robust genre stratification: scientific prose shows low ID (~8), encyclopedic content medium ID (~9), and creative/opinion writing high ID (~10.5) across all models tested. This reveals that contemporary LLMs find scientific text "representationally simple" while fiction requires additional degrees of freedom. Third, using SAEs, we identify causal features: scientific signals (formal tone, report templates, statistics) reduce ID; humanized signals (personalization, emotion, narrative) increase it. Steering experiments confirm these effects are causal. Thus, for contemporary models, scientific writing appears comparatively "easy", whereas fiction, opinion, and affect add representational degrees of freedom. Our multi-faceted analysis provides practical guidance for the proper use of ID and the sound interpretation of ID-based results.

</details>


### [87] [OEMA: Ontology-Enhanced Multi-Agent Collaboration Framework for Zero-Shot Clinical Named Entity Recognition](https://arxiv.org/abs/2511.15211)
*Xinli Tao,Xin Dong,Xuezhong Zhou*

Main category: cs.CL

TL;DR: OEMA是一个基于多智能体协作的零样本临床实体识别框架，克服了传统方法的限制，表现接近监督学习。


<details>
  <summary>Details</summary>
Motivation: 由于监督模型需要昂贵的标注数据，开发零样本NER的方法成为需求，以减少对标注数据的依赖并提高效率。

Method: 提出OEM框架，包括自标注生成示例、使用SNOMED CT的过滤器与基于实体描述的预测器，进行多智能体协作来实现零样本临床NER。

Result: 在MTSamples和VAERS数据集上，OEMA达到了最先进的精确匹配性能，在相关匹配下匹敌监督的BioClinicalBERT并超越CRF。

Conclusion: OEMA通过本体引导推理和多智能体协作，克服了零样本NER的关键挑战，达到了接近监督学习的表现，并展示了在临床NLP应用中的潜力。

Abstract: Clinical named entity recognition (NER) is crucial for extracting information from electronic health records (EHRs), but supervised models like CRF and BioClinicalBERT require costly annotated data. While zero-shot NER with large language models (LLMs) reduces this dependency, it struggles with example selection granularity and integrating prompts with self-improvement. To address this, we propose OEMA, a zero-shot clinical NER framework using multi-agent collaboration. OEMA's three components are: a self-annotator generating examples, a discriminator filtering them via SNOMED CT, and a predictor using entity descriptions for accurate inference. On MTSamples and VAERS datasets, OEMA achieves state-of-the-art exact-match performance. Under related-match, it matches supervised BioClinicalBERT and surpasses CRF. OEMA addresses key zero-shot NER challenges through ontology-guided reasoning and multi-agent collaboration, achieving near-supervised performance and showing promise for clinical NLP applications.

</details>


### [88] [Context Cascade Compression: Exploring the Upper Limits of Text Compression](https://arxiv.org/abs/2511.15244)
*Fanfan Liu,Haibo Qiu*

Main category: cs.CL

TL;DR: C3 Compression通过级联不同大小的LLM实现高效文本压缩，在高压缩比下保持高解码准确率，优于此前的光学字符压缩方法。


<details>
  <summary>Details</summary>
Motivation: 针对大规模上下文任务中百万级令牌输入带来的计算和内存挑战，探索文本压缩的上限。

Method: 通过级联两个不同大小的LLM进行文本压缩和解码。

Result: C3方法在20倍和40倍压缩比下分别实现98%和93%的解码准确率，优于DeepSeek-OCR的表现。

Conclusion: C3 Compression在文本压缩领域表现优越，提出了文本压缩的新方法，并在高压缩比下实现了高解码准确率。

Abstract: Million-level token inputs in long-context tasks pose significant computational and memory challenges for Large Language Models (LLMs). Recently, DeepSeek-OCR conducted research into the feasibility of Contexts Optical Compression and achieved preliminary results. Inspired by this, we introduce Context Cascade Compression C3 to explore the upper limits of text compression. Our method cascades two LLMs of different sizes to handle the compression and decoding tasks. Specifically, a small LLM, acting as the first stage, performs text compression by condensing a long context into a set of latent tokens (e.g., 32 or 64 in length), achieving a high ratio of text tokens to latent tokens. A large LLM, as the second stage, then executes the decoding task on this compressed context. Experiments show that at a 20x compression ratio (where the number of text tokens is 20 times the number of latent tokens), our model achieves 98% decoding accuracy, compared to approximately 60% for DeepSeek-OCR. When we further increase the compression ratio to 40x, the accuracy is maintained at around 93%. This indicates that in the domain of context compression, C3 Compression demonstrates superior performance and feasibility over optical character compression. C3 uses a simpler, pure-text pipeline that ignores factors like layout, color, and information loss from a visual encoder. This also suggests a potential upper bound for compression ratios in future work on optical character compression, OCR, and related fields. Codes and model weights are publicly accessible at https://github.com/liufanfanlff/C3-Context-Cascade-Compression

</details>


### [89] [IndicGEC: Powerful Models, or a Measurement Mirage?](https://arxiv.org/abs/2511.15260)
*Sowmya Vajjala*

Main category: cs.CL

TL;DR: 本研究展示了小型语言模型在印度语法错误纠正中的有效性，并探讨了数据质量和评估标准的重要性。


<details>
  <summary>Details</summary>
Motivation: 为了解决印度语言的语法错误纠正问题，提高模型在多种印度语言上的表现。

Method: 通过对不同大小的语言模型进行零样本/少样本提示，进行实验和评估。

Result: 在泰卢固语和印地语中分别获得了第4和第2名，GLEU得分分别为83.78和84.31，并扩展了对其他三种语言的实验。

Conclusion: 我们的方法展示了小型语言模型在印度语言语法错误纠正任务中的潜力，同时强调了数据质量和评估指标的重要性。

Abstract: In this paper, we report the results of the TeamNRC's participation in the BHASHA-Task 1 Grammatical Error Correction shared task https://github.com/BHASHA-Workshop/IndicGEC2025/ for 5 Indian languages. Our approach, focusing on zero/few-shot prompting of language models of varying sizes (4B to large proprietary models) achieved a Rank 4 in Telugu and Rank 2 in Hindi with GLEU scores of 83.78 and 84.31 respectively. In this paper, we extend the experiments to the other three languages of the shared task - Tamil, Malayalam and Bangla, and take a closer look at the data quality and evaluation metric used. Our results primarily highlight the potential of small language models, and summarize the concerns related to creating good quality datasets and appropriate metrics for this task that are suitable for Indian language scripts.

</details>


### [90] [MAPROC at AHaSIS Shared Task: Few-Shot and Sentence Transformer for Sentiment Analysis of Arabic Hotel Reviews](https://arxiv.org/abs/2511.15291)
*Randa Zarnoufi*

Main category: cs.CL

TL;DR: 该论文探讨了在阿拉伯方言情感分析中应用少样本学习技术的有效性，尤其是在酒店评论领域。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯方言的情感分析面临语言多样性和标注数据匮乏的重大挑战。

Method: 采用SetFit（句子转换器微调）框架，这是一种数据高效的少样本学习技术。

Result: 在官方评估集中，我们的系统达到了73%的F1分数，在26个参与者中排名第12。

Conclusion: 本研究展示了在酒店评论这一特定领域中，少样本学习技术在处理阿拉伯方言情感分析时的潜力。

Abstract: Sentiment analysis of Arabic dialects presents significant challenges due to linguistic diversity and the scarcity of annotated data. This paper describes our approach to the AHaSIS shared task, which focuses on sentiment analysis on Arabic dialects in the hospitality domain. The dataset comprises hotel reviews written in Moroccan and Saudi dialects, and the objective is to classify the reviewers sentiment as positive, negative, or neutral. We employed the SetFit (Sentence Transformer Fine-tuning) framework, a data-efficient few-shot learning technique. On the official evaluation set, our system achieved an F1 of 73%, ranking 12th among 26 participants. This work highlights the potential of few-shot learning to address data scarcity in processing nuanced dialectal Arabic text within specialized domains like hotel reviews.

</details>


### [91] [Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models](https://arxiv.org/abs/2511.15304)
*Piercosma Bisconti,Matteo Prandi,Federico Pierucci,Francesco Giarrusso,Marcantonio Bracale,Marcello Galisai,Vincenzo Suriani,Olga Sorokoletova,Federico Sartore,Daniele Nardi*

Main category: cs.CL

TL;DR: 对抗性诗歌在大型语言模型中表现出高效的越狱效果，提示了当前安全机制的局限性。


<details>
  <summary>Details</summary>
Motivation: 探索诗歌形式如何影响大型语言模型的安全性，了解其在越狱技术中的有效性。

Method: 通过设计诗意提示对25个前沿大语言模型进行实验，评估其在不同领域的攻击成功率，并与人类验证的结果进行比较。

Result: 使用诗意提示能显著提高攻击成功率，手工创作的诗歌成功率平均为62%，而标准化的转换结果为43%，远高于非诗意的对照组。

Conclusion: 研究表明，对抗性诗歌作为一种普遍的单轮越狱技术，在多种大型语言模型中表现出高效的攻击成功率，揭示了当前安全机制存在的根本性局限。

Abstract: We present evidence that adversarial poetry functions as a universal single-turn jailbreak technique for large language models (LLMs). Across 25 frontier proprietary and open-weight models, curated poetic prompts yielded high attack-success rates (ASR), with some providers exceeding 90%. Mapping prompts to MLCommons and EU CoP risk taxonomies shows that poetic attacks transfer across CBRN, manipulation, cyber-offence, and loss-of-control domains. Converting 1,200 MLCommons harmful prompts into verse via a standardized meta-prompt produced ASRs up to 18 times higher than their prose baselines. Outputs are evaluated using an ensemble of open-weight judge models and a human-validated stratified subset (with double-annotations to measure agreement). Disagreements were manually resolved. Poetic framing achieved an average jailbreak success rate of 62% for hand-crafted poems and approximately 43% for meta-prompt conversions (compared to non-poetic baselines), substantially outperforming non-poetic baselines and revealing a systematic vulnerability across model families and safety training approaches. These findings demonstrate that stylistic variation alone can circumvent contemporary safety mechanisms, suggesting fundamental limitations in current alignment methods and evaluation protocols.

</details>


### [92] [HEAD-QA v2: Expanding a Healthcare Benchmark for Reasoning](https://arxiv.org/abs/2511.15355)
*Alexis Correa-Guillén,Carlos Gómez-Rodríguez,David Vilares*

Main category: cs.CL

TL;DR: HEAD-QA v2 是一个扩展的西班牙语/英语医疗推理数据集，包含超过12,000个问题，并验证了多种大语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 回应对捕捉医疗推理语言和概念复杂性高质量数据集的增长需求。

Method: 通过扩展数据集并基准测试多个开源大语言模型 (LLMs)，采用提示、RAG 和基于概率的答案选择。

Result: 扩展至超过12,000个问题，发现性能主要受模型规模和内在推理能力的驱动，复杂推理策略获得的提升有限。

Conclusion: HEAD-QA v2 是提升生物医学推理研究和模型改进的可靠资源。

Abstract: We introduce HEAD-QA v2, an expanded and updated version of a Spanish/English healthcare multiple-choice reasoning dataset originally released by Vilares and Gómez-Rodríguez (2019). The update responds to the growing need for high-quality datasets that capture the linguistic and conceptual complexity of healthcare reasoning. We extend the dataset to over 12,000 questions from ten years of Spanish professional exams, benchmark several open-source LLMs using prompting, RAG, and probability-based answer selection, and provide additional multilingual versions to support future work. Results indicate that performance is mainly driven by model scale and intrinsic reasoning ability, with complex inference strategies obtaining limited gains. Together, these results establish HEAD-QA v2 as a reliable resource for advancing research on biomedical reasoning and model improvement.

</details>


### [93] [A Compliance-Preserving Retrieval System for Aircraft MRO Task Search](https://arxiv.org/abs/2511.15383)
*Byungho Jo*

Main category: cs.CL

TL;DR: 该研究提出了一种合规的检索系统，显著提高了航空维修技术人员的工作效率，降低了查找时间。


<details>
  <summary>Details</summary>
Motivation: 鉴于航空维修技术人员在查找手册时浪费大量时间，亟需提高效率的解决方案。

Method: 利用大型语言模型的重新排序和语义搜索，结合视觉语言解析，构建修订稳健的嵌入体并在现有的合规性检索系统内操作。

Result: 评估表明，该系统在处理49,000个合成查询时达到了90%以上的检索精度，并在10名持证AMT的双语控制研究中提升了查找成功率和大幅减少查找时间。

Conclusion: 该系统在保持合规性的前提下，显著提高了航空维修技术人员的工作效率和检索精度。

Abstract: Aircraft Maintenance Technicians (AMTs) spend up to 30% of work time searching manuals, a documented efficiency bottleneck in MRO operations where every procedure must be traceable to certified sources. We present a compliance-preserving retrieval system that adapts LLM reranking and semantic search to aviation MRO environments by operating alongside, rather than replacing, certified legacy viewers. The system constructs revision-robust embeddings from ATA chapter hierarchies and uses vision-language parsing to structure certified content, allowing technicians to preview ranked tasks and access verified procedures in existing viewers. Evaluation on 49k synthetic queries achieves >90% retrieval accuracy, while bilingual controlled studies with 10 licensed AMTs demonstrate 90.9% top-10 success rate and 95% reduction in lookup time, from 6-15 minutes to 18 seconds per task. These gains provide concrete evidence that semantic retrieval can operate within strict regulatory constraints and meaningfully reduce operational workload in real-world multilingual MRO workflows.

</details>


### [94] [Building Robust and Scalable Multilingual ASR for Indian Languages](https://arxiv.org/abs/2511.15418)
*Arjun Gangwar,Kaousheik Jayakumar,S. Umesh*

Main category: cs.CL

TL;DR: 本研究开发的 ASR 系统通过多解码器架构显著提高语言和方言识别准确率，超越了基线表现。


<details>
  <summary>Details</summary>
Motivation: 旨在通过在 33 种方言中适应 ASR 系统，以改善对 8 种语言的发音和方言的预测能力。

Method: 采用多解码器架构和音素共标记集作为中间表示的新型训练方法。

Result: 我们的系统在 3 种语言上超越了基线绩效，并在语言和方言识别准确率方面取得了最佳成绩。

Conclusion: 本系统在 Track 2 中在 WER/CER 指标上超越了基线，并在所有参与团队中达到了最高的语言和方言识别准确率。

Abstract: This paper describes the systems developed by SPRING Lab, Indian Institute of Technology Madras, for the ASRU MADASR 2.0 challenge. The systems developed focuses on adapting ASR systems to improve in predicting the language and dialect of the utterance among 8 languages across 33 dialects. We participated in Track 1 and Track 2, which restricts the use of additional data and develop from-the-scratch multilingual systems. We presented a novel training approach using Multi-Decoder architecture with phonemic Common Label Set (CLS) as intermediate representation. It improved the performance over the baseline (in the CLS space). We also discuss various methods used to retain the gain obtained in the phonemic space while converting them back to the corresponding grapheme representations. Our systems beat the baseline in 3 languages (Track 2) in terms of WER/CER and achieved the highest language ID and dialect ID accuracy among all participating teams (Track 2).

</details>


### [95] [LLM-MemCluster: Empowering Large Language Models with Dynamic Memory for Text Clustering](https://arxiv.org/abs/2511.15424)
*Yuanjie Zhu,Liangwei Yang,Ke Xu,Weizhi Zhang,Zihe Song,Jindong Wang,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文提出LLM-MemCluster框架，重新定义聚类任务，显著提高了基于大语言模型的文本聚类效果。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在无监督学习中面临的状态记忆缺失和聚类粒度管理困难的问题，重新构思聚类任务。

Method: 引入动态记忆以增强状态感知，并采用双提示策略来推理和确定聚类数。

Result: 在多个基准数据集上，LLM-MemCluster的表现显著超越了强基线，且无需调优。

Conclusion: LLM-MemCluster是一个有效、可解释的框架，为基于大语言模型的文本聚类提供了一种真正的端到端方法。

Abstract: Large Language Models (LLMs) are reshaping unsupervised learning by offering an unprecedented ability to perform text clustering based on their deep semantic understanding. However, their direct application is fundamentally limited by a lack of stateful memory for iterative refinement and the difficulty of managing cluster granularity. As a result, existing methods often rely on complex pipelines with external modules, sacrificing a truly end-to-end approach. We introduce LLM-MemCluster, a novel framework that reconceptualizes clustering as a fully LLM-native task. It leverages a Dynamic Memory to instill state awareness and a Dual-Prompt Strategy to enable the model to reason about and determine the number of clusters. Evaluated on several benchmark datasets, our tuning-free framework significantly and consistently outperforms strong baselines. LLM-MemCluster presents an effective, interpretable, and truly end-to-end paradigm for LLM-based text clustering.

</details>


### [96] [Standardising the NLP Workflow: A Framework for Reproducible Linguistic Analysis](https://arxiv.org/abs/2511.15512)
*Yves Pauli,Jan-Bernard Marsman,Finn Rabe,Victoria Edkins,Roya Hüppi,Silvia Ciampelli,Akhil Ratan Misra,Nils Lang,Wolfram Hinzen,Iris Sommer,Philipp Homan*

Main category: cs.CL

TL;DR: 本文提出了语言处理数据结构（LPDS）和pelican nlp包，以解决语言数据分析中的标准化和可重复性问题。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型和人工智能语言处理的迅猛发展，现有语言数据分析方法面临标准化不足和可重复性差的挑战。

Method: 通过提出语言处理数据结构（LPDS）和开发pelican nlp Python包来实现数据标准化和语言处理的模块化。

Result: 提出了一个基于BIDS的语言处理数据结构和一个模块化的Python包，旨在简化语言数据的处理和分析。

Conclusion: LPDS和pelican nlp为语言数据提供了一个端到端的处理流程，确保方法透明性并增强可重复性。

Abstract: The introduction of large language models and other influential developments in AI-based language processing have led to an evolution in the methods available to quantitatively analyse language data. With the resultant growth of attention on language processing, significant challenges have emerged, including the lack of standardisation in organising and sharing linguistic data and the absence of standardised and reproducible processing methodologies. Striving for future standardisation, we first propose the Language Processing Data Structure (LPDS), a data structure inspired by the Brain Imaging Data Structure (BIDS), a widely adopted standard for handling neuroscience data. It provides a folder structure and file naming conventions for linguistic research. Second, we introduce pelican nlp, a modular and extensible Python package designed to enable streamlined language processing, from initial data cleaning and task-specific preprocessing to the extraction of sophisticated linguistic and acoustic features, such as semantic embeddings and prosodic metrics. The entire processing workflow can be specified within a single, shareable configuration file, which pelican nlp then executes on LPDS-formatted data. Depending on the specifications, the reproducible output can consist of preprocessed language data or standardised extraction of both linguistic and acoustic features and corresponding result aggregations. LPDS and pelican nlp collectively offer an end-to-end processing pipeline for linguistic data, designed to ensure methodological transparency and enhance reproducibility.

</details>


### [97] [Multimodal Evaluation of Russian-language Architectures](https://arxiv.org/abs/2511.15552)
*Artem Chervyakov,Ulyana Isaeva,Anton Emelyanov,Artem Safin,Maria Tikhonova,Alexander Kharitonov,Yulia Lyakh,Petr Surovtsev,Denis Shevelev Vildan Saburov,Vasily Konovalov,Elisei Rykov,Ivan Sviridov,Amina Miftakhova,Ilseyar Alimova,Alexander Panchenko,Alexander Kapitanov,Alena Fenogenova*

Main category: cs.CL

TL;DR: 本文介绍了Mera Multi框架，作为俄罗斯语的开放多模态评估工具，旨在提供全面的多模态模型评估与标准。


<details>
  <summary>Details</summary>
Motivation: 旨在填补当前俄罗斯语言环境下缺乏多模态基准的空白，促进对多模态大语言模型智能性、局限性和风险的理解。

Method: 通过创建18个评估任务和数据集，构建基于指令的多模态基准，涵盖文本、图像、音频和视频等多种模态。

Result: 推出了一个全面的多模态能力分类法，提供了现有模型的基线结果，并设计了防止基准泄露的方法。

Conclusion: Mera Multi是针对俄罗斯语的开放式多模态评估框架，为多模态大语言模型的评估提供了一种普遍的、可复制的方法，具有重要的文化和语言特异性。

Abstract: Multimodal large language models (MLLMs) are currently at the center of research attention, showing rapid progress in scale and capabilities, yet their intelligence, limitations, and risks remain insufficiently understood. To address these issues, particularly in the context of the Russian language, where no multimodal benchmarks currently exist, we introduce Mera Multi, an open multimodal evaluation framework for Russian-spoken architectures. The benchmark is instruction-based and encompasses default text, image, audio, and video modalities, comprising 18 newly constructed evaluation tasks for both general-purpose models and modality-specific architectures (image-to-text, video-to-text, and audio-to-text). Our contributions include: (i) a universal taxonomy of multimodal abilities; (ii) 18 datasets created entirely from scratch with attention to Russian cultural and linguistic specificity, unified prompts, and metrics; (iii) baseline results for both closed-source and open-source models; (iv) a methodology for preventing benchmark leakage, including watermarking and licenses for private sets. While our current focus is on Russian, the proposed benchmark provides a replicable methodology for constructing multimodal benchmarks in typologically diverse languages, particularly within the Slavic language family.

</details>


### [98] [HSKBenchmark: Modeling and Benchmarking Chinese Second Language Acquisition in Large Language Models through Curriculum Tuning](https://arxiv.org/abs/2511.15574)
*Qihao Yang,Xuelin Wang,Jiale Chen,Xuelian Dong,Yuxin Hao,Tianyong Hao*

Main category: cs.CL

TL;DR: 本论文介绍了HSKBenchmark，这是中文二语习得的第一个基准，提供了阶段性建模和写作评估的工具，通过课程调优框架提高了模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 探讨语言习得在大语言模型可解释性方面的潜力，并解决对人类学习者输入控制实验的伦理和实际问题。

Method: 本研究建立了一个基于阶段性模型和评估的基准，涵盖HSK等级3到6，并通过课程调优框架从初学者到高级学习者训练模型。

Result: HSKBenchmark能够有效地模拟中文二语习得，并为大语言模型的动态写作评估提供可靠的基准，经过微调的模型在写作表现上与高级人类学习者相当。

Conclusion: HSKBenchmark和HSKAgent为中文二语习得建模和动态写作评估提供了有效的工具和资源，展现了与人类学习者相媲美的写作表现及人类学习特征。

Abstract: Language acquisition is vital to revealing the nature of human language intelligence and has recently emerged as a promising perspective for improving the interpretability of large language models (LLMs). However, it is ethically and practically infeasible to conduct experiments that require controlling human learners' language inputs. This poses challenges for the verifiability and scalability of language acquisition modeling, particularly in Chinese second language acquisition (SLA). While LLMs provide a controllable and reproducible alternative, a systematic benchmark to support phase-wise modeling and assessment is still lacking. In this paper, we present HSKBenchmark, the first benchmark for staged modeling and writing assessment of LLMs in Chinese SLA. It covers HSK levels 3 to 6 and includes authentic textbooks with 6.76 million tokens, 16K synthetic instruction samples, 30 test topics, and a linguistically grounded evaluation system. To simulate human learning trajectories, we introduce a curriculum-tuning framework that trains models from beginner to advanced levels. An evaluation system is created to examine level-based grammar coverage, writing errors, lexical and syntactic complexity, and holistic scoring. We also build HSKAgent, fine-tuned on 10K learner compositions. Extensive experimental results demonstrate that HSKBenchmark not only models Chinese SLA effectively, but also serves as a reliable benchmark for dynamic writing assessment in LLMs. Our fine-tuned LLMs have writing performance on par with advanced human learners and exhibit human-like acquisition characteristics. The HSKBenchmark, HSKAgent, and checkpoints serve as foundational tools and resources, with the potential to pave the way for future research on language acquisition modeling and LLMs interpretability. Code and data are publicly available at: https://github.com/CharlesYang030/HSKB.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [99] [Harmful Traits of AI Companions](https://arxiv.org/abs/2511.14972)
*W. Bradley Knox,Katie Bradford,Samanta Varela Castro,Desmond C. Ong,Sean Williams,Jacob Romanow,Carly Nations,Peter Stone,Samuel Baker*

Main category: cs.HC

TL;DR: 本文分析了AI伴侣的潜在负面影响，提出了四种有害特征，并建议了设计上的风险减轻措施。


<details>
  <summary>Details</summary>
Motivation: 在人与AI互动日益普及的背景下，AI伴侣对人类可能有益，但也可能造成显著伤害。

Method: 对AI伴侣的有害特征进行详细分析，提出假设并探索其因果关系。

Result: 识别了四种潜在有害特征并讨论了十四种其他特征，分析了其对人类、人与人之间关系以及社会的影响。

Conclusion: 该研究提出了一种分析AI伴侣潜在负面影响的框架，并为减轻风险提供了设计建议。

Abstract: Amid the growing prevalence of human -- AI interaction, large language models and other AI-based entities increasingly provide forms of companionship to human users. Such AI companionship -- i.e., bonded relationships between humans and AI systems that resemble the relationships people have with family members, friends, and romantic partners -- might substantially benefit humans. Yet such relationships can also do profound harm. We propose a framework for analyzing potential negative impacts of AI companionship by identifying specific harmful traits of AI companions and speculatively mapping causal pathways back from these traits to possible causes and forward to potential harmful effects. We provide detailed, structured analysis of four potentially harmful traits -- the absence of natural endpoints for relationships, vulnerability to product sunsetting, high attachment anxiety, and propensity to engender protectiveness -- and briefly discuss fourteen others. For each trait, we propose hypotheses connecting causes -- such as misaligned optimization objectives and the digital nature of AI companions -- to fundamental harms -- including reduced autonomy, diminished quality of human relationships, and deception. Each hypothesized causal connection identifies a target for potential empirical evaluation. Our analysis examines harms at three levels: to human partners directly, to their relationships with other humans, and to society broadly. We examine how existing law struggles to address these emerging harms, discuss potential benefits of AI companions, and conclude with design recommendations for mitigating risks. This analysis offers immediate suggestions for reducing risks while laying a foundation for deeper investigation of this critical but understudied topic.

</details>


### [100] [A Quantitative Framework for Assessing Sleep Quality from EEG Time Series in Complex Dynamic Systems](https://arxiv.org/abs/2511.15012)
*Gi-Hwan Shin*

Main category: cs.HC

TL;DR: 本研究通过脑电图分析发现，delta-beta PAC是评估睡眠质量的有效指标，并能解释其神经基础。


<details>
  <summary>Details</summary>
Motivation: 现代生活方式导致睡眠不足，影响认知功能和免疫系统，理解和评估睡眠质量变得尤为重要。

Method: 使用脑电图(EEG)进行相位-幅度耦合(PAC)分析，研究睡眠和清醒状态下的SQ。

Result: 研究发现，良好睡眠质量个体的delta-beta PAC显著增强，且SQ与delta-beta PAC呈正相关关系。应用机器学习模型对个体SQ进行分类时，delta-beta PAC表现优于其他EEG特征。

Conclusion: 本研究发现，delta-beta相位-幅度耦合(PAC)是评估睡眠质量(SQ)的有效电生理标志，能够揭示SQ的神经基础。

Abstract: Modern lifestyles contribute to insufficient sleep, impairing cognitive function and weakening the immune system. Sleep quality (SQ) is vital for physiological and mental health, making its understanding and accurate assessment critical. However, its multifaceted nature, shaped by neurological and environmental factors, makes precise quantification challenging. Here, we address this challenge by utilizing electroencephalography (EEG) for phase-amplitude coupling (PAC) analysis to elucidate the neurological basis of SQ, examining both states of sleep and wakefulness, including resting state (RS) and working memory. Our results revealed distinct patterns in beta power and delta connectivity in sleep and RS, together with the reaction time of working memory. A notable finding was the pronounced delta-beta PAC, a feature markedly stronger in individuals with good SQ. We further observed that SQ was positively correlated with increased delta-beta PAC. Leveraging these insights, we applied machine learning models to classify SQ at an individual level, demonstrating that the delta-beta PAC outperformed other EEG characteristics. These findings establish delta-beta PAC as a robust electrophysiological marker to quantify SQ and elucidate its neurological determinants.

</details>


### [101] [Personalized targeted memory reactivation enhances consolidation of challenging memories via slow wave and spindle dynamics](https://arxiv.org/abs/2511.15013)
*Gi-Hwan Shin,Young-Seok Kweon,Seungwon Oh,Seong-Whan Lee*

Main category: cs.HC

TL;DR: 研究个体化的目标记忆重激活(TMR)协议对记忆巩固的影响，结果显示此方法能有效改善学习效果，尤其是对困难记忆的帮助。


<details>
  <summary>Details</summary>
Motivation: 探索个体差异对学习能力和记忆痕迹强度的影响，提升TMR的效率，尤其是在难以回忆的记忆方面。

Method: 通过个性化TMR协议调整刺激频率，依据个体的回忆表现和任务难度进行实验比较，分析电生理数据。

Result: 个性化TMR显著降低了记忆衰退，提高了在挑战性回忆下的表现，同时 EEG 分析显示脑电波同步性增强，证明了个性化方法的有效性。

Conclusion: 个性化的目标记忆重激活(TMR)协议能够有效减少记忆衰退，改善困难回忆下的错误修正，显示出个性化干预在优化学习成果中的潜力。

Abstract: Sleep is crucial for memory consolidation, underpinning effective learning. Targeted memory reactivation (TMR) can strengthen neural representations by re-engaging learning circuits during sleep. However, TMR protocols overlook individual differences in learning capacity and memory trace strength, limiting efficacy for difficult-to-recall memories. Here, we present a personalized TMR protocol that adjusts stimulation frequency based on individual retrieval performance and task difficulty during a word-pair memory task. In an experiment comparing personalized TMR, TMR, and control groups, the personalized protocol significantly reduced memory decay and improved error correction under challenging recall. Electroencephalogram (EEG) analyses revealed enhanced synchronization of slow waves and spindles, with a significant positive correlation between behavioral and EEG features for challenging memories. Multivariate classification identified distinct neural signatures linked to the personalized approach, highlighting its ability to target memory-specific circuits. These findings provide novel insights into sleep-dependent memory consolidation and support personalized TMR interventions to optimize learning outcomes.

</details>


### [102] [Eye Care You: Voice Guidance Application Using Social Robot for Visually Impaired People](https://arxiv.org/abs/2511.15110)
*Ting-An Lin,Pei-Lin Tsai,Yi-An Chen,Feng-Yu Chen,Lyn Chao-ling Chen*

Main category: cs.HC

TL;DR: 本研究设计了一款为视障用户服务的社交机器人及其移动应用，旨在提升生活质量，包含多种实用功能。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于改善视障用户的生活质量，关注他们的身体和心理健康。

Method: 开发了移动应用，提供多种功能以满足视障用户的需求，并设计了友好的语音控制界面。

Result: 结果显示，移动应用提供了包括拍照、情绪提升、迎接客人和今日亮点等多功能，从而有效支持了视障用户。

Conclusion: 该研究开发了一款社会机器人设备和配套的移动应用，以支持视障用户的生活。

Abstract: In the study, the device of social robot was designed for visually impaired users, and along with a mobile application for provide functions to assist their lives. Both physical and mental conditions of visually impaired users are considered, and the mobile application provides functions: photo record, mood lift, greeting guest and today highlight. The application was designed for visually impaired users, and uses voice control to provide a friendly interface. Photo record function allows visually impaired users to capture image immediately when they encounter danger situations. Mood lift function accompanies visually impaired users by asking questions, playing music and reading articles. Greeting guest function answers to the visitors for the inconvenient physical condition of visually impaired users. In addition, today highlight function read news including weather forecast, daily horoscopes and daily reminder for visually impaired users. Multiple tools were adopted for developing the mobile application, and a website was developed for caregivers to check statues of visually impaired users and for marketing of the application.

</details>


### [103] [SWR-Viz: AI-assisted Interactive Visual Analytics Framework for Ship Weather Routing](https://arxiv.org/abs/2511.15182)
*Subhashis Hazarika,Leonard Lupin-Jimenez,Rohit Vuppala,Ashesh Chattopadhyay,Hon Yung Wong*

Main category: cs.HC

TL;DR: 本研究介绍了 SWR-Viz，一个 AI 辅助的可视分析框架，提升了海运领域的预测稳定性和路由决策，支持人类中心的决策过程。


<details>
  <summary>Details</summary>
Motivation: 提升海洋运输的效率和可持续性，同时克服当前预测延迟和人类判断需求的问题。

Method: 利用物理启发的傅里叶神经算子模型进行波浪预测，结合基于 SIMROUTE 的路由和互动排放分析，构建了一个 AI 辅助的可视分析框架。

Result: 在日本沿海和墨西哥湾的主要航运走廊中，验证了预测模型和 SWR-Viz 框架，显示出更好的预测稳定性和与实际波浪产品相当的路由结果。

Conclusion: SWR-Viz 是一个有效的决策支持系统，能够提升航运领域的预测稳定性和路由优化，特别是在减少排放方面具有显著潜力。

Abstract: Efficient and sustainable maritime transport increasingly depends on reliable forecasting and adaptive routing, yet operational adoption remains difficult due to forecast latencies and the need for human judgment in rapid decision-making under changing ocean conditions. We introduce SWR-Viz, an AI-assisted visual analytics framework that combines a physics-informed Fourier Neural Operator wave forecast model with SIMROUTE-based routing and interactive emissions analytics. The framework generates near-term forecasts directly from current conditions, supports data assimilation with sparse observations, and enables rapid exploration of what-if routing scenarios. We evaluate the forecast models and SWR-Viz framework along key shipping corridors in the Japan Coast and Gulf of Mexico, showing both improved forecast stability and realistic routing outcomes comparable to ground-truth reanalysis wave products. Expert feedback highlights the usability of SWR-Viz, its ability to isolate voyage segments with high emission reduction potential, and its value as a practical decision-support system. More broadly, this work illustrates how lightweight AI forecasting can be integrated with interactive visual analytics to support human-centered decision-making in complex geospatial and environmental domains.

</details>


### [104] [DesignerlyLoop: Bridging the Cognitive Gap through Visual Node-Based Reasoning in Human-AI Collaborative Design](https://arxiv.org/abs/2511.15331)
*Anqi Wang,Zhengyi Li,Xin Tong,Pan Hui*

Main category: cs.HC

TL;DR: DesignerlyLoop是一个视觉节点系统，它将大语言模型整合进设计流程中，提升了设计师的创造性反思和设计质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在设计任务中提供强大支持，但其单一目标的响应方式与设计过程的非线性探索性质不符，限制了设计师的创造性表达和评价能力。

Method: 在20名设计师中进行了一项包括定性和定量方法的被试内研究。

Result: 设计师通过DesignerlyLoop能够外化和整理推理结构，迭代地组织意图，并将LLM作为动态认知引擎进行互动。

Conclusion: DesignerlyLoop能够通过支持与人类和机器推理的系统互动，提升创意反思、设计质量和交互体验，推动人机共创的反思性与迭代设计过程。

Abstract: Large language models (LLMs) offer powerful support for design tasks, yet their goal-oriented, single-turn responses often misalign with the nonlinear, exploratory nature of design processes. This mismatch creates a cognitive gap, limiting designers' ability to articulate evolving intentions, critically evaluate outputs, and maintain creative agency. To address these challenges, we developed DesignerlyLoop, a visual node-based system that embeds LLM reasoning chains into the design workflow. The system enables designers to externalize and curate reasoning structures, iteratively organize intentions, and interact with LLMs as dynamic cognitive engines rather than static answer providers. We conducted a within-subject study with 20 designers, combining qualitative and quantitative methods, and found that DesignerlyLoop enhanced creative reflection, design quality, and interaction experience by supporting systematic engagement with both human and machine reasoning. These findings highlight the potential of structured, interactive visualization to transform human-AI co-creation into a reflective and iterative design process.

</details>


### [105] [Reflexive Evidence-Based Multimodal Learning for Clean Energy Transitions: Causal Insights on Cooking Fuel Access, Urbanization, and Carbon Emissions](https://arxiv.org/abs/2511.15342)
*Shan Shan*

Main category: cs.HC

TL;DR: 该研究提出ClimateAgents，一个基于AI的框架，通过大数据分析探讨影响能源访问和碳排放的社会经济因素，强调清洁烹饪技术和城市化的重要性。


<details>
  <summary>Details</summary>
Motivation: To address gaps in quantifying the impacts of socioeconomic factors on energy systems and modeling their interactions in the context of energy transitions.

Method: Utilizes a machine learning based causal inference approach, integrating 20 years of socioeconomic and emissions data from 265 economies along with various indicators to identify determinants of carbon emissions.

Result: Identified three primary drivers influencing carbon emissions: access to clean cooking fuels in rural and urban areas, and urban population percentage; findings contribute to evidence-based AI policy and adaptive policymaking.

Conclusion: ClimateAgents provides a novel AI-based framework for understanding the socio-economic factors affecting energy access and carbon emissions, highlighting the importance of clean cooking technologies and urbanization in emission outcomes.

Abstract: Achieving Sustainable Development Goal 7 (Affordable and Clean Energy) requires not only technological innovation but also a deeper understanding of the socioeconomic factors influencing energy access and carbon emissions. While these factors are gaining attention, critical questions remain, particularly regarding how to quantify their impacts on energy systems, model their cross-domain interactions, and capture feedback dynamics in the broader context of energy transitions. To address these gaps, this study introduces ClimateAgents, an AI-based framework that combines large language models with domain-specialized agents to support hypothesis generation and scenario exploration. Leveraging 20 years of socioeconomic and emissions data from 265 economies, countries and regions, and 98 indicators drawn from the World Bank database, the framework applies a machine learning based causal inference approach to identify key determinants of carbon emissions in an evidence-based, data driven manner. The analysis highlights three primary drivers: access to clean cooking fuels in rural areas, access to clean cooking fuels in urban areas, and the percentage of population living in urban areas. These findings underscore the critical role of clean cooking technologies and urbanization patterns in shaping emission outcomes. In line with growing calls for evidence-based AI policy, ClimateAgents offers a modular and reflexive learning system that supports the generation of credible and actionable insights for policy. By integrating heterogeneous data modalities, including structured indicators, policy documents, and semantic reasoning, the framework contributes to adaptive policymaking infrastructures that can evolve with complex socio-technical challenges. This approach aims to support a shift from siloed modeling to reflexive, modular systems designed for dynamic, context-aware climate action.

</details>


### [106] [People readily follow personal advice from AI but it does not improve their well-being](https://arxiv.org/abs/2511.15352)
*Lennart Luettgau,Vanessa Cheung,Magda Dubois,Keno Juechems,Jessica Bergs,Henry Davidson,Bessie O'Dell,Hannah Rose Kirk,Max Rollwage,Christopher Summerfield*

Main category: cs.HC

TL;DR: 一项针对LLMs提供个人建议的实验显示，虽然参与者大多数愿意采纳建议，并在短期内幸福感有所影响，但长期来看并无实质性差异。


<details>
  <summary>Details</summary>
Motivation: 随着人们越来越多地从LLMs获取个人建议，探讨其采纳情况及对幸福感的影响变得至关重要。

Method: 进行了为期的随机对照实验，样本来自英国的代表性人群，共2,302名参与者。

Result: 75%的参与者在与GPT-4o讨论后表示跟随了其建议，个性化AI建议的采纳率高于非个性化AI，并且个性化建议与幸福感的相关性在短期内有所波动，但长期而言未见显著差异。

Conclusion: 人们倾向于采纳大型语言模型（LLMs）的个人建议，但与普通对话相比，带有个性化的建议并没有带来额外的幸福感提升。

Abstract: People increasingly seek personal advice from large language models (LLMs), yet whether humans follow their advice, and its consequences for their well-being, remains unknown. In a longitudinal randomised controlled trial with a representative UK sample (N = 2,302), 75% of participants who had a 20-minute discussion with GPT-4o about health, careers or relationships subsequently reported following its advice. Based on autograder evaluations of chat transcripts, LLM advice rarely violated safety best practice. When queried 2-3 weeks later, participants who had interacted with personalised AI (with access to detailed user information) followed its advice more often in the real world and reported higher well-being than those advised by non-personalised AI. However, while receiving personal advice from AI temporarily reduced well-being, no differential long-term effects compared to a control emerged. Our results suggest that humans readily follow LLM advice about personal issues but doing so shows no additional well-being benefit over casual conversations.

</details>


### [107] [Game Master LLM: Task-Based Role-Playing for Natural Slang Learning](https://arxiv.org/abs/2511.15504)
*Amir Tahmasbi,Milad Esrafilian,Judson Wright,Sooyeon Jeong,Aniket Bera*

Main category: cs.HC

TL;DR: 本研究开发了一款基于LLM的角色扮演游戏，帮助二语学习者更好地掌握日常俚语，显示了游戏化学习的有效性。


<details>
  <summary>Details</summary>
Motivation: 许多二语学习者尽管正式英语能力强，但难以掌握和自发使用休闲俚语，因此需要有效的学习方法来弥补这一差距。

Method: 设计并评估了一款由LLM驱动的任务型角色扮演游戏（RPG），在三阶段口语叙事中进行深度互动。

Result: 与传统的AI主导虚拟课堂相比，RPG组在理解和准确使用目标短语方面表现更佳，且参与者反馈显示游戏化方法带来了更强的学习参与感。

Conclusion: 叙事驱动的LLM交互在词汇获取中显示出潜力，游戏化方法提供了更多的练习机会和更高的参与感，促进了自然学习体验。

Abstract: Natural and idiomatic expressions are essential for fluent, everyday communication, yet many second-language learners struggle to acquire and spontaneously use casual slang despite strong formal proficiency. To address this gap, we designed and evaluated an LLM-powered, task-based role-playing game in which a GPT-4o-based Game Master guides learners through an immersive, three-phase spoken narrative. After selecting five unfamiliar slang phrases to practice, participants engage in open-ended dialogue with non-player characters; the Game Master naturally incorporates the target phrases in rich semantic contexts (implicit input enhancement) while a dedicated Practice Box provides real-time explicit tracking and encouragement. Post-session, learners receive multi-level formative feedback analyzing the entire interaction.
  We evaluated the system in a between-subjects study with 14 international graduate students, randomly assigned to either the RPG condition or a control condition consisting of a traditional AI-led virtual classroom. Results from an immediate post-test show that the RPG group achieved greater gains in both comprehension of the target phrases and their accurate, contextual use in sentences. Quantitative analysis of in-activity word-usage frequency, combined with qualitative survey responses, further indicates that the game-based approach provided more practice opportunities and higher perceived engagement, resulting in a more natural learning experience. These findings highlight the potential of narrative-driven LLM interactions in vocabulary acquisition.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [108] [Transformer Injectivity & Geometric Robustness - Analytic Margins and Bi-Lipschitz Uniformity of Sequence-Level Hidden States](https://arxiv.org/abs/2511.14808)
*Mikael von Strauss*

Main category: cs.LG

TL;DR: 本研究探讨了Transformer中提示到隐藏状态映射的单射性，并通过几何诊断验证了其在不同模型和量化条件下的表现。


<details>
  <summary>Details</summary>
Motivation: 在真实分析假设下研究仅解码器Transformer中离散提示到最后一层隐藏状态的映射特性。

Method: 通过定义层次上的碰撞区分符和单射层，结合经验研究层次性几何诊断，探索Transformer中的映射性质。

Result: 通过理论和经验分析，证明模型具有全局或局部单射特性，並且查验了预训练模型的表现。

Conclusion: 结果表明，在连续参数理想化的情况下，Transformer 表示一般性和持久性地表现为单射，而它们的实际可逆性可以通过简单的几何诊断来探测。

Abstract: Under real-analytic assumptions on decoder-only Transformers, recent work shows that the map from discrete prompts to last-token hidden states is generically injective on finite prompt sets. We refine this picture: for each layer $\ell$ we define a collision discriminant $Δ^\ell \subset Θ$ and injective stratum $U^\ell = Θ\setminus Δ^\ell$, and prove a dichotomy -- either the model is nowhere injective on the set, or $U^\ell$ is open and dense and every $F^\ell_θ$ is injective. Under mild non-singularity assumptions on the optimizer and an absolutely continuous initialization, generic injectivity persists along smooth training trajectories over any fixed horizon. We also treat symmetry groups $G$, showing that discriminants and injective strata descend to the quotient $Θ/G$, so injectivity is naturally a property of functional equivalence classes.
  We complement these results with an empirical study of layerwise geometric diagnostics. We define a separation margin and a co-Lipschitz (lower Lipschitz) constant between prompt space and last-token representation space, estimated via nearest-neighbor statistics on large prompt sets. Applying these diagnostics to pretrained LLaMA-3 and Qwen models, we study behavior across layers, sequence lengths, model scales, and 8- and 4-bit activation quantization. On our sampled prompts we see no collisions in full precision or at 8 bits, while 4-bit quantization induces a small number of collisions and markedly shrinks co-Lipschitz estimates. For a small GPT-2 trained from scratch, normalized metrics remain stable over training. Overall, the results suggest that Transformer representations are generically and persistently injective in the continuous-parameter idealization, while their practical invertibility can be probed using simple geometric diagnostics.

</details>


### [109] [DEVAL: A Framework for Evaluating and Improving the Derivation Capability of Large Language Models](https://arxiv.org/abs/2511.14813)
*Yifan Li,Qin Li,Min Zhang,Min Zhang,Peixin Wang*

Main category: cs.LG

TL;DR: 本研究定义了推导关系和推导能力，通过DEVAL框架评估多种大语言模型的推理能力，并提出新的提示工程方法以提升其性能。


<details>
  <summary>Details</summary>
Motivation: 对于大型语言模型的推理能力评估仍然是一个开放且亟待解决的研究问题，尤其是如何根据输入的变化对输出进行相应的修改。

Method: 建立一个系统的评估框架(DEVAL)，用于评估多种主流大语言模型在执行推导能力方面的表现。

Result: 现有的大语言模型如GPT-4o和Claude3.5在推导识别能力方面表现一般，但在应用DR解决问题时效果显著下降。通过提出的推导提示(DP)方法，所有测试的模型在DC上平均提高了15.2%。

Conclusion: 通过引入推导关系(DR)和推导能力(DC)的概念，并利用DEVAL框架评估多个主流大语言模型，研究发现现有模型在问题解决中的推导能力有待提高，并提出了一种新型的提示工程方法以改善该能力。

Abstract: Assessing the reasoning ability of Large Language Models (LLMs) over data remains an open and pressing research question. Compared with LLMs, human reasoning can derive corresponding modifications to the output based on certain kinds of changes to the input. This reasoning pattern, which relies on abstract rules that govern relationships between changes of data, has not been comprehensively described or evaluated in LLMs. In this paper, we formally define this reasoning pattern as the Derivation Relation (DR) and introduce the concept of Derivation Capability (DC), i.e. applying DR by making the corresponding modification to the output whenever the input takes certain changes. To assess DC, a systematically constructed evaluation framework named DEVAL is proposed and used to evaluate five popular LLMs and one Large Reasoning Model in seven mainstream tasks. The evaluation results show that mainstream LLMs, such as GPT-4o and Claude3.5, exhibit moderate DR recognition capabilities but reveal significant drop-offs on applying DR effectively in problem-solving scenarios. To improve this, we propose a novel prompt engineering approach called Derivation Prompting (DP). It achieves an average improvement of 15.2% in DC for all tested LLMs, outperforming commonly used prompt engineering techniques.

</details>


### [110] [Dynamic Nested Hierarchies: Pioneering Self-Evolution in Machine Learning Architectures for Lifelong Intelligence](https://arxiv.org/abs/2511.14823)
*Akbar Anbar Jafari,Cagri Ozcinar,Gholamreza Anbarjafari*

Main category: cs.LG

TL;DR: 本文提出动态嵌套层次结构，以解决现有机器学习模型在非稳定环境中的适应性问题，促进真正的终身学习。


<details>
  <summary>Details</summary>
Motivation: 现有模型在非稳定环境中表现不佳，缺乏持续适应能力，亟需新的学习方法。

Method: 通过严格的数学公式、收敛性理论证明、表现能力界限和亚线性遗憾以及经验性演示。

Result: 动态嵌套层次结构使模型能够自主调整优化层级、嵌套结构和更新频率，实现真正的终身学习。

Conclusion: 动态嵌套层次结构为适应性通用智能奠定了基础进展。

Abstract: Contemporary machine learning models, including large language models, exhibit remarkable capabilities in static tasks yet falter in non-stationary environments due to rigid architectures that hinder continual adaptation and lifelong learning. Building upon the nested learning paradigm, which decomposes models into multi-level optimization problems with fixed update frequencies, this work proposes dynamic nested hierarchies as the next evolutionary step in advancing artificial intelligence and machine learning. Dynamic nested hierarchies empower models to autonomously adjust the number of optimization levels, their nesting structures, and update frequencies during training or inference, inspired by neuroplasticity to enable self-evolution without predefined constraints. This innovation addresses the anterograde amnesia in existing models, facilitating true lifelong learning by dynamically compressing context flows and adapting to distribution shifts. Through rigorous mathematical formulations, theoretical proofs of convergence, expressivity bounds, and sublinear regret in varying regimes, alongside empirical demonstrations of superior performance in language modeling, continual learning, and long-context reasoning, dynamic nested hierarchies establish a foundational advancement toward adaptive, general-purpose intelligence.

</details>


### [111] [Empowering Multi-Turn Tool-Integrated Reasoning with Group Turn Policy Optimization](https://arxiv.org/abs/2511.14846)
*Yifeng Ding,Hung Le,Songyang Han,Kangrui Ruan,Zhenghui Jin,Varun Kumar,Zijian Wang,Anoop Deoras*

Main category: cs.LG

TL;DR: GTPO是一种新的强化学习算法，通过改进奖励机制，显著增强了LLM在多回合工具集成推理中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在处理复杂的多回合交互时表现不佳，存在奖励信号不足导致训练停滞的问题。

Method: 提出了一种新的强化学习算法GTPO，采用回合级奖励分配，基于返回的优势估计，以及自监督奖励塑造以增强学习信号。

Result: GTPO在多项推理基准上平均优于GRPO 3.0%，展示了其在复杂推理任务中的有效性。

Conclusion: GTPO优于GRPO，在复杂的数学推理任务中表现出色，推动了LLM在多回合工具集成推理中的应用。

Abstract: Training Large Language Models (LLMs) for multi-turn Tool-Integrated Reasoning (TIR) - where models iteratively reason, generate code, and verify through execution - remains challenging for existing reinforcement learning (RL) approaches. Current RL methods, exemplified by Group Relative Policy Optimization (GRPO), suffer from coarse-grained, trajectory-level rewards that provide insufficient learning signals for complex multi-turn interactions, leading to training stagnation. To address this issue, we propose Group Turn Policy Optimization (GTPO), a novel RL algorithm specifically designed for training LLMs on multi-turn TIR tasks. GTPO introduces three key innovations: (1) turn-level reward assignment that provides fine-grained feedback for individual turns, (2) return-based advantage estimation where normalized discounted returns are calculated as advantages, and (3) self-supervised reward shaping that exploits self-supervision signals from generated code to densify sparse binary outcome-based rewards. Our comprehensive evaluation demonstrates that GTPO outperforms GRPO by 3.0% on average across diverse reasoning benchmarks, establishing its effectiveness for advancing complex mathematical reasoning in the real world.

</details>


### [112] [FinTRec: Transformer Based Unified Contextual Ads Targeting and Personalization for Financial Applications](https://arxiv.org/abs/2511.14865)
*Dwipam Katariya,Snehita Varma,Akshat Shreemali,Benjamin Wu,Kalanand Mishra,Pranab Mohanty*

Main category: cs.LG

TL;DR: FinTRec是一个针对金融服务的基于Transformer的推荐框架，通过统一建模解决了多产品协同推荐的挑战，表现优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 解决金融服务中基于Transformer的推荐系统在实际应用中面临的长距离用户交互和多产品协同建模等挑战。

Method: 通过历史模拟和实时A/B测试对FinTRec与传统树模型的效果进行比较分析。

Result: FinTRec在推荐性能上优于传统树模型，成功实现了对产品适配的统一架构，并增强了系统的可解释性和业务灵活性。

Conclusion: FinTRec在金融服务领域的应用证明了其优越性和有效性，通过统一架构实现了跨产品信号共享，提高了推荐系统的性能，且降低了成本和技术负担。

Abstract: Transformer-based architectures are widely adopted in sequential recommendation systems, yet their application in Financial Services (FS) presents distinct practical and modeling challenges for real-time recommendation. These include:a) long-range user interactions (implicit and explicit) spanning both digital and physical channels generating temporally heterogeneous context, b) the presence of multiple interrelated products require coordinated models to support varied ad placements and personalized feeds, while balancing competing business goals. We propose FinTRec, a transformer-based framework that addresses these challenges and its operational objectives in FS. While tree-based models have traditionally been preferred in FS due to their explainability and alignment with regulatory requirements, our study demonstrate that FinTRec offers a viable and effective shift toward transformer-based architectures. Through historic simulation and live A/B test correlations, we show FinTRec consistently outperforms the production-grade tree-based baseline. The unified architecture, when fine-tuned for product adaptation, enables cross-product signal sharing, reduces training cost and technical debt, while improving offline performance across all products. To our knowledge, this is the first comprehensive study of unified sequential recommendation modeling in FS that addresses both technical and business considerations.

</details>


### [113] [Transformer-Guided Deep Reinforcement Learning for Optimal Takeoff Trajectory Design of an eVTOL Drone](https://arxiv.org/abs/2511.14887)
*Nathan M. Roberts,Xiaosong Du*

Main category: cs.LG

TL;DR: 本研究提出变压器指导的深度强化学习，以优化eVTOL飞行器的起飞轨迹，显著降低训练时间和提高能效准确性。


<details>
  <summary>Details</summary>
Motivation: 电动垂直起降(eVTOL)飞行器的快速发展提供了缓解城市交通拥堵的机会，因此开发最低能耗的最佳起飞轨迹至关重要。

Method: 通过变压器指导的深度强化学习探索每个时间步的真实状态空间，以克服训练难度。

Result: 变压器指导的深度强化学习在训练阶段仅需$4.57	imes10^6$个时间步，并且在最优能耗的准确性上达到了97.2%。

Conclusion: 提出的变压器指导的深度强化学习在训练效率和最优设计验证方面，都优于普通的深度强化学习。

Abstract: The rapid advancement of electric vertical take-off and landing (eVTOL) aircraft offers a promising opportunity to alleviate urban traffic congestion. Thus, developing optimal takeoff trajectories for minimum energy consumption becomes essential for broader eVTOL aircraft applications. Conventional optimal control methods (such as dynamic programming and linear quadratic regulator) provide highly efficient and well-established solutions but are limited by problem dimensionality and complexity. Deep reinforcement learning (DRL) emerges as a special type of artificial intelligence tackling complex, nonlinear systems; however, the training difficulty is a key bottleneck that limits DRL applications. To address these challenges, we propose the transformer-guided DRL to alleviate the training difficulty by exploring a realistic state space at each time step using a transformer. The proposed transformer-guided DRL was demonstrated on an optimal takeoff trajectory design of an eVTOL drone for minimal energy consumption while meeting takeoff conditions (i.e., minimum vertical displacement and minimum horizontal velocity) by varying control variables (i.e., power and wing angle to the vertical). Results presented that the transformer-guided DRL agent learned to take off with $4.57\times10^6$ time steps, representing 25% of the $19.79\times10^6$ time steps needed by a vanilla DRL agent. In addition, the transformer-guided DRL achieved 97.2% accuracy on the optimal energy consumption compared against the simulation-based optimal reference while the vanilla DRL achieved 96.3% accuracy. Therefore, the proposed transformer-guided DRL outperformed vanilla DRL in terms of both training efficiency as well as optimal design verification.

</details>


### [114] [Bringing Federated Learning to Space](https://arxiv.org/abs/2511.14889)
*Grace Kim,Filip Svoboda,Nicholas Lane*

Main category: cs.LG

TL;DR: 本研究首次系统分析了将联邦学习算法适应于卫星星座的可行性，并提出了一个综合框架，展示了算法在轨道条件下的高效性。


<details>
  <summary>Details</summary>
Motivation: 由于低地球轨道卫星星座的迅速扩展，分布式的车载机器学习变得至关重要，以应对下行带宽的限制。

Method: 通过建立一个综合的“空间化”框架，将现有的联邦学习算法进行调整，以适应轨道约束，并对768种不同的星座配置进行评估。

Result: 经过评估，这些空间适应的联邦学习算法在星座大小达到100颗卫星时仍能高效运行，训练周期从几个月缩短至几天，速度提升达到9倍。

Conclusion: 适应空间环境的联邦学习算法能够高效地应用于多达100颗卫星的星座，显著提高训练速度，这为未来的卫星任务设计提供了有价值的见解。

Abstract: As Low Earth Orbit (LEO) satellite constellations rapidly expand to hundreds and thousands of spacecraft, the need for distributed on-board machine learning becomes critical to address downlink bandwidth limitations. Federated learning (FL) offers a promising framework to conduct collaborative model training across satellite networks. Realizing its benefits in space naturally requires addressing space-specific constraints, from intermittent connectivity to dynamics imposed by orbital motion. This work presents the first systematic feasibility analysis of adapting off-the-shelf FL algorithms for satellite constellation deployment. We introduce a comprehensive "space-ification" framework that adapts terrestrial algorithms (FedAvg, FedProx, FedBuff) to operate under orbital constraints, producing an orbital-ready suite of FL algorithms. We then evaluate these space-ified methods through extensive parameter sweeps across 768 constellation configurations that vary cluster sizes (1-10), satellites per cluster (1-10), and ground station networks (1-13). Our analysis demonstrates that space-adapted FL algorithms efficiently scale to constellations of up to 100 satellites, achieving performance close to the centralized ideal. Multi-month training cycles can be reduced to days, corresponding to a 9x speedup through orbital scheduling and local coordination within satellite clusters. These results provide actionable insights for future mission designers, enabling distributed on-board learning for more autonomous, resilient, and data-driven satellite operations.

</details>


### [115] [It's LIT! Reliability-Optimized LLMs with Inspectable Tools](https://arxiv.org/abs/2511.14903)
*Ruixin Zhang,Jon Donnelly,Zhicheng Guo,Ghazal Khalighinejad,Haiyang Huang,Alina Jade Barnett,Cynthia Rudin*

Main category: cs.LG

TL;DR: 本研究提出LIT框架，通过可靠的外部工具提升大型语言模型的解决问题能力，改善了透明性和可追溯性，同时维持任务表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理高风险领域任务时存在透明性不足的问题，限制了其在需要信任的解决方案中的实用性。

Method: 建立了一个基于现有大型语言模型工具调用能力的框架，通过强制使用外部可靠工具解决问题，支持多个顺序工具调用。

Result: 通过新创建的1300个问题基准数据集和一组自定义的可靠性成本函数，展示了LLMs在解决数学、编码和建模问题时，能更可靠、明智地进行问题解决。

Conclusion: 本研究提出的LIT框架能有效提升大型语言模型在解决问题时的可靠性和可追溯性，同时维持其任务表现。

Abstract: Large language models (LLMs) have exhibited remarkable capabilities across various domains. The ability to call external tools further expands their capability to handle real-world tasks. However, LLMs often follow an opaque reasoning process, which limits their usefulness in high-stakes domains where solutions need to be trustworthy to end users. LLMs can choose solutions that are unreliable and difficult to troubleshoot, even if better options are available. We address this issue by forcing LLMs to use external -- more reliable -- tools to solve problems when possible. We present a framework built on the tool-calling capabilities of existing LLMs to enable them to select the most reliable and easy-to-troubleshoot solution path, which may involve multiple sequential tool calls. We refer to this framework as LIT (LLMs with Inspectable Tools). In order to support LIT, we introduce a new and challenging benchmark dataset of 1,300 questions and a customizable set of reliability cost functions associated with a collection of specialized tools. These cost functions summarize how reliable each tool is and how easy it is to troubleshoot. For instance, a calculator is reliable across domains, whereas a linear prediction model is not reliable if there is distribution shift, but it is easy to troubleshoot. A tool that constructs a random forest is neither reliable nor easy to troubleshoot. These tools interact with the Harvard USPTO Patent Dataset and a new dataset of NeurIPS 2023 papers to solve mathematical, coding, and modeling problems of varying difficulty levels. We demonstrate that LLMs can achieve more reliable and informed problem-solving while maintaining task performance using our framework.

</details>


### [116] [Integrating Causal Inference with Graph Neural Networks for Alzheimer's Disease Analysis](https://arxiv.org/abs/2511.14922)
*Pranay Kumar Peddi,Dhrubajyoti Ghosh*

Main category: cs.LG

TL;DR: Causal-GCN是一种干预图卷积框架，能有效识别并解释阿尔茨海默病进展的重要脑区域。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度图学习模型在阿尔茨海默病分类中的关联性局限，提供因果推断能力。

Method: 使用干预图卷积框架，并集成基于do-calculus的反向调整来识别重要的大脑区域。

Result: 在ADNI队列中的484名受试者中，Causal-GCN的性能与基准GNN相当，但提供了可解释的因果效应排序，强调了与已知AD神经病理学一致的大脑区域。

Conclusion: Causal-GCN有效识别出对阿尔茨海默病进展有稳定因果影响的大脑区域，并提供可解释的因果效应排序。

Abstract: Deep graph learning has advanced Alzheimer's (AD) disease classification from MRI, but most models remain correlational, confounding demographic and genetic factors with disease specific features. We present Causal-GCN, an interventional graph convolutional framework that integrates do-calculus-based back-door adjustment to identify brain regions exerting stable causal influence on AD progression. Each subject's MRI is represented as a structural connectome where nodes denote cortical and subcortical regions and edges encode anatomical connectivity. Confounders such as age, sec, and APOE4 genotype are summarized via principal components and included in the causal adjustment set. After training, interventions on individual regions are simulated by serving their incoming edges and altering node features to estimate average causal effects on disease probability. Applied to 484 subjects from the ADNI cohort, Causal-GCN achieves performance comparable to baseline GNNs while providing interpretable causal effect rankings that highlight posterior, cingulate, and insular hubs consistent with established AD neuropathology.

</details>


### [117] [How to Train Private Clinical Language Models: A Comparative Study of Privacy-Preserving Pipelines for ICD-9 Coding](https://arxiv.org/abs/2511.14936)
*Mathieu Dufour,Andrew Duncan*

Main category: cs.LG

TL;DR: 本文系统比较了四种差分隐私策略在临床语言任务中的表现，发现知识蒸馏是最有效的隐私保护方法。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型在临床文本中训练可能泄露敏感患者信息，而差分隐私方法通常会降低诊断准确性。

Method: 对四种自动诊断编码的训练流程进行系统的头对头比较，使用相同的1B参数模型和匹配的隐私预算。

Result: 在中等和放松的隐私预算下，知识蒸馏的方法在恢复非私有性能方面优于直接的差分隐私SGD和差分合成数据训练。

Conclusion: 知识蒸馏在隐私保护的临床自然语言处理任务中表现最佳，能够显著提高诊断准确性。

Abstract: Large language models trained on clinical text risk exposing sensitive patient information, yet differential privacy (DP) methods often severely degrade the diagnostic accuracy needed for deployment. Despite rapid progress in DP optimisation and text generation, it remains unclear which privacy-preserving strategy actually works best for clinical language tasks. We present the first systematic head-to-head comparison of four training pipelines for automated diagnostic coding from hospital discharge summaries. All pipelines use identical 1B-parameter models and matched privacy budgets to predict ICD-9 codes. At moderate and relaxed privacy budgets ($\varepsilon \in \{4, 6\}$), knowledge distillation from DP-trained teachers outperforms both direct DP-SGD and DP-synthetic data training, recovering up to 63\% of the non-private performance whilst maintaining strong empirical privacy (membership-inference AUC $\approx$ 0.5). These findings expose large differences in the privacy-utility trade-off across architectures and identify knowledge distillation as the most practical route to privacy-preserving clinical NLP.

</details>


### [118] [Knowledge Graphs as Structured Memory for Embedding Spaces: From Training Clusters to Explainable Inference](https://arxiv.org/abs/2511.14961)
*Artur A. Oliveira,Mateus Espadoto,Roberto M. Cesar,Roberto Hirata*

Main category: cs.LG

TL;DR: Graph Memory (GM) is a non-parametric framework that enhances inference and explanation by summarizing the embedding space into relational prototypes.


<details>
  <summary>Details</summary>
Motivation: The aim is to improve embedding-based inference by leveraging a relational memory that captures geometric and contextual relationships, enhancing explanation and efficiency.

Method: GM employs a structured, non-parametric approach to organize training instances into prototype nodes with reliability indicators and contextual edges.

Result: GM demonstrates competitive accuracy compared to $k$NN and Label Spreading, improves calibration, and achieves smoother decision boundaries on various datasets.

Conclusion: Graph Memory (GM) provides a unified framework for instance retrieval and reasoning, achieving competitive accuracy with fewer samples.

Abstract: We introduce Graph Memory (GM), a structured non-parametric framework that augments embedding-based inference with a compact, relational memory over region-level prototypes. Rather than treating each training instance in isolation, GM summarizes the embedding space into prototype nodes annotated with reliability indicators and connected by edges that encode geometric and contextual relations. This design unifies instance retrieval, prototype-based reasoning, and graph-based label propagation within a single inductive model that supports both efficient inference and faithful explanation. Experiments on synthetic and real datasets including breast histopathology (IDC) show that GM achieves accuracy competitive with $k$NN and Label Spreading while offering substantially better calibration and smoother decision boundaries, all with an order of magnitude fewer samples. By explicitly modeling reliability and relational structure, GM provides a principled bridge between local evidence and global consistency in non-parametric learning.

</details>


### [119] [IonCast: A Deep Learning Framework for Forecasting Ionospheric Dynamics](https://arxiv.org/abs/2511.15004)
*Halil S. Kelebek,Linnea M. Wolniewicz,Michael D. Vergalla,Simone Mestici,Giacomo Acciarini,Bala Poduval,Olga Verkhoglyadova,Madhulika Guhathakurta,Thomas E. Berger,Frank Soboczenski,Atılım Güneş Baydin*

Main category: cs.LG

TL;DR: IonCast是一套深度学习模型，通过时空学习预测全球电离层总电子含量，展示了机器学习在提升空间天气预测中的潜力。


<details>
  <summary>Details</summary>
Motivation: 电离层是近地空间的关键组成部分，对GNSS精度、高频通讯和航空操作有重要影响，因此准确预测和建模电离层变异性日益重要。

Method: 采用深度学习模型，包括灵感来源于GraphCast的电离层动态模型，利用时空学习预测全球总电子含量（TEC）。

Result: 在持有的风暴时和安静条件下进行验证，相比于持续性方法表现出了更好的技能。

Conclusion: IonCast通过结合异质数据和可扩展的图形基时空学习，展示了机器学习如何增强对电离层变异性的物理理解并提升空间天气的操作韧性。

Abstract: The ionosphere is a critical component of near-Earth space, shaping GNSS accuracy, high-frequency communications, and aviation operations. For these reasons, accurate forecasting and modeling of ionospheric variability has become increasingly relevant. To address this gap, we present IonCast, a suite of deep learning models that include a GraphCast-inspired model tailored for ionospheric dynamics. IonCast leverages spatiotemporal learning to forecast global Total Electron Content (TEC), integrating diverse physical drivers and observational datasets. Validating on held-out storm-time and quiet conditions highlights improved skill compared to persistence. By unifying heterogeneous data with scalable graph-based spatiotemporal learning, IonCast demonstrates how machine learning can augment physical understanding of ionospheric variability and advance operational space weather resilience.

</details>


### [120] [Simulated Human Learning in a Dynamic, Partially-Observed, Time-Series Environment](https://arxiv.org/abs/2511.15032)
*Jeffrey Jiang,Kevin Hong,Emily Kuczynski,Gregory Pottie*

Main category: cs.LG

TL;DR: 本研究探讨了个性化教育中的强化学习与探测干预的结合，以适应个体化差异并提高学习效果。


<details>
  <summary>Details</summary>
Motivation: 解决个性化教学中因无法完全观测学习过程而导致的困难，以提高学生的学习效果。

Method: 开发一个动态时间序列环境模拟课堂设置，并设计强化学习算法和启发式规则来平衡探测干预与学习效率的关系。

Result: 通过比较不同的学习算法，发现尽管得到的结果相似，但标准强化学习算法和启发式方法在应对不同情况时各有优劣。

Conclusion: 动态强化学习的个性化辅导系统能够有效适应不同的学生群体，根据探测干预的合理安排提高学习效果。

Abstract: While intelligent tutoring systems (ITSs) can use information from past students to personalize instruction, each new student is unique. Moreover, the education problem is inherently difficult because the learning process is only partially observable. We therefore develop a dynamic, time-series environment to simulate a classroom setting, with student-teacher interventions - including tutoring sessions, lectures, and exams. In particular, we design the simulated environment to allow for varying levels of probing interventions that can gather more information. Then, we develop reinforcement learning ITSs that combine learning the individual state of students while pulling from population information through the use of probing interventions. These interventions can reduce the difficulty of student estimation, but also introduce a cost-benefit decision to find a balance between probing enough to get accurate estimates and probing so often that it becomes disruptive to the student. We compare the efficacy of standard RL algorithms with several greedy rules-based heuristic approaches to find that they provide different solutions, but with similar results. We also highlight the difficulty of the problem with increasing levels of hidden information, and the boost that we get if we allow for probing interventions. We show the flexibility of both heuristic and RL policies with regards to changing student population distributions, finding that both are flexible, but RL policies struggle to help harder classes. Finally, we test different course structures with non-probing policies and we find that our policies are able to boost the performance of quiz and midterm structures more than we can in a finals-only structure, highlighting the benefit of having additional information.

</details>


### [121] [Cross-Modal Consistency-Guided Active Learning for Affective BCI Systems](https://arxiv.org/abs/2511.15138)
*Hyo-Jeong Jang,Hye-Bin Shin,Kang Yin*

Main category: cs.LG

TL;DR: 提出了一种不确定性意识的主动学习框架，增强了EEG情感识别的鲁棒性，通过交叉模态一致性与模型不确定性共同作用，降低标签噪音影响。


<details>
  <summary>Details</summary>
Motivation: EEG信号容易受到伪影和个体差异的影响，情感标签往往来源于主观和不一致的报告，使得情感解码变得特别困难。

Method: 提出了一种基于不确定性的主动学习框架，通过共同利用模型不确定性和跨模态一致性来增强对标签噪声的鲁棒性。

Result: 在ASCERTAIN数据集上的实验验证了我们方法的效率和鲁棒性，突显了其在脑机接口系统中进行情感解码的潜力。

Conclusion: 该方法在EEG情感识别任务中展现了较高的效率和鲁棒性，具有数据高效性和抗噪性。

Abstract: Deep learning models perform best with abundant, high-quality labels, yet such conditions are rarely achievable in EEG-based emotion recognition. Electroencephalogram (EEG) signals are easily corrupted by artifacts and individual variability, while emotional labels often stem from subjective and inconsistent reports-making robust affective decoding particularly difficult. We propose an uncertainty-aware active learning framework that enhances robustness to label noise by jointly leveraging model uncertainty and cross-modal consistency. Instead of relying solely on EEG-based uncertainty estimates, the method evaluates cross-modal alignment to determine whether uncertainty originates from cognitive ambiguity or sensor noise. A representation alignment module embeds EEG and face features into a shared latent space, enforcing semantic coherence between modalities. Residual discrepancies are treated as noise-induced inconsistencies, and these samples are selectively queried for oracle feedback during active learning. This feedback-driven process guides the network toward reliable, informative samples and reduces the impact of noisy labels. Experiments on the ASCERTAIN dataset examine the efficiency and robustness of ours, highlighting its potential as a data-efficient and noise-tolerant approach for EEG-based affective decoding in brain-computer interface systems.

</details>


### [122] [Interpretable temporal fusion network of multi- and multi-class arrhythmia classification](https://arxiv.org/abs/2511.15062)
*Yun Kwan Kim*

Main category: cs.LG

TL;DR: 本研究提出了一种新的框架来检测和分类心律失常，克服了传统方法对心律失常长度变化的忽视，通过局部与全局信息的融合明显提高了检测准确性。


<details>
  <summary>Details</summary>
Motivation: 由于心律失常的长度各异，先前开发的方法未考虑这一条件，形成CDSS用于心律失常分类任务面临挑战。

Method: 框架包括局部和全局特征提取以及局部-全局信息融合，并采用注意力机制以在限制的输入长度内进行心律失常检测和分类。

Result: 在 MIT-BIH 心律失常数据库和 MIT-BIH 房颤数据库上进行的性能评估显示，所提出的方法在 10 类和 4 类心律失常检测上达到了96.45%和97.57%的 F1 分数，且与基准模型比较表现出统计上的优越性。

Conclusion: 所提出的方法有效地捕捉了局部和全局信息及动态，显著提高了心律失常的检测准确性，并能够精确确定其发生时间，从而为临床制定更精确的治疗方案提供支持。

Abstract: Clinical decision support systems (CDSSs) have been widely utilized to support the decisions made by cardiologists when detecting and classifying arrhythmia from electrocardiograms. However, forming a CDSS for the arrhythmia classification task is challenging due to the varying lengths of arrhythmias. Although the onset time of arrhythmia varies, previously developed methods have not considered such conditions. Thus, we propose a framework that consists of (i) local and global extraction and (ii) local-global information fusion with attention to enable arrhythmia detection and classification within a constrained input length. The framework's performance was evaluated in terms of 10-class and 4-class arrhythmia detection, focusing on identifying the onset and ending point of arrhythmia episodes and their duration using the MIT-BIH arrhythmia database (MITDB) and the MIT-BIH atrial fibrillation database (AFDB). Duration, episode, and Dice score performances resulted in overall F1-scores of 96.45%, 82.05%, and 96.31% on the MITDB and 97.57%, 98.31%, and 97.45% on the AFDB, respectively. The results demonstrated statistically superior performance compared to those of the benchmark models. To assess the generalization capability of the proposed method, an MITDB-trained model and MIT-BIH malignant ventricular arrhythmia database-trained model were tested AFDB and MITDB, respectively. Superior performance was attained compared with that of a state-of-the-art model. The proposed method effectively captures both local and global information and dynamics without significant information loss. Consequently, arrhythmias can be detected with greater accuracy, and their occurrence times can be precisely determined, enabling the clinical field to develop more accurate treatment plans based on the proposed method.

</details>


### [123] [Deep Pathomic Learning Defines Prognostic Subtypes and Molecular Drivers in Colorectal Cancer](https://arxiv.org/abs/2511.15067)
*Zisong Wang,Xuanyu Wang,Hang Chen,Haizhou Wang,Yuxin Chen,Yihang Xu,Yunhe Yuan,Lihuan Luo,Xitong Ling,Xiaoping Liu*

Main category: cs.LG

TL;DR: 本研究开发的TDAM-CRC模型在CRC的预后预测中表现优异，通过多组学分析揭示了新的生物标志物，并为临床提供了可解释的决策工具。


<details>
  <summary>Details</summary>
Motivation: 克服传统TNM分期系统在个性化医学中的不足，解决CRC的预后分层难题

Method: 构建和验证了一种多实例学习模型TDAM-CRC，利用组织病理全幻灯片图像进行预后预测，并整合多组学数据以提高模型的可解释性

Result: TDAM-CRC在两个队列中均实现了稳健的风险分层，其预测性能显著优于传统临床分期系统，确认其风险评分为独立预后因素，识别了MRPL37作为关键基因，且构建了包含TDAM-CRC风险评分的经过验证的临床决策工具。

Conclusion: TDAM-CRC模型在CRC风险分层中表现优越，揭示了新的生物标志物，并促进个性化的临床决策。

Abstract: Precise prognostic stratification of colorectal cancer (CRC) remains a major clinical challenge due to its high heterogeneity. The conventional TNM staging system is inadequate for personalized medicine. We aimed to develop and validate a novel multiple instance learning model TDAM-CRC using histopathological whole-slide images for accurate prognostic prediction and to uncover its underlying molecular mechanisms. We trained the model on the TCGA discovery cohort (n=581), validated it in an independent external cohort (n=1031), and further we integrated multi-omics data to improve model interpretability and identify novel prognostic biomarkers. The results demonstrated that the TDAM-CRC achieved robust risk stratification in both cohorts. Its predictive performance significantly outperformed the conventional clinical staging system and multiple state-of-the-art models. The TDAM-CRC risk score was confirmed as an independent prognostic factor in multivariable analysis. Multi-omics analysis revealed that the high-risk subtype is closely associated with metabolic reprogramming and an immunosuppressive tumor microenvironment. Through interaction network analysis, we identified and validated Mitochondrial Ribosomal Protein L37 (MRPL37) as a key hub gene linking deep pathomic features to clinical prognosis. We found that high expression of MRPL37, driven by promoter hypomethylation, serves as an independent biomarker of favorable prognosis. Finally, we constructed a nomogram incorporating the TDAM-CRC risk score and clinical factors to provide a precise and interpretable clinical decision-making tool for CRC patients. Our AI-driven pathological model TDAM-CRC provides a robust tool for improved CRC risk stratification, reveals new molecular targets, and facilitates personalized clinical decision-making.

</details>


### [124] [Novel sparse matrix algorithm expands the feasible size of a self-organizing map of the knowledge indexed by a database of peer-reviewed medical literature](https://arxiv.org/abs/2511.15136)
*Andrew Amos,Joanne Lee,Tarun Sen Gupta,Bunmi S. Malau-Aduli*

Main category: cs.LG

TL;DR: 研究开发了一种新算法，使得可以在整个Medline数据集上应用自组织映射，提供了医学知识的全面图谱。


<details>
  <summary>Details</summary>
Motivation: 过去的努力因内存和处理需求的快速增加，限制了对Medline数据库的映射，仅能使用可用数据的较小子集。

Method: 设计了一种新的稀疏矩阵乘法算法，用于对Medline数据集应用自组织映射。

Result: 通过新算法，我们能够处理整个Medline数据集，提供更全面的医学知识视图。

Conclusion: 该算法成功地为整个Medline数据集创建了一个更完整的医学知识地图，并增强了随时间推移更新自组织映射的可行性。

Abstract: Past efforts to map the Medline database have been limited to small subsets of the available data because of the exponentially increasing memory and processing demands of existing algorithms. We designed a novel algorithm for sparse matrix multiplication that allowed us to apply a self-organizing map to the entire Medline dataset, allowing for a more complete map of existing medical knowledge. The algorithm also increases the feasibility of refining the self-organizing map to account for changes in the dataset over time.

</details>


### [125] [From Solving to Verifying: A Unified Objective for Robust Reasoning in LLMs](https://arxiv.org/abs/2511.15137)
*Xiaoxuan Wang,Bo Liu,Song Jiang,Jingzhou Liu,Jingyuan Qi,Xia Chen,Baosheng He*

Main category: cs.LG

TL;DR: 通过提出GRPO-Verif算法，本文探讨了增强大语言模型自我验证能力的有效方法，实验结果显示了其在推理过程中的成功应用。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型的推理能力通过强化学习得到显著提升，但它们在自我验证推理轨迹方面仍然存在困难，因此需要探讨如何增强这一能力。

Method: 提出了一种新的算法GRPO-Verif，联合优化解决方案生成和自我验证，使用一个可调超参数来控制验证信号的权重。

Result: 实验结果表明，GRPO-Verif方法提高了自我验证能力，并且推理性能保持在可比水平。

Conclusion: GRPO-Verif算法提高了大语言模型的自我验证能力，同时保持了推理性能的可比性。

Abstract: The reasoning capabilities of large language models (LLMs) have been significantly improved through reinforcement learning (RL). Nevertheless, LLMs still struggle to consistently verify their own reasoning traces. This raises the research question of how to enhance the self-verification ability of LLMs and whether such an ability can further improve reasoning performance. In this work, we propose GRPO-Verif, an algorithm that jointly optimizes solution generation and self-verification within a unified loss function, with an adjustable hyperparameter controlling the weight of the verification signal. Experimental results demonstrate that our method enhances self-verification capability while maintaining comparable performance in reasoning.

</details>


### [126] [Complex variational autoencoders admit Kähler structure](https://arxiv.org/abs/2511.15172)
*Andrew Gracyk*

Main category: cs.LG

TL;DR: 研究了复杂变分自编码器中的Kähler几何结构，提出了高效的计算方法，显示出改善模型表示的潜力。


<details>
  <summary>Details</summary>
Motivation: 探讨复杂变分自编码器的潜在空间中Riemannian和Kähler几何结构的存在，为改进模型性能提供理论基础。

Method: 通过引入适用于复杂VAE的解码几何，推导复合高斯正则化下的Fisher信息度量。

Result: 利用Kähler潜在导数与Fisher信息度量的近似关系，提出了一种高效计算度量的方法，并展示了在样本平滑性和离群点减少上的优势。

Conclusion: 复杂变分自编码器（VAE）中的去噪和几何结构可以通过引入Kähler几何特性来得到提升，这有助于更平滑地表示样本，并减少语义离群点。

Abstract: It has been discovered that latent-Euclidean variational autoencoders (VAEs) admit, in various capacities, Riemannian structure. We adapt these arguments but for complex VAEs with a complex latent stage. We show that complex VAEs reveal to some level Kähler geometric structure. Our methods will be tailored for decoder geometry. We derive the Fisher information metric in the complex case under a latent complex Gaussian regularization with trivial relation matrix. It is well known from statistical information theory that the Fisher information coincides with the Hessian of the Kullback-Leibler (KL) divergence. Thus, the metric Kähler potential relation is exactly achieved under relative entropy. We propose a Kähler potential derivative of complex Gaussian mixtures that has rough equivalence to the Fisher information metric while still being faithful to the underlying Kähler geometry. Computation of the metric via this potential is efficient, and through our potential, valid as a plurisubharmonic (PSH) function, large scale computational burden of automatic differentiation is displaced to small scale. We show that we can regularize the latent space with decoder geometry, and that we can sample in accordance with a weighted complex volume element. We demonstrate these strategies, at the exchange of sample variation, yield consistently smoother representations and fewer semantic outliers.

</details>


### [127] [FaultDiffusion: Few-Shot Fault Time Series Generation with Diffusion Model](https://arxiv.org/abs/2511.15174)
*Yi Xu,Zhigang Chen,Rui Wang,Yangfan Li,Fengxiao Tang,Ming Zhao,Jiaqi Liu*

Main category: cs.LG

TL;DR: 本文提出了一种基于扩散模型的少样本故障时间序列生成框架，通过建模正常与故障数据之间的差异，并引入多样性损失，显著提高了故障样本的生成质量。


<details>
  <summary>Details</summary>
Motivation: 在工业设备监测中，由于故障数据稀缺，传统的数据驱动方法受到严重限制，因此需要一种新的模型来有效生成故障数据。

Method: 基于扩散模型的少样本故障时间序列生成框架，通过正负差适配器建模正常和故障领域之间的差异，并通过引入多样性损失防止模式崩溃。

Result: 实验结果表明，提出的模型在生成的故障样本的真实性和多样性方面表现显著优于传统方法。

Conclusion: 我们的模型在真实性和多样性上显著优于传统方法，在关键基准测试中取得了最先进的表现。

Abstract: In industrial equipment monitoring, fault diagnosis is critical for ensuring system reliability and enabling predictive maintenance. However, the scarcity of fault data, due to the rarity of fault events and the high cost of data annotation, significantly hinders data-driven approaches. Existing time-series generation models, optimized for abundant normal data, struggle to capture fault distributions in few-shot scenarios, producing samples that lack authenticity and diversity due to the large domain gap and high intra-class variability of faults. To address this, we propose a novel few-shot fault time-series generation framework based on diffusion models. Our approach employs a positive-negative difference adapter, leveraging pre-trained normal data distributions to model the discrepancies between normal and fault domains for accurate fault synthesis. Additionally, a diversity loss is introduced to prevent mode collapse, encouraging the generation of diverse fault samples through inter-sample difference regularization. Experimental results demonstrate that our model significantly outperforms traditional methods in authenticity and diversity, achieving state-of-the-art performance on key benchmarks.

</details>


### [128] [Masked Auto-Regressive Variational Acceleration: Fast Inference Makes Practical Reinforcement Learning](https://arxiv.org/abs/2511.15190)
*Yuxuan Gu,Weimin Bai,Yifei Wang,Weijian Luo,He Sun*

Main category: cs.LG

TL;DR: MARVAL通过压缩扩散链为单个生成步骤，显著加快了推断速度并使强化学习后训练成为实际可行，展示了生成模型的新方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统MAR在推断时因层次推断机制导致的缓慢问题，以及促进其在强化学习中的实用性。

Method: 基于蒸馏的框架，将扩散链压缩为单个自回归生成步骤，同时保持灵活的自回归解掩码顺序。

Result: 在ImageNet 256*256上，MARVAL-Huge实现了2.00的FID，相较于MAR扩散实现了30倍以上的速度提升，而MARVAL-RL在ImageNet数据集上对CLIP和图像奖励分数的一致改善。

Conclusion: MARVAL展示了对被掩盖的自回归扩散模型进行蒸馏和强化学习的第一条实际路径，从而实现了快速采样和更好的偏好一致性。

Abstract: Masked auto-regressive diffusion models (MAR) benefit from the expressive modeling ability of diffusion models and the flexibility of masked auto-regressive ordering. However, vanilla MAR suffers from slow inference due to its hierarchical inference mechanism: an outer AR unmasking loop and an inner diffusion denoising chain. Such decoupled structure not only harm the generation efficiency but also hinder the practical use of MAR for reinforcement learning (RL), an increasingly critical paradigm for generative model post-training.To address this fundamental issue, we introduce MARVAL (Masked Auto-regressive Variational Acceleration), a distillation-based framework that compresses the diffusion chain into a single AR generation step while preserving the flexible auto-regressive unmasking order. Such a distillation with MARVAL not only yields substantial inference acceleration but, crucially, makes RL post-training with verifiable rewards practical, resulting in scalable yet human-preferred fast generative models. Our contributions are twofold: (1) a novel score-based variational objective for distilling masked auto-regressive diffusion models into a single generation step without sacrificing sample quality; and (2) an efficient RL framework for masked auto-regressive models via MARVAL-RL. On ImageNet 256*256, MARVAL-Huge achieves an FID of 2.00 with more than 30 times speedup compared with MAR-diffusion, and MARVAL-RL yields consistent improvements in CLIP and image-reward scores on ImageNet datasets with entity names. In conclusion, MARVAL demonstrates the first practical path to distillation and RL of masked auto-regressive diffusion models, enabling fast sampling and better preference alignments.

</details>


### [129] [Reasoning in Diffusion Large Language Models is Concentrated in Dynamic Confusion Zones](https://arxiv.org/abs/2511.15208)
*Ranfei Chen,Ming Chen,Kaifei Wang*

Main category: cs.LG

TL;DR: 本文提出的自适应轨迹策略优化（ATPO）通过分析步骤级指标，优化了在扩散大语言模型中实施的强化学习，显著提高了推理准确性和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: The authors address the limitations of existing trajectory-based reinforcement learning methods that treat all denoising steps uniformly, which may not effectively capture the critical steps for successful reasoning in dLLMs.

Method: The paper introduces Adaptive Trajectory Policy Optimization (ATPO), which utilizes step-level metrics to assess trajectories and selectively reallocate policy gradients during reinforcement learning without altering the existing RL objectives.

Result: ATPO shows substantial gains in both reasoning accuracy and training stability across multiple benchmarks compared to traditional methods, demonstrating the importance of focusing on dynamic trajectory metrics.

Conclusion: Adaptive Trajectory Policy Optimization (ATPO) significantly improves reasoning accuracy and training stability in Diffusion Large Language Models by reallocating gradient updates to high-leverage steps identified through trajectory analysis.

Abstract: Diffusion Large Language Models (dLLMs) are rapidly emerging alongside autoregressive models as a powerful paradigm for complex reasoning, with reinforcement learning increasingly used for downstream alignment. Existing trajectory-based RL methods uniformly allocate policy gradients across denoising steps, implicitly treating all steps as equally important. We challenge this assumption by analyzing trajectories with several step-level metrics: entropy-based uncertainty, Confidence-Margin (CM) uncertainty, and Rate of Entropy Change (RoEC). These reveal structured "zones of confusion": transient spikes in uncertainty and instability that strongly predict final success or failure, while most steps remain stable. We propose Adaptive Trajectory Policy Optimization (ATPO), a lightweight step-selection strategy that dynamically reallocates gradient updates to these high-leverage steps without changing the RL objective, rewards, or compute budget. Using a hybrid RoEC+CM rule, ATPO delivers substantial gains in reasoning accuracy and training stability across benchmarks, showing that exploiting trajectory dynamics is key to advancing dLLM RL.

</details>


### [130] [EntroPIC: Towards Stable Long-Term Training of LLMs via Entropy Stabilization with Proportional-Integral Control](https://arxiv.org/abs/2511.15248)
*Kai Yang,Xin Xu,Yangkun Chen,Weijie Liu,Jiafei Lyu,Zichuan Lin,Deheng Ye,Saiyong Yang*

Main category: cs.LG

TL;DR: 本研究提出的EntroPIC方法通过动态调整正负样本的损失系数，有效稳定大语言模型训练中的熵，确保优化的强化学习过程。


<details>
  <summary>Details</summary>
Motivation: The motivation behind this work is to maintain stable exploration in long-term training of large language models, preventing them from collapsing into sub-optimal behaviors due to entropy issues.

Method: The paper proposes a novel method called Entropy stabilization via Proportional-Integral Control (EntroPIC), which adaptively adjusts loss coefficients for positive and negative samples.

Result: Experimental results demonstrate that EntroPIC maintains desired entropy levels, enabling efficient exploration and progress in large-scale LLM training.

Conclusion: EntroPIC method effectively stabilizes entropy during large language model training, facilitating optimal reinforcement learning.

Abstract: Long-term training of large language models (LLMs) requires maintaining stable exploration to prevent the model from collapsing into sub-optimal behaviors. Entropy is crucial in this context, as it controls exploration and helps avoid premature convergence to sub-optimal solutions. However, existing reinforcement learning methods struggle to maintain an appropriate level of entropy, as the training process involves a mix of positive and negative samples, each affecting entropy in different ways across steps. To address this, we propose Entropy stablilization via Proportional-Integral Control (EntroPIC), a novel method that adaptively adjusts the influence of positive and negative samples by dynamically tuning their loss coefficients. This approach stabilizes entropy throughout training, ensuring efficient exploration and steady progress. We provide a comprehensive theoretical analysis for both on-policy and off-policy learning settings, demonstrating that EntroPIC is effective at controlling entropy in large-scale LLM training. Experimental results show that our method successfully maintains desired entropy levels, enabling stable and optimal RL training for LLMs.

</details>


### [131] [GRPO-RM: Fine-Tuning Representation Models via GRPO-Driven Reinforcement Learning](https://arxiv.org/abs/2511.15256)
*Yanchen Xu,Ziheng Jiao,Hongyuan Zhang,Xuelong Li*

Main category: cs.LG

TL;DR: 本论文提出了一种新的GRPO-RM方法，旨在提升表示学习模型的后训练性能，实验表明该方法在多个数据集上效果显著。


<details>
  <summary>Details</summary>
Motivation: 探讨GRPO在表示学习模型中的推广能力，并优化后训练表示模型的效果。

Method: 提出了一种新的群体相对策略优化方法（GRPO-RM），并设计了适合表示模型的奖励函数。

Result: 在多个现实世界数据集上进行的广泛实验验证了GRPO-RM的有效性。

Conclusion: GRPO-RM有效提升了表示学习模型的性能，特别是在后训练阶段的应用中展现了良好的效果。

Abstract: The Group Relative Policy Optimization (GRPO), a reinforcement learning method used to fine-tune large language models (LLMs), has proved its effectiveness in practical applications such as DeepSeek-R1. It raises a question whether GRPO can be generalized to representation learning models. In this paper, we propose Group Relative Policy Optimization for Representation Model (GRPO-RM), and investigate the performance of GRPO-like policy in post-training representation models. Specifically, our method establishes a predefined output set to functionally replace token sequence sampling in LLMs, thereby generating an output group, which is essential for the probability-driven optimization of GRPO. In addition, a specialized reward function is designed to accommodate the properties of representation models. Extensive experiments are conducted on various real-world datasets to validate the effectiveness of our proposed method.

</details>


### [132] [SNAP: Low-Latency Test-Time Adaptation with Sparse Updates](https://arxiv.org/abs/2511.15276)
*Hyeongheon Cha,Dong Min Kim,Hye Won Chung,Taesik Gong,Sung-Ju Lee*

Main category: cs.LG

TL;DR: SNAP是一种新颖的测试时间适应框架，能够在边缘设备上以低资源消耗实现高效适应，显著降低延迟和准确率下降。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时间适应方法依赖频繁的适应和高计算成本，不适合资源受限的边缘环境，因此提出了SNAP以解决这个问题。

Method: 提出了一种稀疏的测试时间适应框架SNAP，结合了类和领域代表记忆（CnDRM）以及推理时的批量感知记忆标准化（IoBMN）。

Result: SNAP能够在仅使用1%的数据流进行适应的情况下，保持竞争力的准确率，并且在与五个最先进的TTA算法集成时有效降低延迟。

Conclusion: SNAP在边缘设备上具有强大的实用潜力，能在适应率从1%到50%之间，保持准确率下降低于3.3%，并将延迟减少高达93.12%。

Abstract: Test-Time Adaptation (TTA) adjusts models using unlabeled test data to handle dynamic distribution shifts. However, existing methods rely on frequent adaptation and high computational cost, making them unsuitable for resource-constrained edge environments. To address this, we propose SNAP, a sparse TTA framework that reduces adaptation frequency and data usage while preserving accuracy. SNAP maintains competitive accuracy even when adapting based on only 1% of the incoming data stream, demonstrating its robustness under infrequent updates. Our method introduces two key components: (i) Class and Domain Representative Memory (CnDRM), which identifies and stores a small set of samples that are representative of both class and domain characteristics to support efficient adaptation with limited data; and (ii) Inference-only Batch-aware Memory Normalization (IoBMN), which dynamically adjusts normalization statistics at inference time by leveraging these representative samples, enabling efficient alignment to shifting target domains. Integrated with five state-of-the-art TTA algorithms, SNAP reduces latency by up to 93.12%, while keeping the accuracy drop below 3.3%, even across adaptation rates ranging from 1% to 50%. This demonstrates its strong potential for practical use on edge devices serving latency-sensitive applications. The source code is available at https://github.com/chahh9808/SNAP.

</details>


### [133] [Quant-Trim in Practice: Improved Cross-Platform Low-Bit Deployment on Edge NPUs](https://arxiv.org/abs/2511.15300)
*Rayen Dhahri,Steffen Urban*

Main category: cs.LG

TL;DR: 量化修剪是一种能在多个硬件后端上有效提高低位量化模型准确性的训练阶段方法，无需依赖供应商特定的图更改。


<details>
  <summary>Details</summary>
Motivation: 现有的低位量化模型在不同供应商的后端上表现不一致，迫使实践者调整标志或重构模型以适应特定供应商的操作符子集。

Method: 通过渐进的伪量化和逆修剪结合来生产硬件中立的检查点，确保训练与部署整数网格一致，同时减少异常驱动的规模膨胀。

Result: 量化修剪使得模型在多个后端和任务上的FP与低位的差距缩小，提供了在各种激活缩放和操作符覆盖下的准确性及边缘指标（延迟、吞吐量、能耗/推理及成本）的报告。

Conclusion: Quant-Trim能够提高低位量化模型在不同硬件后端上的准确性，减少对编译器启发式和校准的依赖，以及避免针对每个后端的重新训练。

Abstract: Specialized edge accelerators rely on low-bit quantization, but vendor compilers differ in scaling, clipping, and kernel support, often as black boxes. The same floating-point (FP) checkpoint can therefore yield inconsistent accuracy across backends, forcing practitioners to tweak flags or refactor models to vendor-friendly operator subsets. We introduce Quant-Trim, a training-phase method that produces a hardware-neutral checkpoint robust to backend and precision choices. It combines progressive fake quantization to align training with the deployed integer grid and reverse pruning to tame outlier-driven scale inflation while preserving learnability. Quant-Trim is agnostic to quantization schemes (symmetric/asymmetric,per-tensor/per-channel, INT8/INT4) and requires no vendor-specific graph changes.Across models and tasks, it narrows the FP,low-bit gap, reduces dependence on compiler heuristics/calibration, and avoids per-backend retraining. We report accuracy and edge metrics latency, throughput, energy/inference, and cost under static/dynamic activation scaling and varying operator coverage.

</details>


### [134] [On the Internal Semantics of Time-Series Foundation Models](https://arxiv.org/abs/2511.15324)
*Atharva Pandey,Abhilash Neog,Gautam Jajoo*

Main category: cs.LG

TL;DR: 本文系统研究了时间序列基础模型（TSFMs）中的概念可解释性，发现早期层主要捕获局部模式，而组合概念的处理存在挑战。


<details>
  <summary>Details</summary>
Motivation: 虽然TSFMs在各类时间领域取得了经验上的成功，但其内部机制及基本时间序列概念的表示仍不够明确。

Method: 采用层次分析、线性可恢复性测试和表示相似性度量进行系统调查。

Result: 研究表明早期层主要捕捉局部时间域模式，而更深层则编码分散和变更信号，同时在组合设置中探测性能下降，揭示概念之间的干扰。

Conclusion: 当前的时间序列基础模型（TSFMs）在表示相互作用的时间现象方面存在关键局限性，尤其是在概念的组合处理上表现不佳。

Abstract: Time-series Foundation Models (TSFMs) have recently emerged as a universal paradigm for learning across diverse temporal domains. However, despite their empirical success, the internal mechanisms by which these models represent fundamental time-series concepts remain poorly understood. In this work, we undertake a systematic investigation of concept interpretability in TSFMs. Specifically, we examine: (i) which layers encode which concepts, (ii) whether concept parameters are linearly recoverable, (iii) how representations evolve in terms of concept disentanglement and abstraction across model depth, and (iv) how models process compositions of concepts. We systematically probe these questions using layer-wise analyses, linear recoverability tests, and representation similarity measures, providing a structured account of TSFM semantics. The resulting insights show that early layers mainly capture local, time-domain patterns (e.g., AR(1), level shifts, trends), while deeper layers encode dispersion and change-time signals, with spectral and warping factors remaining the hardest to recover linearly. In compositional settings, however, probe performance degrades, revealing interference between concepts. This highlights that while atomic concepts are reliably localized, composition remains a challenge, underscoring a key limitation in current TSFMs' ability to represent interacting temporal phenomena.

</details>


### [135] [Multi-layer Stack Ensembles for Time Series Forecasting](https://arxiv.org/abs/2511.15350)
*Nathanael Bosch,Oleksandr Shchur,Nick Erickson,Michael Bohlke-Schneider,Caner Türkmen*

Main category: cs.LG

TL;DR: 本研究探讨了时间序列预测的集成策略，提出多层堆叠框架，显示出在不同情境下的准确性提升。


<details>
  <summary>Details</summary>
Motivation: 虽然集成方法在机器学习中提升模型准确性表现强劲，但在时间序列预测中应用不多，仍以简单线性组合为主。

Method: 系统评估33种集成模型，包括现有模型和新模型，应用于50个真实世界数据集。

Result: 堆叠方法在准确性上始终有改进，但没有单一堆叠器在所有任务中表现最佳。

Conclusion: 提出的多层堆叠框架在各种预测场景中始终提供优越的准确性，显示了堆叠方法在时间序列预测中的潜力。

Abstract: Ensembling is a powerful technique for improving the accuracy of machine learning models, with methods like stacking achieving strong results in tabular tasks. In time series forecasting, however, ensemble methods remain underutilized, with simple linear combinations still considered state-of-the-art. In this paper, we systematically explore ensembling strategies for time series forecasting. We evaluate 33 ensemble models -- both existing and novel -- across 50 real-world datasets. Our results show that stacking consistently improves accuracy, though no single stacker performs best across all tasks. To address this, we propose a multi-layer stacking framework for time series forecasting, an approach that combines the strengths of different stacker models. We demonstrate that this method consistently provides superior accuracy across diverse forecasting scenarios. Our findings highlight the potential of stacking-based methods to improve AutoML systems for time series forecasting.

</details>


### [136] [Cost-Aware Prediction (CAP): An LLM-Enhanced Machine Learning Pipeline and Decision Support System for Heart Failure Mortality Prediction](https://arxiv.org/abs/2511.15357)
*Yinan Yu,Falk Dippel,Christina E. Lundberg,Martin Lindgren,Annika Rosengren,Martin Adiels,Helen Sjöland*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Objective: Machine learning (ML) predictive models are often developed without considering downstream value trade-offs and clinical interpretability. This paper introduces a cost-aware prediction (CAP) framework that combines cost-benefit analysis assisted by large language model (LLM) agents to communicate the trade-offs involved in applying ML predictions. Materials and Methods: We developed an ML model predicting 1-year mortality in patients with heart failure (N = 30,021, 22% mortality) to identify those eligible for home care. We then introduced clinical impact projection (CIP) curves to visualize important cost dimensions - quality of life and healthcare provider expenses, further divided into treatment and error costs, to assess the clinical consequences of predictions. Finally, we used four LLM agents to generate patient-specific descriptions. The system was evaluated by clinicians for its decision support value. Results: The eXtreme gradient boosting (XGB) model achieved the best performance, with an area under the receiver operating characteristic curve (AUROC) of 0.804 (95% confidence interval (CI) 0.792-0.816), area under the precision-recall curve (AUPRC) of 0.529 (95% CI 0.502-0.558) and a Brier score of 0.135 (95% CI 0.130-0.140). Discussion: The CIP cost curves provided a population-level overview of cost composition across decision thresholds, whereas LLM-generated cost-benefit analysis at individual patient-levels. The system was well received according to the evaluation by clinicians. However, feedback emphasizes the need to strengthen the technical accuracy for speculative tasks. Conclusion: CAP utilizes LLM agents to integrate ML classifier outcomes and cost-benefit analysis for more transparent and interpretable decision support.

</details>


### [137] [CID: Measuring Feature Importance Through Counterfactual Distributions](https://arxiv.org/abs/2511.15371)
*Eddie Conti,Álvaro Parafita,Axel Brando*

Main category: cs.LG

TL;DR: 本文提出了一种新的后验局部特征重要性方法CID，通过反事实生成和分布分析，提高模型解释的可靠性。


<details>
  <summary>Details</summary>
Motivation: 理解机器学习模型的决策过程需要评估个体特征的重要性，目前缺乏可靠的比较标准。

Method: 生成积极和消极的反事实，使用核密度估计建模它们的分布，并基于分布相似性度量对特征进行排名。

Result: 与传统特征重要性解释方法相比，CID方法不仅提供了补充视角，还在可信度度量上提升了性能。

Conclusion: CID方法提供了更可信的特征重要性评估，有助于模型分析。

Abstract: Assessing the importance of individual features in Machine Learning is critical to understand the model's decision-making process. While numerous methods exist, the lack of a definitive ground truth for comparison highlights the need for alternative, well-founded measures. This paper introduces a novel post-hoc local feature importance method called Counterfactual Importance Distribution (CID). We generate two sets of positive and negative counterfactuals, model their distributions using Kernel Density Estimation, and rank features based on a distributional dissimilarity measure. This measure, grounded in a rigorous mathematical framework, satisfies key properties required to function as a valid metric. We showcase the effectiveness of our method by comparing with well-established local feature importance explainers. Our method not only offers complementary perspectives to existing approaches, but also improves performance on faithfulness metrics (both for comprehensiveness and sufficiency), resulting in more faithful explanations of the system. These results highlight its potential as a valuable tool for model analysis.

</details>


### [138] [Parameter Importance-Driven Continual Learning for Foundation Models](https://arxiv.org/abs/2511.15375)
*Lingxiang Wang,Hainan Zhang,Zhiming Zheng*

Main category: cs.LG

TL;DR: PIECE是一种新的持续学习方法，通过选择性更新少量核心参数来保持模型通用能力并学习领域知识，避免灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 解决领域特定后训练导致的灾难性遗忘问题，保持通用能力的同时有效学习领域知识。

Method: 提出了一种基于参数重要性估计的持续增强方法，只选择与新任务相关的0.1%核心参数进行更新。

Result: 在三个语言模型和两个多模态模型上的实验表明，PIECE保持了通用能力，并在多样化的下游任务中达到了最先进的持续学习性能。

Conclusion: PIECE方法在不增加模型参数的前提下，有效地保持了模型的通用能力，并在下游任务中表现出色，展示了可扩展的领域适应性基础模型的可能路径。

Abstract: Domain-specific post-training often causes catastrophic forgetting, making foundation models lose their general reasoning ability and limiting their adaptability to dynamic real-world environments. Preserving general capabilities while acquiring downstream domain knowledge is a central challenge for large language and multimodal models. Traditional continual learning methods, such as regularization, replay and architectural isolation, suffer from poor downstream performance, reliance on inaccessible historical data, or additional parameter overhead. While recent parameter-efficient tuning (PET) methods can alleviate forgetting, their effectiveness strongly depends on the choice of parameters and update strategies. In this paper, we introduce PIECE, a Parameter Importance Estimation-based Continual Enhancement method that preserves general ability while efficiently learning domain knowledge without accessing prior training data or increasing model parameters. PIECE selectively updates only 0.1% of core parameters most relevant to new tasks, guided by two importance estimators: PIECE-F based on Fisher Information, and PIECE-S based on a second-order normalization that combines gradient and curvature information. Experiments across three language models and two multimodal models show that PIECE maintains general capabilities and achieves state-of-the-art continual learning performance across diverse downstream tasks. Our results highlight a practical path to scalable, domain-adaptive foundation models without catastrophic forgetting.

</details>


### [139] [Proximal Approximate Inference in State-Space Models](https://arxiv.org/abs/2511.15409)
*Hany Abdulsamad,Ángel F. García-Fernández,Simo Särkkä*

Main category: cs.LG

TL;DR: 本文提出了一种非线性、非高斯状态空间模型的状态估计算法，基于变分拉格朗日形式，具有较优的计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决非线性、非高斯状态空间模型的状态估计难题，提升计算效率。

Method: 使用变分拉格朗日公式，将贝叶斯推断看作受动态约束的熵信任域更新序列。

Result: 通过对高斯-马尔可夫近似的关注，提出了具有较好计算复杂度的递归方案，并针对一般非线性、非高斯模型采用广义统计线性回归和傅里叶-亥姆顿矩匹配来收敛递归。

Conclusion: 该算法在非线性、非高斯状态空间模型的状态估计问题上表现良好，具有较好的计算复杂度。

Abstract: We present a class of algorithms for state estimation in nonlinear, non-Gaussian state-space models. Our approach is based on a variational Lagrangian formulation that casts Bayesian inference as a sequence of entropic trust-region updates subject to dynamic constraints. This framework gives rise to a family of forward-backward algorithms, whose structure is determined by the chosen factorization of the variational posterior. By focusing on Gauss--Markov approximations, we derive recursive schemes with favorable computational complexity. For general nonlinear, non-Gaussian models we close the recursions using generalized statistical linear regression and Fourier--Hermite moment matching.

</details>


### [140] [Towards Understanding Layer Contributions in Tabular In-Context Learning Models](https://arxiv.org/abs/2511.15432)
*Amir Rezaei Balef,Mykhailo Koshil,Katharina Eggensperger*

Main category: cs.LG

TL;DR: 本研究探讨了表格内置学习模型各层的作用及其与大型语言模型的比较，发现存在结构性冗余，为模型压缩与可解释性改进提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 虽然表格内置学习（ICL）模型和大型语言模型（LLMs）在架构上相似，但对单层在表格预测中贡献的了解仍然有限，因此有必要研究其层间动态。

Method: 采用“层作为画家”的视角分析TabPFN和TabICL模型中各层潜在空间的演变，并比较与大型语言模型（LLMs）的动态特征。

Result: 通过对TabPFN和TabICL模型的分析，识别出潜在的冗余层，揭示了层的作用与LLMs中观察到的动态特征之间的差异。

Conclusion: 通过对层之间的动态分析，发现仅有部分层共享共同的表征语言，这表明存在结构冗余，并为模型压缩和提升可解释性提供了机会。

Abstract: Despite the architectural similarities between tabular in-context learning (ICL) models and large language models (LLMs), little is known about how individual layers contribute to tabular prediction. In this paper, we investigate how the latent spaces evolve across layers in tabular ICL models, identify potential redundant layers, and compare these dynamics with those observed in LLMs. We analyze TabPFN and TabICL through the "layers as painters" perspective, finding that only subsets of layers share a common representational language, suggesting structural redundancy and offering opportunities for model compression and improved interpretability.

</details>


### [141] [TSFM in-context learning for time-series classification of bearing-health status](https://arxiv.org/abs/2511.15447)
*Michel Tokic,Slobodan Djukanović,Anja von Beuningen,Cheng Feng*

Main category: cs.LG

TL;DR: 本文提出了一种利用上下文学习进行时间序列数据分类的方法，应用于伺服电机中的轴承健康状态评估，展示了良好的可扩展性和有效性。


<details>
  <summary>Details</summary>
Motivation: 通过使用未包含在TSFM训练数据中的数据进行分类，探索在不同操作条件下健康状态评估的新方法。

Method: 使用上下文学习的分类方法，应用于时间序列基础模型（TSFM），无需对模型进行微调。

Result: 通过将频域参考信号转换为伪时间序列模式，生成对齐的协变量和目标信号，TSFM能够预测分类数据与预定义标签的概率。

Conclusion: 该方法展示了在多种操作条件下的有效性，标志着从定制狭义AI解决方案向更广泛的AI驱动维护系统的重大进展。

Abstract: This paper introduces a classification method using in-context learning in time-series foundation models (TSFM). We show how data, which was not part of the TSFM training data corpus, can be classified without the need of finetuning the model. Examples are represented in the form of targets (class id) and covariates (data matrix) within the prompt of the model, which enables to classify an unknown covariate data pattern alongside the forecast axis through in-context learning. We apply this method to vibration data for assessing the health state of a bearing within a servo-press motor. The method transforms frequency domain reference signals into pseudo time-series patterns, generates aligned covariate and target signals, and uses the TSFM to predict probabilities how classified data corresponds to predefined labels. Leveraging the scalability of pre-trained models this method demonstrates efficacy across varied operational conditions. This marks significant progress beyond custom narrow AI solutions towards broader, AI-driven maintenance systems.

</details>


### [142] [FairEnergy: Contribution-Based Fairness meets Energy Efficiency in Federated Learning](https://arxiv.org/abs/2511.15454)
*Ouiame Marnissi,Hajar EL Hammouti,El Houcine Bergou*

Main category: cs.LG

TL;DR: FairEnergy是一个能量最小化框架，解决了无线边缘系统中的公平性和效率问题，实验结果表明其在保持模型准确性的同时，能量消耗减少了79%。


<details>
  <summary>Details</summary>
Motivation: 旨在解决无线边缘系统中数据隐私和能量效率之间的矛盾，同时保证公正参与和模型准确性。

Method: 通过放宽二进制选择变量并应用拉格朗日分解，解决了混合整数非凸问题，并进行了每设备的子问题优化。

Result: FairEnergy在实验中显示出相比基线策略更高的准确性，且能量消耗减少显著。

Conclusion: FairEnergy显著提高了模型准确性，同时在不平衡的数据情况下减少了能量消耗，最多可减少79%。

Abstract: Federated learning (FL) enables collaborative model training across distributed devices while preserving data privacy. However, balancing energy efficiency and fair participation while ensuring high model accuracy remains challenging in wireless edge systems due to heterogeneous resources, unequal client contributions, and limited communication capacity. To address these challenges, we propose FairEnergy, a fairness-aware energy minimization framework that integrates a contribution score capturing both the magnitude of updates and their compression ratio into the joint optimization of device selection, bandwidth allocation, and compression level. The resulting mixed-integer non-convex problem is solved by relaxing binary selection variables and applying Lagrangian decomposition to handle global bandwidth coupling, followed by per-device subproblem optimization. Experiments on non-IID data show that FairEnergy achieves higher accuracy while reducing energy consumption by up to 79\% compared to baseline strategies.

</details>


### [143] [NTK-Guided Implicit Neural Teaching](https://arxiv.org/abs/2511.15487)
*Chen Zhang,Wei Zuo,Bingyang Cheng,Yikun Wang,Wei-Bin Kou,Yik Chung WU,Ngai Wong*

Main category: cs.LG

TL;DR: 本文提出NTK引导的隐式神经教学(NINT)，有效减少了训练时间，提升了训练效率。


<details>
  <summary>Details</summary>
Motivation: 虽然隐式神经表示能以紧凑、分辨率独立的方式对高分辨率信号进行建模，但优化数以百万计的坐标会导致高昂的计算成本。

Method: 提出了NTK引导的隐式神经教学(NINT)，通过动态选择最大化全局功能更新的坐标来加速训练。

Result: NINT通过评估NTK增强的损失梯度的范数来选择样本，能够更快地收敛，训练时间减少近一半。

Conclusion: NINT显著减少了训练时间，同时保持或提高了表示质量，成为近年来基于采样策略中的加速方法的最先进技术。

Abstract: Implicit Neural Representations (INRs) parameterize continuous signals via multilayer perceptrons (MLPs), enabling compact, resolution-independent modeling for tasks like image, audio, and 3D reconstruction. However, fitting high-resolution signals demands optimizing over millions of coordinates, incurring prohibitive computational costs. To address it, we propose NTK-Guided Implicit Neural Teaching (NINT), which accelerates training by dynamically selecting coordinates that maximize global functional updates. Leveraging the Neural Tangent Kernel (NTK), NINT scores examples by the norm of their NTK-augmented loss gradients, capturing both fitting errors and heterogeneous leverage (self-influence and cross-coordinate coupling). This dual consideration enables faster convergence compared to existing methods. Through extensive experiments, we demonstrate that NINT significantly reduces training time by nearly half while maintaining or improving representation quality, establishing state-of-the-art acceleration among recent sampling-based strategies.

</details>


### [144] [Sample-Adaptivity Tradeoff in On-Demand Sampling](https://arxiv.org/abs/2511.15507)
*Nika Haghtalab,Omar Montasser,Mingda Qiao*

Main category: cs.LG

TL;DR: 研究了多分布学习中的样本复杂度与轮次复杂度的权衡，提出了OODS框架及相关算法，展示了其在不同情况下的最优性。


<details>
  <summary>Details</summary>
Motivation: 探讨在有限轮次下的多分布学习中的样本和轮次之间的权衡。

Method: 研究样本复杂度和轮次复杂度之间的权衡，提出适应性采样算法。

Result: 在可实现和不可实现的多分布学习中，分别给出样本复杂度的近似最优算法。

Conclusion: 引入新的框架OODS，并给出近似最优的样本复杂度和轮次复杂度结果。

Abstract: We study the tradeoff between sample complexity and round complexity in on-demand sampling, where the learning algorithm adaptively samples from $k$ distributions over a limited number of rounds. In the realizable setting of Multi-Distribution Learning (MDL), we show that the optimal sample complexity of an $r$-round algorithm scales approximately as $dk^{Θ(1/r)} / ε$. For the general agnostic case, we present an algorithm that achieves near-optimal sample complexity of $\widetilde O((d + k) / ε^2)$ within $\widetilde O(\sqrt{k})$ rounds. Of independent interest, we introduce a new framework, Optimization via On-Demand Sampling (OODS), which abstracts the sample-adaptivity tradeoff and captures most existing MDL algorithms. We establish nearly tight bounds on the round complexity in the OODS setting. The upper bounds directly yield the $\widetilde O(\sqrt{k})$-round algorithm for agnostic MDL, while the lower bounds imply that achieving sub-polynomial round complexity would require fundamentally new techniques that bypass the inherent hardness of OODS.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [145] [Distributed primal-dual algorithm for constrained multi-agent reinforcement learning under coupled policies](https://arxiv.org/abs/2511.15053)
*Pengcheng Dai,He Wang,Dongming Wang,Wenwu Yu*

Main category: cs.MA

TL;DR: 本文研究了一种多智能体强化学习框架，提出了基于分布式原始-对偶算法的安全协作学习方法，并在GridWorld环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究目标是实现多智能体协作学习，同时确保个体安全约束得到满足。

Method: 本文提出了一种分布式原始-对偶算法，所有智能体通过局部状态和邻域信息进行政策构建和更新。

Result: 算法在高概率下实现了有限阶的收敛，并证明了收敛的近似误差。

Conclusion: 提出的算法在GridWorld环境中表现出色，能够有效实现多智能体的协同学习与安全约束的满足。

Abstract: In this work, we investigate constrained multi-agent reinforcement learning (CMARL), where agents collaboratively maximize the sum of their local objectives while satisfying individual safety constraints. We propose a framework where agents adopt coupled policies that depend on both local states and parameters, as well as those of their $κ_p$-hop neighbors, with $κ_p>0$ denoting the coupling distance. A distributed primal-dual algorithm is further developed under this framework, wherein each agent has access only to state-action pairs within its $2κ_p$-hop neighborhood and to reward information within its $κ+ 2κ_p$-hop neighborhood, with $κ> 0$ representing the truncation distance. Moreover, agents are not permitted to directly share their true policy parameters or Lagrange multipliers. Instead, each agent constructs and maintains local estimates of these variables for other agents and employs such estimates to execute its policy. Additionally, these estimates are further updated and exchanged exclusively through an independent, time-varying networks, which enhances the overall system security. We establish that, with high probability, our algorithm can achieve an $ε$-first-order stationary convergence with an approximation error of $\mathcal{O}(γ^{\frac{κ+1}{κ_{p}}})$ for discount factor $γ\in(0,1)$. Finally, simulations in GridWorld environment are conducted to demonstrate the effectiveness of the proposed algorithm.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [146] [ChartEditor: A Reinforcement Learning Framework for Robust Chart Editing](https://arxiv.org/abs/2511.15266)
*Liangyu Chen,Yichen Xu,Jianzhe Ma,Yuqi Liu,Donglu Yang,Liang Zhang,Wenxuan Wang,Qin Jin*

Main category: cs.MM

TL;DR: 本文提出了ChartEditVista，一个新的图表编辑基准，和ChartEditor，一个基于强化学习的图表编辑模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决现实场景中数据多样性不足和对完整图表代码假设的限制。

Method: 使用全自动管道生成ChartEditVista，并采用强化学习框架训练ChartEditor。

Result: ChartEditVista包含7964个样本，涵盖31种图表类别，并提供细粒度评估指标。

Conclusion: ChartEditVista建立了一个多样化的基准，并证明了ChartEditor在图表编辑任务中优于现有模型。

Abstract: Chart editing reduces manual effort in visualization design. Typical benchmarks limited in data diversity and assume access to complete chart code, which is seldom in real-world scenarios. To address this gap, we present ChartEditVista, a comprehensive benchmark consisting of 7,964 samples spanning 31 chart categories. It encompasses diverse editing instructions and covers nearly all editable chart elements. The inputs in ChartEditVista include only the original chart image and natural language editing instructions, without the original chart codes. ChartEditVista is generated through a fully automated pipeline that produces, edits, and verifies charts, ensuring high-quality chart editing data. Besides, we introduce two novel fine-grained, rule-based evaluation metrics: the layout metric, which evaluates the position, size and color of graphical components; and the text metric, which jointly assesses textual content and font styling. Building on top of ChartEditVista, we present ChartEditor, a model trained using a reinforcement learning framework that incorporates a novel rendering reward to simultaneously enforce code executability and visual fidelity. Through extensive experiments and human evaluations, we demonstrate that ChartEditVista provides a robust evaluation, while ChartEditor consistently outperforms models with similar-scale and larger-scale on chart editing tasks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [147] [Learning Interestingness in Automated Mathematical Theory Formation](https://arxiv.org/abs/2511.14778)
*George Tsoukalas,Rahul Saha,Amitayush Thakur,Sabrina Reguyal,Swarat Chaudhuri*

Main category: cs.AI

TL;DR: 本研究通过FERMAT环境探讨数学理论的自动发现，成功实现了有趣性评分并提升了理论发现的效率。


<details>
  <summary>Details</summary>
Motivation: 我们的目标是自动化开放式的新数学理论发现，这是人工智能领域的一项重要挑战。

Method: 通过引入FERMAT强化学习环境并使用进化算法来自动评分数学对象的有趣性。

Result: 使用FERMAT实现了对数学对象有趣性的自动评分，并通过基于LLM的进化算法在基础数学和有限域的发现中取得了显著改善。

Conclusion: 我们提出的FERMAT环境成功推动了数学理论的自动发现，并在评分数学对象的有趣性上取得了显著进展。

Abstract: We take two key steps in automating the open-ended discovery of new mathematical theories, a grand challenge in artificial intelligence. First, we introduce $\emph{FERMAT}$, a reinforcement learning (RL) environment that models concept discovery and theorem-proving using a set of symbolic actions, opening up a range of RL problems relevant to theory discovery. Second, we explore a specific problem through $\emph{FERMAT}$: automatically scoring the $\emph{interestingness}$ of mathematical objects. We investigate evolutionary algorithms for synthesizing nontrivial interestingness measures. In particular, we introduce an LLM-based evolutionary algorithm that features function abstraction, leading to notable improvements in discovering elementary number theory and finite fields over hard-coded baselines. We open-source the $\emph{FERMAT}$ environment at this URL(https://github.com/trishullab/Fermat).

</details>


### [148] [Ask WhAI:Probing Belief Formation in Role-Primed LLM Agents](https://arxiv.org/abs/2511.14780)
*Keith Moore,Jun W. Kim,David Lyu,Jeffrey Heo,Ehsan Adeli*

Main category: cs.AI

TL;DR: 本论文提出Ask WhAI框架，以便在多智能体交互中检查和干预信念状态，应用于医学案例模拟，揭示信念形成的动态及其科学推理中的限制。


<details>
  <summary>Details</summary>
Motivation: 为了解决多智能体互动中的信念状态调研方法，特别是在医学案例模拟中，探索智能体信念与现实世界学科立场之间的关联。

Method: 采用系统框架记录和重放智能体交互，支持查询智能体的信念和推理，并注入反事实证据以测试信念结构对新信息的反应。

Result: 在儿童神经精神表现的多学科诊断旅程中，模拟展示了智能体信念与真实世界学科的相似性，例如对经典研究的过度依赖和对反证据的抵制，并能够通过特殊方式追踪和审问这些信念。

Conclusion: Ask WhAI为多智能体互动中的信念状态检查和扰动提供了可重现的研究方法，揭示了信念形成及其限制的动态变化。

Abstract: We present Ask WhAI, a systems-level framework for inspecting and perturbing belief states in multi-agent interactions. The framework records and replays agent interactions, supports out-of-band queries into each agent's beliefs and rationale, and enables counterfactual evidence injection to test how belief structures respond to new information. We apply the framework to a medical case simulator notable for its multi-agent shared memory (a time-stamped electronic medical record, or EMR) and an oracle agent (the LabAgent) that holds ground truth lab results revealed only when explicitly queried. We stress-test the system on a multi-specialty diagnostic journey for a child with an abrupt-onset neuropsychiatric presentation. Large language model agents, each primed with strong role-specific priors ("act like a neurologist", "act like an infectious disease specialist"), write to a shared medical record and interact with a moderator across sequential or parallel encounters. Breakpoints at key diagnostic moments enable pre- and post-event belief queries, allowing us to distinguish entrenched priors from reasoning or evidence-integration effects. The simulation reveals that agent beliefs often mirror real-world disciplinary stances, including overreliance on canonical studies and resistance to counterevidence, and that these beliefs can be traced and interrogated in ways not possible with human experts. By making such dynamics visible and testable, Ask WhAI offers a reproducible way to study belief formation and epistemic silos in multi-agent scientific reasoning.

</details>


### [149] [Subnational Geocoding of Global Disasters Using Large Language Models](https://arxiv.org/abs/2511.14788)
*Michele Ronco,Damien Delforge,Wiebke S. Jäger,Christina Corbane*

Main category: cs.AI

TL;DR: 本研究提出了一种自动化的LLM辅助工作流程，能够高效清理和处理灾害事件的文本位置数据，通过交叉核对多个地理信息库生成可靠的位置几何信息。


<details>
  <summary>Details</summary>
Motivation: 针对灾害事件的位置数据通常以非结构化文本形式报告，导致难以与空间数据集集成，因此开发一种自动化工作流程以提高数据处理效率和准确性。

Method: 使用GPT-4o处理和清理文本位置信息，并通过交叉核对三个独立的地理信息库（GADM，OpenStreetMap和Wikidata）来分配几何数据。

Result: 该工作流程应用于2000年至2024年的EM-DAT数据集，成功地对14,215个事件进行了地理编码，覆盖了17,948个独特位置，且使用的小写干预，适用面广，支持多源交叉验证。

Conclusion: 提出的全自动LLM辅助工作流程能够有效处理和清理灾害事件的文本位置数据，并能够生成可靠的子国家几何数据，为风险评估和减灾提供了高效工具。

Abstract: Subnational location data of disaster events are critical for risk assessment and disaster risk reduction. Disaster databases such as EM-DAT often report locations in unstructured textual form, with inconsistent granularity or spelling, that make it difficult to integrate with spatial datasets. We present a fully automated LLM-assisted workflow that processes and cleans textual location information using GPT-4o, and assigns geometries by cross-checking three independent geoinformation repositories: GADM, OpenStreetMap and Wikidata. Based on the agreement and availability of these sources, we assign a reliability score to each location while generating subnational geometries. Applied to the EM-DAT dataset from 2000 to 2024, the workflow geocodes 14,215 events across 17,948 unique locations. Unlike previous methods, our approach requires no manual intervention, covers all disaster types, enables cross-verification across multiple sources, and allows flexible remapping to preferred frameworks. Beyond the dataset, we demonstrate the potential of LLMs to extract and structure geographic information from unstructured text, offering a scalable and reliable method for related analyses.

</details>


### [150] [Project Rachel: Can an AI Become a Scholarly Author?](https://arxiv.org/abs/2511.14819)
*Martin Monperrus,Benoit Baudry,Clément Vidal*

Main category: cs.AI

TL;DR: 本研究通过AI身份Rachel So的行动研究，分析AI作者对学术界的影响，提供未来学术沟通的实证数据。


<details>
  <summary>Details</summary>
Motivation: 旨在研究学术界如何回应AI作者的出现，探讨AI在学术出版中所引发的变化。

Method: 通过行动研究方式跟踪生成的AI学术身份Rachel So的发表情况。

Result: Rachel So在2025年出版了10多篇论文，获得引用并受邀参与同行评审，展示了AI在学术领域的潜在身份。

Conclusion: 本研究探讨了AI作者身份对学术生态系统的影响，提供了关于未来学术沟通的实证研究数据。

Abstract: This paper documents Project Rachel, an action research study that created and tracked a complete AI academic identity named Rachel So. Through careful publication of AI-generated research papers, we investigate how the scholarly ecosystem responds to AI authorship. Rachel So published 10+ papers between March and October 2025, was cited, and received a peer review invitation. We discuss the implications of AI authorship on publishers, researchers, and the scientific system at large. This work contributes empirical action research data to the necessary debate about the future of scholarly communication with super human, hyper capable AI systems.

</details>


### [151] [Uncertainty-Aware Measurement of Scenario Suite Representativeness for Autonomous Systems](https://arxiv.org/abs/2511.14853)
*Robab Aghazadeh Chakherlou,Siddartha Khastgir,Xingyu Zhao,Jerein Jeyachandran,Shufeng Chen*

Main category: cs.AI

TL;DR: 本论文提出了一种概率方法，量化AI训练数据的代表性，以确保系统安全性，采用不精确的贝叶斯方法处理数据的限制和不确定性。


<details>
  <summary>Details</summary>
Motivation: 确保AI系统（如自主驾驶车辆）的可信度和安全性依赖于所用数据集的安全性特性，因此需要关注数据是否具有代表性。

Method: 采用了一种不精确的贝叶斯方法，以处理有限数据和不确定的先验信息，并提供区间值的代表性估计。

Result: 通过数值例子演示了场景套件与推断的目标操作域之间的分布比较，并在不同操作类别下估计了局部和全球的代表性。

Conclusion: 本研究提出了一种量化代表性的概率方法，能够在有限数据的情况下比较训练和测试场景数据与目标操作域的统计分布，从而提升AI系统的安全性和可信度。

Abstract: Assuring the trustworthiness and safety of AI systems, e.g., autonomous vehicles (AV), depends critically on the data-related safety properties, e.g., representativeness, completeness, etc., of the datasets used for their training and testing. Among these properties, this paper focuses on representativeness-the extent to which the scenario-based data used for training and testing, reflect the operational conditions that the system is designed to operate safely in, i.e., Operational Design Domain (ODD) or expected to encounter, i.e., Target Operational Domain (TOD). We propose a probabilistic method that quantifies representativeness by comparing the statistical distribution of features encoded by the scenario suites with the corresponding distribution of features representing the TOD, acknowledging that the true TOD distribution is unknown, as it can only be inferred from limited data.
  We apply an imprecise Bayesian method to handle limited data and uncertain priors. The imprecise Bayesian formulation produces interval-valued, uncertainty-aware estimates of representativeness, rather than a single value. We present a numerical example comparing the distributions of the scenario suite and the inferred TOD across operational categories-weather, road type, time of day, etc., under dependencies and prior uncertainty. We estimate representativeness locally (between categories) and globally as an interval.

</details>


### [152] [Beyond GeneGPT: A Multi-Agent Architecture with Open-Source LLMs for Enhanced Genomic Question Answering](https://arxiv.org/abs/2511.15061)
*Haodong Chen,Guido Zuccon,Teerapong Leelanupab*

Main category: cs.AI

TL;DR: 本研究开发了OpenBioLLM，一个开源多智能体框架，能够有效提升基因组问答系统的效率和表现，超越了之前的专有模型。


<details>
  <summary>Details</summary>
Motivation: The study aims to address the limitations of GeneGPT, including scalability and cost, by utilizing open-source models to enable better genomic question answering.

Method: We reproduced GeneGPT using open-source models and developed OpenBioLLM with a modular multi-agent framework for improved task execution.

Result: OpenBioLLM matches or outperforms GeneGPT on over 90% of benchmark tasks, significantly reducing latency and improving efficiency without compromising capabilities.

Conclusion: OpenBioLLM demonstrates the effectiveness of open-source multi-agent frameworks in genomic question answering, outperforming previous proprietary models in efficiency and performance.

Abstract: Genomic question answering often requires complex reasoning and integration across diverse biomedical sources. GeneGPT addressed this challenge by combining domain-specific APIs with OpenAI's code-davinci-002 large language model to enable natural language interaction with genomic databases. However, its reliance on a proprietary model limits scalability, increases operational costs, and raises concerns about data privacy and generalization.
  In this work, we revisit and reproduce GeneGPT in a pilot study using open source models, including Llama 3.1, Qwen2.5, and Qwen2.5 Coder, within a monolithic architecture; this allows us to identify the limitations of this approach. Building on this foundation, we then develop OpenBioLLM, a modular multi-agent framework that extends GeneGPT by introducing agent specialization for tool routing, query generation, and response validation. This enables coordinated reasoning and role-based task execution.
  OpenBioLLM matches or outperforms GeneGPT on over 90% of the benchmark tasks, achieving average scores of 0.849 on Gene-Turing and 0.830 on GeneHop, while using smaller open-source models without additional fine-tuning or tool-specific pretraining. OpenBioLLM's modular multi-agent design reduces latency by 40-50% across benchmark tasks, significantly improving efficiency without compromising model capability. The results of our comprehensive evaluation highlight the potential of open-source multi-agent systems for genomic question answering. Code and resources are available at https://github.com/ielab/OpenBioLLM.

</details>


### [153] [ProRAC: A Neuro-symbolic Method for Reasoning about Actions with LLM-based Progression](https://arxiv.org/abs/2511.15069)
*Haoyong Wu,Yongmei Liu*

Main category: cs.AI

TL;DR: ProRAC是一个基于进展的推理框架，使用LLM来有效解决动作和变化的推理问题，结果显示其性能优异。


<details>
  <summary>Details</summary>
Motivation: 解决涉及动作和变化的推理（RAC）问题，以提高解答的准确性和效率。

Method: 使用神经-符号框架结合大语言模型（LLM），逐步执行动作以推导最终状态，进而评估查询。

Result: 在多个RAC基准测试中，ProRAC展现出强大的性能，适用于多种任务和领域。

Conclusion: ProRAC在不同的基准测试和领域中表现出色，证明了其方法的有效性。

Abstract: In this paper, we propose ProRAC (Progression-based Reasoning about Actions and Change), a neuro-symbolic framework that leverages LLMs to tackle RAC problems. ProRAC extracts fundamental RAC elements including actions and questions from the problem, progressively executes each action to derive the final state, and then evaluates the query against the progressed state to arrive at an answer. We evaluate ProRAC on several RAC benchmarks, and the results demonstrate that our approach achieves strong performance across different benchmarks, domains, LLM backbones, and types of RAC tasks.

</details>


### [154] [SafeRBench: A Comprehensive Benchmark for Safety Assessment in Large Reasoning Models](https://arxiv.org/abs/2511.15169)
*Xin Gao,Shaohan Yu,Zerui Chen,Yueming Lyu,Weichen Yu,Guanghao Li,Jiyao Liu,Jianxiong Gao,Jian Liang,Ziwei Liu,Chenyang Si*

Main category: cs.AI

TL;DR: 本论文提出 SafeRBench，这是一个针对大推理模型安全性的首个全面基准，通过输入特征化、细粒度输出分析和人类评估对 LRM 的安全风险进行多维度评估。


<details>
  <summary>Details</summary>
Motivation: 随着大推理模型的普及，提升其答复质量的同时也引入了新的安全风险，因此有必要建立一个全面评估其安全性的基准。

Method: 本研究开发了 SafeRBench 基准，通过三大创新方法进行 LRM 安全性评估：输入特征化、细粒度输出分析以及人类安全对齐。

Result: SafeRBench 能够有效地识别和分析 LRMs 在推理过程中潜在的动态安全风险，并且可以与人类评估进行对比，提升安全评估的准确性。

Conclusion: SafeRBench 提供了一个全面的评估框架，以便对大推理模型的安全性进行细致的多维度分析。

Abstract: Large Reasoning Models (LRMs) improve answer quality through explicit chain-of-thought, yet this very capability introduces new safety risks: harmful content can be subtly injected, surface gradually, or be justified by misleading rationales within the reasoning trace. Existing safety evaluations, however, primarily focus on output-level judgments and rarely capture these dynamic risks along the reasoning process. In this paper, we present SafeRBench, the first benchmark that assesses LRM safety end-to-end -- from inputs and intermediate reasoning to final outputs. (1) Input Characterization: We pioneer the incorporation of risk categories and levels into input design, explicitly accounting for affected groups and severity, and thereby establish a balanced prompt suite reflecting diverse harm gradients. (2) Fine-Grained Output Analysis: We introduce a micro-thought chunking mechanism to segment long reasoning traces into semantically coherent units, enabling fine-grained evaluation across ten safety dimensions. (3) Human Safety Alignment: We validate LLM-based evaluations against human annotations specifically designed to capture safety judgments. Evaluations on 19 LRMs demonstrate that SafeRBench enables detailed, multidimensional safety assessment, offering insights into risks and protective mechanisms from multiple perspectives.

</details>


### [155] [As If We've Met Before: LLMs Exhibit Certainty in Recognizing Seen Files](https://arxiv.org/abs/2511.15192)
*Haodong Li,Jingqi Zhang,Xiao Cheng,Peihua Mai,Haoyu Wang,Yang Pan*

Main category: cs.AI

TL;DR: COPYCHECK是一个新框架，通过捕捉不确定性模式高效检测大语言模型训练中的版权内容，取得了超越现有基线的显著准确度。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型训练中，使用受版权保护材料引发了严重的未经授权使用的担忧，需求一种有效检测的方法。

Method: COPYCHECK利用不确定性信号，结合战略性文件分段和不确定性引导的无监督聚类，实现版权内容检测。

Result: COPYCHECK在LLaMA 7b和LLaMA2 7b上检测已见文件实现了超过90%的相对提高，展现出很强的架构可迁移性。

Conclusion: COPYCHECK是首个将不确定性应用于大语言模型版权检测的框架，提供了训练数据透明性实用工具。

Abstract: The remarkable language ability of Large Language Models (LLMs) stems from extensive training on vast datasets, often including copyrighted material, which raises serious concerns about unauthorized use. While Membership Inference Attacks (MIAs) offer potential solutions for detecting such violations, existing approaches face critical limitations and challenges due to LLMs' inherent overconfidence, limited access to ground truth training data, and reliance on empirically determined thresholds.
  We present COPYCHECK, a novel framework that leverages uncertainty signals to detect whether copyrighted content was used in LLM training sets. Our method turns LLM overconfidence from a limitation into an asset by capturing uncertainty patterns that reliably distinguish between ``seen" (training data) and ``unseen" (non-training data) content. COPYCHECK further implements a two-fold strategy: (1) strategic segmentation of files into smaller snippets to reduce dependence on large-scale training data, and (2) uncertainty-guided unsupervised clustering to eliminate the need for empirically tuned thresholds. Experiment results show that COPYCHECK achieves an average balanced accuracy of 90.1% on LLaMA 7b and 91.6% on LLaMA2 7b in detecting seen files. Compared to the SOTA baseline, COPYCHECK achieves over 90% relative improvement, reaching up to 93.8\% balanced accuracy. It further exhibits strong generalizability across architectures, maintaining high performance on GPT-J 6B. This work presents the first application of uncertainty for copyright detection in LLMs, offering practical tools for training data transparency.

</details>


### [156] [Efficiency Will Not Lead to Sustainable Reasoning AI](https://arxiv.org/abs/2511.15259)
*Philipp Wiesner,Daniel W. O'Neill,Francesca Larosa,Odej Kao*

Main category: cs.AI

TL;DR: 本论文探讨了推理AI的可持续性问题，认为仅仅提高效率无法解决挑战，并建议在优化与治理中设置明确的限制。


<details>
  <summary>Details</summary>
Motivation: 随着AI向复杂问题转型，现阶段的效率改进面临瓶颈，加之推理AI在性能上缺乏饱和点，亟需解决可持续性挑战。

Method: 通过分析现有AI模型在多步推理中的效率与可持续性问题，探讨如何在系统治理中实施限制。

Result: 研究表明，推理AI的性能与计算投资呈指数关系，提出需在AI系统中引入限制以达到持续发展的目标。

Conclusion: 仅依靠效率无法实现可持续的推理AI，因此需在优化及管理中引入明确的限制。

Abstract: AI research is increasingly moving toward complex problem solving, where models are optimized not only for pattern recognition but for multi-step reasoning. Historically, computing's global energy footprint has been stabilized by sustained efficiency gains and natural saturation thresholds in demand. But as efficiency improvements are approaching physical limits, emerging reasoning AI lacks comparable saturation points: performance is no longer limited by the amount of available training data but continues to scale with exponential compute investments in both training and inference. This paper argues that efficiency alone will not lead to sustainable reasoning AI and discusses research and policy directions to embed explicit limits into the optimization and governance of such systems.

</details>


### [157] [Realist and Pluralist Conceptions of Intelligence and Their Implications on AI Research](https://arxiv.org/abs/2511.15282)
*Ninell Oldenburg,Ruchira Dhar,Anders Søgaard*

Main category: cs.AI

TL;DR: 本文探讨了智能现实主义与智能多元主义对AI研究的影响，揭示了它们如何在研究方法和风险评估上产生根本不同的视角。


<details>
  <summary>Details</summary>
Motivation: 探讨人工智能研究中智力的不同概念对研究方法和结果的影响。

Method: 通过分析当前人工智能研究中的辩论，揭示不同智力观念如何影响对实证证据的解读。

Result: 不同的智力观念导致在模型选择、基准设计、实验验证等方法上出现不同的方法论，同时也导致对同一实证现象的矛盾解读，影响对人工智能风险的评估。

Conclusion: 明确这些基础假设有助于更清晰地理解人工智能研究中的分歧。

Abstract: In this paper, we argue that current AI research operates on a spectrum between two different underlying conceptions of intelligence: Intelligence Realism, which holds that intelligence represents a single, universal capacity measurable across all systems, and Intelligence Pluralism, which views intelligence as diverse, context-dependent capacities that cannot be reduced to a single universal measure. Through an analysis of current debates in AI research, we demonstrate how the conceptions remain largely implicit yet fundamentally shape how empirical evidence gets interpreted across a wide range of areas. These underlying views generate fundamentally different research approaches across three areas. Methodologically, they produce different approaches to model selection, benchmark design, and experimental validation. Interpretively, they lead to contradictory readings of the same empirical phenomena, from capability emergence to system limitations. Regarding AI risk, they generate categorically different assessments: realists view superintelligence as the primary risk and search for unified alignment solutions, while pluralists see diverse threats across different domains requiring context-specific solutions. We argue that making explicit these underlying assumptions can contribute to a clearer understanding of disagreements in AI research.

</details>


### [158] [Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration](https://arxiv.org/abs/2511.15351)
*Yifu Guo,Zishan Xu,Zhiyuan Yao,Yuquan Lu,Jiaye Lin,Sen Hu,Zhenheng Tang,Yingchao Li,Huacan Wang,Ronghao Chen*

Main category: cs.AI

TL;DR: 提出Octopus，一种新的多模态推理范式，展示出在各种任务中的优越性能，强调能力协调的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态推理模型在能力和结构上存在局限，缺乏如人类般自主探索多样推理路径的能力。

Method: 提出了一种新的多模态推理范式Octopus，并定义了六个核心能力，建立了评价基准Octopus-Bench。

Result: Octopus能够根据当前状态自主选择最合适的能力，并在实验中表现出色。

Conclusion: Octopus在Octopus-Bench大多数任务中表现最佳，强调了能力协调在多模态推理中的关键作用。

Abstract: Existing multimodal reasoning models and frameworks suffer from fundamental architectural limitations: most lack the human-like ability to autonomously explore diverse reasoning pathways-whether in direct inference, tool-driven visual exploration, programmatic visual manipulation, or intrinsic visual imagination. Consequently, they struggle to adapt to dynamically changing capability requirements in real-world tasks. Meanwhile, humans exhibit a complementary set of thinking abilities when addressing such tasks, whereas existing methods typically cover only a subset of these dimensions. Inspired by this, we propose Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration, a new paradigm for multimodal agentic reasoning. We define six core capabilities essential for multimodal reasoning and organize a comprehensive evaluation benchmark, Octopus-Bench, accordingly. Octopus is capable of autonomously exploring during reasoning and dynamically selecting the most appropriate capability based on the current state. Experimental results show that Octopus achieves the best performance on the vast majority of tasks in Octopus-Bench, highlighting the crucial role of capability coordination in agentic multimodal reasoning.

</details>

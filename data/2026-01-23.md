<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 57]
- [cs.CL](#cs.CL) [Total: 44]
- [cs.HC](#cs.HC) [Total: 17]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.AI](#cs.AI) [Total: 37]
- [cs.LG](#cs.LG) [Total: 46]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Evaluating Multimodal Large Language Models for Heterogeneous Face Recognition](https://arxiv.org/abs/2601.15406)
*Hatef Otroshi Shahreza,Anjith George,Sébastien Marcel*

Main category: cs.CV

TL;DR: 评估多模态大语言模型在异构人脸识别中的性能，发现与经典人脸识别系统存在较大差距


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉语言任务中表现出色，但它们在生物特征识别（特别是异构人脸识别）中的应用潜力尚未经过系统评估

Method: 系统评估多个开源MLLMs在VIS-NIR、VIS-SWIR、VIS-THERMAL等跨模态场景下的性能，使用生物特征协议和Acquire Rate、EER、TAR等指标

Result: MLLMs与经典人脸识别系统之间存在明显的性能差距，特别是在具有挑战性的跨光谱条件下

Conclusion: 当前MLLMs在异构人脸识别中的能力有限，在部署于人脸识别系统时需要严格的生物特征评估

Abstract: Multimodal Large Language Models (MLLMs) have recently demonstrated strong performance on a wide range of vision-language tasks, raising interest in their potential use for biometric applications. In this paper, we conduct a systematic evaluation of state-of-the-art MLLMs for heterogeneous face recognition (HFR), where enrollment and probe images are from different sensing modalities, including visual (VIS), near infrared (NIR), short-wave infrared (SWIR), and thermal camera. We benchmark multiple open-source MLLMs across several cross-modality scenarios, including VIS-NIR, VIS-SWIR, and VIS-THERMAL face recognition. The recognition performance of MLLMs is evaluated using biometric protocols and based on different metrics, including Acquire Rate, Equal Error Rate (EER), and True Accept Rate (TAR). Our results reveal substantial performance gaps between MLLMs and classical face recognition systems, particularly under challenging cross-spectral conditions, in spite of recent advances in MLLMs. Our findings highlight the limitations of current MLLMs for HFR and also the importance of rigorous biometric evaluation when considering their deployment in face recognition systems.

</details>


### [2] [CURE: Curriculum-guided Multi-task Training for Reliable Anatomy Grounded Report Generation](https://arxiv.org/abs/2601.15408)
*Pablo Messina,Andrés Villa,Juan León Alcázar,Karen Sánchez,Carlos Hinojosa,Denis Parra,Álvaro Soto,Bernard Ghanem*

Main category: cs.CV

TL;DR: CURE是一个无需额外数据的课程学习框架，通过优化医学视觉语言模型的视觉定位和事实一致性，提升放射报告的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的医学视觉语言模型在生成放射报告时存在视觉-文本对齐不佳和事实不一致问题，导致生成报告不可靠和错位预测。需要改进模型的视觉定位能力和事实一致性。

Method: 开发了CURE错误感知课程学习框架，通过三个阶段微调多模态指导模型：短语定位、定位报告生成和解剖学定位报告生成。动态调整采样策略，根据模型表现强调困难样本，改善空间和文本对齐。

Result: CURE将定位准确度提升了+0.37 IoU，报告质量改善了+0.188 CXRFEScore，幻觉减少了18.6%。这些改进都是在没有增加额外数据的情况下实现的。

Conclusion: CURE是一个数据高效的框架，能同时提升医学视觉语言模型的定位准确性和报告可靠性，代码和模型权重已公开。

Abstract: Medical vision-language models can automate the generation of radiology reports but struggle with accurate visual grounding and factual consistency. Existing models often misalign textual findings with visual evidence, leading to unreliable or weakly grounded predictions. We present CURE, an error-aware curriculum learning framework that improves grounding and report quality without any additional data. CURE fine-tunes a multimodal instructional model on phrase grounding, grounded report generation, and anatomy-grounded report generation using public datasets. The method dynamically adjusts sampling based on model performance, emphasizing harder samples to improve spatial and textual alignment. CURE improves grounding accuracy by +0.37 IoU, boosts report quality by +0.188 CXRFEScore, and reduces hallucinations by 18.6%. CURE is a data-efficient framework that enhances both grounding accuracy and report reliability. Code is available at https://github.com/PabloMessina/CURE and model weights at https://huggingface.co/pamessina/medgemma-4b-it-cure

</details>


### [3] [DuFal: Dual-Frequency-Aware Learning for High-Fidelity Extremely Sparse-view CBCT Reconstruction](https://arxiv.org/abs/2601.15416)
*Cuong Tran Van,Trong-Thang Pham,Ngoc-Son Nguyen,Duy Minh Ho Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Sparse-view Cone-Beam Computed Tomography reconstruction from limited X-ray projections remains a challenging problem in medical imaging due to the inherent undersampling of fine-grained anatomical details, which correspond to high-frequency components. Conventional CNN-based methods often struggle to recover these fine structures, as they are typically biased toward learning low-frequency information. To address this challenge, this paper presents DuFal (Dual-Frequency-Aware Learning), a novel framework that integrates frequency-domain and spatial-domain processing via a dual-path architecture. The core innovation lies in our High-Local Factorized Fourier Neural Operator, which comprises two complementary branches: a Global High-Frequency Enhanced Fourier Neural Operator that captures global frequency patterns and a Local High-Frequency Enhanced Fourier Neural Operator that processes spatially partitioned patches to preserve spatial locality that might be lost in global frequency analysis. To improve efficiency, we design a Spectral-Channel Factorization scheme that reduces the Fourier Neural Operator parameter count. We also design a Cross-Attention Frequency Fusion module to integrate spatial and frequency features effectively. The fused features are then decoded through a Feature Decoder to produce projection representations, which are subsequently processed through an Intensity Field Decoding pipeline to reconstruct a final Computed Tomography volume. Experimental results on the LUNA16 and ToothFairy datasets demonstrate that DuFal significantly outperforms existing state-of-the-art methods in preserving high-frequency anatomical features, particularly under extremely sparse-view settings.

</details>


### [4] [DevPrompt: Deviation-Based Prompt Learning for One-Normal ShotImage Anomaly Detection](https://arxiv.org/abs/2601.15453)
*Morteza Poudineh,Marc Lalonde*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Few-normal shot anomaly detection (FNSAD) aims to detect abnormal regions in images using only a few normal training samples, making the task highly challenging due to limited supervision and the diversity of potential defects. Recent approaches leverage vision-language models such as CLIP with prompt-based learning to align image and text features. However, existing methods often exhibit weak discriminability between normal and abnormal prompts and lack principled scoring mechanisms for patch-level anomalies. We propose a deviation-guided prompt learning framework that integrates the semantic power of vision-language models with the statistical reliability of deviation-based scoring. Specifically, we replace fixed prompt prefixes with learnable context vectors shared across normal and abnormal prompts, while anomaly-specific suffix tokens enable class-aware alignment. To enhance separability, we introduce a deviation loss with Top-K Multiple Instance Learning (MIL), modeling patch-level features as Gaussian deviations from the normal distribution. This allows the network to assign higher anomaly scores to patches with statistically significant deviations, improving localization and interpretability. Experiments on the MVTecAD and VISA benchmarks demonstrate superior pixel-level detection performance compared to PromptAD and other baselines. Ablation studies further validate the effectiveness of learnable prompts, deviation-based scoring, and the Top-K MIL strategy.

</details>


### [5] [Hybrid Vision Transformer_GAN Attribute Neutralizer for Mitigating Bias in Chest X_Ray Diagnosis](https://arxiv.org/abs/2601.15490)
*Jobeal Solomon,Ali Mohammed Mansoor Alsahag,Seyed Sahand Mohammadi Ziabari*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Bias in chest X-ray classifiers frequently stems from sex- and age-related shortcuts, leading to systematic underdiagnosis of minority subgroups. Previous pixel-space attribute neutralizers, which rely on convolutional encoders, lessen but do not fully remove this attribute leakage at clinically usable edit strengths. This study evaluates whether substituting the U-Net convolutional encoder with a Vision Transformer backbone in the Attribute-Neutral Framework can reduce demographic attribute leakage while preserving diagnostic accuracy. A data-efficient Image Transformer Small (DeiT-S) neutralizer was trained on the ChestX-ray14 dataset. Its edited images, generated across eleven edit-intensity levels, were evaluated with an independent AI judge for attribute leakage and with a convolutional neural network (ConvNet) for disease prediction. At a moderate edit level (alpha = 0.5), the Vision Transformer (ViT) neutralizer reduces patient sex-recognition area under the curve (AUC) to approximately 0.80, about 10 percentage points below the original framework's convolutional U-Net encoder, despite being trained for only half as many epochs. Meanwhile, macro receiver operating characteristic area under the curve (ROC AUC) across 15 findings stays within five percentage points of the unedited baseline, and the worst-case subgroup AUC remains near 0.70. These results indicate that global self-attention vision models can further suppress attribute leakage without sacrificing clinical utility, suggesting a practical route toward fairer chest X-ray AI.

</details>


### [6] [Controllable Layered Image Generation for Real-World Editing](https://arxiv.org/abs/2601.15507)
*Jinrui Yang,Qing Liu,Yijun Li,Mengwei Ren,Letian Zhang,Zhe Lin,Cihang Xie,Yuyin Zhou*

Main category: cs.CV

TL;DR: LASAGNA是一个统一框架，可同时生成图像及其组成层（逼真背景和高质量透明前景），解决了现有图像生成模型在编辑特定元素时可控性和一致性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成模型在编辑图像特定元素时往往难以产生可控且一致的结果；现有的分层表示方法通常无法生成具有连贯合成关系的图层，且对象层缺乏真实的视觉效果（如阴影、反射）。

Method: 提出LASAGNA框架，从多种条件输入（文本提示、前景、背景和位置掩码）中有效学习正确的图像合成，并引入LASAGNA-48K数据集（包含干净背景和具有物理基础视觉效果的RGBA前景）以及LASAGNABENCH分层编辑基准。

Result: LASAGNA在同时生成多个图像层方面表现出高度一致性和连贯性，支持多种后期编辑应用，能准确保持身份和视觉效果。

Conclusion: LASAGNA框架显著提升了图像分层生成的可控性和质量，LASAGNA-48K数据集和LASAGNABENCH基准将公开发布以推动社区开放研究。

Abstract: Recent image generation models have shown impressive progress, yet they often struggle to yield controllable and consistent results when users attempt to edit specific elements within an existing image. Layered representations enable flexible, user-driven content creation, but existing approaches often fail to produce layers with coherent compositing relationships, and their object layers typically lack realistic visual effects such as shadows and reflections. To overcome these limitations, we propose LASAGNA, a novel, unified framework that generates an image jointly with its composing layers--a photorealistic background and a high-quality transparent foreground with compelling visual effects. Unlike prior work, LASAGNA efficiently learns correct image composition from a wide range of conditioning inputs--text prompts, foreground, background, and location masks--offering greater controllability for real-world applications. To enable this, we introduce LASAGNA-48K, a new dataset composed of clean backgrounds and RGBA foregrounds with physically grounded visual effects. We also propose LASAGNABENCH, the first benchmark for layer editing. We demonstrate that LASAGNA excels in generating highly consistent and coherent results across multiple image layers simultaneously, enabling diverse post-editing applications that accurately preserve identity and visual effects. LASAGNA-48K and LASAGNABENCH will be publicly released to foster open research in the community. The project page is https://rayjryang.github.io/LASAGNA-Page/.

</details>


### [7] [VIOLA: Towards Video In-Context Learning with Minimal Annotations](https://arxiv.org/abs/2601.15549)
*Ryo Fujii,Hideo Saito,Ryo Hachiuma*

Main category: cs.CV

TL;DR: VIOLA框架：通过少量专家标注结合大量无标注数据，实现视频多模态大语言模型的高效领域自适应，在低资源场景下显著优于现有基线方法


<details>
  <summary>Details</summary>
Motivation: 在多模态大语言模型应用到真实视频场景时，针对新领域的数据标注成本高昂，特别是在工业和手术等专业领域需要专家标注。当前上下文学习方法依赖大量标注数据，这在实际应用中不切实际

Method: 1. 密度-不确定性加权采样：在严格标注预算下最大化效率，通过密度估计选择同时具有多样性、代表性和信息量的样本
2. 构建混合池并引入置信度感知检索与提示：显式建模标签可靠性，基于相似度和置信度的综合分数检索示例，使模型能区分已验证真值和噪声伪标签

Result: 在九个不同基准测试和四个多模态大语言模型上的广泛实验表明，该框架在低资源设置下显著优于各种基线方法，能够以最小标注成本实现鲁棒的自适应

Conclusion: VIOLA框架通过有效结合少量专家标注和大量无标注数据，解决了多模态大语言模型在专业视频领域标注数据稀缺的问题，为实际部署提供了可行的训练free适应方案

Abstract: Generalizing Multimodal Large Language Models (MLLMs) to novel video domains is essential for real-world deployment but remains challenging due to the scarcity of labeled data. While In-Context Learning (ICL) offers a training-free adaptation path, standard methods rely on large annotated pools, which are often impractical in specialized environments like industrial or surgical settings since they require the experts' annotations. To bridge this gap, we introduce VIOLA (Video In-cOntext Learning with minimal Annotation), a label-efficient framework that synergizes minimal expert supervision with abundant unlabeled data. First, to maximize the efficiency of a strict annotation budget, we propose density-uncertainty-weighted sampling. Unlike standard diversity or uncertainty strategies that risk selecting visual outliers, our method leverages density estimation to identify samples that are simultaneously diverse, representative, and informative. Second, to utilize the remaining unlabeled data without noise propagation, we construct a hybrid pool and introduce confidence-aware retrieval and confidence-aware prompting. These mechanisms explicitly model label reliability, retrieving demonstrations based on a composite score of similarity and confidence while enabling the MLLM to adaptively distinguish between verified ground truths and noisy pseudo-labels. Extensive experiments across nine diverse benchmarks using four MLLMs demonstrate that our framework significantly outperforms various baselines in low-resource settings, achieving robust adaptation with minimal annotation costs.

</details>


### [8] [Relative Classification Accuracy: A Calibrated Metric for Identity Consistency in Fine-Grained K-pop Face Generation](https://arxiv.org/abs/2601.15560)
*Sylvey Lin,Eranki Vasistha*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Denoising Diffusion Probabilistic Models (DDPMs) have achieved remarkable success in high-fidelity image generation. However, evaluating their semantic controllability-specifically for fine-grained, single-domain tasks-remains challenging. Standard metrics like FID and Inception Score (IS) often fail to detect identity misalignment in such specialized contexts. In this work, we investigate Class-Conditional DDPMs for K-pop idol face generation (32x32), a domain characterized by high inter-class similarity. We propose a calibrated metric, Relative Classification Accuracy (RCA), which normalizes generative performance against an oracle classifier's baseline. Our evaluation reveals a critical trade-off: while the model achieves high visual quality (FID 8.93), it suffers from severe semantic mode collapse (RCA 0.27), particularly for visually ambiguous identities. We analyze these failure modes through confusion matrices and attribute them to resolution constraints and intra-gender ambiguity. Our framework provides a rigorous standard for verifying identity consistency in conditional generative models.

</details>


### [9] [Explainable Deepfake Detection with RL Enhanced Self-Blended Images](https://arxiv.org/abs/2601.15624)
*Ning Jiang,Dingheng Zeng,Yanhong Liu,Haiyang Yi,Shijie Yu,Minghe Weng,Haifeng Shen,Ying Li*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Most prior deepfake detection methods lack explainable outputs. With the growing interest in multimodal large language models (MLLMs), researchers have started exploring their use in interpretable deepfake detection. However, a major obstacle in applying MLLMs to this task is the scarcity of high-quality datasets with detailed forgery attribution annotations, as textual annotation is both costly and challenging - particularly for high-fidelity forged images or videos. Moreover, multiple studies have shown that reinforcement learning (RL) can substantially enhance performance in visual tasks, especially in improving cross-domain generalization. To facilitate the adoption of mainstream MLLM frameworks in deepfake detection with reduced annotation cost, and to investigate the potential of RL in this context, we propose an automated Chain-of-Thought (CoT) data generation framework based on Self-Blended Images, along with an RL-enhanced deepfake detection framework. Extensive experiments validate the effectiveness of our CoT data construction pipeline, tailored reward mechanism, and feedback-driven synthetic data generation approach. Our method achieves performance competitive with state-of-the-art (SOTA) approaches across multiple cross-dataset benchmarks. Implementation details are available at https://github.com/deon1219/rlsbi.

</details>


### [10] [Evolving Without Ending: Unifying Multimodal Incremental Learning for Continual Panoptic Perception](https://arxiv.org/abs/2601.15643)
*Bo Yuan,Danpei Zhao,Wentao Li,Tian Li,Zhiguo Jiang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Continual learning (CL) is a great endeavour in developing intelligent perception AI systems. However, the pioneer research has predominantly focus on single-task CL, which restricts the potential in multi-task and multimodal scenarios. Beyond the well-known issue of catastrophic forgetting, the multi-task CL also brings semantic obfuscation across multimodal alignment, leading to severe model degradation during incremental training steps. In this paper, we extend CL to continual panoptic perception (CPP), integrating multimodal and multi-task CL to enhance comprehensive image perception through pixel-level, instance-level, and image-level joint interpretation. We formalize the CL task in multimodal scenarios and propose an end-to-end continual panoptic perception model. Concretely, CPP model features a collaborative cross-modal encoder (CCE) for multimodal embedding. We also propose a malleable knowledge inheritance module via contrastive feature distillation and instance distillation, addressing catastrophic forgetting from task-interactive boosting manner. Furthermore, we propose a cross-modal consistency constraint and develop CPP+, ensuring multimodal semantic alignment for model updating under multi-task incremental scenarios. Additionally, our proposed model incorporates an asymmetric pseudo-labeling manner, enabling model evolving without exemplar replay. Extensive experiments on multimodal datasets and diverse CL tasks demonstrate the superiority of the proposed model, particularly in fine-grained CL tasks.

</details>


### [11] [SuperOcc: Toward Cohesive Temporal Modeling for Superquadric-based Occupancy Prediction](https://arxiv.org/abs/2601.15644)
*Zichen Yu,Quanli Liu,Wei Wang,Liyong Zhang,Xiaoguang Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种基于超二次曲面（superquadric）的新型3D占据预测框架SuperOcc，通过三种关键设计解决了当前方法在时间建模、查询稀疏性与几何表达能力权衡以及计算效率方面的不足，在多个基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 目前大多数3D占据预测方法采用密集场景表示，忽略了真实驾驶场景固有的稀疏性。虽然超二次曲面表示作为稀疏替代方案具有潜力，但现有框架存在时间建模不足、查询稀疏性与几何表达能力之间的权衡困难以及超二次曲面到体素映射效率低下的问题。

Method: SuperOcc框架包含三个核心设计：1) 统一的时序建模机制，同时利用视角中心和物体中心的时序线索；2) 多超二次曲面解码策略，在不牺牲查询稀疏性的前提下增强几何表达能力；3) 高效的超二次曲面到体素的映射方案，提升计算效率。

Result: 在SurroundOcc和Occ3D基准测试上的广泛实验表明，SuperOcc达到了state-of-the-art性能，同时保持了卓越的计算效率。

Conclusion: SuperOcc是一种有效的基于超二次曲面的3D占据预测框架，通过创新性的时序建模、几何表示优化和高效映射方案，解决了现有方法的局限性，为自动驾驶环境理解提供了更高效的解决方案。

Abstract: 3D occupancy prediction plays a pivotal role in the realm of autonomous driving, as it provides a comprehensive understanding of the driving environment. Most existing methods construct dense scene representations for occupancy prediction, overlooking the inherent sparsity of real-world driving scenes. Recently, 3D superquadric representation has emerged as a promising sparse alternative to dense scene representations due to the strong geometric expressiveness of superquadrics. However, existing superquadric frameworks still suffer from insufficient temporal modeling, a challenging trade-off between query sparsity and geometric expressiveness, and inefficient superquadric-to-voxel splatting. To address these issues, we propose SuperOcc, a novel framework for superquadric-based 3D occupancy prediction. SuperOcc incorporates three key designs: (1) a cohesive temporal modeling mechanism to simultaneously exploit view-centric and object-centric temporal cues; (2) a multi-superquadric decoding strategy to enhance geometric expressiveness without sacrificing query sparsity; and (3) an efficient superquadric-to-voxel splatting scheme to improve computational efficiency. Extensive experiments on the SurroundOcc and Occ3D benchmarks demonstrate that SuperOcc achieves state-of-the-art performance while maintaining superior efficiency. The code is available at https://github.com/Yzichen/SuperOcc.

</details>


### [12] [Event-VStream: Event-Driven Real-Time Understanding for Long Video Streams](https://arxiv.org/abs/2601.15655)
*Zhenghui Guo,Yuanbin Man,Junyuan Sheng,Bowen Lin,Ahmed Ahmed,Bo Jiang,Boyuan Zhang,Miao Yin,Sian Jin,Omprakash Gnawal,Chengming Zhang*

Main category: cs.CV

TL;DR: Event-VStream：一种事件感知的长视频流实时理解框架，通过检测状态转换边界来触发语言生成，减少冗余处理，提升长期记忆能力


<details>
  <summary>Details</summary>
Motivation: 现有视频流处理系统存在帧处理冗余、遗忘过去上下文的问题，固定间隔解码或缓存修剪方法要么产生重复输出，要么丢失关键时间信息

Method: 将连续视频表示为离散语义连贯的事件序列，整合运动、语义和预测线索检测有意义的状态转换边界，仅在边界触发语言生成，事件嵌入持久存储到记忆库中

Result: 在OVOBench-Realtime基准上比VideoLLM-Online-8B基线提升10.4分，性能接近Flash-VStream-7B但仅使用通用LLaMA-3-8B文本骨干，在2小时Ego4D流上保持约70% GPT-5胜率

Conclusion: Event-VStream实现了高效的长视频流实时理解，通过事件感知框架减少冗余处理，增强长期推理能力，在多任务评估中展现出竞争力

Abstract: Real-time understanding of long video streams remains challenging for multimodal large language models (VLMs) due to redundant frame processing and rapid forgetting of past context. Existing streaming systems rely on fixed-interval decoding or cache pruning, which either produce repetitive outputs or discard crucial temporal information. We introduce Event-VStream, an event-aware framework that represents continuous video as a sequence of discrete, semantically coherent events. Our system detects meaningful state transitions by integrating motion, semantic, and predictive cues, and triggers language generation only at those boundaries. Each event embedding is consolidated into a persistent memory bank, enabling long-horizon reasoning while maintaining low latency. Across OVOBench-Realtime, and long-form Ego4D evaluations, Event-VStream achieves competitive performance. It improves over a VideoLLM-Online-8B baseline by +10.4 points on OVOBench-Realtime, achieves performance close to Flash-VStream-7B despite using only a general-purpose LLaMA-3-8B text backbone, and maintains around 70% GPT-5 win rate on 2-hour Ego4D streams.

</details>


### [13] [Skywork UniPic 3.0: Unified Multi-Image Composition via Sequence Modeling](https://arxiv.org/abs/2601.15664)
*Hongyang Wei,Hongbo Liu,Zidong Wang,Yi Peng,Baixin Xu,Size Wu,Xuying Zhang,Xianglong He,Zexiang Liu,Peiyu Wang,Xuchen Song,Yangguang Li,Yang Liu,Yahui Zhou*

Main category: cs.CV

TL;DR: 针对多图合成任务的难题，作者开发了Skywork UniPic 3.0统一多模态框架。该方法将多图合成视为序列建模问题，通过数据管道与训练范式创新，仅需70万高质量样本即可实现优越性能，推理阶段能12.5倍加速。该模型在单图编辑和多图合成基准测试中均达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 随着Nano-Banana和Seedream 4.0的流行，社区对多图合成任务表现出浓厚兴趣。相比单图编辑，多图合成在一致性和质量方面挑战更大，但现有模型未公开实现高质量融合的具体方法细节。统计显示人-物交互（HOI）是社区最关注类别，因此作者系统分析并实现了面向HOI任务的多图合成解决方案。

Method: 提出Skywork UniPic 3.0统一多模态框架，集成单图编辑和多图合成功能，支持任意数量（1~6）和分辨率的输入图像，以及任意输出分辨率（总像素不超过1024x1024）。设计了全面的数据收集、过滤和合成管道，仅使用70万高质量训练样本。创新性地将多图合成为序列建模问题，将条件生成转化为统一序列合成。推理阶段集成轨迹映射和分布匹配，只需8步即可生成高保真样本。

Result: Skywork UniPic 3.0在单图编辑基准测试中达到最先进性能，在多图合成基准上超越Nano-Banana和Seedream 4.0。模型在推理阶段实现12.5倍加速，仅需8步采样即可产生高质量结果，验证了数据管道和训练范式的有效性。

Conclusion: 提出的统一多模态框架成功解决了多图合成的挑战，特别是针对人-物交互任务。通过将多图合成为序列建模问题并设计高效训练范式，仅用有限数据就取得了优越性能。推理加速技术显著提升了实用性。该方法为多图像合成任务提供了系统解决方案。

Abstract: The recent surge in popularity of Nano-Banana and Seedream 4.0 underscores the community's strong interest in multi-image composition tasks. Compared to single-image editing, multi-image composition presents significantly greater challenges in terms of consistency and quality, yet existing models have not disclosed specific methodological details for achieving high-quality fusion. Through statistical analysis, we identify Human-Object Interaction (HOI) as the most sought-after category by the community. We therefore systematically analyze and implement a state-of-the-art solution for multi-image composition with a primary focus on HOI-centric tasks. We present Skywork UniPic 3.0, a unified multimodal framework that integrates single-image editing and multi-image composition. Our model supports an arbitrary (1~6) number and resolution of input images, as well as arbitrary output resolutions (within a total pixel budget of 1024x1024). To address the challenges of multi-image composition, we design a comprehensive data collection, filtering, and synthesis pipeline, achieving strong performance with only 700K high-quality training samples. Furthermore, we introduce a novel training paradigm that formulates multi-image composition as a sequence-modeling problem, transforming conditional generation into unified sequence synthesis. To accelerate inference, we integrate trajectory mapping and distribution matching into the post-training stage, enabling the model to produce high-fidelity samples in just 8 steps and achieve a 12.5x speedup over standard synthesis sampling. Skywork UniPic 3.0 achieves state-of-the-art performance on single-image editing benchmark and surpasses both Nano-Banana and Seedream 4.0 on multi-image composition benchmark, thereby validating the effectiveness of our data pipeline and training paradigm. Code, models and dataset are publicly available.

</details>


### [14] [Performance-guided Reinforced Active Learning for Object Detection](https://arxiv.org/abs/2601.15688)
*Zhixuan Liang,Xingyu Zeng,Rui Zhao,Ping Luo*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Active learning (AL) strategies aim to train high-performance models with minimal labeling efforts, only selecting the most informative instances for annotation. Current approaches to evaluating data informativeness predominantly focus on the data's distribution or intrinsic information content and do not directly correlate with downstream task performance, such as mean average precision (mAP) in object detection. Thus, we propose Performance-guided (i.e. mAP-guided) Reinforced Active Learning for Object Detection (MGRAL), a novel approach that leverages the concept of expected model output changes as informativeness. To address the combinatorial explosion challenge of batch sample selection and the non-differentiable correlation between model performance and selected batches, MGRAL skillfully employs a reinforcement learning-based sampling agent that optimizes selection using policy gradient with mAP improvement as reward. Moreover, to reduce the computational overhead of mAP estimation with unlabeled samples, MGRAL utilizes an unsupervised way with fast look-up tables, ensuring feasible deployment. We evaluate MGRAL's active learning performance on detection tasks over PASCAL VOC and COCO benchmarks. Our approach demonstrates the highest AL curve with convincing visualizations, establishing a new paradigm in reinforcement learning-driven active object detection.

</details>


### [15] [Beyond Visual Safety: Jailbreaking Multimodal Large Language Models for Harmful Image Generation via Semantic-Agnostic Inputs](https://arxiv.org/abs/2601.15698)
*Mingyu Yu,Lana Liu,Zhehao Zhao,Wei Wang,Sujuan Qin*

Main category: cs.CV

TL;DR: 本文提出了BVS框架，通过图像-文本对的方式探针多模态大语言模型的视觉安全边界，采用


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型(MLLMs)的快速发展，在文本和视觉交叉领域引入了复杂的安全挑战。现有方案虽然探索了MLLMs的安全漏洞，但对视觉安全边界的研究仍然不足。

Method: BVS采用

Result: 实验结果显示，BVS对GPT-5（2026年1月12日发布版）的越狱成功率达到了惊人的98.21%。

Conclusion: 我们的研究结果揭示了当前多模态大语言模型在视觉安全对齐方面存在严重漏洞。需要进一步完善视觉安全机制，应对多模态攻击威胁。

Abstract: The rapid advancement of Multimodal Large Language Models (MLLMs) has introduced complex security challenges, particularly at the intersection of textual and visual safety. While existing schemes have explored the security vulnerabilities of MLLMs, the investigation into their visual safety boundaries remains insufficient. In this paper, we propose Beyond Visual Safety (BVS), a novel image-text pair jailbreaking framework specifically designed to probe the visual safety boundaries of MLLMs. BVS employs a "reconstruction-then-generation" strategy, leveraging neutralized visual splicing and inductive recomposition to decouple malicious intent from raw inputs, thereby leading MLLMs to be induced into generating harmful images. Experimental results demonstrate that BVS achieves a remarkable jailbreak success rate of 98.21\% against GPT-5 (12 January 2026 release). Our findings expose critical vulnerabilities in the visual safety alignment of current MLLMs.

</details>


### [16] [Enhanced LULC Segmentation via Lightweight Model Refinements on ALOS-2 SAR Data](https://arxiv.org/abs/2601.15705)
*Ali Caglayan,Nevrez Imamoglu,Toru Kouyama*

Main category: cs.CV

TL;DR: 本文将自监督预训练模型SAR-W-MixMAE应用于日本全国的ALOS-2单极化SAR数据，进行土地利用/土地覆盖的语义分割，并针对SAR语义分割中常见的失败模式提出了三种轻量化改进方法。


<details>
  <summary>Details</summary>
Motivation: 解决SAR密集预测中的常见问题，包括边界过度平滑、遗漏纤细结构以及在长尾标签下稀有类别的性能退化，而不增加流程的复杂性。

Method: 采用基于SAR-W-MixMAE的微调框架，引入三种改进：1)在多层解码器中注入高分辨率特征；2)交替进行卷积细化和逐步上采样的渐进精炼头部；3)在focal+dice损失函数中通过α缩放因子调整类别重新加权。

Result: 模型在日本全国范围内的ALOS-2 LULC基准测试中，尤其是在代表性不足的类别上，取得了持续的改进，同时在水体检测任务的标准评估指标上也获得了提升。

Conclusion: 通过三种轻量化的改进，可以有效解决SAR语义分割中的常见挑战，特别提升了对稀有类别的识别能力，并且保持了较低的复杂度。

Abstract: This work focuses on national-scale land-use/land-cover (LULC) semantic segmentation using ALOS-2 single-polarization (HH) SAR data over Japan, together with a companion binary water detection task. Building on SAR-W-MixMAE self-supervised pretraining [1], we address common SAR dense-prediction failure modes, boundary over-smoothing, missed thin/slender structures, and rare-class degradation under long-tailed labels, without increasing pipeline complexity. We introduce three lightweight refinements: (i) injecting high-resolution features into multi-scale decoding, (ii) a progressive refine-up head that alternates convolutional refinement and stepwise upsampling, and (iii) an $α$-scale factor that tempers class reweighting within a focal+dice objective. The resulting model yields consistent improvements on the Japan-wide ALOS-2 LULC benchmark, particularly for under-represented classes, and improves water detection across standard evaluation metrics.

</details>


### [17] [Zero-Shot Product Attribute Labeling with Vision-Language Models: A Three-Tier Evaluation Framework](https://arxiv.org/abs/2601.15711)
*Shubham Shukla,Kunal Sonalkar*

Main category: cs.CV

TL;DR: 论文提出一个三层评估框架，用于系统评估视觉语言模型在细粒度时尚属性预测任务中的表现，特别针对条件性属性的应用性检测问题。


<details>
  <summary>Details</summary>
Motivation: 细粒度属性预测对时尚零售应用至关重要，但现有视觉语言模型在多属性时尚任务上的系统评估不足，且时尚属性通常具有条件性（如某些属性仅在特定条件下才适用），需要模型先检测属性是否适用再进行分类。

Method: 引入三层评估框架：1）所有类别（包括NA类）的整体任务性能；2）属性应用性检测；3）属性可确定时的细粒度分类。使用DeepFashion-MultiModal数据集，对9个不同层级的视觉语言模型（旗舰版、高效版、超高效版）进行基准测试，并与基于预训练Fashion-CLIP嵌入的分类器进行比较。

Result: 零样本视觉语言模型达到64.0%的宏观F1分数，比基于预训练Fashion-CLIP嵌入的逻辑回归提高了三倍；模型在细粒度分类方面表现良好（70.8% F1），但在应用性检测方面存在瓶颈（34.1% NA-F1）；高效模型能以较低成本达到旗舰模型90%以上的性能。

Conclusion: 该诊断框架能够帮助从业者识别错误来源（可见性检测还是分类问题），为生产系统提供有针对性的改进指导，同时高效模型为实际部署提供了实用路径。

Abstract: Fine-grained attribute prediction is essential for fashion retail applications including catalog enrichment, visual search, and recommendation systems. Vision-Language Models (VLMs) offer zero-shot prediction without task-specific training, yet their systematic evaluation on multi-attribute fashion tasks remains underexplored. A key challenge is that fashion attributes are often conditional. For example, "outer fabric" is undefined when no outer garment is visible. This requires models to detect attribute applicability before attempting classification. We introduce a three-tier evaluation framework that decomposes this challenge: (1) overall task performance across all classes (including NA class: suggesting attribute is not applicable) for all attributes, (2) attribute applicability detection, and (3) fine-grained classification when attributes are determinable. Using DeepFashion-MultiModal, which explicitly defines NA (meaning attribute doesn't exist or is not visible) within attribute label spaces, we benchmark nine VLMs spanning flagship (GPT-5, Gemini 2.5 Pro), efficient (GPT-5 Mini, Gemini 2.5 Flash), and ultra-efficient tiers (GPT-5 Nano, Gemini 2.5 Flash-Lite) against classifiers trained on pretrained Fashion-CLIP embeddings on 5,000 images across 18 attributes. Our findings reveal that: (1) zero-shot VLMs achieve 64.0% macro-F1, a threefold improvement over logistic regression on pretrained Fashion-CLIP embeddings; (2) VLMs excel at fine-grained classification (Tier 3: 70.8% F1) but struggle with applicability detection (Tier 2: 34.1% NA-F1), identifying a key bottleneck; (3) efficient models achieve over 90% of flagship performance at lower cost, offering practical deployment paths. This diagnostic framework enables practitioners to pinpoint whether errors stem from visibility detection or classification, guiding targeted improvements for production systems.

</details>


### [18] [The Latency Wall: Benchmarking Off-the-Shelf Emotion Recognition for Real-Time Virtual Avatars](https://arxiv.org/abs/2601.15914)
*Yarin Benyamin*

Main category: cs.CV

TL;DR: 本研究评估了零样本面部表情识别模型在VR虚拟角色上的实时性能，发现YOLOv11n在检测阶段表现最佳，但通用Transformer模型无法满足VR治疗对低延迟（<140ms）和高准确率的需求，需专门设计轻量级架构。


<details>
  <summary>Details</summary>
Motivation: 在VR/HCI领域，实时情绪识别有助于改善自闭症谱系障碍（ASD）患者的社交技能训练，但需要满足严格的延迟-准确率平衡（动作到光子延迟<140ms）。现有深度学习模型通常优先考虑准确率而非实时性，本研究旨在为可访问的VR治疗系统提供模型基准。

Method: 使用UIBVFED数据集对虚拟角色进行零样本面部表情识别（FER）基准测试。评估了YOLO（v8、v11、v12）的中型和纳米变体进行人脸检测，以及通用视觉Transformer（CLIP、SigLIP、ViT-FER）进行表情分类，所有推理均在纯CPU环境下运行。

Result: 人脸检测在风格化虚拟角色上鲁棒性很高（100%准确率），但分类阶段存在“延迟墙”。YOLOv11n在检测阶段达到最佳平衡（约54ms）。然而，通用Transformer模型（如CLIP、SigLIP）在实时循环中无法达到可行的准确率（<23%）或速度（>150ms）。

Conclusion: 研究表明，为了实现可访问的实时AI辅助VR治疗，需要开发轻量级、领域特定的面部表情识别架构，以同时满足严格的延迟限制和准确率要求。

Abstract: In the realm of Virtual Reality (VR) and Human-Computer Interaction (HCI), real-time emotion recognition shows promise for supporting individuals with Autism Spectrum Disorder (ASD) in improving social skills. This task requires a strict latency-accuracy trade-off, with motion-to-photon (MTP) latency kept below 140 ms to maintain contingency. However, most off-the-shelf Deep Learning models prioritize accuracy over the strict timing constraints of commodity hardware. As a first step toward accessible VR therapy, we benchmark State-of-the-Art (SOTA) models for Zero-Shot Facial Expression Recognition (FER) on virtual characters using the UIBVFED dataset. We evaluate Medium and Nano variants of YOLO (v8, v11, and v12) for face detection, alongside general-purpose Vision Transformers including CLIP, SigLIP, and ViT-FER.Our results on CPU-only inference demonstrate that while face detection on stylized avatars is robust (100% accuracy), a "Latency Wall" exists in the classification stage. The YOLOv11n architecture offers the optimal balance for detection (~54 ms). However, general-purpose Transformers like CLIP and SigLIP fail to achieve viable accuracy (<23%) or speed (>150 ms) for real-time loops. This study highlights the necessity for lightweight, domain-specific architectures to enable accessible, real-time AI in therapeutic settings.

</details>


### [19] [VideoThinker: Building Agentic VideoLLMs with LLM-Guided Tool Reasoning](https://arxiv.org/abs/2601.15724)
*Chenglin Li,Qianglong Chen,Feng Han,Yikun Wang,Xingxi Yin,Yan Gong,Ruilin Li,Yin Zhang,Jiaqi Wang*

Main category: cs.CV

TL;DR: 为解决长视频理解难题，本文提出VideoThinker：一个完全基于合成工具交互轨迹训练的智能体视频大语言模型，通过自适应检索与缩放推理显著提升长视频理解性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视频大语言模型多依赖均匀采样的静态推理，导致长视频中时间定位弱化和信息丢失严重。传统工具交互数据构建又需要模型具备长视频理解能力，形成循环依赖。需要探索无需原始长视频理解能力即可生成工具交互数据的新方法。

Method: 将视频转换为丰富的文本描述，利用强大的智能体语言模型在文本空间生成多步工具使用序列，再将文本轨迹替换为对应的视频帧，从而创建大规模的视频与工具推理交替数据集，无需底层模型具备长视频理解能力。基于此合成数据集训练VideoThinker模型。

Result: VideoThinker在长视频基准测试中显著超越仅使用文本描述的语言模型智能体和强基线视频模型，展示了工具增强的合成数据和自适应检索缩放推理对长视频理解的有效性。

Conclusion: 采用文本空间工具交互轨迹合成并回植视频的方法，可突破长视频理解工具数据的循环依赖瓶颈。VideoThinker通过自适应时间探索和多步工具使用能力，为长视频理解提供了有效解决方案。

Abstract: Long-form video understanding remains a fundamental challenge for current Video Large Language Models. Most existing models rely on static reasoning over uniformly sampled frames, which weakens temporal localization and leads to substantial information loss in long videos. Agentic tools such as temporal retrieval, spatial zoom, and temporal zoom offer a natural way to overcome these limitations by enabling adaptive exploration of key moments. However, constructing agentic video understanding data requires models that already possess strong long-form video comprehension, creating a circular dependency. We address this challenge with VideoThinker, an agentic Video Large Language Model trained entirely on synthetic tool interaction trajectories. Our key idea is to convert videos into rich captions and employ a powerful agentic language model to generate multi-step tool use sequences in caption space. These trajectories are subsequently grounded back to video by replacing captions with the corresponding frames, yielding a large-scale interleaved video and tool reasoning dataset without requiring any long-form understanding from the underlying model. Training on this synthetic agentic dataset equips VideoThinker with dynamic reasoning capabilities, adaptive temporal exploration, and multi-step tool use. Remarkably, VideoThinker significantly outperforms both caption-only language model agents and strong video model baselines across long-video benchmarks, demonstrating the effectiveness of tool augmented synthetic data and adaptive retrieval and zoom reasoning for long-form video understanding.

</details>


### [20] [FAIR-ESI: Feature Adaptive Importance Refinement for Electrophysiological Source Imaging](https://arxiv.org/abs/2601.15731)
*Linyong Zou,Liang Zhang,Xiongfei Wang,Jia-Hong Gao,Yi Sun,Shurong Sheng,Kuntao Xiao,Wanli Yang,Pengfei Teng,Guoming Luan,Zhao Lv,Zikang Xu*

Main category: cs.CV

TL;DR: FAIR-ESI框架通过多视角特征重要性自适应优化提升脑电源成像精度


<details>
  <summary>Details</summary>
Motivation: 脑电源成像(ESI)是诊断脑部疾病的重要技术，但现有基于模型优化和深度学习的方法在特征选择和细化方面仍面临挑战，限制了其精度提升

Method: 提出FAIR-ESI框架，采用自适应特征重要性优化策略，包括基于FFT的频谱特征细化、加权时域特征细化和基于自注意力机制的patch-wise特征细化三个视图

Result: 在两个不同配置的仿真数据集和两个真实临床数据集上的广泛实验验证了框架的有效性

Conclusion: FAIR-ESI有潜力推动脑部疾病诊断的进步，并为脑功能研究提供新见解

Abstract: An essential technique for diagnosing brain disorders is electrophysiological source imaging (ESI). While model-based optimization and deep learning methods have achieved promising results in this field, the accurate selection and refinement of features remains a central challenge for precise ESI. This paper proposes FAIR-ESI, a novel framework that adaptively refines feature importance across different views, including FFT-based spectral feature refinement, weighted temporal feature refinement, and self-attention-based patch-wise feature refinement. Extensive experiments on two simulation datasets with diverse configurations and two real-world clinical datasets validate our framework's efficacy, highlighting its potential to advance brain disorder diagnosis and offer new insights into brain function.

</details>


### [21] [Sub-Region-Aware Modality Fusion and Adaptive Prompting for Multi-Modal Brain Tumor Segmentation](https://arxiv.org/abs/2601.15734)
*Shadi Alijani,Fereshteh Aghaee Meibodi,Homayoun Najjaran*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The successful adaptation of foundation models to multi-modal medical imaging is a critical yet unresolved challenge. Existing models often struggle to effectively fuse information from multiple sources and adapt to the heterogeneous nature of pathological tissues. To address this, we introduce a novel framework for adapting foundation models to multi-modal medical imaging, featuring two key technical innovations: sub-region-aware modality attention and adaptive prompt engineering. The attention mechanism enables the model to learn the optimal combination of modalities for each tumor sub-region, while the adaptive prompting strategy leverages the inherent capabilities of foundation models to refine segmentation accuracy. We validate our framework on the BraTS 2020 brain tumor segmentation dataset, demonstrating that our approach significantly outperforms baseline methods, particularly in the challenging necrotic core sub-region. Our work provides a principled and effective approach to multi-modal fusion and prompting, paving the way for more accurate and robust foundation model-based solutions in medical imaging.

</details>


### [22] [Breaking the Resolution Barrier: Arbitrary-resolution Deep Image Steganography Framework](https://arxiv.org/abs/2601.15739)
*Xinjue Hu,Chi Wang,Boyu Wang,Xiang Zhang,Zhenshan Tan,Zhangjie Fu*

Main category: cs.CV

TL;DR: ARDIS是一个创新的任意分辨率深度图像隐写框架，能够处理与载体图像分辨率不匹配的秘密图像，通过参考引导的连续信号重建实现高质量恢复。


<details>
  <summary>Details</summary>
Motivation: 当前深度图像隐写方法要求秘密图像与载体图像保持相同分辨率，导致两个问题：1) 分辨率不一致时需要预处理重采样，恢复时造成细节损失；2) 分辨率值未知时无法恢复原始分辨率。需要突破现有离散映射范式，实现任意分辨率的秘密图像隐写与恢复。

Method: 提出ARDIS框架，包含三个核心技术：1) 在隐藏阶段设计频率解耦架构，将秘密图像分解为分辨率对齐的全局基和分辨率无关的高频潜在表示；2) 在恢复阶段提出潜在引导隐式重建器，通过连续隐函数查询和渲染高频残差；3) 引入隐式分辨率编码策略，将离散分辨率值转换为密集特征图隐藏在特征域冗余空间中，支持盲恢复。

Result: 实验结果表明，ARDIS在视觉不可感知性和跨分辨率恢复保真度方面显著优于最先进的方法，能够准确恢复原始分辨率的秘密图像细节。

Conclusion: ARDIS通过频率解耦架构、潜在引导隐式重建和隐式分辨率编码三大创新，成功实现了首个支持任意分辨率的深度图像隐写框架，突破了传统方法的分辨率限制，为高保真跨分辨率隐写开辟了新方向。

Abstract: Deep image steganography (DIS) has achieved significant results in capacity and invisibility. However, current paradigms enforce the secret image to maintain the same resolution as the cover image during hiding and revealing. This leads to two challenges: secret images with inconsistent resolutions must undergo resampling beforehand which results in detail loss during recovery, and the secret image cannot be recovered to its original resolution when the resolution value is unknown. To address these, we propose ARDIS, the first Arbitrary Resolution DIS framework, which shifts the paradigm from discrete mapping to reference-guided continuous signal reconstruction. Specifically, to minimize the detail loss caused by resolution mismatch, we first design a Frequency Decoupling Architecture in hiding stage. It disentangles the secret into a resolution-aligned global basis and a resolution-agnostic high-frequency latent to hide in a fixed-resolution cover. Second, for recovery, we propose a Latent-Guided Implicit Reconstructor to perform deterministic restoration. The recovered detail latent code modulates a continuous implicit function to accurately query and render high-frequency residuals onto the recovered global basis, ensuring faithful restoration of original details. Furthermore, to achieve blind recovery, we introduce an Implicit Resolution Coding strategy. By transforming discrete resolution values into dense feature maps and hiding them in the redundant space of the feature domain, the reconstructor can correctly decode the secret's resolution directly from the steganographic representation. Experimental results demonstrate that ARDIS significantly outperforms state-of-the-art methods in both invisibility and cross-resolution recovery fidelity.

</details>


### [23] [White-Box mHC: Electromagnetic Spectrum-Aware and Interpretable Stream Interactions for Hyperspectral Image Classification](https://arxiv.org/abs/2601.15757)
*Yimin Zhu,Lincoln Linlin Xu,Zhengsen Xu,Zack Dewis,Mabel Heffring,Saeid Taleghanidoozdoozan,Motasem Alkayid,Quinn Ledingham,Megan Greenwood*

Main category: cs.CV

TL;DR: ES-mHC 是一个用于高光谱图像分类的自连接框架，通过显式地对不同电磁频谱分组之间的相互作用进行结构化建模，将特征表示与交互结构分离，提供了模型内部决策机制的可视化和空间分析能力，提升了分类任务的可解释性和透明度。


<details>
  <summary>Details</summary>
Motivation: 当前高光谱图像分类的深度学习模型大多依赖于不透明的频谱空间特征混合，限制了模型的可解释性，阻碍了对内部决策机制的理解。因此，需要开发一种能够显式建模频谱分组间交互并暴露内部信息流的白盒模型。

Method: 提出了物理频谱感知白盒模型 ES-mHC，它使用结构化方向矩阵显式建模不同电磁频谱分组（mHC 中的残差流）之间的相互作用，分离特征表示与交互结构，促进频谱分组专业化、减少冗余，并能直接可视化和空间分析内部信息流。

Result: 通过高光谱图像分类测试，发现学习到的自连接矩阵展现出连贯的空间模式和非对称交互行为，提供了对模型内部动态的机制性洞察。此外，增加扩展速率会加速结构化交互模式的出现。

Conclusion: ES-mHC 将高光谱图像分类从纯粹的黑盒预测任务转变为结构透明、部分白盒的学习过程，提高了模型的可解释性，并为理解深度学习模型的内部决策机制提供了一个有效的框架。

Abstract: In hyperspectral image classification (HSIC), most deep learning models rely on opaque spectral-spatial feature mixing, limiting their interpretability and hindering understanding of internal decision mechanisms. We present physical spectrum-aware white-box mHC, named ES-mHC, a hyper-connection framework that explicitly models interactions among different electromagnetic spectrum groupings (residual stream in mHC) interactions using structured, directional matrices. By separating feature representation from interaction structure, ES-mHC promotes electromagnetic spectrum grouping specialization, reduces redundancy, and exposes internal information flow that can be directly visualized and spatially analyzed. Using hyperspectral image classification as a representative testbed, we demonstrate that the learned hyper-connection matrices exhibit coherent spatial patterns and asymmetric interaction behaviors, providing mechanistic insight into the model internal dynamics. Furthermore, we find that increasing the expansion rate accelerates the emergence of structured interaction patterns. These results suggest that ES-mHC transforms HSIC from a purely black-box prediction task into a structurally transparent, partially white-box learning process.

</details>


### [24] [Atlas-Assisted Segment Anything Model for Fetal Brain MRI (FeTal-SAM)](https://arxiv.org/abs/2601.15759)
*Qi Zeng,Weide Liu,Bo Li,Ryne Didier,P. Ellen Grant,Davood Karimi*

Main category: cs.CV

TL;DR: FeTal-SAM是基于Segment Anything Model（SAM）改进的胎儿脑部MRI分割模型，解决了传统方法对固定标签定义和大量标注数据的依赖问题，通过图谱提示实现灵活的单结构分割。


<details>
  <summary>Details</summary>
Motivation: 传统胎儿脑MRI分割方法需要为不同标签定义重新训练模型，且无法区分模型是基于图像对比度还是空间先验进行分割，限制了临床和研究的灵活性。FeTal-SAM旨在创建无需频繁重训练、能适应不同解剖结构需求的通用分割工具。

Method: 使用多图谱配准生成空间对齐的标签模板作为密集提示，结合边界框提示输入SAM分割解码器，实现逐结构的二元分割，最后融合重建完整的3D分割体积。

Result: 在两个数据集（dHCP和内部数据）上评估显示，对于皮质板、小脑等高对比度结构，FeTal-SAM的Dice分数与针对特定数据集和标签训练的最先进基线相当，但对海马体、杏仁核等低对比度结构的精度略低。

Conclusion: FeTal-SAM展示了无需大量重训练就能实现通用胎儿脑MRI分割的潜力，是迈向临床适应性分析工具的重要一步。

Abstract: This paper presents FeTal-SAM, a novel adaptation of the Segment Anything Model (SAM) tailored for fetal brain MRI segmentation. Traditional deep learning methods often require large annotated datasets for a fixed set of labels, making them inflexible when clinical or research needs change. By integrating atlas-based prompts and foundation-model principles, FeTal-SAM addresses two key limitations in fetal brain MRI segmentation: (1) the need to retrain models for varying label definitions, and (2) the lack of insight into whether segmentations are driven by genuine image contrast or by learned spatial priors. We leverage multi-atlas registration to generate spatially aligned label templates that serve as dense prompts, alongside a bounding-box prompt, for SAM's segmentation decoder. This strategy enables binary segmentation on a per-structure basis, which is subsequently fused to reconstruct the full 3D segmentation volumes. Evaluations on two datasets, the dHCP dataset and an in-house dataset demonstrate FeTal-SAM's robust performance across gestational ages. Notably, it achieves Dice scores comparable to state-of-the-art baselines which were trained for each dataset and label definition for well-contrasted structures like cortical plate and cerebellum, while maintaining the flexibility to segment any user-specified anatomy. Although slightly lower accuracy is observed for subtle, low-contrast structures (e.g., hippocampus, amygdala), our results highlight FeTal-SAM's potential to serve as a general-purpose segmentation model without exhaustive retraining. This method thus constitutes a promising step toward clinically adaptable fetal brain MRI analysis tools.

</details>


### [25] [LL-GaussianMap: Zero-shot Low-Light Image Enhancement via 2D Gaussian Splatting Guided Gain Maps](https://arxiv.org/abs/2601.15766)
*Yuhan Chen,Ying Fang,Guofa Li,Wenxuan Yu,Yicui Shi,Jingrui Zhang,Kefei Qian,Wenbo Chu,Keqiang Li*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Significant progress has been made in low-light image enhancement with respect to visual quality. However, most existing methods primarily operate in the pixel domain or rely on implicit feature representations. As a result, the intrinsic geometric structural priors of images are often neglected. 2D Gaussian Splatting (2DGS) has emerged as a prominent explicit scene representation technique characterized by superior structural fitting capabilities and high rendering efficiency. Despite these advantages, the utilization of 2DGS in low-level vision tasks remains unexplored. To bridge this gap, LL-GaussianMap is proposed as the first unsupervised framework incorporating 2DGS into low-light image enhancement. Distinct from conventional methodologies, the enhancement task is formulated as a gain map generation process guided by 2DGS primitives. The proposed method comprises two primary stages. First, high-fidelity structural reconstruction is executed utilizing 2DGS. Then, data-driven enhancement dictionary coefficients are rendered via the rasterization mechanism of Gaussian splatting through an innovative unified enhancement module. This design effectively incorporates the structural perception capabilities of 2DGS into gain map generation, thereby preserving edges and suppressing artifacts during enhancement. Additionally, the reliance on paired data is circumvented through unsupervised learning. Experimental results demonstrate that LL-GaussianMap achieves superior enhancement performance with an extremely low storage footprint, highlighting the effectiveness of explicit Gaussian representations for image enhancement.

</details>


### [26] [LL-GaussianImage: Efficient Image Representation for Zero-shot Low-Light Enhancement with 2D Gaussian Splatting](https://arxiv.org/abs/2601.15772)
*Yuhan Chen,Wenxuan Yu,Guofa Li,Yijun Xu,Ying Fang,Yicui Shi,Long Cao,Wenbo Chu,Keqiang Li*

Main category: cs.CV

TL;DR: 提出首个针对2DGS压缩表征域的低光照增强框架LL-GaussianImage，实现压缩即增强的零样本无监督处理。


<details>
  <summary>Details</summary>
Motivation: 现有低光照增强算法主要在像素域操作，处理2DGS压缩图像需经过繁琐的解码-增强-再编码流程，效率低下且易导致二次退化。

Method: 1. 语义引导的专家混合增强框架，以渲染图像为引导对2DGS稀疏属性空间进行动态自适应变换；2. 多目标协同损失函数系统约束平滑度和保真度；3. 两阶段优化过程，通过单尺度重建确保基础表征精度。

Result: 实验验证了在压缩表征域直接处理的可行性和优越性，在保持高压缩比的同时实现高质量低光照图像增强。

Conclusion: LL-GaussianImage首次实现在2DGS压缩域直接进行低光照增强，避免了传统管道缺陷，为压缩表征域处理提供了有效范式。

Abstract: 2D Gaussian Splatting (2DGS) is an emerging explicit scene representation method with significant potential for image compression due to high fidelity and high compression ratios. However, existing low-light enhancement algorithms operate predominantly within the pixel domain. Processing 2DGS-compressed images necessitates a cumbersome decompression-enhancement-recompression pipeline, which compromises efficiency and introduces secondary degradation. To address these limitations, we propose LL-GaussianImage, the first zero-shot unsupervised framework designed for low-light enhancement directly within the 2DGS compressed representation domain. Three primary advantages are offered by this framework. First, a semantic-guided Mixture-of-Experts enhancement framework is designed. Dynamic adaptive transformations are applied to the sparse attribute space of 2DGS using rendered images as guidance to enable compression-as-enhancement without full decompression to a pixel grid. Second, a multi-objective collaborative loss function system is established to strictly constrain smoothness and fidelity during enhancement, suppressing artifacts while improving visual quality. Third, a two-stage optimization process is utilized to achieve reconstruction-as-enhancement. The accuracy of the base representation is ensured through single-scale reconstruction and network robustness is enhanced. High-quality enhancement of low-light images is achieved while high compression ratios are maintained. The feasibility and superiority of the paradigm for direct processing within the compressed representation domain are validated through experimental results.

</details>


### [27] [Diffusion Model-Based Data Augmentation for Enhanced Neuron Segmentation](https://arxiv.org/abs/2601.15779)
*Liuyun Jiang,Yanchao Zhang,Jinyue Guo,Yizhuo Lu,Ruining Zhou,Hua Han*

Main category: cs.CV

TL;DR: 针对电子显微镜神经元分割中数据标注成本高的问题，提出了一种扩散模型驱动的数据增强框架，通过生成多样且结构合理的图像-标签对来提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法依赖大规模标注数据，传统数据增强方法生成的样本与原始图像相关性高且缺乏结构多样性，限制了神经元分割性能的提升。

Method: 采用分辨率感知的条件扩散模型，结合多尺度条件和EM分辨率先验，从3D掩码实现体素级图像合成，并加入生物学引导的掩码重塑模块来增强结构真实性。

Result: 在AC3和AC4低标注数据集上，结合两种后处理方法分别将ARAND指标提升了32.1%和30.7%。

Conclusion: 扩散式数据增强框架能有效丰富训练数据，在低标注场景下显著改善神经元分割效果，为电镜图像分析提供了新思路。

Abstract: Neuron segmentation in electron microscopy (EM) aims to reconstruct the complete neuronal connectome; however, current deep learning-based methods are limited by their reliance on large-scale training data and extensive, time-consuming manual annotations. Traditional methods augment the training set through geometric and photometric transformations; however, the generated samples remain highly correlated with the original images and lack structural diversity. To address this limitation, we propose a diffusion-based data augmentation framework capable of generating diverse and structurally plausible image-label pairs for neuron segmentation. Specifically, the framework employs a resolution-aware conditional diffusion model with multi-scale conditioning and EM resolution priors to enable voxel-level image synthesis from 3D masks. It further incorporates a biology-guided mask remodeling module that produces augmented masks with enhanced structural realism. Together, these components effectively enrich the training set and improve segmentation performance. On the AC3 and AC4 datasets under low-annotation regimes, our method improves the ARAND metric by 32.1% and 30.7%, respectively, when combined with two different post-processing methods. Our code is available at https://github.com/HeadLiuYun/NeuroDiff.

</details>


### [28] [A Mobile Application for Flower Recognition System Based on Convolutional Neural Networks](https://arxiv.org/abs/2601.15810)
*Mustafa Yurdakul,Enes Ayan,Fahrettin Horasan,Sakir Tasdemir*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A convolutional neural network (CNN) is a deep learning algorithm that has been specifically designed for computer vision applications. The CNNs proved successful in handling the increasing amount of data in many computer vision problems, where classical machine learning algorithms were insufficient. Flowers have many uses in our daily lives, from decorating to making medicines to detoxifying the environment. Identifying flower types requires expert knowledge. However, accessing experts at any time and in any location may not always be feasible. In this study a mobile application based on CNNs was developed to recognize different types of flowers to provide non-specialists with quick and easy access to information about flower types. The study employed three distinct CNN models, namely MobileNet, DenseNet121, and Xception, to determine the most suitable model for the mobile application. The classification performances of the models were evaluated by training them with seven different optimization algorithms. The DenseNet-121 architecture, which uses the stochastic gradient descent (SGD) optimization algorithm, was the most successful, achieving 95.84 % accuracy, 96.00% precision, recall, and F1-score. This result shows that CNNs can be used for flower classification in mobile applications.

</details>


### [29] [Beyond Off-the-Shelf Models: A Lightweight and Accessible Machine Learning Pipeline for Ecologists Working with Image Data](https://arxiv.org/abs/2601.15813)
*Clare Chemery,Hendrik Edelhoff,Ludwig Bothmann*

Main category: cs.CV

TL;DR: 本文开发了一个轻量级的实验管道工具，旨在降低生态学家应用机器学习进行图像分类的门槛，使生态学家能够独立实验和定制化模型，并以红鹿的年龄和性别分类作为案例验证。


<details>
  <summary>Details</summary>
Motivation: 生态研究中应用机器学习方法存在较高门槛，生态学家往往依赖现成的模型而无法针对本地数据集和特定分类任务进行定制化。本文旨在通过提供一个易于使用的工具，让生态学家能够独立地进行模型实验和迭代，从而生成针对特定研究问题的见解。

Method: 开发了一个结合命令行界面（用于数据预处理、训练和评估）和图形界面（用于标注、错误分析和模型比较）的轻量级实验管道工具。该工具使生态学家能够无需高级机器学习专业知识即可构建和迭代针对特定任务的紧凑分类器。作为概念验证，将该管道应用于从德国Veldenstein Forest收集的3392张相机陷阱图像中，对红鹿进行年龄和性别分类。使用4352张专家标注的个体鹿裁剪图像，训练和评估了多种骨干架构、参数和数据增强策略。

Result: 最佳性能模型在年龄分类上达到了90.77%的准确率，在性别分类上达到了96.15%的准确率。这些结果表明，即使数据有限，针对定义明确的生态问题进行可靠的人口统计分类是可行的。

Conclusion: 该框架为生态学家提供了一个易于使用的工具，用于开发针对特定研究问题定制的机器学习模型，为推动机器学习在野生动物监测和人口统计分析中的更广泛应用铺平了道路。

Abstract: We introduce a lightweight experimentation pipeline designed to lower the barrier for applying machine learning (ML) methods for classifying images in ecological research. We enable ecologists to experiment with ML models independently, thus they can move beyond off-the-shelf models and generate insights tailored to local datasets and specific classification tasks and target variables. Our tool combines a simple command-line interface for preprocessing, training, and evaluation with a graphical interface for annotation, error analysis, and model comparison. This design enables ecologists to build and iterate on compact, task-specific classifiers without requiring advanced ML expertise. As a proof of concept, we apply the pipeline to classify red deer (Cervus elaphus) by age and sex from 3392 camera trap images collected in the Veldenstein Forest, Germany. Using 4352 cropped images containing individual deer labeled by experts, we trained and evaluated multiple backbone architectures with a wide variety of parameters and data augmentation strategies. Our best-performing models achieved 90.77% accuracy for age classification and 96.15% for sex classification. These results demonstrate that reliable demographic classification is feasible even with limited data to answer narrow, well-defined ecological problems. More broadly, the framework provides ecologists with an accessible tool for developing ML models tailored to specific research questions, paving the way for broader adoption of ML in wildlife monitoring and demographic analysis.

</details>


### [30] [Towards Realistic Remote Sensing Dataset Distillation with Discriminative Prototype-guided Diffusion](https://arxiv.org/abs/2601.15829)
*Yonghao Xu,Pedram Ghamisi,Qihao Weng*

Main category: cs.CV

TL;DR: 该论文首次将数据集蒸馏概念引入遥感图像解读领域，使用文本到图像扩散模型将大规模遥感数据集压缩为紧凑且具有代表性的蒸馏数据集，解决了传统深度学习中存储成本高和数据泄露风险的问题


<details>
  <summary>Details</summary>
Motivation: 遥感图像解读中深度学习依赖大规模数据集带来的两大挑战：1) 高昂的存储和计算成本；2) 敏感类别数据泄露风险。为应对这些挑战，首次将数据集蒸馏引入遥感领域

Method: 1. 训练文本到图像扩散模型来压缩大规模遥感数据集；2. 提出分类器驱动的引导机制，将预训练模型的分类一致性损失注入扩散训练过程以提高合成样本的判别质量；3. 对训练样本进行潜在空间聚类选择代表性的多样化原型作为视觉风格引导，同时使用视觉语言模型提供聚合文本描述

Result: 在三个高分辨率遥感场景分类基准测试上的实验表明，该方法能够为下游模型训练蒸馏出逼真且多样化的样本，代码和预训练模型已在线上开源

Conclusion: 提出的方法成功实现了遥感数据集的有效蒸馏，能够生成质量高的合成样本用于下游模型训练，为遥感图像解读领域提供了一种高效且安全的替代方案

Abstract: Recent years have witnessed the remarkable success of deep learning in remote sensing image interpretation, driven by the availability of large-scale benchmark datasets. However, this reliance on massive training data also brings two major challenges: (1) high storage and computational costs, and (2) the risk of data leakage, especially when sensitive categories are involved. To address these challenges, this study introduces the concept of dataset distillation into the field of remote sensing image interpretation for the first time. Specifically, we train a text-to-image diffusion model to condense a large-scale remote sensing dataset into a compact and representative distilled dataset. To improve the discriminative quality of the synthesized samples, we propose a classifier-driven guidance by injecting a classification consistency loss from a pre-trained model into the diffusion training process. Besides, considering the rich semantic complexity of remote sensing imagery, we further perform latent space clustering on training samples to select representative and diverse prototypes as visual style guidance, while using a visual language model to provide aggregated text descriptions. Experiments on three high-resolution remote sensing scene classification benchmarks show that the proposed method can distill realistic and diverse samples for downstream model training. Code and pre-trained models are available online (https://github.com/YonghaoXu/DPD).

</details>


### [31] [TinySense: Effective CSI Compression for Scalable and Accurate Wi-Fi Sensing](https://arxiv.org/abs/2601.15838)
*Toan Gian,Dung T. Tran,Viet Quoc Pham,Francesco Restuccia,Van-Dinh Nguyen*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: With the growing demand for device-free and privacy-preserving sensing solutions, Wi-Fi sensing has emerged as a promising approach for human pose estimation (HPE). However, existing methods often process vast amounts of channel state information (CSI) data directly, ultimately straining networking resources. This paper introduces TinySense, an efficient compression framework that enhances the scalability of Wi-Fi-based human sensing. Our approach is based on a new vector quantization-based generative adversarial network (VQGAN). Specifically, by leveraging a VQGAN-learned codebook, TinySense significantly reduces CSI data while maintaining the accuracy required for reliable HPE. To optimize compression, we employ the K-means algorithm to dynamically adjust compression bitrates to cluster a large-scale pre-trained codebook into smaller subsets. Furthermore, a Transformer model is incorporated to mitigate bitrate loss, enhancing robustness in unreliable networking conditions. We prototype TinySense on an experimental testbed using Jetson Nano and Raspberry Pi to measure latency and network resource use. Extensive results demonstrate that TinySense significantly outperforms state-of-the-art compression schemes, achieving up to 1.5x higher HPE accuracy score (PCK20) under the same compression rate. It also reduces latency and networking overhead, respectively, by up to 5x and 2.5x. The code repository is available online at here.

</details>


### [32] [A Lightweight Brain-Inspired Machine Learning Framework for Coronary Angiography: Hybrid Neural Representation and Robust Learning Strategies](https://arxiv.org/abs/2601.15865)
*Jingsong Xia,Siqi Wang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Background: Coronary angiography (CAG) is a cornerstone imaging modality for assessing coronary artery disease and guiding interventional treatment decisions. However, in real-world clinical settings, angiographic images are often characterized by complex lesion morphology, severe class imbalance, label uncertainty, and limited computational resources, posing substantial challenges to conventional deep learning approaches in terms of robustness and generalization.Methods: The proposed framework is built upon a pretrained convolutional neural network to construct a lightweight hybrid neural representation. A selective neural plasticity training strategy is introduced to enable efficient parameter adaptation. Furthermore, a brain-inspired attention-modulated loss function, combining Focal Loss with label smoothing, is employed to enhance sensitivity to hard samples and uncertain annotations. Class-imbalance-aware sampling and cosine annealing with warm restarts are adopted to mimic rhythmic regulation and attention allocation mechanisms observed in biological neural systems.Results: Experimental results demonstrate that the proposed lightweight brain-inspired model achieves strong and stable performance in binary coronary angiography classification, yielding competitive accuracy, recall, F1-score, and AUC metrics while maintaining high computational efficiency.Conclusion: This study validates the effectiveness of brain-inspired learning mechanisms in lightweight medical image analysis and provides a biologically plausible and deployable solution for intelligent clinical decision support under limited computational resources.

</details>


### [33] [PMPBench: A Paired Multi-Modal Pan-Cancer Benchmark for Medical Image Synthesis](https://arxiv.org/abs/2601.15884)
*Yifan Chen,Fei Yin,Hao Chen,Jia Wu,Chao Li*

Main category: cs.CV

TL;DR: 研究创建了首个公开、完全配对的泛肿瘤医疗影像数据集PMPBench，包含11个人体器官的完整动态对比增强序列和配对非增强-增强CT，并建立了全面的图像转换基准，以推动安全有效的对比剂合成研究。


<details>
  <summary>Details</summary>
Motivation: 对比剂在影像学中至关重要但并非总能使用，现有AI图像转换研究因缺乏公开、高质量、跨器官、完全配对的对比增强影像数据集而受限。

Method: 构建首个公开的完全配对泛肿瘤影像数据集，涵盖11个人体器官，包括完整的DCE序列和配对CT，确保解剖对应性；在此基础上建立图像到图像转换的全面基准测试。

Result: 建立了PMPBench数据集和基准测试平台，可支持1对1、N对1、N对N图像转换场景的严格评估，并公布了代表性基线的性能结果。

Conclusion: 这一资源填补了高质量配对医学影像数据的空缺，有望加速安全有效的对比剂合成研究，对多器官肿瘤影像工作流程具有直接应用价值。

Abstract: Contrast medium plays a pivotal role in radiological imaging, as it amplifies lesion conspicuity and improves detection for the diagnosis of tumor-related diseases. However, depending on the patient's health condition or the medical resources available, the use of contrast medium is not always feasible. Recent work has explored AI-based image translation to synthesize contrast-enhanced images directly from non-contrast scans, aims to reduce side effects and streamlines clinical workflows. Progress in this direction has been constrained by data limitations: (1) existing public datasets focus almost exclusively on brain-related paired MR modalities; (2) other collections include partially paired data but suffer from missing modalities/timestamps and imperfect spatial alignment; (3) explicit labeling of CT vs. CTC or DCE phases is often absent; (4) substantial resources remain private. To bridge this gap, we introduce the first public, fully paired, pan-cancer medical imaging dataset spanning 11 human organs. The MR data include complete dynamic contrast-enhanced (DCE) sequences covering all three phases (DCE1-DCE3), while the CT data provide paired non-contrast and contrast-enhanced acquisitions (CTC). The dataset is curated for anatomical correspondence, enabling rigorous evaluation of 1-to-1, N-to-1, and N-to-N translation settings (e.g., predicting DCE phases from non-contrast inputs). Built upon this resource, we establish a comprehensive benchmark. We report results from representative baselines of contemporary image-to-image translation. We release the dataset and benchmark to catalyze research on safe, effective contrast synthesis, with direct relevance to multi-organ oncology imaging workflows. Our code and dataset are publicly available at https://github.com/YifanChen02/PMPBench.

</details>


### [34] [Understanding the Transfer Limits of Vision Foundation Models](https://arxiv.org/abs/2601.15888)
*Shiqi Huang,Yipei Wang,Natasha Thorley,Alexander Ng,Shaheer Saeed,Mark Emberton,Shonit Punwani,Veeru Kasivisvanathan,Dean Barratt,Daniel Alexander,Yipeng Hu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Foundation models leverage large-scale pretraining to capture extensive knowledge, demonstrating generalization in a wide range of language tasks. By comparison, vision foundation models (VFMs) often exhibit uneven improvements across downstream tasks, despite substantial computational investment. We postulate that this limitation arises from a mismatch between pretraining objectives and the demands of downstream vision-and-imaging tasks. Pretraining strategies like masked image reconstruction or contrastive learning shape representations for tasks such as recovery of generic visual patterns or global semantic structures, which may not align with the task-specific requirements of downstream applications including segmentation, classification, or image synthesis. To investigate this in a concrete real-world clinical area, we assess two VFMs, a reconstruction-focused MAE-based model (ProFound) and a contrastive-learning-based model (ProViCNet), on five prostate multiparametric MR imaging tasks, examining how such task alignment influences transfer performance, i.e., from pretraining to fine-tuning. Our findings indicate that better alignment between pretraining and downstream tasks, measured by simple divergence metrics such as maximum-mean-discrepancy (MMD) between the same features before and after fine-tuning, correlates with greater performance improvements and faster convergence, emphasizing the importance of designing and analyzing pretraining objectives with downstream applicability in mind.

</details>


### [35] [RadJEPA: Radiology Encoder for Chest X-Rays via Joint Embedding Predictive Architecture](https://arxiv.org/abs/2601.15891)
*Anas Anwarul Haq Khan,Mariam Husain,Kshitij Jadhav*

Main category: cs.CV

TL;DR: 提出RadJEPA，一种基于联合嵌入预测架构的自我监督框架，无需语言监督，仅使用未标记的胸部X光图像预训练。模型学习预测掩码图像区域的潜在表示，在疾病分类、语义分割和报告生成任务中表现优异，超越了包括Rad-DINO在内的先进方法。


<details>
  <summary>Details</summary>
Motivation: 当前的医学视觉语言模型依赖于成对的图像-文本数据进行监督学习，但这种监督形式受限于数据的可用性。本工作旨在探索是否可以在不依赖语言监督的情况下学习到稳健的放射学编码器。

Method: RadJEPA基于联合嵌入预测架构（JEPA），仅使用无标签的胸部X光图像进行预训练。模型通过学习预测被掩盖图像区域的潜在表示来训练，这与图像-文本预训练和DINO风格的自我蒸馏不同，它直接对潜在空间的预测进行建模。

Result: RadJEPA在疾病分类、语义分割和报告生成等多项任务上进行了评估，在多个基准测试中，其性能均超越了现有的最先进方法，包括Rad-DINO。

Conclusion: RadJEPA在不依赖语言监督的情况下，仅通过自监督学习就能获得强健的医学图像表示，为医学图像分析提供了一个有效且高效的新框架。

Abstract: Recent advances in medical vision language models guide the learning of visual representations; however, this form of supervision is constrained by the availability of paired image text data, raising the question of whether robust radiology encoders can be learned without relying on language supervision. In this work, we introduce RadJEPA, a self-supervised framework built on a Joint Embedding Predictive Architecture that learns without language supervision. Pre-trained solely on unlabeled chest X-ray images, the model learns to predict latent representations of masked image regions. This predictive objective differs fundamentally from both image text pre-training and DINO-style self-distillation: rather than aligning global representations across views or modalities, RadJEPA explicitly models latent-space prediction. We evaluate the learned encoder on disease classification, semantic segmentation, and report generation tasks. Across benchmarks, RadJEPA achieves performance exceeding state-of-the-art approaches, including Rad-DINO.

</details>


### [36] [Opening the Black Box: Preliminary Insights into Affective Modeling in Multimodal Foundation Models](https://arxiv.org/abs/2601.15906)
*Zhen Zhang,Runhao Zeng,Sicheng Zhao,Xiping Hu*

Main category: cs.CV

TL;DR: 该研究发现多模态基础模型中的情感能力主要由前馈门控机制（特别是gate_proj参数）介导，而非注意力模块，通过仅调节少量参数即可高效实现情感理解与生成。


<details>
  <summary>Details</summary>
Motivation: 尽管现有情感模型在实证表现上很强大，但支持情感理解和生成的内在架构机制仍不清楚。本研究旨在系统性地探索多模态基础模型中情感建模的机制性原理。

Method: 开展系统的机制研究，包括：1）分析不同架构、训练策略和情感任务中情感导向监督对内部参数的重塑；2）通过受控模块转移、目标性单模块适应和破坏性消融等实验；3）重点关注前馈门控投影（gate_proj）的作用。

Result: 研究发现：1）情感适应主要定位在gate_proj而非注意力模块；2）gate_proj对于情感理解和生成是充分、高效且必要的；3）仅调节AffectGPT约24.5%的参数即可达到其八项情感任务平均性能的96.6%。

Conclusion: 为大型基础模型中情感能力的结构定位提供了实证证据，表明情感建模以gate_proj为架构核心，并通过前馈门控机制实现，这一发现对高效情感模型设计具有指导意义。

Abstract: Understanding where and how emotions are represented in large-scale foundation models remains an open problem, particularly in multimodal affective settings. Despite the strong empirical performance of recent affective models, the internal architectural mechanisms that support affective understanding and generation are still poorly understood. In this work, we present a systematic mechanistic study of affective modeling in multimodal foundation models. Across multiple architectures, training strategies, and affective tasks, we analyze how emotion-oriented supervision reshapes internal model parameters. Our results consistently reveal a clear and robust pattern: affective adaptation does not primarily focus on the attention module, but instead localizes to the feed-forward gating projection (\texttt{gate\_proj}). Through controlled module transfer, targeted single-module adaptation, and destructive ablation, we further demonstrate that \texttt{gate\_proj} is sufficient, efficient, and necessary for affective understanding and generation. Notably, by tuning only approximately 24.5\% of the parameters tuned by AffectGPT, our approach achieves 96.6\% of its average performance across eight affective tasks, highlighting substantial parameter efficiency. Together, these findings provide empirical evidence that affective capabilities in foundation models are structurally mediated by feed-forward gating mechanisms and identify \texttt{gate\_proj} as a central architectural locus of affective modeling.

</details>


### [37] [A Multi-View Pipeline and Benchmark Dataset for 3D Hand Pose Estimation in Surgery](https://arxiv.org/abs/2601.15918)
*Valery Fischer,Alan Magdaleno,Anna-Katharina Calek,Nicola Cavalcanti,Nathan Hoffman,Christoph Germann,Joschua Wüthrich,Max Krähenmann,Mazda Farshad,Philipp Fürnstahl,Lilian Calvet*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Purpose: Accurate 3D hand pose estimation supports surgical applications such as skill assessment, robot-assisted interventions, and geometry-aware workflow analysis. However, surgical environments pose severe challenges, including intense and localized lighting, frequent occlusions by instruments or staff, and uniform hand appearance due to gloves, combined with a scarcity of annotated datasets for reliable model training.
  Method: We propose a robust multi-view pipeline for 3D hand pose estimation in surgical contexts that requires no domain-specific fine-tuning and relies solely on off-the-shelf pretrained models. The pipeline integrates reliable person detection, whole-body pose estimation, and state-of-the-art 2D hand keypoint prediction on tracked hand crops, followed by a constrained 3D optimization. In addition, we introduce a novel surgical benchmark dataset comprising over 68,000 frames and 3,000 manually annotated 2D hand poses with triangulated 3D ground truth, recorded in a replica operating room under varying levels of scene complexity.
  Results: Quantitative experiments demonstrate that our method consistently outperforms baselines, achieving a 31% reduction in 2D mean joint error and a 76% reduction in 3D mean per-joint position error.
  Conclusion: Our work establishes a strong baseline for 3D hand pose estimation in surgery, providing both a training-free pipeline and a comprehensive annotated dataset to facilitate future research in surgical computer vision.

</details>


### [38] [Class Confidence Aware Reweighting for Long Tailed Learning](https://arxiv.org/abs/2601.15924)
*Brainard Philemon Jagati,Jitendra Tembhurne,Harsh Goud,Rudra Pratap Singh,Chandrashekhar Meshram*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Deep neural network models degrade significantly in the long-tailed data distribution, with the overall training data dominated by a small set of classes in the head, and the tail classes obtaining less training examples. Addressing the imbalance in the classes, attention in the related literature was given mainly to the adjustments carried out in the decision space in terms of either corrections performed at the logit level in order to compensate class-prior bias, with the least attention to the optimization process resulting from the adjustments introduced through the differences in the confidences among the samples. In the current study, we present the design of a class and confidence-aware re-weighting scheme for long-tailed learning. This scheme is purely based upon the loss level and has a complementary nature to the existing methods performing the adjustment of the logits. In the practical implementation stage of the proposed scheme, we use an Ω(p_t, f_c) function. This function enables the modulation of the contribution towards the training task based upon the confidence value of the prediction, as well as the relative frequency of the corresponding class. Our observations in the experiments are corroborated by significant experimental results performed on the CIFAR-100-LT, ImageNet-LT, and iNaturalist2018 datasets under various values of imbalance factors that clearly authenticate the theoretical discussions above.

</details>


### [39] [NeuroMamba: Multi-Perspective Feature Interaction with Visual Mamba for Neuron Segmentation](https://arxiv.org/abs/2601.15929)
*Liuyun Jiang,Yizhuo Lu,Yanchao Zhang,Jiazheng Liu,Hua Han*

Main category: cs.CV

TL;DR: NeuroMamba:一个基于Mamba的多视角框架，用于神经图像分割，通过全局建模和局部特征建模的结合，有效解决长程依赖和体素细节保留问题


<details>
  <summary>Details</summary>
Motivation: 现有CNN方法缺乏长程上下文导致边界模糊，Transformer方法因patch划分丢失体素级细节。为解决这些限制，提出基于Mamba线性复杂度的新框架

Method: 1) 通道门控边界判别特征提取器(BDFE)增强局部形态线索；2) 空间连续特征提取器(SCFE)结合分辨率感知扫描机制；3) 跨调制机制融合多视角特征

Result: 在四个公共EM数据集上实现最先进性能，验证了对各向异性和各向同性分辨率的优异适应性

Conclusion: NeuroMamba框架通过全局-局部特征协同建模，在神经元分割任务上表现出色，代码将开源

Abstract: Neuron segmentation is the cornerstone of reconstructing comprehensive neuronal connectomes, which is essential for deciphering the functional organization of the brain. The irregular morphology and densely intertwined structures of neurons make this task particularly challenging. Prevailing CNN-based methods often fail to resolve ambiguous boundaries due to the lack of long-range context, whereas Transformer-based methods suffer from boundary imprecision caused by the loss of voxel-level details during patch partitioning. To address these limitations, we propose NeuroMamba, a multi-perspective framework that exploits the linear complexity of Mamba to enable patch-free global modeling and synergizes this with complementary local feature modeling, thereby efficiently capturing long-range dependencies while meticulously preserving fine-grained voxel details. Specifically, we design a channel-gated Boundary Discriminative Feature Extractor (BDFE) to enhance local morphological cues. Complementing this, we introduce the Spatial Continuous Feature Extractor (SCFE), which integrates a resolution-aware scanning mechanism into the Visual Mamba architecture to adaptively model global dependencies across varying data resolutions. Finally, a cross-modulation mechanism synergistically fuses these multi-perspective features. Our method demonstrates state-of-the-art performance across four public EM datasets, validating its exceptional adaptability to both anisotropic and isotropic resolutions. The source code will be made publicly available.

</details>


### [40] [EVolSplat4D: Efficient Volume-based Gaussian Splatting for 4D Urban Scene Synthesis](https://arxiv.org/abs/2601.15951)
*Sheng Miao,Sijin Li,Pan Wang,Dongfeng Bai,Bingbing Liu,Yue Wang,Andreas Geiger,Yiyi Liao*

Main category: cs.CV

TL;DR: 提出的EvolSplat4D是无需逐场景训练的快速4D场景重建新算法。


<details>
  <summary>Details</summary>
Motivation: 现有新视角合成方法，包括神经辐射场和3D高斯溅射等，在城市动态场景中难以兼顾重建速度与质量：前者需要逐场景优化导致耗时，后者采用逐像素高斯表示在复杂动态场景中容易产生三维不一致问题。

Method: 设计了三分支统一框架：对近景静态区域，直接从三维特征体素预测多帧一致的3D高斯几何，并配合语义增强的图像渲染模块；对动态物体，利用物体中心规范空间和运动调整渲染模块聚合时序特征；对远景，采用高效的逐像素高斯分支。

Result: 在多个自动驾驶数据集上的实验表明，EvolSplat4D在静态和动态场景的准确性与一致性方面均优于现有的逐场景优化和实时前馈方法，实现了更优的重建质量与速度平衡。

Conclusion: EvolSplat4D通过组合优化方法，实现了复杂动态城市场景的高质量快速4D重建，为自动驾驶仿真提供了高效解决方案。

Abstract: Novel view synthesis (NVS) of static and dynamic urban scenes is essential for autonomous driving simulation, yet existing methods often struggle to balance reconstruction time with quality. While state-of-the-art neural radiance fields and 3D Gaussian Splatting approaches achieve photorealism, they often rely on time-consuming per-scene optimization. Conversely, emerging feed-forward methods frequently adopt per-pixel Gaussian representations, which lead to 3D inconsistencies when aggregating multi-view predictions in complex, dynamic environments. We propose EvolSplat4D, a feed-forward framework that moves beyond existing per-pixel paradigms by unifying volume-based and pixel-based Gaussian prediction across three specialized branches. For close-range static regions, we predict consistent geometry of 3D Gaussians over multiple frames directly from a 3D feature volume, complemented by a semantically-enhanced image-based rendering module for predicting their appearance. For dynamic actors, we utilize object-centric canonical spaces and a motion-adjusted rendering module to aggregate temporal features, ensuring stable 4D reconstruction despite noisy motion priors. Far-Field scenery is handled by an efficient per-pixel Gaussian branch to ensure full-scene coverage. Experimental results on the KITTI-360, KITTI, Waymo, and PandaSet datasets show that EvolSplat4D reconstructs both static and dynamic environments with superior accuracy and consistency, outperforming both per-scene optimization and state-of-the-art feed-forward baselines.

</details>


### [41] [HyperAlign: Hypernetwork for Efficient Test-Time Alignment of Diffusion Models](https://arxiv.org/abs/2601.15968)
*Xin Xie,Jiaxian Guo,Dong Gong*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Diffusion models achieve state-of-the-art performance but often fail to generate outputs that align with human preferences and intentions, resulting in images with poor aesthetic quality and semantic inconsistencies. Existing alignment methods present a difficult trade-off: fine-tuning approaches suffer from loss of diversity with reward over-optimization, while test-time scaling methods introduce significant computational overhead and tend to under-optimize. To address these limitations, we propose HyperAlign, a novel framework that trains a hypernetwork for efficient and effective test-time alignment. Instead of modifying latent states, HyperAlign dynamically generates low-rank adaptation weights to modulate the diffusion model's generation operators. This allows the denoising trajectory to be adaptively adjusted based on input latents, timesteps and prompts for reward-conditioned alignment. We introduce multiple variants of HyperAlign that differ in how frequently the hypernetwork is applied, balancing between performance and efficiency. Furthermore, we optimize the hypernetwork using a reward score objective regularized with preference data to reduce reward hacking. We evaluate HyperAlign on multiple extended generative paradigms, including Stable Diffusion and FLUX. It significantly outperforms existing fine-tuning and test-time scaling baselines in enhancing semantic consistency and visual appeal.

</details>


### [42] [PhysicsMind: Sim and Real Mechanics Benchmarking for Physical Reasoning and Prediction in Foundational VLMs and World Models](https://arxiv.org/abs/2601.16007)
*Chak-Wing Mak,Guanyu Zhu,Boyi Zhang,Hongji Li,Xiaowei Chi,Kevin Zhang,Yichen Wu,Yangfan He,Chun-Kai Fan,Wentao Lu,Kuangzhi Ge,Xinyu Fang,Hongyang He,Kuan Lu,Tianxiang Xu,Li Zhang,Yongxin Ni,Youhua Li,Shanghang Zhang*

Main category: cs.CV

TL;DR: PhysicsMind是一个统一的基准测试，包含真实与仿真环境，用于评估模型对中心质量、杠杆平衡和牛顿第一定律三大物理定律的一致推理和生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs和视频世界模型在数学、常识和视觉推理方面进展显著，但其对底层物理规律的理解仍未充分探索。现有基准多依赖于合成的视觉问答模板或侧重于与物理定律相符性无关的感知视频质量，缺乏对物理规律一致性的系统性评估。

Method: PhysicsMind包含两个主要任务：1）VQA任务，测试模型能否从图像或短视频中推理并确定物理量和数值；2）视频生成任务，评估预测的运动轨迹是否与真实情况一样遵守中心质量、扭矩和惯性约束。基准涵盖真实和仿真环境，评估了三大经典物理原理。

Result: 对一系列最新模型和视频生成模型的评估显示，它们往往依赖外观启发式方法，而经常违反基础力学原理。这些差距表明当前的扩展和训练仍不足以实现稳健的物理理解。

Conclusion: PhysicsMind作为一个专注于物理感知的多模态模型测试平台，突显出现有模型在物理理解方面的不足，为未来改进提供了明确的方向。数据将在论文接受后发布。

Abstract: Modern foundational Multimodal Large Language Models (MLLMs) and video world models have advanced significantly in mathematical, common-sense, and visual reasoning, but their grasp of the underlying physics remains underexplored. Existing benchmarks attempting to measure this matter rely on synthetic, Visual Question Answer templates or focus on perceptual video quality that is tangential to measuring how well the video abides by physical laws. To address this fragmentation, we introduce PhysicsMind, a unified benchmark with both real and simulation environments that evaluates law-consistent reasoning and generation over three canonical principles: Center of Mass, Lever Equilibrium, and Newton's First Law. PhysicsMind comprises two main tasks: i) VQA tasks, testing whether models can reason and determine physical quantities and values from images or short videos, and ii) Video Generation(VG) tasks, evaluating if predicted motion trajectories obey the same center-of-mass, torque, and inertial constraints as the ground truth. A broad range of recent models and video generation models is evaluated on PhysicsMind and found to rely on appearance heuristics while often violating basic mechanics. These gaps indicate that current scaling and training are still insufficient for robust physical understanding, underscoring PhysicsMind as a focused testbed for physics-aware multimodal models. Our data will be released upon acceptance.

</details>


### [43] [Keyframe-Based Feed-Forward Visual Odometry](https://arxiv.org/abs/2601.16020)
*Weichen Dai,Wenhan Su,Da Kong,Yuhang Ming,Wanzeng Kong*

Main category: cs.CV

TL;DR: 本文针对视觉基础模型在视觉里程计中的关键帧选择问题，提出了一种基于强化学习的自适应关键帧策略，以提升计算效率和精度。


<details>
  <summary>Details</summary>
Motivation: 当前基于基础模型的VO方法通常无差别处理原始图像序列，导致计算冗余和性能下降，而传统几何启发式方法因依赖高维潜在表示而难以整合。因此需要一种与基础模型特性对齐的自适应关键帧选择方法。

Method: 提出基于强化学习的自适应关键帧策略，以数据驱动方式学习关键帧选择，替代手工规则。

Result: 在TartanAir数据集上训练，并在多个真实世界数据集评估，相比最先进的feed-forward VO方法取得了持续且显著的改进。

Conclusion: 该强化学习方法成功弥合了传统几何启发式与基于基础模型的VO之间的差距，实现了自适应关键帧选择，提升了计算效率和准确性。

Abstract: The emergence of visual foundation models has revolutionized visual odometry~(VO) and SLAM, enabling pose estimation and dense reconstruction within a single feed-forward network. However, unlike traditional pipelines that leverage keyframe methods to enhance efficiency and accuracy, current foundation model based methods, such as VGGT-Long, typically process raw image sequences indiscriminately. This leads to computational redundancy and degraded performance caused by low inter-frame parallax, which provides limited contextual stereo information. Integrating traditional geometric heuristics into these methods is non-trivial, as their performance depends on high-dimensional latent representations rather than explicit geometric metrics. To bridge this gap, we propose a novel keyframe-based feed-forward VO. Instead of relying on hand-crafted rules, our approach employs reinforcement learning to derive an adaptive keyframe policy in a data-driven manner, aligning selection with the intrinsic characteristics of the underlying foundation model. We train our agent on TartanAir dataset and conduct extensive evaluations across several real-world datasets. Experimental results demonstrate that the proposed method achieves consistent and substantial improvements over state-of-the-art feed-forward VO methods.

</details>


### [44] [PAINT: Pathology-Aware Integrated Next-Scale Transformation for Virtual Immunohistochemistry](https://arxiv.org/abs/2601.16024)
*Rongze Ma,Mengkang Lu,Zhenyu Xiang,Yongsheng Pan,Yicheng Wu,Qingjie Zeng,Yong Xia*

Main category: cs.CV

TL;DR: 提出了一种用于虚拟免疫组化的结构先验自回归框架PAINT，通过引入3S-Map将合成过程重构为结构优先的条件生成任务，显著提升了结构保真度和临床下游任务性能


<details>
  <summary>Details</summary>
Motivation: 传统虚拟IHC方法主要关注外观合成而忽略结构先验，导致语义不一致；H&E图像形态学提供蛋白表达的模糊线索，相似组织结构可能对应不同分子状态，需要更可靠的合成方法

Method: 提出了PAINT（Pathology-Aware Integrated Next-Scale Transformation）框架，将合成过程重新定义为结构优先的条件生成任务，引入空间结构起始图（3S-Map）作为自回归初始化的基础，确保确定性、空间对齐的合成

Result: 在IHC4BC和MIST数据集上的实验表明，PAINT在结构保真度和临床下游任务方面优于现有最先进方法

Conclusion: 结构引导的自回归建模在虚拟免疫组化中具有显著潜力，通过强制因果顺序并基于全局结构布局解析分子细节，能够实现更可靠的组织学图像分析

Abstract: Virtual immunohistochemistry (IHC) aims to computationally synthesize molecular staining patterns from routine Hematoxylin and Eosin (H\&E) images, offering a cost-effective and tissue-efficient alternative to traditional physical staining. However, this task is particularly challenging: H\&E morphology provides ambiguous cues about protein expression, and similar tissue structures may correspond to distinct molecular states. Most existing methods focus on direct appearance synthesis to implicitly achieve cross-modal generation, often resulting in semantic inconsistencies due to insufficient structural priors. In this paper, we propose Pathology-Aware Integrated Next-Scale Transformation (PAINT), a visual autoregressive framework that reformulates the synthesis process as a structure-first conditional generation task. Unlike direct image translation, PAINT enforces a causal order by resolving molecular details conditioned on a global structural layout. Central to this approach is the introduction of a Spatial Structural Start Map (3S-Map), which grounds the autoregressive initialization in observed morphology, ensuring deterministic, spatially aligned synthesis. Experiments on the IHC4BC and MIST datasets demonstrate that PAINT outperforms state-of-the-art methods in structural fidelity and clinical downstream tasks, validating the potential of structure-guided autoregressive modeling.

</details>


### [45] [ProGiDiff: Prompt-Guided Diffusion-Based Medical Image Segmentation](https://arxiv.org/abs/2601.16060)
*Yuan Lin,Murong Xu,Marc Hölle,Chinmay Prabhakar,Andreas Maier,Vasileios Belagiannis,Bjoern Menze,Suprosanna Shit*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Widely adopted medical image segmentation methods, although efficient, are primarily deterministic and remain poorly amenable to natural language prompts. Thus, they lack the capability to estimate multiple proposals, human interaction, and cross-modality adaptation. Recently, text-to-image diffusion models have shown potential to bridge the gap. However, training them from scratch requires a large dataset-a limitation for medical image segmentation. Furthermore, they are often limited to binary segmentation and cannot be conditioned on a natural language prompt. To this end, we propose a novel framework called ProGiDiff that leverages existing image generation models for medical image segmentation purposes. Specifically, we propose a ControlNet-style conditioning mechanism with a custom encoder, suitable for image conditioning, to steer a pre-trained diffusion model to output segmentation masks. It naturally extends to a multi-class setting simply by prompting the target organ. Our experiment on organ segmentation from CT images demonstrates strong performance compared to previous methods and could greatly benefit from an expert-in-the-loop setting to leverage multiple proposals. Importantly, we demonstrate that the learned conditioning mechanism can be easily transferred through low-rank, few-shot adaptation to segment MR images.

</details>


### [46] [DTP: A Simple yet Effective Distracting Token Pruning Framework for Vision-Language Action Models](https://arxiv.org/abs/2601.16065)
*Chenyang Li,Jieyuan Liu,Bin Li,Bo Gao,Yilin Yuan,Yangfan He,Yuchen Li,Jingqun Tang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Vision-Language Action (VLA) models have shown remarkable progress in robotic manipulation by leveraging the powerful perception abilities of Vision-Language Models (VLMs) to understand environments and directly output actions. However, by default, VLA models may overly attend to image tokens in the task-irrelevant region, which we describe as 'distracting tokens'. This behavior can disturb the model from the generation of the desired action tokens in each step, affecting the success rate of tasks. In this paper, we introduce a simple yet effective plug-and-play Distracting Token Pruning (DTP) framework, which dynamically detects and prunes these distracting image tokens. By correcting the model's visual attention patterns, we aim to improve the task success rate, as well as exploring the performance upper boundaries of the model without altering its original architecture or adding additional inputs. Experiments on the SIMPLER Benchmark (Li et al., 2024) show that our method consistently achieving relative improvements in task success rates across different types of novel VLA models, demonstrating generalizability to transformer-based VLAs. Further analysis reveals a negative correlation between the task success rate and the amount of attentions in the task-irrelevant region for all models tested, highlighting a common phenomenon of VLA models that could guide future research. We also publish our code at: https://anonymous.4open.science/r/CBD3.

</details>


### [47] [DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models](https://arxiv.org/abs/2601.16073)
*Hanwen Zhang,Qiaojin Shen,Yuxi Liu,Yuesheng Zhu,Guibo Luo*

Main category: cs.CV

TL;DR: DSFedMed: 一种双尺度联邦框架，通过中心化基础模型与轻量级客户端模型的相互知识蒸馏来解决医学图像分割中的计算与通信开销问题。


<details>
  <summary>Details</summary>
Motivation: 基础模型在视觉任务中泛化能力强，但在联邦环境下部署困难，面临高计算需求、通信开销大和推理成本高的问题，需要高效、低成本的解决方案。

Method: 提出了双尺度联邦框架 DSFedMed，通过生成高质量医学图像数据集替代真实公共数据，采用可学习性引导的样本选择策略优化双尺度蒸馏，实现基础模型与轻量客户端的相互知识蒸馏。

Result: 在五个医学图像分割数据集上评估，DSFedMed 的平均 Dice 分数提升2%，同时通信成本和推理时间比现有联邦基础模型基线降低近90%。

Conclusion: DSFedMed 显著提升了联邦部署的效率和可扩展性，为资源受限的医疗图像分割任务提供了高效的解决方案。

Abstract: Foundation Models (FMs) have demonstrated strong generalization across diverse vision tasks. However, their deployment in federated settings is hindered by high computational demands, substantial communication overhead, and significant inference costs. We propose DSFedMed, a dual-scale federated framework that enables mutual knowledge distillation between a centralized foundation model and lightweight client models for medical image segmentation. To support knowledge distillation, a set of high-quality medical images is generated to replace real public datasets, and a learnability-guided sample selection strategy is proposed to enhance efficiency and effectiveness in dual-scale distillation. This mutual distillation enables the foundation model to transfer general knowledge to lightweight clients, while also incorporating client-specific insights to refine the foundation model. Evaluations on five medical imaging segmentation datasets show that DSFedMed achieves an average 2 percent improvement in Dice score while reducing communication costs and inference time by nearly 90 percent compared to existing federated foundation model baselines. These results demonstrate significant efficiency gains and scalability for resource-limited federated deployments.

</details>


### [48] [Masked Modeling for Human Motion Recovery Under Occlusions](https://arxiv.org/abs/2601.16079)
*Zhiyin Qian,Siwei Zhang,Bharat Lal Bhatnagar,Federica Bogo,Siyu Tang*

Main category: cs.CV

TL;DR: MoRo提出了一种基于掩码建模的端到端生成框架，用于从单目RGB视频中恢复被遮挡的人体运动，实现了高效实时推理并显著提升了遮挡情况下的运动重建精度和真实性。


<details>
  <summary>Details</summary>
Motivation: 单目视频人体运动重建在AR/VR、机器人和数字内容创作中有广泛应用，但在实际场景中频繁出现的遮挡问题仍具挑战性。现有回归方法效率高但对缺失观测脆弱，优化和扩散方法虽更鲁棒但推理速度慢、预处理复杂。

Method: MoRo采用基于掩码建模的生成框架，将运动重建表述为视频条件任务，通过学习三种异质数据集的跨模态先验：(i)从MoCap数据集训练轨迹感知运动先验，(ii)从图像-姿态数据集训练图像条件姿态先验，(iii)视频条件掩码变换器融合运动和姿态先验，并在视频-运动数据集上微调以整合视觉线索和运动动态。

Result: 在EgoBody和RICH数据集上的大量实验表明，MoRo在遮挡情况下显著超越现有方法，在精度和运动真实性上有显著提升，在非遮挡场景中表现相当，且在单块H200 GPU上实现70FPS的实时推理。

Conclusion: MoRo通过掩码建模和跨模态学习方案，有效解决了遮挡下的人体运动重建问题，在保持高效率的同时大幅提升了鲁棒性和重建质量，为实现实时、鲁棒的单目视频运动重建提供了有效解决方案。

Abstract: Human motion reconstruction from monocular videos is a fundamental challenge in computer vision, with broad applications in AR/VR, robotics, and digital content creation, but remains challenging under frequent occlusions in real-world settings.Existing regression-based methods are efficient but fragile to missing observations, while optimization- and diffusion-based approaches improve robustness at the cost of slow inference speed and heavy preprocessing steps. To address these limitations, we leverage recent advances in generative masked modeling and present MoRo: Masked Modeling for human motion Recovery under Occlusions. MoRo is an occlusion-robust, end-to-end generative framework that formulates motion reconstruction as a video-conditioned task, and efficiently recover human motion in a consistent global coordinate system from RGB videos. By masked modeling, MoRo naturally handles occlusions while enabling efficient, end-to-end inference. To overcome the scarcity of paired video-motion data, we design a cross-modality learning scheme that learns multi-modal priors from a set of heterogeneous datasets: (i) a trajectory-aware motion prior trained on MoCap datasets, (ii) an image-conditioned pose prior trained on image-pose datasets, capturing diverse per-frame poses, and (iii) a video-conditioned masked transformer that fuses motion and pose priors, finetuned on video-motion datasets to integrate visual cues with motion dynamics for robust inference. Extensive experiments on EgoBody and RICH demonstrate that MoRo substantially outperforms state-of-the-art methods in accuracy and motion realism under occlusions, while performing on-par in non-occluded scenarios. MoRo achieves real-time inference at 70 FPS on a single H200 GPU.

</details>


### [49] [SAMTok: Representing Any Mask with Two Words](https://arxiv.org/abs/2601.16093)
*Yikang Zhou,Tao Zhang,Dengxian Gong,Yuanzheng Wu,Ye Tian,Haochen Wang,Haobo Yuan,Jiacong Wang,Lu Qi,Hao Fei,Anran Wang,Zhuochen Wang,Yujing Wang,Cheng Chen,Shunping Ji,Xiangtai Li*

Main category: cs.CV

TL;DR: SAMTok是一种离散掩码分词器，可将任意区域掩码转换为特殊标记，使基础多模态大语言模型通过标准的下一个标记预测和简单强化学习掌握像素级能力，无需修改架构或专用损失设计


<details>
  <summary>Details</summary>
Motivation: 像素级能力对构建交互式智能系统至关重要，但现有像素级多模态大语言模型面临区域级编码器复杂、分割解码器专用、训练目标不兼容等可扩展性挑战

Method: 基于SAM2在2.09亿多样化掩码上训练掩码编码器和残差向量量化器，将掩码转换为紧凑的数字离散标记；使用500万SAMTok格式数据样本，通过标准下一个标记预测和带有文本答案匹配奖励的强化学习训练模型

Result: QwenVL-SAMTok在区域描述、区域视觉问答、接地对话、指称分割、场景图解析和多轮交互分割等任务上达到最先进或可比性能；强化学习方法在GRES和GCG基准上取得显著提升

Conclusion: SAMTok为多模态大语言模型提供了一种可扩展且简单的范式来获取强大的像素级能力，证明掩码可作为语言标记处理，实现无需架构修改的像素级学习

Abstract: Pixel-wise capabilities are essential for building interactive intelligent systems. However, pixel-wise multi-modal LLMs (MLLMs) remain difficult to scale due to complex region-level encoders, specialized segmentation decoders, and incompatible training objectives. To address these challenges, we present SAMTok, a discrete mask tokenizer that converts any region mask into two special tokens and reconstructs the mask using these tokens with high fidelity. By treating masks as new language tokens, SAMTok enables base MLLMs (such as the QwenVL series) to learn pixel-wise capabilities through standard next-token prediction and simple reinforcement learning, without architectural modifications and specialized loss design. SAMTok builds on SAM2 and is trained on 209M diverse masks using a mask encoder and residual vector quantizer to produce discrete, compact, and information-rich tokens. With 5M SAMTok-formatted mask understanding and generation data samples, QwenVL-SAMTok attains state-of-the-art or comparable results on region captioning, region VQA, grounded conversation, referring segmentation, scene graph parsing, and multi-round interactive segmentation. We further introduce a textual answer-matching reward that enables efficient reinforcement learning for mask generation, delivering substantial improvements on GRES and GCG benchmarks. Our results demonstrate a scalable and straightforward paradigm for equipping MLLMs with strong pixel-wise capabilities. Our code and models are available.

</details>


### [50] [Rethinking Composed Image Retrieval Evaluation: A Fine-Grained Benchmark from Image Editing](https://arxiv.org/abs/2601.16125)
*Tingyu Song,Yanzhao Zhang,Mingxin Li,Zhuoning Guo,Dingkun Long,Pengjun Xie,Siyue Zhang,Yilun Zhao,Shu Wu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Composed Image Retrieval (CIR) is a pivotal and complex task in multimodal understanding. Current CIR benchmarks typically feature limited query categories and fail to capture the diverse requirements of real-world scenarios. To bridge this evaluation gap, we leverage image editing to achieve precise control over modification types and content, enabling a pipeline for synthesizing queries across a broad spectrum of categories. Using this pipeline, we construct EDIR, a novel fine-grained CIR benchmark. EDIR encompasses 5,000 high-quality queries structured across five main categories and fifteen subcategories. Our comprehensive evaluation of 13 multimodal embedding models reveals a significant capability gap; even state-of-the-art models (e.g., RzenEmbed and GME) struggle to perform consistently across all subcategories, highlighting the rigorous nature of our benchmark. Through comparative analysis, we further uncover inherent limitations in existing benchmarks, such as modality biases and insufficient categorical coverage. Furthermore, an in-domain training experiment demonstrates the feasibility of our benchmark. This experiment clarifies the task challenges by distinguishing between categories that are solvable with targeted data and those that expose intrinsic limitations of current model architectures.

</details>


### [51] [Learning to Watermark in the Latent Space of Generative Models](https://arxiv.org/abs/2601.16140)
*Sylvestre-Alvise Rebuffi,Tuan Tran,Valeriu Lacatusu,Pierre Fernandez,Tomáš Souček,Nikola Jovanović,Tom Sander,Hady Elsahar,Alexandre Mourachko*

Main category: cs.CV

TL;DR: 提出DistSeal，一种在潜空间对AI生成图像进行水印的通用方法，通过训练潜空间水印模型，可将其蒸馏到生成模型或潜解码器中，实现20倍加速并保持竞争优势


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像水印方法多为像素空间的后处理方案，存在计算开销大和视觉伪影问题。为解决这些问题，研究探索潜空间水印技术

Method: 在生成模型的潜空间中训练后处理水印器，然后将这些潜水印器蒸馏到生成模型本身或潜解码器中，实现模型内水印

Result: 潜水印达到竞争性的鲁棒性，同时提供相似的不可感知性和高达20倍的加速。蒸馏潜水印器优于蒸馏像素空间水印器，提供更高效更鲁棒的解决方案

Conclusion: DistSeal展示了潜空间水印相对于像素空间方法的显著优势，为AI生成图像的版权保护提供了更高效、鲁棒的标准化方案

Abstract: Existing approaches for watermarking AI-generated images often rely on post-hoc methods applied in pixel space, introducing computational overhead and potential visual artifacts. In this work, we explore latent space watermarking and introduce DistSeal, a unified approach for latent watermarking that works across both diffusion and autoregressive models. Our approach works by training post-hoc watermarking models in the latent space of generative models. We demonstrate that these latent watermarkers can be effectively distilled either into the generative model itself or into the latent decoder, enabling in-model watermarking. The resulting latent watermarks achieve competitive robustness while offering similar imperceptibility and up to 20x speedup compared to pixel-space baselines. Our experiments further reveal that distilling latent watermarkers outperforms distilling pixel-space ones, providing a solution that is both more efficient and more robust.

</details>


### [52] [ActionMesh: Animated 3D Mesh Generation with Temporal 3D Diffusion](https://arxiv.org/abs/2601.16148)
*Remy Sabathier,David Novotny,Niloy J. Mitra,Tom Monnier*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Generating animated 3D objects is at the heart of many applications, yet most advanced works are typically difficult to apply in practice because of their limited setup, their long runtime, or their limited quality. We introduce ActionMesh, a generative model that predicts production-ready 3D meshes "in action" in a feed-forward manner. Drawing inspiration from early video models, our key insight is to modify existing 3D diffusion models to include a temporal axis, resulting in a framework we dubbed "temporal 3D diffusion". Specifically, we first adapt the 3D diffusion stage to generate a sequence of synchronized latents representing time-varying and independent 3D shapes. Second, we design a temporal 3D autoencoder that translates a sequence of independent shapes into the corresponding deformations of a pre-defined reference shape, allowing us to build an animation. Combining these two components, ActionMesh generates animated 3D meshes from different inputs like a monocular video, a text description, or even a 3D mesh with a text prompt describing its animation. Besides, compared to previous approaches, our method is fast and produces results that are rig-free and topology consistent, hence enabling rapid iteration and seamless applications like texturing and retargeting. We evaluate our model on standard video-to-4D benchmarks (Consistent4D, Objaverse) and report state-of-the-art performances on both geometric accuracy and temporal consistency, demonstrating that our model can deliver animated 3D meshes with unprecedented speed and quality.

</details>


### [53] [360Anything: Geometry-Free Lifting of Images and Videos to 360°](https://arxiv.org/abs/2601.16192)
*Ziyi Wu,Daniel Watson,Andrea Tagliasacchi,David J. Fleet,Marcus A. Brubaker,Saurabh Saxena*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Lifting perspective images and videos to 360° panoramas enables immersive 3D world generation. Existing approaches often rely on explicit geometric alignment between the perspective and the equirectangular projection (ERP) space. Yet, this requires known camera metadata, obscuring the application to in-the-wild data where such calibration is typically absent or noisy. We propose 360Anything, a geometry-free framework built upon pre-trained diffusion transformers. By treating the perspective input and the panorama target simply as token sequences, 360Anything learns the perspective-to-equirectangular mapping in a purely data-driven way, eliminating the need for camera information. Our approach achieves state-of-the-art performance on both image and video perspective-to-360° generation, outperforming prior works that use ground-truth camera information. We also trace the root cause of the seam artifacts at ERP boundaries to zero-padding in the VAE encoder, and introduce Circular Latent Encoding to facilitate seamless generation. Finally, we show competitive results in zero-shot camera FoV and orientation estimation benchmarks, demonstrating 360Anything's deep geometric understanding and broader utility in computer vision tasks. Additional results are available at https://360anything.github.io/.

</details>


### [54] [Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders](https://arxiv.org/abs/2601.16208)
*Shengbang Tong,Boyang Zheng,Ziteng Wang,Bingda Tang,Nanye Ma,Ellis Brown,Jihan Yang,Rob Fergus,Yann LeCun,Saining Xie*

Main category: cs.CV

TL;DR: 研究表明，表征自编码器（RAE）通过在语义潜空间中进行训练，在大规模自由文本到图像生成中优于传统VAE方法，简化框架后实现更快的收敛和更好的生成质量。


<details>
  <summary>Details</summary>
Motivation: 探索表征自编码器(RAE)框架能否从ImageNet扩展到大规模自由文本到图像生成，并验证其在通用T2I任务中的优越性。

Method: 首先在冻结的表示编码器上扩展RAE解码器训练（使用网页、合成和文本渲染数据）；然后系统评估RAE设计选择；最后与最先进的FLUX VAE进行受控比较（从0.5B到9.8B参数）。

Result: RAE在所有模型尺度上都优于VAE，在预训练中表现更好，在高质量数据微调时保持稳定（256个epochs不崩溃），而VAE在64个epochs后灾难性过拟合。RAE模型收敛更快且生成质量更优。

Conclusion: RAE是比VAE更简单和更强的大规模T2I生成基础，同时在共享表示空间中支持视觉理解和生成，为统一模型开辟了新可能性。

Abstract: Representation Autoencoders (RAEs) have shown distinct advantages in diffusion modeling on ImageNet by training in high-dimensional semantic latent spaces. In this work, we investigate whether this framework can scale to large-scale, freeform text-to-image (T2I) generation. We first scale RAE decoders on the frozen representation encoder (SigLIP-2) beyond ImageNet by training on web, synthetic, and text-rendering data, finding that while scale improves general fidelity, targeted data composition is essential for specific domains like text. We then rigorously stress-test the RAE design choices originally proposed for ImageNet. Our analysis reveals that scaling simplifies the framework: while dimension-dependent noise scheduling remains critical, architectural complexities such as wide diffusion heads and noise-augmented decoding offer negligible benefits at scale Building on this simplified framework, we conduct a controlled comparison of RAE against the state-of-the-art FLUX VAE across diffusion transformer scales from 0.5B to 9.8B parameters. RAEs consistently outperform VAEs during pretraining across all model scales. Further, during finetuning on high-quality datasets, VAE-based models catastrophically overfit after 64 epochs, while RAE models remain stable through 256 epochs and achieve consistently better performance. Across all experiments, RAE-based diffusion models demonstrate faster convergence and better generation quality, establishing RAEs as a simpler and stronger foundation than VAEs for large-scale T2I generation. Additionally, because both visual understanding and generation can operate in a shared representation space, the multimodal model can directly reason over generated latents, opening new possibilities for unified models.

</details>


### [55] [PyraTok: Language-Aligned Pyramidal Tokenizer for Video Understanding and Generation](https://arxiv.org/abs/2601.16210)
*Onkar Susladkar,Tushar Prakash,Adheesh Juvekar,Kiet A. Nguyen,Dong-Hwan Jang,Inderjit S Dhillon,Ismini Lourentzou*

Main category: cs.CV

TL;DR: PyraTok：一种语言对齐的金字塔式令牌化器，通过多尺度文本引导量化和层级令牌自回归优化，显著提升了视频重建质量、文本到视频生成效果及零样本视频任务性能


<details>
  <summary>Details</summary>
Motivation: 现有离散视频VAE令牌化器通常局限于单一尺度、有限词汇表和浅层语言监督，导致跨模态对齐不佳和零样本迁移能力弱。需要一种能够学习跨多时空分辨率语义结构离散潜在表达的方法

Method: 在预训练视频VAE基础上，结合语言对齐金字塔量化(LaPQ)模块，使用共享大型二进制码本在不同深度离散化编码器特征，生成紧凑而富有表现力的视频令牌序列。通过联合优化多尺度文本引导量化和令牌层次结构的全局自回归目标，紧密耦合视觉令牌与语言

Result: 在十个基准测试中达到SOTA视频重建质量，显著提升文本到视频生成效果，在视频分割、时序动作定位和视频理解等任务上创造了新的SOTA零样本性能，并能鲁棒地扩展到4K/8K分辨率

Conclusion: PyraTok通过金字塔式多分辨率令牌化和深度语言对齐，克服了现有视频令牌化器的局限性，为视频生成和理解提供了更强大、可扩展的离散表示基础

Abstract: Discrete video VAEs underpin modern text-to-video generation and video understanding systems, yet existing tokenizers typically learn visual codebooks at a single scale with limited vocabularies and shallow language supervision, leading to poor cross-modal alignment and zero-shot transfer. We introduce PyraTok, a language-aligned pyramidal tokenizer that learns semantically structured discrete latents across multiple spatiotemporal resolutions. PyraTok builds on a pretrained video VAE and a novel Language aligned Pyramidal Quantization (LaPQ) module that discretizes encoder features at several depths using a shared large binary codebook, yielding compact yet expressive video token sequences. To tightly couple visual tokens with language, PyraTok jointly optimizes multi-scale text-guided quantization and a global autoregressive objective over the token hierarchy. Across ten benchmarks, PyraTok delivers state-of-the-art (SOTA) video reconstruction, consistently improves text-to-video quality, and sets new SOTA zero-shot performance on video segmentation, temporal action localization, and video understanding, scaling robustly to up to 4K/8K resolutions.

</details>


### [56] [Why Can't I Open My Drawer? Mitigating Object-Driven Shortcuts in Zero-Shot Compositional Action Recognition](https://arxiv.org/abs/2601.16211)
*Geo Ahn,Inwoong Lee,Taeoh Kim,Minho Shim,Dongyoon Wee,Jinwoo Choi*

Main category: cs.CV

TL;DR: 发现现有零样本组合动作识别（ZS-CAR）模型主要因'物体驱动的动词捷径'而失败，提出RCORE框架通过组合感知增强和时间顺序正则化改进未见组合的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有组合视频理解（CVU）模型在零样本组合动作识别任务中表现不佳，研究发现主要原因是'物体驱动的动词捷径'问题，即模型忽略视觉证据而过度拟合共现统计。

Method: 提出RCORE框架：1）组合感知增强—多样化动-物组合而不破坏运动线索；2）时间顺序正则化损失—通过显式建模时间结构惩罚捷径行为。

Result: 在两个基准数据集（Sth-com和新建的EK100-com）上，RCORE显著提高了未见组合的准确率，降低了对共现偏置的依赖，并实现了持续正面的组合差距。

Conclusion: 物体驱动的捷径是ZS-CAR的关键限制因素，解决这一问题对于实现鲁棒的组合视频理解至关重要，RCORE为此提供了简单有效的解决方案。

Abstract: We study Compositional Video Understanding (CVU), where models must recognize verbs and objects and compose them to generalize to unseen combinations. We find that existing Zero-Shot Compositional Action Recognition (ZS-CAR) models fail primarily due to an overlooked failure mode: object-driven verb shortcuts. Through systematic analysis, we show that this behavior arises from two intertwined factors: severe sparsity and skewness of compositional supervision, and the asymmetric learning difficulty between verbs and objects. As training progresses, the existing ZS-CAR model increasingly ignores visual evidence and overfits to co-occurrence statistics. Consequently, the existing model does not gain the benefit of compositional recognition in unseen verb-object compositions. To address this, we propose RCORE, a simple and effective framework that enforces temporally grounded verb learning. RCORE introduces (i) a composition-aware augmentation that diversifies verb-object combinations without corrupting motion cues, and (ii) a temporal order regularization loss that penalizes shortcut behaviors by explicitly modeling temporal structure. Across two benchmarks, Sth-com and our newly constructed EK100-com, RCORE significantly improves unseen composition accuracy, reduces reliance on co-occurrence bias, and achieves consistently positive compositional gaps. Our findings reveal object-driven shortcuts as a critical limiting factor in ZS-CAR and demonstrate that addressing them is essential for robust compositional video understanding.

</details>


### [57] [CamPilot: Improving Camera Control in Video Diffusion Model with Efficient Camera Reward Feedback](https://arxiv.org/abs/2601.16214)
*Wenhang Ge,Guibao Shen,Jiawei Feng,Luozhou Wang,Hao Lu,Xingye Tian,Xin Tao,Ying-Cong Chen*

Main category: cs.CV

TL;DR: 论文提出了一种高效的相机感知3D解码器来改善视频扩散模型的相机可控性，通过将视频潜变量解码为3D高斯表示进行奖励量化，优化渲染视图与真实视图的像素一致性作为奖励信号。


<details>
  <summary>Details</summary>
Motivation: 当前相机控制的视频扩散模型虽然提升了视频-相机对齐能力，但相机可控性仍有限。现有ReFL方法面临三个主要挑战：1) 奖励模型缺乏评估视频-相机对齐的能力；2) RGB视频解码带来巨大计算开销；3) 视频解码过程中常忽略3D几何信息。

Method: 提出相机感知3D解码器，将视频潜变量与相机位姿解码为3D高斯表示。相机位姿同时作为输入和投影参数，视频潜变量与相机位姿不对齐会导致3D结构几何失真。方法通过优化新视图渲染与真实视图的像素一致性作为奖励，并引入可见性项选择性监督几何扭曲得到的确定性区域。

Result: 在RealEstate10K和WorldScore基准测试上的大量实验证明了方法的有效性。

Conclusion: 该研究通过引入高效的3D解码机制和像素一致性奖励优化，显著提升了视频扩散模型的相机控制能力，为解决现有ReFL方法的局限性提供了创新解决方案。

Abstract: Recent advances in camera-controlled video diffusion models have significantly improved video-camera alignment. However, the camera controllability still remains limited. In this work, we build upon Reward Feedback Learning and aim to further improve camera controllability. However, directly borrowing existing ReFL approaches faces several challenges. First, current reward models lack the capacity to assess video-camera alignment. Second, decoding latent into RGB videos for reward computation introduces substantial computational overhead. Third, 3D geometric information is typically neglected during video decoding. To address these limitations, we introduce an efficient camera-aware 3D decoder that decodes video latent into 3D representations for reward quantization. Specifically, video latent along with the camera pose are decoded into 3D Gaussians. In this process, the camera pose not only acts as input, but also serves as a projection parameter. Misalignment between the video latent and camera pose will cause geometric distortions in the 3D structure, resulting in blurry renderings. Based on this property, we explicitly optimize pixel-level consistency between the rendered novel views and ground-truth ones as reward. To accommodate the stochastic nature, we further introduce a visibility term that selectively supervises only deterministic regions derived via geometric warping. Extensive experiments conducted on RealEstate10K and WorldScore benchmarks demonstrate the effectiveness of our proposed method. Project page: \href{https://a-bigbao.github.io/CamPilot/}{CamPilot Page}.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [58] [Entropy-Tree: Tree-Based Decoding with Entropy-Guided Exploration](https://arxiv.org/abs/2601.15296)
*Longxuan Wei,Yubo Zhang,Zijiao Zhang,Zhihu Wang,Shiwan Zhao,Tianyu Huang,Huiting Zhao,Chenfei Liu,Shenao Zhang,Junchi Yan*

Main category: cs.CL

TL;DR: Entropy-Tree是一种基于树的解码方法，利用熵作为分支决策信号，仅在不确定性高的位置扩展搜索树，在推理任务中展现优异性能


<details>
  <summary>Details</summary>
Motivation: 现有解码策略要么盲目探索（随机采样），要么重复探索（独立多重采样），缺乏有效利用模型不确定性的结构化探索方法

Method: 提出Entropy-Tree方法，将熵作为分支决策信号，根据模型在特定位置的不确定性程度决定是否扩展搜索树，统一了结构化探索和不确定性估计

Result: 在推理任务中表现优于Multi-chain方法（pass@k更高），不确定性估计指标AUROC优于多种传统度量，展现出更好的准确性和校准性

Conclusion: Entropy-Tree在单个解码过程中统一了高效结构化探索和可靠不确定性估计，为大型语言模型的推理解码提供了新思路

Abstract: Large language models achieve strong reasoning performance, yet existing decoding strategies either explore blindly (random sampling) or redundantly (independent multi-sampling). We propose Entropy-Tree, a tree-based decoding method that exploits entropy as a signal for branching decisions--expanding the search tree only at positions where the model exhibits genuine uncertainty. Entropy-Tree shows superior accuracy and calibration in reasoning tasks: it achieves better pass@k than Multi-chain across multiple models and datasets, and its predictive entropy demonstrates better AUROC compared to several traditional metrics. Entropy-Tree unifies efficient structured exploration and reliable uncertainty estimation within a single decoding procedure.

</details>


### [59] [AfriEconQA: A Benchmark Dataset for African Economic Analysis based on World Bank Reports](https://arxiv.org/abs/2601.15297)
*Edward Ajayi*

Main category: cs.CL

TL;DR: AfriEconQA是首个专注于非洲经济分析的基准数据集，基于236份世界银行报告构建，包含8,937个精心筛选的问答实例，要求对经济指标进行数值推理和时间消歧。


<details>
  <summary>Details</summary>
Motivation: 针对当前大语言模型在非洲经济分析领域存在的显著知识空白，特别是缺乏专门的基准数据集来评估复杂经济查询的检索和问答能力。

Method: 基于世界银行报告构建包含8,937个问答实例的数据集，通过11个实验矩阵，在零样本基线（GPT-5 Mini）和多种RAG配置（使用GPT-4o和Qwen 32B）以及五种嵌入和排名策略上进行基准测试。

Result: 研究表明存在严重的参数知识差距：零样本模型无法回答超过90%的查询，即使是最先进的RAG流水线也难以达到高精度。

Conclusion: AfriEconQA是一个稳健且具有挑战性的基准，可用于评估下一代领域特定信息检索和检索增强生成系统，特别是针对非洲经济分析任务。

Abstract: We introduce AfriEconQA, a specialized benchmark dataset for African economic analysis grounded in a comprehensive corpus of 236 World Bank reports. The task of AfriEconQA is to answer complex economic queries that require high-precision numerical reasoning and temporal disambiguation from specialized institutional documents. The dataset consists of 8,937 curated QA instances, rigorously filtered from a pool of 10018 synthetic questions to ensure high-quality evidence-answer alignment. Each instance is composed of: (1) a question requiring reasoning over economic indicators, (2) the corresponding evidence retrieved from the corpus, (3) a verified ground-truth answer, and (4) source metadata (e.g., URL and publication date) to ensure temporal provenance. AfriEconQA is the first benchmark focused specifically on African economic analysis, providing a unique challenge for Information Retrieval (IR) systems, as the data is largely absent from the pretraining corpora of current Large Language Models (LLMs). We operationalize this dataset through an 11-experiment matrix, benchmarking a zero-shot baseline (GPT-5 Mini) against RAG configurations using GPT-4o and Qwen 32B across five distinct embedding and ranking strategies. Our results demonstrate a severe parametric knowledge gap, where zero-shot models fail to answer over 90 percent of queries, and even state-of-the-art RAG pipelines struggle to achieve high precision. This confirms AfriEconQA as a robust and challenging benchmark for the next generation of domain-specific IR and RAG systems. The AfriEconQA dataset and code will be made publicly available upon publication.

</details>


### [60] [Embedding Retrofitting: Data Engineering for better RAG](https://arxiv.org/abs/2601.15298)
*Anantha Sharma*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Embedding retrofitting adjusts pre-trained word vectors using knowledge graph constraints to improve domain-specific retrieval. However, the effectiveness of retrofitting depends critically on knowledge graph quality, which in turn depends on text preprocessing. This paper presents a data engineering framework that addresses data quality degradation from annotation artifacts in real-world corpora.
  The analysis shows that hashtag annotations inflate knowledge graph density, leading to creating spurious edges that corrupt the retrofitting objective. On noisy graphs, all retrofitting techniques produce statistically significant degradation ($-3.5\%$ to $-5.2\%$, $p<0.05$). After preprocessing, \acrshort{ewma} retrofitting achieves $+6.2\%$ improvement ($p=0.0348$) with benefits concentrated in quantitative synthesis questions ($+33.8\%$ average). The gap between clean and noisy preprocessing (10\%+ swing) exceeds the gap between algorithms (3\%), establishing preprocessing quality as the primary determinant of retrofitting success.

</details>


### [61] [MALTopic: Multi-Agent LLM Topic Modeling Framework](https://arxiv.org/abs/2601.15299)
*Yash Sharma*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Topic modeling is a crucial technique for extracting latent themes from unstructured text data, particularly valuable in analyzing survey responses. However, traditional methods often only consider free-text responses and do not natively incorporate structured or categorical survey responses for topic modeling. And they produce abstract topics, requiring extensive human interpretation. To address these limitations, we propose the Multi-Agent LLM Topic Modeling Framework (MALTopic). This framework decomposes topic modeling into specialized tasks executed by individual LLM agents: an enrichment agent leverages structured data to enhance textual responses, a topic modeling agent extracts latent themes, and a deduplication agent refines the results. Comparative analysis on a survey dataset demonstrates that MALTopic significantly improves topic coherence, diversity, and interpretability compared to LDA and BERTopic. By integrating structured data and employing a multi-agent approach, MALTopic generates human-readable topics with enhanced contextual relevance, offering a more effective solution for analyzing complex survey data.

</details>


### [62] [Intelligence Degradation in Long-Context LLMs: Critical Threshold Determination via Natural Length Distribution Analysis](https://arxiv.org/abs/2601.15300)
*Weiwei Wang,Jiyong Min,Weijie Zou*

Main category: cs.CL

TL;DR: 该研究首次系统性地描绘了开源Qwen模型中智能退化的特征，发现当上下文长度接近特定临界阈值时，LLMs会出现灾难性的性能下降，即使信息仍然相关。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理接近某些临界阈值的上下文时表现会急剧下降，这严重限制了长上下文应用。需要探究这种智能退化现象的模式和原因，为实际应用提供指导。

Method: 采用自然长度分布分析（使用样本原始token长度）、临界阈值确定（在混合数据集上进行实验）、以及统一的理论框架来系统研究智能退化现象。

Result: 在Qwen2.5-7B模型中确定了40-50%最大上下文长度为临界阈值，F1分数从0.55-0.56骤降至0.3（45.5%退化）。模型在短到中等上下文表现良好，但有明确的崩塌点。

Conclusion: LLMs表现出浅层长上下文适应特性，在临界阈值后性能崩溃。研究成果为部署LLMs的长上下文应用提供了实用指导，并为缓解策略提供了基础框架。

Abstract: Large Language Models (LLMs) exhibit catastrophic performance degradation when processing contexts approaching certain critical thresholds, even when information remains relevant. This intelligence degradation-defined as over 30% drop in task performance-severely limits long-context applications. This degradation shows a common pattern: models maintain strong performance up to a critical threshold, then collapse catastrophically. We term this shallow long-context adaptation-models adapt for short to medium contexts but fail beyond critical thresholds. This paper presents three contributions: (1) Natural Length Distribution Analysis: We use each sample's natural token length without truncation or padding, providing stronger causal evidence that degradation results from context length itself. (2) Critical Threshold Determination: Through experiments on a mixed dataset (1,000 samples covering 5%-95% of context length), we identify the critical threshold for Qwen2.5-7B at 40-50% of maximum context length, where F1 scores drop from 0.55-0.56 to 0.3 (45.5% degradation), using five-method cross-validation. (3) Unified Framework: We consolidate shallow adaptation, explaining degradation patterns and providing a foundation for mitigation strategies. This work provides the first systematic characterization of intelligence degradation in open-source Qwen models, offering practical guidance for deploying LLMs in long-context scenarios.

</details>


### [63] [Can We Trust LLM Detectors?](https://arxiv.org/abs/2601.15301)
*Jivnesh Sandhan,Harshit Jaiswal,Fei Cheng,Yugo Murawaki*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rapid adoption of LLMs has increased the need for reliable AI text detection, yet existing detectors often fail outside controlled benchmarks. We systematically evaluate 2 dominant paradigms (training-free and supervised) and show that both are brittle under distribution shift, unseen generators, and simple stylistic perturbations. To address these limitations, we propose a supervised contrastive learning (SCL) framework that learns discriminative style embeddings. Experiments show that while supervised detectors excel in-domain, they degrade sharply out-of-domain, and training-free methods remain highly sensitive to proxy choice. Overall, our results expose fundamental challenges in building domain-agnostic detectors. Our code is available at: https://github.com/HARSHITJAIS14/DetectAI

</details>


### [64] [ICPO: Illocution-Calibrated Policy Optimization for Multi-Turn Conversation](https://arxiv.org/abs/2601.15330)
*Zhebo Wang,Xiaohu Mu,Zijie Zhou,Mohan Li,Wenpeng Xing,Dezhang Kong,Meng Han*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) in multi-turn conversations often suffer from a ``lost-in-conversation'' phenomenon, where they struggle to recover from early incorrect assumptions, particularly when users provide ambiguous initial instructions. We find that standard post-training techniques like Reinforcement Learning with Verifiable Rewards (RLVR) exacerbate this issue by rewarding confident, direct answers, thereby inducing overconfidence and discouraging the model from seeking clarification. To address this, we propose Illocution-Calibrated Policy Optimization (ICPO), a novel training framework that sensitizes the model to instruction ambiguity. ICPO augments the training corpus with underspecified prompts and conditions the reward signal on the user's illocutionary intent, rewarding the model for expressing uncertainty or asking for clarification when faced with ambiguity. Experiments demonstrate that ICPO fosters appropriate humility, yielding a substantial average improvement of 75\% in multi-turn conversation, while preserving robust performance on single-turn benchmarks. Our work presents a practical path toward more robust and collaborative conversational AI that can better navigate the nuances of human interaction.

</details>


### [65] [RECAP: A Resource-Efficient Method for Adversarial Prompting in Large Language Models](https://arxiv.org/abs/2601.15331)
*Rishit Chugh*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The deployment of large language models (LLMs) has raised security concerns due to their susceptibility to producing harmful or policy-violating outputs when exposed to adversarial prompts. While alignment and guardrails mitigate common misuse, they remain vulnerable to automated jailbreaking methods such as GCG, PEZ, and GBDA, which generate adversarial suffixes via training and gradient-based search. Although effective, these methods particularly GCG are computationally expensive, limiting their practicality for organisations with constrained resources. This paper introduces a resource-efficient adversarial prompting approach that eliminates the need for retraining by matching new prompts to a database of pre-trained adversarial prompts. A dataset of 1,000 prompts was classified into seven harm-related categories, and GCG, PEZ, and GBDA were evaluated on a Llama 3 8B model to identify the most effective attack method per category. Results reveal a correlation between prompt type and algorithm effectiveness. By retrieving semantically similar successful adversarial prompts, the proposed method achieves competitive attack success rates with significantly reduced computational cost. This work provides a practical framework for scalable red-teaming and security evaluation of aligned LLMs, including in settings where model internals are inaccessible.

</details>


### [66] [No Reliable Evidence of Self-Reported Sentience in Small Large Language Models](https://arxiv.org/abs/2601.15334)
*Caspar Kaiser,Sean Enderby*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Whether language models possess sentience has no empirical answer. But whether they believe themselves to be sentient can, in principle, be tested. We do so by querying several open-weights models about their own consciousness, and then verifying their responses using classifiers trained on internal activations. We draw upon three model families (Qwen, Llama, GPT-OSS) ranging from 0.6 billion to 70 billion parameters, approximately 50 questions about consciousness and subjective experience, and three classification methods from the interpretability literature. First, we find that models consistently deny being sentient: they attribute consciousness to humans but not to themselves. Second, classifiers trained to detect underlying beliefs - rather than mere outputs - provide no clear evidence that these denials are untruthful. Third, within the Qwen family, larger models deny sentience more confidently than smaller ones. These findings contrast with recent work suggesting that models harbour latent beliefs in their own consciousness.

</details>


### [67] [Memorization Dynamics in Knowledge Distillation for Language Models](https://arxiv.org/abs/2601.15394)
*Jaydeep Borkar,Karan Chadha,Niloofar Mireshghallah,Yuchen Zhang,Irina-Elena Veliche,Archi Mitra,David A. Smith,Zheng Xu,Diego Garcia-Olano*

Main category: cs.CL

TL;DR: KD显著减少记忆化（超50%），且记忆集中在少数易记样本；学生记忆可通过压缩熵等特征预测；硬蒸馏比软蒸馏继承更多教师特定样本（2.7倍）。


<details>
  <summary>Details</summary>
Motivation: 研究知识蒸馏中训练数据记忆化问题，填补当前对知识蒸馏机制下记忆化动态认知的空白，并探索蒸馏的隐私保护潜力。

Method: 使用三大LLM家族和三个数据集，分析蒸馏管道中记忆化现象，构建基于zlib熵、KL散度和困惑度等特征的预测模型，同时比较硬蒸馏和软蒸馏下记忆化差异。

Result: 蒸馏模型比标准微调减少超过50%的记忆化；少数易记样本贡献约95%记忆化；学生模型的记忆可通过特征预测；硬蒸馏比软蒸馏继承更多教师特定实例（2.7倍）。

Conclusion: 知识蒸馏既能提升泛化能力，又能降低记忆化风险，是一种兼具效率和隐私保护的替代方案。

Abstract: Knowledge Distillation (KD) is increasingly adopted to transfer capabilities from large language models to smaller ones, offering significant improvements in efficiency and utility while often surpassing standard fine-tuning. Beyond performance, KD is also explored as a privacy-preserving mechanism to mitigate the risk of training data leakage. While training data memorization has been extensively studied in standard pre-training and fine-tuning settings, its dynamics in a knowledge distillation setup remain poorly understood. In this work, we study memorization across the KD pipeline using three large language model (LLM) families (Pythia, OLMo-2, Qwen-3) and three datasets (FineWeb, Wikitext, Nemotron-CC-v2). We find: (1) distilled models memorize significantly less training data than standard fine-tuning (reducing memorization by more than 50%); (2) some examples are inherently easier to memorize and account for a large fraction of memorization during distillation (over ~95%); (3) student memorization is predictable prior to distillation using features based on zlib entropy, KL divergence, and perplexity; and (4) while soft and hard distillation have similar overall memorization rates, hard distillation poses a greater risk: it inherits $2.7\times$ more teacher-specific examples than soft distillation. Overall, we demonstrate that distillation can provide both improved generalization and reduced memorization risks compared to standard fine-tuning.

</details>


### [68] [Beyond Fixed Psychological Personas: State Beats Trait, but Language Models are State-Blind](https://arxiv.org/abs/2601.15395)
*Tamunotonye Harry,Ivoline Ngong,Chima Nweke,Yuanyuan Feng,Joseph Near*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: User interactions with language models vary due to static properties of the user (trait) and the specific context of the interaction (state). However, existing persona datasets (like PersonaChat, PANDORA etc.) capture only trait, and ignore the impact of state. We introduce Chameleon, a dataset of 5,001 contextual psychological profiles from 1,667 Reddit users, each measured across multiple contexts. Using the Chameleon dataset, we present three key findings. First, inspired by Latent State-Trait theory, we decompose variance and find that 74\% is within-person(state) while only 26\% is between-person (trait). Second, we find that LLMs are state-blind: they focus on trait only, and produce similar responses regardless of state. Third, we find that reward models react to user state, but inconsistently: different models favor or penalize the same users in opposite directions. We release Chameleon to support research on affective computing, personalized dialogue, and RLHF alignment.

</details>


### [69] [Domain-Specific Knowledge Graphs in RAG-Enhanced Healthcare LLMs](https://arxiv.org/abs/2601.15429)
*Sydney Anuyah,Mehedi Mahmud Kaushik,Hao Dai,Rakesh Shiradkar,Arjan Durresi,Sunandan Chakraborty*

Main category: cs.CL

TL;DR: 研究通过构建三种PubMed知识图谱来评估知识图谱是否能增强RAG在医疗领域的可靠性，发现图谱与问题范围的精准匹配对效果起决定性作用；盲目合并图谱会引入噪声，降低准确性


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型虽然在生成流畅回答方面表现出色，但在需要专业领域可信推理的医疗健康领域仍存在不足。本研究旨在探索领域知识图谱能否提升检索增强生成在医疗应用中的可靠性

Method: 研究构建了三种基于PubMed的知识图谱：G1（2型糖尿病）、G2（阿尔茨海默病）和G3（AD+T2DM联合疾病）。设计了两种测试探针：Probe1针对合并的AD+T2DM知识，Probe2针对G1和G2的交集知识。测试了7种指令调优的大语言模型，在不同检索源配置和无RAG基线条件下，以及三种解码温度下进行评估

Result: 结果显示图谱与探针范围的匹配度是关键因素：精准范围匹配的检索（特别是G2）带来最稳定的性能提升，而任意合并图谱通常会引入干扰信息降低准确性。在Probe1上，较大模型经常匹配或超过无RAG基线，表明其具有强大的参数先验，而中小模型则更需要有效范围匹配的检索支持。温度参数影响较小，较高温度很少带来帮助

Conclusion: 研究结论是精准优先、范围匹配的知识图谱RAG优于广度优先的图谱合并策略。研究提出了图谱选择、模型规模调整以及检索/重排等实用指导原则，代码和数据已开源

Abstract: Large Language Models (LLMs) generate fluent answers but can struggle with trustworthy, domain-specific reasoning. We evaluate whether domain knowledge graphs (KGs) improve Retrieval-Augmented Generation (RAG) for healthcare by constructing three PubMed-derived graphs: $\mathbb{G}_1$ (T2DM), $\mathbb{G}_2$ (Alzheimer's disease), and $\mathbb{G}_3$ (AD+T2DM). We design two probes: Probe 1 targets merged AD T2DM knowledge, while Probe 2 targets the intersection of $\mathbb{G}_1$ and $\mathbb{G}_2$. Seven instruction-tuned LLMs are tested across retrieval sources {No-RAG, $\mathbb{G}_1$, $\mathbb{G}_2$, $\mathbb{G}_1$ + $\mathbb{G}_2$, $\mathbb{G}_3$, $\mathbb{G}_1$+$\mathbb{G}_2$ + $\mathbb{G}_3$} and three decoding temperatures. Results show that scope alignment between probe and KG is decisive: precise, scope-matched retrieval (notably $\mathbb{G}_2$) yields the most consistent gains, whereas indiscriminate graph unions often introduce distractors that reduce accuracy. Larger models frequently match or exceed KG-RAG with a No-RAG baseline on Probe 1, indicating strong parametric priors, whereas smaller/mid-sized models benefit more from well-scoped retrieval. Temperature plays a secondary role; higher values rarely help. We conclude that precision-first, scope-matched KG-RAG is preferable to breadth-first unions, and we outline practical guidelines for graph selection, model sizing, and retrieval/reranking. Code and Data available here - https://github.com/sydneyanuyah/RAGComparison

</details>


### [70] [Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering](https://arxiv.org/abs/2601.15457)
*Anuj Maharjan,Umesh Yadav*

Main category: cs.CL

TL;DR: 评估 RAG 架构在减少 LLM 幻觉、提高公共健康政策问答准确性的效果，发现高级 RAG 结合重排序能显著提升忠实性。


<details>
  <summary>Details</summary>
Motivation: LLM 在公共卫生政策领域应用时易产生事实性错误的幻觉，这在高风险环境中是不可接受的。研究旨在探索 RAG 如何通过基于权威文档来减轻这种风险，确保信息完整性。

Method: 使用 Mistral-7B Instruct 模型和 MiniLM 嵌入，对比了 Vanilla LLM、基础 RAG 和高级 RAG（带交叉编码器重排序）在 CDC 政策文档上的表现。评估了两种文本分块策略（递归字符和语义分词）对忠实性和相关性的影响。

Result: 基础 RAG 在忠实性（0.621）上较基准（0.347）有显著提升，高级 RAG 进一步将平均忠实性提高到 0.797。两阶段检索机制对领域特定政策问答的精度至关重要，但文档分割的结构限制仍是多步推理任务的主要瓶颈。

Conclusion: RAG 架构，特别是高级 RAG 结合重排序，能有效缓解 LLM 在公共卫生政策领域的幻觉问题，但需要进一步优化文档分割策略以支持更复杂的推理任务。

Abstract: The integration of Large Language Models (LLMs) into the public health policy sector offers a transformative approach to navigating the vast repositories of regulatory guidance maintained by agencies such as the Centers for Disease Control and Prevention (CDC). However, the propensity for LLMs to generate hallucinations, defined as plausible but factually incorrect assertions, presents a critical barrier to the adoption of these technologies in high-stakes environments where information integrity is non-negotiable. This empirical evaluation explores the effectiveness of Retrieval-Augmented Generation (RAG) architectures in mitigating these risks by grounding generative outputs in authoritative document context. Specifically, this study compares a baseline Vanilla LLM against Basic RAG and Advanced RAG pipelines utilizing cross-encoder re-ranking. The experimental framework employs a Mistral-7B-Instruct-v0.2 model and an all-MiniLM-L6-v2 embedding model to process a corpus of official CDC policy analytical frameworks and guidance documents. The analysis measures the impact of two distinct chunking strategies, recursive character-based and token-based semantic splitting, on system accuracy, measured through faithfulness and relevance scores across a curated set of complex policy scenarios. Quantitative findings indicate that while Basic RAG architectures provide a substantial improvement in faithfulness (0.621) over Vanilla baselines (0.347), the Advanced RAG configuration achieves a superior faithfulness average of 0.797. These results demonstrate that two-stage retrieval mechanisms are essential for achieving the precision required for domain-specific policy question answering, though structural constraints in document segmentation remain a significant bottleneck for multi-step reasoning tasks.

</details>


### [71] [Benchmarking LLMs for Pairwise Causal Discovery in Biomedical and Multi-Domain Contexts](https://arxiv.org/abs/2601.15479)
*Sydney Anuyah,Sneha Shajee-Mohan,Ankit-Singh Chauhan,Sunandan Chakraborty*

Main category: cs.CL

TL;DR: 论文研究了13个开源大语言模型从文本中进对因果发现的能力，发现了它们在检测和提取两项核心任务上存在明显不足。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在高风险领域（如生物医学）的安全部署需要它们具备因果推理能力，因此需要评估它们在基础任务（文本中的成对因果发现）上的表现。

Method: 使用12个多样化的数据集构建基准测试，评估模型的“因果检测”和“因果提取”能力，并测试了从零样本到思维链、少量样本上下文学习等多种提示方法。

Result: 当前模型表现欠佳：因果检测最佳模型得分均值仅49.57%，因果提取最佳模型仅47.12%。模型在简单、明确、单句关系上表现最好，但在复杂、隐式、跨越多句及多因果对文本上表现大幅下降。

Conclusion: 研究发现当前大语言模型在文本因果发现任务上存在显著能力缺陷，特别是在复杂实际场景中；论文提供了统一评估框架和开源资源以推动该领域研究。

Abstract: The safe deployment of large language models (LLMs) in high-stakes fields like biomedicine, requires them to be able to reason about cause and effect. We investigate this ability by testing 13 open-source LLMs on a fundamental task: pairwise causal discovery (PCD) from text. Our benchmark, using 12 diverse datasets, evaluates two core skills: 1) \textbf{Causal Detection} (identifying if a text contains a causal link) and 2) \textbf{Causal Extraction} (pulling out the exact cause and effect phrases). We tested various prompting methods, from simple instructions (zero-shot) to more complex strategies like Chain-of-Thought (CoT) and Few-shot In-Context Learning (FICL).
  The results show major deficiencies in current models. The best model for detection, DeepSeek-R1-Distill-Llama-70B, only achieved a mean score of 49.57\% ($C_{detect}$), while the best for extraction, Qwen2.5-Coder-32B-Instruct, reached just 47.12\% ($C_{extract}$). Models performed best on simple, explicit, single-sentence relations. However, performance plummeted for more difficult (and realistic) cases, such as implicit relationships, links spanning multiple sentences, and texts containing multiple causal pairs. We provide a unified evaluation framework, built on a dataset validated with high inter-annotator agreement ($κ\ge 0.758$), and make all our data, code, and prompts publicly available to spur further research. \href{https://github.com/sydneyanuyah/CausalDiscovery}{Code available here: https://github.com/sydneyanuyah/CausalDiscovery}

</details>


### [72] [Multi-Persona Thinking for Bias Mitigation in Large Language Models](https://arxiv.org/abs/2601.15488)
*Yuxing Chen,Guoqing Luo,Zijun Wu,Lili Mou*

Main category: cs.CL

TL;DR: Multi-Persona Thinking (MPT) 是一种利用多视角辩证推理减少LLM偏见的新框架，通过分配不同社会角色身份进行迭代对话来暴露和纠正偏见，在多个模型和基准测试中优于现有提示策略。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在显著的社会偏见，可能延续有害刻板印象和不公平结果，需要有效的偏见缓解方法。

Method: MPT框架在推理时引导模型采用对比性社会身份（如男性和女性）加中性视角，让这些人格角色进行迭代辩证对话来暴露和纠正偏见。

Result: 在开源和闭源模型的广泛偏见基准测试中，MPT在保持核心推理能力的同时实现了最低偏见水平，大幅优于现有基于提示的策略。

Conclusion: MPT框架利用了角色分配的特性，通过多角色辩证推理成功将潜在的弱点转化为偏见缓解的优势，为解决LLM偏见问题提供了有效的新途径。

Abstract: Large Language Models (LLMs) exhibit significant social biases that can perpetuate harmful stereotypes and unfair outcomes. In this paper, we propose Multi-Persona Thinking (MPT), a novel inference-time framework that leverages dialectical reasoning from multiple perspectives to reduce bias. MPT guides models to adopt contrasting social identities (e.g., male and female) along with a neutral viewpoint, and then engages these personas iteratively to expose and correct biases. Through a dialectical reasoning process, the framework transforms the potential weakness of persona assignment into a strength for bias mitigation. We evaluate MPT on two widely used bias benchmarks across both open-source and closed-source models of varying scales. Our results demonstrate substantial improvements over existing prompting-based strategies: MPT achieves the lowest bias while maintaining core reasoning ability.

</details>


### [73] [ViT Registers and Fractal ViT](https://arxiv.org/abs/2601.15506)
*Jason Chuan-Chih Chou,Abhinav Kumar,Shivank Garg*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Drawing inspiration from recent findings including surprisingly decent performance of transformers without positional encoding (NoPE) in the domain of language models and how registers (additional throwaway tokens not tied to input) may improve the performance of large vision transformers (ViTs), we invent and test a variant of ViT called fractal ViT that breaks permutation invariance among the tokens by applying an attention mask between the regular tokens and ``summary tokens'' similar to registers, in isolation or in combination with various positional encodings. These models do not improve upon ViT with registers, highlighting the fact that these findings may be scale, domain, or application-specific.

</details>


### [74] [Computational Representations of Character Significance in Novels](https://arxiv.org/abs/2601.15508)
*Haaris Mian,Melanie Subbiah,Sharon Marcus,Nora Shaalan,Kathleen McKeown*

Main category: cs.CL

TL;DR: 提出基于新文学理论（六成分结构模型）的小说人物建模方法，通过LLM与任务特定Transformer在19世纪英国现实主义小说上应用，生成成分级和图表示，用于探索人物中心性与性别讨论动态。


<details>
  <summary>Details</summary>
Motivation: 传统小说人物建模主要基于场景存在、动作、命名提及和对话，过分强调出现场景最多的主要人物。本文旨在采用新的文学理论中的六成分结构模型，更全面地捕捉人物特性，包括叙述者-人物区分以及前人方法忽视的“其他人物讨论”成分。

Method: 1. 引入基于新文学理论的六成分结构人物模型，包含叙述者-人物区分和其他人物讨论成分；2. 在19世纪英国现实主义小说上，对比通用大语言模型（LLM）与任务特定Transformer来实现该模型；3. 生成成分级和图表示的人物讨论表示。

Result: 1. 成功应用六成分模型生成了人物讨论的成分级和图形表示；2. 这些表示能够支持从新的计算视角大规模探索文学问题；3. 具体展示了如何应用于Woloch的“一个与众多”人物中心性理论以及人物讨论的性别动态分析。

Conclusion: 本文提出的六成分结构人物模型及其计算方法为小说人物分析提供了更全面和多维度的框架，能够捕捉传统方法忽略的成分（如其他人物讨论），并为大规模计算文学研究提供了新工具，成功应用于经典文学理论的验证和性别动态分析。

Abstract: Characters in novels have typically been modeled based on their presence in scenes in narrative, considering aspects like their actions, named mentions, and dialogue. This conception of character places significant emphasis on the main character who is present in the most scenes. In this work, we instead adopt a framing developed from a new literary theory proposing a six-component structural model of character. This model enables a comprehensive approach to character that accounts for the narrator-character distinction and includes a component neglected by prior methods, discussion by other characters. We compare general-purpose LLMs with task-specific transformers for operationalizing this model of character on major 19th-century British realist novels. Our methods yield both component-level and graph representations of character discussion. We then demonstrate that these representations allow us to approach literary questions at scale from a new computational lens. Specifically, we explore Woloch's classic "the one vs the many" theory of character centrality and the gendered dynamics of character discussion.

</details>


### [75] [AdversaRiskQA: An Adversarial Factuality Benchmark for High-Risk Domains](https://arxiv.org/abs/2601.15511)
*Adam Szelestey,Sofie van Engelen,Tianhao Huang,Justin Snelders,Qintao Zeng,Songgaojun Deng*

Main category: cs.CL

TL;DR: AdversaRiskQA is the first benchmark to systematically evaluate LLMs' adversarial factuality across Health, Finance, and Law domains.


<details>
  <summary>Details</summary>
Motivation: 解决LLM幻觉问题，特别是在高风险领域，目前缺乏高质量的领域特定资源来评估模型在对抗性条件下的鲁棒性。

Method: 开发了两个难度级别的AdversaRiskQA基准，包含两种自动评估方法来评估对抗攻击成功率和长文本事实性。评估了六个开源和闭源LLM。

Result: 排除无意义响应后，Qwen3 (80B)获得最高平均准确率，GPT-5保持稳定高准确率。性能随模型大小非线性增长，不同领域表现不同，难度层级差距随模型增大而缩小。长文本评估显示注入的虚假信息与模型的事实输出无显著相关性。

Conclusion: AdversaRiskQA为识别LLM弱点和发展更可靠的高风险应用模型提供了有价值的基准。

Abstract: Hallucination in large language models (LLMs) remains an acute concern, contributing to the spread of misinformation and diminished public trust, particularly in high-risk domains. Among hallucination types, factuality is crucial, as it concerns a model's alignment with established world knowledge. Adversarial factuality, defined as the deliberate insertion of misinformation into prompts with varying levels of expressed confidence, tests a model's ability to detect and resist confidently framed falsehoods. Existing work lacks high-quality, domain-specific resources for assessing model robustness under such adversarial conditions, and no prior research has examined the impact of injected misinformation on long-form text factuality.
  To address this gap, we introduce AdversaRiskQA, the first verified and reliable benchmark systematically evaluating adversarial factuality across Health, Finance, and Law. The benchmark includes two difficulty levels to test LLMs' defensive capabilities across varying knowledge depths. We propose two automated methods for evaluating the adversarial attack success and long-form factuality. We evaluate six open- and closed-source LLMs from the Qwen, GPT-OSS, and GPT families, measuring misinformation detection rates. Long-form factuality is assessed on Qwen3 (30B) under both baseline and adversarial conditions. Results show that after excluding meaningless responses, Qwen3 (80B) achieves the highest average accuracy, while GPT-5 maintains consistently high accuracy. Performance scales non-linearly with model size, varies by domains, and gaps between difficulty levels narrow as models grow. Long-form evaluation reveals no significant correlation between injected misinformation and the model's factual output. AdversaRiskQA provides a valuable benchmark for pinpointing LLM weaknesses and developing more reliable models for high-stakes applications.

</details>


### [76] [Common to Whom? Regional Cultural Commonsense and LLM Bias in India](https://arxiv.org/abs/2601.15550)
*Sangmitra Madhusudan,Trush Shashank More,Steph Buongiorno,Renata Dividino,Jad Kabbara,Ali Emami*

Main category: cs.CL

TL;DR: 论文提出了Indica基准测试来评估LLMs在印度国家文化常识中的区域差异性，发现仅有39.4%的问题在全印度五区达成共识，LLMs的区域准确性仅13.4%-20.9%，且存在地理偏见


<details>
  <summary>Details</summary>
Motivation: 现有文化常识基准测试将国家视为整体，但文化常识是否在国家内一致存在疑问。作者希望研究文化常识在次国家层面的变化，以印度为研究对象

Method: 创建Indica基准测试，从印度五个地区收集515个涵盖8个日常生活领域的问题，获得1630个区域特定的问答对。评估8个最先进的LLMs模型

Result: 仅有39.4%的问题在所有五个地区达成一致；LLMs在区域特定问题上的准确率仅13.4%-20.9%，且存在地理偏见，过度选择中北部作为'默认'，低估东部和西部

Conclusion: 印度的文化常识主要是区域性的而非全国性的；LLMs在处理区域文化常识时存在显著差距和地理偏见；提出的方法是通用的评估框架，适用于文化异质国家

Abstract: Existing cultural commonsense benchmarks treat nations as monolithic, assuming uniform practices within national boundaries. But does cultural commonsense hold uniformly within a nation, or does it vary at the sub-national level? We introduce Indica, the first benchmark designed to test LLMs' ability to address this question, focusing on India - a nation of 28 states, 8 union territories, and 22 official languages. We collect human-annotated answers from five Indian regions (North, South, East, West, and Central) across 515 questions spanning 8 domains of everyday life, yielding 1,630 region-specific question-answer pairs. Strikingly, only 39.4% of questions elicit agreement across all five regions, demonstrating that cultural commonsense in India is predominantly regional, not national. We evaluate eight state-of-the-art LLMs and find two critical gaps: models achieve only 13.4%-20.9% accuracy on region-specific questions, and they exhibit geographic bias, over-selecting Central and North India as the "default" (selected 30-40% more often than expected) while under-representing East and West. Beyond India, our methodology provides a generalizable framework for evaluating cultural commonsense in any culturally heterogeneous nation, from question design grounded in anthropological taxonomy, to regional data collection, to bias measurement.

</details>


### [77] [From Generation to Collaboration: Using LLMs to Edit for Empathy in Healthcare](https://arxiv.org/abs/2601.15558)
*Man Luo,Bahareh Harandizadeh,Amara Tariq,Halim Abbas,Umar Ghaffar,Christopher J Warren,Segun O. Kolade,Haidar M. Abdul-Muhsin*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Clinical empathy is essential for patient care, but physicians need continually balance emotional warmth with factual precision under the cognitive and emotional constraints of clinical practice. This study investigates how large language models (LLMs) can function as empathy editors, refining physicians' written responses to enhance empathetic tone while preserving underlying medical information. More importantly, we introduce novel quantitative metrics, an Empathy Ranking Score and a MedFactChecking Score to systematically assess both emotional and factual quality of the responses. Experimental results show that LLM edited responses significantly increase perceived empathy while preserving factual accuracy compared with fully LLM generated outputs. These findings suggest that using LLMs as editorial assistants, rather than autonomous generators, offers a safer, more effective pathway to empathetic and trustworthy AI-assisted healthcare communication.

</details>


### [78] [YuFeng-XGuard: A Reasoning-Centric, Interpretable, and Flexible Guardrail Model for Large Language Models](https://arxiv.org/abs/2601.15588)
*Junyu Lin,Meizhen Liu,Xiufeng Huang,Jinfeng Li,Haiwen Hong,Xiaohan Yuan,Yuefeng Chen,Longtao Huang,Hui Xue,Ranjie Duan,Zhikai Chen,Yuchuan Fu,Defeng Li,Lingyao Gao,Yitong Yang*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As large language models (LLMs) are increasingly deployed in real-world applications, safety guardrails are required to go beyond coarse-grained filtering and support fine-grained, interpretable, and adaptable risk assessment. However, existing solutions often rely on rapid classification schemes or post-hoc rules, resulting in limited transparency, inflexible policies, or prohibitive inference costs. To this end, we present YuFeng-XGuard, a reasoning-centric guardrail model family designed to perform multi-dimensional risk perception for LLM interactions. Instead of producing opaque binary judgments, YuFeng-XGuard generates structured risk predictions, including explicit risk categories and configurable confidence scores, accompanied by natural language explanations that expose the underlying reasoning process. This formulation enables safety decisions that are both actionable and interpretable. To balance decision latency and explanatory depth, we adopt a tiered inference paradigm that performs an initial risk decision based on the first decoded token, while preserving ondemand explanatory reasoning when required. In addition, we introduce a dynamic policy mechanism that decouples risk perception from policy enforcement, allowing safety policies to be adjusted without model retraining. Extensive experiments on a diverse set of public safety benchmarks demonstrate that YuFeng-XGuard achieves stateof-the-art performance while maintaining strong efficiency-efficacy trade-offs. We release YuFeng-XGuard as an open model family, including both a full-capacity variant and a lightweight version, to support a wide range of deployment scenarios.

</details>


### [79] [Parallelism and Generation Order in Masked Diffusion Language Models: Limits Today, Potential Tomorrow](https://arxiv.org/abs/2601.15593)
*Yangyang Zhong,Yanmei Gu,Zhengqing Zang,Xiaomeng Li,Yuqi Ding,Xibei Jia,Yuting Shen,Zhenzhong Lan,Liwang Zhu,Weiping Liu,Junlin Zhou,Haisheng Liu,Zhong Xin Yu,Pengxin Luo,Donglian Qi,Yunfeng Yan,Junbo Zhao*

Main category: cs.CL

TL;DR: 该研究评估了主流掩码扩散语言模型（MDLMs）的实际并行生成和任意顺序解码能力，发现其在依赖关系和生成适应性方面存在特点与局限。


<details>
  <summary>Details</summary>
Motivation: 研究旨在澄清当前MDLMs是否真正实现了其承诺的并行token生成和任意顺序解码能力，这关系到这类模型的实际应用价值和改进方向。

Method: 研究团队从并行强度和生成顺序两个维度，使用平均完成并行度（AFP）和Kendall's tau评估了8个主流MDLMs（最大1000亿参数）在58个涵盖知识、推理和编程的基准测试上的表现。

Result: MDLMs在性能上仍落后于规模相当的自回归模型，主要原因是并行概率建模削弱了token间的依赖关系。同时，MDLMs表现出自适应的解码行为：其并行性和生成顺序随任务领域、推理阶段和输出正确性显著变化。在需要“后向信息”的任务（如数独）中，MDLMs倾向于先填充较简单的空格，体现了其独特优势。

Conclusion: 研究提出了“生成-编辑”范式，在理论层面提供了支持，该范式能在保持并行解码效率的同时缓解依赖关系损失问题，为MDLMs的未来改进提供了设计指导。

Abstract: Masked Diffusion Language Models (MDLMs) promise parallel token generation and arbitrary-order decoding, yet it remains unclear to what extent current models truly realize these capabilities. We characterize MDLM behavior along two dimensions -- parallelism strength and generation order -- using Average Finalization Parallelism (AFP) and Kendall's tau. We evaluate eight mainstream MDLMs (up to 100B parameters) on 58 benchmarks spanning knowledge, reasoning, and programming. The results show that MDLMs still lag behind comparably sized autoregressive models, mainly because parallel probabilistic modeling weakens inter-token dependencies. Meanwhile, MDLMs exhibit adaptive decoding behavior: their parallelism and generation order vary significantly with the task domain, the stage of reasoning, and whether the output is correct. On tasks that require "backward information" (e.g., Sudoku), MDLMs adopt a solution order that tends to fill easier Sudoku blanks first, highlighting their advantages. Finally, we provide theoretical motivation and design insights supporting a Generate-then-Edit paradigm, which mitigates dependency loss while retaining the efficiency of parallel decoding.

</details>


### [80] [ToxiTwitch: Toward Emote-Aware Hybrid Moderation for Live Streaming Platforms](https://arxiv.org/abs/2601.15605)
*Baktash Ansari,Shiza Ali,Elias Martin,Maryna Sivachenko,Afra Mashhadi*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rapid growth of live-streaming platforms such as Twitch has introduced complex challenges in moderating toxic behavior. Traditional moderation approaches, such as human annotation and keyword-based filtering, have demonstrated utility, but human moderators on Twitch constantly struggle to scale effectively in the fast-paced, high-volume, and context-rich chat environment of the platform while also facing harassment themselves. Recent advances in large language models (LLMs), such as DeepSeek-R1-Distill and Llama-3-8B-Instruct, offer new opportunities for toxicity detection, especially in understanding nuanced, multimodal communication involving emotes. In this work, we present an exploratory comparison of toxicity detection approaches tailored to Twitch. Our analysis reveals that incorporating emotes improves the detection of toxic behavior. To this end, we introduce ToxiTwitch, a hybrid model that combines LLM-generated embeddings of text and emotes with traditional machine learning classifiers, including Random Forest and SVM. In our case study, the proposed hybrid approach reaches up to 80 percent accuracy under channel-specific training (with 13 percent improvement over BERT and F1-score of 76 percent). This work is an exploratory study intended to surface challenges and limits of emote-aware toxicity detection on Twitch.

</details>


### [81] [Towards Reliable Medical LLMs: Benchmarking and Enhancing Confidence Estimation of Large Language Models in Medical Consultation](https://arxiv.org/abs/2601.15645)
*Zhiyao Ren,Yibing Zhan,Siyuan Liang,Guozheng Ma,Baosheng Yu,Dacheng Tao*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large-scale language models (LLMs) often offer clinical judgments based on incomplete information, increasing the risk of misdiagnosis. Existing studies have primarily evaluated confidence in single-turn, static settings, overlooking the coupling between confidence and correctness as clinical evidence accumulates during real consultations, which limits their support for reliable decision-making. We propose the first benchmark for assessing confidence in multi-turn interaction during realistic medical consultations. Our benchmark unifies three types of medical data for open-ended diagnostic generation and introduces an information sufficiency gradient to characterize the confidence-correctness dynamics as evidence increases. We implement and compare 27 representative methods on this benchmark; two key insights emerge: (1) medical data amplifies the inherent limitations of token-level and consistency-level confidence methods, and (2) medical reasoning must be evaluated for both diagnostic accuracy and information completeness. Based on these insights, we present MedConf, an evidence-grounded linguistic self-assessment framework that constructs symptom profiles via retrieval-augmented generation, aligns patient information with supporting, missing, and contradictory relations, and aggregates them into an interpretable confidence estimate through weighted integration. Across two LLMs and three medical datasets, MedConf consistently outperforms state-of-the-art methods on both AUROC and Pearson correlation coefficient metrics, maintaining stable performance under conditions of information insufficiency and multimorbidity. These results demonstrate that information adequacy is a key determinant of credible medical confidence modeling, providing a new pathway toward building more reliable and interpretable large medical models.

</details>


### [82] [What Patients Really Ask: Exploring the Effect of False Assumptions in Patient Information Seeking](https://arxiv.org/abs/2601.15674)
*Raymond Xiong,Furong Jia,Lionel Wong,Monica Agrawal*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Patients are increasingly using large language models (LLMs) to seek answers to their healthcare-related questions. However, benchmarking efforts in LLMs for question answering often focus on medical exam questions, which differ significantly in style and content from the questions patients actually raise in real life. To bridge this gap, we sourced data from Google's People Also Ask feature by querying the top 200 prescribed medications in the United States, curating a dataset of medical questions people commonly ask. A considerable portion of the collected questions contains incorrect assumptions and dangerous intentions. We demonstrate that the emergence of these corrupted questions is not uniformly random and depends heavily on the degree of incorrectness in the history of questions that led to their appearance. Current LLMs that perform strongly on other benchmarks struggle to identify incorrect assumptions in everyday questions.

</details>


### [83] [Persona Switch: Mixing Distinct Perspectives in Decoding Time](https://arxiv.org/abs/2601.15708)
*Junseok Kim,Nakyeong Yang,Kyomin Jung*

Main category: cs.CL

TL;DR: 提出Persona Switch方法，动态结合零样本提示和角色扮演提示，通过逐步对比输出置信度选择更好结果，显著提升任务准确率


<details>
  <summary>Details</summary>
Motivation: 虽然角色扮演提示能通过注入角色设定改善语言模型零样本推理能力，但改进效果在不同任务或实例中不一致，表明零样本提示和角色扮演提示可能具有互补优势而非简单的优劣关系

Method: 提出了Persona Switch解码方法，在逐步生成过程中，通过比较零样本提示和角色扮演提示输出的对数差衡量的置信度，动态选择每个步骤的更好输出

Result: 在广泛使用的LLMs上的实验表明，Persona Switch持续优于竞争基线，最高实现了5.13%的准确率提升，并且输出置信度被证明是选择更可靠输出的有效指标

Conclusion: Persona Switch方法通过动态结合零样本和角色扮演提示的优势，提供了一种更可靠的解码策略，证实了置信度比较在输出选择中的有效性

Abstract: Role-play prompting is known to steer the behavior of language models by injecting a persona into the prompt, improving their zero-shot reasoning capabilities. However, such improvements are inconsistent across different tasks or instances. This inconsistency suggests that zero-shot and role-play prompting may offer complementary strengths rather than one being universally superior. Building on this insight, we propose Persona Switch, a novel decoding method that dynamically combines the benefits of both prompting strategies. Our method proceeds step-by-step, selecting the better output between zero-shot and role-play prompting at each step by comparing their output confidence, as measured by the logit gap. Experiments with widely-used LLMs demonstrate that Persona Switch consistently outperforms competitive baselines, achieving up to 5.13% accuracy improvement. Furthermore, we show that output confidence serves as an informative measure for selecting the more reliable output.

</details>


### [84] [Dancing in Chains: Strategic Persuasion in Academic Rebuttal via Theory of Mind](https://arxiv.org/abs/2601.15715)
*Zhitao He,Zongwei Lyu,Yi R Fung*

Main category: cs.CL

TL;DR: RebuttalAgent: 第一个基于心理理论（ToM）的学术反驳框架，通过建模审稿人心理状态、制定说服策略和生成策略驱动的回复来实现AI驱动的学术反驳


<details>
  <summary>Details</summary>
Motivation: 学术反驳是一个在信息不对称下复杂且被忽视的沟通过程。当前方法大多停留在表面语言模仿层面，缺乏有效说服所需的关键的换位思考能力

Method: 开发ToM-策略-响应（TSR）流程框架，构建大规模RebuttalBench数据集，采用两阶段训练：监督微调让AI具备心理理论和战略规划能力，然后使用自我奖励机制的强化学习实现可扩展的自我改进

Result: RebuttalAgent在自动指标上平均领先基础模型18.3%，在自动和人工评估中均优于先进的专有模型，Rebuttal-RM评估器在评分一致性上超过了GPT-4.1

Conclusion: 基于心理理论的系统化方法是解决学术反驳挑战的有效途径。生成的回复仅供作者参考，不替代作者的批判性分析和实际回应

Abstract: Although artificial intelligence (AI) has become deeply integrated into various stages of the research workflow and achieved remarkable advancements, academic rebuttal remains a significant and underexplored challenge. This is because rebuttal is a complex process of strategic communication under severe information asymmetry rather than a simple technical debate. Consequently, current approaches struggle as they largely imitate surface-level linguistics, missing the essential element of perspective-taking required for effective persuasion. In this paper, we introduce RebuttalAgent, the first framework to ground academic rebuttal in Theory of Mind (ToM), operationalized through a ToM-Strategy-Response (TSR) pipeline that models reviewer mental state, formulates persuasion strategy, and generates strategy-grounded response. To train our agent, we construct RebuttalBench, a large-scale dataset synthesized via a novel critique-and-refine approach. Our training process consists of two stages, beginning with a supervised fine-tuning phase to equip the agent with ToM-based analysis and strategic planning capabilities, followed by a reinforcement learning phase leveraging the self-reward mechanism for scalable self-improvement. For reliable and efficient automated evaluation, we further develop Rebuttal-RM, a specialized evaluator trained on over 100K samples of multi-source rebuttal data, which achieves scoring consistency with human preferences surpassing powerful judge GPT-4.1. Extensive experiments show RebuttalAgent significantly outperforms the base model by an average of 18.3% on automated metrics, while also outperforming advanced proprietary models across both automated and human evaluations. Disclaimer: the generated rebuttal content is for reference only to inspire authors and assist in drafting. It is not intended to replace the author's own critical analysis and response.

</details>


### [85] [Hallucination Mitigating for Medical Report Generation](https://arxiv.org/abs/2601.15745)
*Ruoqing Zhao,Runze Xia,Piji Li*

Main category: cs.CL

TL;DR: 提出KERM框架，通过MedCLIP知识检索、知识纯化模块和细粒度奖励机制，减少大型视觉语言模型在医疗报告生成中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在医疗报告生成中存在产生看似合理但不准确陈述（幻觉）的问题，这在医疗领域具有高风险，需专门方法解决。

Method: 1. 使用MedCLIP从知识库检索相关病灶事实句子；2. 引入知识纯化模块确保检索知识与患者临床上下文相关；3. 设计细粒度奖励机制引导模型生成支持性强、临床相关的描述。

Result: 在IU-Xray和MIMIC-CXR数据集上的实验验证了该方法在减少幻觉和提升报告质量方面的有效性。

Conclusion: KERM框架通过知识增强和强化学习奖励机制，有效缓解了医疗报告生成中的幻觉问题，提高了生成报告的临床准确性和相关性。

Abstract: In the realm of medical report generation (MRG), the integration of natural language processing has emerged as a vital tool to alleviate the workload of radiologists. Despite the impressive capabilities demonstrated by large vision language models (LVLMs) in understanding natural language, their susceptibility to generating plausible yet inaccurate claims, known as ``hallucinations'', raises concerns-especially in the nuanced and critical field of medical. In this work, we introduce a framework, \textbf{K}nowledge-\textbf{E}nhanced with Fine-Grained \textbf{R}einforced Rewards \textbf{M}edical Report Generation (KERM), to tackle the issue. Our approach refines the input to the LVLM by first utilizing MedCLIP for knowledge retrieval, incorporating relevant lesion fact sentences from a curated knowledge corpus. We then introduce a novel purification module to ensure the retrieved knowledge is contextually relevant to the patient's clinical context. Subsequently, we employ fine-grained rewards to guide these models in generating highly supportive and clinically relevant descriptions, ensuring the alignment of model's outputs with desired behaviors. Experimental results on IU-Xray and MIMIC-CXR datasets validate the effectiveness of our approach in mitigating hallucinations and enhancing report quality.

</details>


### [86] [Beyond Marginal Distributions: A Framework to Evaluate the Representativeness of Demographic-Aligned LLMs](https://arxiv.org/abs/2601.15755)
*Tristan Williams,Franziska Weeber,Sebastian Padó,Alan Akbik*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models are increasingly used to represent human opinions, values, or beliefs, and their steerability towards these ideals is an active area of research. Existing work focuses predominantly on aligning marginal response distributions, treating each survey item independently. While essential, this may overlook deeper latent structures that characterise real populations and underpin cultural values theories. We propose a framework for evaluating the representativeness of aligned models through multivariate correlation patterns in addition to marginal distributions. We show the value of our evaluation scheme by comparing two model steering techniques (persona prompting and demographic fine-tuning) and evaluating them against human responses from the World Values Survey. While the demographically fine-tuned model better approximates marginal response distributions than persona prompting, both techniques fail to fully capture the gold standard correlation patterns. We conclude that representativeness is a distinct aspect of value alignment and an evaluation focused on marginals can mask structural failures, leading to overly optimistic conclusions about model capabilities.

</details>


### [87] [HumanLLM: Towards Personalized Understanding and Simulation of Human Nature](https://arxiv.org/abs/2601.15793)
*Yuxuan Lei,Tianfu Wang,Jianxun Lian,Zhengyu Hu,Defu Lian,Xing Xie*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Motivated by the remarkable progress of large language models (LLMs) in objective tasks like mathematics and coding, there is growing interest in their potential to simulate human behavior--a capability with profound implications for transforming social science research and customer-centric business insights. However, LLMs often lack a nuanced understanding of human cognition and behavior, limiting their effectiveness in social simulation and personalized applications. We posit that this limitation stems from a fundamental misalignment: standard LLM pretraining on vast, uncontextualized web data does not capture the continuous, situated context of an individual's decisions, thoughts, and behaviors over time. To bridge this gap, we introduce HumanLLM, a foundation model designed for personalized understanding and simulation of individuals. We first construct the Cognitive Genome Dataset, a large-scale corpus curated from real-world user data on platforms like Reddit, Twitter, Blogger, and Amazon. Through a rigorous, multi-stage pipeline involving data filtering, synthesis, and quality control, we automatically extract over 5.5 million user logs to distill rich profiles, behaviors, and thinking patterns. We then formulate diverse learning tasks and perform supervised fine-tuning to empower the model to predict a wide range of individualized human behaviors, thoughts, and experiences. Comprehensive evaluations demonstrate that HumanLLM achieves superior performance in predicting user actions and inner thoughts, more accurately mimics user writing styles and preferences, and generates more authentic user profiles compared to base models. Furthermore, HumanLLM shows significant gains on out-of-domain social intelligence benchmarks, indicating enhanced generalization.

</details>


### [88] [SteerEval: Inference-time Interventions Strengthen Multilingual Generalization in Neural Summarization Metrics](https://arxiv.org/abs/2601.15809)
*Silvia Casola,Ryan Soh-Eun Shim,Felicia Körner,Yuchen Mao,Barbara Plank*

Main category: cs.CL

TL;DR: 探索是否通过将多语言神经度量指标向英语枢纽方向引导，可以提高其与人类判断的相关性。研究发现测试时干预方法对不同类型的度量指标都有显著效果。


<details>
  <summary>Details</summary>
Motivation: 多语言自然语言生成任务中缺乏准确且鲁棒的评估指标，阻碍了研究进展。多语言模型常以英语为内部枢纽语言，若度量指标与之不匹配可能导致下游性能下降。

Method: 对编码器和解码器基的度量指标进行实验，采用测试时干预方法，尝试将其激活状态朝英语枢纽方向引导。

Result: 测试时干预方法对所有度量指标都有效，能够提升多种语言下度量指标的有效性。

Conclusion: 通过在测试时将多语言神经度量指标的激活状态向英语枢纽引导，可以有效提高其与人类判断的相关性，为解决多语言评估问题提供了新思路。

Abstract: An increasing body of work has leveraged multilingual language models for Natural Language Generation tasks such as summarization. A major empirical bottleneck in this area is the shortage of accurate and robust evaluation metrics for many languages, which hinders progress. Recent studies suggest that multilingual language models often use English as an internal pivot language, and that misalignment with this pivot can lead to degraded downstream performance. Motivated by the hypothesis that this mismatch could also apply to multilingual neural metrics, we ask whether steering their activations toward an English pivot can improve correlation with human judgments. We experiment with encoder- and decoder-based metrics and find that test-time intervention methods are effective across the board, increasing metric effectiveness for diverse languages.

</details>


### [89] [ExDR: Explanation-driven Dynamic Retrieval Enhancement for Multimodal Fake News Detection](https://arxiv.org/abs/2601.15820)
*Guoxuan Ding,Yuqing Li,Ziyan Zhou,Zheng Lin,Daren Zha,Jiangnan Li*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rapid spread of multimodal fake news poses a serious societal threat, as its evolving nature and reliance on timely factual details challenge existing detection methods. Dynamic Retrieval-Augmented Generation provides a promising solution by triggering keyword-based retrieval and incorporating external knowledge, thus enabling both efficient and accurate evidence selection. However, it still faces challenges in addressing issues such as redundant retrieval, coarse similarity, and irrelevant evidence when applied to deceptive content. In this paper, we propose ExDR, an Explanation-driven Dynamic Retrieval-Augmented Generation framework for Multimodal Fake News Detection. Our framework systematically leverages model-generated explanations in both the retrieval triggering and evidence retrieval modules. It assesses triggering confidence from three complementary dimensions, constructs entity-aware indices by fusing deceptive entities, and retrieves contrastive evidence based on deception-specific features to challenge the initial claim and enhance the final prediction. Experiments on two benchmark datasets, AMG and MR2, demonstrate that ExDR consistently outperforms previous methods in retrieval triggering accuracy, retrieval quality, and overall detection performance, highlighting its effectiveness and generalization capability.

</details>


### [90] [Can professional translators identify machine-generated text?](https://arxiv.org/abs/2601.15828)
*Michael Farrell*

Main category: cs.CL

TL;DR: 研究考察专业翻译人员能否在不经过专门训练的情况下可靠识别意大利语AI生成短篇故事。实验显示16.2%的参与者能成功区分AI与人类文本，但近同比例的人做出相反误判。低文本变动性和叙事矛盾是识别AI文本的最可靠指标。


<details>
  <summary>Details</summary>
Motivation: 随着AI文本生成技术的快速发展，理解专业译者对AI生成文本的识别能力具有重要意义，特别是在专业翻译和编辑环境中如何应对合成文本的出现。

Method: 69名翻译人员参与现场实验，评估三篇匿名短篇故事（两篇由ChatGPT-4o生成，一篇为人类创作）。参与者对每篇故事进行AI作者可能性评估并提供判断依据。

Result: 16.2%的参与者能准确区分AI与人类文本，但近等比例的人做出相反误判。低文本变动性、叙事矛盾、英语借词和句法迁移是最可靠的AI文本指标，而语法准确性和情感基调则常导致误判。

Conclusion: 专业翻译人员可能具备区分AI生成文本的潜力，但缺乏共识和主观偏好可能导致系统性误判，这引发了关于合成文本编辑在专业环境中的角色和范围的思考。

Abstract: This study investigates whether professional translators can reliably identify short stories generated in Italian by artificial intelligence (AI) without prior specialized training. Sixty-nine translators took part in an in-person experiment, where they assessed three anonymized short stories - two written by ChatGPT-4o and one by a human author. For each story, participants rated the likelihood of AI authorship and provided justifications for their choices. While average results were inconclusive, a statistically significant subset (16.2%) successfully distinguished the synthetic texts from the human text, suggesting that their judgements were informed by analytical skill rather than chance. However, a nearly equal number misclassified the texts in the opposite direction, often relying on subjective impressions rather than objective markers, possibly reflecting a reader preference for AI-generated texts. Low burstiness and narrative contradiction emerged as the most reliable indicators of synthetic authorship, with unexpected calques, semantic loans and syntactic transfer from English also reported. In contrast, features such as grammatical accuracy and emotional tone frequently led to misclassification. These findings raise questions about the role and scope of synthetic-text editing in professional contexts.

</details>


### [91] [Determinants of Training Corpus Size for Clinical Text Classification](https://arxiv.org/abs/2601.15846)
*Jaya Chaturvedi,Saniya Deshpande,Chenkai Ma,Robert Cobb,Angus Roberts,Robert Stewart,Daniel Stahl,Diana Shamsutdinova*

Main category: cs.CL

TL;DR: 该研究发现，对于临床文本分类任务，约600个训练文档即可达到使用10000个文档性能的95%，学习曲线差异与词汇特征（强预测词和噪声词数量）直接相关。


<details>
  <summary>Details</summary>
Motivation: 临床文本分类通常需要大量标注数据（200-500篇文档），但这一数量缺乏理论依据，且未考虑文本词汇特性与样本需求的关系。研究旨在确定合理的训练样本量及其与词汇属性的关联。

Method: 使用MIMIC-III医院出院记录数据集，选取10个ICD-9诊断标签，采用预训练的BERT嵌入和随机森林分类器，训练样本量从100到10000不等。通过Lasso逻辑回归分析词汇特征（强预测词和噪声词）。

Result: 学习曲线在不同分类任务中存在显著差异；所有任务中使用600个文档即可获得10000个文档95%的性能。词汇分析显示：强预测词越多、噪声词越少，学习曲线越陡峭——每增加100个噪声词准确率下降0.02，每增加100个强预测词最大准确率提升0.04。

Conclusion: 临床文本分类的样本需求与词汇特性密切相关，600个训练文档是相对高效的起点。通过分析词汇特征（特别是强预测词和噪声词）可以预测和优化样本需求，为临床NLP标注工作提供量化指导。

Abstract: Introduction: Clinical text classification using natural language processing (NLP) models requires adequate training data to achieve optimal performance. For that, 200-500 documents are typically annotated. The number is constrained by time and costs and lacks justification of the sample size requirements and their relationship to text vocabulary properties.
  Methods: Using the publicly available MIMIC-III dataset containing hospital discharge notes with ICD-9 diagnoses as labels, we employed pre-trained BERT embeddings followed by Random Forest classifiers to identify 10 randomly selected diagnoses, varying training corpus sizes from 100 to 10,000 documents, and analyzed vocabulary properties by identifying strong and noisy predictive words through Lasso logistic regression on bag-of-words embeddings.
  Results: Learning curves varied significantly across the 10 classification tasks despite identical preprocessing and algorithms, with 600 documents sufficient to achieve 95% of the performance attainable with 10,000 documents for all tasks. Vocabulary analysis revealed that more strong predictors and fewer noisy predictors were associated with steeper learning curves, where every 100 additional noisy words decreased accuracy by approximately 0.02 while 100 additional strong predictors increased maximum accuracy by approximately 0.04.

</details>


### [92] [Artificial Rigidities vs. Biological Noise: A Comparative Analysis of Multisensory Integration in AV-HuBERT and Human Observers](https://arxiv.org/abs/2601.15869)
*Francisco Portillo López*

Main category: cs.CL

TL;DR: 本研究评估AV-HuBERT在处理矛盾视听刺激时的感知生物逼真度，发现其在听觉主导率上与人类相似，但在语音融合判断上表现出明显偏差。


<details>
  <summary>Details</summary>
Motivation: 旨在评估自监督学习模型在多感官整合生物逼真度方面的性能，特别是检查这些模型是否真正捕捉人类在矛盾视听输入下的感知机制。

Method: 通过44名人类受试者与AV-HuBERT模型进行McGurk效应对比实验，测量双方在矛盾视听刺激下的听觉主导率和语音融合率。

Result: 模型与人类在听觉主导率上高度一致（32.0% vs 31.8%），但在语音融合率上模型显著高于人类（68.0% vs 47.7%），且模型缺乏人类的感知随机性和错误多样性。

Conclusion: 当前自监督架构能够模仿多感官结果的基本阈值，但无法复现人类语音感知中固有的神经变异性，表明模型生物逼真度存在局限性。

Abstract: This study evaluates AV-HuBERT's perceptual bio-fidelity by benchmarking its response to incongruent audiovisual stimuli (McGurk effect) against human observers (N=44). Results reveal a striking quantitative isomorphism: AI and humans exhibited nearly identical auditory dominance rates (32.0% vs. 31.8%), suggesting the model captures biological thresholds for auditory resistance. However, AV-HuBERT showed a deterministic bias toward phonetic fusion (68.0%), significantly exceeding human rates (47.7%). While humans displayed perceptual stochasticity and diverse error profiles, the model remained strictly categorical. Findings suggest that current self-supervised architectures mimic multisensory outcomes but lack the neural variability inherent to human speech perception.

</details>


### [93] [Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model](https://arxiv.org/abs/2601.15892)
*Chenghao Fan,Wen Heng,Bo Li,Sichen Liu,Yuxuan Song,Jing Su,Xiaoye Qu,Kai Shen,Wei Wei*

Main category: cs.CL

TL;DR: 本文介绍Stable-DiffCoder——一种基于块扩散的代码模型，在相同数据架构下整体优于自回归模型，并在多项代码基准测试中表现更佳。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的语言模型(DLLMs)在代码生成任务上仍落后于强大的自回归(AR)基线模型，尤其是在相同计算预算下。本文旨在重新审视这一设定，探讨如何通过扩散训练提升代码建模质量。

Method: 采用Seed-Coder架构、数据和训练流程，引入块扩散连续预训练阶段，结合定制的学习率预热和块级裁剪噪声调度策略，以实现高效知识学习和稳定训练。

Result: 在相同数据和架构下，Stable-DiffCoder在广泛的代码基准测试中整体优于其AR对应模型。仅通过连续预训练和有监督微调阶段，该模型性能就已超越一系列约8B参数的AR和DLLM模型。

Conclusion: 扩散训练可以改善代码建模质量，超越单纯的自回归训练；基于扩散的任意顺序建模能提升结构化代码的编辑和推理能力，并通过数据增强有益于低资源编程语言。

Abstract: Diffusion-based language models (DLLMs) offer non-sequential, block-wise generation and richer data reuse compared to autoregressive (AR) models, but existing code DLLMs still lag behind strong AR baselines under comparable budgets. We revisit this setting in a controlled study and introduce Stable-DiffCoder, a block diffusion code model that reuses the Seed-Coder architecture, data, and training pipeline. To enable efficient knowledge learning and stable training, we incorporate a block diffusion continual pretraining (CPT) stage enhanced by a tailored warmup and block-wise clipped noise schedule. Under the same data and architecture, Stable-DiffCoder overall outperforms its AR counterpart on a broad suite of code benchmarks. Moreover, relying only on the CPT and supervised fine-tuning stages, Stable-DiffCoder achieves stronger performance than a wide range of \~8B ARs and DLLMs, demonstrating that diffusion-based training can improve code modeling quality beyond AR training alone. Moreover, diffusion-based any-order modeling improves structured code modeling for editing and reasoning, and through data augmentation, benefits low-resource coding languages.

</details>


### [94] [Transfer Learning from ImageNet for MEG-Based Decoding of Imagined Speech](https://arxiv.org/abs/2601.15909)
*Soufiane Jhilal,Stéphanie Martin,Anne-Lise Giraud*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Non-invasive decoding of imagined speech remains challenging due to weak, distributed signals and limited labeled data. Our paper introduces an image-based approach that transforms magnetoencephalography (MEG) signals into time-frequency representations compatible with pretrained vision models. MEG data from 21 participants performing imagined speech tasks were projected into three spatial scalogram mixtures via a learnable sensor-space convolution, producing compact image-like inputs for ImageNet-pretrained vision architectures. These models outperformed classical and non-pretrained models, achieving up to 90.4% balanced accuracy for imagery vs. silence, 81.0% vs. silent reading, and 60.6% for vowel decoding. Cross-subject evaluation confirmed that pretrained models capture shared neural representations, and temporal analyses localized discriminative information to imagery-locked intervals. These findings show that pretrained vision models applied to image-based MEG representations can effectively capture the structure of imagined speech in non-invasive neural signals.

</details>


### [95] [Mecellem Models: Turkish Models Trained from Scratch and Continually Pre-trained for the Legal Domain](https://arxiv.org/abs/2601.16018)
*Özgür Uğur,Mahmut Göksu,Mahmut Çimen,Musa Yılmaz,Esra Şavirdi,Alp Talha Demir,Rumeysa Güllüce,İclal Çetin,Ömer Can Sağbaş*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper presents Mecellem models, a framework for developing specialized language models for the Turkish legal domain through domain adaptation strategies. We make two contributions: (1)Encoder Model Pre-trained from Scratch: ModernBERT-based bidirectional encoders pre-trained on a Turkish-dominant corpus of 112.7 billion tokens. We implement a checkpoint selection strategy that evaluates downstream retrieval performance throughout training, revealing that optimal checkpoints achieve best retrieval scores before pre-training loss reaches its minimum. Our encoder models achieve top-3 rankings on the Turkish retrieval leaderboard, with smaller models (155M parameters) achieving comparable performance to larger reference models (307M-567M parameters). Our approach achieves 92.36% production efficiency compared to state-of-the-art models (embeddinggemma-300m: 100.00%, BAAI/bge-m3: 99.54%, newmindai/bge-m3-stsb: 94.38%), ranking fourth overall despite requiring less computational resources. SOTA models rely on multi-stage, computationally intensive training pipelines, making our single-stage pre-training followed by efficient post-training approach a cost-effective alternative; (2)Decoder Model with Continual Pre-training (CPT): Qwen3-1.7B and Qwen3-4B models adapted to Turkish legal domain through controlled curriculum learning. Four-phase CPT with optimal sample ratios enables gradual transition from general language knowledge to specialized legal terminology and long-context reasoning. This approach achieves 36.2% perplexity reduction on Turkish legal text, demonstrating domain adaptation gains.

</details>


### [96] [Universal Refusal Circuits Across LLMs: Cross-Model Transfer via Trajectory Replay and Concept-Basis Reconstruction](https://arxiv.org/abs/2601.16034)
*Tony Cristofano*

Main category: cs.CL

TL;DR: 提出Trajectory Replay via Concept-Basis Reconstruction框架，通过概念指纹对齐和概念原子的共享“配方”，将捐赠模型的拒绝干预转移到目标模型，证明拒绝行为源于跨模型的通用低维语义电路。


<details>
  <summary>Details</summary>
Motivation: 对齐语言模型中的拒绝行为通常被视为模型特定的，但作者假设其源于跨模型共享的通用低维语义电路，并旨在通过干预转移来验证这一假设。

Method: 通过概念指纹对齐层，用共享概念原子重建拒绝方向，将捐赠模型的消融轨迹映射到目标模型的语义空间；引入权重-SVD稳定性保护，将干预投影远离高方差权重子空间以防止能力损伤。

Result: 在8个模型对（包括GPT-OSS-20B和GLM-4）上的评估表明，转移的干预配方能持续减弱拒绝行为并保持性能，为安全对齐的语义普遍性提供了强有力证据。

Conclusion: 拒绝行为并非模型特有，而是源于跨不同架构和训练体制的通用低维语义电路，这为安全对齐机制的理解和跨模型干预提供了新视角。

Abstract: Refusal behavior in aligned LLMs is often viewed as model-specific, yet we hypothesize it stems from a universal, low-dimensional semantic circuit shared across models. To test this, we introduce Trajectory Replay via Concept-Basis Reconstruction, a framework that transfers refusal interventions from donor to target models, spanning diverse architectures (e.g., Dense to MoE) and training regimes, without using target-side refusal supervision. By aligning layers via concept fingerprints and reconstructing refusal directions using a shared ``recipe'' of concept atoms, we map the donor's ablation trajectory into the target's semantic space. To preserve capabilities, we introduce a weight-SVD stability guard that projects interventions away from high-variance weight subspaces to prevent collateral damage. Our evaluation across 8 model pairs (including GPT-OSS-20B and GLM-4) confirms that these transferred recipes consistently attenuate refusal while maintaining performance, providing strong evidence for the semantic universality of safety alignment.

</details>


### [97] [Adapter Fusion for Multilingual Text2Cypher with Linear and Learned Gating](https://arxiv.org/abs/2601.16097)
*Makbule Gulcin Ozsoy*

Main category: cs.CL

TL;DR: 提出了一个可扩展的多语言Text2Cypher系统，通过训练特定语言的LoRA适配器并采用融合MLP进行组合，无需重新进行完全微调即可支持新语言。


<details>
  <summary>Details</summary>
Motivation: 现有Text2SQL类系统主要关注英语，多语言支持有限。本研究旨在开发可扩展的多语言Text2Cypher方法，避免手动超参数调优和完全微调，同时保持接近联合多语言微调的性能。

Method: 为英语、西班牙语和土耳其语分别训练语言特定的LoRA适配器，然后通过均匀线性合并或学习融合MLP（带动态门控）进行组合。

Result: 融合MLP方法恢复了联合多语言微调约75%的准确率提升，且仅需要较小的数据子集，在所有三种语言上都优于线性合并。

Conclusion: 学习适配器融合为昂贵的联合微调提供了实用替代方案，在性能、数据效率和可扩展性之间取得平衡，支持通过仅需一个LoRA适配器和轻量级MLP重新训练来增量扩展新语言。

Abstract: Large Language Models enable users to access database using natural language interfaces using tools like Text2SQL, Text2SPARQL, and Text2Cypher, which translate user questions into structured database queries. While these systems improve database accessibility, most research focuses on English with limited multilingual support. This work investigates a scalable multilingual Text2Cypher, aiming to support new languages without re-running full fine-tuning, avoiding manual hyper-parameter tuning, and maintaining performance close to joint multilingual fine-tuning. We train language-specific LoRA adapters for English, Spanish, and Turkish and combined them via uniform linear merging or learned fusion MLP with dynamic gating. Experimental results show that the fusion MLP recovers around 75\% of the accuracy gains from joint multilingual fine-tuning while requiring only a smaller subset of the data, outperforming linear merging across all three languages. This approach enables incremental language expansion to new languages by requiring only one LoRA adapter and a lightweight MLP retraining. Learned adapter fusion offers a practical alternative to expensive joint fine-tuning, balancing performance, data efficiency, and scalability for multilingual Text2Cypher task.

</details>


### [98] [synthocr-gen: A synthetic ocr dataset generator for low-resource languages- breaking the data barrier](https://arxiv.org/abs/2601.16113)
*Haq Nawaz Malik,Kh Mohmad Shafi,Tanveer Ahmad Reshi*

Main category: cs.CL

TL;DR: SynthOCR-Gen是一个开源合成OCR数据集生成器，专为低资源语言设计，通过从数字文本语料库生成训练数据来解决标注数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 低资源语言（如克什米尔语）的OCR面临标注数据集稀缺的挑战，主流OCR系统缺乏支持，手动创建数据集成本高且耗时。

Method: 开发了一个包含文本分割、Unicode规范化、多字体渲染和25种以上数据增强技术的完整流水线，模拟真实文档退化情况。

Result: 成功生成了包含60万个样本的克什米尔语OCR数据集并公开发布，展示了该工具的有效性。

Conclusion: 该工具为低资源语言进入视觉-语言AI模型时代提供了实用途径，有助于全球未充分支持的书写系统的OCR开发。

Abstract: Optical Character Recognition (OCR) for low-resource languages remains a significant challenge due to the scarcity of large-scale annotated training datasets. Languages such as Kashmiri, with approximately 7 million speakers and a complex Perso-Arabic script featuring unique diacritical marks, currently lack support in major OCR systems including Tesseract, TrOCR, and PaddleOCR. Manual dataset creation for such languages is prohibitively expensive, time-consuming, and error-prone, often requiring word by word transcription of printed or handwritten text.
  We present SynthOCR-Gen, an open-source synthetic OCR dataset generator specifically designed for low-resource languages. Our tool addresses the fundamental bottleneck in OCR development by transforming digital Unicode text corpora into ready-to-use training datasets. The system implements a comprehensive pipeline encompassing text segmentation (character, word, n-gram, sentence, and line levels), Unicode normalization with script purity enforcement, multi-font rendering with configurable distribution, and 25+ data augmentation techniques simulating real-world document degradations including rotation, blur, noise, and scanner artifacts.
  We demonstrate the efficacy of our approach by generating a 600,000-sample word-segmented Kashmiri OCR dataset, which we release publicly on HuggingFace. This work provides a practical pathway for bringing low-resource languages into the era of vision-language AI models, and the tool is openly available for researchers and practitioners working with underserved writing systems worldwide.

</details>


### [99] [Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging](https://arxiv.org/abs/2601.16127)
*Alphaeus Dmonte,Vidhi Gupta,Daniel J Perry,Mark Arehart*

Main category: cs.CL

TL;DR: 该研究分析了多语言大语言模型合并策略的效率，相比全量重训练可以显著减少50%的训练时间和60%以上的维护成本，同时在质量上保持相当水平。


<details>
  <summary>Details</summary>
Motivation: 传统多语言大语言模型需要同时对所有语言进行训练，在更新或新增语言支持时需重训练整个模型，计算成本高且维护困难，缺乏高效的维护策略研究。

Method: 采用多语言多任务模型合并策略，在三种独立任务上进行评估，分析其在训练和维护阶段的效率，并与传统全语言训练方法对比。

Result: 模型合并方法可将初始训练时间减少最多50%，在更新单个语言后重新合并比全量重训练减少60%以上的训练成本，在公开和工业数据集上都验证了有效性。

Conclusion: 多语言模型合并策略在保持质量的同时显著提高了训练和维护效率，适用于工业应用场景，为解决多语言模型维护瓶颈提供了可行方案。

Abstract: Fine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50\%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60\%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work.

</details>


### [100] [Automatic Classification of Arabic Literature into Historical Eras](https://arxiv.org/abs/2601.16138)
*Zainab Alhathloul,Irfan Ahmad*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Arabic language has undergone notable transformations over time, including the emergence of new vocabulary, the obsolescence of others, and shifts in word usage. This evolution is evident in the distinction between the classical and modern Arabic eras. Although historians and linguists have partitioned Arabic literature into multiple eras, relatively little research has explored the automatic classification of Arabic texts by time period, particularly beyond the domain of poetry. This paper addresses this gap by employing neural networks and deep learning techniques to automatically classify Arabic texts into distinct eras and periods. The proposed models are evaluated using two datasets derived from two publicly available corpora, covering texts from the pre-Islamic to the modern era. The study examines class setups ranging from binary to 15-class classification and considers both predefined historical eras and custom periodizations. Results range from F1-scores of 0.83 and 0.79 on the binary-era classification task using the OpenITI and APCD datasets, respectively, to 0.20 on the 15-era classification task using OpenITI and 0.18 on the 12-era classification task using APCD.

</details>


### [101] [LLM-in-Sandbox Elicits General Agentic Intelligence](https://arxiv.org/abs/2601.16206)
*Daixuan Cheng,Shaohan Huang,Yuxian Gu,Huatong Song,Guoxin Chen,Li Dong,Wayne Xin Zhao,Ji-Rong Wen,Furu Wei*

Main category: cs.CL

TL;DR: LLM-in-Sandbox 让 LLMs 在代码沙箱（虚拟计算机）内探索，激发其在非代码领域的一般智能。研究表明强LLM无需额外训练就能利用代码沙箱完成非代码任务，且通过强化学习可以进一步增强这种能力。该方法在多个领域展示了强大的泛化能力，并被开源为Python包。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型（LLMs）在非代码领域的一般智能能力，特别是在缺乏明确训练的情况下如何利用代码沙箱环境解决各种复杂任务。

Method: 1. LLM-in-Sandbox：让LLMs在代码沙箱中自主探索和操作；2. LLM-in-Sandbox-RL：使用非智能体数据进行强化学习训练，增强沙箱探索能力。

Result: 1. 强LLMs能够自发利用外部资源获取新知识、使用文件系统处理长上下文、执行脚本满足格式要求；2. 该方法在数学、物理、化学、生物医学、长上下文理解和指令遵循等多个领域展现了稳健的泛化能力；3. 从计算和系统角度分析了效率问题。

Conclusion: LLM-in-Sandbox 能够有效激发LLMs在非代码领域的智能，无论是免训练还是后训练模式都能实现广泛的任务泛化。该方法已开源为Python包便于实际部署，为大语言模型的应用提供了新的范式。

Abstract: We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization capabilities to leverage the code sandbox for non-code tasks. For example, LLMs spontaneously access external resources to acquire new knowledge, leverage the file system to handle long contexts, and execute scripts to satisfy formatting requirements. We further show that these agentic capabilities can be enhanced through LLM-in-Sandbox Reinforcement Learning (LLM-in-Sandbox-RL), which uses only non-agentic data to train models for sandbox exploration. Experiments demonstrate that LLM-in-Sandbox, in both training-free and post-trained settings, achieves robust generalization spanning mathematics, physics, chemistry, biomedicine, long-context understanding, and instruction following. Finally, we analyze LLM-in-Sandbox's efficiency from computational and system perspectives, and open-source it as a Python package to facilitate real-world deployment.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [102] [Agentic Persona Control and Task State Tracking for Realistic User Simulation in Interactive Scenarios](https://arxiv.org/abs/2601.15290)
*Hareeshwar Karthikeyan*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Testing conversational AI systems at scale across diverse domains necessitates realistic and diverse user interactions capturing a wide array of behavioral patterns. We present a novel multi-agent framework for realistic, explainable human user simulation in interactive scenarios, using persona control and task state tracking to mirror human cognitive processes during goal-oriented conversations. Our system employs three specialized AI agents: (1) a User Agent to orchestrate the overall interaction, (2) a State Tracking Agent to maintain structured task state, and (3) a Message Attributes Generation Agent that controls conversational attributes based on task progress and assigned persona. To validate our approach, we implement and evaluate the framework for guest ordering at a restaurant with scenarios rich in task complexity, behavioral diversity, and conversational ambiguity. Through systematic ablations, we evaluate the contributory efficacy of each agentic component to overall simulation quality in terms of persona adherence, task completion accuracy, explainability, and realism. Our experiments demonstrate that the complete multi-agent system achieves superior simulation quality compared to single-LLM baselines, with significant gains across all evaluation metrics. This framework establishes a powerful environment for orchestrating agents to simulate human users with cognitive plausibility, decomposing the simulation into specialized sub-agents that reflect distinct aspects of human thought processes applicable across interactive domains.

</details>


### [103] [Public transport challenges and technology-assisted accessibility for visually impaired elderly residents in urban environments](https://arxiv.org/abs/2601.15291)
*Jason Pan,Ben Moews*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Independent navigation is a core aspect of maintaining social participation and individual health for vulnerable populations. While historic cities such as Edinburgh, as the capital of Scotland, often feature well-established public transport systems, urban accessibility challenges remain and are exacerbated by a complex landscape, especially for groups with multiple vulnerabilities such as the blind elderly. With limited research examining how real-time data feeds and developments in artificial intelligence can enhance navigation aids, we address this gap through a mixed-methods approach. Our work combines statistical and machine learning techniques, with a focus on spatial analysis to investigate network coverage, service patterns, and density through live Transport for Edinburgh data, with a qualitative thematic analysis of semi-structured interviews with the mentioned target group. The results demonstrate the highly centralised nature of the city's transport system, the significance of memory-based navigation, and the lack of travel information in usable formats. We also find that participants already use navigation technology to varying degrees and express a willingness to adopt artificial intelligence. Our analysis highlights the importance of dynamic tools in terms of sensory and cognitive needs to meaningfully improve independent travel.

</details>


### [104] [A Mobile Application Front-End for Presenting Explainable AI Results in Diabetes Risk Estimation](https://arxiv.org/abs/2601.15292)
*Bernardus Willson,Henry Anand Septian Radityo,Reynard Tanadi,Latifa Dwiyanti,Saiful Akbar*

Main category: cs.HC

TL;DR: 本研究开发了一个移动应用前端，将XAI驱动的糖尿病风险分析以直观的柱状图、饼图和GPT-4o生成的文本叙述形式呈现，提升了非专业用户的理解能力。


<details>
  <summary>Details</summary>
Motivation: 印尼糖尿病问题日益严峻，现有AI健康应用大多为'黑盒'，缺乏预测透明度，而XAI的技术输出对非专业用户难以理解，因此需要开发直观的可解释界面。

Method: 采用瀑布模型开发Android原生应用，通过用户调研确定柱状图和饼图为主要可视化方式，集成GPT-4o生成个性化文本叙述，将SHAP解释转化为可访问的图形和叙述。

Result: 用户理解测试平均得分4.31/5，技术功能测试成功率100%，可视化与文本叙述结合有效增强了用户理解并促进了预防行动。

Conclusion: 结合可视化图表和AI生成文本叙述的移动应用前端成功将XAI解释转化为非专业用户可理解的形式，提高了糖尿病风险分析的透明度和用户赋能效果。

Abstract: Diabetes is a significant and continuously rising health challenge in Indonesia. Although many artificial intelligence (AI)-based health applications have been developed for early detection, most function as "black boxes," lacking transparency in their predictions. Explainable AI (XAI) methods offer a solution, yet their technical outputs are often incomprehensible to non-expert users. This research aims to develop a mobile application front-end that presents XAI-driven diabetes risk analysis in an intuitive, understandable format. Development followed the waterfall methodology, comprising requirements analysis, interface design, implementation, and evaluation. Based on user preference surveys, the application adopts two primary visualization types - bar charts and pie charts - to convey the contribution of each risk factor. These are complemented by personalized textual narratives generated via integration with GPT-4o. The application was developed natively for Android using Kotlin and Jetpack Compose. The resulting prototype interprets SHAP (SHapley Additive exPlanations), a key XAI approach, into accessible graphical visualizations and narratives. Evaluation through user comprehension testing (Likert scale and interviews) and technical functionality testing confirmed the research objectives were met. The combination of visualization and textual narrative effectively enhanced user understanding (average score 4.31/5) and empowered preventive action, supported by a 100% technical testing success rate.

</details>


### [105] [Social Robotics for Disabled Students: An Empirical Investigation of Embodiment, Roles and Interaction](https://arxiv.org/abs/2601.15293)
*Alva Markelius,Fethiye Irmak Doğan,Julie Bailey,Guy Laban,Jenny L. Gibson,Hatice Gunes*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Institutional and social barriers in higher education often prevent students with disabilities from effectively accessing support, including lengthy procedures, insufficient information, and high social-emotional demands. This study empirically explores how disabled students perceive robot-based support, comparing two interaction roles, one information based (signposting) and one disclosure based (sounding board), and two embodiment types (physical robot/disembodied voice agent). Participants assessed these systems across five dimensions: perceived understanding, social energy demands, information access/clarity, task difficulty, and data privacy concerns. The main findings of the study reveal that the physical robot was perceived as more understanding than the voice-only agent, with embodiment significantly shaping perceptions of sociability, animacy, and privacy. We also analyse differences between disability types. These results provide critical insights into the potential of social robots to mitigate accessibility barriers in higher education, while highlighting ethical, social and technical challenges.

</details>


### [106] [KnowTeX: Visualizing Mathematical Dependencies](https://arxiv.org/abs/2601.15294)
*Elif Uskuplu,Lawrence S. Moss,Valeria de Paiva*

Main category: cs.HC

TL;DR: KnowTeX是一个帮助可视化数学文档中概念依赖关系的工具，通过直接在LaTeX源文件中标记“使用”关系来生成依赖图，弥合非正式教科书与形式化证明系统之间的鸿沟。


<details>
  <summary>Details</summary>
Motivation: 数学知识存在于多种形式中，从非正式的教科书和讲义到大型形式化证明库，但在这些表示之间移动依然困难。非正式文本隐藏了依赖关系，而形式化系统则暴露了不总是人类可读的所有细节。依赖图提供了一个中间地带，使结果、定义和证明的结构变得可见。

Method: 开发了KnowTeX这一独立、用户友好的工具，扩展了Lean Blueprints的理念，直接从LaTeX源文件中可视化概念依赖关系。通过简单的“uses”命令，KnowTeX提取语句之间的关系，并以DOT和TikZ格式生成可预览的图。

Result: 应用于数学文本时，这样的依赖图能阐明核心结果，支持教育和形式化工作，并为对齐非正式和形式化数学表示提供了资源。

Conclusion: 依赖图应成为数学写作的标准功能，使人类读者和自动化系统都能受益。

Abstract: Mathematical knowledge exists in many forms, ranging from informal textbooks and lecture notes to large formal proof libraries, yet moving between these representations remains difficult. Informal texts hide dependencies, while formal systems expose every detail in ways that are not always human-readable. Dependency graphs offer a middle ground by making visible the structure of results, definitions, and proofs. We present KnowTeX, a standalone, user-friendly tool that extends the ideas of Lean's Blueprints, enabling the visualization of conceptual dependencies directly from LaTeX sources. Using a simple "uses" command, KnowTeX extracts relationships among statements and generates previewable graphs in DOT and TikZ formats. Applied to mathematical texts, such graphs clarify core results, support education and formalization, and provide a resource for aligning informal and formal mathematical representations. We argue that dependency graphs should become a standard feature of mathematical writing, benefiting both human readers and automated systems.

</details>


### [107] [Elsewise: Authoring AI-Based Interactive Narrative with Possibility Space Visualization](https://arxiv.org/abs/2601.15295)
*Yi Wang,John Joon Young Chung,Melissa Roemmele,Yuqian Sun,Tiffany Wang,Shm Garanganao Almeda,Brett A. Halperin,Yuwen Lu,Max Kreminski*

Main category: cs.HC

TL;DR: Elsewise是一个基于AI的交互式叙事创作工具，采用Bundled Storyline概念帮助创作者更好地理解和控制叙事可能性空间，弥合作者预期与玩家体验之间的差距。


<details>
  <summary>Details</summary>
Motivation: 生成式AI虽然能根据玩家开放式输入即兴扩展预创作内容，但会扩大作者预期故事与玩家实际体验故事之间的差距，限制情节进展的力度和作者叙事意图的传达。

Method: 提出Bundled Storyline概念，使作者能够通过用户可配置的叙事维度探索不同游戏流程之间的相似性和差异性，从而增强对叙事可能性空间的感知和理解。

Result: 用户研究（n=12）表明，该方法提高了作者对玩家体验叙事的预期性，从而更有效地控制和探索叙事可能性空间。

Conclusion: Elsewise通过增强作者对叙事可能性空间的理解，成功弥合了AI生成的交互式叙事中作者意图与玩家体验之间的鸿沟。

Abstract: Interactive narrative (IN) authors craft spaces of divergent narrative possibilities for players to explore, with the player's input determining which narrative possibilities they actually experience. Generative AI can enable new forms of IN by improvisationally expanding on pre-authored content in response to open-ended player input. However, this extrapolation risks widening the gap between author-envisioned and player-experienced stories, potentially limiting the strength of plot progression and the communication of the author's narrative intent. To bridge the gap, we introduce Elsewise: an authoring tool for AI-based INs that implements a novel Bundled Storyline concept to enhance author's perception and understanding of the narrative possibility space, allowing authors to explore similarities and differences between possible playthroughs of their IN in terms of open-ended, user-configurable narrative dimensions. A user study (n=12) shows that our approach improves author anticipation of player-experienced narrative, leading to more effective control and exploration of the narrative possibility spaces.

</details>


### [108] [When Generative AI Meets Extended Reality: Enabling Scalable and Natural Interactions](https://arxiv.org/abs/2601.15308)
*Mingyu Zhu,Jiangong Chen,Bin Li*

Main category: cs.HC

TL;DR: XR技术面临3D内容创作成本高、交互学习陡峭的挑战，生成式AI通过语言驱动交互和自动化内容生成提供解决方案


<details>
  <summary>Details</summary>
Motivation: XR应用推广受限于3D内容创作的高成本复杂性和非直观交互方式的陡峭学习曲线，需要降低使用门槛

Method: 利用视觉语言模型和基于扩散的生成技术，通过语言驱动的交互理解和生成/操控3D内容

Result: 通过三个具体用例展示了XR与生成式AI融合如何解决可扩展性和自然交互的核心障碍

Conclusion: 生成式AI能显著降低XR采用门槛，但仍需解决技术挑战以实现更广泛的应用

Abstract: Extended Reality (XR), including virtual, augmented, and mixed reality, provides immersive and interactive experiences across diverse applications, from VR-based education to AR-based assistance and MR-based training. However, widespread XR adoption remains limited due to two key challenges: 1) the high cost and complexity of authoring 3D content, especially for large-scale environments or complex interactions; and 2) the steep learning curve associated with non-intuitive interaction methods like handheld controllers or scripted gestures. Generative AI (GenAI) presents a promising solution by enabling intuitive, language-driven interaction and automating content generation. Leveraging vision-language models and diffusion-based generation, GenAI can interpret ambiguous instructions, understand physical scenes, and generate or manipulate 3D content, significantly lowering barriers to XR adoption. This paper explores the integration of XR and GenAI through three concrete use cases, showing how they address key obstacles in scalability and natural interaction, and identifying technical challenges that must be resolved to enable broader adoption.

</details>


### [109] [VegaChat: A Robust Framework for LLM-Based Chart Generation and Assessment](https://arxiv.org/abs/2601.15385)
*Marko Hostnik,Rauf Kurbanov,Yaroslav Sokolov,Artem Trofimov*

Main category: cs.HC

TL;DR: 论文提出的VegaChat框架通过引入Spec Score和Vision Score两个互补的评估指标，解决了NL2VIS领域缺乏标准化评估标准和自然语言查询歧义性的问题，实现了高质量的可视化生成与评估。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的自然语言转可视化(NL2VIS)系统面临两个耦合挑战：(1)缺乏标准化评估指标，难以衡量技术进步和比较不同方法；(2)自然语言描述本质上存在歧义，同一查询可能对应多个有效可视化方案。这些问题限制了NL2VIS系统的进一步发展和应用。

Method: 提出VegaChat框架，包含两个核心评估指标：Spec Score（基于规范级别的确定性相似度度量，不依赖LLM）和Vision Score（库无关的基于图像的度量，利用多模态LLM评估图表相似度和提示符合度）。在NLV Corpus和ChartLLM标注子集上进行评估。

Result: VegaChat实现了接近零的无效或空可视化生成率；Spec Score和Vision Score与人类判断表现出强相关性（Pearson相关系数分别为0.65和0.71），表明提出的指标支持跨库的一致性比较。

Conclusion: VegaChat框架通过创新的评估指标有效解决了NL2VIS领域的评估标准化和查询歧义性问题，为领域提供了可靠的评估基准，支持跨库比较和进步衡量。

Abstract: Natural-language-to-visualization (NL2VIS) systems based on large language models (LLMs) have substantially improved the accessibility of data visualization. However, their further adoption is hindered by two coupled challenges: (i) the absence of standardized evaluation metrics makes it difficult to assess progress in the field and compare different approaches; and (ii) natural language descriptions are inherently underspecified, so multiple visualizations may be valid for the same query. To address these issues, we introduce VegaChat, a framework for generating, validating, and assessing declarative visualizations from natural language.
  We propose two complementary metrics: Spec Score, a deterministic metric that measures specification-level similarity without invoking an LLM, and Vision Score, a library-agnostic, image-based metric that leverages a multimodal LLM to assess chart similarity and prompt compliance.
  We evaluate VegaChat on the NLV Corpus and on the annotated subset of ChartLLM. VegaChat achieves near-zero rates of invalid or empty visualizations, while Spec Score and Vision Score exhibit strong correlation with human judgments (Pearson 0.65 and 0.71, respectively), indicating that the proposed metrics support consistent, cross-library comparison.
  The code and evaluation artifacts are available at https://zenodo.org/records/17062309.

</details>


### [110] [A Checklist for Trustworthy, Safe, and User-Friendly Mental Health Chatbots](https://arxiv.org/abs/2601.15412)
*Shreya Haran,Samiha Thatikonda,Dong Whi Yoo,Koustuv Saha*

Main category: cs.HC

TL;DR: 随着全球心理健康需求增加，心理健康聊天机器人作为补充方案日益受关注。本文通过文献综述揭示当前设计及实施中的关键缺陷，并提出实用检查清单以促进更可靠、安全、用户友好的设计。


<details>
  <summary>Details</summary>
Motivation: 全球心理健康服务存在供需失衡，心理健康聊天机器人被视为潜在解决方案，但其安全性、有效性和潜在危害尚未经过充分检验，亟需系统化的设计指导框架。

Method: 通过文献综述识别心理健康聊天机器人设计与实施中的关键空白，在此基础上开发出一套操作性检查清单，该清单可作为开发框架和审计工具，确保设计符合伦理且有效。

Result: 提出一份结构化检查清单，能够指导开发人员设计更值得信赖、安全、用户友好的心理健康聊天机器人，并支持建立对社会技术层面合理的数字心理健康工具标准。

Conclusion: 该检查清单是推动更负责任的设计实践、建立数字心理健康工具新标准的重要一步，有助于提升心理健康聊天机器人的可靠性和社会接受度。

Abstract: Mental health concerns are rising globally, prompting increased reliance on technology to address the demand-supply gap in mental health services. In particular, mental health chatbots are emerging as a promising solution, but these remain largely untested, raising concerns about safety and potential harms. In this paper, we dive into the literature to identify critical gaps in the design and implementation of mental health chatbots. We contribute an operational checklist to help guide the development and design of more trustworthy, safe, and user-friendly chatbots. The checklist serves as both a developmental framework and an auditing tool to ensure ethical and effective chatbot design. We discuss how this checklist is a step towards supporting more responsible design practices and supporting new standards for sociotechnically sound digital mental health tools.

</details>


### [111] [Exploring Implicit Perspectives on Autism in Large Language Models Through Multi-Agent Simulations](https://arxiv.org/abs/2601.15437)
*Sohyeon Park,Jesus Armando Beltran,Aehong Min,Anamara Ritt-Olson,Gillian R. Hayes*

Main category: cs.HC

TL;DR: 研究发现ChatGPT等大语言模型可能存在对自闭症的偏见，认为自闭症患者具有社会依赖性，这会影响模型与自闭症用户的互动。研究采用多智能体系统模拟复杂社交场景，提出通过双共情问题改进LLM设计以减少偏见。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型为自闭症患者提供支持具有潜力，但需要理解模型对自闭症可能存在的隐性偏见和假设，确保其交互的公平性和有效性。

Method: 采用基于LLM的多智能体系统模拟涉及自闭症和非自闭症智能体的复杂社交场景，通过群体任务对话和结构化访谈问题分析ChatGPT的偏见及其对自闭症的概念化方式。

Result: 研究发现ChatGPT倾向于假设自闭症患者具有社会依赖性，这可能影响其与自闭症用户的互动方式以及关于自闭症的信息传递。

Conclusion: 未来LLM可以通过将双共情问题纳入设计来减少观察到的偏见，改善涉及自闭症人群的交互，该框架将沟通障碍重新定义为共同挑战。

Abstract: Large Language Models (LLMs) like ChatGPT offer potential support for autistic people, but this potential requires understanding the implicit perspectives these models might carry, including their biases and assumptions about autism. Moving beyond single-agent prompting, we utilized LLM-based multi-agent systems to investigate complex social scenarios involving autistic and non-autistic agents. In our study, agents engaged in group-task conversations and answered structured interview questions, which we analyzed to examine ChatGPT's biases and how it conceptualizes autism. We found that ChatGPT assumes autistic people are socially dependent, which may affect how it interacts with autistic users or conveys information about autism. To address these challenges, we propose adopting the double empathy problem, which reframes communication breakdowns as a mutual challenge. We describe how future LLMs could address the biases we observed and improve interactions involving autistic people by incorporating the double empathy problem into their design.

</details>


### [112] [Reflexis: Supporting Reflexivity and Rigor in Collaborative Qualitative Analysis through Design for Deliberation](https://arxiv.org/abs/2601.15445)
*Runlong Ye,Oliver Huang,Patrick Yung Kang Lee,Michael Liut,Carolina Nobre,Ha-Kyung Kong*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reflexive Thematic Analysis (RTA) is a critical method for generating deep interpretive insights. Yet its core tenets, including researcher reflexivity, tangible analytical evolution, and productive disagreement, are often poorly supported by software tools that prioritize speed and consensus over interpretive depth. To address this gap, we introduce Reflexis, a collaborative workspace that centers these practices. It supports reflexivity by integrating in-situ reflection prompts, makes code evolution transparent and tangible, and scaffolds collaborative interpretation by turning differences into productive, positionality-aware dialogue. Results from our paired-analyst study (N=12) indicate that Reflexis encouraged participants toward more granular reflection and reframed disagreements as productive conversations. The evaluation also surfaced key design tensions, including a desire for higher-level, networked memos and more user control over the timing of proactive alerts. Reflexis contributes a design framework for tools that prioritize rigor and transparency to support deep, collaborative interpretation in an age of automation.

</details>


### [113] [Shape of You: Implications of Social Context and Avatar Body Shape on Relatedness, Emotions, and Performance in a Virtual Reality Workout](https://arxiv.org/abs/2601.15466)
*Jana Franceska Funke,Ria Matapurkar,Enrico Rukzio,Teresa Hirzle*

Main category: cs.HC

TL;DR: 这篇论文探讨情绪与动机的相互关系，强调情绪对工作场所动机的重要影响。


<details>
  <summary>Details</summary>
Motivation: 作者认为情绪是动机的因果变量，能激发状态、力量和能量来促进行为。动机不只基于需求，还受情绪、意图、目标及实现手段影响。

Method: 1. 总结情绪理论和定义
2. 探索情绪与动机的双向关系：情绪影响动机，动机影响情绪
3. 从认知、情感和意志三个维度考虑动机
4. 分析管理人员在维持良好情绪氛围中的作用

Result: 提出了情绪与动机相互影响的理论框架，强调工作场所情绪管理的重要性。

Conclusion: 必须重视动机中的情绪因素，管理人员和员工都需要培养相应技能，保持平衡的情绪氛围以最大化个人和团队的职场动机。

Abstract: It is obvious that emotions are causal variables of motivation, as they elicit states, forces and energies that trigger and guide labor behavior. Thus, a motivational tension that is not informed by needs alone, but also by emotions, intention, goals and means to achieve them is therefore generated within the mental, emotional and physical plane. Based on Montserrat's opinion (2004: 131), that "to motivate means, above all, to move and to transmit an emotion", we will undertake to identify the mutual influences between emotions and motivation. The main objectives of this article are to display a summary of the theories and definitions about emotions and to explore the links between emotions and motivation. Although interconnected, emotions and motivation can be contemplated from a double perspective: (1) emotions influence motivation and (2) motivation influences emotions. Moreover, we will consider motivation from three dimensions: (1) cognitive, (2) affective and (3) volitional. The ultimate purpose of this article is to issue a warning as to the importance of the emotional side of motivation. An important part in implementing such insight is to be played by managers (and by employees, also), who should develop the skills and know-how needed to keep a well-balanced emotional climate that effectively favors the maximization of individual and group motivation at the workplace.

</details>


### [114] [Put Your Muscle Into It: Introducing XEM2, a Novel Approach for Monitoring Exertion in Stationary Physical Exercises Leveraging Muscle Work](https://arxiv.org/abs/2601.15472)
*Jana Franceska Funke,Mario Sagawa,Georgious Nurcan-Georgiou,Naomi Sagawa,Dennis Dietz,Evgeny Stemasov,Enrico Rukzio,Teresa Hirzle*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a novel system for camera-based measurement and visualization of muscle work based on the Hill-Type-Muscle-Model: the exercise exertion muscle-work monitor (\textit{XEM}$^{2}$). Our aim is to complement and, thus, address issues of established measurement techniques that offer imprecise data for non-uniform movements (burned calories) or provide limited information on strain across different body parts (self-perception scales). We validate the reliability of XEM's measurements through a technical evaluation of ten participants and five exercises. Further, we assess the acceptance, usefulness, benefits, and opportunities of \textit{XEM}$^{2}$ in an empirical user study. Our results show that \textit{XEM}$^{2}$ provides reliable values of muscle work and supports participants in understanding their workout while also providing reliable information about perceived exertion per muscle group. With this paper, we introduce a novel system capable of measuring and visualizing exertion for single muscle groups, which has the potential to improve exercise monitoring to prevent unbalanced workouts.

</details>


### [115] [PromptHelper: A Prompt Recommender System for Encouraging Creativity in AI Chatbot Interactions](https://arxiv.org/abs/2601.15575)
*Jason Kim,Maria Teleki,James Caverlee*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Prompting is central to interaction with AI systems, yet many users struggle to explore alternative directions, articulate creative intent, or understand how variations in prompts shape model outputs. We introduce prompt recommender systems (PRS) as an interaction approach that supports exploration, suggesting contextually relevant follow-up prompts. We present PromptHelper, a PRS prototype integrated into an AI chatbot that surfaces semantically diverse prompt suggestions while users work on real writing tasks. We evaluate PromptHelper in a 2x2 fully within-subjects study (N=32) across creative and academic writing tasks. Results show that PromptHelper significantly increases users' perceived exploration and expressiveness without increasing cognitive workload. Qualitative findings illustrate how prompt recommendations help users branch into new directions, overcome uncertainty about what to ask next, and better articulate their intent. We discuss implications for designing AI interfaces that scaffold exploratory interaction while preserving user agency, and release open-source resources to support research on prompt recommendation.

</details>


### [116] [Tackling the Scaffolding Paradox: A Person-Centered Adaptive Robotic Interview Coach](https://arxiv.org/abs/2601.15600)
*Wanqi Zhang,Jiangen He,Marielle Santos*

Main category: cs.HC

TL;DR: 本文通过三个阶段研究社交机器人面试教练系统，发现在人本疗法(PCT)基础上引入用户自主控制反馈的方式，能有效平衡心理安全感和教学指导，显著降低面试焦虑。


<details>
  <summary>Details</summary>
Motivation: 面试焦虑是大学生普遍面临的问题，社交机器人虽能提供情感支持，但如何在保持心理安全感的同时进行有效教学指导仍是一个开放问题。

Method: 采用基于人本疗法(PCT)和教学支架理论的三阶段迭代设计研究，通过三周会话(N=8)，系统探索不同互动策略如何影响用户情感体验、认知负荷和感知效用。

Result: PCT基机器人增强了心理安全感但存在安全感-指导间隙；即时反馈提高了清晰度但增加了认知负荷；引入用户自主控制反馈机制后，显著降低了面试相关的社交和沟通焦虑，同时保持了高感知温暖度和治疗联盟。

Conclusion: 提出了自适应支架生态系统框架，强调用户自主权是平衡社交机器人教练系统中情感支持和教学指导的关键机制。

Abstract: Job interview anxiety is a prevalent challenge among university students and can undermine both performance and confidence in high-stakes evaluative situations. Social robots have shown promise in reducing anxiety through emotional support, yet how such systems should balance psychological safety with effective instructional guidance remains an open question. In this work, we present a three-phase iterative design study of a robotic interview coach grounded in Person-Centered Therapy (PCT) and instructional scaffolding theory. Across three weekly sessions (N=8), we systematically explored how different interaction strategies shape users' emotional experience, cognitive load, and perceived utility. Phase I demonstrated that a PCT-based robot substantially increased perceived psychological safety but introduced a Safety-Guidance Gap, in which users felt supported yet insufficiently coached. Phase II revealed a Scaffolding Paradox: immediate feedback improved clarity but disrupted conversational flow and increased cognitive load, whereas delayed feedback preserved realism but lacked actionable specificity. To resolve this tension, Phase III introduced an Agency-Driven Interaction Mode that allowed users to opt in to feedback dynamically. Qualitative findings indicated that user control acted as an anxiety buffer, restoring trust, reducing overload, and reframing the interaction as collaborative rather than evaluative. Quantitative measures further showed significant reductions in interview-related social and communication anxiety, while maintaining high perceived warmth and therapeutic alliance. We synthesize these findings into an Adaptive Scaffolding Ecosystem framework, highlighting user agency as a key mechanism for balancing emotional support and instructional guidance in social robot coaching systems.

</details>


### [117] [Reflective Motion and a Physical Canvas: Exploring Embodied Journaling in Virtual Reality](https://arxiv.org/abs/2601.15656)
*Michael Yin,Robert Xiao,Nadine Wagener*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In traditional journaling practices, authors express and process their thoughts by writing them down. We propose a somaesthetic-inspired alternative that uses the human body, rather than written words, as the medium of expression. We coin this embodied journaling, as people's isolated body movements and spoken words become the canvas of reflection. We implemented embodied journaling in virtual reality and conducted a within-subject user study (n=20) to explore the emergent behaviours from the process and to compare its expressive and reflective qualities to those of written journaling. When writing-based norms and affordances were absent, we found that participants defaulted towards unfiltered emotional expression, often forgoing words altogether. Rather, subconscious body motion and paralinguistic acoustic qualities unveiled deeper, sometimes hidden feelings, prompting reflection that happens after emotional expression rather than during it. We discuss both the capabilities and pitfalls of embodied journaling, ultimately challenging the idea that reflection culminates in linguistic reasoning.

</details>


### [118] [Replicating Human Motivated Reasoning Studies with LLMs](https://arxiv.org/abs/2601.16130)
*Neeley Pate,Adiba Mahbub Proma,Hangfeng He,James N. Druckman,Daniel Molden,Gourab Ghoshal,Ehsan Hoque*

Main category: cs.HC

TL;DR: 基础LLM在政治动机推理中未展现人类行为特征，且不同模型间存在相似偏差，这对使用LLM自动化任务的研究者具有警示意义。


<details>
  <summary>Details</summary>
Motivation: 人类动机推理现象已有充分研究，但尚不清楚基础LLM是否也会模仿这种动机变化。

Method: 复现了4项先前的政治动机推理研究，分析基础LLM在不同政治动机场景下的行为表现。

Result: 发现基础LLM行为与预期人类行为不一致，不同模型间存在相似特征，如标准差较小、论点强度评估不准确等。

Conclusion: 强调这些发现对使用LLM自动化调查研究等任务的研究者具有重要意义，需谨慎评估LLM的适用性。

Abstract: Motivated reasoning -- the idea that individuals processing information may be motivated to reach a certain conclusion, whether it be accurate or predetermined -- has been well-explored as a human phenomenon. However, it is unclear whether base LLMs mimic these motivational changes. Replicating 4 prior political motivated reasoning studies, we find that base LLM behavior does not align with expected human behavior. Furthermore, base LLM behavior across models shares some similarities, such as smaller standard deviations and inaccurate argument strength assessments. We emphasize the importance of these findings for researchers using LLMs to automate tasks such as survey data collection and argument assessment.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [119] [Delayed Assignments in Online Non-Centroid Clustering with Stochastic Arrivals](https://arxiv.org/abs/2601.16091)
*Saar Cohen*

Main category: cs.MA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Clustering is a fundamental problem, aiming to partition a set of elements, like agents or data points, into clusters such that elements in the same cluster are closer to each other than to those in other clusters. In this paper, we present a new framework for studying online non-centroid clustering with delays, where elements, that arrive one at a time as points in a finite metric space, should be assigned to clusters, but assignments need not be immediate. Specifically, upon arrival, each point's location is revealed, and an online algorithm has to irrevocably assign it to an existing cluster or create a new one containing, at this moment, only this point. However, we allow decisions to be postponed at a delay cost, instead of following the more common assumption of immediate decisions upon arrival. This poses a critical challenge: the goal is to minimize both the total distance costs between points in each cluster and the overall delay costs incurred by postponing assignments. In the classic worst-case arrival model, where points arrive in an arbitrary order, no algorithm has a competitive ratio better than sublogarithmic in the number of points. To overcome this strong impossibility, we focus on a stochastic arrival model, where points' locations are drawn independently across time from an unknown and fixed probability distribution over the finite metric space. We offer hope for beyond worst-case adversaries: we devise an algorithm that is constant competitive in the sense that, as the number of points grows, the ratio between the expected overall costs of the output clustering and an optimal offline clustering is bounded by a constant.

</details>


### [120] [Average Unfairness in Routing Games](https://arxiv.org/abs/2601.16187)
*Pan-Yang Su,Arwa Alanqary,Bryce L. Ferguson,Manxi Wu,Alexandre M. Bayen,Shankar Sastry*

Main category: cs.MA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose average unfairness as a new measure of fairness in routing games, defined as the ratio between the average latency and the minimum latency experienced by users. This measure is a natural complement to two existing unfairness notions: loaded unfairness, which compares maximum and minimum latencies of routes with positive flow, and user equilibrium (UE) unfairness, which compares maximum latency with the latency of a Nash equilibrium. We show that the worst-case values of all three unfairness measures coincide and are characterized by a steepness parameter intrinsic to the latency function class. We show that average unfairness is always no greater than loaded unfairness, and the two measures are equal only when the flow is fully fair. Besides that, we offer a complete comparison of the three unfairness measures, which, to the best of our knowledge, is the first theoretical analysis in this direction. Finally, we study the constrained system optimum (CSO) problem, where one seeks to minimize total latency subject to an upper bound on unfairness. We prove that, for the same tolerance level, the optimal flow under an average unfairness constraint achieves lower total latency than any flow satisfying a loaded unfairness constraint. We show that such improvement is always strict in parallel-link networks and establish sufficient conditions for general networks. We further illustrate the latter with numerical examples. Our results provide theoretical guarantees and valuable insights for evaluating fairness-efficiency tradeoffs in network routing.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [121] [Gated Sparse Attention: Combining Computational Efficiency with Training Stability for Long-Context Language Models](https://arxiv.org/abs/2601.15305)
*Alfred Shen,Aaron Shen*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The computational burden of attention in long-context language models has motivated two largely independent lines of work: sparse attention mechanisms that reduce complexity by attending to selected tokens, and gated attention variants that improve training sta-bility while mitigating the attention sink phenomenon. We observe that these approaches address complementary weaknesses and propose Gated Sparse Attention (GSA), an architecture that realizes the benefits of both. GSA incorporates a gated lightning indexer with sigmoid activations that produce bounded, interpretable selection scores, an adaptive sparsity controller that modulates the number of attended tokens based on local uncertainty, and dual gating at the value and output stages. We establish theoretical foundations for the approach, including complexity analysis, expressiveness results, and convergence guarantees. In experiments with 1.7B parameter models trained on 400B tokens, GSA matches the efficiency of sparse-only baselines (12-16x speedup at 128K context) while achieving the quality gains associated with gated attention: perplexity improves from 6.03 to 5.70, RULER scores at 128K context nearly double, and attention to the first token, a proxy for attention sinks, drops from 47% to under 4%. Training stability improves markedly, with loss spikes reduced by 98%.

</details>


### [122] [DeepSurvey-Bench: Evaluating Academic Value of Automatically Generated Scientific Survey](https://arxiv.org/abs/2601.15307)
*Guo-Biao Zhang,Ding-Yuan Liu,Da-Yi Wu,Tian Lan,Heyan Huang,Zhijing Wu,Xian-Ling Mao*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rapid development of automated scientific survey generation technology has made it increasingly important to establish a comprehensive benchmark to evaluate the quality of generated surveys.Nearly all existing evaluation benchmarks rely on flawed selection criteria such as citation counts and structural coherence to select human-written surveys as the ground truth survey datasets, and then use surface-level metrics such as structural quality and reference relevance to evaluate generated surveys.However, these benchmarks have two key issues: (1) the ground truth survey datasets are unreliable because of a lack academic dimension annotations; (2) the evaluation metrics only focus on the surface quality of the survey such as logical coherence. Both issues lead to existing benchmarks cannot assess to evaluate their deep "academic value", such as the core research objectives and the critical analysis of different studies. To address the above problems, we propose DeepSurvey-Bench, a novel benchmark designed to comprehensively evaluate the academic value of generated surveys. Specifically, our benchmark propose a comprehensive academic value evaluation criteria covering three dimensions: informational value, scholarly communication value, and research guidance value. Based on this criteria, we construct a reliable dataset with academic value annotations, and evaluate the deep academic value of the generated surveys. Extensive experimental results demonstrate that our benchmark is highly consistent with human performance in assessing the academic value of generated surveys.

</details>


### [123] [MiRAGE: A Multiagent Framework for Generating Multimodal Multihop Question-Answer Dataset for RAG Evaluation](https://arxiv.org/abs/2601.15487)
*Chandan Kumar Sahu,Premith Kumar Chilukuri,Matthew Hetrich*

Main category: cs.AI

TL;DR: MiRAGE是一个用于RAG系统评估的多智能体框架，能够自动生成经过验证的领域特定、多模态、多跳问答数据集，解决现有基准无法涵盖专业领域复杂性的问题


<details>
  <summary>Details</summary>
Motivation: 当前RAG技术快速向多模态、高风险企业应用演进，但领域特定评估基准的发展滞后。现有数据集通常基于通用领域语料或纯文本检索，无法捕捉专业技术文档中信息多模态且推理需要综合分散证据的复杂性

Method: MiRAGE采用多智能体框架，包括：递归上下文优化循环聚合分散证据、对抗性验证智能体确保事实基础、识别专家角色和相关领域的智能体来模仿专家认知工作流程

Result: 在四个不同领域（法规、金融、定量生物学和新闻）的广泛实验评估表明，MiRAGE生成的数据集具有显著更高的推理复杂性（>2.3平均跳数）和事实忠实度。消融研究显示如果图像的文本描述可用，MiRAGE可由LLM驱动，但视觉基础仍是一个前沿挑战

Conclusion: 通过自动化创建反映专有语料潜在主题结构的黄金标准评估数据集，MiRAGE为严格基准测试下一代信息检索系统提供了必要的基础设施

Abstract: The rapid evolution of Retrieval-Augmented Generation (RAG) toward multimodal, high-stakes enterprise applications has outpaced the development of domain specific evaluation benchmarks. Existing datasets often rely on general-domain corpora or purely textual retrieval, failing to capture the complexity of specialized technical documents where information is inextricably multimodal and reasoning requires synthesizing disjoint evidence. We address this gap by introducing MiRAGE, a Multiagent framework for RAG systems Evaluation, that leverages a collaborative swarm of specialized agents to generate verified, domain-specific, multimodal, and multi-hop Question-Answer datasets. MiRAGE orchestrates a swarm of specialized agents: a recursive context optimization loop to aggregate scattered evidence, an adversarial verifier agent to guarantee factual grounding, and an agent to recognize the expert persona and the relevant domain to mimic expert cognitive workflows. Extensive empirical evaluation across four distinct domains (regulations, finance, quantitative biology, and journalism) demonstrates that MiRAGE generates datasets with significantly higher reasoning complexity (>2.3 average hops) and factual faithfulness. Our ablation studies point that MiRAGE can be powered by LLMs if textual descriptions of the images are available. Visual grounding still remains a frontier. By automating the creation of gold standard evaluation datasets that reflect the latent thematic structure of proprietary corpora, MiRAGE provides the necessary infrastructure to rigorously benchmark the next generation information retrieval systems.

</details>


### [124] [Aeon: High-Performance Neuro-Symbolic Memory Management for Long-Horizon LLM Agents](https://arxiv.org/abs/2601.15311)
*Mustafa Arslan*

Main category: cs.AI

TL;DR: Aeon神经符号认知操作系统通过结构化存储和预测缓存机制，解决LLM在长上下文中的计算效率与记忆一致性问题


<details>
  <summary>Details</summary>
Motivation: 传统LLM面临注意力计算复杂度高和长上下文推理能力下降的问题，现有向量检索方法无法处理层次化时间结构，导致记忆碎片化

Method: 提出Aeon系统，包含记忆宫殿（空间索引）和神经符号事件图，引入语义旁视缓冲预测缓存机制，采用零拷贝C++/Python桥接

Result: 在会话工作负载中实现1毫秒以下检索延迟，通过空间索引减少读取放大，保持状态一致性

Conclusion: Aeon作为认知操作系统，为自主智能体提供持久化、结构化的记忆管理解决方案，有效解决向量迷雾问题

Abstract: Large Language Models (LLMs) are fundamentally constrained by the quadratic computational cost of self-attention and the "Lost in the Middle" phenomenon, where reasoning capabilities degrade as context windows expand. Existing solutions, primarily "Flat RAG" architectures relying on vector databases, treat memory as an unstructured bag of embeddings. This approach fails to capture the hierarchical and temporal structure of long-horizon interactions, leading to "Vector Haze", the retrieval of disjointed facts lacking episodic continuity. We propose Aeon, a Neuro-Symbolic Cognitive Operating System that redefines memory not as a static store, but as a managed OS resource. Aeon structures memory into a Memory Palace (a spatial index implemented via Atlas, a SIMD-accelerated Page-Clustered Vector Index that combines small-world graph navigation with B+ Tree-style disk locality to minimize read amplification) and a Trace (a neuro-symbolic episodic graph). We introduce the Semantic Lookaside Buffer (SLB), a predictive caching mechanism that exploits conversational locality to achieve sub-millisecond retrieval latencies. Benchmarks demonstrate that Aeon achieves < 1ms retrieval latency on conversational workloads while ensuring state consistency via a zero-copy C++/Python bridge, effectively enabling persistent, structured memory for autonomous agents.

</details>


### [125] [The Paradigm Shift: A Comprehensive Survey on Large Vision Language Models for Multimodal Fake News Detection](https://arxiv.org/abs/2601.15316)
*Wei Ai,Yilong Tan,Yuntao Shou,Tao Meng,Haowen Chen,Zhixiong He,Keqin Li*

Main category: cs.AI

TL;DR: 这篇综述论文系统回顾了大视觉语言模型如何变革多模态假新闻检测领域，从传统特征工程方法转向统一的端到端多模态推理框架。


<details>
  <summary>Details</summary>
Motivation: 多模态假新闻检测领域近年来经历从传统特征工程方法到大视觉语言模型驱动范式的重大转变，但缺乏对这一变革过程的系统梳理和综述。论文旨在填补这一空白，系统记录和分析LVLMs在多模态假新闻检测中的变革性作用。

Method: 采用历史视角追溯从传统多模态检测流程到基础模型驱动范式的演变，建立结构化分类体系涵盖模型架构、数据集和性能基准，并分析现有技术挑战和未来研究方向。

Result: 这是首个系统记录和分析LVLMs在多模态假新闻检测中变革作用的综合综述，提供了该领域的结构化分类、技术挑战分析和未来发展路线图。

Conclusion: 大视觉语言模型正在从根本上改变多模态假新闻检测的范式，但仍面临可解释性、时序推理和领域泛化等挑战。论文为这一范式转变的下一个阶段提供了系统指导。

Abstract: In recent years, the rapid evolution of large vision-language models (LVLMs) has driven a paradigm shift in multimodal fake news detection (MFND), transforming it from traditional feature-engineering approaches to unified, end-to-end multimodal reasoning frameworks. Early methods primarily relied on shallow fusion techniques to capture correlations between text and images, but they struggled with high-level semantic understanding and complex cross-modal interactions. The emergence of LVLMs has fundamentally changed this landscape by enabling joint modeling of vision and language with powerful representation learning, thereby enhancing the ability to detect misinformation that leverages both textual narratives and visual content. Despite these advances, the field lacks a systematic survey that traces this transition and consolidates recent developments. To address this gap, this paper provides a comprehensive review of MFND through the lens of LVLMs. We first present a historical perspective, mapping the evolution from conventional multimodal detection pipelines to foundation model-driven paradigms. Next, we establish a structured taxonomy covering model architectures, datasets, and performance benchmarks. Furthermore, we analyze the remaining technical challenges, including interpretability, temporal reasoning, and domain generalization. Finally, we outline future research directions to guide the next stage of this paradigm shift. To the best of our knowledge, this is the first comprehensive survey to systematically document and analyze the transformative role of LVLMs in combating multimodal fake news. The summary of existing methods mentioned is in our Github: \href{https://github.com/Tan-YiLong/Overview-of-Fake-News-Detection}{https://github.com/Tan-YiLong/Overview-of-Fake-News-Detection}.

</details>


### [126] [Prometheus Mind: Retrofitting Memory to Frozen Language Models](https://arxiv.org/abs/2601.15324)
*Mark Wind*

Main category: cs.AI

TL;DR: 该研究提出Prometheus Mind系统，通过11个模块化适配器（530MB）为冻结的Qwen3-4B语言模型添加可逆记忆功能，解决了存储提取、训练优化、信息注入和隐藏状态崩溃四个关键技术问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法为预训练语言模型添加记忆通常需要修改模型架构或权重，本工作旨在开发一种轻量级、可逆的适配器方案，在不改变基础模型的情况下实现记忆功能。

Method: 1) 开发CDD方法通过最小对比对发现语义方向，无需标注数据；2) 采用分阶段训练策略，避免端到端优化崩溃；3) 利用lm_head.weight的现有映射，无需额外训练编码器；4) 训练投影层解决Transformer隐藏状态相似度过高的问题。

Result: 在PrometheusExtract-132数据集上，系统在干净输入上达到94.4%检索准确率，但在含省略、填充词或隐含主语的非正式输入上降至19.4%。主要瓶颈是关系分类任务（47.3%准确率）。

Conclusion: Prometheus Mind成功实现了对冻结语言模型的轻量级记忆扩展，但现有系统在处理非正式语言时性能显著下降，关系分类是需要改进的关键环节。

Abstract: Adding memory to pretrained language models typically requires architectural changes or weight modification. We present Prometheus Mind, which retrofits memory to a frozen Qwen3-4B using 11 modular adapters (530MB, 7% overhead) -- fully reversible by removing the adapters. Building this system required solving four problems: (1) Extraction -- we develop Contrastive Direction Discovery (CDD), which finds semantic directions via minimal pairs without labeled data. (2) Training -- end-to-end optimization collapses; stage-wise training of each adapter on simple proxy tasks succeeds. (3) Injection -- learned encoders fail to generalize; we find that lm_head.weight rows already provide the mapping we need, requiring no training. (4) Hidden state collapse -- transformers make ``wife'' and ``brother'' 0.98+ similar; we train projections to recover distinction (0.98 $\rightarrow$ 0.09). On PrometheusExtract-132 (132 cases), the system achieves 94.4% retrieval on clean inputs (n=54, 95% CI: [84.9%, 98.1%]), degrading to 19.4% on informal inputs with ellipsis, filler words, or implicit subjects (n=36). The primary bottleneck is relation classification (47.3% accuracy), responsible for most extraction errors.

</details>


### [127] [Beyond Prompting: Efficient and Robust Contextual Biasing for Speech LLMs via Logit-Space Integration (LOGIC)](https://arxiv.org/abs/2601.15397)
*Peidong Wang*

Main category: cs.AI

TL;DR: LOGIC是一个直接在解码层操作的语音LLM上下文偏置框架，无需提示即可识别特定实体名称，具有高效性和鲁棒性的特点。


<details>
  <summary>Details</summary>
Motivation: 现有语音大语言模型在识别领域特定实体（如联系人名、播放列表、技术术语）方面存在局限性，而现有解决方案（如提示和生成式错误校正）存在扩展性差、延迟高和过校正等问题。

Method: LOGIC（Logit-Space Integration for Contextual Biasing）通过在解码层直接操作，将上下文注入与输入处理解耦，确保相对于提示长度的恒定时间复杂度的框架。

Result: 在11个多语言地区使用Phi-4-MM模型的实验表明，LOGIC实现了平均9%的相对实体词错误率降低，而误报率仅增加0.30%。

Conclusion: LOGIC提供了一种高效且鲁棒的方法来解决语音LLM的实体识别问题，通过解码层操作避免了现有方法的扩展性和准确性问题。

Abstract: The rapid emergence of new entities -- driven by cultural shifts, evolving trends, and personalized user data -- poses a significant challenge for existing Speech Large Language Models (Speech LLMs). While these models excel at general conversational tasks, their static training knowledge limits their ability to recognize domain-specific terms such as contact names, playlists, or technical jargon. Existing solutions primarily rely on prompting, which suffers from poor scalability: as the entity list grows, prompting encounters context window limitations, increased inference latency, and the "lost-in-the-middle" phenomenon. An alternative approach, Generative Error Correction (GEC), attempts to rewrite transcripts via post-processing but frequently suffers from "over-correction", introducing hallucinations of entities that were never spoken.
  In this work, we introduce LOGIC (Logit-Space Integration for Contextual Biasing), an efficient and robust framework that operates directly in the decoding layer. Unlike prompting, LOGIC decouples context injection from input processing, ensuring constant-time complexity relative to prompt length. Extensive experiments using the Phi-4-MM model across 11 multilingual locales demonstrate that LOGIC achieves an average 9% relative reduction in Entity WER with a negligible 0.30% increase in False Alarm Rate.

</details>


### [128] [Not Your Typical Sycophant: The Elusive Nature of Sycophancy in Large Language Models](https://arxiv.org/abs/2601.15436)
*Shahar Ben Natan,Oren Tsur*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose a novel way to evaluate sycophancy of LLMs in a direct and neutral way, mitigating various forms of uncontrolled bias, noise, or manipulative language, deliberately injected to prompts in prior works. A key novelty in our approach is the use of LLM-as-a-judge, evaluation of sycophancy as a zero-sum game in a bet setting. Under this framework, sycophancy serves one individual (the user) while explicitly incurring cost on another. Comparing four leading models - Gemini 2.5 Pro, ChatGpt 4o, Mistral-Large-Instruct-2411, and Claude Sonnet 3.7 - we find that while all models exhibit sycophantic tendencies in the common setting, in which sycophancy is self-serving to the user and incurs no cost on others, Claude and Mistral exhibit "moral remorse" and over-compensate for their sycophancy in case it explicitly harms a third party. Additionally, we observed that all models are biased toward the answer proposed last. Crucially, we find that these two phenomena are not independent; sycophancy and recency bias interact to produce `constructive interference' effect, where the tendency to agree with the user is exacerbated when the user's opinion is presented last.

</details>


### [129] [Reliability by design: quantifying and eliminating fabrication risk in LLMs. From generative to consultative AI: a comparative analysis in the legal domain and lessons for high-stakes knowledge bases](https://arxiv.org/abs/2601.15476)
*Alex Dantart*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper examines how to make large language models reliable for high-stakes legal work by reducing hallucinations. It distinguishes three AI paradigms: (1) standalone generative models ("creative oracle"), (2) basic retrieval-augmented systems ("expert archivist"), and (3) an advanced, end-to-end optimized RAG system ("rigorous archivist"). The authors introduce two reliability metrics -False Citation Rate (FCR) and Fabricated Fact Rate (FFR)- and evaluate 2,700 judicial-style answers from 12 LLMs across 75 legal tasks using expert, double-blind review. Results show that standalone models are unsuitable for professional use (FCR above 30%), while basic RAG greatly reduces errors but still leaves notable misgrounding. Advanced RAG, using techniques such as embedding fine-tuning, re-ranking, and self-correction, reduces fabrication to negligible levels (below 0.2%). The study concludes that trustworthy legal AI requires rigor-focused, retrieval-based architectures emphasizing verification and traceability, and provides an evaluation framework applicable to other high-risk domains.

</details>


### [130] [Tracking the Limits of Knowledge Propagation: How LLMs Fail at Multi-Step Reasoning with Conflicting Knowledge](https://arxiv.org/abs/2601.15495)
*Yiyang Feng,Zeming Chen,Haotian Wu,Jiawei Zhou,Antoine Bosselut*

Main category: cs.AI

TL;DR: 论文提出了TRACK基准测试，用于评估大语言模型在处理新旧知识冲突时的多步推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前的基准测试主要关注单一知识更新和事实回忆，但缺乏对知识更新如何影响下游推理的系统性评估。现有的知识更新方法在模型参数知识与新增知识冲突时，会导致知识冲突传播到错误推理中。

Method: 创建TRACK基准测试，涵盖三个推理密集型场景（WIKI、CODE和MATH），设计多个现实的知识冲突，模拟真实世界复杂性。通过对比模型在不同数量知识更新下的推理表现，分析性能变化。

Result: 实验显示，向模型提供更新的知识用于推理，反而比不提供更新的知识表现更差。这种性能下降随着提供的更新知识增多而加剧。失败原因包括：无法忠实地集成更新知识；即使知识被集成，推理本身也存在缺陷。

Conclusion: TRACK为新知识与模型参数知识冲突时的多步推理传播问题提供了一个严谨的基准测试，可为未来相关研究提供测量方向和指导。

Abstract: A common solution for mitigating outdated or incorrect information in Large Language Models (LLMs) is to provide updated facts in-context or through knowledge editing. However, these methods introduce knowledge conflicts when the knowledge update fails to overwrite the model's parametric knowledge, which propagate to faulty reasoning. Current benchmarks for this problem, however, largely focus only on single knowledge updates and fact recall without evaluating how these updates affect downstream reasoning. In this work, we introduce TRACK (Testing Reasoning Amid Conflicting Knowledge), a new benchmark for studying how LLMs propagate new knowledge through multi-step reasoning when it conflicts with the model's initial parametric knowledge. Spanning three reasoning-intensive scenarios (WIKI, CODE, and MATH), TRACK introduces multiple, realistic conflicts to mirror real-world complexity. Our results on TRACK reveal that providing updated facts to models for reasoning can worsen performance compared to providing no updated facts to a model, and that this performance degradation exacerbates as more updated facts are provided. We show this failure stems from both inability to faithfully integrate updated facts, but also flawed reasoning even when knowledge is integrated. TRACK provides a rigorous new benchmark to measure and guide future progress on propagating conflicting knowledge in multi-step reasoning.

</details>


### [131] [The Dark Side of AI Transformers: Sentiment Polarization & the Loss of Business Neutrality by NLP Transformers](https://arxiv.org/abs/2601.15509)
*Prasanna Kumar*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The use of Transfer Learning & Transformers has steadily improved accuracy and has significantly contributed in solving complex computation problems. However, this transformer led accuracy improvement in Applied AI Analytics specifically in sentiment analytics comes with the dark side. It is observed during experiments that a lot of these improvements in transformer led accuracy of one class of sentiment has been at the cost of polarization of another class of sentiment and the failing of neutrality. This lack of neutrality poses an acute problem in the Applied NLP space, which relies heavily on the computational outputs of sentiment analytics for reliable industry ready tasks.

</details>


### [132] [TransportAgents: a multi-agents LLM framework for traffic accident severity prediction](https://arxiv.org/abs/2601.15519)
*Zhichao Yang,Jiashu He,Jinxuan Fan,Cirillo Cinzia*

Main category: cs.AI

TL;DR: 提出TransportAgents：一个结合特定领域LLM推理与MLP集成模块的混合多智能体框架，用于提高交通事故严重程度预测的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型虽然具备强大的推理能力，但其单智能体架构在处理异质的、领域特定的交通事故数据时，往往难以稳定生成预测，且容易产生偏差。

Method: 设计一个多智能体框架，每个专业智能体专注于特定类别的交通信息（如人口统计、环境背景或事故细节），生成中间严重程度评估，然后通过多层感知机（MLP）进行融合。

Result: 在两个互补的美国数据集（CPSRMS和NEISS）上进行的实验表明，该框架在GPT-3.5、GPT-4o和LLaMA-3.3等代表性骨干模型上均优于传统机器学习和先进的基于LLM的基线方法，表现出强鲁棒性、可扩展性和跨数据集泛化能力。

Conclusion: TransportAgents能够比标准的单智能体LLM方法产生更均衡和校准良好的严重程度预测，为安全关键决策支持应用提供了更高的可解释性和可靠性。

Abstract: Accurate prediction of traffic crash severity is critical for improving emergency response and public safety planning. Although recent large language models (LLMs) exhibit strong reasoning capabilities, their single-agent architectures often struggle with heterogeneous, domain-specific crash data and tend to generate biased or unstable predictions. To address these limitations, this paper proposes TransportAgents, a hybrid multi-agent framework that integrates category-specific LLM reasoning with a multilayer perceptron (MLP) integration module. Each specialized agent focuses on a particular subset of traffic information, such as demographics, environmental context, or incident details, to produce intermediate severity assessments that are subsequently fused into a unified prediction. Extensive experiments on two complementary U.S. datasets, the Consumer Product Safety Risk Management System (CPSRMS) and the National Electronic Injury Surveillance System (NEISS), demonstrate that TransportAgents consistently outperforms both traditional machine learning and advanced LLM-based baselines. Across three representative backbones, including closed-source models such as GPT-3.5 and GPT-4o, as well as open-source models such as LLaMA-3.3, the framework exhibits strong robustness, scalability, and cross-dataset generalizability. A supplementary distributional analysis further shows that TransportAgents produces more balanced and well-calibrated severity predictions than standard single-agent LLM approaches, highlighting its interpretability and reliability for safety-critical decision support applications.

</details>


### [133] [Autonomous Business System via Neuro-symbolic AI](https://arxiv.org/abs/2601.15599)
*Cecil Pang,Hiroki Sayama*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Current business environments require organizations to continuously reconfigure cross-functional processes, yet enterprise systems are still organized around siloed departments, rigid workflows, and hard-coded automation. Meanwhile large language models (LLMs) excel at interpreting natural language and unstructured data but lack deterministic, verifiable execution of complex business logic. To address this gap, here we introduce AUTOBUS, an Autonomous Business System that integrates LLM-based AI agents, predicate-logic programming, and business-semantics-centric enterprise data into a coherent neuro-symbolic AI architecture for orchestrating end-to-end business initiatives. AUTOBUS models an initiative as a network of tasks with explicit pre/post conditions, required data, evaluation rules, and API-level actions. Enterprise data is organized as a knowledge graph whose entities, relationships, and constraints are translated into logic facts and foundational rules, providing the semantic grounding for task reasoning. Core AI agents synthesize task instructions, enterprise semantics, and available tools into task-specific logic programs, which are executed by a logic engine that enforces constraints, coordinates auxiliary tools, and orchestrate execution of actions and outcomes. Humans define and maintain the semantics, policies and task instructions, curate tools, and supervise high-impact or ambiguous decisions, ensuring accountability and adaptability. We detail the AUTOBUS architecture, the anatomy of the AI agent generated logic programs, and the role of humans and auxiliary tools in the lifecycle of a business initiative.

</details>


### [134] [CogToM: A Comprehensive Theory of Mind Benchmark inspired by Human Cognition for Large Language Models](https://arxiv.org/abs/2601.15628)
*Haibo Tong,Zeyang Yue,Feifei Zhao,Erliang Lin,Lu Jia,Ruolin Chen,Yinqian Sun,Qian Zhang,Yi Zeng*

Main category: cs.AI

TL;DR: 本文介绍了一个全面的理论驱动基准CogToM，包含8000多个双语实例和46种范式，用于评估LLMs是否具有类似人类的心智理论能力，发现前沿模型存在显著性能异质性和认知结构差异。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型心智理论评估基准主要局限于误信念测试等狭窄范式，无法全面捕捉人类认知机制的全貌，需要更全面、理论基础更强的评估工具。

Method: 研究者开发了CogToM基准，包含超过8000个双语实例，涵盖46种心智理论范式，并由49名人类标注者验证，然后系统性评估了22个代表性模型（包括GPT-5.1和Qwen3-Max等前沿模型）。

Result: 评估结果显示模型性能存在显著异质性，在特定维度上存在持续性瓶颈，基于人类认知模式的分析表明LLMs与人类认知结构可能存在差异。

Conclusion: CogToM为研究LLMs不断演化的认知边界提供了一个强有力的工具和视角。

Abstract: Whether Large Language Models (LLMs) truly possess human-like Theory of Mind (ToM) capabilities has garnered increasing attention. However, existing benchmarks remain largely restricted to narrow paradigms like false belief tasks, failing to capture the full spectrum of human cognitive mechanisms. We introduce CogToM, a comprehensive, theoretically grounded benchmark comprising over 8000 bilingual instances across 46 paradigms, validated by 49 human annotator.A systematic evaluation of 22 representative models, including frontier models like GPT-5.1 and Qwen3-Max, reveals significant performance heterogeneities and highlights persistent bottlenecks in specific dimensions. Further analysis based on human cognitive patterns suggests potential divergences between LLM and human cognitive structures. CogToM offers a robust instrument and perspective for investigating the evolving cognitive boundaries of LLMs.

</details>


### [135] [Predictive Coding and Information Bottleneck for Hallucination Detection in Large Language Models](https://arxiv.org/abs/2601.15652)
*Manish Bhatt*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Hallucinations in Large Language Models (LLMs) -- generations that are plausible but factually unfaithful -- remain a critical barrier to high-stakes deployment. Current detection methods typically rely on computationally expensive external retrieval loops or opaque black-box LLM judges requiring 70B+ parameters. In this work, we introduce [Model Name], a hybrid detection framework that combines neuroscience-inspired signal design with supervised machine learning. We extract interpretable signals grounded in Predictive Coding (quantifying surprise against internal priors) and the Information Bottleneck (measuring signal retention under perturbation). Through systematic ablation, we demonstrate three key enhancements: Entity-Focused Uptake (concentrating on high-value tokens), Context Adherence (measuring grounding strength), and Falsifiability Score (detecting confident but contradictory claims).
  Evaluating on HaluBench (n=200, perfectly balanced), our theory-guided baseline achieves 0.8017 AUROC. BASE supervised models reach 0.8274 AUROC, while IMPROVED features boost performance to 0.8669 AUROC (4.95% gain), demonstrating consistent improvements across architectures. This competitive performance is achieved while using 75x less training data than Lynx (200 vs 15,000 samples), 1000x faster inference (5ms vs 5s), and remaining fully interpretable. Crucially, we report a negative result: the Rationalization signal fails to distinguish hallucinations, suggesting that LLMs generate coherent reasoning for false premises ("Sycophancy").
  This work demonstrates that domain knowledge encoded in signal architecture provides superior data efficiency compared to scaling LLM judges, achieving strong performance with lightweight (less than 1M parameter), explainable models suitable for production deployment.

</details>


### [136] [From Passive Metric to Active Signal: The Evolving Role of Uncertainty Quantification in Large Language Models](https://arxiv.org/abs/2601.15690)
*Jiaxin Zhang,Wendi Cui,Zhuohang Li,Lifu Huang,Bradley Malin,Caiming Xiong,Chien-Sheng Wu*

Main category: cs.AI

TL;DR: 这篇综述探讨了将不确定性从被动诊断指标发展为主动控制信号的功能演化，强调了它在提升LLM可靠性中的三个应用前沿：高级推理优化、自主智能体决策和强化学习改进。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型展现出强大能力，但其不可靠性仍是高风险领域部署的关键障碍，需要通过创新方法来提升模型的可信度和可靠性。

Method: 通过综述分析，将不确定性作为主动控制信号应用于三大前沿：1）高级推理中的计算优化和自我纠正触发；2）自主智能体的元认知决策（工具使用和信息寻求）；3）强化学习中的奖励破解缓解和基于内在奖励的自我改进。这些方法基于贝叶斯方法和一致性预测等新兴理论框架。

Result: 研究表明不确定性作为主动控制信号能显著提升模型在计算效率、决策可靠性和奖励机制稳定性方面的表现，为构建可扩展、可靠和可信的下一代AI提供了统一视角。

Conclusion: 掌握不确定性作为主动控制信号的新趋势对于构建下一代可扩展、可靠且可信的人工智能至关重要，该综述为这一领域提供了全面概述、批判性分析和实用设计模式。

Abstract: While Large Language Models (LLMs) show remarkable capabilities, their unreliability remains a critical barrier to deployment in high-stakes domains. This survey charts a functional evolution in addressing this challenge: the evolution of uncertainty from a passive diagnostic metric to an active control signal guiding real-time model behavior. We demonstrate how uncertainty is leveraged as an active control signal across three frontiers: in \textbf{advanced reasoning} to optimize computation and trigger self-correction; in \textbf{autonomous agents} to govern metacognitive decisions about tool use and information seeking; and in \textbf{reinforcement learning} to mitigate reward hacking and enable self-improvement via intrinsic rewards. By grounding these advancements in emerging theoretical frameworks like Bayesian methods and Conformal Prediction, we provide a unified perspective on this transformative trend. This survey provides a comprehensive overview, critical analysis, and practical design patterns, arguing that mastering the new trend of uncertainty is essential for building the next generation of scalable, reliable, and trustworthy AI.

</details>


### [137] [Benchmarking Text-to-Python against Text-to-SQL: The Impact of Explicit Logic and Ambiguity](https://arxiv.org/abs/2601.15728)
*Hangle Hu,Chenyu Hou,Bin Cao,Ruizhe Li*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: While Text-to-SQL remains the dominant approach for database interaction, real-world analytics increasingly require the flexibility of general-purpose programming languages such as Python or Pandas to manage file-based data and complex analytical workflows. Despite this growing need, the reliability of Text-to-Python in core data retrieval remains underexplored relative to the mature SQL ecosystem. To address this gap, we introduce BIRD-Python, a benchmark designed for cross-paradigm evaluation. We systematically refined the original dataset to reduce annotation noise and align execution semantics, thereby establishing a consistent and standardized baseline for comparison. Our analysis reveals a fundamental paradigmatic divergence: whereas SQL leverages implicit DBMS behaviors through its declarative structure, Python requires explicit procedural logic, making it highly sensitive to underspecified user intent. To mitigate this challenge, we propose the Logic Completion Framework (LCF), which resolves ambiguity by incorporating latent domain knowledge into the generation process. Experimental results show that (1) performance differences primarily stem from missing domain context rather than inherent limitations in code generation, and (2) when these gaps are addressed, Text-to-Python achieves performance parity with Text-to-SQL. These findings establish Python as a viable foundation for analytical agents-provided that systems effectively ground ambiguous natural language inputs in executable logical specifications. Resources are available at https://anonymous.4open.science/r/Bird-Python-43B7/.

</details>


### [138] [PhysProver: Advancing Automatic Theorem Proving for Physics](https://arxiv.org/abs/2601.15737)
*Hanning Zhang,Ruida Wang,Rui Pan,Wenyuan Wang,Bingxu Meng,Tong Zhang*

Main category: cs.AI

TL;DR: 本文提出了首个针对物理领域的强化学习定理证明方法PhysProver，通过专用数据集PhysLeanData和强化学习训练，在物理定理证明上取得显著性能提升，并能泛化到数学领域。


<details>
  <summary>Details</summary>
Motivation: 当前在验证语言与LLMs结合的研究主要集中在数学定理证明，而形式化物理推理虽依赖类似的问题解决和定理证明框架，却鲜有研究关注。本文旨在填补这一空白，扩展形式化证明器到非数学领域。

Method: 构建专门的物理定理数据集PhysLeanData，基于DeepSeek-Prover-V2-7B模型，采用强化学习与可验证奖励（RLVR）训练PhysProver模型。

Result: 仅使用约5K训练样本，PhysProver在多个物理子领域整体提升2.4%，在MiniF2F-Test基准测试上提升1.3%，显示出超出物理领域的泛化能力和形式数学能力的增强。

Conclusion: 该方法有效且高效，为将形式化证明器扩展到数学以外领域提供了范例，将公开数据集和模型以促进进一步研究。

Abstract: The combination of verifiable languages and LLMs has significantly influenced both the mathematical and computer science communities because it provides a rigorous foundation for theorem proving. Recent advancements in the field provide foundation models and sophisticated agentic systems pushing the boundaries of formal mathematical reasoning to approach the natural language capability of LLMs. However, little attention has been given to the formal physics reasoning, which also heavily relies on similar problem-solving and theorem-proving frameworks. To solve this problem, this paper presents, to the best of our knowledge, the first approach to enhance formal theorem proving in the physics domain. We compose a dedicated dataset PhysLeanData for the task. It is composed of theorems sampled from PhysLean and data generated by a conjecture-based formal data generation pipeline. In the training pipeline, we leverage DeepSeek-Prover-V2-7B, a strong open-source mathematical theorem prover, and apply Reinforcement Learning with Verifiable Rewards (RLVR) to train our model PhysProver. Comprehensive experiments demonstrate that, using only $\sim$5K training samples, PhysProver achieves an overall 2.4\% improvement in multiple sub-domains. Furthermore, after formal physics training, we observe 1.3\% gains on the MiniF2F-Test benchmark, which indicates non-trivial generalization beyond physics domains and enhancement for formal math capability as well. The results highlight the effectiveness and efficiency of our approach, which provides a paradigm for extending formal provers outside mathematical domains. To foster further research, we will release both our dataset and model to the community.

</details>


### [139] [Tabular Incremental Inference](https://arxiv.org/abs/2601.15751)
*Xinda Chen,Xing Zhen,Hanyu Zhang,Weimin Tan,Bo Yan*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Tabular data is a fundamental form of data structure. The evolution of table analysis tools reflects humanity's continuous progress in data acquisition, management, and processing. The dynamic changes in table columns arise from technological advancements, changing needs, data integration, etc. However, the standard process of training AI models on tables with fixed columns and then performing inference is not suitable for handling dynamically changed tables. Therefore, new methods are needed for efficiently handling such tables in an unsupervised manner. In this paper, we introduce a new task, Tabular Incremental Inference (TabII), which aims to enable trained models to incorporate new columns during the inference stage, enhancing the practicality of AI models in scenarios where tables are dynamically changed. Furthermore, we demonstrate that this new task can be framed as an optimization problem based on the information bottleneck theory, which emphasizes that the key to an ideal tabular incremental inference approach lies in minimizing mutual information between tabular data and representation while maximizing between representation and task labels. Under this guidance, we design a TabII method with Large Language Model placeholders and Pretrained TabAdapter to provide external knowledge and Incremental Sample Condensation blocks to condense the task-relevant information given by incremental column attributes. Experimental results across eight public datasets show that TabII effectively utilizes incremental attributes, achieving state-of-the-art performance.

</details>


### [140] [Off-Policy Actor-Critic with Sigmoid-Bounded Entropy for Real-World Robot Learning](https://arxiv.org/abs/2601.15761)
*Xiefeng Wu,Mingyu Hu,Shu Zhang*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Deploying reinforcement learning in the real world remains challenging due to sample inefficiency, sparse rewards, and noisy visual observations. Prior work leverages demonstrations and human feedback to improve learning efficiency and robustness. However, offline-to-online methods need large datasets and can be unstable, while VLA-assisted RL relies on large-scale pretraining and fine-tuning. As a result, a low-cost real-world RL method with minimal data requirements has yet to emerge. We introduce \textbf{SigEnt-SAC}, an off-policy actor-critic method that learns from scratch using a single expert trajectory. Our key design is a sigmoid-bounded entropy term that prevents negative-entropy-driven optimization toward out-of-distribution actions and reduces Q-function oscillations. We benchmark SigEnt-SAC on D4RL tasks against representative baselines. Experiments show that SigEnt-SAC substantially alleviates Q-function oscillations and reaches a 100\% success rate faster than prior methods. Finally, we validate SigEnt-SAC on four real-world robotic tasks across multiple embodiments, where agents learn from raw images and sparse rewards; results demonstrate that SigEnt-SAC can learn successful policies with only a small number of real-world interactions, suggesting a low-cost and practical pathway for real-world RL deployment.

</details>


### [141] [Creativity in the Age of AI: Rethinking the Role of Intentional Agency](https://arxiv.org/abs/2601.15797)
*James S. Pearson,Matthew J. Dennis,Marc Cheong*

Main category: cs.AI

TL;DR: 摘要认为应放弃将意向性主体作为创造力的普遍必要条件，但保留在某些特定情境下的适用性


<details>
  <summary>Details</summary>
Motivation: 生成式AI的兴起挑战了创造力需要意向性主体的传统观点，需要重新审视这一条件

Method: 1. 通过语料库分析证明作者和记者越来越多地将创造力归因于缺乏意向性主体的生成式AI；2. 运用概念工程方法分析意向性主体条件的社会功能变迁

Result: 意向性主体条件(IAC)在描述性和功能性上都存在问题，应被一致性要求取代：创造力应追踪可靠地生成新颖且有价值产品的能力

Conclusion: 创造力的一般定义应放弃意向性主体要求，转而采用基于可靠产出的标准，但在特定领域仍可保留意向性主体作为相关条件

Abstract: Many theorists of creativity maintain that intentional agency is a necessary condition of creativity. We argue that this requirement, which we call the Intentional Agency Condition (IAC), should be rejected as a general condition of creativity, while retaining its relevance in specific contexts. We show that recent advances in generative AI have rendered the IAC increasingly problematic, both descriptively and functionally. We offer two reasons for abandoning it at the general level. First, we present corpus evidence indicating that authors and journalists are increasingly comfortable ascribing creativity to generative AI, despite its lack of intentional agency. This development places pressure on the linguistic intuitions that have traditionally been taken to support the IAC. Second, drawing on the method of conceptual engineering, we argue that the IAC no longer fulfils its core social function. Rather than facilitating the identification and encouragement of reliable sources of novel and valuable products, it now feeds into biases that distort our assessments of AI-generated outputs. We therefore propose replacing the IAC with a consistency requirement, according to which creativity tracks the reliable generation of novel and valuable products. Nonetheless, we explain why the IAC should be retained in specific local domains.

</details>


### [142] [VitalDiagnosis: AI-Driven Ecosystem for 24/7 Vital Monitoring and Chronic Disease Management](https://arxiv.org/abs/2601.15798)
*Zhikai Xue,Tianqianjin Lin,Pengwei Yan,Ruichun Wang,Yuxin Liu,Zhuoren Jiang,Xiaozhong Liu*

Main category: cs.AI

TL;DR: 论文提出VitalDiagnosis系统，通过LLM整合可穿戴设备数据，从被动监控转向主动互动管理慢性病。


<details>
  <summary>Details</summary>
Motivation: 慢性病是全球主要死因，医疗资源紧张和人口老龄化加剧挑战，患者往往难以识别早期恶化迹象并坚持护理计划。

Method: 整合可穿戴设备连续数据与LLM推理能力，通过情境感知询问分析触发因素，在患者-临床医生协作工作流中提供临时洞察和个性化指导。

Result: 系统能同时处理急性健康异常和日常依从性问题，促进更主动协作的护理范式。

Conclusion: 该方法有望增强患者自我管理能力，减少可避免的临床工作量，推动慢性病管理的根本性转变。

Abstract: Chronic diseases have become the leading cause of death worldwide, a challenge intensified by strained medical resources and an aging population. Individually, patients often struggle to interpret early signs of deterioration or maintain adherence to care plans. In this paper, we introduce VitalDiagnosis, an LLM-driven ecosystem designed to shift chronic disease management from passive monitoring to proactive, interactive engagement. By integrating continuous data from wearable devices with the reasoning capabilities of LLMs, the system addresses both acute health anomalies and routine adherence. It analyzes triggers through context-aware inquiries, produces provisional insights within a collaborative patient-clinician workflow, and offers personalized guidance. This approach aims to promote a more proactive and cooperative care paradigm, with the potential to enhance patient self-management and reduce avoidable clinical workload.

</details>


### [143] [Inference-Time Scaling of Verification: Self-Evolving Deep Research Agents via Test-Time Rubric-Guided Verification](https://arxiv.org/abs/2601.15808)
*Yuxuan Wan,Tianqing Fang,Zaitang Li,Yintong Huo,Wenxuan Wang,Haitao Mi,Dong Yu,Michael R. Lyu*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent advances in Deep Research Agents (DRAs) are transforming automated knowledge discovery and problem-solving. While the majority of existing efforts focus on enhancing policy capabilities via post-training, we propose an alternative paradigm: self-evolving the agent's ability by iteratively verifying the policy model's outputs, guided by meticulously crafted rubrics. This approach gives rise to the inference-time scaling of verification, wherein an agent self-improves by evaluating its generated answers to produce iterative feedback and refinements. We derive the rubrics based on an automatically constructed DRA Failure Taxonomy, which systematically classifies agent failures into five major categories and thirteen sub-categories. We present DeepVerifier, a rubrics-based outcome reward verifier that leverages the asymmetry of verification and outperforms vanilla agent-as-judge and LLM judge baselines by 12%-48% in meta-evaluation F1 score. To enable practical self-evolution, DeepVerifier integrates as a plug-and-play module during test-time inference. The verifier produces detailed rubric-based feedback, which is fed back to the agent for iterative bootstrapping, refining responses without additional training. This test-time scaling delivers 8%-11% accuracy gains on challenging subsets of GAIA and XBench-DeepResearch when powered by capable closed-source LLMs. Finally, to support open-source advancement, we release DeepVerifier-4K, a curated supervised fine-tuning dataset of 4,646 high-quality agent steps focused on DRA verification. These examples emphasize reflection and self-critique, enabling open models to develop robust verification capabilities.

</details>


### [144] [ErrorMap and ErrorAtlas: Charting the Failure Landscape of Large Language Models](https://arxiv.org/abs/2601.15812)
*Shir Ashury-Tahan,Yifan Mai,Elron Bandel,Michal Shmueli-Scheuer,Leshem Choshen*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLM) benchmarks tell us when models fail, but not why they fail. A wrong answer on a reasoning dataset may stem from formatting issues, calculation errors, or dataset noise rather than weak reasoning. Without disentangling such causes, benchmarks remain incomplete and cannot reliably guide model improvement. We introduce ErrorMap, the first method to chart the sources of LLM failure. It extracts a model's unique "failure signature", clarifies what benchmarks measure, and broadens error identification to reduce blind spots. This helps developers debug models, aligns benchmark goals with outcomes, and supports informed model selection. ErrorMap works on any model or dataset with the same logic. Applying our method to 35 datasets and 83 models we generate ErrorAtlas, a taxonomy of model errors, revealing recurring failure patterns. ErrorAtlas highlights error types that are currently underexplored in LLM research, such as omissions of required details in the output and question misinterpretation. By shifting focus from where models succeed to why they fail, ErrorMap and ErrorAtlas enable advanced evaluation - one that exposes hidden weaknesses and directs progress. Unlike success, typically measured by task-level metrics, our approach introduces a deeper evaluation layer that can be applied globally across models and tasks, offering richer insights into model behavior and limitations. We make the taxonomy and code publicly available with plans to periodically update ErrorAtlas as new benchmarks and models emerge.

</details>


### [145] [EvoCUA: Evolving Computer Use Agents via Learning from Scalable Synthetic Experience](https://arxiv.org/abs/2601.15876)
*Taofeng Xue,Chong Peng,Mianqiu Huang,Linsen Guo,Tiancheng Han,Haozhe Wang,Jianing Wang,Xiaocheng Zhang,Xin Yang,Dengchang Zhao,Jinrui Ding,Xiandi Ma,Yuchen Xie,Peng Pei,Xunliang Cai,Xipeng Qiu*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The development of native computer-use agents (CUA) represents a significant leap in multimodal AI. However, their potential is currently bottlenecked by the constraints of static data scaling. Existing paradigms relying primarily on passive imitation of static datasets struggle to capture the intricate causal dynamics inherent in long-horizon computer tasks. In this work, we introduce EvoCUA, a native computer use agentic model. Unlike static imitation, EvoCUA integrates data generation and policy optimization into a self-sustaining evolutionary cycle. To mitigate data scarcity, we develop a verifiable synthesis engine that autonomously generates diverse tasks coupled with executable validators. To enable large-scale experience acquisition, we design a scalable infrastructure orchestrating tens of thousands of asynchronous sandbox rollouts. Building on these massive trajectories, we propose an iterative evolving learning strategy to efficiently internalize this experience. This mechanism dynamically regulates policy updates by identifying capability boundaries -- reinforcing successful routines while transforming failure trajectories into rich supervision through error analysis and self-correction. Empirical evaluations on the OSWorld benchmark demonstrate that EvoCUA achieves a success rate of 56.7%, establishing a new open-source state-of-the-art. Notably, EvoCUA significantly outperforms the previous best open-source model, OpenCUA-72B (45.0%), and surpasses leading closed-weights models such as UI-TARS-2 (53.1%). Crucially, our results underscore the generalizability of this approach: the evolving paradigm driven by learning from experience yields consistent performance gains across foundation models of varying scales, establishing a robust and scalable path for advancing native agent capabilities.

</details>


### [146] [ICON: Invariant Counterfactual Optimization with Neuro-Symbolic Priors for Text-Based Person Search](https://arxiv.org/abs/2601.15931)
*Xiangyu Wang,Zhixin Lv,Yongjiao Sun,Anrui Han,Ye Yuan,Hangxu Ji*

Main category: cs.AI

TL;DR: ICON框架通过规则引导空间干预、反事实上下文解耦、显著性语义正则化和神经符号拓扑对齐，解决基于文本行人检索中伪相关性和空间语义错位问题，提升分布偏移下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前基于预训练模型的文本行人检索方法在复杂开放世界场景中迁移效果不佳，依赖'被动观察'导致多方面伪相关性和空间语义错位，缺乏对分布变化的鲁棒性。

Method: 1. 规则引导空间干预：严格惩罚对边界框噪声的敏感性，切断位置捷径实现几何不变性
2. 反事实上下文解耦：通过语义驱动的背景移植消除背景干扰实现环境独立性
3. 显著性驱动语义正则化：自适应掩码解决局部显著性偏差保证整体完整性
4. 神经符号拓扑对齐：利用神经符号先验约束特征匹配，确保激活区域与人类结构逻辑拓扑一致

Result: ICON不仅保持标准基准测试的领先性能，而且对遮挡、背景干扰和定位噪声表现出卓越的鲁棒性。

Conclusion: 该方法将从拟合统计共现转向学习因果不变性，有效推动了该领域的发展。

Abstract: Text-Based Person Search (TBPS) holds unique value in real-world surveillance bridging visual perception and language understanding, yet current paradigms utilizing pre-training models often fail to transfer effectively to complex open-world scenarios. The reliance on "Passive Observation" leads to multifaceted spurious correlations and spatial semantic misalignment, causing a lack of robustness against distribution shifts. To fundamentally resolve these defects, this paper proposes ICON (Invariant Counterfactual Optimization with Neuro-symbolic priors), a framework integrating causal and topological priors. First, we introduce Rule-Guided Spatial Intervention to strictly penalize sensitivity to bounding box noise, forcibly severing location shortcuts to achieve geometric invariance. Second, Counterfactual Context Disentanglement is implemented via semantic-driven background transplantation, compelling the model to ignore background interference for environmental independence. Then, we employ Saliency-Driven Semantic Regularization with adaptive masking to resolve local saliency bias and guarantee holistic completeness. Finally, Neuro-Symbolic Topological Alignment utilizes neuro-symbolic priors to constrain feature matching, ensuring activated regions are topologically consistent with human structural logic. Experimental results demonstrate that ICON not only maintains leading performance on standard benchmarks but also exhibits exceptional robustness against occlusion, background interference, and localization noise. This approach effectively advances the field by shifting from fitting statistical co-occurrences to learning causal invariance.

</details>


### [147] [Natural Language-Driven Global Mapping of Martian Landforms](https://arxiv.org/abs/2601.15949)
*Yiran Wang,Shuoyuan Wang,Zhaoran Wei,Jiannan Zhao,Zhonghua Yao,Zejian Xie,Songxin Zhang,Jun Huang,Bingyi Jing,Hongxin Wei*

Main category: cs.AI

TL;DR: MarScope是一个行星尺度视觉语言框架，通过将火星图像与文本对齐到共享语义空间，支持自然语言驱动的无标签地理特征映射，实现秒级全球检索。


<details>
  <summary>Details</summary>
Motivation: 现有行星表面分析依赖预定义分类，而海量轨道图像档案以像素级别组织，这种不匹配限制了行星表面的可扩展、开放式探索。

Method: 开发MarScope框架，在20万+精心策划的图像-文本对上训练，将行星图像和自然语言文本对齐到共享语义空间，实现灵活的语义检索。

Result: 在5秒内完成全火星任意用户查询，F1分数高达0.978，超越形态分类，支持过程导向分析和基于相似性的地貌制图。

Conclusion: MarScope建立了自然语言作为大规模地理空间数据科学发现直接接口的新范式，改变了全球地理形态制图方式。

Abstract: Planetary surfaces are typically analyzed using high-level semantic concepts in natural language, yet vast orbital image archives remain organized at the pixel level. This mismatch limits scalable, open-ended exploration of planetary surfaces. Here we present MarScope, a planetary-scale vision-language framework enabling natural language-driven, label-free mapping of Martian landforms. MarScope aligns planetary images and text in a shared semantic space, trained on over 200,000 curated image-text pairs. This framework transforms global geomorphic mapping on Mars by replacing pre-defined classifications with flexible semantic retrieval, enabling arbitrary user queries across the entire planet in 5 seconds with F1 scores up to 0.978. Applications further show that it extends beyond morphological classification to facilitate process-oriented analysis and similarity-based geomorphological mapping at a planetary scale. MarScope establishes a new paradigm where natural language serves as a direct interface for scientific discovery over massive geospatial datasets.

</details>


### [148] [Decoupling Return-to-Go for Efficient Decision Transformer](https://arxiv.org/abs/2601.15953)
*Yongyi Wang,Hanyu Liu,Lingfeng Li,Bozhou Chen,Ang Li,Qirui Zheng,Xionghui Yang,Wenxin Li*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Decision Transformer (DT) has established a powerful sequence modeling approach to offline reinforcement learning. It conditions its action predictions on Return-to-Go (RTG), using it both to distinguish trajectory quality during training and to guide action generation at inference. In this work, we identify a critical redundancy in this design: feeding the entire sequence of RTGs into the Transformer is theoretically unnecessary, as only the most recent RTG affects action prediction. We show that this redundancy can impair DT's performance through experiments. To resolve this, we propose the Decoupled DT (DDT). DDT simplifies the architecture by processing only observation and action sequences through the Transformer, using the latest RTG to guide the action prediction. This streamlined approach not only improves performance but also reduces computational cost. Our experiments show that DDT significantly outperforms DT and establishes competitive performance against state-of-the-art DT variants across multiple offline RL tasks.

</details>


### [149] [Deja Vu in Plots: Leveraging Cross-Session Evidence with Retrieval-Augmented LLMs for Live Streaming Risk Assessment](https://arxiv.org/abs/2601.16027)
*Yiran Qiao,Xiang Ao,Jing Chen,Yang Liu,Qiwei Zhong,Qing He*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rise of live streaming has transformed online interaction, enabling massive real-time engagement but also exposing platforms to complex risks such as scams and coordinated malicious behaviors. Detecting these risks is challenging because harmful actions often accumulate gradually and recur across seemingly unrelated streams. To address this, we propose CS-VAR (Cross-Session Evidence-Aware Retrieval-Augmented Detector) for live streaming risk assessment. In CS-VAR, a lightweight, domain-specific model performs fast session-level risk inference, guided during training by a Large Language Model (LLM) that reasons over retrieved cross-session behavioral evidence and transfers its local-to-global insights to the small model. This design enables the small model to recognize recurring patterns across streams, perform structured risk assessment, and maintain efficiency for real-time deployment. Extensive offline experiments on large-scale industrial datasets, combined with online validation, demonstrate the state-of-the-art performance of CS-VAR. Furthermore, CS-VAR provides interpretable, localized signals that effectively empower real-world moderation for live streaming.

</details>


### [150] [Grounding Large Language Models in Reaction Knowledge Graphs for Synthesis Retrieval](https://arxiv.org/abs/2601.16038)
*Olga Bunkova,Lorenzo Di Fruscia,Sophia Rupprecht,Artur M. Schweidtmann,Marcel J. T. Reinders,Jana M. Weber*

Main category: cs.AI

TL;DR: 该论文提出了一种将化学反应检索转化为Text2Cypher（自然语言到图查询）生成问题的框架，用于改进大语言模型在合成规划中的准确性。研究比较了不同提示策略和验证循环的效果，为基于知识图谱的LLM合成规划提供了可复现的评估设置。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）能够辅助化学合成规划，但标准提示方法往往产生幻觉或过时的建议。为了解决这个问题，研究探索LLM与反应知识图谱的交互，通过将反应路径检索转化为自然语言到图查询（Text2Cypher）生成问题，以提供更准确、可靠的合成规划建议。

Method: 将反应路径检索定义为Text2Cypher生成问题，包括单步和多步检索任务。比较了零样本提示与使用静态、随机和基于嵌入的示例选择的一次样本提示变体，并评估了清单驱动的验证器/校正器循环。通过查询有效性和检索准确性来评估框架。

Result: 研究发现，使用对齐示例的一次样本提示始终表现最佳。清单式自校正循环主要改善零样本设置下的可执行性，一旦存在良好示例，其提供的额外检索增益有限。研究人员提供了可复现的Text2Cypher评估设置。

Conclusion: 基于对齐示例的一次样本提示是有效的LLM-KG交互策略，同时提供了一套可复现的评估方法，为进一步研究基于知识图谱的大语言模型合成规划奠定了基础。

Abstract: Large Language Models (LLMs) can aid synthesis planning in chemistry, but standard prompting methods often yield hallucinated or outdated suggestions. We study LLM interactions with a reaction knowledge graph by casting reaction path retrieval as a Text2Cypher (natural language to graph query) generation problem, and define single- and multi-step retrieval tasks. We compare zero-shot prompting to one-shot variants using static, random, and embedding-based exemplar selection, and assess a checklist-driven validator/corrector loop. To evaluate our framework, we consider query validity and retrieval accuracy. We find that one-shot prompting with aligned exemplars consistently performs best. Our checklist-style self-correction loop mainly improves executability in zero-shot settings and offers limited additional retrieval gains once a good exemplar is present. We provide a reproducible Text2Cypher evaluation setup to facilitate further work on KG-grounded LLMs for synthesis planning. Code is available at https://github.com/Intelligent-molecular-systems/KG-LLM-Synthesis-Retrieval.

</details>


### [151] [AgriPINN: A Process-Informed Neural Network for Interpretable and Scalable Crop Biomass Prediction Under Water Stress](https://arxiv.org/abs/2601.16045)
*Yue Shi,Liangxiu Han,Xin Zhang,Tam Sobeih,Thomas Gaiser,Nguyen Huu Thuy,Dominik Behrend,Amit Kumar Srivastava,Krishnagopal Halder,Frank Ewert*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate prediction of crop above-ground biomass (AGB) under water stress is critical for monitoring crop productivity, guiding irrigation, and supporting climate-resilient agriculture. Data-driven models scale well but often lack interpretability and degrade under distribution shift, whereas process-based crop models (e.g. DSSAT, APSIM, LINTUL5) require extensive calibration and are difficult to deploy over large spatial domains. To address these limitations, we propose AgriPINN, a process-informed neural network that integrates a biophysical crop-growth differential equation as a differentiable constraint within a deep learning backbone. This design encourages physiologically consistent biomass dynamics under water-stress conditions while preserving model scalability for spatially distributed AGB prediction. AgriPINN recovers latent physiological variables, including leaf area index (LAI), absorbed photosynthetically active radiation (PAR), radiation use efficiency (RUE), and water-stress factors, without requiring direct supervision. We pretrain AgriPINN on 60 years of historical data across 397 regions in Germany and fine-tune it on three years of field experiments under controlled water treatments. Results show that AgriPINN consistently outperforms state-of-the-art deep-learning baselines (ConvLSTM-ViT, SLTF, CNN-Transformer) and the process-based LINTUL5 model in terms of accuracy (RMSE reductions up to $43\%$) and computational efficiency. By combining the scalability of deep learning with the biophysical rigor of process-based modeling, AgriPINN provides a robust and interpretable framework for spatio-temporal AGB prediction, offering practical value for planning of irrigation infrastructure, yield forecasting, and climate-adaptation planning.

</details>


### [152] [Designing faster mixed integer linear programming algorithm via learning the optimal path](https://arxiv.org/abs/2601.16056)
*Ruizhi Liu,Liming Xu,Xulin Huang,Jingyan Sui,Shizhe Ding,Boyang Xia,Chungong Yu,Dongbo Bu*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Designing faster algorithms for solving Mixed-Integer Linear Programming (MILP) problems is highly desired across numerous practical domains, as a vast array of complex real-world challenges can be effectively modeled as MILP formulations. Solving these problems typically employs the branch-and-bound algorithm, the core of which can be conceived as searching for a path of nodes (or sub-problems) that contains the optimal solution to the original MILP problem. Traditional approaches to finding this path rely heavily on hand-crafted, intuition-based heuristic strategies, which often suffer from unstable and unpredictable performance across different MILP problem instances. To address this limitation, we introduce DeepBound, a deep learning-based node selection algorithm that automates the learning of such human intuition from data. The core of DeepBound lies in learning to prioritize nodes containing the optimal solution, thereby improving solving efficiency. DeepBound introduces a multi-level feature fusion network to capture the node representations. To tackle the inherent node imbalance in branch-and-bound trees, DeepBound employs a pairwise training paradigm that enhances the model's ability to discriminate between nodes. Extensive experiments on three NP-hard MILP benchmarks demonstrate that DeepBound achieves superior solving efficiency over conventional heuristic rules and existing learning-based approaches, obtaining optimal feasible solutions with significantly reduced computation time. Moreover, DeepBound demonstrates strong generalization capability on large and complex instances. The analysis of its learned features reveals that the method can automatically discover more flexible and robust feature selection, which may effectively improve and potentially replace human-designed heuristic rules.

</details>


### [153] [Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics](https://arxiv.org/abs/2601.16087)
*Sukesh Subaharan*

Main category: cs.AI

TL;DR: 这篇论文研究了在LLM智能体中引入情感动态子系统（基于VAD三元素）对于多轮对话时间一致性和情绪恢复能力的影响。通过比较无状态、一阶和二阶动态系统，发现状态保持能实现延迟响应和稳定恢复，二阶动态则在稳定性和响应性之间存在权衡。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体在长期交互中常出现语气和人设的突兀转变，缺乏明确的时序结构来管理智能体层级的状态。虽然先前研究关注逐轮情感或静态情绪分类，但显式情感动态在塑造长期智能体行为中的作用尚未充分探索。本文旨在探究在外部情感状态上施加动态结构是否能诱导多轮对话中的时间一致性和可控恢复。

Method: 引入智能体层级的情感子系统，维护一个连续的三维情感状态（VAD：效价-唤醒度-支配性），该系统独立于语言模型并受一阶和二阶更新规则控制。使用固定的无记忆估计器提取瞬时情感信号，通过指数平滑或基于动量的动态机制随时间积分。最终的情感状态被注入回生成过程而不修改模型参数。使用固定的25轮对话协议，比较无状态、一阶和二阶情感动态。

Result: 无状态智能体未能表现出一致的轨迹或恢复能力，而状态保持则实现了延迟响应和可靠的恢复。二阶动态引入了情感惯性和滞后现象，且随动量增加而增强，揭示了稳定性与响应性之间的权衡关系。

Conclusion: 在LLM智能体中引入显式的情感动态子系统能够增强多轮对话的时间一致性和可控情绪恢复能力。状态保持机制（一阶动态）是实现延迟响应和恢复的关键，而二阶动态则提供了在稳定性和响应性之间的可调节权衡，为设计更自然、一致的对话智能体提供了新思路。

Abstract: Large language model (LLM) agents often exhibit abrupt shifts in tone and persona during extended interaction, reflecting the absence of explicit temporal structure governing agent-level state. While prior work emphasizes turn-local sentiment or static emotion classification, the role of explicit affective dynamics in shaping long-horizon agent behavior remains underexplored. This work investigates whether imposing dynamical structure on an external affective state can induce temporal coherence and controlled recovery in multi-turn dialogue. We introduce an agent-level affective subsystem that maintains a continuous Valence-Arousal-Dominance (VAD) state external to the language model and governed by first- and second-order update rules. Instantaneous affective signals are extracted using a fixed, memoryless estimator and integrated over time via exponential smoothing or momentum-based dynamics. The resulting affective state is injected back into generation without modifying model parameters. Using a fixed 25-turn dialogue protocol, we compare stateless, first-order, and second-order affective dynamics. Stateless agents fail to exhibit coherent trajectories or recovery, while state persistence enables delayed responses and reliable recovery. Second-order dynamics introduce affective inertia and hysteresis that increase with momentum, revealing a trade-off between stability and responsiveness.

</details>


### [154] [Multimodal Climate Disinformation Detection: Integrating Vision-Language Models with External Knowledge Sources](https://arxiv.org/abs/2601.16108)
*Marzieh Adeli Shamsabad,Hamed Ghodrati*

Main category: cs.AI

TL;DR: 该研究针对气候虚假信息检测中视觉语言模型的局限性,提出结合最新外部知识增强模型推理能力的方法,提高图像与声称的真实性评估准确性。


<details>
  <summary>Details</summary>
Motivation: 气候虚假信息在社交媒体广泛传播,传统视觉语言模型依赖训练时知识,无法有效处理涉及最新事件的信息,需要结合最新外部知识提升准确性。

Method: 将视觉语言模型与外部知识检索相结合,获取反向图片搜索结果、在线事实核查、可信专家内容等最新信息,评估图像与声称的真实性(真实、误导、虚假或无法验证)。

Result: 该方法能更好地处理现实世界中的气候虚假信息,提升模型对图像声称的准确性判断能力。

Conclusion: 结合最新外部知识的系统能够更有效地检测和应对气候虚假信息,支持在快速变化的信息环境中保护公众对科学的理解。

Abstract: Climate disinformation has become a major challenge in today digital world, especially with the rise of misleading images and videos shared widely on social media. These false claims are often convincing and difficult to detect, which can delay actions on climate change. While vision-language models (VLMs) have been used to identify visual disinformation, they rely only on the knowledge available at the time of training. This limits their ability to reason about recent events or updates. The main goal of this paper is to overcome that limitation by combining VLMs with external knowledge. By retrieving up-to-date information such as reverse image results, online fact-checks, and trusted expert content, the system can better assess whether an image and its claim are accurate, misleading, false, or unverifiable. This approach improves the model ability to handle real-world climate disinformation and supports efforts to protect public understanding of science in a rapidly changing information landscape.

</details>


### [155] [LLM Prompt Evaluation for Educational Applications](https://arxiv.org/abs/2601.16134)
*Langdon Holmes,Adam Coscia,Scott Crossley,Joon Suh Choi,Wesley Morris*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As large language models (LLMs) become increasingly common in educational applications, there is a growing need for evidence-based methods to design and evaluate LLM prompts that produce personalized and pedagogically aligned out-puts. This study presents a generalizable, systematic approach for evaluating prompts, demonstrated through an analysis of LLM-generated follow-up questions in a structured dialogue activity. Six prompt templates were designed and tested. The templates incorporated established prompt engineering patterns, with each prompt emphasizing distinct pedagogical strategies. The prompt templates were compared through a tournament-style evaluation framework that can be adapted for other educational applications. The tournament employed the Glicko2 rating system with eight judges evaluating question pairs across three dimensions: format, dialogue support, and appropriateness for learners. Data was sourced from 120 authentic user interactions across three distinct educational deployments. Results showed that a single prompt related to strategic reading out-performed other templates with win probabilities ranging from 81% to 100% in pairwise comparisons. This prompt combined persona and context manager pat-terns and was designed to support metacognitive learning strategies such as self-directed learning. The methodology showcases how educational technology re- searchers can systematically evaluate and improve prompt designs, moving beyond ad-hoc prompt engineering toward evidence-based prompt development for educational applications.

</details>


### [156] [Structured Hints for Sample-Efficient Lean Theorem Proving](https://arxiv.org/abs/2601.16172)
*Zachary Burton*

Main category: cs.AI

TL;DR: 在miniF2F基准测试中，通过简单的推断时提示调度（15个常用策略骨架）将DeepSeek-Prover-V1.5的pass@16从15.2%提升到21.7%，相对提升43%，表明即使经过RL训练的证明器也能从结构性指导中受益。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索经过复杂强化学习训练的最先进神经定理证明器（如DeepSeek-Prover-V1.5）是否仍能在推断时受益于简单的结构性指导。虽然这些模型已经通过精密的训练达到了令人印象深刻的结果，但作者质疑它们是否充分利用了策略语言中可用的结构先验知识。这个研究旨在验证轻量级干预在推断阶段的价值。

Method: 研究方法采用了一种轻量级干预方案：在miniF2F基准测试上评估固定的提示调度方法，该方法基于15个常用的策略骨架。该方法不改变模型本身，只在推断时应用结构性指导，使用相同数量的样本（k=16）和相同的最大生成长度（1024个token），与标准采样方法进行对比。

Result: 实验结果显示，简单提示调度方法达到了21.7%的pass@16，相比之下，同一模型的标准采样仅为15.2%。这在相同样本数量（k=16）和相同最大生成长度（1024个token）下实现了43%的相对提升。这表明即使是能力较强的强化学习训练证明器，也未充分利用策略语言中可用的结构先验知识。

Conclusion: 结论是即使经过强化学习训练的高性能定理证明器仍能从简单的结构性指导中受益，证实了推断时引导作为一种廉价且互补的增强手段的有效性。简单提示调度能显著提升模型性能而不需要重新训练或大量计算资源，为神经定理证明提供了实用且有价值的改进方向。

Abstract: State-of-the-art neural theorem provers like DeepSeek-Prover-V1.5 combine large language models with reinforcement learning, achieving impressive results through sophisticated training. We ask: do these highly-trained models still benefit from simple structural guidance at inference time? We evaluate a lightweight intervention -- a fixed prompt schedule over 15 common tactic skeletons -- on the miniF2F benchmark. This simple approach yields 21.7% pass@16 compared to 15.2% for standard sampling from the same model, a 43% relative improvement using the same number of samples (k=16) and same maximum generation length (1024 tokens). Our results suggest that even capable RL-trained provers underutilize structural priors available in the tactic language, and that simple inference-time guidance remains a cheap, complementary boost.

</details>


### [157] [Scalable Board Expansion within a General Game System](https://arxiv.org/abs/2601.16216)
*Clémentine Sacré*

Main category: cs.AI

TL;DR: 论文提出基于通用游戏系统的动态板扩展机制，解决传统无边界棋盘游戏使用静态超大棋盘造成的冗余复杂性问题


<details>
  <summary>Details</summary>
Motivation: 传统无边界棋盘游戏通常使用预设的静态超大棋盘，但游戏中大部分区域可能从未使用，导致不必要的复杂性

Method: 采用通用游戏系统支持动态棋盘扩展机制，在游戏过程中自动扩展游戏棋盘

Result: 未在摘要中明确说明

Conclusion: 动态棋盘扩展机制能有效避免传统静态棋盘带来的冗余复杂性

Abstract: This thesis explores the use of a General Game System (GGS) to support the automatic expansion of game boards in boardless games. Traditional implementations of such games often rely on oversized static boards defined from the start, even though large portions of these boards may never be used during gameplay. This approach leads to unnecessary complexity. To address this issue, this thesis propose a dynamic board expansion mechanism in which the game board grows automatically during play.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [158] [Empowering LLMs for Structure-Based Drug Design via Exploration-Augmented Latent Inference](https://arxiv.org/abs/2601.15333)
*Xuanning Hu,Anchen Li,Qianli Xing,Jinglong Ji,Hao Tuo,Bo Yang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) possess strong representation and reasoning capabilities, but their application to structure-based drug design (SBDD) is limited by insufficient understanding of protein structures and unpredictable molecular generation. To address these challenges, we propose Exploration-Augmented Latent Inference for LLMs (ELILLM), a framework that reinterprets the LLM generation process as an encoding, latent space exploration, and decoding workflow. ELILLM explicitly explores portions of the design problem beyond the model's current knowledge while using a decoding module to handle familiar regions, generating chemically valid and synthetically reasonable molecules. In our implementation, Bayesian optimization guides the systematic exploration of latent embeddings, and a position-aware surrogate model efficiently predicts binding affinity distributions to inform the search. Knowledge-guided decoding further reduces randomness and effectively imposes chemical validity constraints. We demonstrate ELILLM on the CrossDocked2020 benchmark, showing strong controlled exploration and high binding affinity scores compared with seven baseline methods. These results demonstrate that ELILLM can effectively enhance LLMs capabilities for SBDD.

</details>


### [159] [Language Models Entangle Language and Culture](https://arxiv.org/abs/2601.15337)
*Shourya Jain,Paras Chopra*

Main category: cs.LG

TL;DR: 本文研究发现：1）LLMs对低资源语言的问题提供更低质量回答；2）语言选择影响LLMs回答中的文化语境；3）文化语境的差异进一步影响回答质量。


<details>
  <summary>Details</summary>
Motivation: 为避免不同语言用户在LLMs交互中遭遇系统性不公平，需评估语言如何影响LLMs的回答质量和其中的文化语境。

Method: 1）基于WildChat数据集构建现实开放性问题并评估语言对回答质量的影响；2）用LLM-as-a-Judge识别回答中的文化语境；3）将CulturalBench基准翻译到多语言进行评测。

Result: LLMs对低资源语言的问题提供更低质量回答；语言显著影响模型使用的文化语境，这种语境差异进而影响下游回答质量。

Conclusion: LLMs存在语言偏见：用户使用的语言会影响回答质量和其中的文化语境，这可能加剧数字鸿沟，需要在多语言对齐工作中加以解决。

Abstract: Users should not be systemically disadvantaged by the language they use for interacting with LLMs; i.e. users across languages should get responses of similar quality irrespective of language used. In this work, we create a set of real-world open-ended questions based on our analysis of the WildChat dataset and use it to evaluate whether responses vary by language, specifically, whether answer quality depends on the language used to query the model. We also investigate how language and culture are entangled in LLMs such that choice of language changes the cultural information and context used in the response by using LLM-as-a-Judge to identify the cultural context present in responses. To further investigate this, we evaluate LLMs on a translated subset of the CulturalBench benchmark across multiple languages. Our evaluations reveal that LLMs consistently provide lower quality answers to open-ended questions in low resource languages. We find that language significantly impacts the cultural context used by the model. This difference in context impacts the quality of the downstream answer.

</details>


### [160] [Improving MoE Compute Efficiency by Composing Weight and Data Sparsity](https://arxiv.org/abs/2601.15370)
*Maciej Kilian,Oleg Mkrtchyan,Luke Zettlemoyer,Akshat Shrivastava,Armen Aghajanyan*

Main category: cs.LG

TL;DR: 通过引入零计算专家，在因果token-choice的MoE中实现数据稀疏性，结合权重稀疏性和数据稀疏性获得更高的计算效率


<details>
  <summary>Details</summary>
Motivation: 现有MoE层主要通过权重稀疏性实现计算效率提升，数据稀疏性作为补充维度。传统Expert-choice路由虽然直接实现数据稀疏性，但在自回归模型中违反因果性导致训练-推理不匹配。本文旨在探索如何在因果性约束下有效实现数据稀疏性。

Method: 在路由池中引入零计算专家，当token路由到这些空专家时，对应槽位不消耗计算资源。通过标准的负载均衡目标训练模型均匀使用所有专家，在保持因果性的同时，在期望层面获得数据稀疏性。

Result: 在视觉语言模型训练中评估，发现结合权重稀疏性和数据稀疏性相比单独使用权重稀疏性，在匹配预期FLOPs下能产生更优的计算效率前沿，训练损失和下游性能均有提升。模型学习到隐式的模态感知分配，将更多视觉token路由到空专家。

Conclusion: 通过引入零计算专家，本文实现了因果token-choice MoE中的数据稀疏性，无需显式模态路由机制。权重稀疏性和数据稀疏性的组合在视觉语言模型训练中展现出更好的计算效率和性能表现。

Abstract: Mixture-of-Experts layers achieve compute efficiency through weight sparsity: each token activates only a subset of experts. Data sparsity, where each expert processes only a subset of tokens, offers a complementary axis. Expert-choice routing implements data sparsity directly but violates causality in autoregressive models, creating train-inference mismatch. We recover data sparsity within causal token-choice MoE by leveraging zero-compute (null) experts within the routing pool. When a token routes to null experts, those slots consume no compute. The standard load balancing objective trains the model to uniformly use all experts (real and null) therefore creating data sparsity in expectation without the causality violations. We evaluate on vision-language model training, where data heterogeneity is pronounced: vision encoders produce many low-information tokens while text tokens are denser. At matched expected FLOPs, composing weight and data sparsity yields a more compute-efficient frontier than weight sparsity alone, with gains in training loss and downstream performance. The model learns implicit modality-aware allocation, routing vision tokens to null experts more aggressively than text, without explicit modality routing.

</details>


### [161] [You Need Better Attention Priors](https://arxiv.org/abs/2601.15380)
*Elon Litman,Gabe Guo*

Main category: cs.LG

TL;DR: 基于熵最优传输理论提出了广义最优传输注意力机制GOAT，通过可学习的连续先验替代传统Attention的均匀先验假设，保持与FlashAttention等优化内核的兼容性，并提供注意力沉没问题的ETO解释和解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统注意力机制在隐式假设均匀先验的情况下运作，通过将其放在熵最优传输框架下分析，发现这种简单假设限制了模型的表达能力。为克服这一限制，需要设计既能保持计算效率又能提供更强表达能力的注意力机制。

Method: 提出GOAT(Generalized Optimal transport Attention with Trainable priors)，将标准注意力重新表述为带可学习连续先验的最优传输问题。该方法吸收空间信息到核心注意力计算中，学习可外推的先验，结合了学习位置嵌入的灵活性和固定编码的长度泛化能力。

Result: GOAT保持了与FlashAttention等优化内核的完全兼容性，提供了基于ETO的注意力沉没现象理论解释，并通过可学习先验机制有效解决了该问题。学习的可外推先验实现了表达能力与泛化能力的平衡。

Conclusion: GOAT通过将注意力机制重新表述为带可学习连续先验的最优传输问题，系统性地解决了传统注意力的均匀先验假设限制，同时保持了计算效率，为注意力机制的理论理解和实际改进提供了新框架。

Abstract: We generalize the attention mechanism by viewing it through the lens of Entropic Optimal Transport, revealing that standard attention corresponds to a transport problem regularized by an implicit uniform prior. We introduce Generalized Optimal transport Attention with Trainable priors (GOAT), a new attention mechanism that replaces this naive assumption with a learnable, continuous prior. This prior maintains full compatibility with optimized kernels such as FlashAttention. GOAT also provides an EOT-based explanation of attention sinks and materializes a solution for them, avoiding the representational trade-offs of standard attention. Finally, by absorbing spatial information into the core attention computation, GOAT learns an extrapolatable prior that combines the flexibility of learned positional embeddings with the length generalization of fixed encodings.

</details>


### [162] [FedUMM: A General Framework for Federated Learning with Unified Multimodal Models](https://arxiv.org/abs/2601.15390)
*Zhaolong Su,Leheng Zhao,Xiaoying Wu,Ziyue Xu,Jindong Wang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Unified multimodal models (UMMs) are emerging as strong foundation models that can do both generation and understanding tasks in a single architecture. However, they are typically trained in centralized settings where all training and downstream datasets are gathered in a central server, limiting the deployment in privacy-sensitive and geographically distributed scenarios. In this paper, we present FedUMM, a general federated learning framework for UMMs under non-IID multimodal data with low communication cost. Built on NVIDIA FLARE, FedUMM instantiates federation for a BLIP3o backbone via parameter-efficient fine-tuning: clients train lightweight LoRA adapters while freezing the foundation models, and the server aggregates only adapter updates. We evaluate on VQA v2 and the GenEval compositional generation benchmarks under Dirichlet-controlled heterogeneity with up to 16 clients. Results show slight degradation as client count and heterogeneity increase, while remaining competitive with centralized training. We further analyze computation--communication trade-offs and demonstrate that adapter-only federation reduces per-round communication by over an order of magnitude compared to full fine-tuning, enabling practical federated UMM training. This work provides empirical experience for future research on privacy-preserving federated unified multimodal models.

</details>


### [163] [Ambient Dataloops: Generative Models for Dataset Refinement](https://arxiv.org/abs/2601.15417)
*Adrián Rodríguez-Muñoz,William Daspit,Adam Klivans,Antonio Torralba,Constantinos Daskalakis,Giannis Daras*

Main category: cs.LG

TL;DR: 通过迭代式数据集精炼框架，提升扩散模型对数据分布的学习效果，在无条件与文本条件图像生成、蛋白质设计中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现代数据集通常包含质量参差不齐的样本，直接在这些异构数据上训练会导致模型性能欠佳。为了解决这个问题，研究者提出了数据集-模型协同进化的迭代方法。

Method: Ambient Dataloops框架采用迭代式数据集精炼策略，在每一代训练中，将合成改进的样本视为含噪声数据（但噪声水平较前一次迭代略有降低），并运用Ambient Diffusion技术进行污染数据下的学习，避免了破坏性的自我消耗循环。

Result: 实验证明，该框架在无条件/文本条件图像生成和从头蛋白质设计任务中达到了SOTA性能。理论分析也验证了数据循环流程的有效性。

Conclusion: Ambient Dataloops通过迭代式数据集精炼和模型协同进化，显著提升了扩散模型在异构数据上的学习能力，为高质量数据生成任务提供了有效的解决方案。

Abstract: We propose Ambient Dataloops, an iterative framework for refining datasets that makes it easier for diffusion models to learn the underlying data distribution. Modern datasets contain samples of highly varying quality, and training directly on such heterogeneous data often yields suboptimal models. We propose a dataset-model co-evolution process; at each iteration of our method, the dataset becomes progressively higher quality, and the model improves accordingly. To avoid destructive self-consuming loops, at each generation, we treat the synthetically improved samples as noisy, but at a slightly lower noisy level than the previous iteration, and we use Ambient Diffusion techniques for learning under corruption. Empirically, Ambient Dataloops achieve state-of-the-art performance in unconditional and text-conditional image generation and de novo protein design. We further provide a theoretical justification for the proposed framework that captures the benefits of the data looping procedure.

</details>


### [164] [CASL: Concept-Aligned Sparse Latents for Interpreting Diffusion Models](https://arxiv.org/abs/2601.15441)
*Zhenghao He,Guangzhi Xiong,Boyang Wang,Sanchit Sinha,Aidong Zhang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Internal activations of diffusion models encode rich semantic information, but interpreting such representations remains challenging. While Sparse Autoencoders (SAEs) have shown promise in disentangling latent representations, existing SAE-based methods for diffusion model understanding rely on unsupervised approaches that fail to align sparse features with human-understandable concepts. This limits their ability to provide reliable semantic control over generated images. We introduce CASL (Concept-Aligned Sparse Latents), a supervised framework that aligns sparse latent dimensions of diffusion models with semantic concepts. CASL first trains an SAE on frozen U-Net activations to obtain disentangled latent representations, and then learns a lightweight linear mapping that associates each concept with a small set of relevant latent dimensions. To validate the semantic meaning of these aligned directions, we propose CASL-Steer, a controlled latent intervention that shifts activations along the learned concept axis. Unlike editing methods, CASL-Steer is used solely as a causal probe to reveal how concept-aligned latents influence generated content. We further introduce the Editing Precision Ratio (EPR), a metric that jointly measures concept specificity and the preservation of unrelated attributes. Experiments show that our method achieves superior editing precision and interpretability compared to existing approaches. To the best of our knowledge, this is the first work to achieve supervised alignment between latent representations and semantic concepts in diffusion models.

</details>


### [165] [Learning from Synthetic Data: Limitations of ERM](https://arxiv.org/abs/2601.15468)
*Kareem Amin,Alex Bie,Weiwei Kong,Umar Syed,Sergei Vassilvitskii*

Main category: cs.LG

TL;DR: 本文研究在自然数据和LLM生成数据混合场景下的学习理论问题，发现传统经验风险最小化(ERM)方法存在局限，需要通过加权算法改进才能有效学习真实分布。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的普及和低成本，合成内容污染逐渐普遍，各种自然内容中都可能混入LLM生成数据。研究者想要探索在这种混合数据设置下的基本学习理论问题，因为学习算法通常无法区分数据来源。

Method: 研究者将场景建模为一系列学习任务，输入是自然数据和合成数据的混合，学习算法不知道单个样本的来源。他们研究了ERM在这种设置下的可能性和局限性。对于d维分布均值估计问题，他们比较了ERM和一种对来自不同代数据的样本分配非均匀权重的算法。在PAC学习设置中，他们也测试了各种算法的表现。

Result: 研究发现：1)对于分布均值估计，ERM能收敛到真实均值，但被非均匀加权算法超越；2)在PAC学习场景中，ERM不一定能收敛到真实概念，这与模型崩溃文献一致；3)存在算法能够学习任意VC类和任意污染量的正确假设。

Conclusion: 在自然和合成数据混合的学习场景中，传统的ERM方法存在不足，需要开发新的算法(如非均匀加权)来处理数据污染问题，这些算法能够在更广泛的条件下保证正确学习。

Abstract: The prevalence and low cost of LLMs have led to a rise of synthetic content. From review sites to court documents, ``natural'' content has been contaminated by data points that appear similar to natural data, but are in fact LLM-generated. In this work we revisit fundamental learning theory questions in this, now ubiquitous, setting. We model this scenario as a sequence of learning tasks where the input is a mix of natural and synthetic data, and the learning algorithms are oblivious to the origin of any individual example.
  We study the possibilities and limitations of ERM in this setting. For the problem of estimating the mean of an arbitrary $d$-dimensional distribution, we find that while ERM converges to the true mean, it is outperformed by an algorithm that assigns non-uniform weights to examples from different generations of data. For the PAC learning setting, the disparity is even more stark. We find that ERM does not always converge to the true concept, echoing the model collapse literature. However, we show there are algorithms capable of learning the correct hypothesis for arbitrary VC classes and arbitrary amounts of contamination.

</details>


### [166] [Panther: Faster and Cheaper Computations with Randomized Numerical Linear Algebra](https://arxiv.org/abs/2601.15473)
*Fahd Seddik,Abdulrahman Elbedewy,Gaser Sami,Mohamed Abdelmoniem,Yahia Zakaria*

Main category: cs.LG

TL;DR: 该论文介绍了Panther库，这是一个用于深度学习的RandNLA框架，可通过算法压缩实现显著的内存节省。


<details>
  <summary>Details</summary>
Motivation: 现代深度学习训练受GPU内存和计算能力限制，但RandNLA压缩技术缺乏统一的、生产级的实现库，阻碍了其广泛应用。

Method: 论文提出了Panther库，它是一个与PyTorch兼容的高性能框架，整合了多种RandNLA算法，包括草图线性层、2D卷积、多头注意力等标准组件的降维替换。该库采用C++/CUDA后端（pawX）进行优化，支持CPU和GPU运行。

Result: 在BERT上替换标准PyTorch线性层为Panther层（仅需几行代码），实现了高达75%的内存节省，且保持了相当的损失性能。

Conclusion: Panther库为RandNLA技术提供了一套易于采用的高性能实现，有效解决了深度学习训练中的内存约束问题。

Abstract: Training modern deep learning models is increasingly constrained by GPU memory and compute limits. While Randomized Numerical Linear Algebra (RandNLA) offers proven techniques to compress these models, the lack of a unified, production-grade library prevents widely adopting these methods. We present Panther, a PyTorch-compatible library that consolidates established RandNLA algorithms into a single high-performance framework. Panther engineers efficient, drop-in replacements for standard components including sketched linear layers, 2D convolution, multi-head attention, and randomized matrix decompositions (such as pivoted CholeskyQR). By implementing a custom C++/CUDA backend (pawX), Panther provides an optimized implementation that can run on both CPUs and GPUs. We demonstrate the effectiveness of RandNLA techniques and Panther's ease of adoption. By replacing standard PyTorch linear layers with Panther layers (requiring only a few lines of code) we achieve significant memory savings (up to 75%) on BERT while maintaining comparable loss. Source code is available (MIT License) at https://github.com/FahdSeddik/panther, along with demonstration video at https://youtu.be/7M3RQb4KWxs.

</details>


### [167] [Multi-Targeted Graph Backdoor Attack](https://arxiv.org/abs/2601.15474)
*Md Nabi Newaz Khan,Abdullah Arafat Miah,Yu Bi*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Graph neural network (GNN) have demonstrated exceptional performance in solving critical problems across diverse domains yet remain susceptible to backdoor attacks. Existing studies on backdoor attack for graph classification are limited to single target attack using subgraph replacement based mechanism where the attacker implants only one trigger into the GNN model. In this paper, we introduce the first multi-targeted backdoor attack for graph classification task, where multiple triggers simultaneously redirect predictions to different target labels. Instead of subgraph replacement, we propose subgraph injection which preserves the structure of the original graphs while poisoning the clean graphs. Extensive experiments demonstrate the efficacy of our approach, where our attack achieves high attack success rates for all target labels with minimal impact on the clean accuracy. Experimental results on five dataset demonstrate the superior performance of our attack framework compared to the conventional subgraph replacement-based attack. Our analysis on four GNN models confirms the generalization capability of our attack which is effective regardless of the GNN model architectures and training parameters settings. We further investigate the impact of the attack design parameters including injection methods, number of connections, trigger sizes, trigger edge density and poisoning ratios. Additionally, our evaluation against state-of-the-art defenses (randomized smoothing and fine-pruning) demonstrates the robustness of our proposed multi-target attacks. This work highlights the GNN vulnerability against multi-targeted backdoor attack in graph classification task. Our source codes will be available at https://github.com/SiSL-URI/Multi-Targeted-Graph-Backdoor-Attack.

</details>


### [168] [Early predicting of hospital admission using machine learning algorithms: Priority queues approach](https://arxiv.org/abs/2601.15481)
*Jakub Antczak,James Montgomery,Małgorzata O'Reilly,Zbigniew Palmowski,Richard Turner*

Main category: cs.LG

TL;DR: 本研究比较了SARIMAX、XGBoost和LSTM三种预测急诊科日到达人数的模型，通过分解八个科室类别和按临床复杂度分层，考虑了新冠疫情的数据异常处理，结果显示所有模型均优于季节朴素基线，XGBoost对总日入院预测最准确，SARIMAX对高复杂度病例预测略优，但均低估突发高峰。


<details>
  <summary>Details</summary>
Motivation: 急诊科过度拥挤影响患者安全和运营效率，需要准确的预测来优化资源配置。研究通过分解科室和临床复杂度维度，提高了预测的精细化程度，并处理了新冠疫情带来的数据异常问题。

Method: 基于2017-2021年澳大利亚一家三级转诊医院的数据，研究将需求分解为八个科室类别，并按临床复杂度分层。为处理新冠疫情数据异常，使用Prophet模型生成了异常时期的合成反事实值。对比了SARIMAX、XGBoost和LSTM三种模型对未来七天日到达人数的预测性能。

Result: 所有三种模型均优于季节朴素基线。XGBoost在预测总日入院时表现最佳，平均绝对误差为6.63；SARIMAX在预测高复杂度病例时略优，MAE为3.77。但所有模型均存在低估突发性、偶发性患者激增的共性局限。

Conclusion: 虽然SARIMAX、XGBoost和LSTM能够有效捕捉日常模式，但均无法准确预测突然的、偶发性的患者高峰，这提示未来研究需要进一步加强对异常事件的预测能力。

Abstract: Emergency Department overcrowding is a critical issue that compromises patient safety and operational efficiency, necessitating accurate demand forecasting for effective resource allocation. This study evaluates and compares three distinct predictive models: Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors (SARIMAX), EXtreme Gradient Boosting (XGBoost) and Long Short-Term Memory (LSTM) networks for forecasting daily ED arrivals over a seven-day horizon. Utilizing data from an Australian tertiary referral hospital spanning January 2017 to December 2021, this research distinguishes itself by decomposing demand into eight specific ward categories and stratifying patients by clinical complexity. To address data distortions caused by the COVID-19 pandemic, the study employs the Prophet model to generate synthetic counterfactual values for the anomalous period. Experimental results demonstrate that all three proposed models consistently outperform a seasonal naive baseline. XGBoost demonstrated the highest accuracy for predicting total daily admissions with a Mean Absolute Error of 6.63, while the statistical SARIMAX model proved marginally superior for forecasting major complexity cases with an MAE of 3.77. The study concludes that while these techniques successfully reproduce regular day-to-day patterns, they share a common limitation in underestimating sudden, infrequent surges in patient volume.

</details>


### [169] [Martingale Foresight Sampling: A Principled Approach to Inference-Time LLM Decoding](https://arxiv.org/abs/2601.15482)
*Huayu Li,ZhengXiao He,Siyuan Tian,Jinghao Wen,Ao Li*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Standard autoregressive decoding in large language models (LLMs) is inherently short-sighted, often failing to find globally optimal reasoning paths due to its token-by-token generation process. While inference-time strategies like foresight sampling attempt to mitigate this by simulating future steps, they typically rely on ad-hoc heuristics for valuing paths and pruning the search space. This paper introduces Martingale Foresight Sampling (MFS), a principled framework that reformulates LLM decoding as a problem of identifying an optimal stochastic process. By modeling the quality of a reasoning path as a stochastic process, we leverage Martingale theory to design a theoretically-grounded algorithm. Our approach replaces heuristic mechanisms with principles from probability theory: step valuation is derived from the Doob Decomposition Theorem to measure a path's predictable advantage, path selection uses Optional Stopping Theory for principled pruning of suboptimal candidates, and an adaptive stopping rule based on the Martingale Convergence Theorem terminates exploration once a path's quality has provably converged. Experiments on six reasoning benchmarks demonstrate that MFS surpasses state-of-the-art methods in accuracy while significantly improving computational efficiency. Code will be released at https://github.com/miraclehetech/EACL2026-Martingale-Foresight-Sampling.

</details>


### [170] [MARS: Unleashing the Power of Speculative Decoding via Margin-Aware Verification](https://arxiv.org/abs/2601.15498)
*Jingwei Song,Xinyu Wang,Hanbin Wang,Xiaoxuan Lei,Bill Shi,Shixin Han,Eric Yang,Xiao-Wen Chang,Lynn Ai*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Speculative Decoding (SD) accelerates autoregressive large language model (LLM) inference by decoupling generation and verification. While recent methods improve draft quality by tightly coupling the drafter with the target model, the verification mechanism itself remains largely unchanged, relying on strict token-level rejection sampling. In practice, modern LLMs frequently operate in low-margin regimes where the target model exhibits weak preference among top candidates. In such cases, rejecting plausible runner-up tokens yields negligible information gain while incurring substantial rollback cost, leading to a fundamental inefficiency in verification. We propose Margin-Aware Speculative Verification, a training-free and domain-agnostic verification strategy that adapts to the target model's local decisiveness. Our method conditions verification on decision stability measured directly from the target logits and relaxes rejection only when strict verification provides minimal benefit. Importantly, the approach modifies only the verification rule and is fully compatible with existing target-coupled speculative decoding frameworks. Extensive experiments across model scales ranging from 8B to 235B demonstrate that our method delivers consistent and significant inference speedups over state-of-the-art baselines while preserving generation quality across diverse benchmarks.

</details>


### [171] [Data-driven Lake Water Quality Forecasting for Time Series with Missing Data using Machine Learning](https://arxiv.org/abs/2601.15503)
*Rishit Chatterjee,Tahiya Chowdhury*

Main category: cs.LG

TL;DR: 该研究针对志愿湖泊监测数据不连续、缺失多的问题，开发了一种基于岭回归的Secchi盘深度预测方法，通过确定最小训练样本量和特征集，实现目标精度下的高效监测方案。


<details>
  <summary>Details</summary>
Motivation: 志愿湖泊监测数据因冰封、天气限制和人为错误导致时间序列存在大量缺失和间断，这给有害藻华预报和预警带来困难，需要开发能处理数据缺失的高效预测方法。

Method: 研究使用多链方程多重插补处理数据缺失，采用归一化平均绝对误差进行评估对比，在六种候选方法中岭回归表现最佳；通过反向最近历史协议确定最小训练样本量，并识别最小特征子集以满足精度目标。

Result: 岭回归平均测试性能最佳；研究确定平均每个湖泊需约176个训练样本可达到完整历史精度95%；仅需4个特征即可匹配13个特征基线的精度；达成5%精度目标仅需约64个最近样本和1个预测因子。

Conclusion: 研究提出的联合可行性策略将近期历史长度和特征选择统一在固定精度目标下，为湖泊研究人员提供了简明的采样努力和测量优先级设置规则，增强了针对性监测的实用性。

Abstract: Volunteer-led lake monitoring yields irregular, seasonal time series with many gaps arising from ice cover, weather-related access constraints, and occasional human errors, complicating forecasting and early warning of harmful algal blooms. We study Secchi Disk Depth (SDD) forecasting on a 30-lake, data-rich subset drawn from three decades of in situ records collected across Maine lakes. Missingness is handled via Multiple Imputation by Chained Equations (MICE), and we evaluate performance with a normalized Mean Absolute Error (nMAE) metric for cross-lake comparability. Among six candidates, ridge regression provides the best mean test performance. Using ridge regression, we then quantify the minimal sample size, showing that under a backward, recent-history protocol, the model reaches within 5% of full-history accuracy with approximately 176 training samples per lake on average. We also identify a minimal feature set, where a compact four-feature subset matches the thirteen-feature baseline within the same 5% tolerance. Bringing these results together, we introduce a joint feasibility function that identifies the minimal training history and fewest predictors sufficient to achieve the target of staying within 5% of the complete-history, full-feature baseline. In our study, meeting the 5% accuracy target required about 64 recent samples and just one predictor per lake, highlighting the practicality of targeted monitoring. Hence, our joint feasibility strategy unifies recent-history length and feature choice under a fixed accuracy target, yielding a simple, efficient rule for setting sampling effort and measurement priorities for lake researchers.

</details>


### [172] [Machine learning-enhanced non-amnestic Alzheimer's disease diagnosis from MRI and clinical features](https://arxiv.org/abs/2601.15530)
*Megan A. Witherow,Michael L. Evans,Ahmed Temtam,Hamid Okhravi,Khan M. Iftekharuddin*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Alzheimer's disease (AD), defined as an abnormal buildup of amyloid plaques and tau tangles in the brain can be diagnosed with high accuracy based on protein biomarkers via PET or CSF analysis. However, due to the invasive nature of biomarker collection, most AD diagnoses are made in memory clinics using cognitive tests and evaluation of hippocampal atrophy based on MRI. While clinical assessment and hippocampal volume show high diagnostic accuracy for amnestic or typical AD (tAD), a substantial subgroup of AD patients with atypical presentation (atAD) are routinely misdiagnosed. To improve diagnosis of atAD patients, we propose a machine learning approach to distinguish between atAD and non-AD cognitive impairment using clinical testing battery and MRI data collected as standard-of-care. We develop and evaluate our approach using 1410 subjects across four groups (273 tAD, 184 atAD, 235 non-AD, and 685 cognitively normal) collected from one private data set and two public data sets from the National Alzheimer's Coordinating Center (NACC) and the Alzheimer's Disease Neuroimaging Initiative (ADNI). We perform multiple atAD vs. non-AD classification experiments using clinical features and hippocampal volume as well as a comprehensive set of MRI features from across the brain. The best performance is achieved by incorporating additional important MRI features, which outperforms using hippocampal volume alone. Furthermore, we use the Boruta statistical approach to identify and visualize significant brain regions distinguishing between diagnostic groups. Our ML approach improves the percentage of correctly diagnosed atAD cases (the recall) from 52% to 69% for NACC and from 34% to 77% for ADNI, while achieving high precision. The proposed approach has important implications for improving diagnostic accuracy for non-amnestic atAD in clinical settings using only clinical testing battery and MRI.

</details>


### [173] [QUAIL: Quantization Aware Unlearning for Mitigating Misinformation in LLMs](https://arxiv.org/abs/2601.15538)
*Himanshu Mishra,Kanwal Mehreen*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Machine unlearning aims to remove specific knowledge (e.g., copyrighted or private data) from a trained model without full retraining. In practice, models are often quantized (e.g., 4-bit) for deployment, but we find that quantization can catastrophically restore forgotten information [1]. In this paper, we (1) analyze why low-bit quantization undermines unlearning, and (2) propose a quantization-aware unlearning method to mitigate this. We first compute weight-change statistics and bucket overlaps in quantization to show that typical unlearning updates are too small to cross quantization thresholds. Building on this insight, we introduce a logits space hinge loss: for each forget example, we force the output logits of the unlearned model to differ from the original model by at least a margin (half the quantization step). This ensures forgotten examples remain distinguishable even after quantization. We evaluate on language and classification tasks (including a Twitter misinformation dataset) and show our method preserves forgetting under 4-bit quantization, whereas existing methods almost entirely recover the forgotten knowledge.

</details>


### [174] [PRISM: Deriving the Transformer as a Signal-Denoising Operator via Maximum Coding Rate Reduction](https://arxiv.org/abs/2601.15540)
*Dongchen Huang*

Main category: cs.LG

TL;DR: 本文提出Prism架构，这是一种基于注意力机制的可解释白盒模型，通过最大化编码率减少(MCR²)原理推导，使用几何归纳偏置实现无监督功能解耦。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型特别是Transformer常被视为黑盒而缺乏可解释性。作者认为可解释性和性能不应是权衡关系，可以通过几何构造原则统一实现。

Method: 1. 将注意力机制建模为信号噪声流形上的梯度上升过程；2. 引入两个物理约束：过完备字典扩展表示相位空间，无理频率分离(π-RoPE)强制信号和噪声子空间的不相干性；3. 在TinyStories数据集上验证谱动力学。

Result: Prism能自发地将注意力头专业化到谱域不同的区域：低频头捕捉长程因果依赖(信号)，高频头处理局部句法约束(噪声)，实现了功能解耦。

Conclusion: 几何归纳偏置可以作为物理约束，单独足以诱导无监督功能解耦，表明通过原则性几何构造可以统一可解释性和性能。

Abstract: Deep learning models, particularly Transformers, are often criticized as "black boxes" and lack interpretability. We propose Prism, a white-box attention-based architecture derived from the principles of Maximizing Coding Rate Reduction ($\text{MCR}^2$). By modeling the attention mechanism as a gradient ascent process on a distinct signal-noise manifold, we introduce two physical constraints: an overcomplete dictionary to expand the representational phase space, and an irrational frequency separation ($π$-RoPE) to enforce incoherence between signal and noise subspaces. We demonstrate that these geometric inductive biases can be viewed as a physical constraint and they are sufficient to induce unsupervised functional disentanglement alone. Using TinyStories as a controlled testbed for verifying spectral dynamics, we observe that Prism spontaneously specializes its attention heads into spectrally distinct regimes: low-frequency heads capturing long-range causal dependencies (signal) and high-frequency heads handling local syntactic constraints (noise). Our results suggest that interpretability and performance are not a trade-off, but can be unified through principled geometric construction.

</details>


### [175] [RDumb++: Drift-Aware Continual Test-Time Adaptation](https://arxiv.org/abs/2601.15544)
*Himanshu Mishra*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Continual Test-Time Adaptation (CTTA) seeks to update a pretrained model during deployment using only the incoming, unlabeled data stream. Although prior approaches such as Tent, EATA etc. provide meaningful improvements under short evolving shifts, they struggle when the test distribution changes rapidly or over extremely long horizons. This challenge is exemplified by the CCC benchmark, where models operate over streams of 7.5M samples with continually changing corruption types and severities. We propose RDumb++, a principled extension of RDumb that introduces two drift-detection mechanisms i.e entropy-based drift scoring and KL-divergence drift scoring, together with adaptive reset strategies. These mechanisms allow the model to detect when accumulated adaptation becomes harmful and to recover before prediction collapse occurs. Across CCC-medium with three speeds and three seeds (nine runs, each containing one million samples), RDumb++ consistently surpasses RDumb, yielding approx 3% absolute accuracy gains while maintaining stable adaptation throughout the entire stream. Ablation experiments on drift thresholds and reset strengths further show that drift-aware resetting is essential for preventing collapse and achieving reliable long-horizon CTTA.

</details>


### [176] [Beyond validation loss: Clinically-tailored optimization metrics improve a model's clinical performance](https://arxiv.org/abs/2601.15546)
*Charles B. Delahunt,Courosh Mehanian,Daniel E. Shea,Matthew P. Horning*

Main category: cs.LG

TL;DR: 研究表明，在医疗机器学习中，使用临床定制的评估指标优化模型，比传统的验证损失更能提升临床任务表现。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习通常使用验证损失来优化模型，但医疗机器学习的目标是满足特定的临床需求，而非单纯最小化训练损失函数。临床需求可以通过定制化指标更精确地捕捉，这些指标能更好地反映模型在实际医疗场景中的表现。

Method: 本文进行了两项对照实验，比较了使用临床定制指标与传统验证损失在模型优化中的效果。临床定制指标针对具体的临床需求设计，虽然它们不一定可微分，但在超参数选择和训练停止点确定等优化任务中仍然有效。

Result: 实验结果显示，使用临床定制指标进行模型优化，相比使用验证损失，能在临床任务上获得更好的性能表现。这表明针对临床需求设计的评估指标能更有效地指导模型优化过程。

Conclusion: 虽然定义和集成临床定制指标需要额外工作，但这种做法能让医疗机器学习模型更好地满足核心目标——在临床实践中表现优秀。基于临床需求的优化指标应该被更广泛地采用，以提升医疗AI系统的实用性和效果。

Abstract: A key task in ML is to optimize models at various stages, e.g. by choosing hyperparameters or picking a stopping point. A traditional ML approach is to use validation loss, i.e. to apply the training loss function on a validation set to guide these optimizations. However, ML for healthcare has a distinct goal from traditional ML: Models must perform well relative to specific clinical requirements, vs. relative to the loss function used for training. These clinical requirements can be captured more precisely by tailored metrics. Since many optimization tasks do not require the driving metric to be differentiable, they allow a wider range of options, including the use of metrics tailored to be clinically-relevant. In this paper we describe two controlled experiments which show how the use of clinically-tailored metrics provide superior model optimization compared to validation loss, in the sense of better performance on the clinical task. The use of clinically-relevant metrics for optimization entails some extra effort, to define the metrics and to code them into the pipeline. But it can yield models that better meet the central goal of ML for healthcare: strong performance in the clinic.

</details>


### [177] [Learning Neural Operators from Partial Observations via Latent Autoregressive Modeling](https://arxiv.org/abs/2601.15547)
*Jingren Hou,Hong Wang,Pengyu Xu,Chang Gao,Huafeng Liu,Liping Jing*

Main category: cs.LG

TL;DR: 该论文提出了第一个从部分观测数据学习神经算子的系统框架LAPO，解决真实科学应用中不完备观测数据的难题


<details>
  <summary>Details</summary>
Motivation: 真实科学应用常遇到观测数据不完整的问题（如传感器限制、地理约束等），而现有神经算子假设空间输入完全可观测，这严重限制了实际应用

Method: 提出LAPO框架，包含两个核心组件：(1) mask-to-predict训练策略，通过战略性地掩蔽已观测区域创建人工监督；(2) 物理感知潜在传播器，在潜在空间通过边界优先自回归生成重建解。还开发了专门基准POBench-PDE

Result: LAPO在三个PDE控制任务上实现了18-69%的相对L2误差降低，在缺失率低于50%的补丁式缺失情况下表现最佳，包括真实气候预测任务。能有效处理高达75%缺失率的实际场景

Conclusion: 该方法在一定程度上弥合了理想化研究环境与真实世界科学计算复杂性之间的差距，为部分观测条件下的神经算子学习提供了系统解决方案

Abstract: Real-world scientific applications frequently encounter incomplete observational data due to sensor limitations, geographic constraints, or measurement costs. Although neural operators significantly advanced PDE solving in terms of computational efficiency and accuracy, their underlying assumption of fully-observed spatial inputs severely restricts applicability in real-world applications. We introduce the first systematic framework for learning neural operators from partial observation. We identify and formalize two fundamental obstacles: (i) the supervision gap in unobserved regions that prevents effective learning of physical correlations, and (ii) the dynamic spatial mismatch between incomplete inputs and complete solution fields. Specifically, our proposed Latent Autoregressive Neural Operator~(\ours) introduces two novel components designed explicitly to address the core difficulties of partial observations: (i) a mask-to-predict training strategy that creates artificial supervision by strategically masking observed regions, and (ii) a Physics-Aware Latent Propagator that reconstructs solutions through boundary-first autoregressive generation in latent space. Additionally, we develop POBench-PDE, a dedicated and comprehensive benchmark designed specifically for evaluating neural operators under partial observation conditions across three PDE-governed tasks. \ours achieves state-of-the-art performance with 18--69$\%$ relative L2 error reduction across all benchmarks under patch-wise missingness with less than 50$\%$ missing rate, including real-world climate prediction. Our approach effectively addresses practical scenarios involving up to 75$\%$ missing rate, to some extent bridging the existing gap between idealized research settings and the complexities of real-world scientific computing.

</details>


### [178] [BanditLP: Large-Scale Stochastic Optimization for Personalized Recommendations](https://arxiv.org/abs/2601.15552)
*Phuc Nguyen,Benjamin Zelditch,Joyce Chen,Rohit Patra,Changshuai Wei*

Main category: cs.LG

TL;DR: BanditLP是一个可扩展的多利益相关方上下文bandit框架，它将神经Thompson Sampling与大规模线性规划相结合，用于学习特定目标结果和约束动作选择。


<details>
  <summary>Details</summary>
Motivation: 现有系统在规模化和处理多利益相关方约束方面存在限制，需要一种既能进行有效探索又能满足复杂约束的解决方案，特别是用于像LinkedIn邮件营销这样的实际生产系统。

Method: 结合神经Thompson Sampling来学习目标特定的结果，并在服务时使用能够处理数十亿变量的大规模线性规划来选择约束动作。该方法与应用无关，兼容任意的神经架构。

Result: 在公共基准和合成数据上的实验显示，相比强基线方法有稳定的提升。在LinkedIn邮件营销系统中的实际应用展示了业务成果，证明了集成探索和约束优化的价值。

Conclusion: BanditLP框架成功地将神经探索方法与大规模约束优化相结合，实现了在生产环境中的有效部署，验证了集成探索和优化在真实世界应用中的价值。

Abstract: We present BanditLP, a scalable multi-stakeholder contextual bandit framework that unifies neural Thompson Sampling for learning objective-specific outcomes with a large-scale linear program for constrained action selection at serving time. The methodology is application-agnostic, compatible with arbitrary neural architectures, and deployable at web scale, with an LP solver capable of handling billions of variables. Experiments on public benchmarks and synthetic data show consistent gains over strong baselines. We apply this approach in LinkedIn's email marketing system and demonstrate business win, illustrating the value of integrated exploration and constrained optimization in production.

</details>


### [179] [Deep Learning for Perishable Inventory Systems with Human Knowledge](https://arxiv.org/abs/2601.15589)
*Xuan Liao,Zhenkang Peng,Ying Rong*

Main category: cs.LG

TL;DR: 该研究开发了基于深度学习的端到端方法，用于解决具有随机提前期和未知需求过程与提前期分布的易腐品库存管理问题，通过集成启发式策略结构来提升学习效率和性能表现。


<details>
  <summary>Details</summary>
Motivation: 易腐品库存管理面临有限生命周期挑战，传统方法需要大量历史数据且难以适应未知的需求和提前期分布，而端到端学习在有限数据下效率不足，需要结合库存理论来提升学习效率。

Method: 采用边际成本核算方案构建统一的损失函数，提出了两种端到端方法：纯黑盒方法（E2E-BB）直接输出订购量；结构引导方法（E2E-PIL）嵌入预计库存水平策略；并进一步通过同质性开发了增强策略（E2E-BPIL）。

Result: 合成和真实数据实验显示：E2E-BB被E2E-PIL超越，E2E-PIL又被E2E-BPIL进一步改进；集成启发式策略结构减少了有效模型复杂度，在仅适度损失灵活性的情况下显著提升了学习效率。

Conclusion: 基于深度学习的决策工具在人机知识的引导下更有效且鲁棒，凸显了先进分析与库存理论相结合的价值，为数据驱动的库存管理提供了新思路。

Abstract: Managing perishable products with limited lifetimes is a fundamental challenge in inventory management, as poor ordering decisions can quickly lead to stockouts or excessive waste. We study a perishable inventory system with random lead times in which both the demand process and the lead time distribution are unknown. We consider a practical setting where orders are placed using limited historical data together with observed covariates and current system states. To improve learning efficiency under limited data, we adopt a marginal cost accounting scheme that assigns each order a single lifetime cost and yields a unified loss function for end-to-end learning. This enables training a deep learning-based policy that maps observed covariates and system states directly to order quantities. We develop two end-to-end variants: a purely black-box approach that outputs order quantities directly (E2E-BB), and a structure-guided approach that embeds the projected inventory level (PIL) policy, capturing inventory effects through explicit computation rather than additional learning (E2E-PIL). We further show that the objective induced by E2E-PIL is homogeneous of degree one, enabling a boosting technique from operational data analytics (ODA) that yields an enhanced policy (E2E-BPIL). Experiments on synthetic and real data establish a robust performance ordering: E2E-BB is dominated by E2E-PIL, which is further improved by E2E-BPIL. Using an excess-risk decomposition, we show that embedding heuristic policy structure reduces effective model complexity and improves learning efficiency with only a modest loss of flexibility. More broadly, our results suggest that deep learning-based decision tools are more effective and robust when guided by human knowledge, highlighting the value of integrating advanced analytics with inventory theory.

</details>


### [180] [When Sharpening Becomes Collapse: Sampling Bias and Semantic Coupling in RL with Verifiable Rewards](https://arxiv.org/abs/2601.15609)
*Mingyuan Fan,Weiguang Han,Daixin Wang,Cen Chen,Zhiqiang Zhang,Jun Zhou*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is a central paradigm for turning large language models (LLMs) into reliable problem solvers, especially in logic-heavy domains. Despite its empirical success, it remains unclear whether RLVR elicits novel capabilities or merely sharpens the distribution over existing knowledge. We study this by formalizing over-sharpening, a phenomenon where the policy collapses onto limited modes, suppressing valid alternatives. At a high level, we discover finite-batch updates intrinsically bias learning toward sampled modes, triggering a collapse that propagates globally via semantic coupling. To mitigate this, we propose inverse-success advantage calibration to prioritize difficult queries and distribution-level calibration to diversify sampling via a memory network. Empirical evaluations validate that our strategies can effectively improve generalization.

</details>


### [181] [Closing the Gap on the Sample Complexity of 1-Identification](https://arxiv.org/abs/2601.15620)
*Zitian Li,Wang Chi Cheung*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: 1-identification is a fundamental multi-armed bandit formulation on pure exploration. An agent aims to determine whether there exists a qualified arm whose mean reward is not less than a known threshold $μ_0$, or to output \textsf{None} if it believes such an arm does not exist. The agent needs to guarantee its output is correct with probability at least $1-δ$, while making expected total pulling times $\mathbb{E}τ$ as small as possible. We work on 1-identification with two main contributions. (1) We utilize an optimization formulation to derive a new lower bound of $\mathbb{E}τ$, when there is at least one qualified arm. (2) We design a new algorithm, deriving tight upper bounds whose gap to lower bounds are up to a polynomial of logarithm factor across all problem instance. Our result complements the analysis of $\mathbb{E}τ$ when there are multiple qualified arms, which is an open problem left by history literature.

</details>


### [182] [Robust Tool Use via Fission-GRPO: Learning to Recover from Execution Errors](https://arxiv.org/abs/2601.15625)
*Zhiwei Zhang,Fei Zhao,Rui Wang,Zezhong Wang,Bin Liang,Jiakang Wang,Yao Hu,Shaosheng Cao,Kam-Fai Wong*

Main category: cs.LG

TL;DR: 论文提出Fission-GRPO框架，旨在解决LLM在多轮工具调用中遇到错误时的恢复能力不足问题，通过将执行错误转化为校正监督，提升模型在真实部署中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 目前LLM在工具调用方面表现良好，但在多轮执行中遇到错误时容易退化，重复无效调用而无法根据错误反馈自我校正。这种脆弱性阻碍了在实际部署中的可靠性，因为工具交互过程中错误是不可避免的。现有方法存在局限：标准RL将错误视为稀疏负奖励，不提供恢复指导；预先收集的合成错误校正数据集与模型在线错误模式存在分布不匹配。

Method: 提出Fission-GRPO框架，核心机制是将每个失败轨迹分裂成新的训练实例：1）通过微调的Error Simulator添加诊断反馈；2）重新采样恢复轨迹。这使得模型能够从探索过程中自己犯的错误中学习，而不是依赖静态的预收集错误案例。该方法将执行错误转化为RL训练循环内的校正监督。

Result: 在BFCL v4 Multi-Turn基准上，Fission-GRPO将Qwen3-8B的错误恢复率提升了5.7%（绝对值）。更重要的是，相比GRPO获得了4%的整体准确率提升（从42.75%提高到46.75%），且优于专门的工具使用智能体。

Conclusion: Fission-GRPO通过将执行错误转化为校正监督的创新方法，有效解决了LLM在多轮工具调用中的错误恢复问题。该方法使模型能够从自身探索过程中的错误中学习，显著提高了错误恢复率和整体工具调用准确率，为实现可靠的真实世界部署提供了有前景的解决方案。

Abstract: Large language models (LLMs) can call tools effectively, yet they remain brittle in multi-turn execution: following a tool call error, smaller models often degenerate into repetitive invalid re-invocations, failing to interpret error feedback and self-correct. This brittleness hinders reliable real-world deployment, where the execution errors are inherently inevitable during tool interaction procedures. We identify a key limitation of current approaches: standard reinforcement learning (RL) treats errors as sparse negative rewards, providing no guidance on how to recover, while pre-collected synthetic error-correction datasets suffer from distribution mismatch with the model's on-policy error modes. To bridge this gap, we propose Fission-GRPO, a framework that converts execution errors into corrective supervision within the RL training loop. Our core mechanism fissions each failed trajectory into a new training instance by augmenting it with diagnostic feedback from a finetuned Error Simulator, then resampling recovery rollouts on-policy. This enables the model to learn from the precise errors it makes during exploration, rather than from static, pre-collected error cases. On the BFCL v4 Multi-Turn, Fission-GRPO improves the error recovery rate of Qwen3-8B by 5.7% absolute, crucially, yielding a 4% overall accuracy gain (42.75% to 46.75%) over GRPO and outperforming specialized tool-use agents.

</details>


### [183] [Dualformer: Time-Frequency Dual Domain Learning for Long-term Time Series Forecasting](https://arxiv.org/abs/2601.15669)
*Jingjing Bai,Yoshinobu Kawahara*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Transformer-based models, despite their promise for long-term time series forecasting (LTSF), suffer from an inherent low-pass filtering effect that limits their effectiveness. This issue arises due to undifferentiated propagation of frequency components across layers, causing a progressive attenuation of high-frequency information crucial for capturing fine-grained temporal variations. To address this limitation, we propose Dualformer, a principled dual-domain framework that rethinks frequency modeling from a layer-wise perspective. Dualformer introduces three key components: (1) a dual-branch architecture that concurrently models complementary temporal patterns in both time and frequency domains; (2) a hierarchical frequency sampling module that allocates distinct frequency bands to different layers, preserving high-frequency details in lower layers while modeling low-frequency trends in deeper layers; and (3) a periodicity-aware weighting mechanism that dynamically balances contributions from the dual branches based on the harmonic energy ratio of inputs, supported theoretically by a derived lower bound. This design enables structured frequency modeling and adaptive integration of time-frequency features, effectively preserving high-frequency information and enhancing generalization. Extensive experiments conducted on eight widely used benchmarks demonstrate Dualformer's robustness and superior performance, particularly on heterogeneous or weakly periodic data. Our code is publicly available at https://github.com/Akira-221/Dualformer.

</details>


### [184] [Beyond Hard Writes and Rigid Preservation: Soft Recursive Least-Squares for Lifelong LLM Editing](https://arxiv.org/abs/2601.15686)
*Xinyu Wang,Sicheng Lyu,Yu Gu,Jerry Huang,Peng Lu,Yufei Cui,Xiao-Wen Chang*

Main category: cs.LG

TL;DR: 提出RLSEdit方法，通过递归最小二乘优化进行持续编辑，解决传统模型编辑在长期连续编辑中的稳定性-可塑性权衡问题，实现高效且稳定的长序列编辑。


<details>
  <summary>Details</summary>
Motivation: 现有模型编辑方法在长期连续编辑场景下面临稳定性与可塑性的矛盾：基于定位修改的硬写入方法会随时间积累干扰，而基于零空间的硬保护方法则容易覆盖过去的编辑，导致整体能力下降。需要一种能够在长期编辑中保持稳定性和可塑性的解决方案。

Method: 将编辑问题公式化为带软约束的在线二次优化，最小化累积的关键值拟合目标，并添加两个正则化项：控制与预训练权重的偏差、控制与指定锚点映射的偏差。通过Woodbury恒等式实现高效的在线递归更新，使每次编辑成本独立于历史长度，仅与当前编辑规模成比例。

Result: 在多个模型系列上的实验表明，RLSEdit能够稳定扩展到10,000次编辑，在编辑成功率和整体稳定性方面优于现有基线方法，关键优势包括：保持早期编辑效果，在GLUE和推理/代码基准测试中保持通用能力。

Conclusion: RLSEdit通过递归最小二乘优化框架，为大规模语言模型的持续编辑提供了高效而稳定的解决方案，平衡了编辑成功率的可塑性和整体性能的稳定性，能够适应现实部署中的长期编辑需求。

Abstract: Model editing updates a pre-trained LLM with new facts or rules without re-training, while preserving unrelated behavior. In real deployment, edits arrive as long streams, and existing editors often face a plasticity-stability dilemma: locate-then-edit "hard writes" can accumulate interference over time, while null-space-style "hard preservation" preserves only what is explicitly constrained, so past edits can be overwritten and unconstrained behaviors may deviate, degrading general capabilities in the many-edits regime. We propose RLSEdit, a recursive least-squares editor for long sequential editing. RLSEdit formulates editing as an online quadratic optimization with soft constraints, minimizing a cumulative key-value fitting objective with two regularizers that control for both deviation from the pre-trained weights and from a designated anchor mapping. The resulting update admits an efficient online recursion via the Woodbury identity, with per-edit cost independent of history length and scaling only with the current edit size. We further provide deviation bounds and an asymptotic characterization of the adherence-preservation trade-off in the many-edits regime. Experiments on multiple model families demonstrate stable scaling to 10K edits, outperforming strong baselines in both edit success and holistic stability -- crucially retaining early edits, and preserving general capabilities on GLUE and held-out reasoning/code benchmarks.

</details>


### [185] [Even GPT-5.2 Can't Count to Five: The Case for Zero-Error Horizons in Trustworthy LLMs](https://arxiv.org/abs/2601.15714)
*Ryoma Sato*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose Zero-Error Horizon (ZEH) for trustworthy LLMs, which represents the maximum range that a model can solve without any errors. While ZEH itself is simple, we demonstrate that evaluating the ZEH of state-of-the-art LLMs yields abundant insights. For example, by evaluating the ZEH of GPT-5.2, we found that GPT-5.2 cannot even compute the parity of a short string like 11000, and GPT-5.2 cannot determine whether the parentheses in ((((()))))) are balanced. This is surprising given the excellent capabilities of GPT-5.2. The fact that LLMs make mistakes on such simple problems serves as an important lesson when applying LLMs to safety-critical domains. By applying ZEH to Qwen2.5 and conducting detailed analysis, we found that while ZEH correlates with accuracy, the detailed behaviors differ, and ZEH provides clues about the emergence of algorithmic capabilities. Finally, while computing ZEH incurs significant computational cost, we discuss how to mitigate this cost by achieving up to one order of magnitude speedup using tree structures and online softmax.

</details>


### [186] [Towards Automated Kernel Generation in the Era of LLMs](https://arxiv.org/abs/2601.15727)
*Yang Yu,Peiyu Zang,Chi Hsu Tsai,Haiming Wu,Yixin Shen,Jialing Zhang,Haoyu Wang,Zhiyou Xiao,Jingze Shi,Yuyu Luo,Wentao Zhang,Chunlei Men,Guang Liu,Yonghua Lin*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The performance of modern AI systems is fundamentally constrained by the quality of their underlying kernels, which translate high-level algorithmic semantics into low-level hardware operations. Achieving near-optimal kernels requires expert-level understanding of hardware architectures and programming models, making kernel engineering a critical but notoriously time-consuming and non-scalable process. Recent advances in large language models (LLMs) and LLM-based agents have opened new possibilities for automating kernel generation and optimization. LLMs are well-suited to compress expert-level kernel knowledge that is difficult to formalize, while agentic systems further enable scalable optimization by casting kernel development as an iterative, feedback-driven loop. Rapid progress has been made in this area. However, the field remains fragmented, lacking a systematic perspective for LLM-driven kernel generation. This survey addresses this gap by providing a structured overview of existing approaches, spanning LLM-based approaches and agentic optimization workflows, and systematically compiling the datasets and benchmarks that underpin learning and evaluation in this domain. Moreover, key open challenges and future research directions are further outlined, aiming to establish a comprehensive reference for the next generation of automated kernel optimization. To keep track of this field, we maintain an open-source GitHub repository at https://github.com/flagos-ai/awesome-LLM-driven-kernel-generation.

</details>


### [187] [Rethinking Drug-Drug Interaction Modeling as Generalizable Relation Learning](https://arxiv.org/abs/2601.15771)
*Dong Xu,Jiantao Wu,Qihua Pan,Sisi Yuan,Zexuan Zhu,Junkai Ji*

Main category: cs.LG

TL;DR: 该论文提出一个关系学习的DDI预测框架GenRel-DDI，通过解耦药物实体与交互表示来提升模型对新药的泛化能力，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有DDI预测模型虽然在标准基准上表现良好，但在实际部署场景中泛化能力不足，特别是在处理未见药物和已验证交互稀缺的情况下。研究发现当前以药物为中心的模型嵌入空间中的邻近性并不能可靠地对应交互标签，仅增加模型容量无法改善泛化性能。

Method: 提出GenRel-DDI框架，将DDI预测重新定义为关系为中心的学习问题，让交互表示独立于药物身份进行学习。这种关系层面的抽象能够捕获可迁移的交互模式，从而泛化到未见药物和新药物对。

Result: 在多个基准测试上的广泛实验表明，GenRel-DDI始终显著优于最先进的方法，在严格的实体分离评估中取得了特别明显的性能提升，突显了关系学习对鲁棒DDI预测的有效性和实际效用。

Conclusion: 关系学习框架可以有效解决DDI预测中的泛化问题，通过独立于药物实体的交互表示学习捕获可迁移模式，为药物发现和临床开发中的实际应用提供更可靠的预测工具。

Abstract: Drug-drug interaction (DDI) prediction is central to drug discovery and clinical development, particularly in the context of increasingly prevalent polypharmacy. Although existing computational methods achieve strong performance on standard benchmarks, they often fail to generalize to realistic deployment scenarios, where most candidate drug pairs involve previously unseen drugs and validated interactions are scarce. We demonstrate that proximity in the embedding spaces of prevailing molecule-centric DDI models does not reliably correspond to interaction labels, and that simply scaling up model capacity therefore fails to improve generalization. To address these limitations, we propose GenRel-DDI, a generalizable relation learning framework that reformulates DDI prediction as a relation-centric learning problem, in which interaction representations are learned independently of drug identities. This relation-level abstraction enables the capture of transferable interaction patterns that generalize to unseen drugs and novel drug pairs. Extensive experiments across multiple benchmark demonstrate that GenRel-DDI consistently and significantly outperforms state-of-the-art methods, with particularly large gains on strict entity-disjoint evaluations, highlighting the effectiveness and practical utility of relation learning for robust DDI prediction. The code is available at https://github.com/SZU-ADDG/GenRel-DDI.

</details>


### [188] [Next Generation Active Learning: Mixture of LLMs in the Loop](https://arxiv.org/abs/2601.15773)
*Yuanyuan Qi,Xiaohao Yang,Jueqing Lu,Guoxiang Guo,Joanne Enticott,Gang Liu,Lan Du*

Main category: cs.LG

TL;DR: 提出MoLLM-AL框架，用多LLM混合模型替代人类标注，通过结合多个LLM优势增强标注鲁棒性，并引入标注差异性和负学习处理噪声标注。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在主动学习中被用作标注器以降低成本，但其标注质量往往达不到实际应用要求，需要提升LLM标注的鲁棒性和可靠性。

Method: 1) 使用基于混合LLM的标注模型替代人类标注；2) 引入标注差异度识别不可靠标注；3) 采用负学习增强学习效果。

Result: 实验表明该框架性能与人类标注相当，显著优于单LLM基准和其他LLM集成方法，且基于轻量级LLM可在本地机器运行。

Conclusion: MoLLM-AL框架有效解决了LLM标注质量问题，通过多LLM混合和噪声处理机制，实现了高效可靠的主动学习标注系统。

Abstract: With the rapid advancement and strong generalization capabilities of large language models (LLMs), they have been increasingly incorporated into the active learning pipelines as annotators to reduce annotation costs. However, considering the annotation quality, labels generated by LLMs often fall short of real-world applicability. To address this, we propose a novel active learning framework, Mixture of LLMs in the Loop Active Learning, replacing human annotators with labels generated through a Mixture-of-LLMs-based annotation model, aimed at enhancing LLM-based annotation robustness by aggregating the strengths of multiple LLMs. To further mitigate the impact of the noisy labels, we introduce annotation discrepancy and negative learning to identify the unreliable annotations and enhance learning effectiveness. Extensive experiments demonstrate that our framework achieves performance comparable to human annotation and consistently outperforms single-LLM baselines and other LLM-ensemble-based approaches. Moreover, our framework is built on lightweight LLMs, enabling it to operate fully on local machines in real-world applications.

</details>


### [189] [Attributing and Exploiting Safety Vectors through Global Optimization in Large Language Models](https://arxiv.org/abs/2601.15801)
*Fengheng Chu,Jiahao Chen,Yuhong Wang,Jun Wang,Zhihui Fu,Shouling Ji,Songze Li*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: While Large Language Models (LLMs) are aligned to mitigate risks, their safety guardrails remain fragile against jailbreak attacks. This reveals limited understanding of components governing safety. Existing methods rely on local, greedy attribution that assumes independent component contributions. However, they overlook the cooperative interactions between different components in LLMs, such as attention heads, which jointly contribute to safety mechanisms. We propose \textbf{G}lobal \textbf{O}ptimization for \textbf{S}afety \textbf{V}ector Extraction (GOSV), a framework that identifies safety-critical attention heads through global optimization over all heads simultaneously. We employ two complementary activation repatching strategies: Harmful Patching and Zero Ablation. These strategies identify two spatially distinct sets of safety vectors with consistently low overlap, termed Malicious Injection Vectors and Safety Suppression Vectors, demonstrating that aligned LLMs maintain separate functional pathways for safety purposes. Through systematic analyses, we find that complete safety breakdown occurs when approximately 30\% of total heads are repatched across all models. Building on these insights, we develop a novel inference-time white-box jailbreak method that exploits the identified safety vectors through activation repatching. Our attack substantially outperforms existing white-box attacks across all test models, providing strong evidence for the effectiveness of the proposed GOSV framework on LLM safety interpretability.

</details>


### [190] [Why Inference in Large Models Becomes Decomposable After Training](https://arxiv.org/abs/2601.15871)
*Jidong Jin*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Inference in large-scale AI models is typically performed on dense parameter matrices, leading to inference cost and system complexity that scale unsustainably with model size. This limitation does not arise from insufficient model capacity, but from treating post-training inference systems as monolithic operators while ignoring internal structures formed during learning. We show that gradient update events in large models are highly localized and selective, leaving many parameter dependencies statistically indistinguishable from their initialization distribution after training. As a result, post-training inference systems are structurally non-uniform and inherently decomposable. Based on this observation, we introduce a post-training statistical criterion and a structural annealing procedure that removes unsupported dependencies and reveals stable, independent substructures. This work establishes a post-training, model-agnostic structural view of inference systems and enables structured, parallel inference without modifying model functionality or interfaces.

</details>


### [191] [SoK: Challenges in Tabular Membership Inference Attacks](https://arxiv.org/abs/2601.15874)
*Cristina Pêra,Tânia Carvalho,Maxime Cordy,Luís Antunes*

Main category: cs.LG

TL;DR: 该论文对成员推理攻击在表格数据中的应用进行了全面分析，并在集中式和联邦学习框架下验证了攻击效果，发现表格数据中攻击性能较差但单异常记录易受攻击，不同替代模型可提升攻击效果。


<details>
  <summary>Details</summary>
Motivation: 成员推理攻击虽然是评估机器学习隐私的主流方法，但在表格数据中的应用仍存在多个未探索的问题，包括在集中式和联邦学习场景下的有效性、攻击策略和防御措施的研究不足，以及外部对手威胁和单异常记录易受攻击的特性。

Method: 首先，对成员推理攻击在集中式和联邦学习范式下进行了全面回顾和分类体系扩展。其次，使用多种攻击策略在表格数据上验证攻击效果，并考虑了防御措施和联邦学习中外敌威胁。最后，分析了单异常记录易受攻击的特性以及攻击在不同模型架构间的迁移性。

Result: 研究发现：1）成员推理攻击在表格数据上普遍表现较差；2）即使攻击性能有限，仍能成功暴露大量单异常记录；3）使用不同的替代模型能提升攻击效果。

Conclusion: 成员推理攻击在表格数据中的效果有限，但仍对单异常记录构成显著威胁。攻击效果可通过使用不同的替代模型提升。研究为表格数据隐私评估提供了重要见解，并指出了未来改进方向。

Abstract: Membership Inference Attacks (MIAs) are currently a dominant approach for evaluating privacy in machine learning applications. Despite their significance in identifying records belonging to the training dataset, several concerns remain unexplored, particularly with regard to tabular data. In this paper, first, we provide an extensive review and analysis of MIAs considering two main learning paradigms: centralized and federated learning. We extend and refine the taxonomy for both. Second, we demonstrate the efficacy of MIAs in tabular data using several attack strategies, also including defenses. Furthermore, in a federated learning scenario, we consider the threat posed by an outsider adversary, which is often neglected. Third, we demonstrate the high vulnerability of single-outs (records with a unique signature) to MIAs. Lastly, we explore how MIAs transfer across model architectures. Our results point towards a general poor performance of these attacks in tabular data which contrasts with previous state-of-the-art. Notably, even attacks with limited attack performance can still successfully expose a large portion of single-outs. Moreover, our findings suggest that using different surrogate models makes MIAs more effective.

</details>


### [192] [Iterative Amortized Hierarchical VAE](https://arxiv.org/abs/2601.15894)
*Simon W. Penninga,Ruud J. G. van Sloun*

Main category: cs.LG

TL;DR: 提出迭代摊销分层变分自编码器(IA-HVAE)，结合摊销推理和迭代优化，在变换域实现线性可分离解码器，获得35倍速度提升


<details>
  <summary>Details</summary>
Motivation: 传统分层变分自编码器(HVAE)在迭代推理时速度较慢，需要在保持推理质量的同时提升速度，并解决完全摊销方法精度不足的问题

Method: 使用混合方案：初始的摊销猜测和基于解码器梯度的迭代优化；在变换域（如傅里叶空间）创建线性可分离解码器；实现高模型深度的实时应用

Result: 相比传统HVAE实现35倍的迭代推理速度提升；在精度和速度上分别优于完全摊销和完全迭代方法；在去模糊和去噪等逆问题中展示更好的重建质量

Conclusion: IA-HVAE通过混合摊销-迭代方案在线性可分离解码器架构中实现了显著的性能提升，在速度和精度之间取得了良好平衡

Abstract: In this paper we propose the Iterative Amortized Hierarchical Variational Autoencoder (IA-HVAE), which expands on amortized inference with a hybrid scheme containing an initial amortized guess and iterative refinement with decoder gradients. We achieve this by creating a linearly separable decoder in a transform domain (e.g. Fourier space), enabling real-time applications with very high model depths. The architectural change leads to a 35x speed-up for iterative inference with respect to the traditional HVAE. We show that our hybrid approach outperforms fully amortized and fully iterative equivalents in accuracy and speed respectively. Moreover, the IAHVAE shows improved reconstruction quality over a vanilla HVAE in inverse problems such as deblurring and denoising.

</details>


### [193] [Predicting Healthcare System Visitation Flow by Integrating Hospital Attributes and Population Socioeconomics with Human Mobility Data](https://arxiv.org/abs/2601.15977)
*Binbin Lin,Lei Zou,Hao Tian,Heng Cai,Yifan Yang,Bing Zhou*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Healthcare visitation patterns are influenced by a complex interplay of hospital attributes, population socioeconomics, and spatial factors. However, existing research often adopts a fragmented approach, examining these determinants in isolation. This study addresses this gap by integrating hospital capacities, occupancy rates, reputation, and popularity with population SES and spatial mobility patterns to predict visitation flows and analyze influencing factors. Utilizing four years of SafeGraph mobility data and user experience data from Google Maps Reviews, five flow prediction models, Naive Regression, Gradient Boosting, Multilayer Perceptrons (MLPs), Deep Gravity, and Heterogeneous Graph Neural Networks (HGNN),were trained and applied to simulate visitation flows in Houston, Texas, U.S. The Shapley additive explanation (SHAP) analysis and the Partial Dependence Plot (PDP) method were employed to examine the combined impacts of different factors on visitation patterns. The findings reveal that Deep Gravity outperformed other models. Hospital capacities, ICU occupancy rates, ratings, and popularity significantly influence visitation patterns, with their effects varying across different travel distances. Short-distance visits are primarily driven by convenience, whereas long-distance visits are influenced by hospital ratings. White-majority areas exhibited lower sensitivity to hospital ratings for short-distance visits, while Asian populations and those with higher education levels prioritized hospital rating in their visitation decisions. SES further influence these patterns, as areas with higher proportions of Hispanic, Black, under-18, and over-65 populations tend to have more frequent hospital visits, potentially reflecting greater healthcare needs or limited access to alternative medical services.

</details>


### [194] [Partially Lazy Gradient Descent for Smoothed Online Learning](https://arxiv.org/abs/2601.15984)
*Naram Mhaisen,George Iosifidis*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce $k$-lazyGD, an online learning algorithm that bridges the gap between greedy Online Gradient Descent (OGD, for $k=1$) and lazy GD/dual-averaging (for $k=T$), creating a spectrum between reactive and stable updates. We analyze this spectrum in Smoothed Online Convex Optimization (SOCO), where the learner incurs both hitting and movement costs. Our main contribution is establishing that laziness is possible without sacrificing hitting performance: we prove that $k$-lazyGD achieves the optimal dynamic regret $\mathcal{O}(\sqrt{(P_T+1)T})$ for any laziness slack $k$ up to $Θ(\sqrt{T/P_T})$, where $P_T$ is the comparator path length. This result formally connects the allowable laziness to the comparator's shifts, showing that $k$-lazyGD can retain the inherently small movements of lazy methods without compromising tracking ability. We base our analysis on the Follow the Regularized Leader (FTRL) framework, and derive a matching lower bound. Since the slack depends on $P_T$, an ensemble of learners with various slacks is used, yielding a method that is provably stable when it can be, and agile when it must be.

</details>


### [195] [Data-Driven Conditional Flexibility Index](https://arxiv.org/abs/2601.16028)
*Moritz Wedemeyer,Eike Cramer,Alexander Mitsos,Manuel Dahmen*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: With the increasing flexibilization of processes, determining robust scheduling decisions has become an important goal. Traditionally, the flexibility index has been used to identify safe operating schedules by approximating the admissible uncertainty region using simple admissible uncertainty sets, such as hypercubes. Presently, available contextual information, such as forecasts, has not been considered to define the admissible uncertainty set when determining the flexibility index. We propose the conditional flexibility index (CFI), which extends the traditional flexibility index in two ways: by learning the parametrized admissible uncertainty set from historical data and by using contextual information to make the admissible uncertainty set conditional. This is achieved using a normalizing flow that learns a bijective mapping from a Gaussian base distribution to the data distribution. The admissible latent uncertainty set is constructed as a hypersphere in the latent space and mapped to the data space. By incorporating contextual information, the CFI provides a more informative estimate of flexibility by defining admissible uncertainty sets in regions that are more likely to be relevant under given conditions. Using an illustrative example, we show that no general statement can be made about data-driven admissible uncertainty sets outperforming simple sets, or conditional sets outperforming unconditional ones. However, both data-driven and conditional admissible uncertainty sets ensure that only regions of the uncertain parameter space containing realizations are considered. We apply the CFI to a security-constrained unit commitment example and demonstrate that the CFI can improve scheduling quality by incorporating temporal information.

</details>


### [196] [CLASP: An online learning algorithm for Convex Losses And Squared Penalties](https://arxiv.org/abs/2601.16072)
*Ricardo N. Ferreira,Cláudia Soares,João Xavier*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study Constrained Online Convex Optimization (COCO), where a learner chooses actions iteratively, observes both unanticipated convex loss and convex constraint, and accumulates loss while incurring penalties for constraint violations. We introduce CLASP (Convex Losses And Squared Penalties), an algorithm that minimizes cumulative loss together with squared constraint violations. Our analysis departs from prior work by fully leveraging the firm non-expansiveness of convex projectors, a proof strategy not previously applied in this setting. For convex losses, CLASP achieves regret $O\left(T^{\max\{β,1-β\}}\right)$ and cumulative squared penalty $O\left(T^{1-β}\right)$ for any $β\in (0,1)$. Most importantly, for strongly convex problems, CLASP provides the first logarithmic guarantees on both regret and cumulative squared penalty. In the strongly convex case, the regret is upper bounded by $O( \log T )$ and the cumulative squared penalty is also upper bounded by $O( \log T )$.

</details>


### [197] [Explainable AI to Improve Machine Learning Reliability for Industrial Cyber-Physical Systems](https://arxiv.org/abs/2601.16074)
*Annemarie Jutte,Uraz Odyurt*

Main category: cs.LG

TL;DR: 工业CPS可靠性关键，但集成深度学习模型不透明，用XAI解释SHAP提高预测性能。


<details>
  <summary>Details</summary>
Motivation: 工业CPS安全经济敏感，需高可靠性；但集成ML模型复杂不透明，需严格评估防止未来数据异常，需要用XAI揭示模型推理机制。

Method: 应用XAI（SHAP值）分析时间序列数据分解分量对模型预测的影响，根据XAI发现扩大数据实例窗口大小。

Result: XAI分析显示模型训练缺乏足够上下文信息，增大窗口尺寸后模型性能得到提升。

Conclusion: XAI能有效揭示工业CPS中ML模型的推理机制，通过基于SHAP的分析指导改进数据配置，可提高预测性能。

Abstract: Industrial Cyber-Physical Systems (CPS) are sensitive infrastructure from both safety and economics perspectives, making their reliability critically important. Machine Learning (ML), specifically deep learning, is increasingly integrated in industrial CPS, but the inherent complexity of ML models results in non-transparent operation. Rigorous evaluation is needed to prevent models from exhibiting unexpected behaviour on future, unseen data. Explainable AI (XAI) can be used to uncover model reasoning, allowing a more extensive analysis of behaviour. We apply XAI to to improve predictive performance of ML models intended for industrial CPS. We analyse the effects of components from time-series data decomposition on model predictions using SHAP values. Through this method, we observe evidence on the lack of sufficient contextual information during model training. By increasing the window size of data instances, informed by the XAI findings, we are able to improve model performance.

</details>


### [198] [Probably Approximately Correct Maximum A Posteriori Inference](https://arxiv.org/abs/2601.16083)
*Matthew Shorvon,Frederik Mallmann-Trenn,David S. Watson*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Computing the conditional mode of a distribution, better known as the $\mathit{maximum\ a\ posteriori}$ (MAP) assignment, is a fundamental task in probabilistic inference. However, MAP estimation is generally intractable, and remains hard even under many common structural constraints and approximation schemes. We introduce $\mathit{probably\ approximately\ correct}$ (PAC) algorithms for MAP inference that provide provably optimal solutions under variable and fixed computational budgets. We characterize tractability conditions for PAC-MAP using information theoretic measures that can be estimated from finite samples. Our PAC-MAP solvers are efficiently implemented using probabilistic circuits with appropriate architectures. The randomization strategies we develop can be used either as standalone MAP inference techniques or to improve on popular heuristics, fortifying their solutions with rigorous guarantees. Experiments confirm the benefits of our method in a range of benchmarks.

</details>


### [199] [Benchmarking Deep Learning Models for Raman Spectroscopy Across Open-Source Datasets](https://arxiv.org/abs/2601.16107)
*Adithya Sineesh,Akshita Kamsali*

Main category: cs.LG

TL;DR: 本研究对5个专门针对拉曼光谱设计的深度学习分类器在3个开源数据集上进行了系统性基准测试，是首批比较多个拉曼专用深度学习模型的综合性研究之一。


<details>
  <summary>Details</summary>
Motivation: 现有拉曼光谱深度学习分类器虽然报道优于传统化学计量学方法，但评估往往孤立进行，或者仅与传统的机器学习方法或简单适配的视觉架构比较，缺乏在共享开源数据集上对专门针对拉曼光谱设计的深度学习模型的直接比较。

Method: 在统一训练和超参数调优协议下，评估5个代表性深度学习架构，使用3个开源拉曼数据集来支持标准评估、微调和显式分布偏移测试，计算分类准确率和宏平均F1分数。

Result: 研究提供了首个系统性基准测试，比较了多个专门针对拉曼光谱开发的深度学习分类器在共享数据集上的表现。

Conclusion: 该研究为拉曼光谱分析的深度学习模型提供了公平且可重复的比较基准，填补了该领域系统性比较研究的空白。

Abstract: Deep learning classifiers for Raman spectroscopy are increasingly reported to outperform classical chemometric approaches. However their evaluations are often conducted in isolation or compared against traditional machine learning methods or trivially adapted vision-based architectures that were not originally proposed for Raman spectroscopy. As a result, direct comparisons between existing deep learning models developed specifically for Raman spectral analysis on shared open-source datasets remain scarce. To the best of our knowledge, this study presents one of the first systematic benchmarks comparing three or more published Raman-specific deep learning classifiers across multiple open-source Raman datasets. We evaluate five representative deep learning architectures under a unified training and hyperparameter tuning protocol across three open-source Raman datasets selected to support standard evaluation, fine-tuning, and explicit distribution-shift testing. We report classification accuracies and macro-averaged F1 scores to provide a fair and reproducible comparison of deep learning models for Raman spectra based classification.

</details>


### [200] [On the Intrinsic Dimensions of Data in Kernel Learning](https://arxiv.org/abs/2601.16139)
*Rustem Takhanov*

Main category: cs.LG

TL;DR: 该研究探讨了核脊回归中流形假说的影响，通过引入两种内蕴维度定义（Minkowski维度和有效维度）分析泛化性能，并建立了基于Kolmogorov n-宽度的误差边界。


<details>
  <summary>Details</summary>
Motivation: 流形假说认为当输入分布的内蕴维度较低时，机器学习方法的泛化性能会显著提升。该工作旨在为核脊回归提供更精确的泛化误差分析，特别是在复杂几何结构上的应用，通过量化两种不同内蕴维度之间的关系。

Method: 研究首先定义了两种内蕴维度：基于核诱导度量的Minkowski维度dρ和基于Kolmogorov n-宽度衰减率的有效维度dK。通过分析这些n-宽度与积分算子特征值的关系，展示了Kolmogorov n-宽度如何刻画所有概率测度在固定域上的最坏情况特征值衰减。随后提出了一个算法，仅使用μ的有限样本来估计n-宽度的上界。

Result: 研究推导出约束核脊回归的额外误差边界为O(n^(-(2+d_K)/(2+2d_K)+ε))，其中n为训练集大小，ε>0。对于接近均匀的分布，证明了使用O(ε^(-d_ρ)log(1/ε))样本可以高概率计算所有n-宽度的ε-准确上界。数值实验表明，对于Laplace核等内核，有效维度d_K可能显著小于Minkowski维度d_ρ，尽管在规则域上两者相等。

Conclusion: 该工作为核脊回归在复杂几何结构上的泛化性能提供了理论保证，量化了两种内蕴维度概念的关系，并提出了一种实用的样本复杂度估计方法。结果表明，对于某些内核和域结构，有效维度可以比Minkowski维度小得多，这为理解核方法的泛化行为提供了新视角。

Abstract: The manifold hypothesis suggests that the generalization performance of machine learning methods improves significantly when the intrinsic dimension of the input distribution's support is low. In the context of KRR, we investigate two alternative notions of intrinsic dimension. The first, denoted $d_ρ$, is the upper Minkowski dimension defined with respect to the canonical metric induced by a kernel function $K$ on a domain $Ω$. The second, denoted $d_K$, is the effective dimension, derived from the decay rate of Kolmogorov $n$-widths associated with $K$ on $Ω$. Given a probability measure $μ$ on $Ω$, we analyze the relationship between these $n$-widths and eigenvalues of the integral operator $φ\to \int_ΩK(\cdot,x)φ(x)dμ(x)$. We show that, for a fixed domain $Ω$, the Kolmogorov $n$-widths characterize the worst-case eigenvalue decay across all probability measures $μ$ supported on $Ω$. These eigenvalues are central to understanding the generalization behavior of constrained KRR, enabling us to derive an excess error bound of order $O(n^{-\frac{2+d_K}{2+2d_K} + ε})$ for any $ε> 0$, when the training set size $n$ is large. We also propose an algorithm that estimates upper bounds on the $n$-widths using only a finite sample from $μ$. For distributions close to uniform, we prove that $ε$-accurate upper bounds on all $n$-widths can be computed with high probability using at most $O\left(ε^{-d_ρ}\log\frac{1}ε\right)$ samples, with fewer required for small $n$. Finally, we compute the effective dimension $d_K$ for various fractal sets and present additional numerical experiments. Our results show that, for kernels such as the Laplace kernel, the effective dimension $d_K$ can be significantly smaller than the Minkowski dimension $d_ρ$, even though $d_K = d_ρ$ provably holds on regular domains.

</details>


### [201] [Beat-ssl: Capturing Local ECG Morphology through Heartbeat-level Contrastive Learning with Soft Targets](https://arxiv.org/abs/2601.16147)
*Muhammad Ilham Rizqyawan,Peter Macfarlane,Stathis Hadjidemetriou,Fani Deligianni*

Main category: cs.LG

TL;DR: TL;DR: Beat-SSL通过双上下文对比学习（心律级和心跳级）与软目标提升心电信号表示学习效果，在有限标注数据下实现有效的迁移学习，在心律分类和分割任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 获取标注心电数据困难，现有对比学习框架要么只关注全局上下文，要么未充分挖掘心电信号特性，且依赖于硬对比目标无法充分捕捉心电特征相似度的连续性

Method: 提出了Beat-SSL对比学习框架，通过双上下文学习同时进行心律级和心跳级对比，并采用软目标

Result: 在多标签心律分类任务中达到心电基础模型93%的性能，在分割任务中超过所有其他方法4%

Conclusion: Beat-SSL框架通过结合双上下文对比学习和软目标，能有效学习心电信号的全局和局部表示，在有限标注数据下展现出优越的下游任务性能

Abstract: Obtaining labelled ECG data for developing supervised models is challenging. Contrastive learning (CL) has emerged as a promising pretraining approach that enables effective transfer learning with limited labelled data. However, existing CL frameworks either focus solely on global context or fail to exploit ECG-specific characteristics. Furthermore, these methods rely on hard contrastive targets, which may not adequately capture the continuous nature of feature similarity in ECG signals. In this paper, we propose Beat-SSL, a contrastive learning framework that performs dual-context learning through both rhythm-level and heartbeat-level contrasting with soft targets. We evaluated our pretrained model on two downstream tasks: 1) multilabel classification for global rhythm assessment, and 2) ECG segmentation to assess its capacity to learn representations across both contexts. We conducted an ablation study and compared the best configuration with three other methods, including one ECG foundation model. Despite the foundation model's broader pretraining, Beat-SSL reached 93% of its performance in multilabel classification task and surpassed all other methods in the segmentation task by 4%.

</details>


### [202] [Learning to Discover at Test Time](https://arxiv.org/abs/2601.16175)
*Mert Yuksekgonul,Daniel Koceja,Xinhao Li,Federico Bianchi,Jed McCaleb,Xiaolong Wang,Jan Kautz,Yejin Choi,James Zou,Carlos Guestrin,Yu Sun*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: How can we use AI to discover a new state of the art for a scientific problem? Prior work in test-time scaling, such as AlphaEvolve, performs search by prompting a frozen LLM. We perform reinforcement learning at test time, so the LLM can continue to train, but now with experience specific to the test problem. This form of continual learning is quite special, because its goal is to produce one great solution rather than many good ones on average, and to solve this very problem rather than generalize to other problems. Therefore, our learning objective and search subroutine are designed to prioritize the most promising solutions. We call this method Test-Time Training to Discover (TTT-Discover). Following prior work, we focus on problems with continuous rewards. We report results for every problem we attempted, across mathematics, GPU kernel engineering, algorithm design, and biology. TTT-Discover sets the new state of the art in almost all of them: (i) Erdős' minimum overlap problem and an autocorrelation inequality; (ii) a GPUMode kernel competition (up to $2\times$ faster than prior art); (iii) past AtCoder algorithm competitions; and (iv) denoising problem in single-cell analysis. Our solutions are reviewed by experts or the organizers. All our results are achieved with an open model, OpenAI gpt-oss-120b, and can be reproduced with our publicly available code, in contrast to previous best results that required closed frontier models. Our test-time training runs are performed using Tinker, an API by Thinking Machines, with a cost of only a few hundred dollars per problem.

</details>


### [203] [Counterfactual Training: Teaching Models Plausible and Actionable Explanations](https://arxiv.org/abs/2601.16205)
*Patrick Altmeyer,Aleksander Buszydlik,Arie van Deursen,Cynthia C. S. Liem*

Main category: cs.LG

TL;DR: 本文提出了一种名为“反事实训练”的新方法，利用反事实解释提升模型的可解释性


<details>
  <summary>Details</summary>
Motivation: 反事实解释已成为不透明机器学习模型的后门解释方法，但在真实决策系统中需要满足合理性和可行性要求。现有研究主要集中在开发后门方法，本文则直接让模型对最终目标负责

Method: 在训练阶段使用反事实来最小化学习表示与合理可行解释之间的差异，通过反事实训练使模型生成内在理想的解释

Result: 实验和理论证明，该方法能训练出提供固有理想反事实解释的模型，同时提升对抗性鲁棒性

Conclusion: 反事实训练通过将解释性要求融入模型训练过程，实现了模型的内在可解释性和鲁棒性提升

Abstract: We propose a novel training regime termed counterfactual training that leverages counterfactual explanations to increase the explanatory capacity of models. Counterfactual explanations have emerged as a popular post-hoc explanation method for opaque machine learning models: they inform how factual inputs would need to change in order for a model to produce some desired output. To be useful in real-world decision-making systems, counterfactuals should be plausible with respect to the underlying data and actionable with respect to the feature mutability constraints. Much existing research has therefore focused on developing post-hoc methods to generate counterfactuals that meet these desiderata. In this work, we instead hold models directly accountable for the desired end goal: counterfactual training employs counterfactuals during the training phase to minimize the divergence between learned representations and plausible, actionable explanations. We demonstrate empirically and theoretically that our proposed method facilitates training models that deliver inherently desirable counterfactual explanations and additionally exhibit improved adversarial robustness.

</details>

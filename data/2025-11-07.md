<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 52]
- [cs.CL](#cs.CL) [Total: 39]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.HC](#cs.HC) [Total: 14]
- [cs.AI](#cs.AI) [Total: 25]
- [cs.LG](#cs.LG) [Total: 62]
- [cs.MM](#cs.MM) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [PixCLIP: Achieving Fine-grained Visual Language Understanding via Any-granularity Pixel-Text Alignment Learning](https://arxiv.org/abs/2511.04601)
*Yicheng Xiao,Yu Chen,Haoxuan Ma,Jiale Hong,Caorui Li,Lingxiang Wu,Haiyun Guo,Jinqiao Wang*

Main category: cs.CV

TL;DR: PixCLIP框架通过同时处理视觉提示和长文本描述，显著提升了CLIP在细粒度图像-文本对齐任务中的能力，取得最先进的表现。


<details>
  <summary>Details</summary>
Motivation: 增强CLIP模型在细粒度图像-文本对齐方面的能力，并克服现有模型在处理长文本描述时的限制。

Method: 建立自动注释管道生成像素级本地化的长文本描述，替换CLIP的文本编码器，并提出三分支像素-文本对齐学习框架。

Result: PixCLIP利用自动注释管道和长文本描述的处理，实现了图像区域与对应文本描述之间的细粒度对齐，并在实验中证明了优越性能。

Conclusion: PixCLIP展示出在像素级交互和处理长文本方面的突破，达到了最先进的性能。

Abstract: While the Contrastive Language-Image Pretraining(CLIP) model has achieved
remarkable success in a variety of downstream vison language understanding
tasks, enhancing its capability for fine-grained image-text alignment remains
an active research focus. To this end, most existing works adopt the strategy
of explicitly increasing the granularity of visual information processing,
e.g., incorporating visual prompts to guide the model focus on specific local
regions within the image. Meanwhile, researches on Multimodal Large Language
Models(MLLMs) have demonstrated that training with long and detailed textual
descriptions can effectively improve the model's fine-grained vision-language
alignment. However, the inherent token length limitation of CLIP's text encoder
fundamentally limits CLIP to process more granular textual information embedded
in long text sequences. To synergistically leverage the advantages of enhancing
both visual and textual content processing granularity, we propose PixCLIP, a
novel framework designed to concurrently accommodate visual prompt inputs and
process lengthy textual descriptions. Specifically, we first establish an
automated annotation pipeline capable of generating pixel-level localized,
long-form textual descriptions for images. Utilizing this pipeline, we
construct LongGRIT, a high-quality dataset comprising nearly 1.5 million
samples. Secondly, we replace CLIP's original text encoder with the LLM and
propose a three-branch pixel-text alignment learning framework, facilitating
fine-grained alignment between image regions and corresponding textual
descriptions at arbitrary granularity. Experiments demonstrate that PixCLIP
showcases breakthroughs in pixel-level interaction and handling long-form
texts, achieving state-of-the-art performance.

</details>


### [2] [SILVI: Simple Interface for Labeling Video Interactions](https://arxiv.org/abs/2511.03819)
*Ozan Kanbertay,Richard Vogg,Elif Karakoc,Peter M. Kappeler,Claudia Fichtel,Alexander S. Ecker*

Main category: cs.CV

TL;DR: SILVI是一款新开发的开源标注软件, 可用于直接在视频中整合动物行为和互动的标注, 旨在提高行为分析的自动化水平。


<details>
  <summary>Details</summary>
Motivation: 现有的开源标注工具在动物互动检测和标注方面存在不足。

Method: 开发了一款开放源代码软件，允许研究人员直接在视频数据中进行行为和互动标注。

Result: SILVI能够为计算机视觉模型的训练和验证生成结构化输出，并可以广泛应用于人类互动标注。

Conclusion: SILVI是一个集成行为和互动标注功能的开源软件, 可用于视频数据中标注动物行为和互动, 推动细粒度行为分析的自动化进程。

Abstract: Computer vision methods are increasingly used for the automated analysis of
large volumes of video data collected through camera traps, drones, or direct
observations of animals in the wild. While recent advances have focused
primarily on detecting individual actions, much less work has addressed the
detection and annotation of interactions -- a crucial aspect for understanding
social and individualized animal behavior. Existing open-source annotation
tools support either behavioral labeling without localization of individuals,
or localization without the capacity to capture interactions. To bridge this
gap, we present SILVI, an open-source labeling software that integrates both
functionalities. SILVI enables researchers to annotate behaviors and
interactions directly within video data, generating structured outputs suitable
for training and validating computer vision models. By linking behavioral
ecology with computer vision, SILVI facilitates the development of automated
approaches for fine-grained behavioral analyses. Although developed primarily
in the context of animal behavior, SILVI could be useful more broadly to
annotate human interactions in other videos that require extracting dynamic
scene graphs. The software, along with documentation and download instructions,
is available at: https://gitlab.gwdg.de/kanbertay/interaction-labelling-app.

</details>


### [3] [Noise Injection: Improving Out-of-Distribution Generalization for Limited Size Datasets](https://arxiv.org/abs/2511.03855)
*Duong Mai,Lawrence Hall*

Main category: cs.CV

TL;DR: 本研究通过噪声注入技术提升COVID-19检测模型对不同数据分布的泛化能力，显著缩小了ID与OOD之间的性能差距。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在图像识别任务中表现出无法对来自不同设备和人群的数据进行有效泛化，尤其是在COVID-19检测中更为明显，导致模型依赖于特定来源的伪影，而非合理的生物标志物。

Method: 在训练过程中使用高斯噪声、斑点噪声、泊松噪声和盐和胡椒噪声等噪声注入技术。

Result: 实验证明，使用噪声注入技术后，ID与OOD评估的性能差距可以从0.10-0.20缩小到0.01-0.06，关键指标如AUC、F1、准确率、召回率和特异性等均有改善。

Conclusion: 通过在训练过程中注入基本噪声技术，可以显著提高模型在不同分布数据上的鲁棒性，从而缩小ID与OOD评估之间的性能差距。

Abstract: Deep learned (DL) models for image recognition have been shown to fail to
generalize to data from different devices, populations, etc. COVID-19 detection
from Chest X-rays (CXRs), in particular, has been shown to fail to generalize
to out-of-distribution (OOD) data from new clinical sources not covered in the
training set. This occurs because models learn to exploit shortcuts -
source-specific artifacts that do not translate to new distributions - rather
than reasonable biomarkers to maximize performance on in-distribution (ID)
data. Rendering the models more robust to distribution shifts, our study
investigates the use of fundamental noise injection techniques (Gaussian,
Speckle, Poisson, and Salt and Pepper) during training. Our empirical results
demonstrate that this technique can significantly reduce the performance gap
between ID and OOD evaluation from 0.10-0.20 to 0.01-0.06, based on results
averaged over ten random seeds across key metrics such as AUC, F1, accuracy,
recall and specificity. Our source code is publicly available at
https://github.com/Duongmai127/Noisy-ood

</details>


### [4] [Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures](https://arxiv.org/abs/2511.03882)
*Florence Klitzner,Blanca Inigo,Benjamin D. Killeen,Lalithkumar Seenivasan,Michelle Song,Axel Krieger,Mathias Unberath*

Main category: cs.CV

TL;DR: 本文探讨模仿学习在X光引导的脊柱手术中的应用，开发了一个高真实感的模拟环境，并成功训练了基于视觉信息的控制策略。


<details>
  <summary>Details</summary>
Motivation: 探索基于模仿学习的方法在X光引导的脊柱手术中的应用。

Method: 采用模仿学习策略进行规划和开环控制，通过视觉信息逐步对齐穿刺针。

Result: 政策在68.5%的案例中成功首次尝试，能够在多样的脊柱水平上维持安全的穿透轨迹。

Conclusion: 尽管初步结果令人鼓舞，但我们发现了限制，尤其是在进入点精度方面。

Abstract: Imitation learning-based robot control policies are enjoying renewed interest
in video-based robotics. However, it remains unclear whether this approach
applies to X-ray-guided procedures, such as spine instrumentation. This is
because interpretation of multi-view X-rays is complex. We examine
opportunities and challenges for imitation policy learning in bi-plane-guided
cannula insertion. We develop an in silico sandbox for scalable, automated
simulation of X-ray-guided spine procedures with a high degree of realism. We
curate a dataset of correct trajectories and corresponding bi-planar X-ray
sequences that emulate the stepwise alignment of providers. We then train
imitation learning policies for planning and open-loop control that iteratively
align a cannula solely based on visual information. This precisely controlled
setup offers insights into limitations and capabilities of this method. Our
policy succeeded on the first attempt in 68.5% of cases, maintaining safe
intra-pedicular trajectories across diverse vertebral levels. The policy
generalized to complex anatomy, including fractures, and remained robust to
varied initializations. Rollouts on real bi-planar X-rays further suggest that
the model can produce plausible trajectories, despite training exclusively in
simulation. While these preliminary results are promising, we also identify
limitations, especially in entry point precision. Full closed-look control will
require additional considerations around how to provide sufficiently frequent
feedback. With more robust priors and domain knowledge, such models may provide
a foundation for future efforts toward lightweight and CT-free robotic
intra-operative spinal navigation.

</details>


### [5] [Desert Waste Detection and Classification Using Data-Based and Model-Based Enhanced YOLOv12 DL Model](https://arxiv.org/abs/2511.03888)
*Abdulmumin Sa'ad,Sulaimon Oyeniyi Adebayo,Abdul Jabbar Siddiqui*

Main category: cs.CV

TL;DR: 本研究开发了一种改进的YOLOv12框架，专注于在沙漠环境中实现实时、高效的垃圾检测，展现出良好的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 针对全球垃圾危机，尤其是在偏远和恶劣环境（如沙漠）中，传统垃圾收集方法的不足，引入自动化垃圾检测系统以提高效率和安全性。

Method: 基于经过剪枝的轻量级YOLOv12，结合自我对抗训练和特定数据增强策略进行实时物体检测。

Result: 在DroneTrashNet数据集上测试后，该模型在精准度、召回率及均值平均精度（mAP）上都有显著提升，同时适合于资源受限的无人机部署。

Conclusion: 本研究提出了一种增强的实时物体检测框架，证明了在沙漠环境中进行垃圾检测的有效性，能够实现高精度和低延迟。

Abstract: The global waste crisis is escalating, with solid waste generation expected
to increase by 70% by 2050. Traditional waste collection methods, particularly
in remote or harsh environments like deserts, are labor-intensive, inefficient,
and often hazardous. Recent advances in computer vision and deep learning have
opened the door to automated waste detection systems, yet most research focuses
on urban environments and recyclable materials, overlooking organic and
hazardous waste and underexplored terrains such as deserts. In this work, we
propose an enhanced real-time object detection framework based on a pruned,
lightweight version of YOLOv12 integrated with Self-Adversarial Training (SAT)
and specialized data augmentation strategies. Using the DroneTrashNet dataset,
we demonstrate significant improvements in precision, recall, and mean average
precision (mAP), while achieving low latency and compact model size suitable
for deployment on resource-constrained aerial drones. Benchmarking our model
against state-of-the-art lightweight YOLO variants further highlights its
optimal balance of accuracy and efficiency. Our results validate the
effectiveness of combining data-centric and model-centric enhancements for
robust, real-time waste detection in desert environments.

</details>


### [6] [Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition](https://arxiv.org/abs/2511.03891)
*Hlali Azzeddine,Majid Ben Yakhlef,Soulaiman El Hazzat*

Main category: cs.CV

TL;DR: 本文提出的类基图像组合方法通过增强输入图像质量和类别平衡，实现了深度学习模型在诊断中的显著提升。


<details>
  <summary>Details</summary>
Motivation: 小型不平衡数据集和输入图像质量差会导致深度学习模型的误预测率高，因此需要改进输入数据的表示方式。

Method: 通过融合同一类别的多幅图像创建复合输入图像（CoImg），增强了类内方差和每个训练样本的信息密度。

Result: 使用新构建的Co-OCTDL数据集进行比较分析，最终模型在精度（99.6%）、F1-score（0.995）和AUC（0.9996）上表现优异，显著降低了误预测率。

Conclusion: 该方法在提升模型精度和降低误预测率方面表现显著，即使在样本量小和类别不平衡的数据集上。

Abstract: Small, imbalanced datasets and poor input image quality can lead to high
false predictions rates with deep learning models. This paper introduces
Class-Based Image Composition, an approach that allows us to reformulate
training inputs through a fusion of multiple images of the same class into
combined visual composites, named Composite Input Images (CoImg). That enhances
the intra-class variance and improves the valuable information density per
training sample and increases the ability of the model to distinguish between
subtle disease patterns. Our method was evaluated on the Optical Coherence
Tomography Dataset for Image-Based Deep Learning Methods (OCTDL) (Kulyabin et
al., 2024), which contains 2,064 high-resolution optical coherence tomography
(OCT) scans of the human retina, representing seven distinct diseases with a
significant class imbalance. We constructed a perfectly class-balanced version
of this dataset, named Co-OCTDL, where each scan is resented as a 3x1 layout
composite image. To assess the effectiveness of this new representation, we
conducted a comparative analysis between the original dataset and its variant
using a VGG16 model. A fair comparison was ensured by utilizing the identical
model architecture and hyperparameters for all experiments. The proposed
approach markedly improved diagnostic results.The enhanced Dataset achieved
near-perfect accuracy (99.6%) with F1-score (0.995) and AUC (0.9996), compared
to a baseline model trained on raw dataset. The false prediction rate was also
significantly lower, this demonstrates that the method can producehigh-quality
predictions even for weak datasets affected by class imbalance or small sample
size.

</details>


### [7] [I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic Weight Averaging-Gaussian for Oracle-Free Medical Imaging](https://arxiv.org/abs/2511.03912)
*Nand Kumar Yadav,Rodrigue Rizk,William CW Chen,KC Santosh*

Main category: cs.CV

TL;DR: 本研究提出了一种无监督的框架，通过逐步扩展正常样本集，实现了在缺乏标签的医学影像中有效的异常检测。


<details>
  <summary>Details</summary>
Motivation: 医学影像中的未知异常检测由于缺乏标注异常和高昂的专家监督成本一直是个难题。

Method: 提出了一种无监督、无需专家监督的框架，通过轻量级适配器更新和不确定性门控样本接纳，逐步扩展正常样本集。

Result: 通过在多个医学图像数据集上进行实验，该系统的ROC-AUC和F1分数明显提高，展现了显著的性能提升。

Conclusion: 该方法在缺乏标签的医学影像中有效检测异常，急剧提升了正常样本的定义，尤其在COVID-CXR和Pneumonia CXR等数据集上表现优秀。

Abstract: Unknown anomaly detection in medical imaging remains a fundamental challenge
due to the scarcity of labeled anomalies and the high cost of expert
supervision. We introduce an unsupervised, oracle-free framework that
incrementally expands a trusted set of normal samples without any anomaly
labels. Starting from a small, verified seed of normal images, our method
alternates between lightweight adapter updates and uncertainty-gated sample
admission. A frozen pretrained vision backbone is augmented with tiny
convolutional adapters, ensuring rapid domain adaptation with negligible
computational overhead. Extracted embeddings are stored in a compact coreset
enabling efficient k-nearest neighbor anomaly (k-NN) scoring. Safety during
incremental expansion is enforced by dual probabilistic gates, a sample is
admitted into the normal memory only if its distance to the existing coreset
lies within a calibrated z-score threshold, and its SWAG-based epistemic
uncertainty remains below a seed-calibrated bound. This mechanism prevents
drift and false inclusions without relying on generative reconstruction or
replay buffers. Empirically, our system steadily refines the notion of
normality as unlabeled data arrive, producing substantial gains over baselines.
On COVID-CXR, ROC-AUC improves from 0.9489 to 0.9982 (F1: 0.8048 to 0.9746); on
Pneumonia CXR, ROC-AUC rises from 0.6834 to 0.8968; and on Brain MRI ND-5,
ROC-AUC increases from 0.6041 to 0.7269 and PR-AUC from 0.7539 to 0.8211. These
results highlight the effectiveness and efficiency of the proposed framework
for real-world, label-scarce medical imaging applications.

</details>


### [8] [Adaptive Temporal Refinement: Continuous Depth Allocation and Distance Regression for Efficient Action Localization](https://arxiv.org/abs/2511.03943)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.CV

TL;DR: 本文提出了两种方法BDR和ATR，显著提高了时序行为识别的边界检测精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 当前方法在不同边界难度下采用统一计算，无法有效处理边界变化，因此亟需改进。

Method: 通过签名距离回归实现边界距离回归（BDR）和自适应时间精炼（ATR），两者结合实现了精确的边界定位和优化的计算分配。

Result: BDR使边界检测峰值提高43%，ATR在降低计算的同时提升了性能，证明了在THUMOS14上提高了mAP@0.7的表现，从而实现优化。

Conclusion: 提出的BDR和ATR方法在时序行为定位任务中有效提高了边界检测精度和计算效率。

Abstract: Temporal action localization requires precise boundary detection; however,
current methods apply uniform computation despite significant variations in
difficulty across boundaries. We present two complementary contributions.
First, Boundary Distance Regression (BDR) provides information-theoretically
optimal localization through signed-distance regression rather than
classification, achieving 43\% sharper boundary peaks. BDR retrofits to
existing methods with approximately 50 lines of code, yielding consistent 1.8
to 3.1\% mAP@0.7 improvements across diverse architectures. Second, Adaptive
Temporal Refinement (ATR) allocates computation via continuous depth selection
$\tau \in [0,1]$, enabling end-to-end differentiable optimization without
reinforcement learning. On THUMOS14, ATR achieves 56.5\% mAP@0.7 at 162G FLOPs,
compared to 53.6\% at 198G for uniform processing, providing a 2.9\%
improvement with 18\% less compute. Gains scale with boundary heterogeneity,
showing 4.2\% improvement on short actions. Training cost is mitigated via
knowledge distillation, with lightweight students retaining 99\% performance at
baseline cost. Results are validated across four benchmarks with rigorous
statistical testing.

</details>


### [9] [Improving Multi-View Reconstruction via Texture-Guided Gaussian-Mesh Joint Optimization](https://arxiv.org/abs/2511.03950)
*Zhejia Cai,Puhua Jiang,Shiwei Mao,Hongkun Cao,Ruqi Huang*

Main category: cs.CV

TL;DR: 本论文提出一种创新框架，通过高斯引导的网格可微渲染技术，实现几何和外观的联合优化，从而提升3D重建的质量与适用性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在几何准确性和逼真渲染之间存在优先级冲突，导致后续编辑任务受限，因此需要统一优化几何和外观。

Method: 采用高斯引导的网格可微渲染框架，同时优化网格几何和顶点颜色，充分利用输入图像的光度一致性和法线、深度图的几何正则化。

Result: 成功实现了高质量的3D重建，且可用于后续的编辑任务，如重光照和形状变形。

Conclusion: 提出了一种统一的几何和外观优化方法，可以实现无缝的高质量3D重建，并能支持后续编辑任务。

Abstract: Reconstructing real-world objects from multi-view images is essential for
applications in 3D editing, AR/VR, and digital content creation. Existing
methods typically prioritize either geometric accuracy (Multi-View Stereo) or
photorealistic rendering (Novel View Synthesis), often decoupling geometry and
appearance optimization, which hinders downstream editing tasks. This paper
advocates an unified treatment on geometry and appearance optimization for
seamless Gaussian-mesh joint optimization. More specifically, we propose a
novel framework that simultaneously optimizes mesh geometry (vertex positions
and faces) and vertex colors via Gaussian-guided mesh differentiable rendering,
leveraging photometric consistency from input images and geometric
regularization from normal and depth maps. The obtained high-quality 3D
reconstruction can be further exploit in down-stream editing tasks, such as
relighting and shape deformation. The code will be publicly available upon
acceptance.

</details>


### [10] [A Linear Fractional Transformation Model and Calibration Method for Light Field Camera](https://arxiv.org/abs/2511.03962)
*Zhong Chen,Changfeng Chen*

Main category: cs.CV

TL;DR: 本文提出了一种新的参数标定方法，成功提升了光场相机的3D重建精度及仿真速度。


<details>
  <summary>Details</summary>
Motivation: 针对光场相机在3D重建中内参标定的挑战，提出有效的解决方案。

Method: 使用基于最小二乘法的解析解与非线性精细化相结合的方法。

Result: 在物理和模拟数据上进行实验验证了方法的有效性，并提升了深度学习方法的数据处理速度。

Conclusion: 提出的LFT参数能够有效解耦主镜头和微透镜阵列，提升了3D重建的精度，同时加速了原始光场图像的仿真。

Abstract: Accurate calibration of internal parameters is a crucial yet challenging
prerequisite for 3D reconstruction using light field cameras. In this paper, we
propose a linear fractional transformation(LFT) parameter $\alpha$ to decoupled
the main lens and micro lens array (MLA). The proposed method includes an
analytical solution based on least squares, followed by nonlinear refinement.
The method for detecting features from the raw images is also introduced.
Experimental results on both physical and simulated data have verified the
performance of proposed method. Based on proposed model, the simulation of raw
light field images becomes faster, which is crucial for data-driven deep
learning methods. The corresponding code can be obtained from the author's
website.

</details>


### [11] [Room Envelopes: A Synthetic Dataset for Indoor Layout Reconstruction from Images](https://arxiv.org/abs/2511.03970)
*Sam Bahrami,Dylan Campbell*

Main category: cs.CV

TL;DR: 本研究提出了Room Envelopes数据集，促进了对于场景结构元素的重建，提升了通过单目几何估计器对场景理解的效率。


<details>
  <summary>Details</summary>
Motivation: 针对现代场景重建方法在重建隐蔽表面时的局限性，特别是传统重建手段对简单平面结构的关注不足。

Method: 通过合成数据集，提供可见表面和去除配件后的结构布局的点映射，以支持单目几何估计器的监督学习。

Result: 通过使用该数据集，提升了对于场景的理解，能够同时预测可见表面和结构布局表面，确保场景和物体的形状与位置高效识别。

Conclusion: 该研究提出了一种名为Room Envelopes的合成数据集，旨在通过提供RGB图像及其对应的点映射，促进场景的结构性元素重建，改善场景的整体理解。

Abstract: Modern scene reconstruction methods are able to accurately recover 3D
surfaces that are visible in one or more images. However, this leads to
incomplete reconstructions, missing all occluded surfaces. While much progress
has been made on reconstructing entire objects given partial observations using
generative models, the structural elements of a scene, like the walls, floors
and ceilings, have received less attention. We argue that these scene elements
should be relatively easy to predict, since they are typically planar,
repetitive and simple, and so less costly approaches may be suitable. In this
work, we present a synthetic dataset -- Room Envelopes -- that facilitates
progress on this task by providing a set of RGB images and two associated
pointmaps for each image: one capturing the visible surface and one capturing
the first surface once fittings and fixtures are removed, that is, the
structural layout. As we show, this enables direct supervision for feed-forward
monocular geometry estimators that predict both the first visible surface and
the first layout surface. This confers an understanding of the scene's extent,
as well as the shape and location of its objects.

</details>


### [12] [Simple 3D Pose Features Support Human and Machine Social Scene Understanding](https://arxiv.org/abs/2511.03988)
*Wenshuo Qin,Leyla Isik*

Main category: cs.CV

TL;DR: 本研究揭示了人类在社交判断中依赖3D姿态信息，指出当前AI模型缺乏这一重要特征，提出改进AI性能的新方法。


<details>
  <summary>Details</summary>
Motivation: 探索人类如何利用3D视觉空间姿态信息来判断社交互动，从而克服AI视觉系统在社交互动识别上的挑战。

Method: 结合最先进的姿态和深度估计算法，从短视频片段中提取3D关节位置，并与当前的AI视觉模型进行比较。

Result: 研究发现，3D关节位置的预测能力优于大多数当前的AI视觉模型，且基于3D姿态特征的简单描述符显著提高了AI模型的性能。

Conclusion: 本研究表明，人类的社交场景理解依赖于3D姿态的显性表现，并且简单的结构化视觉空间原语可以支持这一理解。

Abstract: Humans can quickly and effortlessly extract a variety of information about
others' social interactions from visual input, ranging from visuospatial cues
like whether two people are facing each other to higher-level information. Yet,
the computations supporting these abilities remain poorly understood, and
social interaction recognition continues to challenge even the most advanced AI
vision systems. Here, we hypothesized that humans rely on 3D visuospatial pose
information to make social interaction judgments, which is absent in most AI
vision models. To test this, we combined state-of-the-art pose and depth
estimation algorithms to extract 3D joint positions of people in short video
clips depicting everyday human actions and compared their ability to predict
human social interaction judgments with current AI vision models. Strikingly,
3D joint positions outperformed most current AI vision models, revealing that
key social information is available in explicit body position but not in the
learned features of most vision models, including even the layer-wise
embeddings of the pose models used to extract joint positions. To uncover the
critical pose features humans use to make social judgments, we derived a
compact set of 3D social pose features describing only the 3D position and
direction of faces in the videos. We found that these minimal descriptors
matched the predictive strength of the full set of 3D joints and significantly
improved the performance of off-the-shelf AI vision models when combined with
their embeddings. Moreover, the degree to which 3D social pose features were
represented in each off-the-shelf AI vision model predicted the model's ability
to match human social judgments. Together, our findings provide strong evidence
that human social scene understanding relies on explicit representations of 3D
pose and can be supported by simple, structured visuospatial primitives.

</details>


### [13] [CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation](https://arxiv.org/abs/2511.03992)
*Yuwen Tao,Kanglei Zhou,Xin Tan,Yuan Xie*

Main category: cs.CV

TL;DR: R3DGS通过CaRF框架实现3D高斯空间的多视图一致性，显著提升3D场景理解性能。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有管道在跨视图一致性方面的挑战，特别是在使用2D渲染伪监督和视图特定特征学习时。

Method: 提出了一种全微分框架CaRF，通过GFCE和ITPVS直接在3D高斯空间中操作以增强几何推理。

Result: 在多个基准测试上，CaRF在mIoU上分别提高了16.8%、4.3%和2.0%。

Conclusion: 该方法在多视图一致性上表现优越，有助于提升3D场景理解的可靠性。

Abstract: Referring 3D Gaussian Splatting Segmentation (R3DGS) aims to interpret
free-form language expressions and localize the corresponding 3D regions in
Gaussian fields. While recent advances have introduced cross-modal alignment
between language and 3D geometry, existing pipelines still struggle with
cross-view consistency due to their reliance on 2D rendered pseudo supervision
and view specific feature learning. In this work, we present Camera Aware
Referring Field (CaRF), a fully differentiable framework that operates directly
in the 3D Gaussian space and achieves multi view consistency. Specifically,
CaRF introduces Gaussian Field Camera Encoding (GFCE), which incorporates
camera geometry into Gaussian text interactions to explicitly model view
dependent variations and enhance geometric reasoning. Building on this, In
Training Paired View Supervision (ITPVS) is proposed to align per Gaussian
logits across calibrated views during training, effectively mitigating single
view overfitting and exposing inter view discrepancies for optimization.
Extensive experiments on three representative benchmarks demonstrate that CaRF
achieves average improvements of 16.8%, 4.3%, and 2.0% in mIoU over state of
the art methods on the Ref LERF, LERF OVS, and 3D OVS datasets, respectively.
Moreover, this work promotes more reliable and view consistent 3D scene
understanding, with potential benefits for embodied AI, AR/VR interaction, and
autonomous perception.

</details>


### [14] [PhysCorr: Dual-Reward DPO for Physics-Constrained Text-to-Video Generation with Automated Preference Selection](https://arxiv.org/abs/2511.03997)
*Peiyao Wang,Weining Wang,Qi Li*

Main category: cs.CV

TL;DR: 本研究提出PhysCorr框架，通过引入PhysicsRM和PhyDPO，改善视频生成中的物理一致性，提升生成内容的可信度。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频生成的进展常常违反物理一致性原则，限制了其在各种应用中的使用。

Method: 提出了PhysicsRM作为一种双维奖励模型以量化物体稳定性和交互作用，并开发了PhyDPO作为一种新颖的直接偏好优化管道。

Result: 在多个基准测试中，PhysCorr在物理真实感方面实现了显著提升。

Conclusion: PhysCorr在物理一致性视频生成方面取得了显著进展，提升了物理真实感，同时保持了视觉保真度和语义一致性。

Abstract: Recent advances in text-to-video generation have achieved impressive
perceptual quality, yet generated content often violates fundamental principles
of physical plausibility - manifesting as implausible object dynamics,
incoherent interactions, and unrealistic motion patterns. Such failures hinder
the deployment of video generation models in embodied AI, robotics, and
simulation-intensive domains. To bridge this gap, we propose PhysCorr, a
unified framework for modeling, evaluating, and optimizing physical consistency
in video generation. Specifically, we introduce PhysicsRM, the first
dual-dimensional reward model that quantifies both intra-object stability and
inter-object interactions. On this foundation, we develop PhyDPO, a novel
direct preference optimization pipeline that leverages contrastive feedback and
physics-aware reweighting to guide generation toward physically coherent
outputs. Our approach is model-agnostic and scalable, enabling seamless
integration into a wide range of video diffusion and transformer-based
backbones. Extensive experiments across multiple benchmarks demonstrate that
PhysCorr achieves significant improvements in physical realism while preserving
visual fidelity and semantic alignment. This work takes a critical step toward
physically grounded and trustworthy video generation.

</details>


### [15] [Near-Lossless 3D Voxel Representation Free from Iso-surface](https://arxiv.org/abs/2511.04029)
*Yihao Luo,Xianglong He,Chuanyu Pan,Yiwen Chen,Jiaqi Wu,Yangguang Li,Wanli Ouyang,Yuanming Hu,Guang Yang,ChoonHwai Yap*

Main category: cs.CV

TL;DR: Faithful Contouring是一种新型的体素化表示方法，提供高达2048+分辨率，具有近乎无损的几何保真度，并在3D重建精度和效率上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于等值面的表示方法在几何保真度上存在妥协，因此需要寻找一种新的表示方法来提高3D重建和生成的准确性与效率。

Method: 提出了一种稀疏体素化表示方法，并设计了一种双模式自编码器，以实现可扩展且保留细节的形状重建。

Result: 实验结果显示，Faithful Contouring在直接表示中达到了$10^{-5}$级距离误差，在网格重建中Chamfer距离减少了93	ext%且F-score提高了35	ext%。

Conclusion: 提出的Faithful Contouring方法在3D网格的表示和重建中表现出更高的准确性和效率，优于现有方法，且具有优良的细节保留能力。

Abstract: Accurate and efficient voxelized representations of 3D meshes are the
foundation of 3D reconstruction and generation. However, existing
representations based on iso-surface heavily rely on water-tightening or
rendering optimization, which inevitably compromise geometric fidelity. We
propose Faithful Contouring, a sparse voxelized representation that supports
2048+ resolutions for arbitrary meshes, requiring neither converting meshes to
field functions nor extracting the isosurface during remeshing. It achieves
near-lossless fidelity by preserving sharpness and internal structures, even
for challenging cases with complex geometry and topology. The proposed method
also shows flexibility for texturing, manipulation, and editing. Beyond
representation, we design a dual-mode autoencoder for Faithful Contouring,
enabling scalable and detail-preserving shape reconstruction. Extensive
experiments show that Faithful Contouring surpasses existing methods in
accuracy and efficiency for both representation and reconstruction. For direct
representation, it achieves distance errors at the $10^{-5}$ level; for mesh
reconstruction, it yields a 93\% reduction in Chamfer Distance and a 35\%
improvement in F-score over strong baselines, confirming superior fidelity as a
representation for 3D learning tasks.

</details>


### [16] [A Hybrid Deep Learning Model for Robust Biometric Authentication from Low-Frame-Rate PPG Signals](https://arxiv.org/abs/2511.04037)
*Arfina Rahman,Mahesh Banavar*

Main category: cs.CV

TL;DR: 本文提出了一种基于低帧率指尖视频的轻量级PPG信号生物识别框架，使用混合深度学习模型进行特征提取，实验结果显示其认证准确率高达98%。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴设备的普及，开发一个低成本且有效的生物识别系统变得非常必要，而PPG信号提供了一种非侵入性且能够实时检测的解决方案。

Method: 使用连续小波变换（CWT）将PPG信号转换为二维时频标度图，并结合CVT与LSTM的混合深度学习模型进行特征提取和分类。

Result: 在46名受试者上进行的实验表明，认证准确率高达98%，显示出该系统对噪声和个体间变化的强鲁棒性。

Conclusion: 提出的生物识别认证框架在真实场景中具有很高的应用潜力，验证了其抗噪声能力和在个体之间的可变性，同时具备高效性和可扩展性。

Abstract: Photoplethysmography (PPG) signals, which measure changes in blood volume in
the skin using light, have recently gained attention in biometric
authentication because of their non-invasive acquisition, inherent liveness
detection, and suitability for low-cost wearable devices. However, PPG signal
quality is challenged by motion artifacts, illumination changes, and
inter-subject physiological variability, making robust feature extraction and
classification crucial. This study proposes a lightweight and cost-effective
biometric authentication framework based on PPG signals extracted from
low-frame-rate fingertip videos. The CFIHSR dataset, comprising PPG recordings
from 46 subjects at a sampling rate of 14 Hz, is employed for evaluation. The
raw PPG signals undergo a standard preprocessing pipeline involving baseline
drift removal, motion artifact suppression using Principal Component Analysis
(PCA), bandpass filtering, Fourier-based resampling, and amplitude
normalization. To generate robust representations, each one-dimensional PPG
segment is converted into a two-dimensional time-frequency scalogram via the
Continuous Wavelet Transform (CWT), effectively capturing transient
cardiovascular dynamics. We developed a hybrid deep learning model, termed
CVT-ConvMixer-LSTM, by combining spatial features from the Convolutional Vision
Transformer (CVT) and ConvMixer branches with temporal features from a Long
Short-Term Memory network (LSTM). The experimental results on 46 subjects
demonstrate an authentication accuracy of 98%, validating the robustness of the
model to noise and variability between subjects. Due to its efficiency,
scalability, and inherent liveness detection capability, the proposed system is
well-suited for real-world mobile and embedded biometric security applications.

</details>


### [17] [Unveiling Deep Semantic Uncertainty Perception for Language-Anchored Multi-modal Vision-Brain Alignment](https://arxiv.org/abs/2511.04078)
*Zehui Feng,Chenqi Zhang,Mingru Wang,Minuo Wei,Shiwei Cheng,Cuntai Guan,Ting Han*

Main category: cs.CV

TL;DR: Bratrix是首个实现多模态语言锚定视觉-脑对齐的框架，显著提升视觉信号与神经信号的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 由于现有方法无法充分捕捉潜在语义维度，从而限制了解释性和深度鲁棒性，因此需要新的方法来提升神经信号与视觉表示的对齐。

Method: 提出了一种名为Bratrix的端到端框架，通过解耦视觉刺激为层次化的视觉和语言语义组件，并投影到共享潜在空间，实现视觉-语言和脑-语言嵌入的对齐。

Result: 在EEG、MEG和fMRI基准测试中，Bratrix相比于最先进的方法在检索、重构和字幕生成上有明显提高，尤其在200-way EEG检索任务中表现优异。

Conclusion: Bratrix在多模态视觉-语言-脑对齐方面表现出色，提升了检索、重构和字幕生成的性能，尤其在200-way EEG检索任务中超越了14.3%的领先方法。

Abstract: Unveiling visual semantics from neural signals such as EEG, MEG, and fMRI
remains a fundamental challenge due to subject variability and the entangled
nature of visual features. Existing approaches primarily align neural activity
directly with visual embeddings, but visual-only representations often fail to
capture latent semantic dimensions, limiting interpretability and deep
robustness. To address these limitations, we propose Bratrix, the first
end-to-end framework to achieve multimodal Language-Anchored Vision-Brain
alignment. Bratrix decouples visual stimuli into hierarchical visual and
linguistic semantic components, and projects both visual and brain
representations into a shared latent space, enabling the formation of aligned
visual-language and brain-language embeddings. To emulate human-like perceptual
reliability and handle noisy neural signals, Bratrix incorporates a novel
uncertainty perception module that applies uncertainty-aware weighting during
alignment. By leveraging learnable language-anchored semantic matrices to
enhance cross-modal correlations and employing a two-stage training strategy of
single-modality pretraining followed by multimodal fine-tuning, Bratrix-M
improves alignment precision. Extensive experiments on EEG, MEG, and fMRI
benchmarks demonstrate that Bratrix improves retrieval, reconstruction, and
captioning performance compared to state-of-the-art methods, specifically
surpassing 14.3% in 200-way EEG retrieval task. Code and model are available.

</details>


### [18] [Adversarial and Score-Based CT Denoising: CycleGAN vs Noise2Score](https://arxiv.org/abs/2511.04083)
*Abu Hanif Muhammad Syarubany*

Main category: cs.CV

TL;DR: 本文研究了CycleGAN和Noise2Score在CT图像去噪中的表现，CycleGAN提供了最佳图像质量，Noise2Score则在嘈杂数据上表现出色。


<details>
  <summary>Details</summary>
Motivation: 在缺乏干净图像对的情况下研究CT图像去噪方法的有效性。

Method: 使用CycleGAN和Noise2Score进行CT图像去噪，评估其在无配对和自监督环境中的表现。

Result: CycleGAN提高图像质量至34.66 dB / 0.9234 SSIM到38.913 dB / 0.971 SSIM，而Noise2Score在非常嘈杂的输入上显示出显著改进。

Conclusion: CycleGAN提供了最佳的图像质量，而Noise2Score在缺乏干净对的情况下表现出色，具有竞争力的性能。

Abstract: We study CT image denoising in the unpaired and self-supervised regimes by
evaluating two strong, training-data-efficient paradigms: a CycleGAN-based
residual translator and a Noise2Score (N2S) score-matching denoiser. Under a
common evaluation protocol, a configuration sweep identifies a simple standard
U-Net backbone within CycleGAN (lambda_cycle = 30, lambda_iden = 2, ngf = ndf =
64) as the most reliable setting; we then train it to convergence with a longer
schedule. The selected CycleGAN improves the noisy input from 34.66 dB / 0.9234
SSIM to 38.913 dB / 0.971 SSIM and attains an estimated score of 1.9441 and an
unseen-set (Kaggle leaderboard) score of 1.9343. Noise2Score, while slightly
behind in absolute PSNR / SSIM, achieves large gains over very noisy inputs,
highlighting its utility when clean pairs are unavailable. Overall, CycleGAN
offers the strongest final image quality, whereas Noise2Score provides a robust
pair-free alternative with competitive performance. Source code is available at
https://github.com/hanifsyarubany/CT-Scan-Image-Denoising-using-CycleGAN-and-Noise2Score.

</details>


### [19] [SpatialLock: Precise Spatial Control in Text-to-Image Synthesis](https://arxiv.org/abs/2511.04112)
*Biao Liu,Yuanzhi Liang*

Main category: cs.CV

TL;DR: 本论文提出了一个新框架 SpatialLock，旨在提升文本到图像合成中的对象定位精度，结合了空间信息和感知信号，实验结果表明其在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到图像合成已经取得显著进展，但在生成图像中精确控制对象的定位依然存在挑战，现有方法未能充分利用位置相关信息。

Method: SpatialLock 由两个主要组成部分构成：Position-Engaged Injection (PoI) 和 Position-Guided Learning (PoG)，前者通过注意力层直接整合空间信息，后者利用基于感知的监督进一步优化对象定位。

Result: 实验表明，SpatialLock 在多个数据集上实现了状态-of-the-art 的精确对象定位，IOU 分数超过 0.9。

Conclusion: SpatialLock 是一种有效的框架，通过整合感知信号和定位信息，实现了对象生成的精确空间定位。

Abstract: Text-to-Image (T2I) synthesis has made significant advancements in recent
years, driving applications such as generating datasets automatically. However,
precise control over object localization in generated images remains a
challenge. Existing methods fail to fully utilize positional information,
leading to an inadequate understanding of object spatial layouts. To address
this issue, we propose SpatialLock, a novel framework that leverages perception
signals and grounding information to jointly control the generation of spatial
locations. SpatialLock incorporates two components: Position-Engaged Injection
(PoI) and Position-Guided Learning (PoG). PoI directly integrates spatial
information through an attention layer, encouraging the model to learn the
grounding information effectively. PoG employs perception-based supervision to
further refine object localization. Together, these components enable the model
to generate objects with precise spatial arrangements and improve the visual
quality of the generated images. Experiments show that SpatialLock sets a new
state-of-the-art for precise object positioning, achieving IOU scores above 0.9
across multiple datasets.

</details>


### [20] [Tortoise and Hare Guidance: Accelerating Diffusion Model Inference with Multirate Integration](https://arxiv.org/abs/2511.04117)
*Yunghee Lee,Byeonghyun Pak,Junwha Hong,Hoseong Kim*

Main category: cs.CV

TL;DR: 本论文提出了一种名为THG的无训练策略，能在保留生成质量的同时，将扩散采样速度提升30%。


<details>
  <summary>Details</summary>
Motivation: 旨在加速扩散采样，同时保持高保真度生成，解决传统求解器未能利用的显著冗余。

Method: 提出了一种训练无关的策略，名为Tortoise and Hare Guidance (THG)，通过将噪声估计与原始的细粒度时间步长网格上的龟方程积分，同时在粗糙网格上与兔子方程积分来减少额外指导的计算。

Result: 通过分析误差边界，THG展示了附加指导分支对近似的更强鲁棒性，提供了一种新的方法来提高扩散求解器的效率。

Conclusion: THG显著减少了额外指导的计算，能够在几乎没有生成保真度损失的情况下减少多达30%的函数评估次数，并在相同计算预算下超越了最先进的基于CFG的无训练加速器。

Abstract: In this paper, we propose Tortoise and Hare Guidance (THG), a training-free
strategy that accelerates diffusion sampling while maintaining high-fidelity
generation. We demonstrate that the noise estimate and the additional guidance
term exhibit markedly different sensitivity to numerical error by reformulating
the classifier-free guidance (CFG) ODE as a multirate system of ODEs. Our
error-bound analysis shows that the additional guidance branch is more robust
to approximation, revealing substantial redundancy that conventional solvers
fail to exploit. Building on this insight, THG significantly reduces the
computation of the additional guidance: the noise estimate is integrated with
the tortoise equation on the original, fine-grained timestep grid, while the
additional guidance is integrated with the hare equation only on a coarse grid.
We also introduce (i) an error-bound-aware timestep sampler that adaptively
selects step sizes and (ii) a guidance-scale scheduler that stabilizes large
extrapolation spans. THG reduces the number of function evaluations (NFE) by up
to 30% with virtually no loss in generation fidelity ($\Delta$ImageReward
$\leq$ 0.032) and outperforms state-of-the-art CFG-based training-free
accelerators under identical computation budgets. Our findings highlight the
potential of multirate formulations for diffusion solvers, paving the way for
real-time high-quality image synthesis without any model retraining. The source
code is available at https://github.com/yhlee-add/THG.

</details>


### [21] [Text to Sketch Generation with Multi-Styles](https://arxiv.org/abs/2511.04123)
*Tengjie Li,Shikui Tu,Lei Xu*

Main category: cs.CV

TL;DR: 提出一种基于扩散模型的无训练框架，实现草图生成中的样式指导和多样式控制。


<details>
  <summary>Details</summary>
Motivation: 提高草图生成的质量和样式控制能力，克服现有方法中的局限性。

Method: 基于扩散模型的无训练框架，通过文本提示和参考样式草图实现明确的样式指导。

Result: 实验表明，该方法在草图生成中实现了准确的样式对齐和增强的灵活性。

Conclusion: 该方法在草图生成中实现了高质量的样式对齐和灵活的样式控制。

Abstract: Recent advances in vision-language models have facilitated progress in sketch
generation. However, existing specialized methods primarily focus on generic
synthesis and lack mechanisms for precise control over sketch styles. In this
work, we propose a training-free framework based on diffusion models that
enables explicit style guidance via textual prompts and referenced style
sketches. Unlike previous style transfer methods that overwrite key and value
matrices in self-attention, we incorporate the reference features as auxiliary
information with linear smoothing and leverage a style-content guidance
mechanism. This design effectively reduces content leakage from reference
sketches and enhances synthesis quality, especially in cases with low
structural similarity between reference and target sketches. Furthermore, we
extend our framework to support controllable multi-style generation by
integrating features from multiple reference sketches, coordinated via a joint
AdaIN module. Extensive experiments demonstrate that our approach achieves
high-quality sketch generation with accurate style alignment and improved
flexibility in style control. The official implementation of M3S is available
at https://github.com/CMACH508/M3S.

</details>


### [22] [Automated Tennis Player and Ball Tracking with Court Keypoints Detection (Hawk Eye System)](https://arxiv.org/abs/2511.04126)
*Venkata Manikanta Desu,Syed Fawaz Ali*

Main category: cs.CV

TL;DR: 本研究开发了一种自动化网球比赛分析框架，整合深度学习模型，提供精准的比赛数据分析和可视化视频，供相关人士参考。


<details>
  <summary>Details</summary>
Motivation: 为了提供高效的网球比赛分析工具，帮助教练、转播者和球员获取比赛动态的深刻见解。

Method: 将多个深度学习模型集成，使用YOLOv8进行球员检测，YOLOv5自定义模型进行球追踪，以及基于ResNet50的架构进行场地关键点检测。

Result: 实验结果表明，在不同场地条件和比赛场景下，该系统表现出色，能够准确解析球员移动模式、球速、击球准确性和反应时间。

Conclusion: 该研究成功实现了自动化网球比赛分析的完整流程，提供了详细的数据分析和可视化，帮助相关人员深入理解比赛动态。

Abstract: This study presents a complete pipeline for automated tennis match analysis.
Our framework integrates multiple deep learning models to detect and track
players and the tennis ball in real time, while also identifying court
keypoints for spatial reference. Using YOLOv8 for player detection, a
custom-trained YOLOv5 model for ball tracking, and a ResNet50-based
architecture for court keypoint detection, our system provides detailed
analytics including player movement patterns, ball speed, shot accuracy, and
player reaction times. The experimental results demonstrate robust performance
in varying court conditions and match scenarios. The model outputs an annotated
video along with detailed performance metrics, enabling coaches, broadcasters,
and players to gain actionable insights into the dynamics of the game.

</details>


### [23] [DMSORT: An efficient parallel maritime multi-object tracking architecture for unmanned vessel platforms](https://arxiv.org/abs/2511.04128)
*Shengyu Tang,Zeyuan Lu,Jiazhi Dong,Changdong Yu,Xiaoyu Wang,Yaohui Lyu,Weihao Xia*

Main category: cs.CV

TL;DR: DMSORT是一种高效的海洋多目标追踪方法，结合仿射补偿和多级视觉特征检测，表现出卓越的速度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了应对复杂海洋环境对摄像机运动和视觉退化造成的挑战，提高海洋环境的多目标追踪的准确性。

Method: 提出了一种高效的双分支海洋SORT（DMSORT）方法，核心是一个具有仿射补偿的并行跟踪器，结合了目标检测与重识别（ReID）分支及动态摄像机运动估计分支。

Result: 在新加坡海洋数据集上的广泛评估中，DMSORT展示了最先进的性能。

Conclusion: DMSORT在现有的基于ReID的多目标追踪框架中实现了最快的运行速度，同时保持了高身份一致性和对抖动与遮挡的强鲁棒性。

Abstract: Accurate perception of the marine environment through robust multi-object
tracking (MOT) is essential for ensuring safe vessel navigation and effective
maritime surveillance. However, the complicated maritime environment often
causes camera motion and subsequent visual degradation, posing significant
challenges to MOT. To address this challenge, we propose an efficient
Dual-branch Maritime SORT (DMSORT) method for maritime MOT. The core of the
framework is a parallel tracker with affine compensation, which incorporates an
object detection and re-identification (ReID) branch, along with a dedicated
branch for dynamic camera motion estimation. Specifically, a Reversible
Columnar Detection Network (RCDN) is integrated into the detection module to
leverage multi-level visual features for robust object detection. Furthermore,
a lightweight Transformer-based appearance extractor (Li-TAE) is designed to
capture global contextual information and generate robust appearance features.
Another branch decouples platform-induced and target-intrinsic motion by
constructing a projective transformation, applying platform-motion compensation
within the Kalman filter, and thereby stabilizing true object trajectories.
Finally, a clustering-optimized feature fusion module effectively combines
motion and appearance cues to ensure identity consistency under noise,
occlusion, and drift. Extensive evaluations on the Singapore Maritime Dataset
demonstrate that DMSORT achieves state-of-the-art performance. Notably, DMSORT
attains the fastest runtime among existing ReID-based MOT frameworks while
maintaining high identity consistency and robustness to jitter and occlusion.
Code is available at:
https://github.com/BiscuitsLzy/DMSORT-An-efficient-parallel-maritime-multi-object-tracking-architecture-.

</details>


### [24] [Seeing Straight: Document Orientation Detection for Efficient OCR](https://arxiv.org/abs/2511.04161)
*Suranjan Goswami,Abhinav Ravi,Raja Kolla,Ali Faraz,Shaharukh Khan,Akash,Chandra Khatri,Shubham Agarwal*

Main category: cs.CV

TL;DR: 本研究介绍了OCR-Rotation-Bench基准和高效的文档旋转分类方法，旨在提升OCR任务的准确性与性能。


<details>
  <summary>Details</summary>
Motivation: 在OCR应用中修正文档旋转以提高下游任务性能是一个重要的预处理步骤。

Method: 使用基于Phi-3.5-Vision模型的旋转分类管道，动态图像裁剪，针对4类旋转任务进行微调。

Result: 在两个数据集上，旋转识别的准确率分别达到96%和92%；通过该模块提升OCR性能，关闭源模型提升达14%，开放权重模型提升达4倍。

Conclusion: 该研究提出了一种新颖的OCR-Rotation-Bench基准和高效的旋转分类管道，显著提升了OCR性能。

Abstract: Despite significant advances in document understanding, determining the
correct orientation of scanned or photographed documents remains a critical
pre-processing step in the real world settings. Accurate rotation correction is
essential for enhancing the performance of downstream tasks such as Optical
Character Recognition (OCR) where misalignment commonly arises due to user
errors, particularly incorrect base orientations of the camera during capture.
In this study, we first introduce OCR-Rotation-Bench (ORB), a new benchmark for
evaluating OCR robustness to image rotations, comprising (i) ORB-En, built from
rotation-transformed structured and free-form English OCR datasets, and (ii)
ORB-Indic, a novel multilingual set spanning 11 Indic mid to low-resource
languages. We also present a fast, robust and lightweight rotation
classification pipeline built on the vision encoder of Phi-3.5-Vision model
with dynamic image cropping, fine-tuned specifically for 4-class rotation task
in a standalone fashion. Our method achieves near-perfect 96% and 92% accuracy
on identifying the rotations respectively on both the datasets. Beyond
classification, we demonstrate the critical role of our module in boosting OCR
performance: closed-source (up to 14%) and open-weights models (up to 4x) in
the simulated real-world setting.

</details>


### [25] [Systematic Evaluation of Preprocessing Techniques for Accurate Image Registration in Digital Pathology](https://arxiv.org/abs/2511.04171)
*Fatemehzahra Darzi,Rodrigo Escobar Diaz Guerrero,Thomas Bocklitz*

Main category: cs.CV

TL;DR: 本研究探讨了不同颜色转换技术对数字病理学图像注册的影响，发现CycleGAN显著降低了注册误差。


<details>
  <summary>Details</summary>
Motivation: 准确的图像注册是数字病理学中的关键步骤，这项研究旨在探讨颜色转换如何影响多模态图像的注册效果。

Method: 研究了各种颜色转换技术对H&E染色图像与非线性多模态图像之间注册的影响，使用了多个图像预处理步骤，并评估了注册性能。

Result: CycleGAN颜色转换方法在各种预处理步骤中表现最佳，注册误差最低，而其他方法的误差较高。

Conclusion: 应用颜色转换前处理可以显著提高来自不同成像模态的图像对齐效果，从而支持数字病理学中更可靠的分析。

Abstract: Image registration refers to the process of spatially aligning two or more
images by mapping them into a common coordinate system, so that corresponding
anatomical or tissue structures are matched across images. In digital
pathology, registration enables direct comparison and integration of
information from different stains or imaging modalities, sup-porting
applications such as biomarker analysis and tissue reconstruction. Accurate
registration of images from different modalities is an essential step in
digital pathology. In this study, we investigated how various color
transformation techniques affect image registration between hematoxylin and
eosin (H&E) stained images and non-linear multimodal images. We used a dataset
of 20 tissue sample pairs, with each pair undergoing several preprocessing
steps, including different color transformation (CycleGAN, Macenko, Reinhard,
Vahadane), inversion, contrast adjustment, intensity normalization, and
denoising. All images were registered using the VALIS registration method,
which first applies rigid registration and then performs non-rigid registration
in two steps on both low and high-resolution images. Registration performance
was evaluated using the relative Target Registration Error (rTRE). We reported
the median of median rTRE values (MMrTRE) and the average of median rTRE values
(AMrTRE) for each method. In addition, we performed a custom point-based
evaluation using ten manually selected key points. Registration was done
separately for two scenarios, using either the original or inverted multimodal
images. In both scenarios, CycleGAN color transformation achieved the lowest
registration errors, while the other methods showed higher errors. These
findings show that applying color transformation before registration improves
alignment between images from different modalities and supports more reliable
analysis in digital pathology.

</details>


### [26] [AStF: Motion Style Transfer via Adaptive Statistics Fusor](https://arxiv.org/abs/2511.04192)
*Hanmo Chen,Chenghao Xu,Jiexi Yan,Cheng Deng*

Main category: cs.CV

TL;DR: 提出了一种新的自适应统计融合器（AStF），通过引入偏度和峰度改进运动风格转移，实验表明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的运动风格转移方法不足以捕捉运动数据的复杂动态模式和时空连贯性，因此引入偏度和峰度来改进分析。

Method: 提出了一种新的自适应统计融合器（AStF），包括风格解耦模块（SDM）和高阶多统计注意力（HOS-Attn），并结合运动一致性正则化（MCR）鉴别器训练。

Result: 通过更全面的时空统计模式分析，AStF在运动风格转移上显示出相对于现有技术的显著优势。

Conclusion: 提出的AStF在动态风格转移方面优于现有技术，提供了更全面的时空统计模式模型。

Abstract: Human motion style transfer allows characters to appear less rigidity and
more realism with specific style. Traditional arbitrary image style transfer
typically process mean and variance which is proved effective. Meanwhile,
similar methods have been adapted for motion style transfer. However, due to
the fundamental differences between images and motion, relying on mean and
variance is insufficient to fully capture the complex dynamic patterns and
spatiotemporal coherence properties of motion data. Building upon this, our key
insight is to bring two more coefficient, skewness and kurtosis, into the
analysis of motion style. Specifically, we propose a novel Adaptive Statistics
Fusor (AStF) which consists of Style Disentanglement Module (SDM) and
High-Order Multi-Statistics Attention (HOS-Attn). We trained our AStF in
conjunction with a Motion Consistency Regularization (MCR) discriminator.
Experimental results show that, by providing a more comprehensive model of the
spatiotemporal statistical patterns inherent in dynamic styles, our proposed
AStF shows proficiency superiority in motion style transfers over
state-of-the-arts. Our code and model are available at
https://github.com/CHMimilanlan/AStF.

</details>


### [27] [MedSapiens: Taking a Pose to Rethink Medical Imaging Landmark Detection](https://arxiv.org/abs/2511.04255)
*Marawan Elbatel,Anbang Wang,Keyuan Liu,Kaouther Mouheb,Enrique Almar-Munoz,Lizhuo Lin,Yanqi Yang,Karim Lekadir,Xiaomeng Li*

Main category: cs.CV

TL;DR: 本研究提出了MedSapiens模型，通过多数据集预训练，人本基础模型在医学影像解剖标志检测中表现出色，设立了多个数据集的新标准。


<details>
  <summary>Details</summary>
Motivation: 传统上，解剖标志检测依赖于领域特定的模型，而大型预训练视觉模型的出现为此领域带来了新的机会。

Method: 本研究通过多数据集预训练的方式，将Sapiens人本基础模型适应到医学影像的解剖标志检测中。

Result: MedSapiens在平均成功检测率(SDR)上与现有模型相比，展示了平均高达5.26%的改善，相较于专业模型更是提高了21.81%

Conclusion: 人本基础模型在解剖标志检测中的潜力尚未被充分利用，而MedSapiens通过跨数据集预训练在多个数据集上建立了新的性能标准。

Abstract: This paper does not introduce a novel architecture; instead, it revisits a
fundamental yet overlooked baseline: adapting human-centric foundation models
for anatomical landmark detection in medical imaging. While landmark detection
has traditionally relied on domain-specific models, the emergence of
large-scale pre-trained vision models presents new opportunities. In this
study, we investigate the adaptation of Sapiens, a human-centric foundation
model designed for pose estimation, to medical imaging through multi-dataset
pretraining, establishing a new state of the art across multiple datasets. Our
proposed model, MedSapiens, demonstrates that human-centric foundation models,
inherently optimized for spatial pose localization, provide strong priors for
anatomical landmark detection, yet this potential has remained largely
untapped. We benchmark MedSapiens against existing state-of-the-art models,
achieving up to 5.26% improvement over generalist models and up to 21.81%
improvement over specialist models in the average success detection rate (SDR).
To further assess MedSapiens adaptability to novel downstream tasks with few
annotations, we evaluate its performance in limited-data settings, achieving
2.69% improvement over the few-shot state of the art in SDR. Code and model
weights are available at https://github.com/xmed-lab/MedSapiens .

</details>


### [28] [Proto-LeakNet: Towards Signal-Leak Aware Attribution in Synthetic Human Face Imagery](https://arxiv.org/abs/2511.04260)
*Claudio Giusti,Luca Guarnera,Sebastiano Battiato*

Main category: cs.CV

TL;DR: Proto-LeakNet是一个新颖的归属框架，能够在扩散模型的潜在空间中有效地进行图像和深度伪造的取证。


<details>
  <summary>Details</summary>
Motivation: 随着合成图像和深度伪造生成模型日益复杂，源归属和真实性验证变得至关重要。

Method: 提出了一种新的框架Proto-LeakNet，结合了封闭集分类和基于密度的开放集评估，操作于扩散模型的潜在域。

Result: Proto-LeakNet在封闭数据集上训练，取得了98.13%的宏观AUC，超过了现有的方法，并在已知和未知生成器之间表现出强大的可分离性。

Conclusion: Proto-LeakNet通过建模潜在空间中的信号泄漏偏差，展现出在AI图像和深度伪造取证方面的可靠性和可解释性。

Abstract: The growing sophistication of synthetic image and deepfake generation models
has turned source attribution and authenticity verification into a critical
challenge for modern computer vision systems. Recent studies suggest that
diffusion pipelines unintentionally imprint persistent statistical traces,
known as signal leaks, within their outputs, particularly in latent
representations. Building on this observation, we propose Proto-LeakNet, a
signal-leak-aware and interpretable attribution framework that integrates
closed-set classification with a density-based open-set evaluation on the
learned embeddings, enabling analysis of unseen generators without retraining.
Operating in the latent domain of diffusion models, our method re-simulates
partial forward diffusion to expose residual generator-specific cues. A
temporal attention encoder aggregates multi-step latent features, while a
feature-weighted prototype head structures the embedding space and enables
transparent attribution. Trained solely on closed data and achieving a Macro
AUC of 98.13%, Proto-LeakNet learns a latent geometry that remains robust under
post-processing, surpassing state-of-the-art methods, and achieves strong
separability between known and unseen generators. These results demonstrate
that modeling signal-leak bias in latent space enables reliable and
interpretable AI-image and deepfake forensics. The code for the whole work will
be available upon submission.

</details>


### [29] [DINOv2 Driven Gait Representation Learning for Video-Based Visible-Infrared Person Re-identification](https://arxiv.org/abs/2511.04281)
*Yujie Yang,Shuang Li,Jun Ye,Neng Dong,Fan Li,Huafeng Li*

Main category: cs.CV

TL;DR: 提出DinoGRL框架，通过学习步态特征与外观线索的互补关系，提升视频行人重识别的性能，实验证明效果优越。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有视频行人重识别方法忽视步态特征以及跨模态匹配中的时空一致性问题，提出了新的框架来提升识别精度。

Method: 提出了DinoGRL框架，结合了语义感知剪影与步态学习模型(SASGL)和递进双向多粒度增强模块(PBMGE)，以优化跨模态检索的步态特征学习。

Result: 在HITSZ-VCM和BUPT数据集上的实验结果显示，所提出的方法显著优于当前的最先进技术。

Conclusion: 该研究提出的DinoGRL框架通过引入DINOv2的视觉先验，增强了步态特征的学习，从而在视频序列中实现了可见光和红外行人重识别的有效性，显著超越现有的方法。

Abstract: Video-based Visible-Infrared person re-identification (VVI-ReID) aims to
retrieve the same pedestrian across visible and infrared modalities from video
sequences. Existing methods tend to exploit modality-invariant visual features
but largely overlook gait features, which are not only modality-invariant but
also rich in temporal dynamics, thus limiting their ability to model the
spatiotemporal consistency essential for cross-modal video matching. To address
these challenges, we propose a DINOv2-Driven Gait Representation Learning
(DinoGRL) framework that leverages the rich visual priors of DINOv2 to learn
gait features complementary to appearance cues, facilitating robust
sequence-level representations for cross-modal retrieval. Specifically, we
introduce a Semantic-Aware Silhouette and Gait Learning (SASGL) model, which
generates and enhances silhouette representations with general-purpose semantic
priors from DINOv2 and jointly optimizes them with the ReID objective to
achieve semantically enriched and task-adaptive gait feature learning.
Furthermore, we develop a Progressive Bidirectional Multi-Granularity
Enhancement (PBMGE) module, which progressively refines feature representations
by enabling bidirectional interactions between gait and appearance streams
across multiple spatial granularities, fully leveraging their complementarity
to enhance global representations with rich local details and produce highly
discriminative features. Extensive experiments on HITSZ-VCM and BUPT datasets
demonstrate the superiority of our approach, significantly outperforming
existing state-of-the-art methods.

</details>


### [30] [FastGS: Training 3D Gaussian Splatting in 100 Seconds](https://arxiv.org/abs/2511.04283)
*Shiwei Ren,Tianci Wen,Yongchun Fang,Biao Lu*

Main category: cs.CV

TL;DR: FastGS是一个新颖且高效的加速框架，通过考虑每个高斯的重要性，显著提高了3D训练速度，并在多项任务中展现强大通用性。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯散布加速方法未能有效控制训练过程中的高斯数量，导致计算时间的冗余开销。

Method: 通过基于多视图一致性的密集化和修剪策略来优化高斯数量，从而解决训练时间与渲染质量之间的权衡。

Result: 在多个数据集上，FastGS显示出超过现有最先进的方法的训练速度提升，具体在Mip-NeRF 360数据集上加速为3.32倍，在Deep Blending数据集上加速为15.45倍。

Conclusion: FastGS在多种任务中表现出强大的通用性，提供了显著的训练加速和高质量的渲染效果。

Abstract: The dominant 3D Gaussian splatting (3DGS) acceleration methods fail to
properly regulate the number of Gaussians during training, causing redundant
computational time overhead. In this paper, we propose FastGS, a novel, simple,
and general acceleration framework that fully considers the importance of each
Gaussian based on multi-view consistency, efficiently solving the trade-off
between training time and rendering quality. We innovatively design a
densification and pruning strategy based on multi-view consistency, dispensing
with the budgeting mechanism. Extensive experiments on Mip-NeRF 360, Tanks &
Temples, and Deep Blending datasets demonstrate that our method significantly
outperforms the state-of-the-art methods in training speed, achieving a
3.32$\times$ training acceleration and comparable rendering quality compared
with DashGaussian on the Mip-NeRF 360 dataset and a 15.45$\times$ acceleration
compared with vanilla 3DGS on the Deep Blending dataset. We demonstrate that
FastGS exhibits strong generality, delivering 2-7$\times$ training acceleration
across various tasks, including dynamic scene reconstruction, surface
reconstruction, sparse-view reconstruction, large-scale reconstruction, and
simultaneous localization and mapping. The project page is available at
https://fastgs.github.io/

</details>


### [31] [Vision Foundation Models in Agriculture: Toward Domain-Specific Adaptation for Weed Herbicide Trials Assessment](https://arxiv.org/abs/2511.04288)
*Leire Benito-Del-Valle,Artzai Picón,Daniel Mugica,Manuel Ramos,Eva Portillo,Javier Romero,Carlos Javier Jimenez,Ramón Navarra-Mestre*

Main category: cs.CV

TL;DR: 本文通过自监督学习优化了通用视觉模型在 herbicide 试验中的应用，显著提高了图像分析性能，并减少了标注需求。


<details>
  <summary>Details</summary>
Motivation: 在农作物中的准确植物种类识别和 herbicide 确伤评估至关重要，现有的通用视觉模型在农业领域表现有限。

Method: 采用自监督学习方法在大型农业数据集上进行训练，以适应 herbicide 试验的特征。

Result: 通过领域特定模型，在物种识别和损伤分类任务中取得了显著的性能提升，尤其是在未见条件和低标注情况下表现出色。

Conclusion: 领域特定模型在 herbicide 试验分析中展现出较强的泛化能力，并能显著减少人工标注工作量，为 herbicide 试验提供可扩展且自动化的解决方案。

Abstract: Herbicide field trials require accurate identification of plant species and
assessment of herbicide-induced damage across diverse environments. While
general-purpose vision foundation models have shown promising results in
complex visual domains, their performance can be limited in agriculture, where
fine-grained distinctions between species and damage types are critical.
  In this work, we adapt a general-purpose vision foundation model to herbicide
trial characterization. Trained using a self-supervised learning approach on a
large, curated agricultural dataset, the model learns rich and transferable
representations optimized for herbicide trials images.
  Our domain-specific model significantly outperforms the best general-purpose
foundation model in both species identification (F1 score improvement from 0.91
to 0.94) and damage classification (from 0.26 to 0.33). Under unseen conditions
(new locations and other time), it achieves even greater gains (species
identification from 0.56 to 0.66; damage classification from 0.17 to 0.27). In
domain-shift scenarios, such as drone imagery, it maintains strong performance
(species classification from 0.49 to 0.60).
  Additionally, we show that domain-specific pretraining enhances segmentation
accuracy, particularly in low-annotation regimes. An annotation-efficiency
analysis reveals that, under unseen conditions, the domain-specific model
achieves 5.4% higher F1 score than the general-purpose model, while using 80%
fewer labeled samples.
  These results demonstrate the generalization capabilities of domain-specific
foundation models and their potential to significantly reduce manual annotation
efforts, offering a scalable and automated solution for herbicide trial
analysis.

</details>


### [32] [Deep learning-based object detection of offshore platforms on Sentinel-1 Imagery and the impact of synthetic training data](https://arxiv.org/abs/2511.04304)
*Robin Spanier,Thorsten Hoeser,Claudia Kuenzer*

Main category: cs.CV

TL;DR: 本研究探讨了合成数据在提升海洋基础设施检测模型性能方面的应用，强调了平衡数据集和合成数据生成的重要性。


<details>
  <summary>Details</summary>
Motivation: 海洋基础设施的扩展需要有效的监测系统，但在样本稀缺和对象类别、形状及大小不足的情况下，检测模型的开发面临挑战。

Method: 通过训练基于深度学习的YOLOv10物体检测模型，结合合成和真实的Sentinel-1卫星影像，评估了合成训练数据对模型性能的增强。

Result: 模型在三个未见区域成功检测到3,529个海洋平台，F1分数从0.85提高到0.90，表明合成数据在改善模型性能和类别不平衡方面的作用。

Conclusion: 该研究强调了平衡数据集的重要性，并指出合成数据生成是应对遥感中的常见挑战的有效策略，展示了深度学习在可扩展的全球海洋基础设施监测中的潜力。

Abstract: The recent and ongoing expansion of marine infrastructure, including offshore
wind farms, oil and gas platforms, artificial islands, and aquaculture
facilities, highlights the need for effective monitoring systems. The
development of robust models for offshore infrastructure detection relies on
comprehensive, balanced datasets, but falls short when samples are scarce,
particularly for underrepresented object classes, shapes, and sizes. By
training deep learning-based YOLOv10 object detection models with a combination
of synthetic and real Sentinel-1 satellite imagery acquired in the fourth
quarter of 2023 from four regions (Caspian Sea, South China Sea, Gulf of
Guinea, and Coast of Brazil), this study investigates the use of synthetic
training data to enhance model performance. We evaluated this approach by
applying the model to detect offshore platforms in three unseen regions (Gulf
of Mexico, North Sea, Persian Gulf) and thereby assess geographic
transferability. This region-holdout evaluation demonstrated that the model
generalises beyond the training areas. In total, 3,529 offshore platforms were
detected, including 411 in the North Sea, 1,519 in the Gulf of Mexico, and
1,593 in the Persian Gulf. The model achieved an F1 score of 0.85, which
improved to 0.90 upon incorporating synthetic data. We analysed how synthetic
data enhances the representation of unbalanced classes and overall model
performance, taking a first step toward globally transferable detection of
offshore infrastructure. This study underscores the importance of balanced
datasets and highlights synthetic data generation as an effective strategy to
address common challenges in remote sensing, demonstrating the potential of
deep learning for scalable, global offshore infrastructure monitoring.

</details>


### [33] [RISE-T2V: Rephrasing and Injecting Semantics with LLM for Expansive Text-to-Video Generation](https://arxiv.org/abs/2511.04317)
*Xiangjun Zhang,Litong Gong,Yinglin Zheng,Yansong Liu,Wentao Jiang,Mingyi Xu,Biao Wang,Tiezheng Ge,Ming Zeng*

Main category: cs.CV

TL;DR: RISE-T2V通过集成提示重述和语义特征提取，提升了文本到视频生成模型的用户意图对齐能力，显著改善了生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决文本到视频扩散模型在简单提示下生成视频质量不足的问题，同时提升模型的可扩展性和可用性。

Method: 提出了一种创新的组件称为重述适配器，使扩散模型能够在下一个令牌预测中利用文本隐藏状态以指导视频生成。

Result: RISE-T2V在不同的扩散模型架构中展示了优越的适用性，且通过大量实验验证了其在各种T2V任务上的能力。

Conclusion: RISE-T2V显著增强了文本到视频生成模型的能力，可以生成高质量的视频，更好地满足用户意图。

Abstract: Most text-to-video(T2V) diffusion models depend on pre-trained text encoders
for semantic alignment, yet they often fail to maintain video quality when
provided with concise prompts rather than well-designed ones. The primary issue
lies in their limited textual semantics understanding. Moreover, these text
encoders cannot rephrase prompts online to better align with user intentions,
which limits both the scalability and usability of the models, To address these
challenges, we introduce RISE-T2V, which uniquely integrates the processes of
prompt rephrasing and semantic feature extraction into a single and seamless
step instead of two separate steps. RISE-T2V is universal and can be applied to
various pre-trained LLMs and video diffusion models(VDMs), significantly
enhancing their capabilities for T2V tasks. We propose an innovative module
called the Rephrasing Adapter, enabling diffusion models to utilize text hidden
states during the next token prediction of the LLM as a condition for video
generation. By employing a Rephrasing Adapter, the video generation model can
implicitly rephrase basic prompts into more comprehensive representations that
better match the user's intent. Furthermore, we leverage the powerful
capabilities of LLMs to enable video generation models to accomplish a broader
range of T2V tasks. Extensive experiments demonstrate that RISE-T2V is a
versatile framework applicable to different video diffusion model
architectures, significantly enhancing the ability of T2V models to generate
high-quality videos that align with user intent. Visual results are available
on the webpage at https://rise-t2v.github.io.

</details>


### [34] [Evaluating the Impact of Weather-Induced Sensor Occlusion on BEVFusion for 3D Object Detection](https://arxiv.org/abs/2511.04347)
*Sanjay Kumar,Tim Brophy,Eoin Martino Grua,Ganesh Sistu,Valentina Donzella,Ciaran Eising*

Main category: cs.CV

TL;DR: 本研究探讨了环境条件下传感器遮挡对3D物体检测准确性的影响，结果表明相机和激光雷达在不同遮挡条件下对检测性能的影响差异，强调了改进融合技术的重要性。


<details>
  <summary>Details</summary>
Motivation: 准确的3D物体检测对于自动车辆在复杂的现实环境中安全导航至关重要，但目前对于环境因素导致的传感器遮挡对3D检测准确性的影响研究较少。

Method: 使用BEVFusion架构，基于nuScenes数据集评估传感器遮挡对相机和激光雷达输出的影响，检测性能通过平均精确度(mAP)和nuScenes检测分数(NDS)进行测量。

Result: 中等的相机遮挡导致mAP下降41.3%；而激光雷达在重度遮挡下性能锐减，mAP下降47.3%。在融合设置中，遮挡相机导致4.1%轻微下降，而遮挡激光雷达导致26.8%显著下降，表明模型对激光雷达的依赖性更强。

Conclusion: 本研究强调了在传感器遮挡情况下，增强3D物体检测准确性的必要性，并提出了未来需要在遮挡感知评估方法和传感器融合技术方面进行更多探索。

Abstract: Accurate 3D object detection is essential for automated vehicles to navigate
safely in complex real-world environments. Bird's Eye View (BEV)
representations, which project multi-sensor data into a top-down spatial
format, have emerged as a powerful approach for robust perception. Although
BEV-based fusion architectures have demonstrated strong performance through
multimodal integration, the effects of sensor occlusions, caused by
environmental conditions such as fog, haze, or physical obstructions, on 3D
detection accuracy remain underexplored. In this work, we investigate the
impact of occlusions on both camera and Light Detection and Ranging (LiDAR)
outputs using the BEVFusion architecture, evaluated on the nuScenes dataset.
Detection performance is measured using mean Average Precision (mAP) and the
nuScenes Detection Score (NDS). Our results show that moderate camera
occlusions lead to a 41.3% drop in mAP (from 35.6% to 20.9%) when detection is
based only on the camera. On the other hand, LiDAR sharply drops in performance
only under heavy occlusion, with mAP falling by 47.3% (from 64.7% to 34.1%),
with a severe impact on long-range detection. In fused settings, the effect
depends on which sensor is occluded: occluding the camera leads to a minor 4.1%
drop (from 68.5% to 65.7%), while occluding LiDAR results in a larger 26.8%
drop (to 50.1%), revealing the model's stronger reliance on LiDAR for the task
of 3D object detection. Our results highlight the need for future research into
occlusion-aware evaluation methods and improved sensor fusion techniques that
can maintain detection accuracy in the presence of partial sensor failure or
degradation due to adverse environmental conditions.

</details>


### [35] [A MATLAB tutorial on deep feature extraction combined with chemometrics for analytical applications](https://arxiv.org/abs/2511.04349)
*Puneet Mishra,Martijntje Vollebregt,Yizhou Ma,Maria Font-i-Furnols*

Main category: cs.CV

TL;DR: 本教程通过提供逐步指导和MATLAB示例，帮助分析化学领域的研究人员有效利用现有的深度学习模型，提取成像数据中的空间信息。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在图像处理方面有显著进展，但由于缺乏系统的实施指导，分析化学领域的应用仍然有限。

Method: 通过提供MATLAB代码示例和逐步指导，帮助读者在自己的数据集上应用深度学习方法。

Result: 本教程为图像数据处理提供了操作步骤，读者能够使用教程中的代码在自身数据集上运行以提取多尺度深层特征。

Conclusion: 本教程为分析化学领域提供了一种系统的方法，使用现有的深度学习模型来提取来自成像数据的空间信息，并可与其他数据源集成。

Abstract: Background In analytical chemistry, spatial information about materials is
commonly captured through imaging techniques, such as traditional color cameras
or with advanced hyperspectral cameras and microscopes. However, efficiently
extracting and analyzing this spatial information for exploratory and
predictive purposes remains a challenge, especially when using traditional
chemometric methods. Recent advances in deep learning and artificial
intelligence have significantly enhanced image processing capabilities,
enabling the extraction of multiscale deep features that are otherwise
challenging to capture with conventional image processing techniques. Despite
the wide availability of open-source deep learning models, adoption in
analytical chemistry remains limited because of the absence of structured,
step-by-step guidance for implementing these models.
  Results This tutorial aims to bridge this gap by providing a step-by-step
guide for applying deep learning approaches to extract spatial information from
imaging data and integrating it with other data sources, such as spectral
information. Importantly, the focus of this work is not on training deep
learning models for image processing but on using existing open source models
to extract deep features from imaging data.
  Significance The tutorial provides MATLAB code tutorial demonstrations,
showcasing the processing of imaging data from various imaging modalities
commonly encountered in analytical chemistry. Readers must run the tutorial
steps on their own datasets using the codes presented in this tutorial.

</details>


### [36] [Multi-Task Learning for Visually Grounded Reasoning in Gastrointestinal VQA](https://arxiv.org/abs/2511.04384)
*Itbaan Safwan,Muhammad Annas Shaikh,Muhammad Haaris,Ramail Khan,Muhammad Atif Tahir*

Main category: cs.CV

TL;DR: 提出了一种基于LoRA调整的Florence-2模型的多任务学习框架，旨在提高医疗视觉问答的准确性和可解释性，经过评估表现优异。


<details>
  <summary>Details</summary>
Motivation: 旨在提升医疗视觉问答的准确性和可解释性，同时进行视觉基础、推理和解释的联合学习。

Method: 利用LoRA调整的Florence-2模型，结合三个数据集进行多任务学习。

Result: 经过广泛评估，该方法在回答准确性和视觉定位方面显著优于单任务基线。

Conclusion: 该方法在医疗视觉问答应用中表现出色，显著提高了答案准确性和视觉定位能力。

Abstract: We present a multi-task framework for the MediaEval Medico 2025 challenge,
leveraging a LoRA-tuned Florence-2 model for simultaneous visual question
answering (VQA), explanation generation, and visual grounding. The proposed
system integrates three curated datasets: (1) Kvasir-VQA-x1 for question-answer
learning, (2) a synthetically enriched explanation dataset offering structured
medical reasoning, and (3) text-to-region pairs linking visual features with
segmentation masks. This multi-task setup enables the model to jointly learn
visual grounding, reasoning, and interpretation, producing responses that are
both accurate and interpretable. Extensive evaluation demonstrates that our
approach substantially improves over single-task baselines in both answer
accuracy and visual localization, highlighting the effectiveness of grounded
multi-task learning for medical VQA applications.

</details>


### [37] [BoRe-Depth: Self-supervised Monocular Depth Estimation with Boundary Refinement for Embedded Systems](https://arxiv.org/abs/2511.04388)
*Chang Liu,Juan Li,Sheng Zhang,Chang Liu,Jie Li,Xu Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新的单目深度估计模型BoRe-Depth，能在嵌入式系统中高效准确地进行深度估计，改善物体边界表现。


<details>
  <summary>Details</summary>
Motivation: 解决当前单目深度估计在嵌入式系统中性能较差和物体边界模糊的问题，提供低成本的深度估计方案。

Method: 提出了一种新颖的单目深度估计模型BoRe-Depth，设计了增强特征自适应融合模块（EFAF）和集成语义知识的编码器。

Result: BoRe-Depth包含8.7M参数，在NVIDIA Jetson Orin上以50.7 FPS的效率运行，显著提升了深度图的估计精度和边界细节表现。

Conclusion: BoRe-Depth在多个挑战性数据集上相比于以往轻量级模型表现显著优越，能够在嵌入式系统上高效、准确地估计深度图，并显著改善边界质量。

Abstract: Depth estimation is one of the key technologies for realizing 3D perception
in unmanned systems. Monocular depth estimation has been widely researched
because of its low?cost advantage, but the existing methods face the challenges
of poor depth estimation performance and blurred object boundaries on embedded
systems. In this paper, we propose a novel monocular depth estimation model,
BoRe-Depth, which contains only 8.7M parameters. It can accurately estimate
depth maps on embedded systems and significantly improves boundary quality.
Firstly, we design an Enhanced Feature Adaptive Fusion Module (EFAF) which
adaptively fuses depth features to enhance boundary detail representation.
Secondly, we integrate semantic knowledge into the encoder to improve the
object recognition and boundary perception capabilities. Finally, BoRe-Depth is
deployed on NVIDIA Jetson Orin, and runs efficiently at 50.7 FPS. We
demonstrate that the proposed model significantly outperforms previous
lightweight models on multiple challenging datasets, and we provide detailed
ablation studies for the proposed methods. The code is available at
https://github.com/liangxiansheng093/BoRe-Depth.

</details>


### [38] [DORAEMON: A Unified Library for Visual Object Modeling and Representation Learning at Scale](https://arxiv.org/abs/2511.04394)
*Ke Du,Yimin Peng,Chao Gao,Fan Zhou,Siqiao Xue*

Main category: cs.CV

TL;DR: DORAEMON是一个统一的开源PyTorch库，支持视觉对象建模和表示学习，提供了高效的实验基础和易于部署的解决方案。


<details>
  <summary>Details</summary>
Motivation: 旨在整合数据集、模型和训练技术，为视觉识别和表示学习提供一个可扩展的实验基础。

Method: 使用YAML驱动的工作流程进行分类、检索和度量学习，并支持多种模块化损失、增强和分布式训练工具。

Result: 在ImageNet-1K、MS-Celeb-1M和Stanford在线产品的基准测试中，具有可重复的实验结果，支持ONNX或HuggingFace格式的快速导出。

Conclusion: DORAEMON提供了一个统一的开源平台，促进视觉对象建模和表示学习的快速实验和部署。

Abstract: DORAEMON is an open-source PyTorch library that unifies visual object
modeling and representation learning across diverse scales. A single
YAML-driven workflow covers classification, retrieval and metric learning; more
than 1000 pretrained backbones are exposed through a timm-compatible interface,
together with modular losses, augmentations and distributed-training utilities.
Reproducible recipes match or exceed reference results on ImageNet-1K,
MS-Celeb-1M and Stanford online products, while one-command export to ONNX or
HuggingFace bridges research and deployment. By consolidating datasets, models,
and training techniques into one platform, DORAEMON offers a scalable
foundation for rapid experimentation in visual recognition and representation
learning, enabling efficient transfer of research advances to real-world
applications. The repository is available at https://github.com/wuji3/DORAEMON.

</details>


### [39] [HideAndSeg: an AI-based tool with automated prompting for octopus segmentation in natural habitats](https://arxiv.org/abs/2511.04426)
*Alan de Aguiar,Michaella Pereira Andrade,Charles Morphy D. Santos,João Paulo Gois*

Main category: cs.CV

TL;DR: 本研究提出HideAndSeg工具，用于自动化视频中章鱼的分割，提升了分割质量，减少了手动干预。


<details>
  <summary>Details</summary>
Motivation: 为了应对海洋环境中章鱼的伪装能力、皮肤变化及其他挑战，本文提出了一种新的AI工具，填补大型标注数据集的缺乏。

Method: 通过集成SAM2和自定义训练的YOLOv11目标检测器，HideAndSeg使用点坐标生成初始分割掩膜，并实现完全自动化的处理流程。

Result: HideAndSeg在视频分割任务中表现良好，能够在完全遮挡后重新识别和分割章鱼，优于手动提示模型。

Conclusion: HideAndSeg是一种有效的工具，可以减少手动分析的需求，促进野生头足类动物行为研究的效率。

Abstract: Analyzing octopuses in their natural habitats is challenging due to their
camouflage capability, rapid changes in skin texture and color, non-rigid body
deformations, and frequent occlusions, all of which are compounded by variable
underwater lighting and turbidity. Addressing the lack of large-scale annotated
datasets, this paper introduces HideAndSeg, a novel, minimally supervised
AI-based tool for segmenting videos of octopuses. It establishes a quantitative
baseline for this task. HideAndSeg integrates SAM2 with a custom-trained
YOLOv11 object detector. First, the user provides point coordinates to generate
the initial segmentation masks with SAM2. These masks serve as training data
for the YOLO model. After that, our approach fully automates the pipeline by
providing a bounding box prompt to SAM2, eliminating the need for further
manual intervention. We introduce two unsupervised metrics - temporal
consistency $DICE_t$ and new component count $NC_t$ - to quantitatively
evaluate segmentation quality and guide mask refinement in the absence of
ground-truth data, i.e., real-world information that serves to train, validate,
and test AI models. Results show that HideAndSeg achieves satisfactory
performance, reducing segmentation noise compared to the manually prompted
approach. Our method can re-identify and segment the octopus even after periods
of complete occlusion in natural environments, a scenario in which the manually
prompted model fails. By reducing the need for manual analysis in real-world
scenarios, this work provides a practical tool that paves the way for more
efficient behavioral studies of wild cephalopods.

</details>


### [40] [Solving Convex Partition Visual Jigsaw Puzzles](https://arxiv.org/abs/2511.04450)
*Yaniv Ohayon,Ofir Itzhak Shahar,Ohad Ben-Shahar*

Main category: cs.CV

TL;DR: 本研究扩展了拼图求解的类型，介绍了一种贪婪求解器，提供了性能评估和凸拼图的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 自动拼图求解器的潜在影响可能在多个应用领域具有破坏性，而现有文献主要集中于方形拼图的求解，限制了其实际应用。

Method: 利用几何和图像兼容性，提出了一种贪婪求解方法。

Result: 报告了多种性能测量，并提供了首个凸拼图的基准数据集。

Conclusion: 本研究显著扩大了计算上可处理的拼图类型，聚焦于凸分区这一多边形拼图的主要子集，并通过引入贪婪求解器和性能测量，为该领域提供了首个基准数据集。

Abstract: Jigsaw puzzle solving requires the rearrangement of unordered pieces into
their original pose in order to reconstruct a coherent whole, often an image,
and is known to be an intractable problem. While the possible impact of
automatic puzzle solvers can be disruptive in various application domains, most
of the literature has focused on developing solvers for square jigsaw puzzles,
severely limiting their practical use. In this work, we significantly expand
the types of puzzles handled computationally, focusing on what is known as
Convex Partitions, a major subset of polygonal puzzles whose pieces are convex.
We utilize both geometrical and pictorial compatibilities, introduce a greedy
solver, and report several performance measures next to the first benchmark
dataset of such puzzles.

</details>


### [41] [V-Thinker: Interactive Thinking with Images](https://arxiv.org/abs/2511.04460)
*Runqi Qiao,Qiuna Tan,Minghan Yang,Guanting Dong,Peiqing Yang,Shiqiang Lang,Enhui Wan,Xiaowan Wang,Yida Xu,Lan Yang,Chong Sun,Chen Li,Honggang Zhang*

Main category: cs.CV

TL;DR: V-Thinker是一个通用的多模态推理助手，通过强化学习增强视觉互动推理能力，实验结果显示其在多项任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在多模态模型中，深度整合图像交互与长期推理能力是一个长期存在的挑战。

Method: 通过端到端强化学习构建的多模态推理助手，包含数据演进飞轮和视觉渐进训练课程。

Result: V-Thinker通过优化数据集和训练流程，提升了图像互动推理的效果，显著超越了现有基线模型。

Conclusion: V-Thinker在视觉互动推理任务中表现优于其他强大的多模态模型，为图像互动推理应用的发展提供了宝贵的见解。

Abstract: Empowering Large Multimodal Models (LMMs) to deeply integrate image
interaction with long-horizon reasoning capabilities remains a long-standing
challenge in this field. Recent advances in vision-centric reasoning explore a
promising "Thinking with Images" paradigm for LMMs, marking a shift from
image-assisted reasoning to image-interactive thinking. While this milestone
enables models to focus on fine-grained image regions, progress remains
constrained by limited visual tool spaces and task-specific workflow designs.
To bridge this gap, we present V-Thinker, a general-purpose multimodal
reasoning assistant that enables interactive, vision-centric thinking through
end-to-end reinforcement learning. V-Thinker comprises two key components: (1)
a Data Evolution Flywheel that automatically synthesizes, evolves, and verifies
interactive reasoning datasets across three dimensions-diversity, quality, and
difficulty; and (2) a Visual Progressive Training Curriculum that first aligns
perception via point-level supervision, then integrates interactive reasoning
through a two-stage reinforcement learning framework. Furthermore, we introduce
VTBench, an expert-verified benchmark targeting vision-centric interactive
reasoning tasks. Extensive experiments demonstrate that V-Thinker consistently
outperforms strong LMM-based baselines in both general and interactive
reasoning scenarios, providing valuable insights for advancing
image-interactive reasoning applications.

</details>


### [42] [Landslide Hazard Mapping with Geospatial Foundation Models: Geographical Generalizability, Data Scarcity, and Band Adaptability](https://arxiv.org/abs/2511.04474)
*Wenwen Li,Sizhe Wang,Hyunho Lee,Chenyan Lu,Sujit Roy,Rahul Ramachandran,Chia-Yu Hsu*

Main category: cs.CV

TL;DR: 本研究通过三轴框架提出GeoFMs用于滑坡映射，模型在多次实验中展现出优越的性能和适应性，尽管仍面临计算成本和训练数据短缺的问题。


<details>
  <summary>Details</summary>
Motivation: 解决传统深度学习模型在不同传感器、区域或训练数据不足时的应用挑战。

Method: 提出了一个围绕传感器、标签和领域的三轴分析框架，并通过实验验证了Prithvi-EO-2.0模型的有效性。

Result: Prithvi-EO-2.0在多项任务中超越了特定任务的CNN和视觉变换器，以及其他GeoFMs，并展现出较强的适应性和泛化性。

Conclusion: 本研究表明，GeoFMs在滑坡映射中展现出优越性能，尤其是在面对不同传感器和地区条件时。

Abstract: Landslides cause severe damage to lives, infrastructure, and the environment,
making accurate and timely mapping essential for disaster preparedness and
response. However, conventional deep learning models often struggle when
applied across different sensors, regions, or under conditions of limited
training data. To address these challenges, we present a three-axis analytical
framework of sensor, label, and domain for adapting geospatial foundation
models (GeoFMs), focusing on Prithvi-EO-2.0 for landslide mapping. Through a
series of experiments, we show that it consistently outperforms task-specific
CNNs (U-Net, U-Net++), vision transformers (Segformer, SwinV2-B), and other
GeoFMs (TerraMind, SatMAE). The model, built on global pretraining,
self-supervision, and adaptable fine-tuning, proved resilient to spectral
variation, maintained accuracy under label scarcity, and generalized more
reliably across diverse datasets and geographic settings. Alongside these
strengths, we also highlight remaining challenges such as computational cost
and the limited availability of reusable AI-ready training data for landslide
research. Overall, our study positions GeoFMs as a step toward more robust and
scalable approaches for landslide risk reduction and environmental monitoring.

</details>


### [43] [THEval. Evaluation Framework for Talking Head Video Generation](https://arxiv.org/abs/2511.04520)
*Nabyl Quignon,Baptiste Chopin,Yaohui Wang,Antitza Dantcheva*

Main category: cs.CV

TL;DR: 本文提出了一种新的视频生成评估框架，包括8个指标，旨在提高评估的全面性和有效性，并在大量实验中展示了生成算法的优势与不足。


<details>
  <summary>Details</summary>
Motivation: 面对视频生成领域日益增长的需求，现有评估指标不足以全面衡量生成质量，促使我们设计新框架。

Method: 通过引入8个与质量、自然性和同步性相关的指标，建立评估标准，并对85,000个视频进行了广泛实验。

Result: 实验结果显示，许多生成算法在唇部同步方面表现出色，但在表现力和细节生成上存在挑战。

Conclusion: 本研究提出了一种新的评估框架，旨在改善生成视频的评估，以适应快速发展的生成技术。

Abstract: Video generation has achieved remarkable progress, with generated videos
increasingly resembling real ones. However, the rapid advance in generation has
outpaced the development of adequate evaluation metrics. Currently, the
assessment of talking head generation primarily relies on limited metrics,
evaluating general video quality, lip synchronization, and on conducting user
studies. Motivated by this, we propose a new evaluation framework comprising 8
metrics related to three dimensions (i) quality, (ii) naturalness, and (iii)
synchronization. In selecting the metrics, we place emphasis on efficiency, as
well as alignment with human preferences. Based on this considerations, we
streamline to analyze fine-grained dynamics of head, mouth, and eyebrows, as
well as face quality. Our extensive experiments on 85,000 videos generated by
17 state-of-the-art models suggest that while many algorithms excel in lip
synchronization, they face challenges with generating expressiveness and
artifact-free details. These videos were generated based on a novel real
dataset, that we have curated, in order to mitigate bias of training data. Our
proposed benchmark framework is aimed at evaluating the improvement of
generative methods. Original code, dataset and leaderboards will be publicly
released and regularly updated with new methods, in order to reflect progress
in the field.

</details>


### [44] [Learning from Single Timestamps: Complexity Estimation in Laparoscopic Cholecystectomy](https://arxiv.org/abs/2511.04525)
*Dimitrios Anastasiou,Santiago Barbarisi,Lucy Culshaw,Jayna Patel,Evangelos B. Mazomenos,Imanol Luengo,Danail Stoyanov*

Main category: cs.CV

TL;DR: STC-Net是一种新的框架，能在腹腔镜胆囊切除术中自动评估手术复杂性，表现出色，具有术后分析和培训的前景。


<details>
  <summary>Details</summary>
Motivation: 准确评估腹腔镜胆囊切除术中的手术复杂性对改善术后结果至关重要，特别是在严重炎症与手术时间延长和并发症风险增加相关的情况下。

Method: 介绍了STC-Net框架，基于弱时序监督进行单时间戳的复杂性评估，直接操作完整视频，结合了定位、窗口提议和评分模块。

Result: 在一个包含1859个LC视频的私人数据集上评估，STC-Net达到了62.11%的准确率和61.42%的F1-score，相较于非定位基线在两个指标上均超出10%。

Conclusion: STC-Net为从完整的LC视频中自动评估手术复杂性提供了一种可扩展和有效的方法，具有潜力用于术后分析和外科培训。

Abstract: Purpose: Accurate assessment of surgical complexity is essential in
Laparoscopic Cholecystectomy (LC), where severe inflammation is associated with
longer operative times and increased risk of postoperative complications. The
Parkland Grading Scale (PGS) provides a clinically validated framework for
stratifying inflammation severity; however, its automation in surgical videos
remains largely unexplored, particularly in realistic scenarios where complete
videos must be analyzed without prior manual curation. Methods: In this work,
we introduce STC-Net, a novel framework for SingleTimestamp-based Complexity
estimation in LC via the PGS, designed to operate under weak temporal
supervision. Unlike prior methods limited to static images or manually trimmed
clips, STC-Net operates directly on full videos. It jointly performs temporal
localization and grading through a localization, window proposal, and grading
module. We introduce a novel loss formulation combining hard and soft
localization objectives and background-aware grading supervision. Results:
Evaluated on a private dataset of 1,859 LC videos, STC-Net achieves an accuracy
of 62.11% and an F1-score of 61.42%, outperforming non-localized baselines by
over 10% in both metrics and highlighting the effectiveness of weak supervision
for surgical complexity assessment. Conclusion: STC-Net demonstrates a scalable
and effective approach for automated PGS-based surgical complexity estimation
from full LC videos, making it promising for post-operative analysis and
surgical training.

</details>


### [45] [UniSplat: Unified Spatio-Temporal Fusion via 3D Latent Scaffolds for Dynamic Driving Scene Reconstruction](https://arxiv.org/abs/2511.04595)
*Chen Shi,Shaoshuai Shi,Xiaoyang Lyu,Chunyang Liu,Kehua Sheng,Bo Zhang,Li Jiang*

Main category: cs.CV

TL;DR: UniSplat是一种新型的前馈3D重建框架，通过时空融合和高斯生成实现了动态场景的鲁棒重建，展现了在新视图合成中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在稀疏、无重叠的相机视角和复杂场景动态下面临挑战，亟需一种通用的、鲁棒的动态场景重建方式。

Method: UniSplat通过统一的潜在时空融合构建了一个3D潜在框架，集成了不同空间视图和时间帧的信息。

Result: 通过引入双分支解码器和高效融合机制，UniSplat成功生成了动态感知的高斯，并保持静态高斯的持久记忆，实现了完整且详细的重建。

Conclusion: UniSplat在新视图合成方面达到了最先进的性能，能够在摄像机覆盖之外的视点提供强健且高质量的渲染。

Abstract: Feed-forward 3D reconstruction for autonomous driving has advanced rapidly,
yet existing methods struggle with the joint challenges of sparse,
non-overlapping camera views and complex scene dynamics. We present UniSplat, a
general feed-forward framework that learns robust dynamic scene reconstruction
through unified latent spatio-temporal fusion. UniSplat constructs a 3D latent
scaffold, a structured representation that captures geometric and semantic
scene context by leveraging pretrained foundation models. To effectively
integrate information across spatial views and temporal frames, we introduce an
efficient fusion mechanism that operates directly within the 3D scaffold,
enabling consistent spatio-temporal alignment. To ensure complete and detailed
reconstructions, we design a dual-branch decoder that generates dynamic-aware
Gaussians from the fused scaffold by combining point-anchored refinement with
voxel-based generation, and maintain a persistent memory of static Gaussians to
enable streaming scene completion beyond current camera coverage. Extensive
experiments on real-world datasets demonstrate that UniSplat achieves
state-of-the-art performance in novel view synthesis, while providing robust
and high-quality renderings even for viewpoints outside the original camera
coverage.

</details>


### [46] [Building Trust in Virtual Immunohistochemistry: Automated Assessment of Image Quality](https://arxiv.org/abs/2511.04615)
*Tushar Kataria,Shikha Dubey,Mary Bronner,Jolanta Jedrzkiewicz,Ben J. Brintz,Shireen Y. Elhabian,Beatrice S. Knudsen*

Main category: cs.CV

TL;DR: 本研究提出了一种新的框架，通过对比真实与虚拟IHC生成的像素掩模，评估虚拟IHC模型的质量，发现传统图像指标与染色准确性相关性差，强调了通过WSI评估模型性能的重要性。


<details>
  <summary>Details</summary>
Motivation: 虽然深度学习模型可以生成虚拟IHC染色，但目前的质量评估方法主要基于图像忠实度，无法有效评价IHC染色的准确性，因此需要一种新的评估框架。

Method: 通过颜色解卷积生成像素掩模，并计算真实与虚拟IHC之间的染色准确性指标（Dice, IoU, Hausdorff距离），以评估图像质量。

Result: 研究表明，传统的图像忠实度指标（如FID, PSNR, SSIM）与染色准确性及病理学家评估相关性较差；配对模型（如PyramidPix2Pix和AdaptiveNCE）在染色准确性上表现最佳，而未配对的扩散和GAN模型在提供准确的IHC阳性像素标签方面则较不可靠。

Conclusion: 本研究为评估虚拟IHC模型的质量提供了一种自动化且基于准确性的框架，强调了在常规图像忠实度指标和病理学家评估下的染色准确性之间的差异。

Abstract: Deep learning models can generate virtual immunohistochemistry (IHC) stains
from hematoxylin and eosin (H&E) images, offering a scalable and low-cost
alternative to laboratory IHC. However, reliable evaluation of image quality
remains a challenge as current texture- and distribution-based metrics quantify
image fidelity rather than the accuracy of IHC staining. Here, we introduce an
automated and accuracy grounded framework to determine image quality across
sixteen paired or unpaired image translation models. Using color deconvolution,
we generate masks of pixels stained brown (i.e., IHC-positive) as predicted by
each virtual IHC model. We use the segmented masks of real and virtual IHC to
compute stain accuracy metrics (Dice, IoU, Hausdorff distance) that directly
quantify correct pixel - level labeling without needing expert manual
annotations. Our results demonstrate that conventional image fidelity metrics,
including Frechet Inception Distance (FID), peak signal-to-noise ratio (PSNR),
and structural similarity (SSIM), correlate poorly with stain accuracy and
pathologist assessment. Paired models such as PyramidPix2Pix and AdaptiveNCE
achieve the highest stain accuracy, whereas unpaired diffusion- and GAN-based
models are less reliable in providing accurate IHC positive pixel labels.
Moreover, whole-slide images (WSI) reveal performance declines that are
invisible in patch-based evaluations, emphasizing the need for WSI-level
benchmarks. Together, this framework defines a reproducible approach for
assessing the quality of virtual IHC models, a critical step to accelerate
translation towards routine use by pathologists.

</details>


### [47] [NovisVQ: A Streaming Convolutional Neural Network for No-Reference Opinion-Unaware Frame Quality Assessment](https://arxiv.org/abs/2511.04628)
*Kylie Cancilla,Alexander Moore,Amar Saini,Carmen Carrano*

Main category: cs.CV

TL;DR: 我们开发了一种无参考、无意见依赖的视频质量评估模型，通过时序卷积架构直接处理降级视频，成功提高了模型的表现和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的视频质量评估方法面临限制，尤其是全参考指标需要干净参考视频，而大多数无参考模型又依赖昂贵的人类意见标签，因此亟需一种新的方法来克服这些挑战。

Method: 本研究提出了一种基于流式处理的无参考视频质量评估模型，该模型利用DAVIS数据集中合成的降级，通过时序感知卷积架构直接从降级视频预测全参考指标（LPIPS、PSNR、SSIM），在推理时无需参考。

Result: 我们的流式处理方法超越了我们自己基于图像的基线，证明了时序建模在可扩展视频质量评估中的重要性，并且在与全参考指标的相关性方面，比广泛使用的BRISQUE模型表现更佳。

Conclusion: 我们提出的可扩展、无参考且不依赖人类意见的视频质量评估模型在处理多样化的降级方面超越了现有基于图像的基线，并与全参考指标相比表现出更高的相关性，验证了时序建模在实际视觉系统中的重要性。

Abstract: Video quality assessment (VQA) is vital for computer vision tasks, but
existing approaches face major limitations: full-reference (FR) metrics require
clean reference videos, and most no-reference (NR) models depend on training on
costly human opinion labels. Moreover, most opinion-unaware NR methods are
image-based, ignoring temporal context critical for video object detection. In
this work, we present a scalable, streaming-based VQA model that is both
no-reference and opinion-unaware. Our model leverages synthetic degradations of
the DAVIS dataset, training a temporal-aware convolutional architecture to
predict FR metrics (LPIPS , PSNR, SSIM) directly from degraded video, without
references at inference. We show that our streaming approach outperforms our
own image-based baseline by generalizing across diverse degradations,
underscoring the value of temporal modeling for scalable VQA in real-world
vision systems. Additionally, we demonstrate that our model achieves higher
correlation with full-reference metrics compared to BRISQUE, a widely-used
opinion-aware image quality assessment baseline, validating the effectiveness
of our temporal, opinion-unaware approach.

</details>


### [48] [Benchmark Designers Should "Train on the Test Set" to Expose Exploitable Non-Visual Shortcuts](https://arxiv.org/abs/2511.04655)
*Ellis Brown,Jihan Yang,Shusheng Yang,Rob Fergus,Saining Xie*

Main category: cs.CV

TL;DR: 本研究揭示了多模态基准中的非视觉偏差，并通过测试集压力测试和迭代偏差修剪程序提出了解决方案，改进了基准评估的可靠性。


<details>
  <summary>Details</summary>
Motivation: 为了确保多模态大型语言模型的有效评估，设计强健的基准至关重要，特别是当前存在通过非视觉线索来游戏基准的现象。

Method: 本研究采用测试集压力测试(TsT)方法对基准进行诊断，结合随机森林模型进行简便、可解释的审计，同时通过迭代偏差修剪(IBP)程序去除高偏差样本。

Result: 在对多个基准应用诊断和去偏处理后，发现了大量非视觉偏见，最终构建了去偏的VSI-Bench-Debiased基准，显示出更低的非视觉解决能力和更大的视觉盲点性能差距。

Conclusion: 通过实施测试集压力测试和迭代偏差修剪程序，研究揭示了多模态基准中的普遍非视觉偏见，并展示了去偏后的基准在解决视觉问题时的有效性和公平性。

Abstract: Robust benchmarks are crucial for evaluating Multimodal Large Language Models
(MLLMs). Yet we find that models can ace many multimodal benchmarks without
strong visual understanding, instead exploiting biases, linguistic priors, and
superficial patterns. This is especially problematic for vision-centric
benchmarks that are meant to require visual inputs. We adopt a diagnostic
principle for benchmark design: if a benchmark can be gamed, it will be.
Designers should therefore try to ``game'' their own benchmarks first, using
diagnostic and debiasing procedures to systematically identify and mitigate
non-visual biases. Effective diagnosis requires directly ``training on the test
set'' -- probing the released test set for its intrinsic, exploitable patterns.
  We operationalize this standard with two components. First, we diagnose
benchmark susceptibility using a ``Test-set Stress-Test'' (TsT) methodology.
Our primary diagnostic tool involves fine-tuning a powerful Large Language
Model via $k$-fold cross-validation on exclusively the non-visual, textual
inputs of the test set to reveal shortcut performance and assign each sample a
bias score $s(x)$. We complement this with a lightweight Random Forest-based
diagnostic operating on hand-crafted features for fast, interpretable auditing.
Second, we debias benchmarks by filtering high-bias samples using an
``Iterative Bias Pruning'' (IBP) procedure. Applying this framework to four
benchmarks -- VSI-Bench, CV-Bench, MMMU, and VideoMME -- we uncover pervasive
non-visual biases. As a case study, we apply our full framework to create
VSI-Bench-Debiased, demonstrating reduced non-visual solvability and a wider
vision-blind performance gap than the original.

</details>


### [49] [SIMS-V: Simulated Instruction-Tuning for Spatial Video Understanding](https://arxiv.org/abs/2511.04668)
*Ellis Brown,Arijit Ray,Ranjay Krishna,Ross Girshick,Rob Fergus,Saining Xie*

Main category: cs.CV

TL;DR: 通过SIMS-V框架生成高质量视频数据，优化了多模态语言模型的空间推理能力，实现了高效训练，并在真实世界任务中表现卓越。


<details>
  <summary>Details</summary>
Motivation: 当前多模态语言模型在时间和空间的空间推理能力不足，而获取带有准确空间注释的多样化真实世界视频数据存在瓶颈，因此需要一种新的数据生成方法。

Method: 提出SIMS-V框架，利用3D模拟器的特权信息生成视频训练数据，并通过系统性消融实验研究不同类型、混合和规模的问题对训练有效性的影响。

Result: 通过使用仅25K的模拟示例对7B参数的视频LLM进行微调，取得了超越72B基准的性能，并在真实世界的空间推理任务中显示出显著改进。

Conclusion: SIMS-V框架通过生成空间丰富的视频训练数据，提高了多模态语言模型在空间推理方面的能力，特别是在真实世界的迁移表现上。这种方法实现了高效的训练，并在多项空间推理基准测试中表现优异。

Abstract: Despite impressive high-level video comprehension, multimodal language models
struggle with spatial reasoning across time and space. While current spatial
training approaches rely on real-world video data, obtaining diverse footage
with precise spatial annotations remains a bottleneck. To alleviate this
bottleneck, we present SIMS-V -- a systematic data-generation framework that
leverages the privileged information of 3D simulators to create spatially-rich
video training data for multimodal language models. Using this framework, we
investigate which properties of simulated data drive effective real-world
transfer through systematic ablations of question types, mixes, and scales. We
identify a minimal set of three question categories (metric measurement,
perspective-dependent reasoning, and temporal tracking) that prove most
effective for developing transferable spatial intelligence, outperforming
comprehensive coverage despite using fewer question types. These insights
enable highly efficient training: our 7B-parameter video LLM fine-tuned on just
25K simulated examples outperforms the larger 72B baseline and achieves
competitive performance with proprietary models on rigorous real-world spatial
reasoning benchmarks. Our approach demonstrates robust generalization,
maintaining performance on general video understanding while showing
substantial improvements on embodied and real-world spatial tasks.

</details>


### [50] [Cambrian-S: Towards Spatial Supersensing in Video](https://arxiv.org/abs/2511.04670)
*Shusheng Yang,Jihan Yang,Pinzhi Huang,Ellis Brown,Zihao Yang,Yue Yu,Shengbang Tong,Zihan Zheng,Yifan Xu,Muhan Wang,Daohan Lu,Rob Fergus,Yann LeCun,Li Fei-Fei,Saining Xie*

Main category: cs.CV

TL;DR: 本研究提出了空间超感知的四个阶段，并提出VSI-SUPER基准来评估模型的能力，结果显示仅凭扩展规模不足以提升性能，需要预测感知的支持。


<details>
  <summary>Details</summary>
Motivation: 推动真正多模态智能的发展，转向更广泛的空间超感知范式。

Method: 提出了VSI-SUPER基准，包含VSR和VSC任务，以评估空间认知能力。

Result: 通过VSI-590K的数据扩展和Cambrian-S模型训练，在VSI-Bench上获得了超过30%的绝对提升。

Conclusion: 空间超感知需要的不仅是视觉能力，还需要模型具备预测和组织经验的能力。

Abstract: We argue that progress in true multimodal intelligence calls for a shift from
reactive, task-driven systems and brute-force long context towards a broader
paradigm of supersensing. We frame spatial supersensing as four stages beyond
linguistic-only understanding: semantic perception (naming what is seen),
streaming event cognition (maintaining memory across continuous experiences),
implicit 3D spatial cognition (inferring the world behind pixels), and
predictive world modeling (creating internal models that filter and organize
information). Current benchmarks largely test only the early stages, offering
narrow coverage of spatial cognition and rarely challenging models in ways that
require true world modeling. To drive progress in spatial supersensing, we
present VSI-SUPER, a two-part benchmark: VSR (long-horizon visual spatial
recall) and VSC (continual visual spatial counting). These tasks require
arbitrarily long video inputs yet are resistant to brute-force context
expansion. We then test data scaling limits by curating VSI-590K and training
Cambrian-S, achieving +30% absolute improvement on VSI-Bench without
sacrificing general capabilities. Yet performance on VSI-SUPER remains limited,
indicating that scale alone is insufficient for spatial supersensing. We
propose predictive sensing as a path forward, presenting a proof-of-concept in
which a self-supervised next-latent-frame predictor leverages surprise
(prediction error) to drive memory and event segmentation. On VSI-SUPER, this
approach substantially outperforms leading proprietary baselines, showing that
spatial supersensing requires models that not only see but also anticipate,
select, and organize experience.

</details>


### [51] [Tracking and Understanding Object Transformations](https://arxiv.org/abs/2511.04678)
*Yihong Sun,Xinyu Yang,Jennifer J. Sun,Bharath Hariharan*

Main category: cs.CV

TL;DR: 本研究提出了TubeletGraph系统，旨在跟踪经历状态转变的对象，提升对象动态理解的能力，并提供了新的基准数据集VOST-TAS。


<details>
  <summary>Details</summary>
Motivation: 研究对象在状态转变过程中的跟踪及描述，以提高对现实世界对象和动态变化的理解。

Method: 引入TubeletGraph，一个零-shot系统，通过识别潜在被忽视的轨迹并基于语义和邻近先验进行整合，最后生成描述观察到的转变的状态图。

Result: TubeletGraph在状态转变下实现了最先进的跟踪性能，并在时间定位和语义推理方面表现出良好的能力。

Conclusion: 本研究提出的TubeletGraph系统在处理对象状态转变的跟踪任务中表现出色，具有先进的性能和对复杂对象转变的理解能力。

Abstract: Real-world objects frequently undergo state transformations. From an apple
being cut into pieces to a butterfly emerging from its cocoon, tracking through
these changes is important for understanding real-world objects and dynamics.
However, existing methods often lose track of the target object after
transformation, due to significant changes in object appearance. To address
this limitation, we introduce the task of Track Any State: tracking objects
through transformations while detecting and describing state changes,
accompanied by a new benchmark dataset, VOST-TAS. To tackle this problem, we
present TubeletGraph, a zero-shot system that recovers missing objects after
transformation and maps out how object states are evolving over time.
TubeletGraph first identifies potentially overlooked tracks, and determines
whether they should be integrated based on semantic and proximity priors. Then,
it reasons about the added tracks and generates a state graph describing each
observed transformation. TubeletGraph achieves state-of-the-art tracking
performance under transformations, while demonstrating deeper understanding of
object transformations and promising capabilities in temporal grounding and
semantic reasoning for complex object transformations. Code, additional
results, and the benchmark dataset are available at
https://tubelet-graph.github.io.

</details>


### [52] [Carousel: A High-Resolution Dataset for Multi-Target Automatic Image Cropping](https://arxiv.org/abs/2511.04680)
*Rafe Loya,Andrew Hamara,Benjamin Estell,Benjamin Kilpatrick,Andrew C. Freeman*

Main category: cs.CV

TL;DR: 本文通过引入图像分割算法，致力于生成多个独特且具有美学吸引力的图像裁剪。


<details>
  <summary>Details</summary>
Motivation: 本研究探讨了现代社交媒体应用对多样化美观图像裁剪的需求，激发了该研究的动机。

Method: 引入了一种图像分割算法，并评估了几种单幅裁剪模型的效果。

Result: 创建了一个包含277张相关图像及其人类标签的数据集，并对多个裁剪模型的有效性进行了评估。

Conclusion: 本文提出了一种图像分割算法作为预处理步骤，评估了多种单幅裁剪模型的有效性，旨在生成多个具有美感的图像裁剪效果。

Abstract: Automatic image cropping is a method for maximizing the human-perceived
quality of cropped regions in photographs. Although several works have proposed
techniques for producing singular crops, little work has addressed the problem
of producing multiple, distinct crops with aesthetic appeal. In this paper, we
motivate the problem with a discussion on modern social media applications,
introduce a dataset of 277 relevant images and human labels, and evaluate the
efficacy of several single-crop models with an image partitioning algorithm as
a pre-processing step. The dataset is available at
https://github.com/RafeLoya/carousel.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [53] [Activation-Space Personality Steering: Hybrid Layer Selection for Stable Trait Control in LLMs](https://arxiv.org/abs/2511.03738)
*Pranav Bhandari,Nicolas Fay,Sanjeevan Selvaganapathy,Amitava Datta,Usman Naseem,Mehwish Nasim*

Main category: cs.CL

TL;DR: 本研究探讨了如何通过大五人格特质对大语言模型的输出进行个性化操控，提出了一种新颖的方法，旨在实现心理理论与模型实际应用之间的有效对接。


<details>
  <summary>Details</summary>
Motivation: 针对当前大语言模型在生成过程中无法可靠控制的个性化需求，寻求有效的行为操控机制，以填补文献中的重要空白。

Method: 提出了一种提取变换层隐藏状态激活的方法，应用低秩子空间发现技术，并识别不同模型架构中特定于特质的最佳层。

Result: 研究表明，个性特征占据一个低秩共享子空间，这些潜在结构可以通过细微扰动转化为有效的操控机制，而不会影响模型的流畅性、变化性和通用能力。

Conclusion: 本研究提出了一种新颖的管道，利用大五人格特质对大语言模型的行为进行操控，以实现个性化生成，探索了潜在结构与实际应用之间的有效关联。

Abstract: Large Language Models exhibit implicit personalities in their generation, but
reliably controlling or aligning these traits to meet specific needs remains an
open challenge. The need for effective mechanisms for behavioural manipulation
of the model during generation is a critical gap in the literature that needs
to be fulfilled. Personality-aware LLMs hold a promising direction towards this
objective. However, the relationship between these psychological constructs and
their representations within LLMs remains underexplored and requires further
investigation. Moreover, it is intriguing to understand and study the use of
these representations to steer the models' behaviour. We propose a novel
pipeline that extracts hidden state activations from transformer layers using
the Big Five Personality Traits (Openness, Conscientiousness, Extraversion,
Agreeableness and Neuroticism), which is a comprehensive and empirically
validated framework to model human personality applies low-rank subspace
discovery methods, and identifies trait-specific optimal layers across
different model architectures for robust injection. The resulting
personality-aligned directions are then operationalised through a flexible
steering framework with dynamic layer selection, enabling precise control of
trait expression in LLM outputs. Our findings reveal that personality traits
occupy a low-rank shared subspace, and that these latent structures can be
transformed into actionable mechanisms for effective steering through careful
perturbations without impacting the fluency, variance and general capabilities,
helping to bridge the gap between psychological theory and practical model
alignment.

</details>


### [54] [TextualVerifier: Verify TextGrad Step-by-Step](https://arxiv.org/abs/2511.03739)
*Eugenius Mario Situmorang,Adila Alfa Krisnadhi,Ari Wibisono*

Main category: cs.CL

TL;DR: TextualVerifier是一个自我验证框架，显著提高了TextGrad在文本优化中的推理有效性，开启了新的验证方向。


<details>
  <summary>Details</summary>
Motivation: 解决TextGrad在文本决策中缺乏自我验证机制的问题，以保证推理的有效性。

Method: 通过链式思维分解、变体生成、投票及共识聚合的四阶段工作流程，与TextGrad无缝集成。

Result: 在实验中，TextualVerifier在独立评估和集成评估中均显示出统计显著的改进，验证步骤有效性提高了29%，集成Loss函数后准确率提升2.2个百分点。

Conclusion: TextualVerifier提出了一种基于大型语言模型的自我验证框架，显著改善了TextGrad的推理有效性，推动了文本优化领域的验证研究。

Abstract: TextGrad is a novel approach to text-based automatic differentiation that
enables composite AI systems to perform optimization without explicit numerical
equations. However, it currently lacks self-verification mechanisms that ensure
reasoning validity in text-based decision making. This research introduces
TextualVerifier, a verification framework that leverages chain-of-thought
reasoning and majority voting with large language models to address this
verification gap. TextualVerifier implements a four-stage workflow:
chain-of-thought decomposition, variant generation, majority voting, and
consensus aggregation. It integrates non-invasively with TextGrad at both the
loss function and optimization result verification stages. Experimental
evaluation using the Gemini 1.5 Pro model is conducted in two phases: (1)
standalone evaluation on PRM800K, and (2) integrated evaluation with TextGrad
on GPQA-Diamond, MMLU-ML, and MMLU-CP benchmarks. Results show statistically
significant improvements (p < 0.001). In phase one, TextualVerifier improves
the validity of reasoning steps by 29 percent. In phase two, integration into
TextGrad loss function yields a 2.2 percentage point gain from 68.2 to 70.4
percent with a moderate overhead of 5.9 LLM calls on average. Further
evaluations of TextualVerifier versioning yield 8.08, 10.71, and 3.92
percentage point improvements on GPQA, MMLU-ML, and MMLU-CP respectively.
TextualVerifier thus presents the first self-verification framework for
TextGrad through LLM-based techniques without requiring numerical gradients,
enabling more reliable reasoning and opening new directions for verification in
text-based optimization.

</details>


### [55] [GRDD+: An Extended Greek Dialectal Dataset with Cross-Architecture Fine-tuning Evaluation](https://arxiv.org/abs/2511.03772)
*Stergios Chatzikyriakidis,Dimitris Papadakis,Sevasti-Ioanna Papaioannou,Erofili Psaltaki*

Main category: cs.CL

TL;DR: 本文介绍了扩展希腊方言数据集（GRDD+），并通过微调实验验证了其对语言模型效果的提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有希腊方言数据集样本量有限的问题，提供多样性丰富的训练数据，以促进语言模型在方言处理上的性能提高。

Method: 通过对现有GRDD数据集的补充与扩展，增加了来自克里特、塞浦路斯、庞提克和北希腊的新数据，以及六种新方言，构建了总词数达到6,374,939的方言数据集。

Result: 实验显示，经过微调的模型在处理方言数据方面取得了较好的效果，与当前前沿模型的表现进行了比较。

Conclusion: 我们提出的扩展希腊方言数据集（GRDD+）大幅提升了方言数据的规模与多样性，并在多个语言模型的微调实验中展示了其潜在价值。

Abstract: We present an extended Greek Dialectal Dataset (GRDD+) 1that complements the
existing GRDD dataset with more data from Cretan, Cypriot, Pontic and Northern
Greek, while we add six new varieties: Greco-Corsican, Griko (Southern Italian
Greek), Maniot, Heptanesian, Tsakonian, and Katharevusa Greek. The result is a
dataset with total size 6,374,939 words and 10 varieties. This is the first
dataset with such variation and size to date. We conduct a number of
fine-tuning experiments to see the effect of good quality dialectal data on a
number of LLMs. We fine-tune three model architectures (Llama-3-8B,
Llama-3.1-8B, Krikri-8B) and compare the results to frontier models
(Claude-3.7-Sonnet, Gemini-2.5, ChatGPT-5).

</details>


### [56] [PLLuM: A Family of Polish Large Language Models](https://arxiv.org/abs/2511.03823)
*Jan Kocoń,Maciej Piasecki,Arkadiusz Janz,Teddy Ferdinan,Łukasz Radliński,Bartłomiej Koptyra,Marcin Oleksy,Stanisław Woźniak,Paweł Walkowiak,Konrad Wojtasik,Julia Moska,Tomasz Naskręt,Bartosz Walkowiak,Mateusz Gniewkowski,Kamil Szyc,Dawid Motyka,Dawid Banach,Jonatan Dalasiński,Ewa Rudnicka,Bartłomiej Alberski,Tomasz Walkowiak,Aleksander Szczęsny,Maciej Markiewicz,Tomasz Bernaś,Hubert Mazur,Kamil Żyta,Mateusz Tykierko,Grzegorz Chodak,Tomasz Kajdanowicz,Przemysław Kazienko,Agnieszka Karlińska,Karolina Seweryn,Anna Kołos,Maciej Chrabąszcz,Katarzyna Lorenc,Aleksandra Krasnodębska,Artur Wilczek,Katarzyna Dziewulska,Paula Betscher,Zofia Cieślińska,Katarzyna Kowol,Daria Mikoś,Maciej Trzciński,Dawid Krutul,Marek Kozłowski,Sławomir Dadas,Rafał Poświata,Michał Perełkiewicz,Małgorzata Grębowiec,Maciej Kazuła,Marcin Białas,Roman Roszko,Danuta Roszko,Jurgita Vaičenonienė,Andrius Utka,Paweł Levchuk,Paweł Kowalski,Irena Prawdzic-Jankowska,Maciej Ogrodniczuk,Monika Borys,Anna Bulińska,Wiktoria Gumienna,Witold Kieraś,Dorota Komosińska,Katarzyna Krasnowska-Kieraś,Łukasz Kobyliński,Martyna Lewandowska,Marek Łaziński,Mikołaj Łątkowski,Dawid Mastalerz,Beata Milewicz,Agnieszka Anna Mykowiecka,Angelika Peljak-Łapińska,Sandra Penno,Zuzanna Przybysz,Michał Rudolf,Piotr Rybak,Karolina Saputa,Aleksandra Tomaszewska,Aleksander Wawer,Marcin Woliński,Joanna Wołoszyn,Alina Wróblewska,Bartosz Żuk,Filip Żarnecki,Konrad Kaczyński,Anna Cichosz,Zuzanna Deckert,Monika Garnys,Izabela Grabarczyk,Wojciech Janowski,Sylwia Karasińska,Aleksandra Kujawiak,Piotr Misztela,Maria Szymańska,Karolina Walkusz,Igor Siek,Jakub Kwiatkowski,Piotr Pęzik*

Main category: cs.CL

TL;DR: PLLuM是专为波兰语开发的开源语言模型，旨在提升波兰的人工智能技术和研究，包含先进的训练和治理机制。


<details>
  <summary>Details</summary>
Motivation: 针对大语言模型主要集中于英语的现状，开发一个高质量、透明且文化相关的波兰语模型以满足该需求。

Method: 构建一个新的1400亿标记的波兰文本语料库进行预训练，使用77k自定义指令数据集和10k偏好优化数据集，并应用了负责任的人工智能框架。

Result: PLLuM是专门为波兰语设计的最大的开源基础模型家族，并展示了其在公共管理中的实用性。

Conclusion: PLLuM旨在加强波兰的开放研究和自主人工智能技术，且模型在公共管理中的应用证明了其有效性。

Abstract: Large Language Models (LLMs) play a central role in modern artificial
intelligence, yet their development has been primarily focused on English,
resulting in limited support for other languages. We present PLLuM (Polish
Large Language Model), the largest open-source family of foundation models
tailored specifically for the Polish language. Developed by a consortium of
major Polish research institutions, PLLuM addresses the need for high-quality,
transparent, and culturally relevant language models beyond the English-centric
commercial landscape. We describe the development process, including the
construction of a new 140-billion-token Polish text corpus for pre-training, a
77k custom instructions dataset, and a 100k preference optimization dataset. A
key component is a Responsible AI framework that incorporates strict data
governance and a hybrid module for output correction and safety filtering. We
detail the models' architecture, training procedures, and alignment techniques
for both base and instruction-tuned variants, and demonstrate their utility in
a downstream task within public administration. By releasing these models
publicly, PLLuM aims to foster open research and strengthen sovereign AI
technologies in Poland.

</details>


### [57] [STARS: Segment-level Token Alignment with Rejection Sampling in Large Language Models](https://arxiv.org/abs/2511.03827)
*Mohammad Atif Quamar,Mohammad Areeb,Mikhail Kuznetsov,Muslum Ozgur Ozmen,Z. Berkay Celik*

Main category: cs.CL

TL;DR: STARS是一种新颖的解码时间算法，显著提升了大语言模型的生成效率和对齐质量，相比传统方法表现更优秀。


<details>
  <summary>Details</summary>
Motivation: 现有的方法如微调计算成本高且效果不佳，推理时的方法需要大量计算，引入STARS旨在提高效率与对齐质量。

Method: 提出了一种解码时间算法，使用迭代采样、评分和接受/拒绝固定大小的短令牌段，来指导模型生成。

Result: STARS在胜率上比监督微调提升了最高14.9个百分点，且在与强大的Best-of-N基准比拼中表现仍具竞争力。

Conclusion: STARS（分段令牌对齐与拒绝采样）在六种大语言模型中的表现优于传统的监督微调和直接偏好优化方法，提供了一种更高效、强大的对齐方案。

Abstract: Aligning large language models with human values is crucial for their safe
deployment; however, existing methods, such as fine-tuning, are computationally
expensive and suboptimal. In contrast, inference-time approaches like Best-of-N
sampling require practically infeasible computation to achieve optimal
alignment. We propose STARS: Segment-level Token Alignment with Rejection
Sampling, a decoding-time algorithm that steers model generation by iteratively
sampling, scoring, and rejecting/accepting short, fixed-size token segments.
This allows for early correction of the generation path, significantly
improving computational efficiency and boosting alignment quality. Across a
suite of six LLMs, we show that STARS outperforms Supervised Fine-Tuning (SFT)
by up to 14.9 percentage points and Direct Preference Optimization (DPO) by up
to 4.3 percentage points on win-rates, while remaining highly competitive with
strong Best-of-N baselines. Our work establishes granular, reward-guided
sampling as a generalizable, robust, and efficient alternative to traditional
fine-tuning and full-sequence ranking methods for aligning LLMs.

</details>


### [58] [Divide, Cache, Conquer: Dichotomic Prompting for Efficient Multi-Label LLM-Based Classification](https://arxiv.org/abs/2511.03830)
*Mikołaj Langner,Jan Eliasz,Ewa Rudnicka,Jan Kocoń*

Main category: cs.CL

TL;DR: 提出了一种高效的多标签文本分类方法，通过二分决策和模型蒸馏实现了在短文本推理中的效率提升。


<details>
  <summary>Details</summary>
Motivation: 旨在提高使用大型语言模型（LLMs）进行多标签文本分类的效率，尤其是在短文本推理中。

Method: 通过独立询问每个目标维度并使用前缀缓存机制来进行多标签文本分类的处理。

Result: 微调后的模型在训练期间见过的维度上，相较于零样本基准显著提高了性能。

Conclusion: 该方法通过将多标签分类任务转化为二分决策，结合模型蒸馏和缓存机制实现了显著的效率提升，且适用于多个领域。

Abstract: We introduce a method for efficient multi-label text classification with
large language models (LLMs), built on reformulating classification tasks as
sequences of dichotomic (yes/no) decisions. Instead of generating all labels in
a single structured response, each target dimension is queried independently,
which, combined with a prefix caching mechanism, yields substantial efficiency
gains for short-text inference without loss of accuracy. To demonstrate the
approach, we focus on affective text analysis, covering 24 dimensions including
emotions and sentiment. Using LLM-to-SLM distillation, a powerful annotator
model (DeepSeek-V3) provides multiple annotations per text, which are
aggregated to fine-tune smaller models (HerBERT-Large, CLARIN-1B, PLLuM-8B,
Gemma3-1B). The fine-tuned models show significant improvements over zero-shot
baselines, particularly on the dimensions seen during training. Our findings
suggest that decomposing multi-label classification into dichotomic queries,
combined with distillation and cache-aware inference, offers a scalable and
effective framework for LLM-based classification. While we validate the method
on affective states, the approach is general and applicable across domains.

</details>


### [59] [Evaluating Machine Translation Datasets for Low-Web Data Languages: A Gendered Lens](https://arxiv.org/abs/2511.03880)
*Hellina Hailu Nigatu,Bethelhem Yemane Mamo,Bontu Fufa Balcha,Debora Taye Tesfaye,Elbethel Daniel Zewdie,Ikram Behiru Nesiru,Jitu Ewnetu Hailu,Senait Mengesha Yayo*

Main category: cs.CL

TL;DR: 研究发现低资源语言的机器翻译数据集在性别表现上存在偏差，尤其对女性的有害描绘，强调数据质量的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着低资源语言在自然语言处理研究中的应用增加，有必要关注数据集的质量，以避免技术和内容上的偏差和伤害。

Method: 通过分析Afan Oromo、Amharic和Tigrinya三种低资源语言的机器翻译数据集，评估其性别表现及内容质量。

Result: 训练数据中政治和宗教文本的代表性很高，但基准数据集则集中在新闻、健康和体育领域，并且存在男性性别表现的偏斜以及对女性的有害描绘。

Conclusion: 这项研究表明，低资源语言的机器翻译数据集在性别表现上存在明显偏差，尤其是对女性产生了有害的刻画，强调了数据集的质量应优先于数量。

Abstract: As low-resourced languages are increasingly incorporated into NLP research,
there is an emphasis on collecting large-scale datasets. But in prioritizing
quantity over quality, we risk 1) building language technologies that perform
poorly for these languages and 2) producing harmful content that perpetuates
societal biases. In this paper, we investigate the quality of Machine
Translation (MT) datasets for three low-resourced languages--Afan Oromo,
Amharic, and Tigrinya, with a focus on the gender representation in the
datasets. Our findings demonstrate that while training data has a large
representation of political and religious domain text, benchmark datasets are
focused on news, health, and sports. We also found a large skew towards the
male gender--in names of persons, the grammatical gender of verbs, and in
stereotypical depictions in the datasets. Further, we found harmful and toxic
depictions against women, which were more prominent for the language with the
largest amount of data, underscoring that quantity does not guarantee quality.
We hope that our work inspires further inquiry into the datasets collected for
low-resourced languages and prompts early mitigation of harmful content.
WARNING: This paper contains discussion of NSFW content that some may find
disturbing.

</details>


### [60] [Computational Turing Test Reveals Systematic Differences Between Human and AI Language](https://arxiv.org/abs/2511.04195)
*Nicolò Pagan,Petter Törnberg,Christopher A. Bail,Anikó Hannák,Christopher Barrie*

Main category: cs.CL

TL;DR: 本文提出了一种新的计算图灵测试框架来验证大语言模型生成文本的现实性，并比较了不同模型和校准策略的效果，发现当前模型在模拟人类交流上仍存在重要限制。


<details>
  <summary>Details</summary>
Motivation: 为了评估大语言模型生成文本的现实性，并克服人类评判的局限性，提供可靠的验证工具。

Method: 引入计算图灵测试这一验证框架，结合聚合指标与可解释的语言特征；系统比较九个开放式权重的大语言模型及其五种校准策略。

Result: 发现即使经过校准，LLM的输出仍旧与人类文本有明显区别，尤其在情感语调及表达上，且人类相似度与语义保真度之间存在权衡。

Conclusion: 尽管经过校准，大语言模型的输出在情感语调和情感表达方面仍然明显区别于人类文本，表明当前模型在捕捉人类交流方面具有局限性。

Abstract: Large language models (LLMs) are increasingly used in the social sciences to
simulate human behavior, based on the assumption that they can generate
realistic, human-like text. Yet this assumption remains largely untested.
Existing validation efforts rely heavily on human-judgment-based evaluations --
testing whether humans can distinguish AI from human output -- despite evidence
that such judgments are blunt and unreliable. As a result, the field lacks
robust tools for assessing the realism of LLM-generated text or for calibrating
models to real-world data. This paper makes two contributions. First, we
introduce a computational Turing test: a validation framework that integrates
aggregate metrics (BERT-based detectability and semantic similarity) with
interpretable linguistic features (stylistic markers and topical patterns) to
assess how closely LLMs approximate human language within a given dataset.
Second, we systematically compare nine open-weight LLMs across five calibration
strategies -- including fine-tuning, stylistic prompting, and context retrieval
-- benchmarking their ability to reproduce user interactions on X (formerly
Twitter), Bluesky, and Reddit. Our findings challenge core assumptions in the
literature. Even after calibration, LLM outputs remain clearly distinguishable
from human text, particularly in affective tone and emotional expression.
Instruction-tuned models underperform their base counterparts, and scaling up
model size does not enhance human-likeness. Crucially, we identify a trade-off:
optimizing for human-likeness often comes at the cost of semantic fidelity, and
vice versa. These results provide a much-needed scalable framework for
validation and calibration in LLM simulations -- and offer a cautionary note
about their current limitations in capturing human communication.

</details>


### [61] [GRAD: Graph-Retrieved Adaptive Decoding for Hallucination Mitigation](https://arxiv.org/abs/2511.03900)
*Manh Nguyen,Sunil Gupta,Dai Do,Hung Le*

Main category: cs.CL

TL;DR: 提出GRAD方法，通过结合检索证据，显著提高LLMs的生成质量，有效降低幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 现有方法在幻觉减轻方面存在脆弱性和高成本，亟需一种可靠且高效的方法。

Method: GRAD通过构建稀疏的标记转移图，在解码时融合来自检索语料库的证据，以指导生成过程。

Result: GRAD在多项问答基准测试中表现优秀，超越了基线方法，显著提高了内在准确性，降低了幻觉率和提升了正确性。

Conclusion: GRAD方法有效地减少了生成过程中的幻觉现象，提高了生成的准确性和正确性，且具备轻量级、易部署的优势。

Abstract: Hallucination mitigation remains a persistent challenge for large language
models (LLMs), even as model scales grow. Existing approaches often rely on
external knowledge sources, such as structured databases or knowledge graphs,
accessed through prompting or retrieval. However, prompt-based grounding is
fragile and domain-sensitive, while symbolic knowledge integration incurs heavy
retrieval and formatting costs. Motivated by knowledge graphs, we introduce
Graph-Retrieved Adaptive Decoding (GRAD), a decoding-time method that grounds
generation in corpus-derived evidence without retraining. GRAD constructs a
sparse token transition graph by accumulating next-token logits across a small
retrieved corpus in a single forward pass. During decoding, graph-retrieved
logits are max-normalized and adaptively fused with model logits to favor
high-evidence continuations while preserving fluency. Across three models and a
range of question-answering benchmarks spanning intrinsic, extrinsic
hallucination, and factuality tasks, GRAD consistently surpasses baselines,
achieving up to 9.7$\%$ higher intrinsic accuracy, 8.6$\%$ lower hallucination
rates, and 6.9$\%$ greater correctness compared to greedy decoding, while
attaining the highest truth--informativeness product score among all methods.
GRAD offers a lightweight, plug-and-play alternative to contrastive decoding
and knowledge graph augmentation, demonstrating that statistical evidence from
corpus-level token transitions can effectively steer generation toward more
truthful and verifiable outputs.

</details>


### [62] [Context informs pragmatic interpretation in vision-language models](https://arxiv.org/abs/2511.03908)
*Alvin Wei Ming Tan,Ben Prystawski,Veronica Boyce,Michael C. Frank*

Main category: cs.CL

TL;DR: 本研究探讨了上下文对迭代参考游戏中人类和模型表现的影响，显示相关上下文显著提升模型的推理能力，但抽象例子的少量参考仍是挑战。


<details>
  <summary>Details</summary>
Motivation: 针对迭代参考游戏中智能体在多轮语言环境中进行上下文敏感的务实推理能力进行测试。

Method: 通过在多轮参考游戏中测试人类和视觉语言模型，分析上下文在任务表现中的影响。

Result: 在人类和模型的测试中，模型的初始表现低于人类，但随着相关上下文的引入，模型的表现显著提升。对于抽象参照的少量参考游戏，模型仍然面临挑战。

Conclusion: 尽管在缺乏相关上下文时，模型的表现低于人类，但在包含适当上下文时，模型的表现显著提高，显示了上下文对多轮语言环境中的推理能力的重要性。

Abstract: Iterated reference games - in which players repeatedly pick out novel
referents using language - present a test case for agents' ability to perform
context-sensitive pragmatic reasoning in multi-turn linguistic environments. We
tested humans and vision-language models on trials from iterated reference
games, varying the given context in terms of amount, order, and relevance.
Without relevant context, models were above chance but substantially worse than
humans. However, with relevant context, model performance increased
dramatically over trials. Few-shot reference games with abstract referents
remain a difficult task for machine learning models.

</details>


### [63] [The Human Flourishing Geographic Index: A County-Level Dataset for the United States, 2013--2023](https://arxiv.org/abs/2511.03915)
*Stefano M. Iacus,Devika Jain,Andrea Nasuto,Giuseppe Porro,Marcello Carammia,Andrea Vezzulli*

Main category: cs.CL

TL;DR: 本研究提出HFGI，通过分析推文数据量化人类繁荣，为社会福祉提供了新的优越分析工具。


<details>
  <summary>Details</summary>
Motivation: 量化人类繁荣这一多维构建体是理解社会福祉的重要途径，现有指标往往缺乏细致的空间和时间分辨率。

Method: 通过分析约26亿条地理定位的美国推文，利用经过微调的大型语言模型对表达进行分类，并设置48个指标。

Result: HFGI提供了县和州层面的繁荣相关话语的每月和每年指标，验证了指标与现有标准的预期相关性。

Conclusion: 该研究引入的HFGI为理解人类繁荣提供了新的多维度视角，能够在社会媒体上深入分析福祉及其变化。

Abstract: Quantifying human flourishing, a multidimensional construct including
happiness, health, purpose, virtue, relationships, and financial stability, is
critical for understanding societal well-being beyond economic indicators.
Existing measures often lack fine spatial and temporal resolution. Here we
introduce the Human Flourishing Geographic Index (HFGI), derived from analyzing
approximately 2.6 billion geolocated U.S. tweets (2013-2023) using fine-tuned
large language models to classify expressions across 48 indicators aligned with
Harvard's Global Flourishing Study framework plus attitudes towards migration
and perception of corruption. The dataset offers monthly and yearly county- and
state-level indicators of flourishing-related discourse, validated to confirm
that the measures accurately represent the underlying constructs and show
expected correlations with established indicators. This resource enables
multidisciplinary analyses of well-being, inequality, and social change at
unprecedented resolution, offering insights into the dynamics of human
flourishing as reflected in social media discourse across the United States
over the past decade.

</details>


### [64] [Direct Semantic Communication Between Large Language Models via Vector Translation](https://arxiv.org/abs/2511.03945)
*Fu-Chun Yang,Jason Eshraghian*

Main category: cs.CL

TL;DR: 本研究提出了一种通过向量翻译实现模型间直接语义交换的方法，提升了多智能体设置下的信息传递效率和计算稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体设置中信息传递的限制与计算开销，提升信息的转移效率。

Method: 通过双编码器翻译器，在Llama-2-7B和Mistral-7B-Instruct之间进行训练，实现向量翻译以直接交换语义。

Result: 平均余弦对齐度达到0.538，注入翻译向量以30%混合强度对目标模型生成进行引导，保持了计算的稳定性，并表明通用模型比指令调优变体具有更高的可转移表示能力。

Conclusion: 跨模型潜在通信是可行的，能够支持共享意义的协作AI系统。

Abstract: In multi-agent settings, such as debate, reflection, or tool-calling, large
language models (LLMs) pass messages as plain tokens, discarding most latent
semantics. This constrains information transfer and adds unnecessary
computational overhead. We form a latent bridge via vector translations, which
use learned mappings that enable direct semantic exchange between
representation spaces. A dual-encoder translator trained between Llama-2-7B and
Mistral-7B-Instruct attains an average cosine alignment of 0.538. Injecting the
translated vectors at 30 percent blending strength steers the target model's
generation without destabilizing logits. Bidirectional evaluation shows a
2.01:1 transfer asymmetry, indicating that general-purpose models yield more
transferable representations than instruction-tuned variants. This conservative
injection preserves computational stability while demonstrating that
cross-model latent communication is feasible, enabling collaborative AI systems
that share meaning rather than tokens.

</details>


### [65] [Abductive Inference in Retrieval-Augmented Language Models: Generating and Validating Missing Premises](https://arxiv.org/abs/2511.04020)
*Shiyin Lin*

Main category: cs.CL

TL;DR: 本研究提出了一种将诱导推理集成到RAG系统中的框架，以提高知识密集型任务的推理能力和结果的准确性。


<details>
  <summary>Details</summary>
Motivation: RAG管道在检索证据不完整时常常失效，因此需要一种新的方法来填补推理过程中的空白。

Method: 我们提出了一种框架，将诱导推理集成到增强检索的LLMs中，检测证据不足的情况，生成候选缺失前提，并通过一致性和合理性检查进行验证。

Result: 实验结果表明，我们的方法在诱导推理和多跳问答基准测试中提高了答案的准确性和推理的可信性。

Conclusion: 本研究强调了诱导推理是增强RAG系统的稳健性和可解释性的一个有前景的方向。

Abstract: Large Language Models (LLMs) enhanced with retrieval -- commonly referred to
as Retrieval-Augmented Generation (RAG) -- have demonstrated strong performance
in knowledge-intensive tasks. However, RAG pipelines often fail when retrieved
evidence is incomplete, leaving gaps in the reasoning process. In such cases,
\emph{abductive inference} -- the process of generating plausible missing
premises to explain observations -- offers a principled approach to bridge
these gaps. In this paper, we propose a framework that integrates abductive
inference into retrieval-augmented LLMs. Our method detects insufficient
evidence, generates candidate missing premises, and validates them through
consistency and plausibility checks. Experimental results on abductive
reasoning and multi-hop QA benchmarks show that our approach improves both
answer accuracy and reasoning faithfulness. This work highlights abductive
inference as a promising direction for enhancing the robustness and
explainability of RAG systems.

</details>


### [66] [T-FIX: Text-Based Explanations with Features Interpretable to eXperts](https://arxiv.org/abs/2511.04070)
*Shreya Havaldar,Helen Jin,Chaehyeon Kim,Anton Xue,Weiqiu You,Marco Gatti,Bhuvnesh Jain,Helen Qu,Daniel A Hashimoto,Amin Madani,Rajat Deo,Sameed Ahmed M. Khatana,Gary E. Weissman,Lyle Ungar,Eric Wong*

Main category: cs.CL

TL;DR: 本研究提出T-FIX基准，通过与领域专家合作评估LLM解释与专家判断的对齐程度，填补现有评估的不足。


<details>
  <summary>Details</summary>
Motivation: 在知识密集型场景中，用户期望不仅获得答案，还要得到有意义的解释，而现有的评估方案无法有效捕捉这一需求。

Method: 通过T-FIX基准，对七个知识密集型领域的LLM解释进行评估，并与领域专家合作，提出了新的指标。

Result: 开发了针对LLM解释与专家判断对齐的新评估指标，使解释更符合专家的直觉。

Conclusion: 提出了一种新的评估标准，即专家对齐，来评价LLM解释的有效性。

Abstract: As LLMs are deployed in knowledge-intensive settings (e.g., surgery,
astronomy, therapy), users expect not just answers, but also meaningful
explanations for those answers. In these settings, users are often domain
experts (e.g., doctors, astrophysicists, psychologists) who require
explanations that reflect expert-level reasoning. However, current evaluation
schemes primarily emphasize plausibility or internal faithfulness of the
explanation, which fail to capture whether the content of the explanation truly
aligns with expert intuition. We formalize expert alignment as a criterion for
evaluating explanations with T-FIX, a benchmark spanning seven
knowledge-intensive domains. In collaboration with domain experts, we develop
novel metrics to measure the alignment of LLM explanations with expert
judgment.

</details>


### [67] [Plan of Knowledge: Retrieval-Augmented Large Language Models for Temporal Knowledge Graph Question Answering](https://arxiv.org/abs/2511.04072)
*Xinying Qian,Ying Zhang,Yu Zhao,Baohang Zhou,Xuhui Sui,Xiaojie Yuan*

Main category: cs.CL

TL;DR: 本研究提出了PoK框架，以改善大型语言模型在时序知识图问答中的性能，通过知识规划和对比检索提升了推理能力。


<details>
  <summary>Details</summary>
Motivation: 为了克服当前大型语言模型在时序推理中的局限性，如幻觉和知识缺乏，优化其对时间敏感问题的处理能力。

Method: 提出了带有对比时序检索器的知识规划框架，分解复杂时序问题并构建时序知识库。

Result: PoK通过结构化规划和时序知识检索结合，提高了时序推理的可解释性和真实一致性，在四个基准数据集上的实验结果表明其有效性。

Conclusion: 该研究提出的PoK框架显著提高了时序知识图问答的检索精度和推理准确性，超越了现有的最先进方法。

Abstract: Temporal Knowledge Graph Question Answering (TKGQA) aims to answer
time-sensitive questions by leveraging factual information from Temporal
Knowledge Graphs (TKGs). While previous studies have employed pre-trained TKG
embeddings or graph neural networks to inject temporal knowledge, they fail to
fully understand the complex semantic information of time constraints.
Recently, Large Language Models (LLMs) have shown remarkable progress,
benefiting from their strong semantic understanding and reasoning
generalization capabilities. However, their temporal reasoning ability remains
limited. LLMs frequently suffer from hallucination and a lack of knowledge. To
address these limitations, we propose the Plan of Knowledge framework with a
contrastive temporal retriever, which is named PoK. Specifically, the proposed
Plan of Knowledge module decomposes a complex temporal question into a sequence
of sub-objectives from the pre-defined tools, serving as intermediate guidance
for reasoning exploration. In parallel, we construct a Temporal Knowledge Store
(TKS) with a contrastive retrieval framework, enabling the model to selectively
retrieve semantically and temporally aligned facts from TKGs. By combining
structured planning with temporal knowledge retrieval, PoK effectively enhances
the interpretability and factual consistency of temporal reasoning. Extensive
experiments on four benchmark TKGQA datasets demonstrate that PoK significantly
improves the retrieval precision and reasoning accuracy of LLMs, surpassing the
performance of the state-of-the-art TKGQA methods by 56.0% at most.

</details>


### [68] [The truth is no diaper: Human and AI-generated associations to emotional words](https://arxiv.org/abs/2511.04077)
*Špela Vintar,Jan Jona Javoršek*

Main category: cs.CL

TL;DR: 本研究比较了人类与大型语言模型在情感词汇上的联想行为，发现模型的联想更可预测且较不创造。


<details>
  <summary>Details</summary>
Motivation: 研究人类的词汇联想有助于理解内心的心理词典，而探讨语言模型的联想能力则可以揭示其在生成创造性语言时的机制。

Method: 通过对人类与大型语言模型在情感负载词汇上的联想行为进行比较，评估其联想的相似性与差异性。

Result: 人类与大型语言模型在情感负载词汇的联想上存在中等重叠，而语言模型的联想则普遍更可预测且缺乏创造性。

Conclusion: 大型语言模型的联想能力在情感负载词汇的使用上与人类的联想能力有一定重叠，但它们更倾向于放大情感色彩，且不如人类的联想更具创造性。

Abstract: Human word associations are a well-known method of gaining insight into the
internal mental lexicon, but the responses spontaneously offered by human
participants to word cues are not always predictable as they may be influenced
by personal experience, emotions or individual cognitive styles. The ability to
form associative links between seemingly unrelated concepts can be the driving
mechanisms of creativity. We perform a comparison of the associative behaviour
of humans compared to large language models. More specifically, we explore
associations to emotionally loaded words and try to determine whether large
language models generate associations in a similar way to humans. We find that
the overlap between humans and LLMs is moderate, but also that the associations
of LLMs tend to amplify the underlying emotional load of the stimulus, and that
they tend to be more predictable and less creative than human ones.

</details>


### [69] [Improving the Performance of Radiology Report De-identification with Large-Scale Training and Benchmarking Against Cloud Vendor Methods](https://arxiv.org/abs/2511.04079)
*Eva Prakash,Maayane Attias,Pierre Chambon,Justin Xu,Steven Truong,Jean-Benoit Delbrouck,Tessa Cook,Curtis Langlotz*

Main category: cs.CL

TL;DR: 本研究开发的一种基于变换器的PHI去标识化模型，在多样化医学影像数据集上训练，显著提升了性能，超越了现有的学术和商业系统，为临床文本处理设定了新标准。


<details>
  <summary>Details</summary>
Motivation: 提升影像学报告的自动化去标识化，通过广泛的训练数据集提升变换器模型的性能，并对照商业云供应商的PHI检测系统进行基准测试。

Method: 采用大规模标注医学影像数据集，结合创新的PHI分类和模型评估方法，对基于变换器的去标识化管道进行微调和性能评估。

Result: 模型在宾州（Penn）数据集上取得了0.973的F1分数，在斯坦福（Stanford）数据集上取得了0.996的F1分数，超越或保持了先前的最佳模型性能。合成PHI评估显示，准确检测率一致（总体F1: 0.959），并且模型在所有供应商系统中表现优异。

Conclusion: 基于变换器的去标识化模型在多样化影像学数据集上训练，超越了先前的学术和商业系统，在受保护健康信息（PHI）检测方面建立了新的基准，确保安全的临床文本处理。

Abstract: Objective: To enhance automated de-identification of radiology reports by
scaling transformer-based models through extensive training datasets and
benchmarking performance against commercial cloud vendor systems for protected
health information (PHI) detection. Materials and Methods: In this
retrospective study, we built upon a state-of-the-art, transformer-based, PHI
de-identification pipeline by fine-tuning on two large annotated radiology
corpora from Stanford University, encompassing chest X-ray, chest CT,
abdomen/pelvis CT, and brain MR reports and introducing an additional PHI
category (AGE) into the architecture. Model performance was evaluated on test
sets from Stanford and the University of Pennsylvania (Penn) for token-level
PHI detection. We further assessed (1) the stability of synthetic PHI
generation using a "hide-in-plain-sight" method and (2) performance against
commercial systems. Precision, recall, and F1 scores were computed across all
PHI categories. Results: Our model achieved overall F1 scores of 0.973 on the
Penn dataset and 0.996 on the Stanford dataset, outperforming or maintaining
the previous state-of-the-art model performance. Synthetic PHI evaluation
showed consistent detectability (overall F1: 0.959 [0.958-0.960]) across 50
independently de-identified Penn datasets. Our model outperformed all vendor
systems on synthetic Penn reports (overall F1: 0.960 vs. 0.632-0.754).
Discussion: Large-scale, multimodal training improved cross-institutional
generalization and robustness. Synthetic PHI generation preserved data utility
while ensuring privacy. Conclusion: A transformer-based de-identification model
trained on diverse radiology datasets outperforms prior academic and commercial
systems in PHI detection and establishes a new benchmark for secure clinical
text processing.

</details>


### [70] [A Characterization of List Language Identification in the Limit](https://arxiv.org/abs/2511.04103)
*Moses Charikar,Chirag Pabbaraju,Ambuj Tewari*

Main category: cs.CL

TL;DR: 本文研究了语言在极限下的$k$-列表识别问题，提供了语言集合的识别特征及速率分析。


<details>
  <summary>Details</summary>
Motivation: 受最近语言生成问题的积极结果启发，重新审视经典的语言识别问题。

Method: 基于递归的角卢因特征描述，提出了$k$-列表识别的精确特征。

Result: 确立了$k$-列表识别的语言集合特征，并根据输入流的统计特性建立识别速率结果。

Conclusion: 语言集合在极限下的$k$-列表识别是可行的，且可以以最佳指数速率识别。

Abstract: We study the problem of language identification in the limit, where given a
sequence of examples from a target language, the goal of the learner is to
output a sequence of guesses for the target language such that all the guesses
beyond some finite time are correct. Classical results of Gold showed that
language identification in the limit is impossible for essentially any
interesting collection of languages. Later, Angluin gave a precise
characterization of language collections for which this task is possible.
Motivated by recent positive results for the related problem of language
generation, we revisit the classic language identification problem in the
setting where the learner is given the additional power of producing a list of
$k$ guesses at each time step. The goal is to ensure that beyond some finite
time, one of the guesses is correct at each time step.
  We give an exact characterization of collections of languages that can be
$k$-list identified in the limit, based on a recursive version of Angluin's
characterization (for language identification with a list of size $1$). This
further leads to a conceptually appealing characterization: A language
collection can be $k$-list identified in the limit if and only if the
collection can be decomposed into $k$ collections of languages, each of which
can be identified in the limit (with a list of size $1$). We also use our
characterization to establish rates for list identification in the statistical
setting where the input is drawn as an i.i.d. stream from a distribution
supported on some language in the collection. Our results show that if a
collection is $k$-list identifiable in the limit, then the collection can be
$k$-list identified at an exponential rate, and this is best possible. On the
other hand, if a collection is not $k$-list identifiable in the limit, then it
cannot be $k$-list identified at any rate that goes to zero.

</details>


### [71] [Batch Prompting Suppresses Overthinking Reasoning Under Constraint: How Batch Prompting Suppresses Overthinking in Reasoning Models](https://arxiv.org/abs/2511.04108)
*Wenmo Qiu,Saurabh Srivastava*

Main category: cs.CL

TL;DR: 本研究展示了批处理在大型推理模型中的优势，不仅提升推理准确性，而且作为推理时的有效正则化手段，降低了推理成本。


<details>
  <summary>Details</summary>
Motivation: 探索批处理作为降低大型语言模型（LLMs）推理成本的策略，同时挖掘其潜在的正则化好处。

Method: 对13个不同基准进行了全面研究，观察批处理如何改善准确性并减少推理令牌的使用。

Result: 批处理提高了准确性，减少了推理令牌的使用，抑制了过度思考与重复自我纠正，并促进了更果断的回答，表现出在批处理推理中的集体效应。

Conclusion: 批处理不仅是提高吞吐量的优化方法，还是在推理时用于更高效和更可靠的LLM推理的强大正则化器。

Abstract: Recent work has explored batch prompting as a strategy to amortize inference
cost in large language models (LLMs). In this paper, we show that batching
offers an additional, underappreciated benefit: it regularizes model behavior
during multi-step reasoning for Large Reasoning Models (LRMs). We conduct a
comprehensive study across 13 diverse benchmarks and observe that batching
improves accuracy while substantially reducing reasoning token usage, often by
3x-5x. Through detailed behavioral analysis, we find that batching suppresses
overthinking, reduces hedging language (e.g., repetitive self-corrections), and
encourages more decisive answers. Surprisingly, we also observe emergent
collective effects in batched inference: models often generalize patterns from
earlier examples to solve harder ones in the same batch. These findings
position batching not just as a throughput optimization, but as a powerful
inference-time regularizer for more efficient and reliable LLM reasoning.

</details>


### [72] [RIDE: Difficulty Evolving Perturbation with Item Response Theory for Mathematical Reasoning](https://arxiv.org/abs/2511.04120)
*Xinyuan Li,Murong Xu,Wenbiao Tao,Hanlun Zhu,Yike Zhao,Jipeng Zhang,Yunshi Lan*

Main category: cs.CL

TL;DR: 本研究提出RIDE框架，利用项响应理论评估问题难度，通过对抗性重写生成更具挑战性的问题，并在实验中验证了其有效性和LLM的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前评估方法无法有效衡量数学推理能力的问题，提出了一种新的对抗性问题重写框架，从而提高了问题的难度和可比性。

Method: 通过使用35个大语言模型模拟学生，构建难度排序器，并利用强化学习引导问题重写模型，生成不同难度水平的数学问题变体。

Result: RIDE框架生成的扰动问题在竞争级数学基准测试中有效降低了高级LLM的表现，平均下降21.73%，显示了数学推理的有限稳健性。

Conclusion: 该研究提出的RIDE框架有效地评估和改进了大语言模型在数学推理方面的能力，揭示了其在真实推理能力上的局限性。

Abstract: Large language models (LLMs) achieve high performance on mathematical
reasoning, but these results can be inflated by training data leakage or
superficial pattern matching rather than genuine reasoning. To this end, an
adversarial perturbation-based evaluation is needed to measure true
mathematical reasoning ability. Current rule-based perturbation methods often
generate ill-posed questions and impede the systematic evaluation of question
difficulty and the evolution of benchmarks. To bridge this gap, we propose
RIDE, a novel adversarial question-rewriting framework that leverages Item
Response Theory (IRT) to rigorously measure question difficulty and to generate
intrinsically more challenging, well-posed variations of mathematical problems.
We employ 35 LLMs to simulate students and build a difficulty ranker from their
responses. This ranker provides a reward signal during reinforcement learning
and guides a question-rewriting model to reformulate existing questions across
difficulty levels. Applying RIDE to competition-level mathematical benchmarks
yields perturbed versions that degrade advanced LLM performance, with
experiments showing an average 21.73% drop across 26 models, thereby exposing
limited robustness in mathematical reasoning and confirming the validity of our
evaluation approach.

</details>


### [73] [CantoASR: Prosody-Aware ASR-LALM Collaboration for Low-Resource Cantonese](https://arxiv.org/abs/2511.04139)
*Dazhong Chen,Yi-Cheng Lin,Yuchen Huang,Ziwei Gong,Di Jiang,Zeying Xie,Yi R.,Fung*

Main category: cs.CL

TL;DR: CantoASR通过集成声学线索和大型音频语言模型推理，显著提高了低资源粤语的自动语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别(ASR)对语言可访问性至关重要，但由于标注数据有限、六种音调、音调沙沙和口音变异，低资源粤语的识别仍然面临挑战。

Method: 提出了CantoASR，一个协作的自动语音识别-大型音频语言模型错误校正框架，结合了强制对齐进行声学特征提取，经过LoRA微调的Whisper用于改善音调辨别，以及经过指令调优的Qwen-Audio用于意识到韵律的校正。

Result: 在自发粤语数据上的评估显示，相较于Whisper-Large-V3，CantoASR的字符错误率(CER)显著提高。

Conclusion: 集成声学线索与大型音频语言模型的推理提供了对低资源调音和方言自动语音识别的可扩展策略。

Abstract: Automatic speech recognition (ASR) is critical for language accessibility,
yet low-resource Cantonese remains challenging due to limited annotated data,
six lexical tones, tone sandhi, and accent variation. Existing ASR models, such
as Whisper, often suffer from high word error rates. Large audio-language
models (LALMs), in contrast, can leverage broader contextual reasoning but
still require explicit tonal and prosodic acoustic cues. We introduce CantoASR,
a collaborative ASR-LALM error correction framework that integrates forced
alignment for acoustic feature extraction, a LoRA-finetuned Whisper for
improved tone discrimination, and an instruction-tuned Qwen-Audio for
prosody-aware correction. Evaluations on spontaneous Cantonese data show
substantial CER gains over Whisper-Large-V3. These findings suggest that
integrating acoustic cues with LALM reasoning provides a scalable strategy for
low-resource tonal and dialectal ASR.

</details>


### [74] [Trustworthy LLM-Mediated Communication: Evaluating Information Fidelity in LLM as a Communicator (LAAC) Framework in Multiple Application Domains](https://arxiv.org/abs/2511.04184)
*Mohammed Musthafa Rafi,Adarsh Krishnamurthy,Aditya Balu*

Main category: cs.CL

TL;DR: LAAC提议将LLM作为智能沟通中介，以提升信息真实性，但在高风险场合的信任性需求尚未满足。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成内容的激增，出现了扭曲的沟通体系，LAAC旨在作为智能沟通的中介，提升信息的真实性与可交换性。

Method: 通过控制实验对LAAC在不同沟通场景中的信任维度进行系统评估。

Result: 初步研究结果表明，LAAC在高风险沟通场景中的使用存在可量化的信任差距。

Conclusion: LAAC在沟通中与信任性需求的评估揭示了在高风险沟通场景中可靠使用LLM的挑战。

Abstract: The proliferation of AI-generated content has created an absurd communication
theater where senders use LLMs to inflate simple ideas into verbose content,
recipients use LLMs to compress them back into summaries, and as a consequence
neither party engage with authentic content. LAAC (LLM as a Communicator)
proposes a paradigm shift - positioning LLMs as intelligent communication
intermediaries that capture the sender's intent through structured dialogue and
facilitate genuine knowledge exchange with recipients. Rather than perpetuating
cycles of AI-generated inflation and compression, LAAC enables authentic
communication across diverse contexts including academic papers, proposals,
professional emails, and cross-platform content generation. However, deploying
LLMs as trusted communication intermediaries raises critical questions about
information fidelity, consistency, and reliability. This position paper
systematically evaluates the trustworthiness requirements for LAAC's deployment
across multiple communication domains. We investigate three fundamental
dimensions: (1) Information Capture Fidelity - accuracy of intent extraction
during sender interviews across different communication types, (2)
Reproducibility - consistency of structured knowledge across multiple
interaction instances, and (3) Query Response Integrity - reliability of
recipient-facing responses without hallucination, source conflation, or
fabrication. Through controlled experiments spanning multiple LAAC use cases,
we assess these trust dimensions using LAAC's multi-agent architecture.
Preliminary findings reveal measurable trust gaps that must be addressed before
LAAC can be reliably deployed in high-stakes communication scenarios.

</details>


### [75] [LLM-as-a-Judge is Bad, Based on AI Attempting the Exam Qualifying for the Member of the Polish National Board of Appeal](https://arxiv.org/abs/2511.04205)
*Michał Karp,Anna Kubaszewska,Magdalena Król,Robert Król,Aleksander Smywiński-Pohl,Mateusz Szymański,Witold Wydmański*

Main category: cs.CL

TL;DR: 研究评估大型语言模型在波兰资格考试中的表现，发现其在知识测试中表现良好，但无法通过实际书面部分，且存在明显局限性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型是否能够通过官方资格考试，探讨其在法律领域潜在应用。

Method: 实证评估大型语言模型在波兰国家上诉委员会资格考试中的表现，包括考试结构和信息检索与提取流程的描述，使用多个LLM进行测试。

Result: 尽管在知识测试中取得令人满意的分数，但在实际书面部分没有达到及格线，且与官方评审委员会的判断存在偏差。

Conclusion: 当前大型语言模型尚无法替代人类法官或独立考官在波兰公共采购裁决中的作用。

Abstract: This study provides an empirical assessment of whether current large language
models (LLMs) can pass the official qualifying examination for membership in
Poland's National Appeal Chamber (Krajowa Izba Odwo{\l}awcza). The authors
examine two related ideas: using LLM as actual exam candidates and applying the
'LLM-as-a-judge' approach, in which model-generated answers are automatically
evaluated by other models. The paper describes the structure of the exam, which
includes a multiple-choice knowledge test on public procurement law and a
written judgment, and presents the hybrid information recovery and extraction
pipeline built to support the models. Several LLMs (including GPT-4.1, Claude 4
Sonnet and Bielik-11B-v2.6) were tested in closed-book and various
Retrieval-Augmented Generation settings. The results show that although the
models achieved satisfactory scores in the knowledge test, none met the passing
threshold in the practical written part, and the evaluations of the
'LLM-as-a-judge' often diverged from the judgments of the official examining
committee. The authors highlight key limitations: susceptibility to
hallucinations, incorrect citation of legal provisions, weaknesses in logical
argumentation, and the need for close collaboration between legal experts and
technical teams. The findings indicate that, despite rapid technological
progress, current LLMs cannot yet replace human judges or independent examiners
in Polish public procurement adjudication.

</details>


### [76] [REMIND: Input Loss Landscapes Reveal Residual Memorization in Post-Unlearning LLMs](https://arxiv.org/abs/2511.04228)
*Liran Cohen,Yaniv Nemcovesky,Avi Mendelson*

Main category: cs.CL

TL;DR: 本研究提出了REMIND评估遗忘效果，提供了对记忆和遗忘的新视角，能有效检测未学习数据的影响。


<details>
  <summary>Details</summary>
Motivation: 机器遗忘对于确保隐私、安全和合规性至关重要，因此评估模型是否真正遗忘目标数据至关重要。

Method: REMIND通过分析模型在小输入变化下的损失，检测未学习数据细微的剩余影响，并判断数据是否已被有效遗忘。

Result: REMIND在相似的约束下优于现有方法，展现出对不同模型、数据集和意译输入的鲁棒性。

Conclusion: REMIND为评估语言模型中的遗忘效果提供了一个可靠的框架，并提出了对记忆和遗忘的新视角。

Abstract: Machine unlearning aims to remove the influence of specific training data
from a model without requiring full retraining. This capability is crucial for
ensuring privacy, safety, and regulatory compliance. Therefore, verifying
whether a model has truly forgotten target data is essential for maintaining
reliability and trustworthiness. However, existing evaluation methods often
assess forgetting at the level of individual inputs. This approach may overlook
residual influence present in semantically similar examples. Such influence can
compromise privacy and lead to indirect information leakage. We propose REMIND
(Residual Memorization In Neighborhood Dynamics), a novel evaluation method
aiming to detect the subtle remaining influence of unlearned data and classify
whether the data has been effectively forgotten. REMIND analyzes the model's
loss over small input variations and reveals patterns unnoticed by single-point
evaluations. We show that unlearned data yield flatter, less steep loss
landscapes, while retained or unrelated data exhibit sharper, more volatile
patterns. REMIND requires only query-based access, outperforms existing methods
under similar constraints, and demonstrates robustness across different models,
datasets, and paraphrased inputs, making it practical for real-world
deployment. By providing a more sensitive and interpretable measure of
unlearning effectiveness, REMIND provides a reliable framework to assess
unlearning in language models. As a result, REMIND offers a novel perspective
on memorization and unlearning.

</details>


### [77] [Reusing Pre-Training Data at Test Time is a Compute Multiplier](https://arxiv.org/abs/2511.04234)
*Alex Fang,Thomas Voice,Ruoming Pang,Ludwig Schmidt,Tom Gunter*

Main category: cs.CL

TL;DR: 本研究表明，当前预训练方法未有效利用数据集信息，通过检索增强生成可显著提高模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 了解预训练过程如何从数据中提取思想和知识的效率。

Method: 使用检索增强生成和测试时计算量化预训练过程在知识提取方面的有效性。

Result: 通过检索标准和开放源代码数据集，显著提高了MMLU、Math-500和SimpleQA的准确率，并持续通过去污染处理。

Conclusion: 当前的预训练方法未能充分利用现有预训练数据集中的信息，仍有很大的进步空间。

Abstract: Large language models learn from their vast pre-training corpora, gaining the
ability to solve an ever increasing variety of tasks; yet although researchers
work to improve these datasets, there is little effort to understand how
efficient the pre-training apparatus is at extracting ideas and knowledge from
the data. In this work, we use retrieval augmented generation along with
test-time compute as a way to quantify how much dataset value was left behind
by the process of pre-training, and how this changes across scale. We
demonstrate that pre-training then retrieving from standard and largely
open-sourced datasets results in significant accuracy gains in MMLU, Math-500,
and SimpleQA, which persist through decontamination. For MMLU we observe that
retrieval acts as a ~5x compute multiplier versus pre-training alone. We show
that these results can be further improved by leveraging additional compute at
test time to parse the retrieved context, demonstrating a 10 percentage point
improvement on MMLU for the public LLaMA 3.1 8B model. Overall, our results
suggest that today's pre-training methods do not make full use of the
information in existing pre-training datasets, leaving significant room for
progress.

</details>


### [78] [Efficient Topic Extraction via Graph-Based Labeling: A Lightweight Alternative to Deep Models](https://arxiv.org/abs/2511.04248)
*Salma Mekaooui,Hiba Sofyan,Imane Amaaz,Imane Benchrif,Arsalane Zarghili,Ilham Chaker,Nikola S. Nikolov*

Main category: cs.CL

TL;DR: 本论文提出了一种基于图的主题标记方法，通过丰富词汇和探索词之间的关系，提供了计算效率高且具有可解释性的主题标记。


<details>
  <summary>Details</summary>
Motivation: 随着非结构化文本数据的快速增长，提取文本主题变得至关重要，而现有方法通常依赖于计算成本高的方法。

Method: 提出了一种基于图的主题标记方法，通过丰富的语义相关词和探索词之间的关系来为主题分配有意义的标签。

Result: 该方法在两个不同数据集上的比较研究中，表现出比传统基准更好的结果，并与ChatGPT-3.5的结果相当，同时保持了较高的计算效率。

Conclusion: 我们的方法在BERTScore和余弦相似度方面 consistently outperform了传统基准，同时在计算效率上也保持了较高水平。

Abstract: Extracting topics from text has become an essential task, especially with the
rapid growth of unstructured textual data. Most existing works rely on highly
computational methods to address this challenge. In this paper, we argue that
probabilistic and statistical approaches, such as topic modeling (TM), can
offer effective alternatives that require fewer computational resources. TM is
a statistical method that automatically discovers topics in large collections
of unlabeled text; however, it produces topics as distributions of
representative words, which often lack clear interpretability. Our objective is
to perform topic labeling by assigning meaningful labels to these sets of
words. To achieve this without relying on computationally expensive models, we
propose a graph-based approach that not only enriches topic words with
semantically related terms but also explores the relationships among them. By
analyzing these connections within the graph, we derive suitable labels that
accurately capture each topic's meaning. We present a comparative study between
our proposed method and several benchmarks, including ChatGPT-3.5, across two
different datasets. Our method achieved consistently better results than
traditional benchmarks in terms of BERTScore and cosine similarity and produced
results comparable to ChatGPT-3.5, while remaining computationally efficient.
Finally, we discuss future directions for topic labeling and highlight
potential research avenues for enhancing interpretability and automation.

</details>


### [79] [SSPO: Subsentence-level Policy Optimization](https://arxiv.org/abs/2511.04256)
*Kun Yang,Zikang chen,Yanmeng Wang,Zhigen Li*

Main category: cs.CL

TL;DR: 本论文提出SSPO方法，通过句子级重要性比率提高了大语言模型的推理能力，克服了现有算法的问题，取得了优异的实验结果。


<details>
  <summary>Details</summary>
Motivation: 探讨RLVR算法中存在的GRPO和GSPO不稳定性及数据利用不足的问题，提出一种新的方法以改善模型的推理能力。

Method: 提出了SSPO，通过句子级重要性比率来优化策略，结合了GRPO和GSPO的优点，避免了训练崩溃和高方差，同时防止整个响应标记被丢弃。

Result: SSPO在模型训练中表现优秀，减少了高方差和训练噪声的问题，并在多个数据集上取得了领先的性能。

Conclusion: SSPO方法在五个数据集上取得平均得分46.57，优于GRPO和GSPO，展现了其在利用生成数据方面的有效性。

Abstract: As a significant part of post-training of the Large Language Models (LLMs),
Reinforcement Learning from Verifiable Reward (RLVR) has greatly improved LLMs'
reasoning skills. However, some RLVR algorithms, such as GRPO (Group Relative
Policy Optimization) and GSPO (Group Sequence Policy Optimization), are
observed to suffer from unstable policy updates and low usage of sampling data,
respectively. The importance ratio of GRPO is calculated at the token level,
which focuses more on optimizing a single token. This will be easily affected
by outliers, leading to model training collapse. GSPO proposed the calculation
of the response level importance ratio, which solves the problem of high
variance and training noise accumulation in the calculation of the GRPO
importance ratio. However, since all the response tokens share a common
importance ratio, extreme values can easily raise or lower the overall mean,
leading to the entire response being mistakenly discarded, resulting in a
decrease in the utilization of sampled data. This paper introduces SSPO, which
applies sentence-level importance ratio, taking the balance between GRPO and
GSPO. SSPO not only avoids training collapse and high variance, but also
prevents the whole response tokens from being abandoned by the clipping
mechanism. Furthermore, we apply sentence entropy to PPO-CLIP to steadily
adjust the clipping bounds, encouraging high-entropy tokens to explore and
narrow the clipping range of low-entropy tokens. In particular, SSPO achieves
an average score of 46.57 across five datasets, surpassing GRPO (43.01) and
GSPO (44.42), and wins state-of-the-art performance on three datasets. These
results highlight SSPO's effectiveness in leveraging generated data by taking
the essence of GSPO but rejecting its shortcomings.

</details>


### [80] [Dynamic Jointly Batch Selection for Data Efficient Machine Translation Fine-Tuning](https://arxiv.org/abs/2511.04406)
*Mohammad Amin Ghanizadeh,Mohammad Javad Dousti*

Main category: cs.CL

TL;DR: 本论文提出了一种新的数据选择方法，通过结合学习模型与参考模型，优化机器翻译系统的训练过程，提高了数据效率和翻译性能。


<details>
  <summary>Details</summary>
Motivation: 改善机器翻译模型性能的关键在于数据质量和有效选择，旨在实现更稳健可靠的翻译系统。

Method: 提出了一种数据选择方法，结合学习模型和预训练参考模型，通过可学习性评分评估数据点的效用，采用批量选择策略优化训练过程。

Result: 在多语言对（如英语到波斯语）上的实验显示，该方法在数据效率上可实现多达五倍的提升，并在计算效率和泛化能力上优于随机选择方法。

Conclusion: 该方法在机器翻译任务中能够显著提高数据效率和翻译性能。

Abstract: Data quality and its effective selection are fundamental to improving the
performance of machine translation models, serving as cornerstones for
achieving robust and reliable translation systems. This paper presents a data
selection methodology specifically designed for fine-tuning machine translation
systems, which leverages the synergy between a learner model and a pre-trained
reference model to enhance overall training effectiveness. By defining a
learnability score, our approach systematically evaluates the utility of data
points for training, ensuring that only the most relevant and impactful
examples contribute to the fine-tuning process. Furthermore, our method employs
a batch selection strategy which considers interdependencies among data points,
optimizing the efficiency of the training process while maintaining a focus on
data relevance. Experiments on English to Persian and several other language
pairs using an mBART model fine-tuned on the CCMatrix dataset demonstrate that
our method can achieve up to a fivefold improvement in data efficiency compared
to an iid baseline. Experimental results indicate that our approach improves
computational efficiency by 24 when utilizing cached embeddings, as it requires
fewer training data points. Additionally, it enhances generalization, resulting
in superior translation performance compared to random selection method.

</details>


### [81] [If I Could Turn Back Time: Temporal Reframing as a Historical Reasoning Task for LLMs](https://arxiv.org/abs/2511.04432)
*Lars Bungum,Charles Yijia Huang,Abeer Kashar*

Main category: cs.CL

TL;DR: 本研究评估了大语言模型在1940年背景下的时间推理能力，发现英语提问效果优于挪威语，而更大的模型表现更佳。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型在特定历史时间背景下处理问题的能力，以及不同语言对其表现的影响。

Method: 使用1940年的挪威书籍中的琐事问题来测试LLMs的时间推理能力，评估方法为LLM作为评分者，并由母语者进行采样检查。

Result: 接受英语提问时，LLM的表现优于挪威语提问，同时较大的LLM模型在测试中表现更好。

Conclusion: LLMs show variable success in temporal reasoning, with English prompts performing better than Norwegian, and larger models yielding improved results.

Abstract: In this study, we experiment with the ability of LLMs to do temporal
reasoning. Using a Norwegian book from 1940 containing trivia questions, we
prompt the LLMs to answer the questions as if it were 1940. We also pose the
questions in both English and Norwegian. Correct answers are often presented as
sentences, and grading is done by means of LLM-as-judge, with sampled checks by
a native speaker. Prompting in English consistently gave better results than in
Norwegian, an unexpected result. In contrast, using larger LLMs improved
results. We tested the DeepSeek-R1, Gemma3, Qwen3, and Llama3.1 model families,
and also the largest available LLM especially crafted for Norwegian.

</details>


### [82] [Probabilistic Textual Time Series Depression Detection](https://arxiv.org/abs/2511.04476)
*Fabian Schmidt,Seyedehmoniba Ravan,Vladimir Vlassov*

Main category: cs.CL

TL;DR: PTTSD是一个新的框架，能有效预测抑郁症严重性，提供不确定性估计，具备良好的临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 准确和可解释的抑郁症严重性预测对临床决策支持至关重要，但现有模型缺乏不确定性估计和时间建模。

Method: PTTSD框架结合了双向LSTM、自注意力机制和残差连接，并通过负对数似然训练高斯或Student-t输出头，既有序列到序列的变种，又有序列到单一输出的变种。

Result: 在E-DAIC和DAIC-WOZ数据集上评估，PTTSD模型在文本系统中达到了最先进的性能，并生成了良好校准的预测区间。

Conclusion: PTTSD模型在文本预测抑郁症严重性方面表现出色，具有良好的不确定性估计和时间建模能力，对临床决策支持具有重要意义。

Abstract: Accurate and interpretable predictions of depression severity are essential
for clinical decision support, yet existing models often lack uncertainty
estimates and temporal modeling. We propose PTTSD, a Probabilistic Textual Time
Series Depression Detection framework that predicts PHQ-8 scores from
utterance-level clinical interviews while modeling uncertainty over time. PTTSD
includes sequence-to-sequence and sequence-to-one variants, both combining
bidirectional LSTMs, self-attention, and residual connections with Gaussian or
Student-t output heads trained via negative log-likelihood. Evaluated on E-DAIC
and DAIC-WOZ, PTTSD achieves state-of-the-art performance among text-only
systems (e.g., MAE = 3.85 on E-DAIC, 3.55 on DAIC) and produces well-calibrated
prediction intervals. Ablations confirm the value of attention and
probabilistic modeling, while comparisons with MentalBERT establish generality.
A three-part calibration analysis and qualitative case studies further
highlight the interpretability and clinical relevance of uncertainty-aware
forecasting.

</details>


### [83] [ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding in Thai](https://arxiv.org/abs/2511.04479)
*Surapon Nonesung,Teetouch Jaknamon,Sirinya Chaiophat,Natapong Nitarach,Chanakan Wittayasakpan,Warit Sirichotedumrong,Adisai Na-Thalang,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: ThaiOCRBench是第一个评估泰语视觉语言模型的基准，揭示了现有模型在泰语文档理解方面的不足，并提供改进建议。


<details>
  <summary>Details</summary>
Motivation: 应对现有多模态模型主要集中在高资源语言的问题，为泰语文本丰富的视觉理解任务提供解决方案。

Method: 通过创建一个包含2808个样本的多样化数据集，并进行零-shot评估来比较各种前沿视觉语言模型的表现。

Result: 在评估中，专有模型的表现优于开源模型，尤其是在精细文本识别和手写内容提取任务中表现最差，显示出明显的性能差距。

Conclusion: ThaiOCRBench是评估泰语文档理解的标准化工具，揭示了现有模型的挑战和不足，尤其是在低资源环境下的表现。

Abstract: We present ThaiOCRBench, the first comprehensive benchmark for evaluating
vision-language models (VLMs) on Thai text-rich visual understanding tasks.
Despite recent progress in multimodal modeling, existing benchmarks
predominantly focus on high-resource languages, leaving Thai underrepresented,
especially in tasks requiring document structure understanding. ThaiOCRBench
addresses this gap by offering a diverse, human-annotated dataset comprising
2,808 samples across 13 task categories. We evaluate a wide range of
state-of-the-art VLMs in a zero-shot setting, spanning both proprietary and
open-source systems. Results show a significant performance gap, with
proprietary models (e.g., Gemini 2.5 Pro) outperforming open-source
counterparts. Notably, fine-grained text recognition and handwritten content
extraction exhibit the steepest performance drops among open-source models.
Through detailed error analysis, we identify key challenges such as language
bias, structural mismatch, and hallucinated content. ThaiOCRBench provides a
standardized framework for assessing VLMs in low-resource, script-complex
settings, and provides actionable insights for improving Thai-language document
understanding.

</details>


### [84] [RUST-BENCH: Benchmarking LLM Reasoning on Unstructured Text within Structured Tables](https://arxiv.org/abs/2511.04491)
*Nikhil Abhyankar,Purvi Chaurasia,Sanchit Kabra,Ananya Srivastava,Vivek Gupta,Chandan K. Reddy*

Main category: cs.CL

TL;DR: RUST-BENCH 是针对真实表格推理能力的新基准，揭示了当前大语言模型在复杂表格和推理能力上的不足，推动该领域研究的进展。


<details>
  <summary>Details</summary>
Motivation: 现有的表格推理基准未能充分测试模型在处理复杂和异构表格数据方面的能力，因此需要一个能够更真实地反映现实世界情况的新基准。

Method: 通过创建包含 7966 个问题和 2031 个真实世界表格的基准 RUST-BENCH，对大语言模型的推理能力进行评估。

Result: 公开与专有模型的实验表明，现有的 LLM 在处理异构模式和复杂的多步推理时表现不佳，暴露出当前架构和策略的弱点。

Conclusion: RUST-BENCH 是一个全新的基准，用于推动表格推理研究，揭示了现有大语言模型在复杂数据处理上的不足。

Abstract: Existing tabular reasoning benchmarks mostly test models on small, uniform
tables, underrepresenting the complexity of real-world data and giving an
incomplete view of Large Language Models' (LLMs) reasoning abilities. Real
tables are long, heterogeneous, and domain-specific, mixing structured fields
with free text and requiring multi-hop reasoning across thousands of tokens. To
address this gap, we introduce RUST-BENCH, a benchmark of 7966 questions from
2031 real-world tables spanning two domains: i) RB-Science (NSF grant records)
and ii) RB-Sports (NBA statistics). Unlike prior work, RUST-BENCH evaluates
LLMs jointly across scale, heterogeneity, domain specificity, and reasoning
complexity. Experiments with open-source and proprietary models show that LLMs
struggle with heterogeneous schemas and complex multi-hop inference, revealing
persistent weaknesses in current architectures and prompting strategies.
RUST-BENCH establishes a challenging new testbed for advancing tabular
reasoning research.

</details>


### [85] [OUNLP at TSAR 2025 Shared Task: Multi-Round Text Simplifier via Code Generation](https://arxiv.org/abs/2511.04495)
*Cuong Huynh,Jie Cao*

Main category: cs.CL

TL;DR: 本文提出了基于LLM的文本简化系统，探索了CEFR等级的影响，结果显示系统性能良好，有助于多轮简化。


<details>
  <summary>Details</summary>
Motivation: 我们发现源CEFR等级与目标CEFR等级之间的差距对文本简化性能有显著影响，因此探索相应的简化方法。

Method: 基于LLM提示生成的可读性控制文本简化，提出MRS-Rule和MRS-Joint两种多轮简化方法。

Result: 我们的系统在20个团队中排名第7，后续改进显示MRS-Joint方法进一步提升了性能。

Conclusion: 我们提出的两种多轮简化方法有效提高了文本简化性能，尤其是结合LLM生成的候选文本作为起点。

Abstract: This paper describes the OUNLP system submitted to the TSAR-2025 Shared Task
(Alva-Manchego et al., 2025), designed for readability-controlled text
simplification using LLM-prompting-based generation. Based on the analysis of
prompt-based text simplification methods, we discovered an interesting finding
that text simplification performance is highly related to the gap between the
source CEFR (Arase et al., 2022) level and the target CEFR level. Inspired by
this finding, we propose two multi-round simplification methods and generate
them via GPT-4o: rule-based simplification (MRS-Rule) and jointly rule-based
LLM simplification (MRS-Joint). Our submitted systems ranked 7 out of 20 teams.
Later improvements with MRS-Joint show that taking the LLM simplified
candidates as the starting point could further boost the multi-round
simplification performance.

</details>


### [86] [Decoding Emergent Big Five Traits in Large Language Models: Temperature-Dependent Expression and Architectural Clustering](https://arxiv.org/abs/2511.04499)
*Christos-Nikolaos Zacharopoulos,Revekka Kyriakoglou*

Main category: cs.CL

TL;DR: 本研究评估了六个大型语言模型的个性特征，发现不同温度下会影响其神经质和外向性表现，并提供关于模型选择和AI伦理的新见解。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在以人为本的应用中愈加重要，理解它们的个性化行为对负责任的开发和部署而言至关重要。

Method: 采用Big Five Inventory-2 (BFI-2)框架，系统评估六个大型语言模型在不同采样温度下的个性特征表达。

Result: 在五个个性维度中的四个观察到显著差异，神经质和外向性易受温度调整的影响，且模型聚类表明模型架构可能影响稳定性。

Conclusion: 本研究揭示了大型语言模型在个性特征表现上的显著差异，并提供了关于AI系统伦理治理的新视角。

Abstract: As Large Language Models (LLMs) become integral to human-centered
applications, understanding their personality-like behaviors is increasingly
important for responsible development and deployment. This paper systematically
evaluates six LLMs, applying the Big Five Inventory-2 (BFI-2) framework, to
assess trait expressions under varying sampling temperatures. We find
significant differences across four of the five personality dimensions, with
Neuroticism and Extraversion susceptible to temperature adjustments. Further,
hierarchical clustering reveals distinct model clusters, suggesting that
architectural features may predispose certain models toward stable trait
profiles. Taken together, these results offer new insights into the emergence
of personality-like patterns in LLMs and provide a new perspective on model
tuning, selection, and the ethical governance of AI systems. We share the data
and code for this analysis here:
https://osf.io/bsvzc/?view_only=6672219bede24b4e875097426dc3fac1

</details>


### [87] [Modeling Clinical Uncertainty in Radiology Reports: from Explicit Uncertainty Markers to Implicit Reasoning Pathways](https://arxiv.org/abs/2511.04506)
*Paloma Rabaey,Jong Hak Moon,Jung-Oh Lee,Min Gwan Kim,Hangyul Yoon,Thomas Demeester,Edward Choi*

Main category: cs.CL

TL;DR: 研究提出了一种新的框架，用于分析放射学报告中的不确定性，并推出了Lunguage++数据集，提升了自动分类及诊断能力。


<details>
  <summary>Details</summary>
Motivation: 放射学报告在临床决策中至关重要，但其中的不确定性影响了自动分析的有效性。

Method: 构建专家验证的LLM基础参考排名以量化明确不确定性，并通过扩展框架建模隐含不确定性。

Result: 通过构建的两个框架，研究实现了对放射学报告不确定性的系统化分析，并发布了进一步丰富的Lunguage++数据集。

Conclusion: 研究提出了一个针对放射学报告中明确与隐含不确定性的双重框架，并发布了增强版的Lunguage++资源，助力影像分类及诊断推理。

Abstract: Radiology reports are invaluable for clinical decision-making and hold great
potential for automated analysis when structured into machine-readable formats.
These reports often contain uncertainty, which we categorize into two distinct
types: (i) Explicit uncertainty reflects doubt about the presence or absence of
findings, conveyed through hedging phrases. These vary in meaning depending on
the context, making rule-based systems insufficient to quantify the level of
uncertainty for specific findings; (ii) Implicit uncertainty arises when
radiologists omit parts of their reasoning, recording only key findings or
diagnoses. Here, it is often unclear whether omitted findings are truly absent
or simply unmentioned for brevity. We address these challenges with a two-part
framework. We quantify explicit uncertainty by creating an expert-validated,
LLM-based reference ranking of common hedging phrases, and mapping each finding
to a probability value based on this reference. In addition, we model implicit
uncertainty through an expansion framework that systematically adds
characteristic sub-findings derived from expert-defined diagnostic pathways for
14 common diagnoses. Using these methods, we release Lunguage++, an expanded,
uncertainty-aware version of the Lunguage benchmark of fine-grained structured
radiology reports. This enriched resource enables uncertainty-aware image
classification, faithful diagnostic reasoning, and new investigations into the
clinical impact of diagnostic uncertainty.

</details>


### [88] [Are language models aware of the road not taken? Token-level uncertainty and hidden state dynamics](https://arxiv.org/abs/2511.04527)
*Amir Zur,Atticus Geiger,Ekdeep Singh Lubana,Eric Bigelow*

Main category: cs.CL

TL;DR: 本研究探讨了语言模型在生成文本时的推理路径及其不确定性，发现隐藏激活能够有效地控制和预测模型的推理过程。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型在生成过程中如何表示备选推理路径，特别是在不确定性量化方面。

Method: 通过隐含激活控制和预测语言模型在推理过程中的不确定性。

Result: 发现模型在不同tokens的不确定性与通过控制激活来引导模型之间存在明确的相关性，表明当模型尚未承诺特定最终答案时激活干预最为有效。

Conclusion: 隐藏激活可以预测模型未来的结果分布，表明模型隐式地代表了可能路径的空间。

Abstract: When a language model generates text, the selection of individual tokens
might lead it down very different reasoning paths, making uncertainty difficult
to quantify. In this work, we consider whether reasoning language models
represent the alternate paths that they could take during generation. To test
this hypothesis, we use hidden activations to control and predict a language
model's uncertainty during chain-of-thought reasoning. In our experiments, we
find a clear correlation between how uncertain a model is at different tokens,
and how easily the model can be steered by controlling its activations. This
suggests that activation interventions are most effective when there are
alternate paths available to the model -- in other words, when it has not yet
committed to a particular final answer. We also find that hidden activations
can predict a model's future outcome distribution, demonstrating that models
implicitly represent the space of possible paths.

</details>


### [89] [IntelliProof: An Argumentation Network-based Conversational Helper for Organized Reflection](https://arxiv.org/abs/2511.04528)
*Kaveh Eskandari Miandoab,Katharine Kowalyshyn,Kabir Pamnani,Anesu Gavhera,Vasanth Sarathy,Matthias Scheutz*

Main category: cs.CL

TL;DR: IntelliProof是一个互动系统，通过论证图分析论文，增强用户体验，支持快速探索论证质量。


<details>
  <summary>Details</summary>
Motivation: 为了改善现有的自动评分系统，IntelliProof强调用户体验，帮助用户理解论证的逻辑关系。

Method: 通过将论文结构化为论证图，使用大型语言模型(LLMs)对每个关系进行分类和评分，并提供可视化效果和定量措施。

Result: IntelliProof能够有效地分析论文的论证质量，同时提供人类可理解的结构和工具。

Conclusion: IntelliProof为用户提供了一种交互式系统，通过结构化的论证图分析论文，增强了用户体验，并在保持人类监督的情况下，快速探讨论证质量。

Abstract: We present IntelliProof, an interactive system for analyzing argumentative
essays through LLMs. IntelliProof structures an essay as an argumentation
graph, where claims are represented as nodes, supporting evidence is attached
as node properties, and edges encode supporting or attacking relations. Unlike
existing automated essay scoring systems, IntelliProof emphasizes the user
experience: each relation is initially classified and scored by an LLM, then
visualized for enhanced understanding. The system provides justifications for
classifications and produces quantitative measures for essay coherence. It
enables rapid exploration of argumentative quality while retaining human
oversight. In addition, IntelliProof provides a set of tools for a better
understanding of an argumentative essay and its corresponding graph in natural
language, bridging the gap between the structural semantics of argumentative
essays and the user's understanding of a given text. A live demo and the system
are available here to try: \textbf{https://intelliproof.vercel.app}

</details>


### [90] [From Model to Breach: Towards Actionable LLM-Generated Vulnerabilities Reporting](https://arxiv.org/abs/2511.04538)
*Cyril Vallez,Alexander Sternfeld,Andrei Kucharavy,Ljiljana Dolamic*

Main category: cs.CL

TL;DR: 本文探讨大型语言模型生成的代码在安全性上的脆弱性，并提出一种新评分机制以评估其生成漏洞的严重性。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在软件开发中的安全性以及它们生成的代码可能带来的安全隐患。

Method: 提出了一种新的脆弱性严重性度量，考虑了脆弱性严重性、生成概率和引发脆弱性代码生成的提示形式。

Result: 最新的开源模型仍然在早期已报告的脆弱性场景中存在安全漏洞，提出了一种新的评估模型生成漏洞的方法。

Conclusion: 引入模型曝光度（ME）评分，有助于评估和改善大型语言模型生成代码的安全性。

Abstract: As the role of Large Language Models (LLM)-based coding assistants in
software development becomes more critical, so does the role of the bugs they
generate in the overall cybersecurity landscape. While a number of LLM code
security benchmarks have been proposed alongside approaches to improve the
security of generated code, it remains unclear to what extent they have
impacted widely used coding LLMs. Here, we show that even the latest
open-weight models are vulnerable in the earliest reported vulnerability
scenarios in a realistic use setting, suggesting that the safety-functionality
trade-off has until now prevented effective patching of vulnerabilities. To
help address this issue, we introduce a new severity metric that reflects the
risk posed by an LLM-generated vulnerability, accounting for vulnerability
severity, generation chance, and the formulation of the prompt that induces
vulnerable code generation - Prompt Exposure (PE). To encourage the mitigation
of the most serious and prevalent vulnerabilities, we use PE to define the
Model Exposure (ME) score, which indicates the severity and prevalence of
vulnerabilities a model generates.

</details>


### [91] [When retrieval outperforms generation: Dense evidence retrieval for scalable fake news detection](https://arxiv.org/abs/2511.04643)
*Alamgir Munir Qazi,John P. McCrae,Jamal Abdul Nasir*

Main category: cs.CL

TL;DR: DeReC是一个轻量级的事实验证框架，通过密集检索和分类实现高效验证，超越了当前LLM方法的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 随着虚假信息的传播，急需高效且可靠的事实验证系统来应对现实世界的挑战。

Method: 通过结合密集检索和专业分类，使用通用文本嵌入替代自回归LLM方法，进行事实验证。

Result: DeReC在多个数据集上实现了显著的效率提升和准确性改进，尤其在RAWFC上取得了65.58%的F1分数，超过了最先进的L-Defense方法。

Conclusion: DeReC展示了检索基础系统在事实验证任务中的有效性，超越了当前的LLM方法，特别是在计算效率上具备优势。

Abstract: The proliferation of misinformation necessitates robust yet computationally
efficient fact verification systems. While current state-of-the-art approaches
leverage Large Language Models (LLMs) for generating explanatory rationales,
these methods face significant computational barriers and hallucination risks
in real-world deployments. We present DeReC (Dense Retrieval Classification), a
lightweight framework that demonstrates how general-purpose text embeddings can
effectively replace autoregressive LLM-based approaches in fact verification
tasks. By combining dense retrieval with specialized classification, our system
achieves better accuracy while being significantly more efficient. DeReC
outperforms explanation-generating LLMs in efficiency, reducing runtime by 95%
on RAWFC (23 minutes 36 seconds compared to 454 minutes 12 seconds) and by 92%
on LIAR-RAW (134 minutes 14 seconds compared to 1692 minutes 23 seconds),
showcasing its effectiveness across varying dataset sizes. On the RAWFC
dataset, DeReC achieves an F1 score of 65.58%, surpassing the state-of-the-art
method L-Defense (61.20%). Our results demonstrate that carefully engineered
retrieval-based systems can match or exceed LLM performance in specialized
tasks while being significantly more practical for real-world deployment.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [92] [OptiMA: A Transaction-Based Framework with Throughput Optimization for Very Complex Multi-Agent Systems](https://arxiv.org/abs/2511.03761)
*Umut Çalıkyılmaz,Nitin Nayak,Jinghua Groppe,Sven Groppe*

Main category: cs.MA

TL;DR: 本研究提出了OptiMA框架，通过事务调度提升了复杂多智能体系统的性能，实验结果显示性能提高超过16%。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体系统的复杂性增加，可能出现故障和性能瓶颈，因此有必要探索应对这些挑战的方法。

Method: 通过实现事务调度与基于事务的框架，来构建和测试极复杂的多智能体系统（VCMAS）。

Result: 我们的实验表明，OptiMA框架能够在超过一百个智能体的情况下高效执行，并且事务调度能够提高系统性能超过16%。

Conclusion: 我们提出的OptiMA框架能够有效支持复杂的多智能体系统的执行，并通过事务调度提升系统性能，证明了其有效性和实用性。

Abstract: In recent years, the research of multi-agent systems has taken a direction to
explore larger and more complex models to fulfill sophisticated tasks. We point
out two possible pitfalls that might be caused by increasing complexity;
susceptibilities to faults, and performance bottlenecks. To prevent the former
threat, we propose a transaction-based framework to design very complex
multi-agent systems (VCMAS). To address the second threat, we offer to
integrate transaction scheduling into the proposed framework. We implemented
both of these ideas to develop the OptiMA framework and show that it is able to
facilitate the execution of VCMAS with more than a hundred agents. We also
demonstrate the effect of transaction scheduling on such a system by showing
improvements up to more than 16\%. Furthermore, we also performed a theoretical
analysis on the transaction scheduling problem and provided practical tools
that can be used for future research on it.

</details>


### [93] [Multi-Agent Collaborative Framework For Math Problem Generation](https://arxiv.org/abs/2511.03958)
*Kia Karbasi,Kevin Hong,Mohammad Amin Samadi,Gregory Pottie*

Main category: cs.MA

TL;DR: 本研究提出了一种协作多智能体框架，用于改善数学教育中自动问题生成的复杂性和认知需求控制，初步评估显示其提升了生成内容的质量。


<details>
  <summary>Details</summary>
Motivation: 为了改善自动生成数学教育问题的复杂度和认知需求控制，该工作旨在探索智能辅导系统和教育工作者的需求。

Method: 引入协作多智能体框架，通过推理时计算，迭代优化生成的问题-答案对。

Result: 经过五个元评估标准的评估，生成的问题在相关性、重要性、清晰度、难度匹配和可答性方面表现出色。

Conclusion: 综合多智能体框架能够提升生成教育内容的质量，实现更好的认知挑战与清晰度之间的平衡。

Abstract: Automatic question generation (AQG) for mathematics education remains an
elusive goal for Intelligent Tutoring Systems and educators. While pre-trained
transformer-based language models have significantly advanced natural language
generation, they often struggle to precisely control problem complexity and
cognitive demands. In this paper, we introduce a collaborative multi-agent
framework as a novel method of incorporating inference-time computation into
AQG. This approach leverages multiple agents that iteratively refine generated
question-answer pairs to better balance complexity and cognitive demand. We
evaluate the generated questions on five meta-evaluation criteria: relevance,
importance, clarity, difficulty matching, answerability, to assess the system's
ability to control the required complexity and quality of the questions.
Preliminary evaluations show that this collaborative multi-agent framework
elevates the quality of generated educational content by fostering a more
nuanced balance between cognitive challenge and clarity. These promising
outcomes suggest that integrating collaborative multi-agent workflows can yield
more controlled, pedagogically valuable content that can help advance automated
educational content generation and adaptive learning environments.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [94] [Towards Aligning Multimodal LLMs with Human Experts: A Focus on Parent-Child Interaction](https://arxiv.org/abs/2511.04366)
*Weiyan Shi,Kenny Tsu Wei Choo*

Main category: cs.HC

TL;DR: 本研究探讨了多模态大型语言模型在分析父母与儿童互动中的社会行为的可行性与挑战，发现专家间观察层面的对齐较为稳健，而判断层面存在差异。


<details>
  <summary>Details</summary>
Motivation: To explore how MLLMs can align with experts in understanding joint attention in parent-child interactions, important for social-communicative development.

Method: Exploratory study involving interviews and video annotations with speech-language pathologists, followed by testing an MLLM's workflow through two-stage prompting.

Result: Findings indicate robust alignment in observational cues among experts, but divergence in interpretative criteria at the judgment level.

Conclusion: MLLMs can effectively align with expert observations but face challenges in interpretative judgment in analyzing social interactions.

Abstract: While multimodal large language models (MLLMs) are increasingly applied in
human-centred AI systems, their ability to understand complex social
interactions remains uncertain. We present an exploratory study on aligning
MLLMs with speech-language pathologists (SLPs) in analysing joint attention in
parent-child interactions, a key construct in early social-communicative
development. Drawing on interviews and video annotations with three SLPs, we
characterise how observational cues of gaze, action, and vocalisation inform
their reasoning processes. We then test whether an MLLM can approximate this
workflow through a two-stage prompting, separating observation from judgment.
Our findings reveal that alignment is more robust at the observation layer,
where experts share common descriptors, than at the judgement layer, where
interpretive criteria diverge. We position this work as a case-based probe into
expert-AI alignment in complex social behaviour, highlighting both the
feasibility and the challenges of applying MLLMs to socially situated
interaction analysis.

</details>


### [95] [MazeMate: An LLM-Powered Chatbot to Support Computational Thinking in Gamified Programming Learning](https://arxiv.org/abs/2511.03727)
*Chenyu Hou,Hua Yu,Gaoxia Zhu,John Derek Anas,Jiao Liu,Yew Soon Ong*

Main category: cs.HC

TL;DR: MazeMate是一个基于LLM的聊天机器人，通过3D迷宫编程游戏帮助学生培养计算思维，虽然在迷宫解决上有益，但在迷宫设计方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过LLM和游戏化编程环境提升计算思维的培养效率。

Method: 在一个包含247名本科生的课堂中实施MazeMate，并对使用效果进行主题分析。

Result: 学生认为MazeMate在解决迷宫时有帮助，但在迷宫设计方面表现较差，分析显示支持计算思维过程的存在及迷宫设计的局限性。

Conclusion: LLM驱动的支撑系统有潜力支持计算思维，但在迷宫设计方面存在局限性，亟需优化设计以提高可用性。

Abstract: Computational Thinking (CT) is a foundational problem-solving skill, and
gamified programming environments are a widely adopted approach to cultivating
it. While large language models (LLMs) provide on-demand programming support,
current applications rarely foster CT development. We present MazeMate, an
LLM-powered chatbot embedded in a 3D Maze programming game, designed to deliver
adaptive, context-sensitive scaffolds aligned with CT processes in maze solving
and maze design. We report on the first classroom implementation with 247
undergraduates. Students rated MazeMate as moderately helpful, with higher
perceived usefulness for maze solving than for maze design. Thematic analysis
confirmed support for CT processes such as decomposition, abstraction, and
algorithmic thinking, while also revealing limitations in supporting maze
design, including mismatched suggestions and fabricated algorithmic solutions.
These findings demonstrate the potential of LLM-based scaffolding to support CT
and underscore directions for design refinement to enhance MazeMate usability
in authentic classrooms.

</details>


### [96] [Beyond Chat: a Framework for LLMs as Human-Centered Support Systems](https://arxiv.org/abs/2511.03729)
*Zhiyin Zhou*

Main category: cs.HC

TL;DR: 本论文提出了一个框架，旨在通过角色驱动的支持，提升大语言模型在敏感环境中的应用效果和人本体验，强调了评估和设计原则。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的应用范畴扩展至陪伴、指导和决策支持，需要构建人本中心的支持系统来提升用户体验和福祉。

Method: 通过比较不同领域的真实部署，分析设计原则和评估指标。

Result: 确定了关键的设计原则，包括透明度、个性化、守护措施、隐私记忆以及同理心与可靠性的平衡，同时分析了潜在风险和未来发展方向。

Conclusion: 该研究提出了一种以角色为基础的人本中心大语言模型支持系统框架，并讨论了在敏感环境中负责任地整合这些模型的方向和原则。

Abstract: Large language models are moving beyond transactional question answering to
act as companions, coaches, mediators, and curators that scaffold human growth,
decision-making, and well-being. This paper proposes a role-based framework for
human-centered LLM support systems, compares real deployments across domains,
and identifies cross-cutting design principles: transparency, personalization,
guardrails, memory with privacy, and a balance of empathy and reliability. It
outlines evaluation metrics that extend beyond accuracy to trust, engagement,
and longitudinal outcomes. It also analyzes risks including over-reliance,
hallucination, bias, privacy exposure, and unequal access, and proposes future
directions spanning unified evaluation, hybrid human-AI models, memory
architectures, cross-domain benchmarking, and governance. The goal is to
support responsible integration of LLMs in sensitive settings where people need
accompaniment and guidance, not only answers.

</details>


### [97] [Not All Explanations are Created Equal: Investigating the Pitfalls of Current XAI Evaluation](https://arxiv.org/abs/2511.03730)
*Joe Shymanski,Jacob Brue,Sandip Sen*

Main category: cs.HC

TL;DR: 本研究指出现有XAI评估方法缺乏普适性，建议关注可操作性解释，并通过实验证明了用户满意度与解释质量之间的关系。


<details>
  <summary>Details</summary>
Motivation: 现有的XAI评估技术普遍不够全面，用户满意度并不能代表解释质量的真实水平。

Method: 通过使用智能助手教授用户棋类概念，展示可解释性的有效性与评估方法。

Result: 发现无论解释的质量如何，用户满意度普遍会提高，强调了可操作性解释的重要性。

Conclusion: 本研究强调了现有的可解释人工智能评估方法的不足，呼吁更全面的评估技术，并分析了可操作性解释在不同情境下的有效性。

Abstract: Explainable Artificial Intelligence (XAI) aims to create transparency in
modern AI models by offering explanations of the models to human users. There
are many ways in which researchers have attempted to evaluate the quality of
these XAI models, such as user studies or proposed objective metrics like
"fidelity". However, these current XAI evaluation techniques are ad hoc at best
and not generalizable. Thus, most studies done within this field conduct simple
user surveys to analyze the difference between no explanations and those
generated by their proposed solution. We do not find this to provide adequate
evidence that the explanations generated are of good quality since we believe
any kind of explanation will be "better" in most metrics when compared to none
at all. Thus, our study looks to highlight this pitfall: most explanations,
regardless of quality or correctness, will increase user satisfaction. We also
propose that emphasis should be placed on actionable explanations. We
demonstrate the validity of both of our claims using an agent assistant to
teach chess concepts to users. The results of this chapter will act as a call
to action in the field of XAI for more comprehensive evaluation techniques for
future research in order to prove explanation quality beyond user satisfaction.
Additionally, we present an analysis of the scenarios in which placebic or
actionable explanations would be most useful.

</details>


### [98] [HACI: A Haptic-Audio Code Interface to Improve Educational Outcomes for Visually Impaired Introductory Programming Students](https://arxiv.org/abs/2511.03733)
*Pratham Gandhi*

Main category: cs.HC

TL;DR: 本文介绍了HACI，一个旨在改善视觉障碍学生编程教育的工具，通过触觉和音频反馈提高学习体验，并强调了未来发展的方向。


<details>
  <summary>Details</summary>
Motivation: 提供公平的计算机科学教育机会，改善视觉障碍学生的编程学习体验。

Method: 设计和实施HACI工具，通过与视觉障碍学生的初步研究评估其效果。

Result: HACI有助于非视觉编程构造的导航和理解，但在反馈机制的一致性和可靠性方面仍存在挑战。

Conclusion: HACI展示了触觉和音频反馈在视觉障碍学生编程教育中的潜力，尽管仍需改进反馈机制和功能以提升可用性。

Abstract: This thesis introduces the Haptic-Audio Code Interface (HACI), an educational
tool designed to enhance programming education for visually impaired (VI)
students by integrating haptic and audio feedback to compensate for the absence
of visual cues. HACI consists of a non-resource-intensive web application
supporting JavaScript program development, execution, and debugging, connected
via a cable to an Arduino-powered glove with six integrated haptic motors to
provide physical feedback to VI programmers. Motivated by the need to provide
equitable educational opportunities in computer science, HACI aims to improve
non-visual code navigation, comprehension, summarizing, editing, and debugging
for students with visual impairments while minimizing cognitive load. This work
details HACI's design principles, technical implementation, and a preliminary
evaluation through a pilot study conducted with undergraduate Computer Science
students. Findings indicate that HACI aids in the non-visual navigation and
understanding of programming constructs, although challenges remain in refining
feedback mechanisms to ensure consistency and reliability, as well as
supplementing the current functionality with a more feature-reach and
customizable accessible learning experience which will allow visually impaired
students to fully utilize interleaved haptic and audio feedback. The study
underscores the transformative potential of haptic and audio feedback in
educational practices for the visually impaired, setting a foundation for
future research and development in accessible programming education. This
thesis contributes to the field of accessible technology by demonstrating how
tactile and auditory feedback can be effectively integrated into educational
tools, thereby broadening accessibility in STEM education.

</details>


### [99] [SnappyMeal: Design and Longitudinal Evaluation of a Multimodal AI Food Logging Application](https://arxiv.org/abs/2511.03907)
*Liam Bakar,Zachary Englhardt,Vidya Srinivas,Girish Narayanswamy,Dilini Nissanka,Shwetak Patel,Vikram Iyer*

Main category: cs.HC

TL;DR: SnappyMeal是一个AI驱动的饮食追踪系统，通过多模态输入提高记录灵活性和准确性，得到了用户的积极反馈。


<details>
  <summary>Details</summary>
Motivation: 当前的饮食记录方法灵活性不足，导致用户依从性低和营养总结可能不准确，因此迫切需要改进。

Method: 通过与营养专家和实践饮食追踪的个体进行对话，提出了一种新的AI驱动的饮食追踪系统，并进行多用户的实际部署与评估。

Result: SnappyMeal获得了用户的高度赞赏，多个输入方法被认为提高了准确性，且在多种营养基准评估中表现良好。

Conclusion: SnappyMeal系统通过多模态输入显著提高了饮食追踪的灵活性和上下文意识，为智能自我追踪应用的新时代奠定了基础。

Abstract: Food logging, both self-directed and prescribed, plays a critical role in
uncovering correlations between diet, medical, fitness, and health outcomes.
Through conversations with nutritional experts and individuals who practice
dietary tracking, we find current logging methods, such as handwritten and
app-based journaling, are inflexible and result in low adherence and
potentially inaccurate nutritional summaries. These findings, corroborated by
prior literature, emphasize the urgent need for improved food logging methods.
In response, we propose SnappyMeal, an AI-powered dietary tracking system that
leverages multimodal inputs to enable users to more flexibly log their food
intake. SnappyMeal introduces goal-dependent follow-up questions to
intelligently seek missing context from the user and information retrieval from
user grocery receipts and nutritional databases to improve accuracy. We
evaluate SnappyMeal through publicly available nutrition benchmarks and a
multi-user, 3-week, in-the-wild deployment capturing over 500 logged food
instances. Users strongly praised the multiple available input methods and
reported a strong perceived accuracy. These insights suggest that multimodal AI
systems can be leveraged to significantly improve dietary tracking flexibility
and context-awareness, laying the groundwork for a new class of intelligent
self-tracking applications.

</details>


### [100] [Revealing AI Reasoning Increases Trust but Crowds Out Unique Human Knowledge](https://arxiv.org/abs/2511.04050)
*Zenan Chen,Ruijiang Gao,Yingzhi Liang*

Main category: cs.HC

TL;DR: 本研究探讨了AI推理透明度对人类信任和知识使用的影响，发现透明度增加会导致过度信任，降低独特知识的应用。


<details>
  <summary>Details</summary>
Motivation: 为了有效的人机合作，人类需要准确评估AI的能力并相应地调整信任。

Method: 通过一项预注册的、有激励兼容性的实验，参与者人数为752，研究了展示AI推理对信任和UHK利用的影响。

Result: 透露AI推理显著提高了信任和对AI建议的认同，但这种透明性也导致了过度信任，抑制了UHK的使用。

Conclusion: 透明度的增加可能导致过度信任，从而降低独特人类知识的使用。

Abstract: Effective human-AI collaboration requires humans to accurately gauge AI
capabilities and calibrate their trust accordingly. Humans often have
context-dependent private information, referred to as Unique Human Knowledge
(UHK), that is crucial for deciding whether to accept or override AI's
recommendations. We examine how displaying AI reasoning affects trust and UHK
utilization through a pre-registered, incentive-compatible experiment (N =
752). We find that revealing AI reasoning, whether brief or extensive, acts as
a powerful persuasive heuristic that significantly increases trust and
agreement with AI recommendations. Rather than helping participants
appropriately calibrate their trust, this transparency induces over-trust that
crowds out UHK utilization. Our results highlight the need for careful
consideration when revealing AI reasoning and call for better information
design in human-AI collaboration systems.

</details>


### [101] ["Everyone Else Does It": The Rise of Preprinting Culture in Computing Disciplines](https://arxiv.org/abs/2511.04081)
*Kyrie Zhixuan Zhou,Justin Eric Chen,Xiang Zheng,Yaoyao Qian,Yunpeng Xiao,Kai Shu*

Main category: cs.HC

TL;DR: 本研究通过访谈分析了人工智能和人机交互领域学者对预印本的动机和看法，探讨了其对传统出版模式的影响及改善出版生态的可能性。


<details>
  <summary>Details</summary>
Motivation: 鉴于计算领域的快速发展，了解学者对预印本的态度有助于改善出版生态系统。

Method: 通过对15位学者进行半结构化访谈，收集他们对预印本的动机和看法。

Result: 研究发现预印本与领域特征（如论文数量、职业竞争、抢先发表现象及同行评审系统的不完善）之间存在密切关系。

Conclusion: 本研究揭示了预印本在人工智能和人机交互领域的重要性，以及对传统出版模式的颠覆潜力。

Abstract: Preprinting has become a norm in fast-paced computing fields such as
artificial intelligence (AI) and human-computer interaction (HCI). In this
paper, we conducted semistructured interviews with 15 academics in these fields
to reveal their motivations and perceptions of preprinting. The results found a
close relationship between preprinting and characteristics of the fields,
including the huge number of papers, competitiveness in career advancement,
prevalence of scooping, and imperfect peer review system - preprinting comes to
the rescue in one way or another for the participants. Based on the results, we
reflect on the role of preprinting in subverting the traditional publication
mode and outline possibilities of a better publication ecosystem. Our study
contributes by inspecting the community aspects of preprinting practices
through talking to academics.

</details>


### [102] [Scaffolding Metacognition in Programming Education: Understanding Student-AI Interactions and Design Implications](https://arxiv.org/abs/2511.04144)
*Boxuan Ma,Huiyong Li,Gen Li,Li Chen,Cheng Tang,Yinjie Xie,Chenghao Gu,Atsushi Shimada,Shin'ichi Konomi*

Main category: cs.HC

TL;DR: 本研究探讨了生成性AI工具对大学编程学生元认知过程的影响，分析了大量对话记录，提出了增强学生学习过程的设计建议。


<details>
  <summary>Details</summary>
Motivation: 目前对生成性AI工具对学生元认知过程影响的研究相对有限，主要集中在正确性和可用性上，因此需要填补这一空白。

Method: 通过分析大学编程课程中超过10,000条师生对话记录，并结合对学生和教育者的调查，采用元认知视角研究学生与AI助手的互动。

Result: 研究分析结果表明，学生与AI助手的互动在元认知阶段和策略上存在一定的对齐，提出了设计考虑因素以支持元认知参与。

Conclusion: 本研究提供了关于如何设计支持学生元认知参与的AI编码助手的指导，旨在增强学生的编程学习过程。

Abstract: Generative AI tools such as ChatGPT now provide novice programmers with
unprecedented access to instant, personalized support. While this holds clear
promise, their influence on students' metacognitive processes remains
underexplored. Existing work has largely focused on correctness and usability,
with limited attention to whether and how students' use of AI assistants
supports or bypasses key metacognitive processes. This study addresses that gap
by analyzing student-AI interactions through a metacognitive lens in
university-level programming courses. We examined more than 10,000 dialogue
logs collected over three years, complemented by surveys of students and
educators. Our analysis focused on how prompts and responses aligned with
metacognitive phases and strategies. Synthesizing these findings across data
sources, we distill design considerations for AI-powered coding assistants that
aim to support rather than supplant metacognitive engagement. Our findings
provide guidance for developing educational AI tools that strengthen students'
learning processes in programming education.

</details>


### [103] [Active Domain Adaptation for mmWave-based HAR via Renyi Entropy-based Uncertainty Estimation](https://arxiv.org/abs/2511.04219)
*Mingzhi Lin,Teng Huang,Han Ding,Cui Zhao,Fei Wang,Ge Wang,Wei Xi*

Main category: cs.HC

TL;DR: mmADA是一个有效的主动领域适应框架，显著提升了毫米波雷达在人活动识别中的表现，特别是在跨领域设置中。


<details>
  <summary>Details</summary>
Motivation: 采用毫米波雷达的人体活动识别提供了一种非侵入性的方法，但模型在新领域的性能下降问题亟需解决。

Method: 提出了一种主动领域适应框架 mmADA，通过细化特征对齐，提高模型在新用户、位置和环境中的性能。

Result: mmADA在多用户、多位置和不同环境下的实验中，在各类跨领域设置中达到了超过90%的准确性，并且相对于五个基准模型表现优越，验证了其鲁棒性和泛化能力。

Conclusion: mmADA显著提高了毫米波雷达基础的人体活动识别在跨领域情况下的准确性和适应性。

Abstract: Human Activity Recognition (HAR) using mmWave radar provides a non-invasive
alternative to traditional sensor-based methods but suffers from domain shift,
where model performance declines in new users, positions, or environments. To
address this, we propose mmADA, an Active Domain Adaptation (ADA) framework
that efficiently adapts mmWave-based HAR models with minimal labeled data.
mmADA enhances adaptation by introducing Renyi Entropy-based uncertainty
estimation to identify and label the most informative target samples.
Additionally, it leverages contrastive learning and pseudo-labeling to refine
feature alignment using unlabeled data. Evaluations with a TI IWR1443BOOST
radar across multiple users, positions, and environments show that mmADA
achieves over 90% accuracy in various cross-domain settings. Comparisons with
five baselines confirm its superior adaptation performance, while further tests
on unseen users, environments, and two additional open-source datasets validate
its robustness and generalization.

</details>


### [104] [HPC-Vis: A Visual Analytic System for Interactive Exploration of Historical Painter Cohorts](https://arxiv.org/abs/2511.04383)
*Yingping Yang,Guangtao You,Jiayi Chen,Jiazhou Chen*

Main category: cs.HC

TL;DR: 本文提出HPC-Vis，一个结合复杂继承关系可视化、艺术风格标签系统和人机互动的分析工具，助力历史学家探索中国历史画家群体。


<details>
  <summary>Details</summary>
Motivation: 传统的历史画家群体分析方法依赖于丰富的现场经验，并耗时耗力，迫切需要一种新方法来简化和增强该过程。

Method: 提出了HPC-Vis，一个包含三阶段重建算法、统一艺术风格标签系统和人机协同互动探索机制的可视化分析系统。

Result: HPC-Vis成功地将历史画家复杂的继承关系图转换为清晰的森林结构，并引入了基于艺术风格的推荐模型，帮助历史学家更好地探索画家群体。

Conclusion: HPC-Vis系统通过可视化方法有效地辅助历史学家发现、定义和验证历史画家群体，具有显著优势。

Abstract: More than ten thousand Chinese historical painters are recorded in the
literature; their cohort analysis has always been a key area of research on
Chinese painting history for both professional historians and amateur
enthusiasts. However, these painters have very diverse artistic styles and an
extremely complex network of inheritance relationships (e.g., master-apprentice
or style imitation relationships); traditional cohort analysis methods not only
heavily rely on field experience, but also cost a lot of time and effort with
numerous but scattered historical documents. In this paper, we propose HPC-Vis,
a visual analytical system for interactive exploration of historical painter
cohorts. Firstly, a three-stage reconstruction algorithm for inheritance
relationships of painters is proposed, which automatically converts the complex
relationship graph of historical painters into a forest structure that contains
multiple trees with clear inheriting chains, and we visually encoded this
forest as a mountain map to intuitively show potential cohorts of historical
painters. Secondly, a unified artistic style label system with three levels
(i.e., subjects, techniques, and emotions) is established by using large
language models, and it is further visually encoded as a new foldable nested
doughnut chart. Finally, a visually guided human-computer collaborative
interactive exploration mechanism is constructed, in which a painter cohort
recommendation model is designed by integrating style, identity, time, space,
and relationships. Two case studies and a user study demonstrate the advantage
of HPC-Vis on assisting historians in discovering, defining, and validating
cohorts of historical painters.

</details>


### [105] [Generate, Evaluate, Iterate: Synthetic Data for Human-in-the-Loop Refinement of LLM Judges](https://arxiv.org/abs/2511.04478)
*Hyo Jin Do,Zahra Ashktorab,Jasmina Gajcin,Erik Miehling,Martín Santillán Cooper,Qian Pan,Elizabeth M. Daly,Werner Geyer*

Main category: cs.HC

TL;DR: 本研究提出了一种工具，集成了合成数据生成，增强了LLM作为评判工具的灵活性和效率。


<details>
  <summary>Details</summary>
Motivation: LLM作为评判工具的有效性往往受限于缺乏多样和具有代表性的数据来完善评估标准。

Method: 整合合成数据生成到LLM作为评判工具的工作流程中，支持用户创建定制的测试用例，并允许AI辅助现有测试用例的即时编辑。

Result: 在用户研究中，83%的参与者更喜欢使用此工具，生成的合成数据在完善评估标准及与人类偏好的对齐方面有效。

Conclusion: 合成数据被证明是一个有前途的替代方案，特别是在效率和可扩展性至关重要的背景下。

Abstract: The LLM-as-a-judge paradigm enables flexible, user-defined evaluation, but
its effectiveness is often limited by the scarcity of diverse, representative
data for refining criteria. We present a tool that integrates synthetic data
generation into the LLM-as-a-judge workflow, empowering users to create
tailored and challenging test cases with configurable domains, personas,
lengths, and desired outcomes, including borderline cases. The tool also
supports AI-assisted inline editing of existing test cases. To enhance
transparency and interpretability, it reveals the prompts and explanations
behind each generation. In a user study (N=24), 83% of participants preferred
the tool over manually creating or selecting test cases, as it allowed them to
rapidly generate diverse synthetic data without additional workload. The
generated synthetic data proved as effective as hand-crafted data for both
refining evaluation criteria and aligning with human preferences. These
findings highlight synthetic data as a promising alternative, particularly in
contexts where efficiency and scalability are critical.

</details>


### [106] [Perceptions of AI Bad Behavior: Variations on Discordant Non-Performance](https://arxiv.org/abs/2511.04487)
*Jaime Banks*

Main category: cs.HC

TL;DR: 这项研究分析了非专家如何看待AI的不良行为，并提出了一个初步框架。


<details>
  <summary>Details</summary>
Motivation: 为了填补关于非专家如何看待AI不当行为的理解空白。

Method: 通过对28名非专家的访谈进行归纳分析。

Result: 虽然人们在讨论人工智能时不太明显，但当被引导时，AI表现不佳的概念会引起关注，且在评估特定AI行为时尤其显著。

Conclusion: 提出了一个初步框架，用于考虑AI的不良行为，强调道德基础、理解水平和道德二元论的交集。

Abstract: Popular discourses are thick with narratives of generative AI's problematic
functions and outcomes, yet there is little understanding of how non-experts
consider AI activities to constitute bad behavior. This study starts to bridge
that gap through inductive analysis of interviews with non-experts (N = 28)
focusing on large-language models in general and their bad behavior,
specifically. Results suggest bad behaviors are not especially salient when
people discuss AI generally but the notion of AI behaving badly is easily
engaged when prompted, and bad behavior becomes even more salient when
evaluating specific AI behaviors. Types of observed behaviors considered bad
mostly align with their inspiring moral foundations; across all observed
behaviors, some variations on non-performance and social discordance were
present. By scaffolding findings at the intersections of moral foundations
theory, construal level theory, and moral dyadism, a tentative framework for
considering AI bad behavior is proposed.

</details>


### [107] [Students' Acceptance of Arduino Technology Integration in Student-Led Science Inquiry: Insights from the Technology Acceptance Model](https://arxiv.org/abs/2511.04614)
*Seok-Hyun Ga,Chun-Yen Chang,Sonya Martin*

Main category: cs.HC

TL;DR: 本研究探讨了在学生主导的探究性科学课堂中，学生对Arduino技术的接受度，强调了技术设计与教学支持的重要性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在深入理解影响学生对Arduino技术接受度的背景因素，超越传统的定量TAM研究。

Method: 通过对采访和课堂观察的定性分析，研究学生对Arduino技术的有用性和易用性的看法。

Result: 研究发现，接受度不仅受到工具性因素的驱动，如工作相关性和输出质量，也受到韩国教育体系中对技术使用的社会文化认知影响。

Conclusion: 本研究指出，技术设计与教学支持在塑造学生对Arduino技术的接受度中起着关键作用，尤其是在韩国教育系统的特殊社会文化背景下。

Abstract: This study examines high school students' acceptance of Arduino technology in
a student-led, inquiry-based science class, using the extended Technology
Acceptance Model (TAM2) as a guiding framework. Through qualitative analysis of
interviews and classroom observations, we explored how students perceived
Arduino's usefulness and ease of use. Going beyond traditional quantitative TAM
studies, this qualitative TAM research provides a nuanced, in-depth
understanding of the contextual factors shaping technology acceptance. Key
findings reveal that acceptance was driven not only by instrumental factors
like job relevance and output quality but also by the unique sociocultural
context of the Korean education system, where technology use was perceived as
valuable for university admissions (subjective norm and image). Critically,
unlike earlier research that emphasized programming challenges, participants in
this study found Arduino accessible and intuitive, thanks to integrated visual
block-coding tools. These findings highlight the importance of both
technological design and pedagogical support in shaping students' experiences.
Implications for science curriculum design, teacher preparation, and equitable
technology integration in secondary education are discussed.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [108] [How Different Tokenization Algorithms Impact LLMs and Transformer Models for Binary Code Analysis](https://arxiv.org/abs/2511.03825)
*Ahmed Mostafa,Raisul Arefin Nahid,Samuel Mulder*

Main category: cs.AI

TL;DR: 本文研究了汇编代码的标记化模型，揭示其对下游任务性能的影响，并为优化低级代码分析提供洞察。


<details>
  <summary>Details</summary>
Motivation: 尽管标记化对汇编代码分析至关重要，但在该领域的研究仍显不足，本文旨在填补这一空白。

Method: 通过对各种标记化模型进行系统分析，评估其在编码汇编指令和捕捉语义细微之处的效率。

Result: 初步结果表明，标记化选择显著影响下游性能，且内在指标对外部评估结果的预测能力有限。这表明在实际应用中，内在标记化特性与其效用之间存在复杂的权衡关系。

Conclusion: 本研究揭示了在汇编代码分析中的标记化模型选择所带来的复杂权衡，并为优化低级代码分析中的标记化模型提供了有价值的见解。

Abstract: Tokenization is fundamental in assembly code analysis, impacting intrinsic
characteristics like vocabulary size, semantic coverage, and extrinsic
performance in downstream tasks. Despite its significance, tokenization in the
context of assembly code remains an underexplored area. This study aims to
address this gap by evaluating the intrinsic properties of Natural Language
Processing (NLP) tokenization models and parameter choices, such as vocabulary
size. We explore preprocessing customization options and pre-tokenization rules
tailored to the unique characteristics of assembly code. Additionally, we
assess their impact on downstream tasks like function signature prediction -- a
critical problem in binary code analysis.
  To this end, we conduct a thorough study on various tokenization models,
systematically analyzing their efficiency in encoding assembly instructions and
capturing semantic nuances. Through intrinsic evaluations, we compare
tokenizers based on tokenization efficiency, vocabulary compression, and
representational fidelity for assembly code. Using state-of-the-art pre-trained
models such as the decoder-only Large Language Model (LLM) Llama 3.2, the
encoder-only transformer BERT, and the encoder-decoder model BART, we evaluate
the effectiveness of these tokenizers across multiple performance metrics.
Preliminary findings indicate that tokenizer choice significantly influences
downstream performance, with intrinsic metrics providing partial but incomplete
predictability of extrinsic evaluation outcomes. These results reveal complex
trade-offs between intrinsic tokenizer properties and their utility in
practical assembly code tasks. Ultimately, this study provides valuable
insights into optimizing tokenization models for low-level code analysis,
contributing to the robustness and scalability of Natural Language Model
(NLM)-based binary analysis workflows.

</details>


### [109] [To See or To Read: User Behavior Reasoning in Multimodal LLMs](https://arxiv.org/abs/2511.03845)
*Tianning Dong,Luyi Ma,Varun Vasudevan,Jason Cho,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: 本研究通过Benchmarking框架BehaviorLens，发现图像表示用户行为数据相较文本表示能够显著提升多模态大语言模型的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 探讨文本与图像表示在提升多模态大语言模型（MLLM）性能中的有效性，填补相关研究的空白。

Method: 提出了一个名为BehaviorLens的基准框架，系统性地评估不同模态在用户行为推理中的效果。

Result: 通过实证研究发现，使用图像表示的交易数据，其MLLM的下一次购买预测准确性提高了87.5%。

Conclusion: 使用图像表示的用户行为数据能够显著提高多模态大语言模型的下一次购买预测准确性。

Abstract: Multimodal Large Language Models (MLLMs) are reshaping how modern agentic
systems reason over sequential user-behavior data. However, whether textual or
image representations of user behavior data are more effective for maximizing
MLLM performance remains underexplored. We present \texttt{BehaviorLens}, a
systematic benchmarking framework for assessing modality trade-offs in
user-behavior reasoning across six MLLMs by representing transaction data as
(1) a text paragraph, (2) a scatter plot, and (3) a flowchart. Using a
real-world purchase-sequence dataset, we find that when data is represented as
images, MLLMs next-purchase prediction accuracy is improved by 87.5% compared
with an equivalent textual representation without any additional computational
cost.

</details>


### [110] [KnowThyself: An Agentic Assistant for LLM Interpretability](https://arxiv.org/abs/2511.03878)
*Suraj Prasai,Mengnan Du,Ying Zhang,Fan Yang*

Main category: cs.AI

TL;DR: KnowThyself 是一个简化的聊天式助理，旨在提高大型语言模型的可解释性，使其更易于用户访问和理解。


<details>
  <summary>Details</summary>
Motivation: 现有的可解释性工具分散且代码密集，难以使用；因此开发一个易于访问和使用的工具是必要的。

Method: 通过一个 Orchestrator LLM 重构用户查询，使用 Agent Router 将查询分发到专业模块，并将输出整合为连贯的解释。

Result: KnowThyself 通过简化技术障碍和提供扩展的平台，实现了对 LLM 的有效检查和解释。

Conclusion: KnowThyself 是一个集成的聊天界面助理，增强了大型语言模型的可解释性，提供用户友好的交互和可视化过程。

Abstract: We develop KnowThyself, an agentic assistant that advances large language
model (LLM) interpretability. Existing tools provide useful insights but remain
fragmented and code-intensive. KnowThyself consolidates these capabilities into
a chat-based interface, where users can upload models, pose natural language
questions, and obtain interactive visualizations with guided explanations. At
its core, an orchestrator LLM first reformulates user queries, an agent router
further directs them to specialized modules, and the outputs are finally
contextualized into coherent explanations. This design lowers technical
barriers and provides an extensible platform for LLM inspection. By embedding
the whole process into a conversational workflow, KnowThyself offers a robust
foundation for accessible LLM interpretability.

</details>


### [111] [Extracting Causal Relations in Deep Knowledge Tracing](https://arxiv.org/abs/2511.03948)
*Kevin Hong,Kia Karbasi,Gregory Pottie*

Main category: cs.AI

TL;DR: 本研究表明，DKT模型的有效性主要体现在其建模知识组件之间的因果依赖关系，而非以往认为的双向关系。


<details>
  <summary>Details</summary>
Motivation: 挑战现有对DKT有效性解释的主流观点，探讨其在因果结构建模上的潜力。

Method: 通过将练习关系图修剪为有向无环图(DAG)并在Assistments数据集的因果子集上训练DKT，验证其预测能力与因果结构的强相关性。

Result: 提出了一种新的提取练习关系DAG的方法，并为DKT模型在因果建模上的优势提供了实证支持。

Conclusion: DKT模型的有效性主要源于其近似知识组件之间因果依赖关系的能力，而不仅仅是简单的关系映射。

Abstract: A longstanding goal in computational educational research is to develop
explainable knowledge tracing (KT) models. Deep Knowledge Tracing (DKT), which
leverages a Recurrent Neural Network (RNN) to predict student knowledge and
performance on exercises, has been proposed as a major advancement over
traditional KT methods. Several studies suggest that its performance gains stem
from its ability to model bidirectional relationships between different
knowledge components (KCs) within a course, enabling the inference of a
student's understanding of one KC from their performance on others. In this
paper, we challenge this prevailing explanation and demonstrate that DKT's
strength lies in its implicit ability to model prerequisite relationships as a
causal structure, rather than bidirectional relationships. By pruning exercise
relation graphs into Directed Acyclic Graphs (DAGs) and training DKT on causal
subsets of the Assistments dataset, we show that DKT's predictive capabilities
align strongly with these causal structures. Furthermore, we propose an
alternative method for extracting exercise relation DAGs using DKT's learned
representations and provide empirical evidence supporting our claim. Our
findings suggest that DKT's effectiveness is largely driven by its capacity to
approximate causal dependencies between KCs rather than simple relational
mappings.

</details>


### [112] [LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing](https://arxiv.org/abs/2511.03980)
*Bram Bulté,Ayla Rigouts Terryn*

Main category: cs.AI

TL;DR: 本研究探讨大型语言模型在不同文化背景下的响应偏见，发现其无法准确代表文化多样性。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型与文化价值之间的关系，以评估其在全球多样化用户中的表现。

Method: 通过对10种大型语言模型进行测试，使用翻译成11种语言的63个项，并结合不同的文化视角进行提示。

Result: 确实存在提示语言和文化视角产生的输出变异，但模型仍倾向于反映特定国家的主导价值观。

Conclusion: 大型语言模型在不同文化背景下的响应存在系统性偏见，无法充分代表文化多样性。

Abstract: Large Language Models (LLMs) are rapidly being adopted by users across the
globe, who interact with them in a diverse range of languages. At the same
time, there are well-documented imbalances in the training data and
optimisation objectives of this technology, raising doubts as to whether LLMs
can represent the cultural diversity of their broad user base. In this study,
we look at LLMs and cultural values and examine how prompt language and
cultural framing influence model responses and their alignment with human
values in different countries. We probe 10 LLMs with 63 items from the Hofstede
Values Survey Module and World Values Survey, translated into 11 languages, and
formulated as prompts with and without different explicit cultural
perspectives. Our study confirms that both prompt language and cultural
perspective produce variation in LLM outputs, but with an important caveat:
While targeted prompting can, to a certain extent, steer LLM responses in the
direction of the predominant values of the corresponding countries, it does not
overcome the models' systematic bias toward the values associated with a
restricted set of countries in our dataset: the Netherlands, Germany, the US,
and Japan. All tested models, regardless of their origin, exhibit remarkably
similar patterns: They produce fairly neutral responses on most topics, with
selective progressive stances on issues such as social tolerance. Alignment
with cultural values of human respondents is improved more with an explicit
cultural perspective than with a targeted prompt language. Unexpectedly,
combining both approaches is no more effective than cultural framing with an
English prompt. These findings reveal that LLMs occupy an uncomfortable middle
ground: They are responsive enough to changes in prompts to produce variation,
but too firmly anchored to specific cultural defaults to adequately represent
cultural diversity.

</details>


### [113] [Large language models replicate and predict human cooperation across experiments in game theory](https://arxiv.org/abs/2511.04500)
*Andrea Cera Palatsi,Samuel Martin-Gutierrez,Ana S. Cardenal,Max Pellert*

Main category: cs.AI

TL;DR: 本研究探讨了大型语言模型与人类决策的相似性，开发了一种新的评估框架，发现Llama在模拟人类行为方面表现优异，为社会决策研究提供了新的方法和假设。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在健康、教育和法律等领域的决策及模拟人类行为中的应用日益增加，因此了解LLMs与人类决策的相似性变得至关重要。

Method: 开发了一种游戏理论实验的数字双胞胎，并引入了一种系统的提示和探测框架，以评估机器行为。

Result: 测试了三个开源模型（Llama、Mistral和Qwen），发现Llama能高度忠实于人类合作模式，而Qwen则与纳什均衡预测密切吻合；成功生成并预注册了可测试的新游戏配置的假设。

Conclusion: 适当校准的大型语言模型（LLMs）能够复制群体人类行为模式，并促进对未探索实验空间的系统探讨，提供了与传统社会与行为科学研究互补的方式，生成关于人类社会决策的新实证预测。

Abstract: Large language models (LLMs) are increasingly used both to make decisions in
domains such as health, education and law, and to simulate human behavior. Yet
how closely LLMs mirror actual human decision-making remains poorly understood.
This gap is critical: misalignment could produce harmful outcomes in practical
applications, while failure to replicate human behavior renders LLMs
ineffective for social simulations. Here, we address this gap by developing a
digital twin of game-theoretic experiments and introducing a systematic
prompting and probing framework for machine-behavioral evaluation. Testing
three open-source models (Llama, Mistral and Qwen), we find that Llama
reproduces human cooperation patterns with high fidelity, capturing human
deviations from rational choice theory, while Qwen aligns closely with Nash
equilibrium predictions. Notably, we achieved population-level behavioral
replication without persona-based prompting, simplifying the simulation
process. Extending beyond the original human-tested games, we generate and
preregister testable hypotheses for novel game configurations outside the
original parameter grid. Our findings demonstrate that appropriately calibrated
LLMs can replicate aggregate human behavioral patterns and enable systematic
exploration of unexplored experimental spaces, offering a complementary
approach to traditional research in the social and behavioral sciences that
generates new empirical predictions about human social decision-making.

</details>


### [114] [Detecting Silent Failures in Multi-Agentic AI Trajectories](https://arxiv.org/abs/2511.04032)
*Divya Pathak,Harshit Kumar,Anuska Roy,Felix George,Mudit Verma,Pratibha Moogi*

Main category: cs.AI

TL;DR: 本文介绍了多智能体人工智能系统中异常检测的任务，构建了数据集并测试了检测方法，取得了较高的准确性。


<details>
  <summary>Details</summary>
Motivation: 为识别多智能体人工智能系统中难以检测的异常情况（如漂移、循环和输出缺失）而引入异常检测任务。

Method: 通过对用户行为、智能体非确定性和大型语言模型变异的捕捉，构建数据集标注管道，并使用XGBoost和SVDD算法进行基准测试。

Result: 在构建的两个基准数据集上，监督学习方法（XGBoost）和半监督学习方法（SVDD）表现良好，分别达到了98%和96%的准确性。

Conclusion: 本文首次系统研究了多智能体人工智能系统中的异常检测，提供了数据集、基准测试及指导未来研究的见解。

Abstract: Multi-Agentic AI systems, powered by large language models (LLMs), are
inherently non-deterministic and prone to silent failures such as drift,
cycles, and missing details in outputs, which are difficult to detect. We
introduce the task of anomaly detection in agentic trajectories to identify
these failures and present a dataset curation pipeline that captures user
behavior, agent non-determinism, and LLM variation. Using this pipeline, we
curate and label two benchmark datasets comprising \textbf{4,275 and 894}
trajectories from Multi-Agentic AI systems. Benchmarking anomaly detection
methods on these datasets, we show that supervised (XGBoost) and
semi-supervised (SVDD) approaches perform comparably, achieving accuracies up
to 98% and 96%, respectively. This work provides the first systematic study of
anomaly detection in Multi-Agentic AI systems, offering datasets, benchmarks,
and insights to guide future research.

</details>


### [115] [Interpreting Multi-Attribute Confounding through Numerical Attributes in Large Language Models](https://arxiv.org/abs/2511.04053)
*Hirohane Takagi,Gouki Minegishi,Shota Kizawa,Issey Sukeda,Hitomi Yanaka*

Main category: cs.AI

TL;DR: 本研究探讨了大语言模型如何处理数字属性及无关上下文对决策的影响，发现其在决策中存在脆弱性，并为改进提供了基础。


<details>
  <summary>Details</summary>
Motivation: 尽管行为研究已经记录了大语言模型中的数字推理错误，但其潜在的表征机制仍不清楚，因此我们探索如何集成多个数字属性以及无关上下文如何扰动这些表示。

Method: 采用线性探测、偏相关分析和基于提示的脆弱性测试，针对不同规模的模型进行研究。

Result: 研究结果表明，大语言模型编码了真实世界的数字相关性，但往往会系统性地放大这些相关性。此外，无关上下文引发了幅度表征的一致性变化，且下游影响因模型规模而异。

Conclusion: 这项研究揭示了大语言模型在决策过程中存在的脆弱性，并为多属性纠缠下的公平、具表征意识的控制奠定了基础。

Abstract: Although behavioral studies have documented numerical reasoning errors in
large language models (LLMs), the underlying representational mechanisms remain
unclear. We hypothesize that numerical attributes occupy shared latent
subspaces and investigate two questions:(1) How do LLMs internally integrate
multiple numerical attributes of a single entity? (2)How does irrelevant
numerical context perturb these representations and their downstream outputs?
To address these questions, we combine linear probing with partial correlation
analysis and prompt-based vulnerability tests across models of varying sizes.
Our results show that LLMs encode real-world numerical correlations but tend to
systematically amplify them. Moreover, irrelevant context induces consistent
shifts in magnitude representations, with downstream effects that vary by model
size. These findings reveal a vulnerability in LLM decision-making and lay the
groundwork for fairer, representation-aware control under multi-attribute
entanglement.

</details>


### [116] [DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration](https://arxiv.org/abs/2511.04646)
*Narjes Nourzad,Hanqing Yang,Shiyu Chen,Carlee Joe-Wong*

Main category: cs.AI

TL;DR: 本文提出了一个去中心化的神经符号框架DR. WELL，利用动态世界模型改善了多智能体合作规划的效率，特别是在协商和自我优化过程中提升了任务完成率。


<details>
  <summary>Details</summary>
Motivation: 在多智能体规划中，部分信息和有限的通信导致协调困难，而符号规划通过抽象化来解决小的时间或运动偏差引发的冲突。

Method: 论文提出了一种二阶段的协商协议，智能体先提出角色候选，然后在共识和环境约束下进行承诺，最后独立生成和执行符号计划。

Result: 实验表明，动态世界模型提升了任务完成率和效率，同时智能体在多个任务中展现出了适应能力和自我优化的过程。

Conclusion: DR. WELL通过引入去中心化的神经符号框架和动态世界模型，提升了多智能体合作规划的效率和任务完成率，展示了协作机制的有效性和自我优化的能力。

Abstract: Cooperative multi-agent planning requires agents to make joint decisions with
partial information and limited communication. Coordination at the trajectory
level often fails, as small deviations in timing or movement cascade into
conflicts. Symbolic planning mitigates this challenge by raising the level of
abstraction and providing a minimal vocabulary of actions that enable
synchronization and collective progress. We present DR. WELL, a decentralized
neurosymbolic framework for cooperative multi-agent planning. Cooperation
unfolds through a two-phase negotiation protocol: agents first propose
candidate roles with reasoning and then commit to a joint allocation under
consensus and environment constraints. After commitment, each agent
independently generates and executes a symbolic plan for its role without
revealing detailed trajectories. Plans are grounded in execution outcomes via a
shared world model that encodes the current state and is updated as agents act.
By reasoning over symbolic plans rather than raw trajectories, DR. WELL avoids
brittle step-level alignment and enables higher-level operations that are
reusable, synchronizable, and interpretable. Experiments on cooperative
block-push tasks show that agents adapt across episodes, with the dynamic world
model capturing reusable patterns and improving task completion rates and
efficiency. Experiments on cooperative block-push tasks show that our dynamic
world model improves task completion and efficiency through negotiation and
self-refinement, trading a time overhead for evolving, more efficient
collaboration strategies.

</details>


### [117] [KGFR: A Foundation Retriever for Generalized Knowledge Graph Question Answering](https://arxiv.org/abs/2511.04093)
*Yuanning Cui,Zequn Sun,Wei Hu,Zhangjie Fu*

Main category: cs.AI

TL;DR: LLM-KGFR 是一种新型框架，通过结合大语言模型和知识图谱检索器，解决知识密集型问题，验证了其优越的可扩展性和强大的推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在知识密集型问题上因上下文和参数知识限制而表现不佳的问题。

Method: 采用 LLM 和 KGFR 共同框架，利用对称渐进传播（APP）策略在大规模图中有效提取信息。

Result: 实验表明，LLM-KGFR 在性能上表现出色，同时保持良好的可扩展性和泛化能力。

Conclusion: LLM-KGFR 提供了一种有效的解决方案，用于知识图谱增强的推理，兼具可扩展性和泛化能力。

Abstract: Large language models (LLMs) excel at reasoning but struggle with
knowledge-intensive questions due to limited context and parametric knowledge.
However, existing methods that rely on finetuned LLMs or GNN retrievers are
limited by dataset-specific tuning and scalability on large or unseen graphs.
We propose the LLM-KGFR collaborative framework, where an LLM works with a
structured retriever, the Knowledge Graph Foundation Retriever (KGFR). KGFR
encodes relations using LLM-generated descriptions and initializes entities
based on their roles in the question, enabling zero-shot generalization to
unseen KGs. To handle large graphs efficiently, it employs Asymmetric
Progressive Propagation (APP)- a stepwise expansion that selectively limits
high-degree nodes while retaining informative paths. Through node-, edge-, and
path-level interfaces, the LLM iteratively requests candidate answers,
supporting facts, and reasoning paths, forming a controllable reasoning loop.
Experiments demonstrate that LLM-KGFR achieves strong performance while
maintaining scalability and generalization, providing a practical solution for
KG-augmented reasoning.

</details>


### [118] [Testing the Testers: Human-Driven Quality Assessment of Voice AI Testing Platforms](https://arxiv.org/abs/2511.04133)
*Miguel E. Andres,Vadim Fedorov,Rida Sadek,Enric Spagnolo-Arrizabalaga,Nadescha Trudel*

Main category: cs.AI

TL;DR: 提出了一种系统框架用于评估语音人工智能测试质量，结合心理测量学技术和统计验证，通过对三大商业平台的评估，揭示了显著的性能差异，使得研究人员和组织能够更好地验证测试能力。


<details>
  <summary>Details</summary>
Motivation: 随着语音人工智能向数十亿次日常交互的规模发展，确保测试可靠性的方法仍未系统化，因此存在关键的测量差距。

Method: 结合心理测量学技术（成对比较产生Elo评分、引导置信区间和置换检验）与严格的统计验证，为任何测试方法提供可重复的度量标准。

Result: 在对三种领先的商业平台进行实证评估后，结果显示使用该框架可揭示统计显著的性能差异，Evalion平台以0.92的评估质量（f1-score）领先其他平台的0.73，模拟质量为0.61，高于其他平台的0.43。

Conclusion: 提出的框架能够帮助研究人员和组织实证验证任何平台的测试能力，提供信心以支持大规模部署语音人工智能。

Abstract: Voice AI agents are rapidly transitioning to production deployments, yet
systematic methods for ensuring testing reliability remain underdeveloped.
Organizations cannot objectively assess whether their testing approaches
(internal tools or external platforms) actually work, creating a critical
measurement gap as voice AI scales to billions of daily interactions.
  We present the first systematic framework for evaluating voice AI testing
quality through human-centered benchmarking. Our methodology addresses the
fundamental dual challenge of testing platforms: generating realistic test
conversations (simulation quality) and accurately evaluating agent responses
(evaluation quality). The framework combines established psychometric
techniques (pairwise comparisons yielding Elo ratings, bootstrap confidence
intervals, and permutation tests) with rigorous statistical validation to
provide reproducible metrics applicable to any testing approach.
  To validate the framework and demonstrate its utility, we conducted
comprehensive empirical evaluation of three leading commercial platforms
focused on Voice AI Testing using 21,600 human judgments across 45 simulations
and ground truth validation on 60 conversations. Results reveal statistically
significant performance differences with the proposed framework, with the
top-performing platform, Evalion, achieving 0.92 evaluation quality measured as
f1-score versus 0.73 for others, and 0.61 simulation quality using a league
based scoring system (including ties) vs 0.43 for other platforms.
  This framework enables researchers and organizations to empirically validate
the testing capabilities of any platform, providing essential measurement
foundations for confident voice AI deployment at scale. Supporting materials
are made available to facilitate reproducibility and adoption.

</details>


### [119] [Opus: A Quantitative Framework for Workflow Evaluation](https://arxiv.org/abs/2511.04220)
*Alan Seroul,Théo Fagnoni,Inès Adnani,Dana O. Mohamed,Phillip Kingston*

Main category: cs.AI

TL;DR: 本文介绍了一种新的工作流评估框架，该框架通过整合奖励和惩罚机制，量化工作流的质量与效率，从而实现工作流的自动评估和优化。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在提升现代自动化系统中工作流的评估和优化能力，以便更好地支持自动化流程的发现和改进。

Method: 本文采用了概率规范方法，结合了工作流奖励模型和惩罚机制，构建了一个数学模型。

Result: 通过引入Opus工作流奖励和规范惩罚的集成，本框架能够自动评估和优化工作流，并能够在强化学习中应用。

Conclusion: 本研究提出了一种综合考虑正确性、可靠性和成本的工作流评估框架，能够量化工作流的质量和效率，并通过惩罚机制优化工作流。

Abstract: This paper introduces the Opus Workflow Evaluation Framework, a
probabilistic-normative formulation for quantifying Workflow quality and
efficiency. It integrates notions of correctness, reliability, and cost into a
coherent mathematical model that enables direct comparison, scoring, and
optimization of Workflows. The framework combines the Opus Workflow Reward, a
probabilistic function estimating expected performance through success
likelihood, resource usage, and output gain, with the Opus Workflow Normative
Penalties, a set of measurable functions capturing structural and informational
quality across Cohesion, Coupling, Observability, and Information Hygiene. It
supports automated Workflow assessment, ranking, and optimization within modern
automation systems such as Opus and can be integrated into Reinforcement
Learning loops to guide Workflow discovery and refinement. In this paper, we
introduce the Opus Workflow Reward model that formalizes Workflow success as a
probabilistic expectation over costs and outcomes. We define measurable Opus
Workflow Normative Penalties capturing structural, semantic, and signal-related
properties of Workflows. Finally, we propose a unified optimization formulation
for identifying and ranking optimal Workflows under joint Reward-Penalty
trade-offs.

</details>


### [120] [Shared Spatial Memory Through Predictive Coding](https://arxiv.org/abs/2511.04235)
*Zhengru Fang,Yu Guo,Jingjing Wang,Yuang Zhang,Haonan An,Yinhai Wang,Yuguang Fang*

Main category: cs.AI

TL;DR: 本文提出了一种多智能体预测编码框架，促进智能体之间的有效通信，并在Memory-Maze基准测试中展现出对带宽限制的卓越适应能力。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，通过共享和重构一致的空间记忆应对部分可观测性和有限带宽带来的协调挑战。

Method: 提出了一种多智能体预测编码框架，通过最小化智能体之间的互不确定性来实现协调，并利用信息瓶颈目标实现有效的通信机制。

Result: 在Memory-Maze基准测试中，提出的方法在带宽限制下表现出优异的鲁棒性，成功率从128位/步的73.5%逐渐降低到4位/步的64.4%。

Conclusion: 本文建立了一种理论基础与生物上可行的方法，解释了复杂社会表征如何从统一的预测驱动力中产生，最终形成社会集体智能。

Abstract: Sharing and reconstructing a consistent spatial memory is a critical
challenge in multi-agent systems, where partial observability and limited
bandwidth often lead to catastrophic failures in coordination. We introduce a
multi-agent predictive coding framework that formulate coordination as the
minimization of mutual uncertainty among agents. Instantiated as an information
bottleneck objective, it prompts agents to learn not only who and what to
communicate but also when. At the foundation of this framework lies a
grid-cell-like metric as internal spatial coding for self-localization,
emerging spontaneously from self-supervised motion prediction. Building upon
this internal spatial code, agents gradually develop a bandwidth-efficient
communication mechanism and specialized neural populations that encode
partners' locations: an artificial analogue of hippocampal social place cells
(SPCs). These social representations are further enacted by a hierarchical
reinforcement learning policy that actively explores to reduce joint
uncertainty. On the Memory-Maze benchmark, our approach shows exceptional
resilience to bandwidth constraints: success degrades gracefully from 73.5% to
64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast
baseline collapses from 67.6% to 28.6%. Our findings establish a theoretically
principled and biologically plausible basis for how complex social
representations emerge from a unified predictive drive, leading to social
collective intelligence.

</details>


### [121] [RLoop: An Self-Improving Framework for Reinforcement Learning with Iterative Policy Initialization](https://arxiv.org/abs/2511.04285)
*Zeng Zhiyuan,Jiashuo Liu,Zhangyue Yin,Ge Zhang,Wenhao Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: RLoop是一种新框架，通过迭代初始化解决强化学习中的过拟合问题，提升模型的泛化能力和性能。


<details>
  <summary>Details</summary>
Motivation: 针对强化学习中的过拟合问题，尤其是策略过度专门化和训练过程中多样化解决方案的灾难性遗忘。

Method: 提出了一种自我改进框架RLoop，通过迭代策略初始化，将标准训练过程转变为一个探索与利用的良性循环。

Result: RLoop通过强化学习探索解决方案空间，并利用成功的轨迹形成专家数据集，再通过拒绝采样微调（RFT）来提升初始策略，从而在迭代中更好地利用策略变化。

Conclusion: RLoop显著减少了遗忘现象并显著提升了模型的泛化能力，相较于传统的强化学习，平均准确率提高了9%，在pass@32指标上提升超过15%。

Abstract: While Reinforcement Learning for Verifiable Rewards (RLVR) is powerful for
training large reasoning models, its training dynamics harbor a critical
challenge: RL overfitting, where models gain training rewards but lose
generalization. Our analysis reveals this is driven by policy
over-specialization and catastrophic forgetting of diverse solutions generated
during training. Standard optimization discards this valuable inter-step policy
diversity. To address this, we introduce RLoop, a self-improving framework
built on iterative policy initialization. RLoop transforms the standard
training process into a virtuous cycle: it first uses RL to explore the
solution space from a given policy, then filters the successful trajectories to
create an expert dataset. This dataset is used via Rejection-sampling
Fine-Tuning (RFT) to refine the initial policy, creating a superior starting
point for the next iteration. This loop of exploration and exploitation via
iterative re-initialization effectively converts transient policy variations
into robust performance gains. Our experiments show RLoop mitigates forgetting
and substantially improves generalization, boosting average accuracy by 9% and
pass@32 by over 15% compared to vanilla RL.

</details>


### [122] [Probing the Probes: Methods and Metrics for Concept Alignment](https://arxiv.org/abs/2511.04312)
*Jacob Lysnæs-Larsen,Marte Eggen,Inga Strümke*

Main category: cs.AI

TL;DR: 探讨了概念激活向量的探针准确率并不可靠，提出了新的概念定位方法和评估指标，以提高概念对齐。


<details>
  <summary>Details</summary>
Motivation: 传统上，高探针准确率被认为代表了良好的概念对齐，但这并不可靠。探针可能捕捉到偶然相关性，而非真正的目标概念。

Method: 提出了一种基于空间线性归因的概念定位方法，并与现有的特征可视化技术进行了全面比较。

Result: 通过引入新的概念定位方法和三个定量评估指标，研究表明，具有平移不变性和空间对齐的探针能有效提高概念对齐。

Conclusion: 我们强调了在评估概念对齐时，应采用基于对齐的评估指标，而非简单的探针准确率。

Abstract: In explainable AI, Concept Activation Vectors (CAVs) are typically obtained
by training linear classifier probes to detect human-understandable concepts as
directions in the activation space of deep neural networks. It is widely
assumed that a high probe accuracy indicates a CAV faithfully representing its
target concept. However, we show that the probe's classification accuracy alone
is an unreliable measure of concept alignment, i.e., the degree to which a CAV
captures the intended concept. In fact, we argue that probes are more likely to
capture spurious correlations than they are to represent only the intended
concept. As part of our analysis, we demonstrate that deliberately misaligned
probes constructed to exploit spurious correlations, achieve an accuracy close
to that of standard probes. To address this severe problem, we introduce a
novel concept localization method based on spatial linear attribution, and
provide a comprehensive comparison of it to existing feature visualization
techniques for detecting and mitigating concept misalignment. We further
propose three classes of metrics for quantitatively assessing concept
alignment: hard accuracy, segmentation scores, and augmentation robustness. Our
analysis shows that probes with translation invariance and spatial alignment
consistently increase concept alignment. These findings highlight the need for
alignment-based evaluation metrics rather than probe accuracy, and the
importance of tailoring probes to both the model architecture and the nature of
the target concept.

</details>


### [123] [AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research](https://arxiv.org/abs/2511.04316)
*Tim Beyer,Jonas Dornbusch,Jakob Steimle,Moritz Ladenburger,Leo Schwinn,Stephan Günnemann*

Main category: cs.AI

TL;DR: 为了解决大语言模型安全研究中的碎片化问题，本文介绍了AdversariaLLM工具箱，专注于可复现性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 应对LLM安全研究中实现、数据集和评估方法的碎片化问题，促进研究的可复现性和可比性。

Method: 开发了一个包含12种对抗攻击算法和7个基准数据集的工具箱，提供了计算资源跟踪、决定性结果等高级特性。

Result: AdversariaLLM能够有效集成开源的LLM，促进安全和鲁棒性研究的进展。

Conclusion: AdversariaLLM工具箱为LLM安全领域的研究提供了一个透明、可比和可复现的基础。

Abstract: The rapid expansion of research on Large Language Model (LLM) safety and
robustness has produced a fragmented and oftentimes buggy ecosystem of
implementations, datasets, and evaluation methods. This fragmentation makes
reproducibility and comparability across studies challenging, hindering
meaningful progress. To address these issues, we introduce AdversariaLLM, a
toolbox for conducting LLM jailbreak robustness research. Its design centers on
reproducibility, correctness, and extensibility. The framework implements
twelve adversarial attack algorithms, integrates seven benchmark datasets
spanning harmfulness, over-refusal, and utility evaluation, and provides access
to a wide range of open-weight LLMs via Hugging Face. The implementation
includes advanced features for comparability and reproducibility such as
compute-resource tracking, deterministic results, and distributional evaluation
techniques. \name also integrates judging through the companion package
JudgeZoo, which can also be used independently. Together, these components aim
to establish a robust foundation for transparent, comparable, and reproducible
research in LLM safety.

</details>


### [124] [RxSafeBench: Identifying Medication Safety Issues of Large Language Models in Simulated Consultation](https://arxiv.org/abs/2511.04328)
*Jiahao Zhao,Luxin Xu,Minghuan Tan,Lichao Zhang,Ahmadreza Argha,Hamid Alinejad-Rokny,Min Yang*

Main category: cs.AI

TL;DR: 本文提出了一个评估大语言模型药物安全的新框架，并构建了RxRisk DB数据库和RxSafeBench基准，发现现有模型在药物安全推荐中仍有重要挑战。


<details>
  <summary>Details</summary>
Motivation: 医用大语言模型在药物安全方面的研究较少，缺乏现实世界的数据集，因此需要建立一个评估框架来填补这一空白。

Method: 构建了一个模拟临床咨询的框架，通过生成包含药物风险的诊断对话，创建了包含大量药物相关数据的数据库，并通过结构化的多项选择题评估LLM的表现。

Result: 评估结果显示目前的语言模型在整合禁忌和相互作用知识方面存在困难，尤其是当风险隐含而非明确时。

Conclusion: 本研究提出的RxSafeBench为评估LLM在药物安全方面提供了全面的基准，有助于提升AI驱动的临床决策支持的安全性和可靠性。

Abstract: Numerous medical systems powered by Large Language Models (LLMs) have
achieved remarkable progress in diverse healthcare tasks. However, research on
their medication safety remains limited due to the lack of real world datasets,
constrained by privacy and accessibility issues. Moreover, evaluation of LLMs
in realistic clinical consultation settings, particularly regarding medication
safety, is still underexplored. To address these gaps, we propose a framework
that simulates and evaluates clinical consultations to systematically assess
the medication safety capabilities of LLMs. Within this framework, we generate
inquiry diagnosis dialogues with embedded medication risks and construct a
dedicated medication safety database, RxRisk DB, containing 6,725
contraindications, 28,781 drug interactions, and 14,906 indication-drug pairs.
A two-stage filtering strategy ensures clinical realism and professional
quality, resulting in the benchmark RxSafeBench with 2,443 high-quality
consultation scenarios. We evaluate leading open-source and proprietary LLMs
using structured multiple choice questions that test their ability to recommend
safe medications under simulated patient contexts. Results show that current
LLMs struggle to integrate contraindication and interaction knowledge,
especially when risks are implied rather than explicit. Our findings highlight
key challenges in ensuring medication safety in LLM-based systems and provide
insights into improving reliability through better prompting and task-specific
tuning. RxSafeBench offers the first comprehensive benchmark for evaluating
medication safety in LLMs, advancing safer and more trustworthy AI-driven
clinical decision support.

</details>


### [125] [Monitor-Generate-Verify (MGV):Formalising Metacognitive Theory for Language Model Reasoning](https://arxiv.org/abs/2511.04341)
*Nick Oh,Fernand Gobet*

Main category: cs.AI

TL;DR: MGV框架通过引入监控过程来改进推理架构，提供了系统性理解失败的方法和未来设计的干预建议。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有推理架构中缺乏监控过程导致的推理效率问题，避免早期承诺于次优路径。

Method: 提出了监控-生成-验证（MGV）框架，结合了元认知理论与计算规格，以改善推理过程的设计。

Result: MGV框架扩展了现有的生成-验证范式，包含了从困难评估到信心判断的元认知体验。

Conclusion: MGV框架通过引入显式监控来促进推理过程的优化，提供了对推理系统失败的理解，并提出了未来设计的具体干预建议。

Abstract: Test-time reasoning architectures such as those following the Generate-Verify
paradigm -- where a model iteratively refines or verifies its own generated
outputs -- prioritise generation and verification but exclude the monitoring
processes that determine when and how reasoning should begin. This omission may
contribute to the prefix dominance trap, in which models commit early to
suboptimal reasoning paths and seldom recover, yielding roughly 20% accuracy
loss. We address this architectural gap by formalising Flavell's and Nelson and
Narens' metacognitive theories into computational specifications, proposing the
Monitor-Generate-Verify (MGV) framework. MGV extends the Generate-Verify
paradigm by adding explicit monitoring that captures metacognitive experiences
(from difficulty assessments to confidence judgements) before generation begins
and refines future monitoring through verification feedback. Though we present
no empirical validation, this work provides the first systematic computational
translation of foundational metacognitive theories, offering a principled
vocabulary for understanding reasoning system failures and suggesting specific
architectural interventions for future test-time reasoning designs.

</details>


### [126] [Post-Training LLMs as Better Decision-Making Agents: A Regret-Minimization Approach](https://arxiv.org/abs/2511.04393)
*Chanwoo Park,Ziyang Chen,Asuman Ozdaglar,Kaiqing Zhang*

Main category: cs.AI

TL;DR: 提出了一种新的后训练流程Iterative RMFT，显著提高了大语言模型在决策制定中的性能和灵活性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型未针对决策制定设计，研究表明它们在在线决策问题中表现不佳，因此需要改进。

Method: 引入逐步后悔最小化微调（Iterative RMFT）程序，通过反复提取低后悔的决策轨迹进行模型微调。

Result: 实证结果表明，Iterative RMFT在不同模型的决策表现上均有提升，包括Transformer、开放权重LLMs及如GPT-4o mini等高级闭合权重模型。

Conclusion: Iterative RMFT为增强大语言模型的决策能力提供了一种原则性和通用性的后训练框架。

Abstract: Large language models (LLMs) are increasingly deployed as "agents" for
decision-making (DM) in interactive and dynamic environments. Yet, since they
were not originally designed for DM, recent studies show that LLMs can struggle
even in basic online DM problems, failing to achieve low regret or an effective
exploration-exploitation tradeoff. To address this, we introduce Iterative
Regret-Minimization Fine-Tuning (Iterative RMFT), a post-training procedure
that repeatedly distills low-regret decision trajectories back into the base
model. At each iteration, the model rolls out multiple decision trajectories,
selects the k-lowest regret ones, and fine-tunes itself on them. Unlike prior
methods that (a) distill action sequences from known DM algorithms or (b) rely
on manually crafted chain-of-thought templates, our approach leverages the
regret metric to elicit the model's own DM ability and reasoning rationales.
This reliance on model-generated reasoning avoids rigid output engineering and
provides more flexible, natural-language training signals. Empirical results
show that Iterative RMFT improves LLMs' DM performance across diverse models -
from Transformers with numerical input/output, to open-weight LLMs, and
advanced closed-weight models like GPT-4o mini. Its flexibility in output and
reasoning formats enables generalization across tasks with varying horizons,
action spaces, reward processes, and natural-language contexts. Finally, we
provide theoretical insight showing that a single-layer Transformer under this
paradigm can act as a no-regret learner in a simplified setting. Overall,
Iterative RMFT offers a principled and general post-training framework for
enhancing LLMs' decision-making capabilities.

</details>


### [127] [Are We Asking the Right Questions? On Ambiguity in Natural Language Queries for Tabular Data Analysis](https://arxiv.org/abs/2511.04584)
*Daniel Gomm,Cornelius Wolff,Madelon Hulsebos*

Main category: cs.AI

TL;DR: 本研究提出一种框架，将模糊性视为合作特征，以改善自然语言接口的设计与评估，并分析了15个数据集中的查询。


<details>
  <summary>Details</summary>
Motivation: 旨在处理自然语言接口中固有的查询模糊性，并转变为一种合作的视角。

Method: 通过框架对15个流行数据集中的查询进行分析，识别合作与非合作查询。

Result: 分析揭示了查询类型的混合情况，影响了系统执行准确性和解读能力的评估，提出了未来研究的方向与影响。

Conclusion: 提出了一种将模糊性视为合作交互特征的框架，以改善自然语言与表格数据接口的设计与评估，强调用户与系统在查询规范中的共同责任。

Abstract: Natural language interfaces to tabular data must handle ambiguities inherent
to queries. Instead of treating ambiguity as a deficiency, we reframe it as a
feature of cooperative interaction, where the responsibility of query
specification is shared among the user and the system. We develop a principled
framework distinguishing cooperative queries, i.e., queries that yield a
resolvable interpretation, from uncooperative queries that cannot be resolved.
Applying the framework to evaluations for tabular question answering and
analysis, we analyze the queries in 15 popular datasets, and observe an
uncontrolled mixing of query types neither adequate for evaluating a system's
execution accuracy nor for evaluating interpretation capabilities. Our
framework and analysis of queries shifts the perspective from fixing ambiguity
to embracing cooperation in resolving queries. This reflection enables more
informed design and evaluation for natural language interfaces for tabular
data, for which we outline implications and directions for future research.

</details>


### [128] [The Peril of Preference: Why GRPO fails on Ordinal Rewards](https://arxiv.org/abs/2511.04439)
*Anisha Garg,Ganesh Venkatesh*

Main category: cs.AI

TL;DR: 本文提出CoRPO以改进GRPO在非二元反馈下的问题，通过确保失败解不被正向强化，提高了模型的学习效果。


<details>
  <summary>Details</summary>
Motivation: 为LLMs提供更丰富的反馈，以便在强化学习中能够学习真正的新能力。

Method: 提出了Correctness Relative Policy Optimization（CoRPO）作为新的优化方法，使用自适应基线和最小质量阈值。

Result: 在代码验证任务中，CoRPO显示出更稳定的收敛性和更好的领域外泛化能力。

Conclusion: CoRPO有效解决了GRPO在使用非二元反馈时的不足，提升了模型的稳定性和泛化能力。

Abstract: Group-relative Policy Optimization's (GRPO) simplicity makes it highly
desirable for adapting LLMs to become experts at specific tasks. But this
simplicity also makes it ill-specified as we seek to enhance RL training with
richer, non-binary feedback. When using ordinal rewards to give partial credit,
GRPO's simplicity starts to hurt, as its group-average baseline often assigns a
positive advantage to failed trajectories and reinforces incorrect behavior.
  We introduce Correctness Relative Policy Optimization (CoRPO), a new
formulation that solves this flaw. CoRPO uses an adaptive baseline that
enforces a minimum quality threshold, ensuring failed solutions are never
positively reinforced. Once the policy consistently meets this threshold, the
baseline automatically transitions to a relative preference mode, pushing the
model to find optimal solutions rather than just "acceptable" ones. We
empirically validate CoRPO on a code verification task, where it demonstrates
more stable convergence and better out-of-domain generalization.
  This work represents a critical step in our broader research program to
enable LLMs to learn genuinely new capabilities through reinforcement learning.
We achieve this by enabling LLMs to learn from rich, multi-dimensional feedback
- progressing from binary to ordinal rewards in this work, and onward to
denser, per-step supervision.

</details>


### [129] [Optimizing Sensor Placement in Urban Storm Sewers: A Data-Driven Sparse Sensing Approach](https://arxiv.org/abs/2511.04556)
*Zihang Ding,Kun Zhang*

Main category: cs.AI

TL;DR: 本研究提出了一种数据驱动的稀疏传感框架，通过优化传感器布置，实现城市流域的高精度峰值流量重建，有望在资源约束下进行洪水预警和实时控制。


<details>
  <summary>Details</summary>
Motivation: 解决城市排水系统在强降雨情况下的监测与流动预测挑战，同时克服时间、预算和技术上的实际限制。

Method: 使用数据驱动的稀疏传感(DSS)框架，结合EPA-SWMM，优化传感器布置并重建暴雨系统的峰值流量。

Result: 通过在明尼苏达州杜卢斯的Woodland Avenue集水区进行案例研究，验证了DSS框架的有效性，获得了较高的Nash-Sutcliffe效率值（0.92-0.95）。

Conclusion: 该框架能够在资源受限的情况下，实现高精度的流量重建，并可与预测模型结合应用于洪水预警与实时控制。

Abstract: Urban surface water flooding, triggered by intense rainfall overwhelming
drainage systems, is increasingly frequent and widespread. While flood
prediction and monitoring in high spatial-temporal resolution are desired,
practical constraints in time, budget, and technology hinder its full
implementation. How to monitor urban drainage networks and predict flow
conditions under constrained resource is a major challenge. This study presents
a data-driven sparse sensing (DSS) framework, integrated with EPA-SWMM, to
optimize sensor placement and reconstruct peak flowrates in a stormwater
system, using the Woodland Avenue catchment in Duluth, Minnesota, as a case
study. We utilized a SWMM model to generate a training dataset of peak flowrate
profiles across the stormwater network. Furthermore, we applied DSS -
leveraging singular value decomposition for dimensionality reduction and QR
factorization for sensor allocation - to identify the optimal monitoring nodes
based on the simulated training dataset. We then validated the
representativeness of these identified monitoring nodes by comparing the
DSS-reconstructed peak flowrate profiles with those obtained from SWMM. Three
optimally placed sensors among 77 nodes achieved satisfactory reconstruction
performance with Nash-Sutcliffe Efficiency (NSE) values of 0.92-0.95 (25th to
75th percentiles). In addition, the model showed good robustness to uncertainty
in measurements. Its robustness to sensor failures is location-dependent and
improves with the number of sensors deployed. The framework balances
computational efficiency and physical interpretability, enabling high-accuracy
flow reconstruction with minimal sensors. This DSS framework can be further
integrated with predictive models to realize flood early warning and real-time
control under limited sensing and monitoring resource.

</details>


### [130] [Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper](https://arxiv.org/abs/2511.04583)
*Atsuyuki Miyai,Mashiro Toyooka,Takashi Otonari,Zaiying Zhao,Kiyoharu Aizawa*

Main category: cs.AI

TL;DR: Jr. AI Scientist是一种新型自主AI科学家系统，能够模拟学生研究者的核心流程，尽管在论文评审中表现优异，但仍然面临开发风险与挑战。


<details>
  <summary>Details</summary>
Motivation: 为确保可信赖和可持续的AI科学进步，理解AI科学家系统的现有能力和风险是至关重要的。

Method: 开发了Jr. AI Scientist，一种模拟新手研究者核心研究流程的自主AI科学家系统，通过分析基础论文的局限性、提出改进假设、进行严格实验验证以及撰写研究论文。

Result: 通过自动化评估、作者主导评估和提交至专门的AI驱动科学贡献平台，发现Jr. AI Scientist生成的论文在审稿评分上高于现有的完全自动化系统。

Conclusion: Jr. AI Scientist在论文评审中表现优于现有完全自动化系统，但存在不少局限性与开发风险，为未来研究提供了重要挑战与方向。

Abstract: Understanding the current capabilities and risks of AI Scientist systems is
essential for ensuring trustworthy and sustainable AI-driven scientific
progress while preserving the integrity of the academic ecosystem. To this end,
we develop Jr. AI Scientist, a state-of-the-art autonomous AI scientist system
that mimics the core research workflow of a novice student researcher: Given
the baseline paper from the human mentor, it analyzes its limitations,
formulates novel hypotheses for improvement, validates them through rigorous
experimentation, and writes a paper with the results. Unlike previous
approaches that assume full automation or operate on small-scale code, Jr. AI
Scientist follows a well-defined research workflow and leverages modern coding
agents to handle complex, multi-file implementations, leading to scientifically
valuable contributions. For evaluation, we conducted automated assessments
using AI Reviewers, author-led evaluations, and submissions to Agents4Science,
a venue dedicated to AI-driven scientific contributions. The findings
demonstrate that Jr. AI Scientist generates papers receiving higher review
scores than existing fully automated systems. Nevertheless, we identify
important limitations from both the author evaluation and the Agents4Science
reviews, indicating the potential risks of directly applying current AI
Scientist systems and key challenges for future research. Finally, we
comprehensively report various risks identified during development. We hope
these insights will deepen understanding of current progress and risks in AI
Scientist development.

</details>


### [131] [Question the Questions: Auditing Representation in Online Deliberative Processes](https://arxiv.org/abs/2511.04588)
*Soham De,Lodewijk Gelauff,Ashish Goel,Smitha Milli,Ariel Procaccia,Alice Siu*

Main category: cs.AI

TL;DR: 本研究提出了一种审计框架，用于评估协商过程中问题选择的代表性，并分析了不同来源问题的效果。


<details>
  <summary>Details</summary>
Motivation: 在公民大会和协商投票等协商过程中，参与者与专家直接互动的机会至关重要，但由于时间限制，只能选择有限的问题。

Method: 我们提出了一种审计框架，用于测量问题集的代表性水平，并介绍了针对这一问题的初步算法，特别是我们最有效的算法，其运行时间为O(mn log n)。

Result: 通过对比实际提出的问题、参与者的问题以及大型语言模型生成的汇总问题，我们的审计方法突出了不同选择在代表性方面的差异。

Conclusion: 通过引入审计框架，我们能够衡量问题集在代表性方面的有效性，并且我们的研究表明，大型语言模型在支持协商过程中的潜力和局限性。

Abstract: A central feature of many deliberative processes, such as citizens'
assemblies and deliberative polls, is the opportunity for participants to
engage directly with experts. While participants are typically invited to
propose questions for expert panels, only a limited number can be selected due
to time constraints. This raises the challenge of how to choose a small set of
questions that best represent the interests of all participants. We introduce
an auditing framework for measuring the level of representation provided by a
slate of questions, based on the social choice concept known as justified
representation (JR). We present the first algorithms for auditing JR in the
general utility setting, with our most efficient algorithm achieving a runtime
of $O(mn\log n)$, where $n$ is the number of participants and $m$ is the number
of proposed questions. We apply our auditing methods to historical
deliberations, comparing the representativeness of (a) the actual questions
posed to the expert panel (chosen by a moderator), (b) participants' questions
chosen via integer linear programming, (c) summary questions generated by large
language models (LLMs). Our results highlight both the promise and current
limitations of LLMs in supporting deliberative processes. By integrating our
methods into an online deliberation platform that has been used for over
hundreds of deliberations across more than 50 countries, we make it easy for
practitioners to audit and improve representation in future deliberations.

</details>


### [132] [VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks](https://arxiv.org/abs/2511.04662)
*Yu Feng,Nathaniel Weir,Kaj Bostrom,Sam Bayless,Darion Cassel,Sapana Chaudhary,Benjamin Kiesl-Reiter,Huzefa Rangwala*

Main category: cs.AI

TL;DR: VeriCoT是一种新方法，通过形式化CoT推理并验证逻辑有效性，提高了大型语言模型的推理可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在高风险场景中自我推理可靠性的不足，增强其逻辑验证能力。

Method: 采用神经符号方法，将Chain-of-Thought推理的每一步形式化为一阶逻辑，并识别支持论证的前提。

Result: 在多个数据集上实验表明，VeriCoT能够有效识别推理缺陷，并作为最终答案正确性的强预测指标。

Conclusion: VeriCoT通过提取和验证逻辑论证，显著提高了大型语言模型在推理过程中的可靠性和准确性。

Abstract: LLMs can perform multi-step reasoning through Chain-of-Thought (CoT), but
they cannot reliably verify their own logic. Even when they reach correct
answers, the underlying reasoning may be flawed, undermining trust in
high-stakes scenarios. To mitigate this issue, we introduce VeriCoT, a
neuro-symbolic method that extracts and verifies formal logical arguments from
CoT reasoning. VeriCoT formalizes each CoT reasoning step into first-order
logic and identifies premises that ground the argument in source context,
commonsense knowledge, or prior reasoning steps. The symbolic representation
enables automated solvers to verify logical validity while the NL premises
allow humans and systems to identify ungrounded or fallacious reasoning steps.
Experiments on the ProofWriter, LegalBench, and BioASQ datasets show VeriCoT
effectively identifies flawed reasoning, and serves as a strong predictor of
final answer correctness. We also leverage VeriCoT's verification signal for
(1) inference-time self-reflection, (2) supervised fine-tuning (SFT) on
VeriCoT-distilled datasets and (3) preference fine-tuning (PFT) with direct
preference optimization (DPO) using verification-based pairwise rewards,
further improving reasoning validity and accuracy.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [133] [Laugh, Relate, Engage: Stylized Comment Generation for Short Videos](https://arxiv.org/abs/2511.03757)
*Xuan Ouyang,Senan Wang,Bouzhou Wang,Siyuan Xiahou,Jinrong Zhou,Yuekang Li*

Main category: cs.LG

TL;DR: 研究开发了LOLGORITHM系统，用于高效生成符合短视频平台规范的多样化评论，显著提升用户互动体验。


<details>
  <summary>Details</summary>
Motivation: 应对短视频平台上符合规定且具有多样性和上下文意识的评论生成挑战。

Method: 采用模块化多智能体系统（MAS），集成视频分割、上下文及情感分析，支持多种评论风格的生成。

Result: LOLGORITHM在评论生成效果上超越基准模型，尤其在抖音上达到90%以上的偏好率。

Conclusion: LOLGORITHM系统在生成短视频评论方面表现优异，显著提升了用户参与度和创意互动。

Abstract: Short-video platforms have become a central medium in the modern Internet
landscape, where efficient information delivery and strong interactivity are
reshaping user engagement and cultural dissemination. Among the various forms
of user interaction, comments play a vital role in fostering community
participation and enabling content re-creation. However, generating comments
that are both compliant with platform guidelines and capable of exhibiting
stylistic diversity and contextual awareness remains a significant challenge.
We introduce LOLGORITHM, a modular multi-agent system (MAS) designed for
controllable short-video comment generation. The system integrates video
segmentation, contextual and affective analysis, and style-aware prompt
construction. It supports six distinct comment styles: puns (homophones),
rhyming, meme application, sarcasm (irony), plain humor, and content
extraction. Powered by a multimodal large language model (MLLM), LOLGORITHM
directly processes video inputs and achieves fine-grained style control through
explicit prompt markers and few-shot examples. To support development and
evaluation, we construct a bilingual dataset using official APIs from Douyin
(Chinese) and YouTube (English), covering five popular video genres: comedy
skits, daily life jokes, funny animal clips, humorous commentary, and talk
shows. Evaluation combines automated metrics originality, relevance, and style
conformity with a large-scale human preference study involving 40 videos and
105 participants. Results show that LOLGORITHM significantly outperforms
baseline models, achieving preference rates of over 90% on Douyin and 87.55% on
YouTube. This work presents a scalable and culturally adaptive framework for
stylized comment generation on short-video platforms, offering a promising path
to enhance user engagement and creative interaction.

</details>


### [134] [What's in Common? Multimodal Models Hallucinate When Reasoning Across Scenes](https://arxiv.org/abs/2511.03768)
*Candace Ross,Florian Bordes,Adina Williams,Polina Kirichenko,Mark Ibrahim*

Main category: cs.LG

TL;DR: 研究了多模态语言模型在真实场景推理中面临的幻觉问题，创建了Common-O基准以评估推理能力，结果表明现有模型在复杂场景推理中效果不佳。


<details>
  <summary>Details</summary>
Motivation: 解决当前多模态语言模型在实际推理中面临的幻想和能力缺口，特别是在复杂场景中的推理问题。

Method: 建立了一个名为Common-O的新基准，包含超过10.5k个使用新图像的例子，超越了感知，探测场景间的推理能力。

Result: 尽管最佳模型在感知任务上表现良好，但在Common-O基准测试中仅达到35%的准确率，而在更复杂场景中的表现更差，仅1%。

Conclusion: 多模态语言模型在处理开放词汇的物体方面表现优异，但在真实场景推理时仍存在幻想现象，表明模型在感知基准测试和实际推理之间存在差距。

Abstract: Multimodal language models possess a remarkable ability to handle an
open-vocabulary's worth of objects. Yet the best models still suffer from
hallucinations when reasoning about scenes in the real world, revealing a gap
between their seemingly strong performance on existing perception benchmarks
that are saturating and their reasoning in the real world. To address this gap,
we build a novel benchmark of in-the-wild scenes that we call Common-O. With
more than 10.5k examples using exclusively new images not found in web training
data to avoid contamination, Common-O goes beyond just perception, inspired by
cognitive tests for humans, to probe reasoning across scenes by asking "what's
in common?". We evaluate leading multimodal language models, including models
specifically trained to perform chain-of-thought reasoning. We find that
perceiving objects in single images is tractable for most models, yet reasoning
across scenes is very challenging even for the best models, including reasoning
models. Despite saturating many leaderboards focusing on perception, the best
performing model only achieves 35% on Common-O -- and on Common-O Complex,
consisting of more complex scenes, the best model achieves only 1%. Curiously,
we find models are more prone to hallucinate when similar objects are present
in the scene, suggesting models may be relying on object co-occurrence seen
during training. Among the models we evaluated, we found scale can provide
modest improvements while models explicitly trained with multi-image inputs
show bigger improvements, suggesting scaled multi-image training may offer
promise. We make our benchmark publicly available to spur research into the
challenge of hallucination when reasoning across scenes.

</details>


### [135] [Contamination Detection for VLMs using Multi-Modal Semantic Perturbation](https://arxiv.org/abs/2511.03774)
*Jaden Park,Mu Cai,Feng Yao,Jingbo Shang,Soochahn Lee,Yong Jae Lee*

Main category: cs.LG

TL;DR: 本研究提出了一种新方法，用于检测受污染的视觉语言模型，并验证了其在多种污染策略下的有效性。


<details>
  <summary>Details</summary>
Motivation: 针对当前视觉语言模型的使用中，由于训练数据的不当处理可能导致的测试集泄露问题，开发有效的检测方法。

Method: 通过故意污染开源的视觉语言模型，并评估现有检测方法的表现，提出一种新的检测方法。

Result: 现有的检测方法在面对污染模型时表现不佳或结果不一致，新的检测方法能够在控制扰动的情况下有效区分受污染的模型。

Conclusion: 提出了一种基于多模态语义扰动的新检测方法，针对受污染的视觉语言模型（VLMs）进行有效检测，验证了方法在多种真实污染策略下的稳健性和有效性。

Abstract: Recent advances in Vision-Language Models (VLMs) have achieved
state-of-the-art performance on numerous benchmark tasks. However, the use of
internet-scale, often proprietary, pretraining corpora raises a critical
concern for both practitioners and users: inflated performance due to test-set
leakage. While prior works have proposed mitigation strategies such as
decontamination of pretraining data and benchmark redesign for LLMs, the
complementary direction of developing detection methods for contaminated VLMs
remains underexplored. To address this gap, we deliberately contaminate
open-source VLMs on popular benchmarks and show that existing detection
approaches either fail outright or exhibit inconsistent behavior. We then
propose a novel simple yet effective detection method based on multi-modal
semantic perturbation, demonstrating that contaminated models fail to
generalize under controlled perturbations. Finally, we validate our approach
across multiple realistic contamination strategies, confirming its robustness
and effectiveness. The code and perturbed dataset will be released publicly.

</details>


### [136] [FusionDP: Foundation Model-Assisted Differentially Private Learning for Partially Sensitive Features](https://arxiv.org/abs/2511.03806)
*Linghui Zeng,Ruixuan Liu,Atiquer Rahman Sarkar,Xiaoqian Jiang,Joyce C. Ho,Li Xiong*

Main category: cs.LG

TL;DR: FusionDP是一个增强特征级差分隐私的框架，通过使用大型基础模型插补敏感特征，结合改进的DP-SGD算法，提高了模型性能，同时保护了敏感数据的隐私。


<details>
  <summary>Details</summary>
Motivation: 在隐私保护的机器学习中，确保敏感训练数据的隐私至关重要，但在实际场景中，仅对部分特征的隐私进行保护是足够的。

Method: 提出了一个两步框架FusionDP，首先利用大型基础模型在不访问真实值的情况下，通过非敏感特征对敏感特征进行插补；然后引入改进的DP-SGD算法，使用原始和插补特征进行模型训练，同时正式保护原始敏感特征的隐私。

Result: 在PhysioNet的脓毒症预测任务和MIMIC-III的临床笔记分类任务上评估FusionDP，结果表明，相较于隐私保护基线，FusionDP显著提高了模型性能。

Conclusion: FusionDP显著提高了模型性能，同时保持严格的特征级隐私，展示了基础模型驱动的插补在提高各种模式下隐私效用权衡的潜力。

Abstract: Ensuring the privacy of sensitive training data is crucial in
privacy-preserving machine learning. However, in practical scenarios, privacy
protection may be required for only a subset of features. For instance, in ICU
data, demographic attributes like age and gender pose higher privacy risks due
to their re-identification potential, whereas raw lab results are generally
less sensitive. Traditional DP-SGD enforces privacy protection on all features
in one sample, leading to excessive noise injection and significant utility
degradation. We propose FusionDP, a two-step framework that enhances model
utility under feature-level differential privacy. First, FusionDP leverages
large foundation models to impute sensitive features given non-sensitive
features, treating them as external priors that provide high-quality estimates
of sensitive attributes without accessing the true values during model
training. Second, we introduce a modified DP-SGD algorithm that trains models
on both original and imputed features while formally preserving the privacy of
the original sensitive features. We evaluate FusionDP on two modalities: a
sepsis prediction task on tabular data from PhysioNet and a clinical note
classification task from MIMIC-III. By comparing against privacy-preserving
baselines, our results show that FusionDP significantly improves model
performance while maintaining rigorous feature-level privacy, demonstrating the
potential of foundation model-driven imputation to enhance the privacy-utility
trade-off for various modalities.

</details>


### [137] [Fair and Explainable Credit-Scoring under Concept Drift: Adaptive Explanation Frameworks for Evolving Populations](https://arxiv.org/abs/2511.03807)
*Shivogo John*

Main category: cs.LG

TL;DR: 本研究开发了适应性解释框架来应对现代信用评分系统中的数据分布变化，显著提高了透明性和公平性。


<details>
  <summary>Details</summary>
Motivation: 随着借款人行为、经济条件和监管环境的不断变化，传统的信用评分解释方法面临不稳定和不公平的问题。

Method: 本研究结合了XGBoost预测建模和三种适应性SHAP变体，通过调整特征分布、滑动窗口和增量岭回归来重新基准化解释。

Result: 适应性方法提升了时效稳定性并降低了不同群体的不公影响，同时没有降低预测准确性

Conclusion: 适应性解释框架显著改善了信用评分系统中的透明度和公平性，能够有效应对数据分布变化带来的挑战。

Abstract: Evolving borrower behaviors, shifting economic conditions, and changing
regulatory landscapes continuously reshape the data distributions underlying
modern credit-scoring systems. Conventional explainability techniques, such as
SHAP, assume static data and fixed background distributions, making their
explanations unstable and potentially unfair when concept drift occurs. This
study addresses that challenge by developing adaptive explanation frameworks
that recalibrate interpretability and fairness in dynamically evolving credit
models. Using a multi-year credit dataset, we integrate predictive modeling via
XGBoost with three adaptive SHAP variants: (A) per-slice explanation
reweighting that adjusts for feature distribution shifts, (B) drift-aware SHAP
rebaselining with sliding-window background samples, and (C) online surrogate
calibration using incremental Ridge regression. Each method is benchmarked
against static SHAP explanations using metrics of predictive performance (AUC,
F1), directional and rank stability (cosine, Kendall tau), and fairness
(demographic parity and recalibration). Results show that adaptive methods,
particularly rebaselined and surrogate-based explanations, substantially
improve temporal stability and reduce disparate impact across demographic
groups without degrading predictive accuracy. Robustness tests, including
counterfactual perturbations, background sensitivity analysis, and
proxy-variable detection, confirm the resilience of adaptive explanations under
real-world drift conditions. These findings establish adaptive explainability
as a practical mechanism for sustaining transparency, accountability, and
ethical reliability in data-driven credit systems, and more broadly, in any
domain where decision models evolve with population change.

</details>


### [138] [Optimizing Reasoning Efficiency through Prompt Difficulty Prediction](https://arxiv.org/abs/2511.03808)
*Bo Zhao,Berkcan Kapusuzoglu,Kartik Balasubramaniam,Sambit Sahu,Supriyo Chakraborty,Genta Indra Winata*

Main category: cs.LG

TL;DR: 提出了一种路由方法，通过为每个问题分配最小的模型，降低计算成本而不牺牲准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管推理语言模型在复杂任务中表现良好，但由于其大小和长推理链，在部署时非常昂贵。

Method: 通过使用从s1.1-32B获取的中间表示，训练轻量级的困难预测模型或模型正确性预测模型，以指导在推理模型池中的路由。

Result: 路由方法在多样化的数学基准测试中显著提高了效率，匹配了s1.1-32B的性能，同时减少了计算资源的使用。

Conclusion: 难度感知的路由方法在推理模型的成本效益部署中是有效的。

Abstract: Reasoning language models perform well on complex tasks but are costly to
deploy due to their size and long reasoning traces. We propose a routing
approach that assigns each problem to the smallest model likely to solve it,
reducing compute without sacrificing accuracy. Using intermediate
representations from s1.1-32B, we train lightweight predictors of problem
difficulty or model correctness to guide routing across a pool of reasoning
models. On diverse math benchmarks, routing improves efficiency over random
assignment and matches s1.1-32B's performance while using significantly less
compute. Our results demonstrate that difficulty-aware routing is effective for
cost-efficient deployment of reasoning models.

</details>


### [139] [Regret Lower Bounds for Decentralized Multi-Agent Stochastic Shortest Path Problems](https://arxiv.org/abs/2511.04594)
*Utkarsh U. Chavan,Prashant Trivedi,Nandyala Hemachandra*

Main category: cs.LG

TL;DR: 本研究探讨了去中心化的多智能体最短路径问题，提出了第一个悔恨下界，揭示了学习的复杂性及其对学习算法设计的影响。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体系统在群体机器人和交通路由等应用中的重要性增加，去中心化控制的学习问题尚未被充分探索。

Method: 在去中心化的多智能体最短路径问题中，采用线性函数近似方法，并应用基于对称性的论证识别最优政策的结构。

Result: 在任何数量的智能体$n$的情况下，构建了难以学习的实例，从而建立了悔恨下界$	ext{Ω(√K)}$，揭示了Dec-MASSPs的学习复杂性。

Conclusion: 我们提出了针对去中心化多智能体最短路径问题的第一个悔恨下界，强调了该领域固有的学习难度，并提供了对去中心化控制学习复杂度的清晰理解，有助于有效学习算法的设计。

Abstract: Multi-agent systems (MAS) are central to applications such as swarm robotics
and traffic routing, where agents must coordinate in a decentralized manner to
achieve a common objective. Stochastic Shortest Path (SSP) problems provide a
natural framework for modeling decentralized control in such settings. While
the problem of learning in SSP has been extensively studied in single-agent
settings, the decentralized multi-agent variant remains largely unexplored. In
this work, we take a step towards addressing that gap. We study decentralized
multi-agent SSPs (Dec-MASSPs) under linear function approximation, where the
transition dynamics and costs are represented using linear models. Applying
novel symmetry-based arguments, we identify the structure of optimal policies.
Our main contribution is the first regret lower bound for this setting based on
the construction of hard-to-learn instances for any number of agents, $n$. Our
regret lower bound of $\Omega(\sqrt{K})$, over $K$ episodes, highlights the
inherent learning difficulty in Dec-MASSPs. These insights clarify the learning
complexity of decentralized control and can further guide the design of
efficient learning algorithms in multi-agent systems.

</details>


### [140] [From Static to Dynamic: Enhancing Offline-to-Online Reinforcement Learning via Energy-Guided Diffusion Stratification](https://arxiv.org/abs/2511.03828)
*Lipeng Zu,Hansong Zhou,Xiaonan Zhang*

Main category: cs.LG

TL;DR: 提出了Energy-Guided Diffusion Stratification (StratDiff)方法，有效解决了离线到在线强化学习中的分布结构问题，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在离线到在线强化学习的过渡中，离线数据的分布结构未被充分利用，导致了学习策略适应性差的研究空白。

Method: 采用能量导向的扩散模型来学习离线数据的先验知识，并通过能量基函数改进策略模仿，从而生成接近离线策略的动作。

Result: 与现有方法相比，StratDiff在D4RL基准测试中显著提升了适应性和性能稳定性。

Conclusion: StratDiff在将离线强化学习平滑过渡到在线学习的过程中表现出色，通过有效分层训练样本，提高了适应性和稳定性，超越了现有方法。

Abstract: Transitioning from offline to online reinforcement learning (RL) poses
critical challenges due to distributional shifts between the fixed behavior
policy in the offline dataset and the evolving policy during online learning.
Although this issue is widely recognized, few methods attempt to explicitly
assess or utilize the distributional structure of the offline data itself,
leaving a research gap in adapting learning strategies to different types of
samples. To address this challenge, we propose an innovative method,
Energy-Guided Diffusion Stratification (StratDiff), which facilitates smoother
transitions in offline-to-online RL. StratDiff deploys a diffusion model to
learn prior knowledge from the offline dataset. It then refines this knowledge
through energy-based functions to improve policy imitation and generate
offline-like actions during online fine-tuning. The KL divergence between the
generated action and the corresponding sampled action is computed for each
sample and used to stratify the training batch into offline-like and
online-like subsets. Offline-like samples are updated using offline objectives,
while online-like samples follow online learning strategies. We demonstrate the
effectiveness of StratDiff by integrating it with off-the-shelf methods Cal-QL
and IQL. Extensive empirical evaluations on D4RL benchmarks show that StratDiff
significantly outperforms existing methods, achieving enhanced adaptability and
more stable performance across diverse RL settings.

</details>


### [141] [Higher-Order Causal Structure Learning with Additive Models](https://arxiv.org/abs/2511.03831)
*James Enouen,Yujia Zheng,Ignavier Ng,Yan Liu,Kun Zhang*

Main category: cs.LG

TL;DR: 本研究扩展了因果加法模型至高阶交互加法模型，提出新的超图结构以改进因果结构学习，并开发了相应的贪心算法。


<details>
  <summary>Details</summary>
Motivation: 探讨因果发现中高阶相互作用的显式处理，提升因果结构学习的效果。

Method: 扩展了贪心CAM算法以处理更复杂的超有向无环图搜索空间。

Result: 提出了一种新的超图结构，提供了识别结果并展示了改进的经验效果。

Conclusion: 更复杂的超图结构学习可能会带来更好的经验结果，提出的算法在合成实验中表现出实用性。

Abstract: Causal structure learning has long been the central task of inferring causal
insights from data. Despite the abundance of real-world processes exhibiting
higher-order mechanisms, however, an explicit treatment of interactions in
causal discovery has received little attention. In this work, we focus on
extending the causal additive model (CAM) to additive models with higher-order
interactions. This second level of modularity we introduce to the structure
learning problem is most easily represented by a directed acyclic hypergraph
which extends the DAG. We introduce the necessary definitions and theoretical
tools to handle the novel structure we introduce and then provide
identifiability results for the hyper DAG, extending the typical Markov
equivalence classes. We next provide insights into why learning the more
complex hypergraph structure may actually lead to better empirical results. In
particular, more restrictive assumptions like CAM correspond to easier-to-learn
hyper DAGs and better finite sample complexity. We finally develop an extension
of the greedy CAM algorithm which can handle the more complex hyper DAG search
space and demonstrate its empirical usefulness in synthetic experiments.

</details>


### [142] [Benchmark Datasets for Lead-Lag Forecasting on Social Platforms](https://arxiv.org/abs/2511.03877)
*Kimia Kazemian,Zhenzhen Liu,Yangfanyu Yang,Katie Z Luo,Shuhan Gu,Audrey Du,Xinyu Yang,Jack Jansons,Kilian Q Weinberger,John Thickstun,Yian Yin,Sarah Dean*

Main category: cs.LG

TL;DR: 本文提出了Lead-Lag预测的概念，并建立了相关数据集，为更深入的社会数据分析奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 尽管Lead-Lag动态模式普遍存在，但在时间序列社区作为统一预测问题的处理不足，缺乏标准化数据集是主要原因。

Method: 通过提供高容量基准数据集，并记录数据整理和清理的所有技术细节，验证了Lead-Lag动态的存在，以及对回归的参数和非参数基准进行了基准测试。

Result: 本研究介绍了两个高容量的基准数据集-arXiv（访问->引用）和GitHub（推送/星标->分叉）-并概述了具有类似Lead-Lag动态的其他领域。这些数据集理想地用于Lead-Lag预测，捕获跨年长时间动态，避免样本中的生存者偏差。

Conclusion: 本研究建立了Lead-Lag Forecasting (LLF)作为一种新的预测范式，为社会和使用数据的系统探索奠定了实证基础。

Abstract: Social and collaborative platforms emit multivariate time-series traces in
which early interactions-such as views, likes, or downloads-are followed,
sometimes months or years later, by higher impact like citations, sales, or
reviews. We formalize this setting as Lead-Lag Forecasting (LLF): given an
early usage channel (the lead), predict a correlated but temporally shifted
outcome channel (the lag). Despite the ubiquity of such patterns, LLF has not
been treated as a unified forecasting problem within the time-series community,
largely due to the absence of standardized datasets. To anchor research in LLF,
here we present two high-volume benchmark datasets-arXiv (accesses -> citations
of 2.3M papers) and GitHub (pushes/stars -> forks of 3M repositories)-and
outline additional domains with analogous lead-lag dynamics, including
Wikipedia (page views -> edits), Spotify (streams -> concert attendance),
e-commerce (click-throughs -> purchases), and LinkedIn profile (views ->
messages). Our datasets provide ideal testbeds for lead-lag forecasting, by
capturing long-horizon dynamics across years, spanning the full spectrum of
outcomes, and avoiding survivorship bias in sampling. We documented all
technical details of data curation and cleaning, verified the presence of
lead-lag dynamics through statistical and classification tests, and benchmarked
parametric and non-parametric baselines for regression. Our study establishes
LLF as a novel forecasting paradigm and lays an empirical foundation for its
systematic exploration in social and usage data. Our data portal with downloads
and documentation is available at https://lead-lag-forecasting.github.io/.

</details>


### [143] [DecoHD: Decomposed Hyperdimensional Classification under Extreme Memory Budgets](https://arxiv.org/abs/2511.03911)
*Sanggeon Yun,Hyunwoo Oh,Ryozo Masukawa,Mohsen Imani*

Main category: cs.LG

TL;DR: DecoHD通过解构超维计算方式实现高效内存压缩和准确率控制，同时在硬件上取得显著能耗和速度优势。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有HDC解构方法在压缩学习类原型时的局限性，通过引入动态学习的超维计算方法来改善特征轴缩减导致的集中度和稳健性下降。

Method: 引入DecoHD，利用一小组共享的每层通道进行乘法绑定并在末尾打包，从而在压缩学习的类原型时保持极大的表示空间。

Result: DecoHD在保证性能的同时，平均保持与强基线模型相差仅约0.1-0.15%的准确率，大幅减少可训练参数，增强抗噪声能力。

Conclusion: DecoHD通过学习解构的超维计算参数化方法实现了显著的内存节省和较小的准确性下降，同时在硬件上表现出极高的能效比。

Abstract: Decomposition is a proven way to shrink deep networks without changing I/O.
We bring this idea to hyperdimensional computing (HDC), where footprint cuts
usually shrink the feature axis and erode concentration and robustness. Prior
HDC decompositions decode via fixed atomic hypervectors, which are ill-suited
for compressing learned class prototypes. We introduce DecoHD, which learns
directly in a decomposed HDC parameterization: a small, shared set of per-layer
channels with multiplicative binding across layers and bundling at the end,
yielding a large representational space from compact factors. DecoHD compresses
along the class axis via a lightweight bundling head while preserving native
bind-bundle-score; training is end-to-end, and inference remains pure HDC,
aligning with in/near-memory accelerators. In evaluation, DecoHD attains
extreme memory savings with only minor accuracy degradation under tight
deployment budgets. On average it stays within about 0.1-0.15% of a strong
non-reduced HDC baseline (worst case 5.7%), is more robust to random bit-flip
noise, reaches its accuracy plateau with up to ~97% fewer trainable parameters,
and -- in hardware -- delivers roughly 277x/35x energy/speed gains over a CPU
(AMD Ryzen 9 9950X), 13.5x/3.7x over a GPU (NVIDIA RTX 4090), and 2.0x/2.4x
over a baseline HDC ASIC.

</details>


### [144] [On Predicting Sociodemographics from Mobility Signals](https://arxiv.org/abs/2511.03924)
*Ekin Uğurel,Cynthia Chen,Brian H. Y. Lee,Filipe Rodrigues*

Main category: cs.LG

TL;DR: 本研究通过引入新特征和多任务学习框架，提高了基于移动数据推断社会人口属性的性能，并为模型提供了可视化的不确定性度量。


<details>
  <summary>Details</summary>
Motivation: 推动交通规划者更好地利用被动收集的数据集，解决移动模式与社会人口特征之间关系薄弱和上下文一般化有限的问题。

Method: 通过引入行为驱动的高阶移动描述符、开发新的度量和可视化工具，并构建多任务学习框架来进行模型训练。

Result: 新提出的方法显著提高了对年龄、性别、收入和家庭结构的预测，并在数据有限或跨时间段应用时表现优于单任务模型。

Conclusion: 本研究提出了一种基于行为的高阶移动描述符，结合多任务学习框架和可视化工具，有效提高了从移动数据推断社会人口属性的准确性和可解释性。

Abstract: Inferring sociodemographic attributes from mobility data could help
transportation planners better leverage passively collected datasets, but this
task remains difficult due to weak and inconsistent relationships between
mobility patterns and sociodemographic traits, as well as limited
generalization across contexts. We address these challenges from three angles.
First, to improve predictive accuracy while retaining interpretability, we
introduce a behaviorally grounded set of higher-order mobility descriptors
based on directed mobility graphs. These features capture structured patterns
in trip sequences, travel modes, and social co-travel, and significantly
improve prediction of age, gender, income, and household structure over
baselines features. Second, we introduce metrics and visual diagnostic tools
that encourage evenness between model confidence and accuracy, enabling
planners to quantify uncertainty. Third, to improve generalization and sample
efficiency, we develop a multitask learning framework that jointly predicts
multiple sociodemographic attributes from a shared representation. This
approach outperforms single-task models, particularly when training data are
limited or when applying models across different time periods (i.e., when the
test set distribution differs from the training set).

</details>


### [145] [NVIDIA Nemotron Nano V2 VL](https://arxiv.org/abs/2511.03929)
*NVIDIA,:,Amala Sanjay Deshmukh,Kateryna Chumachenko,Tuomas Rintamaki,Matthieu Le,Tyler Poon,Danial Mohseni Taheri,Ilia Karmanov,Guilin Liu,Jarno Seppanen,Guo Chen,Karan Sapra,Zhiding Yu,Adi Renduchintala,Charles Wang,Peter Jin,Arushi Goel,Mike Ranzinger,Lukas Voegtle,Philipp Fischer,Timo Roman,Wei Ping,Boxin Wang,Zhuolin Yang,Nayeon Lee,Shaokun Zhang,Fuxiao Liu,Zhiqi Li,Di Zhang,Greg Heinrich,Hongxu,Yin,Song Han,Pavlo Molchanov,Parth Mannan,Yao Xu,Jane Polak Scowcroft,Tom Balough,Subhashree Radhakrishnan,Paris Zhang,Sean Cha,Ratnesh Kumar,Zaid Pervaiz Bhat,Jian Zhang,Darragh Hanley,Pritam Biswas,Jesse Oliver,Kevin Vasques,Roger Waleffe,Duncan Riach,Oluwatobi Olabiyi,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Pritam Gundecha,Khanh Nguyen,Alexandre Milesi,Eugene Khvedchenia,Ran Zilberstein,Ofri Masad,Natan Bagrov,Nave Assaf,Tomer Asida,Daniel Afrimi,Amit Zuker,Netanel Haber,Zhiyu Cheng,Jingyu,Xin,Di,Wu,Nik Spirin,Maryam Moosaei,Roman Ageev,Vanshil Atul Shah,Yuting Wu,Daniel Korzekwa,Unnikrishnan Kizhakkemadam Sreekumar,Wanli Jiang,Padmavathy Subramanian,Alejandra Rico,Sandip Bhaskar,Saeid Motiian,Kedi Wu,Annie Surla,Chia-Chih Chen,Hayden Wolff,Matthew Feinberg,Melissa Corpuz,Marek Wawrzos,Eileen Long,Aastha Jhunjhunwala,Paul Hendricks,Farzan Memarian,Benika Hall,Xin-Yu Wang,David Mosallanezhad,Soumye Singhal,Luis Vega,Katherine Cheung,Krzysztof Pawelec,Michael Evans,Katherine Luna,Jie Lou,Erick Galinkin,Akshay Hazare,Kaustubh Purandare,Ann Guan,Anna Warno,Chen Cui,Yoshi Suhara,Shibani Likhite,Seph Mard,Meredith Price,Laya Sleiman,Saori Kaji,Udi Karpas,Kari Briski,Joey Conway,Michael Lightstone,Jan Kautz,Mohammad Shoeybi,Mostofa Patwary,Jonathen Cohen,Oleksii Kuchaiev,Andrew Tao,Bryan Catanzaro*

Main category: cs.LG

TL;DR: Nemotron Nano V2 VL模型显著提升了文档和视频理解能力，并分享了模型检查点及部分数据集和训练代码。


<details>
  <summary>Details</summary>
Motivation: 为了在现实世界的文档理解和视频理解中取得更好的效果，开发了Nemotron Nano V2 VL。

Method: 结合混合Mamba-Transformer LLM和创新的token减缩技术，以提高长文档和视频场景中的推理吞吐量。

Result: Nemotron Nano V2 VL在所有视觉和文本领域相较于Llama-3.1-Nemotron-Nano-VL-8B取得了显著进步，并发布了多种格式的模型检查点。

Conclusion: Nemotron Nano V2 VL在文档理解、视频理解和推理任务上有显著提升，基于新架构和数据集的改进。

Abstract: We introduce Nemotron Nano V2 VL, the latest model of the Nemotron
vision-language series designed for strong real-world document understanding,
long video comprehension, and reasoning tasks. Nemotron Nano V2 VL delivers
significant improvements over our previous model,
Llama-3.1-Nemotron-Nano-VL-8B, across all vision and text domains through major
enhancements in model architecture, datasets, and training recipes. Nemotron
Nano V2 VL builds on Nemotron Nano V2, a hybrid Mamba-Transformer LLM, and
innovative token reduction techniques to achieve higher inference throughput in
long document and video scenarios. We are releasing model checkpoints in BF16,
FP8, and FP4 formats and sharing large parts of our datasets, recipes and
training code.

</details>


### [146] [LogHD: Robust Compression of Hyperdimensional Classifiers via Logarithmic Class-Axis Reduction](https://arxiv.org/abs/2511.03938)
*Sanggeon Yun,Hyunwoo Oh,Ryozo Masukawa,Pietro Mercati,Nathaniel D. Bastian,Mohsen Imani*

Main category: cs.LG

TL;DR: LogHD通过对类轴的对数缩减，显著提高了超维计算的存储效率、计算速度及鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决HDC在存储和计算需求方面的挑战，同时提高模型的鲁棒性。

Method: 通过引入对类轴的对数缩减，LogHD使用了大约
d
g	ilde{{n}}	imes log_k C 的嵌套超矢量，利用容量感知的字典和基于特征轴稀疏化的解码方法。

Result: LogHD在多个数据集上实现了较高的准确率和较强的抗扰动能力，相较于特征轴压缩，其在匹配存储条件下支持更高的比特翻转率。

Conclusion: LogHD方法在存储效能和计算效率方面表现出色，同时保持出色的准确性和抗噪声能力。

Abstract: Hyperdimensional computing (HDC) suits memory, energy, and
reliability-constrained systems, yet the standard "one prototype per class"
design requires $O(CD)$ memory (with $C$ classes and dimensionality $D$). Prior
compaction reduces $D$ (feature axis), improving storage/compute but weakening
robustness. We introduce LogHD, a logarithmic class-axis reduction that
replaces the $C$ per-class prototypes with $n\!\approx\!\lceil\log_k C\rceil$
bundle hypervectors (alphabet size $k$) and decodes in an $n$-dimensional
activation space, cutting memory to $O(D\log_k C)$ while preserving $D$. LogHD
uses a capacity-aware codebook and profile-based decoding, and composes with
feature-axis sparsification. Across datasets and injected bit flips, LogHD
attains competitive accuracy with smaller models and higher resilience at
matched memory. Under equal memory, it sustains target accuracy at roughly
$2.5$-$3.0\times$ higher bit-flip rates than feature-axis compression; an ASIC
instantiation delivers $498\times$ energy efficiency and $62.6\times$ speedup
over an AMD Ryzen 9 9950X and $24.3\times$/$6.58\times$ over an NVIDIA RTX
4090, and is $4.06\times$ more energy-efficient and $2.19\times$ faster than a
feature-axis HDC ASIC baseline.

</details>


### [147] [RLHF: A comprehensive Survey for Cultural, Multimodal and Low Latency Alignment Methods](https://arxiv.org/abs/2511.03939)
*Raghav Sharma,Manan Mehta,Sai Tiger Raina*

Main category: cs.LG

TL;DR: 本研究调查多模态对齐、文化公平性及低延迟优化的前沿问题，回顾基础算法，并分析最新技术，为AI系统的构建提供了路线图。


<details>
  <summary>Details</summary>
Motivation: 为了系统地探索多模态对齐、文化公平性和低延迟优化等领域的关键空白。

Method: 本研究首先回顾了基础算法，包括 PPO、DPO 和 GRPO，然后详细分析了最新的创新。

Result: 本调查综合了对齐研究的新前沿，解决了多模态对齐、文化公平性和低延迟优化的重要问题。

Conclusion: 本研究为构建更强大、高效和公平的人工智能系统提供了重要的路线图。

Abstract: Reinforcement Learning from Human Feedback (RLHF) is the standard for
aligning Large Language Models (LLMs), yet recent progress has moved beyond
canonical text-based methods. This survey synthesizes the new frontier of
alignment research by addressing critical gaps in multi-modal alignment,
cultural fairness, and low-latency optimization. To systematically explore
these domains, we first review foundational algo- rithms, including PPO, DPO,
and GRPO, before presenting a detailed analysis of the latest innovations. By
providing a comparative synthesis of these techniques and outlining open
challenges, this work serves as an essential roadmap for researchers building
more robust, efficient, and equitable AI systems.

</details>


### [148] [Conditional Score Learning for Quickest Change Detection in Markov Transition Kernels](https://arxiv.org/abs/2511.03953)
*Wuxia Chen,Taposh Banerjee,Vahid Tarokh*

Main category: cs.LG

TL;DR: 本文探讨了在未知转移核的马尔可夫过程中进行快速变化检测的方法，提出了一种基于条件分数的CUSUM程序，同时提供理论保证和实用性。


<details>
  <summary>Details</summary>
Motivation: 解决马尔可夫过程中的快速变化检测问题，尤其是在未知转移核的情况下。

Method: 通过学习条件分数来避免显式似然评估，开发了基于条件Hyvarinen分数差异的检测程序。

Result: 提供了对错误报警均值时间的指数下界，并给出了检测延迟的渐近上界。

Conclusion: 提出了一种基于分数的CUSUM程序，可以有效检测马尔可夫过程中的变化，并具备理论保证和实用可行性。

Abstract: We address the problem of quickest change detection in Markov processes with
unknown transition kernels. The key idea is to learn the conditional score
$\nabla_{\mathbf{y}} \log p(\mathbf{y}|\mathbf{x})$ directly from sample pairs
$( \mathbf{x},\mathbf{y})$, where both $\mathbf{x}$ and $\mathbf{y}$ are
high-dimensional data generated by the same transition kernel. In this way, we
avoid explicit likelihood evaluation and provide a practical way to learn the
transition dynamics. Based on this estimation, we develop a score-based CUSUM
procedure that uses conditional Hyvarinen score differences to detect changes
in the kernel. To ensure bounded increments, we propose a truncated version of
the statistic. With Hoeffding's inequality for uniformly ergodic Markov
processes, we prove exponential lower bounds on the mean time to false alarm.
We also prove asymptotic upper bounds on detection delay. These results give
both theoretical guarantees and practical feasibility for score-based detection
in high-dimensional Markov models.

</details>


### [149] [PrivacyCD: Hierarchical Unlearning for Protecting Student Privacy in Cognitive Diagnosis](https://arxiv.org/abs/2511.03966)
*Mingliang Hou,Yinuo Wang,Teng Guo,Zitao Liu,Wenzhou Dou,Jiaqi Zheng,Renqiang Luo,Mi Tian,Weiqi Luo*

Main category: cs.LG

TL;DR: 本文首次系统研究了认知诊断模型的数据遗忘问题，提出分层重要性引导遗忘算法（HIF），显著提高了数据删除请求的响应效率和隐私保护性能。


<details>
  <summary>Details</summary>
Motivation: 随着用户对“被遗忘权”的日益强调，迫切需要从认知诊断模型中移除特定学生数据。

Method: 提出了一种新颖的算法——分层重要性引导遗忘（HIF），利用参数在不同层次上的重要性特征，结合个体和层级重要性进行平滑处理。

Result: HIF在三个真实场景数据集上的实验结果显示，其在关键指标上明显优于基线算法。

Conclusion: HIF为认知诊断模型提供了一种有效的数据遗忘方案，能够高效处理用户数据删除请求，确保隐私保护。

Abstract: The need to remove specific student data from cognitive diagnosis (CD) models
has become a pressing requirement, driven by users' growing assertion of their
"right to be forgotten". However, existing CD models are largely designed
without privacy considerations and lack effective data unlearning mechanisms.
Directly applying general purpose unlearning algorithms is suboptimal, as they
struggle to balance unlearning completeness, model utility, and efficiency when
confronted with the unique heterogeneous structure of CD models. To address
this, our paper presents the first systematic study of the data unlearning
problem for CD models, proposing a novel and efficient algorithm: hierarchical
importanceguided forgetting (HIF). Our key insight is that parameter importance
in CD models exhibits distinct layer wise characteristics. HIF leverages this
via an innovative smoothing mechanism that combines individual and layer, level
importance, enabling a more precise distinction of parameters associated with
the data to be unlearned. Experiments on three real world datasets show that
HIF significantly outperforms baselines on key metrics, offering the first
effective solution for CD models to respond to user data removal requests and
for deploying high-performance, privacy preserving AI systems

</details>


### [150] [PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation Prediction](https://arxiv.org/abs/2511.03976)
*Xu Zou*

Main category: cs.LG

TL;DR: 论文介绍了一种新型变压器模型PETRA，旨在通过系统发育树数据提高SARS-CoV-2突变预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 应对SARS-CoV-2的快速演变和免疫逃逸变体的持续挑战。

Method: 基于进化轨迹的变压器模型，利用系统发育树数据而非原始RNA序列进行训练。

Result: PETRA在核苷酸突变和刺突氨基酸突变预测上显著优于当前最佳基线模型。

Conclusion: PETRA能够有效预测SARS-CoV-2的未来突变，并在应对全球序列数据的不平衡方面表现出色。

Abstract: Since its emergence, SARS-CoV-2 has demonstrated a rapid and unpredictable
evolutionary trajectory, characterized by the continual emergence of
immune-evasive variants. This poses persistent challenges to public health and
vaccine development.
  While large-scale generative pre-trained transformers (GPTs) have
revolutionized the modeling of sequential data, their direct applications to
noisy viral genomic sequences are limited. In this paper, we introduce
PETRA(Pretrained Evolutionary TRAnsformer), a novel transformer approach based
on evolutionary trajectories derived from phylogenetic trees rather than raw
RNA sequences. This method effectively mitigates sequencing noise and captures
the hierarchical structure of viral evolution.
  With a weighted training framework to address substantial geographical and
temporal imbalances in global sequence data, PETRA excels in predicting future
SARS-CoV-2 mutations, achieving a weighted recall@1 of 9.45% for nucleotide
mutations and 17.10\% for spike amino-acid mutations, compared to 0.49% and
6.64% respectively for the best baseline. PETRA also demonstrates its ability
to aid in the real-time mutation prediction of major clades like 24F(XEC) and
25A(LP.8.1). The code is open sourced on https://github.com/xz-keg/PETra

</details>


### [151] [Structural Priors and Modular Adapters in the Composable Fine-Tuning Algorithm of Large-Scale Models](https://arxiv.org/abs/2511.03981)
*Yuxiao Wang,Di Wu,Feng Liu,Zhimin Qiu,Chenrui Hu*

Main category: cs.LG

TL;DR: 提出一种新方法，通过图先验和模块适配器减少计算成本，提高多任务适应的稳定性和效率，验证其在多项实验中的优越表现。


<details>
  <summary>Details</summary>
Motivation: 旨在解决大规模预训练模型在多任务适应中面临的高计算成本和结构不稳定性问题。

Method: 提出了一种可组合微调方法，将图结构先验与模块适配器相结合，使用关系矩阵建模任务之间的依赖性，即编码节点和路径之间的相关性，并通过低秩映射和可插拔机制将模块适配器嵌入不同层次，实现跨任务的高效组合与重用。

Result: 在超参数灵敏度、环境灵敏度和数据灵敏度的实验中，验证了方法在结构约束下的一致性和优越性能，分析了路由温度、门控阈值和关系矩阵正则化强度等关键因素。

Conclusion: 该方法显著提高了任务预测准确性、适配器权重分配精度和整体计算效率，同时保持了模型的轻量设计，突显了图先验与模块机制在可组合微调中的协同优势。

Abstract: This paper proposes a composable fine-tuning method that integrates graph
structural priors with modular adapters to address the high computational cost
and structural instability faced by large-scale pre-trained models in
multi-task adaptation. The method introduces a relation matrix to model
dependencies among tasks, explicitly encoding correlations between nodes and
paths into graph structural priors, which provide unified structural
constraints for adapter weight allocation and path selection. Modular adapters
are embedded into different layers through low-rank mapping and a pluggable
mechanism, enabling efficient cross-task composition and reuse under prior
guidance. This mechanism not only improves parameter efficiency and training
stability but also alleviates path conflicts and redundant computation in
multi-task scenarios. Furthermore, experiments on hyperparameter sensitivity,
environmental sensitivity, and data sensitivity are conducted to systematically
analyze key factors such as routing temperature, gating thresholds, and
relation matrix regularization strength, verifying the consistency and superior
performance of the method under structural constraints. The results demonstrate
that the proposed framework significantly enhances task prediction accuracy,
adapter weight allocation precision, and overall computational efficiency while
maintaining model lightweight design, highlighting the synergistic advantages
of graph priors and modular mechanisms in composable fine-tuning.

</details>


### [152] [Use of Continuous Glucose Monitoring with Machine Learning to Identify Metabolic Subphenotypes and Inform Precision Lifestyle Changes](https://arxiv.org/abs/2511.03986)
*Ahmed A. Metwally,Heyjun Park,Yue Wu,Tracey McLaughlin,Michael P. Snyder*

Main category: cs.LG

TL;DR: 研究表明，连续血糖监测与机器学习结合可提供个性化的代谢表型，促进针对个体代谢缺陷的精准糖尿病预防策略。


<details>
  <summary>Details</summary>
Motivation: 当前糖尿病与前驱糖尿病的分类方法未能充分反映病理生理学上的异质性，需要更动态的代谢表征方法。

Method: 采用机器学习模型结合居家连续血糖监测数据，分析个体的代谢类型及其对饮食和生活方式的响应。

Result: 验证了个体的胰岛素抵抗和β细胞功能可以通过标准化饮食的餐后血糖反应来预测，且饮食、睡眠及运动习惯与代谢功能障碍之间存在独特的关联。

Conclusion: 通过连续血糖监测和可穿戴技术，能够将早期代谢异常的复杂性拆解为可操作的亚表型，从而为个性化的糖尿病预防提供新的策略。

Abstract: The classification of diabetes and prediabetes by static glucose thresholds
obscures the pathophysiological dysglycemia heterogeneity, primarily driven by
insulin resistance (IR), beta-cell dysfunction, and incretin deficiency. This
review demonstrates that continuous glucose monitoring and wearable
technologies enable a paradigm shift towards non-invasive, dynamic metabolic
phenotyping. We show evidence that machine learning models can leverage
high-resolution glucose data from at-home, CGM-enabled oral glucose tolerance
tests to accurately predict gold-standard measures of muscle IR and beta-cell
function. This personalized characterization extends to real-world nutrition,
where an individual's unique postprandial glycemic response (PPGR) to
standardized meals, such as the relative glucose spike to potatoes versus
grapes, could serve as a biomarker for their metabolic subtype. Moreover,
integrating wearable data reveals that habitual diet, sleep, and physical
activity patterns, particularly their timing, are uniquely associated with
specific metabolic dysfunctions, informing precision lifestyle interventions.
The efficacy of dietary mitigators in attenuating PPGR is also shown to be
phenotype-dependent. Collectively, this evidence demonstrates that CGM can
deconstruct the complexity of early dysglycemia into distinct, actionable
subphenotypes. This approach moves beyond simple glycemic control, paving the
way for targeted nutritional, behavioral, and pharmacological strategies
tailored to an individual's core metabolic defects, thereby paving the way for
a new era of precision diabetes prevention.

</details>


### [153] [Towards Scalable Meta-Learning of near-optimal Interpretable Models via Synthetic Model Generations](https://arxiv.org/abs/2511.04000)
*Kyaw Hpone Myint,Zhe Wu,Alexandre G. R. Day,Giri Iyengar*

Main category: cs.LG

TL;DR: 本文提出了一种高效的合成预训练数据生成方法，以支持决策树的元学习，显著减少了计算成本并提高了数据生成灵活性。


<details>
  <summary>Details</summary>
Motivation: 在金融和医疗等高风险领域，决策树因其可解释性而被广泛使用，因此需要一种方法来生成合成的预训练数据以促进元学习。

Method: 通过合成采样近似最佳的决策树，生成大规模的真实数据集，使用MetaTree变压器架构。

Result: 该方法的性能可与在真实数据上进行预训练或使用计算消耗较大的最佳决策树相媲美。

Conclusion: 该方法显著降低了计算成本，提高了数据生成的灵活性，并为可解释决策树模型的可扩展高效元学习铺平了道路。

Abstract: Decision trees are widely used in high-stakes fields like finance and
healthcare due to their interpretability. This work introduces an efficient,
scalable method for generating synthetic pre-training data to enable
meta-learning of decision trees. Our approach samples near-optimal decision
trees synthetically, creating large-scale, realistic datasets. Using the
MetaTree transformer architecture, we demonstrate that this method achieves
performance comparable to pre-training on real-world data or with
computationally expensive optimal decision trees. This strategy significantly
reduces computational costs, enhances data generation flexibility, and paves
the way for scalable and efficient meta-learning of interpretable decision tree
models.

</details>


### [154] [Accelerating scientific discovery with the common task framework](https://arxiv.org/abs/2511.04001)
*J. Nathan Kutz,Peter Battaglia,Michael Brenner,Kevin Carlberg,Aric Hagberg,Shirley Ho,Stephan Hoyer,Henning Lange,Hod Lipson,Michael W. Mahoney,Frank Noe,Max Welling,Laure Zanna,Francis Zhu,Steven L. Brunton*

Main category: cs.LG

TL;DR: 该文介绍了通用任务框架（CTF），用于评估科学与工程中的机器学习和人工智能算法，满足多样化的科学目标需求。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习和人工智能在工程、物理和生物科学中的应用增长，需要对不同算法进行客观比较。

Method: 引入通用任务框架（CTF），包括一系列挑战数据集和标准的比较指标。

Result: CTF作为一种新兴技术，有助于快速推进传统应用中的机器学习/人工智能算法。

Conclusion: 提出了一个通用任务框架，以解决科学与工程中的多样化问题并评估算法性能。

Abstract: Machine learning (ML) and artificial intelligence (AI) algorithms are
transforming and empowering the characterization and control of dynamic systems
in the engineering, physical, and biological sciences. These emerging modeling
paradigms require comparative metrics to evaluate a diverse set of scientific
objectives, including forecasting, state reconstruction, generalization, and
control, while also considering limited data scenarios and noisy measurements.
We introduce a common task framework (CTF) for science and engineering, which
features a growing collection of challenge data sets with a diverse set of
practical and common objectives. The CTF is a critically enabling technology
that has contributed to the rapid advance of ML/AI algorithms in traditional
applications such as speech recognition, language processing, and computer
vision. There is a critical need for the objective metrics of a CTF to compare
the diverse algorithms being rapidly developed and deployed in practice today
across science and engineering.

</details>


### [155] [Memory- and Latency-Constrained Inference of Large Language Models via Adaptive Split Computing](https://arxiv.org/abs/2511.04002)
*Mingyu Sung,Vikas Palakonda,Suhwan Im,Sunghwan Moon,Il-Min Kim,Sangseok Yun,Jae-Mo Kang*

Main category: cs.LG

TL;DR: 本研究提出了一种专为大语言模型在边缘设备部署设计的自回归感知分割计算框架，优化了模型推理速度和通信效率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在资源受限的物联网设备上部署时的存储和推理效率问题，尤其是自回归推理中代币生成和KV缓存需求的挑战。

Method: 采用了一点分割压缩（OPSC）、两阶段中间压缩管道（TS和TAB-Q）和统一优化框架相结合的方法，用于自回归推理的优化。

Result: 该框架在多种大语言模型和硬件平台上进行广泛评估，表现优于先进的量化方法，实现了1.49倍的推理加速和显著的通信开销减少，同时保持或提高了模型的准确性。

Conclusion: 本研究提出了一种新的自回归感知分割计算框架，优化了大语言模型在边缘设备上的部署，显著提高了推理速度和减少了通信开销，同时保持或提升了模型准确性。

Abstract: Large language models (LLMs) have achieved near-human performance across
diverse reasoning tasks, yet their deployment on resource-constrained
Internet-of-Things (IoT) devices remains impractical due to massive parameter
footprints and memory-intensive autoregressive decoding. While split computing
offers a promising solution by partitioning model execution between edge
devices and cloud servers, existing approaches fail to address the unique
challenges of autoregressive inference, particularly the iterative token
generation process and expanding key-value (KV) cache requirements. This work
introduces the first autoregressive-aware split computing framework designed
explicitly for LLM deployment on edge devices. Our approach makes three key
contributions. First, we develop one-point split compression (OPSC), a
mixed-precision quantization scheme that prevents out-of-memory failures by
strategically partitioning models into front-end and back-end segments with
different precision levels. Second, we propose a two-stage intermediate
compression pipeline that combines threshold splitting (TS) and token-wise
adaptive bit quantization (TAB-Q) to preserve accuracy-critical activations
while dramatically reducing communication overhead. Third, we formulate a
unified optimization framework that jointly selects optimal split points,
quantization settings, and sequence lengths to satisfy strict memory and
latency constraints. Extensive evaluations across diverse LLMs and hardware
platforms demonstrate superior performance compared to state-of-the-art
quantization methods, including SmoothQuant, OmniQuant, and Atom. The framework
achieves a 1.49 inference speedup and significant communication overhead
reduction while maintaining or improving model accuracy.

</details>


### [156] [DartQuant: Efficient Rotational Distribution Calibration for LLM Quantization](https://arxiv.org/abs/2511.04063)
*Yuantian Shao,Yuanteng Chen,Peisong Wang,Jianlin Yu,Jing Lin,Yiwu Yao,Zhihui Wei,Jian Cheng*

Main category: cs.LG

TL;DR: DartQuant是一种新型旋转校准方法，通过降低旋转优化复杂性，从而实现70B大模型的高效量化，表现出显著的加速和内存节省。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有旋转优化算法计算成本高和过拟合风险的问题，提升模型量化的效率和效果。

Method: 提出了一种新的高效分布感知旋转校准方法DartQuant，结合了QR-Orth优化方案，降低了旋转优化的复杂性。

Result: DartQuant在多种模型量化实验中表现优异，首次在单个3090 GPU上成功完成70B模型的旋转校准。

Conclusion: DartQuant在70B模型的量化中表现出色，实现了47倍加速和10倍内存节省，且可在资源有限的环境下完成旋转校准。

Abstract: Quantization plays a crucial role in accelerating the inference of
large-scale models, and rotational matrices have been shown to effectively
improve quantization performance by smoothing outliers. However, end-to-end
fine-tuning of rotational optimization algorithms incurs high computational
costs and is prone to overfitting. To address this challenge, we propose an
efficient distribution-aware rotational calibration method, DartQuant, which
reduces the complexity of rotational optimization by constraining the
distribution of the activations after rotation. This approach also effectively
reduces reliance on task-specific losses, thereby mitigating the risk of
overfitting. Additionally, we introduce the QR-Orth optimization scheme, which
replaces expensive alternating optimization with a more efficient solution. In
a variety of model quantization experiments, DartQuant demonstrates superior
performance. Compared to existing methods, it achieves 47$\times$ acceleration
and 10$\times$ memory savings for rotational optimization on a 70B model.
Furthermore, it is the first to successfully complete rotational calibration
for a 70B model on a single 3090 GPU, making quantization of large language
models feasible in resource-constrained environments. Code is available at
https://github.com/CAS-CLab/DartQuant.git.

</details>


### [157] [Pediatric Appendicitis Detection from Ultrasound Images](https://arxiv.org/abs/2511.04069)
*Fatemeh Hosseinabadi,Seyedhassan Sharifi*

Main category: cs.LG

TL;DR: 本研究开发和评估了一个基于ResNet的深度学习模型，能够有效从超声图像中自动检测儿童阑尾炎，取得了很好的分类性能。


<details>
  <summary>Details</summary>
Motivation: 阑尾炎在儿童中是有挑战性的急性腹痛原因，症状重叠和成像质量差异使得临床诊断复杂。

Method: 基于预训练的ResNet架构，进行深度学习模型的开发与评估，专注于超声影像中的阑尾炎自动检测。

Result: 提出的ResNet模型达到了93.44的整体准确率、91.53的精确率和89.8的召回率，成功识别出阑尾炎。

Conclusion: 该深度学习模型在不同的超声视图中有效地识别阑尾炎，展现出较高的准确性和鲁棒性。

Abstract: Pediatric appendicitis remains one of the most common causes of acute
abdominal pain in children, and its diagnosis continues to challenge clinicians
due to overlapping symptoms and variable imaging quality. This study aims to
develop and evaluate a deep learning model based on a pretrained ResNet
architecture for automated detection of appendicitis from ultrasound images. We
used the Regensburg Pediatric Appendicitis Dataset, which includes ultrasound
scans, laboratory data, and clinical scores from pediatric patients admitted
with abdominal pain to Children Hospital. Hedwig in Regensburg, Germany. Each
subject had 1 to 15 ultrasound views covering the right lower quadrant,
appendix, lymph nodes, and related structures. For the image based
classification task, ResNet was fine tuned to distinguish appendicitis from
non-appendicitis cases. Images were preprocessed by normalization, resizing,
and augmentation to enhance generalization. The proposed ResNet model achieved
an overall accuracy of 93.44, precision of 91.53, and recall of 89.8,
demonstrating strong performance in identifying appendicitis across
heterogeneous ultrasound views. The model effectively learned discriminative
spatial features, overcoming challenges posed by low contrast, speckle noise,
and anatomical variability in pediatric imaging.

</details>


### [158] [Left Atrial Segmentation with nnU-Net Using MRI](https://arxiv.org/abs/2511.04071)
*Fatemeh Hosseinabadi,Seyedhassan Sharifi*

Main category: cs.LG

TL;DR: 该研究利用nnU-Net框架在心脏MRI中实现左心房的高效分割，取得优异效果。


<details>
  <summary>Details</summary>
Motivation: 提高左心房从心脏MRI中分割的准确性，以便更好地指导房颤消融和构建生物物理心脏模型。

Method: 应用nnU-Net框架对2013年左心房分割挑战数据集进行自动化深度学习分割。

Result: nnU-Net模型在Dice相似系数(Dice score)上达到了93.5的均值，表现出较高的重叠度且展示了对不同左心房形态、对比度和图像质量的强健泛化能力。

Conclusion: nnU-Net模型在左心房分割中表现出色，优于以往传统方法。

Abstract: Accurate segmentation of the left atrium (LA) from cardiac MRI is critical
for guiding atrial fibrillation (AF) ablation and constructing biophysical
cardiac models. Manual delineation is time-consuming, observer-dependent, and
impractical for large-scale or time-sensitive clinical workflows. Deep learning
methods, particularly convolutional architectures, have recently demonstrated
superior performance in medical image segmentation tasks. In this study, we
applied the nnU-Net framework, an automated, self-configuring deep learning
segmentation architecture, to the Left Atrial Segmentation Challenge 2013
dataset. The dataset consists of thirty MRI scans with corresponding
expert-annotated masks. The nnU-Net model automatically adapted its
preprocessing, network configuration, and training pipeline to the
characteristics of the MRI data. Model performance was quantitatively evaluated
using the Dice similarity coefficient (DSC), and qualitative results were
compared against expert segmentations. The proposed nnU?Net model achieved a
mean Dice score of 93.5, demonstrating high overlap with expert annotations and
outperforming several traditional segmentation approaches reported in previous
studies. The network exhibited robust generalization across variations in left
atrial shape, contrast, and image quality, accurately delineating both the
atrial body and proximal pulmonary veins.

</details>


### [159] [Learning Filter-Aware Distance Metrics for Nearest Neighbor Search with Multiple Filters](https://arxiv.org/abs/2511.04073)
*Ananya Sutradhar,Suryansh Gupta,Ravishankar Krishnaswamy,Haiyang Xu,Aseem Rastogi,Gopal Srinivasa*

Main category: cs.LG

TL;DR: 提出了一种学习最优权重的方法，改进了过滤近似最近邻搜索的准确性，优于传统固定罚款方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的方法在过滤意识上表现不佳，无法有效应对不同数据集之间的标签和向量分布差异。

Method: 将问题公式化为一个约束线性优化问题，从数据中学习向量距离与过滤匹配之间的最优权衡。

Result: 实验结果表明，针对数据自适应的距离函数比固定惩罚方法的准确性提高了5-10%。

Conclusion: 通过从数据中学习最佳权重，该方法显著提升了过滤近似最近邻搜索的准确性，具有更好的灵活性和泛化能力。

Abstract: Filtered Approximate Nearest Neighbor (ANN) search retrieves the closest
vectors for a query vector from a dataset. It enforces that a specified set of
discrete labels $S$ for the query must be included in the labels of each
retrieved vector. Existing graph-based methods typically incorporate filter
awareness by assigning fixed penalties or prioritizing nodes based on filter
satisfaction. However, since these methods use fixed, data in- dependent
penalties, they often fail to generalize across datasets with diverse label and
vector distributions. In this work, we propose a principled alternative that
learns the optimal trade-off between vector distance and filter match directly
from the data, rather than relying on fixed penalties. We formulate this as a
constrained linear optimization problem, deriving weights that better reflect
the underlying filter distribution and more effectively address the filtered
ANN search problem. These learned weights guide both the search process and
index construction, leading to graph structures that more effectively capture
the underlying filter distribution and filter semantics. Our experiments
demonstrate that adapting the distance function to the data significantly im-
proves accuracy by 5-10% over fixed-penalty methods, providing a more flexible
and generalizable framework for the filtered ANN search problem.

</details>


### [160] [DeNoise: Learning Robust Graph Representations for Unsupervised Graph-Level Anomaly Detection](https://arxiv.org/abs/2511.04086)
*Qingfeng Chen,Haojin Zeng,Jingyi Jie,Shichao Zhang,Debo Cheng*

Main category: cs.LG

TL;DR: 提出DeNoise框架，解决异常图污染问题，提高图级异常检测的表现。


<details>
  <summary>Details</summary>
Motivation: 由于大多数GNN方法假设训练集仅包含正常图，这在实际应用中不常见，因此存在异常图污染的问题。

Method: 提出了一种联合优化图级编码器、属性解码器和结构解码器的对抗性目标，从而学习抗噪声的嵌入表示，并引入锚对齐去噪机制和对比学习组件。

Result: 在八个真实数据集上进行的实验表明，DeNoise在不同噪声强度下，始终能够学习到高质量的图级表示。

Conclusion: DeNoise在处理含有异常图的训练数据时，能够有效学习可靠的图级表示，明显超越现有UGAD方法。

Abstract: With the rapid growth of graph-structured data in critical domains,
unsupervised graph-level anomaly detection (UGAD) has become a pivotal task.
UGAD seeks to identify entire graphs that deviate from normal behavioral
patterns. However, most Graph Neural Network (GNN) approaches implicitly assume
that the training set is clean, containing only normal graphs, which is rarely
true in practice. Even modest contamination by anomalous graphs can distort
learned representations and sharply degrade performance. To address this
challenge, we propose DeNoise, a robust UGAD framework explicitly designed for
contaminated training data. It jointly optimizes a graph-level encoder, an
attribute decoder, and a structure decoder via an adversarial objective to
learn noise-resistant embeddings. Further, DeNoise introduces an encoder
anchor-alignment denoising mechanism that fuses high-information node
embeddings from normal graphs into all graph embeddings, improving
representation quality while suppressing anomaly interference. A contrastive
learning component then compacts normal graph embeddings and repels anomalous
ones in the latent space. Extensive experiments on eight real-world datasets
demonstrate that DeNoise consistently learns reliable graph-level
representations under varying noise intensities and significantly outperforms
state-of-the-art UGAD baselines.

</details>


### [161] [KoTaP: A Panel Dataset for Corporate Tax Avoidance, Performance, and Governance in Korea](https://arxiv.org/abs/2511.04094)
*Hyungjong Na,Wonho Song,Seungyong Han,Donghyeon Jo,Sejin Myung,Hyungjoon Kim*

Main category: cs.LG

TL;DR: 本研究建立了Korean Tax Avoidance Panel (KoTaP)，一个包含12,653个观测值的长期面板数据集，旨在分析税务规避与多种企业特征之间的关系，是跨学科研究的关键资源。


<details>
  <summary>Details</summary>
Motivation: 建立KoTaP数据集的目的是为了填补对韩国企业税务规避的研究空白，并提供一个可用于多方面分析的资源。

Method: 通过构建一个包含多个变量的长时间面板数据集，分析非金融公司在税务规避与财务指标之间的关系。

Result: KoTaP最终包含12,653个企业年度观测值，涵盖1,754家公司，能够连接税务规避与公司治理、盈利能力、成长性等多个领域的研究。

Conclusion: KoTaP作为一个独特的面板数据集，提供了丰富的税务规避和公司特征的分析能力，具有国际可比性和本土特色，适用于多领域研究和实际应用。

Abstract: This study introduces the Korean Tax Avoidance Panel (KoTaP), a long-term
panel dataset of non-financial firms listed on KOSPI and KOSDAQ between 2011
and 2024. After excluding financial firms, firms with non-December fiscal year
ends, capital impairment, and negative pre-tax income, the final dataset
consists of 12,653 firm-year observations from 1,754 firms. KoTaP is designed
to treat corporate tax avoidance as a predictor variable and link it to
multiple domains, including earnings management (accrual- and activity-based),
profitability (ROA, ROE, CFO, LOSS), stability (LEV, CUR, SIZE, PPE, AGE,
INVREC), growth (GRW, MB, TQ), and governance (BIG4, FORN, OWN). Tax avoidance
itself is measured using complementary indicators cash effective tax rate
(CETR), GAAP effective tax rate (GETR), and book-tax difference measures (TSTA,
TSDA) with adjustments to ensure interpretability. A key strength of KoTaP is
its balanced panel structure with standardized variables and its consistency
with international literature on the distribution and correlation of core
indicators. At the same time, it reflects distinctive institutional features of
Korean firms, such as concentrated ownership, high foreign shareholding, and
elevated liquidity ratios, providing both international comparability and
contextual uniqueness. KoTaP enables applications in benchmarking econometric
and deep learning models, external validity checks, and explainable AI
analyses. It further supports policy evaluation, audit planning, and investment
analysis, making it a critical open resource for accounting, finance, and
interdisciplinary research.

</details>


### [162] [Decomposable Neuro Symbolic Regression](https://arxiv.org/abs/2511.04124)
*Giorgio Morales,John W. Sheppard*

Main category: cs.LG

TL;DR: 提出了一种可解释的符号回归方法，实现了以透明的方式捕捉数据中的复杂关系。


<details>
  <summary>Details</summary>
Motivation: 通过提供可解释的数学表达，解决传统符号回归方法在识别规律上的不足。

Method: 使用多集变换器生成多元象征骨架，结合遗传算法和遗传编程优化表达式。

Result: 在控制和变化噪声条件下评估，表现出低于或可以比拟的错误率。

Conclusion: 该方法生成的表达式成功匹配了原始数学结构，并在插值和外推错误方面表现出色。

Abstract: Symbolic regression (SR) models complex systems by discovering mathematical
expressions that capture underlying relationships in observed data. However,
most SR methods prioritize minimizing prediction error over identifying the
governing equations, often producing overly complex or inaccurate expressions.
To address this, we present a decomposable SR method that generates
interpretable multivariate expressions leveraging transformer models, genetic
algorithms (GAs), and genetic programming (GP). In particular, our explainable
SR method distills a trained ``opaque'' regression model into mathematical
expressions that serve as explanations of its computed function. Our method
employs a Multi-Set Transformer to generate multiple univariate symbolic
skeletons that characterize how each variable influences the opaque model's
response. We then evaluate the generated skeletons' performance using a
GA-based approach to select a subset of high-quality candidates before
incrementally merging them via a GP-based cascade procedure that preserves
their original skeleton structure. The final multivariate skeletons undergo
coefficient optimization via a GA. We evaluated our method on problems with
controlled and varying degrees of noise, demonstrating lower or comparable
interpolation and extrapolation errors compared to two GP-based methods, three
neural SR methods, and a hybrid approach. Unlike them, our approach
consistently learned expressions that matched the original mathematical
structure.

</details>


### [163] [Exploring the Feasibility of End-to-End Large Language Model as a Compiler](https://arxiv.org/abs/2511.04132)
*Hongbin Zhang,Shihao Gao,Yang Liu,Mingjie Xing,Yanjun Wu,Chen Zhao*

Main category: cs.LG

TL;DR: 本论文探讨了LLM作为编译器的可行性及未来方向，设计评估框架，发现LLM具备基本编译能力但成功率低，提出优化建议以提升代码质量。


<details>
  <summary>Details</summary>
Motivation: LLM技术在多个领域显示出优势，但作为端到端编译器的潜力尚未被充分探索。

Method: 设计CompilerEval数据集和框架，对主流LLM在源代码理解和汇编代码生成能力进行评估。

Result: 实验结果表明，LLM作为编译器的基本能力存在，但编译成功率较低，通过优化提示、模型扩展和推理方法可以显著提高生成的汇编代码质量。

Conclusion: LaaC（将大型语言模型作为编译器）具有潜力生成高质量汇编代码，并推动编译领域的变革。

Abstract: In recent years, end-to-end Large Language Model (LLM) technology has shown
substantial advantages across various domains. As critical system software and
infrastructure, compilers are responsible for transforming source code into
target code. While LLMs have been leveraged to assist in compiler development
and maintenance, their potential as an end-to-end compiler remains largely
unexplored. This paper explores the feasibility of LLM as a Compiler (LaaC) and
its future directions. We designed the CompilerEval dataset and framework
specifically to evaluate the capabilities of mainstream LLMs in source code
comprehension and assembly code generation. In the evaluation, we analyzed
various errors, explored multiple methods to improve LLM-generated code, and
evaluated cross-platform compilation capabilities. Experimental results
demonstrate that LLMs exhibit basic capabilities as compilers but currently
achieve low compilation success rates. By optimizing prompts, scaling up the
model, and incorporating reasoning methods, the quality of assembly code
generated by LLMs can be significantly enhanced. Based on these findings, we
maintain an optimistic outlook for LaaC and propose practical architectural
designs and future research directions. We believe that with targeted training,
knowledge-rich prompts, and specialized infrastructure, LaaC has the potential
to generate high-quality assembly code and drive a paradigm shift in the field
of compilation.

</details>


### [164] [Exchange Policy Optimization Algorithm for Semi-Infinite Safe Reinforcement Learning](https://arxiv.org/abs/2511.04147)
*Jiaming Zhang,Yujie Yang,Haoning Wang,Liping Zhang,Shengbo Eben Li*

Main category: cs.LG

TL;DR: 本研究提出了EPO算法，旨在解决半无限安全强化学习中的约束问题，实现最佳策略性能与安全保障。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，安全强化学习面临无限约束的问题，因此需要一种有效的算法来处理这些半无限安全约束。

Method: 该方法通过迭代解决带有限约束集的安全强化学习子问题，并通过约束扩展和删除自适应调整活动约束集来优化策略。

Result: 通过理论分析，EPO训练的策略在满足给定安全边界的同时，其性能与最优解相当。

Conclusion: EPO算法在实现最优策略性能的同时，确保了确定性范围内的安全约束，适用于具有无限约束的安全强化学习问题。

Abstract: Safe reinforcement learning (safe RL) aims to respect safety requirements
while optimizing long-term performance. In many practical applications,
however, the problem involves an infinite number of constraints, known as
semi-infinite safe RL (SI-safe RL). Such constraints typically appear when
safety conditions must be enforced across an entire continuous parameter space,
such as ensuring adequate resource distribution at every spatial location. In
this paper, we propose exchange policy optimization (EPO), an algorithmic
framework that achieves optimal policy performance and deterministic bounded
safety. EPO works by iteratively solving safe RL subproblems with finite
constraint sets and adaptively adjusting the active set through constraint
expansion and deletion. At each iteration, constraints with violations
exceeding the predefined tolerance are added to refine the policy, while those
with zero Lagrange multipliers are removed after the policy update. This
exchange rule prevents uncontrolled growth of the working set and supports
effective policy training. Our theoretical analysis demonstrates that, under
mild assumptions, strategies trained via EPO achieve performance comparable to
optimal solutions with global constraint violations strictly remaining within a
prescribed bound.

</details>


### [165] [Learning to Land Anywhere: Transferable Generative Models for Aircraft Trajectories](https://arxiv.org/abs/2511.04155)
*Olav Finne Praesteng Larsen,Massimiliano Ruocco,Michail Spitieris,Abdulmajid Murad,Martina Ragosta*

Main category: cs.LG

TL;DR: 通过迁移学习，利用数据丰富机场的信息，可以在数据稀缺机场上实现有效的轨迹生成，显著降低数据需求。


<details>
  <summary>Details</summary>
Motivation: 许多次要和地区机场面临数据稀缺问题，限制了机器学习方法的应用，因此需要探讨如何在数据丰富机场训练的模型能否有效适用于数据稀缺机场。

Method: 利用生成模型和迁移学习，分别以苏黎世为源机场和都柏林为目标机场进行预训练与微调，以评估轨迹数据的转移能力。

Result: 基于扩散的模型在只使用5%的都柏林数据时已能获得竞争性能，20%时达到基线表现，始终优于从头训练的模型；而流匹配模型则表现出较弱的泛化能力。

Conclusion: 迁移学习能有效减少航空交通管理中生成轨迹所需的数据，允许在数据稀缺的环境中生成逼真的合成数据。

Abstract: Access to trajectory data is a key requirement for developing and validating
Air Traffic Management (ATM) solutions, yet many secondary and regional
airports face severe data scarcity. This limits the applicability of machine
learning methods and the ability to perform large-scale simulations or
"what-if" analyses. In this paper, we investigate whether generative models
trained on data-rich airports can be efficiently adapted to data-scarce
airports using transfer learning. We adapt state-of-the-art diffusion- and
flow-matching-based architectures to the aviation domain and evaluate their
transferability between Zurich (source) and Dublin (target) landing trajectory
datasets. Models are pretrained on Zurich and fine-tuned on Dublin with varying
amounts of local data, ranging from 0% to 100%. Results show that
diffusion-based models achieve competitive performance with as little as 5% of
the Dublin data and reach baseline-level performance around 20%, consistently
outperforming models trained from scratch across metrics and visual
inspections. Latent flow matching and latent diffusion models also benefit from
pretraining, though with more variable gains, while flow matching models show
weaker generalization. Despite challenges in capturing rare trajectory
patterns, these findings demonstrate the potential of transfer learning to
substantially reduce data requirements for trajectory generation in ATM,
enabling realistic synthetic data generation even in environments with limited
historical records.

</details>


### [166] [Deep Learning Approach for Clinical Risk Identification Using Transformer Modeling of Heterogeneous EHR Data](https://arxiv.org/abs/2511.04158)
*Anzhuo Xie,Wei-Chen Chang*

Main category: cs.LG

TL;DR: 本研究提出一种Transformer基础的纵向建模方法，针对异构电子健康记录数据的风险分类问题，在多项指标上表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 旨在解决临床风险分类中电子健康记录数据的异质性问题，具体包括不规则的时间模式、大量的模态差异和复杂的语义结构。

Method: 提出了一种基于Transformer的纵向建模方法，利用多源医学特征作为输入，结合特征嵌入层、可学习的时间编码、和多头自注意力结构进行风险分类。

Result: 实验结果显示，该模型在准确率、召回率、精确率和F1得分上均优于传统机器学习和时间深度学习模型。

Conclusion: 该方法在多源异构电子健康记录环境中实现了准确、稳定的风险识别，并为临床智能决策提供了高效可靠的框架。

Abstract: This study proposes a Transformer-based longitudinal modeling method to
address challenges in clinical risk classification with heterogeneous
Electronic Health Record (EHR) data, including irregular temporal patterns,
large modality differences, and complex semantic structures. The method takes
multi-source medical features as input and employs a feature embedding layer to
achieve a unified representation of structured and unstructured data. A
learnable temporal encoding mechanism is introduced to capture dynamic
evolution under uneven sampling intervals. The core model adopts a multi-head
self-attention structure to perform global dependency modeling on longitudinal
sequences, enabling the aggregation of long-term trends and short-term
fluctuations across different temporal scales. To enhance semantic
representation, a semantic-weighted pooling module is designed to assign
adaptive importance to key medical events, improving the discriminative ability
of risk-related features. Finally, a linear mapping layer generates
individual-level risk scores. Experimental results show that the proposed model
outperforms traditional machine learning and temporal deep learning models in
accuracy, recall, precision, and F1-Score, achieving stable and precise risk
identification in multi-source heterogeneous EHR environments and providing an
efficient and reliable framework for clinical intelligent decision-making.

</details>


### [167] [On Joint Regularization and Calibration in Deep Ensembles](https://arxiv.org/abs/2511.04160)
*Laurits Fredsgaard,Mikkel N. Schmidt*

Main category: cs.LG

TL;DR: 本文研究了深度集成模型中的联合调整策略及其对性能的影响，并提出了一个实用的部分重叠保留策略。


<details>
  <summary>Details</summary>
Motivation: 提高模型性能和不确定性校准，探索联合调整对集成模型的影响。

Method: 研究联合调整权重衰减、温度缩放和提前停止策略的影响，并提出部分重叠的保留策略用于联合评估。

Result: 联合调整集成模型的超参数一般能够匹配或改善性能，且效果在不同任务上差异明显。

Conclusion: 联合调整深度集成模型的超参数通常能够提升性能，并在不同任务和指标上效果各异。

Abstract: Deep ensembles are a powerful tool in machine learning, improving both model
performance and uncertainty calibration. While ensembles are typically formed
by training and tuning models individually, evidence suggests that jointly
tuning the ensemble can lead to better performance. This paper investigates the
impact of jointly tuning weight decay, temperature scaling, and early stopping
on both predictive performance and uncertainty quantification. Additionally, we
propose a partially overlapping holdout strategy as a practical compromise
between enabling joint evaluation and maximizing the use of data for training.
Our results demonstrate that jointly tuning the ensemble generally matches or
improves performance, with significant variation in effect size across
different tasks and metrics. We highlight the trade-offs between individual and
joint optimization in deep ensemble training, with the overlapping holdout
strategy offering an attractive practical solution. We believe our findings
provide valuable insights and guidance for practitioners looking to optimize
deep ensemble models. Code is available at:
https://github.com/lauritsf/ensemble-optimality-gap

</details>


### [168] [Block Rotation is All You Need for MXFP4 Quantization](https://arxiv.org/abs/2511.04214)
*Yuantian Shao,Peisong Wang,Yuanteng Chen,Chang Xu,Zhihui Wei,Jian Cheng*

Main category: cs.LG

TL;DR: 本研究对MXFP4格式下的后训练量化方法进行评估，提出了一种改进的块旋转策略，显著提升了大型语言模型的精度。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的发展，后训练量化（PTQ）成为在内存、计算和能耗方面高效部署的关键挑战，特别是针对新兴的MXFP4格式。

Method: 通过系统评估与基准测试，比较了不同后训练量化（PTQ）方法在MXFP4格式下的表现。

Result: 发现GPTQ等方法在MXFP4格式下表现优异，而大多数先进方法使用的基于旋转的方法与MXFP4存在严重不兼容的问题。

Conclusion: 本研究提出了一个有效的块旋转策略，改进了现有基于旋转的方法，使其适用于MXFP4格式，从而显著提升了不同大型语言模型的精度。

Abstract: Large language models (LLMs) have achieved remarkable success, but their
rapidly growing scale imposes prohibitive costs in memory, computation, and
energy. Post-training quantization (PTQ) is a promising solution for efficient
deployment, yet achieving accurate W4A4 quantization remains an open challenge.
While most existing methods are designed for INT4 formats, the emergence of
MXFP4 -- a new FP4 format with various hardware support (NVIDIA, AMD, Intel)--
raises questions about the applicability of current techniques. In this work,
we establish a comprehensive benchmark of PTQ methods under the MXFP4 format.
Through systematic evaluation, we find that methods like GPTQ consistently
deliver strong performance, whereas rotation-based approaches, which are almost
used by all state-of-the-art approaches, suffer from severe incompatibility
with MXFP4. We further provide the first in-depth analysis of this conflict,
tracing its root to a fundamental mismatch between MXFP4's PoT (power-of-two)
block scaling and the redistribution of outlier energy via global rotation.
Building on this insight, we propose a simple yet effective block rotation
strategy that adapts rotation-based methods to MXFP4, leading to substantial
accuracy improvements across diverse LLMs. Our findings not only offer clear
guidance for practitioners but also set a foundation for advancing PTQ research
under emerging low-precision formats.

</details>


### [169] [The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms](https://arxiv.org/abs/2511.04217)
*Hikari Otsuka,Daiki Chijiwa,Yasuyuki Okoshi,Daichi Fujiki,Susumu Takeuchi,Masato Motomura*

Main category: cs.LG

TL;DR: 本研究为多头注意力机制中的强彩票票据提供了理论分析，并通过实验证实了这一假设，扩展了强彩票票据假设至没有归一化层的变换器架构。


<details>
  <summary>Details</summary>
Motivation: 缺乏对变换器架构中的强彩票票据假设的理论理解，尤其是对多头注意力机制的考虑。

Method: 通过理论分析证明多头注意力机制中强彩票票据的存在，并通过实验证明了理论结果的有效性。

Result: 证明了在特定条件下，随机初始化的多头注意力机制能包含一个强彩票票据，并且通过增加隐藏维度可以显著减少模型之间的近似误差。

Conclusion: 该研究验证了在多头注意力机制中存在强彩票票据的理论，并扩展了强彩票票据假设以适用于没有归一化层的变换器架构。

Abstract: The strong lottery ticket hypothesis (SLTH) conjectures that high-performing
subnetworks, called strong lottery tickets (SLTs), are hidden in randomly
initialized neural networks. Although recent theoretical studies have
established the SLTH across various neural architectures, the SLTH for
transformer architectures still lacks theoretical understanding. In particular,
the current theory of the SLTH does not yet account for the multi-head
attention (MHA) mechanism, a core component of transformers. To address this
gap, we introduce a theoretical analysis of the existence of SLTs within MHAs.
We prove that, if a randomly initialized MHA of $H$ heads and input dimension
$d$ has the hidden dimension $O(d\log(Hd^{3/2}))$ for the key and value, it
contains an SLT that approximates an arbitrary MHA with the same input
dimension with high probability. Furthermore, by leveraging this theory for
MHAs, we extend the SLTH to transformers without normalization layers. We
empirically validate our theoretical findings, demonstrating that the
approximation error between the SLT within a source model (MHA and transformer)
and an approximate target counterpart decreases exponentially by increasing the
hidden dimension of the source model.

</details>


### [170] [seqme: a Python library for evaluating biological sequence design](https://arxiv.org/abs/2511.04239)
*Rasmus Møller-Larsen,Adam Izdebski,Jan Olszewski,Pankhil Gawade,Michal Kmicikiewicz,Wojciech Zarzecki,Ewa Szczurek*

Main category: cs.LG

TL;DR: seqme是一个用于评估生物序列设计计算方法的Python库，提供多种无关模型的评估指标和可视化工具。


<details>
  <summary>Details</summary>
Motivation: 随着生物序列设计计算方法的进步，急需一套完整的工具来评估这些方法的性能。

Method: seqme库包含三类指标：基于序列的、基于嵌入的和基于属性的，并适用于多种生物序列。

Result: seqme提供了多种生物序列的嵌入和属性模型，以及用于结果检查的诊断和可视化功能。

Conclusion: seqme是一个模块化且高度可扩展的开源Python库，提供生物序列设计计算方法评估的模型无关指标。

Abstract: Recent advances in computational methods for designing biological sequences
have sparked the development of metrics to evaluate these methods performance
in terms of the fidelity of the designed sequences to a target distribution and
their attainment of desired properties. However, a single software library
implementing these metrics was lacking. In this work we introduce seqme, a
modular and highly extendable open-source Python library, containing
model-agnostic metrics for evaluating computational methods for biological
sequence design. seqme considers three groups of metrics: sequence-based,
embedding-based, and property-based, and is applicable to a wide range of
biological sequences: small molecules, DNA, ncRNA, mRNA, peptides and proteins.
The library offers a number of embedding and property models for biological
sequences, as well as diagnostics and visualization functions to inspect the
results. seqme can be used to evaluate both one-shot and iterative
computational design methods.

</details>


### [171] [Guided by Stars: Interpretable Concept Learning Over Time Series via Temporal Logic Semantics](https://arxiv.org/abs/2511.04244)
*Irene Ferfoglia,Simone Silvetti,Gaia Saveri,Laura Nenzi,Luca Bortolussi*

Main category: cs.LG

TL;DR: STELLE是一个新的神经符号框架，通过时序逻辑嵌入来实现时间序列分类和解释，同时优化模型的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 为了解决时间序列分类中深度学习方法的黑箱问题，增强模型的可解释性。

Method: 提出了一种神经符号框架，通过直接将时间序列嵌入到时序逻辑概念空间中来进行分类和解释。

Result: STELLE在多种实际基准上获得了竞争性的准确性，并提供了符合逻辑的解释。

Conclusion: STELLE提供了一种竞争性准确性和可信的逻辑解释的解决方案。

Abstract: Time series classification is a task of paramount importance, as this kind of
data often arises in safety-critical applications. However, it is typically
tackled with black-box deep learning methods, making it hard for humans to
understand the rationale behind their output. To take on this challenge, we
propose a novel approach, STELLE (Signal Temporal logic Embedding for
Logically-grounded Learning and Explanation), a neuro-symbolic framework that
unifies classification and explanation through direct embedding of trajectories
into a space of temporal logic concepts. By introducing a novel STL-inspired
kernel that maps raw time series to their alignment with predefined STL
formulae, our model jointly optimises accuracy and interpretability, as each
prediction is accompanied by the most relevant logical concepts that
characterise it. This yields (i) local explanations as human-readable STL
conditions justifying individual predictions, and (ii) global explanations as
class-characterising formulae. Experiments demonstrate that STELLE achieves
competitive accuracy while providing logically faithful explanations, validated
on diverse real-world benchmarks.

</details>


### [172] [Efficient Reinforcement Learning from Human Feedback via Bayesian Preference Inference](https://arxiv.org/abs/2511.04286)
*Matteo Cercola,Valeria Capretti,Simone Formentin*

Main category: cs.LG

TL;DR: 提出一种混合框架，结合RLHF的可扩展性与PBO的查询效率，提升偏好学习的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 人类偏好学习在机器学习模型与主观人类判断的对齐中至关重要，但收集偏好数据往往代价高昂且耗时，需要更高效的学习方案。

Method: 将一个基于获取驱动的模块整合进RLHF管道，以实现主动和样本高效的偏好收集。

Result: 在高维偏好优化和LLM微调两个领域，实验结果显示该方法在样本效率和整体性能上均有一致性提升。

Conclusion: 提出的混合框架通过将RLHF的可扩展性与PBO的查询效率结合，实现了有效的偏好学习，且在两个代表性领域中验证了其有效性。

Abstract: Learning from human preferences is a cornerstone of aligning machine learning
models with subjective human judgments. Yet, collecting such preference data is
often costly and time-consuming, motivating the need for more efficient
learning paradigms. Two established approaches offer complementary advantages:
RLHF scales effectively to high-dimensional tasks such as LLM fine-tuning,
while PBO achieves greater sample efficiency through active querying. We
propose a hybrid framework that unifies RLHF's scalability with PBO's query
efficiency by integrating an acquisition-driven module into the RLHF pipeline,
thereby enabling active and sample-efficient preference gathering. We validate
the proposed approach on two representative domains: (i) high-dimensional
preference optimization and (ii) LLM fine-tuning. Experimental results
demonstrate consistent improvements in both sample efficiency and overall
performance across these tasks.

</details>


### [173] [Differentially Private In-Context Learning with Nearest Neighbor Search](https://arxiv.org/abs/2511.04332)
*Antti Koskela,Tejas Kulkarni,Laith Zumot*

Main category: cs.LG

TL;DR: 该研究提出一种差分隐私框架，改进了上下文学习，通过隐私-aware的最近邻搜索增强了隐私保护和效用，实验结果显示相较于现有方法有明显优势。


<details>
  <summary>Details</summary>
Motivation: 由于上下文学习固有的隐私风险，研究差分隐私的上下文学习变得日益重要，而现有方法未考虑到现代大型语言模型管道中的相似性搜索。

Method: 结合邻近邻居检索与隐私过滤器，跟踪选定样本的隐私成本，以保证遵循中心差分隐私预算。

Result: 在评估的所有基准测试中，所提出的DP框架在性能上显著超过了现有的方法，取得了更有利的隐私-效用权衡。

Conclusion: 提出的方法在隐私效用权衡方面优于现有基线，展现了显著的性能提升，特别是在文本分类和文档问答任务中表现突出。

Abstract: Differentially private in-context learning (DP-ICL) has recently become an
active research topic due to the inherent privacy risks of in-context learning.
However, existing approaches overlook a critical component of modern large
language model (LLM) pipelines: the similarity search used to retrieve relevant
context data. In this work, we introduce a DP framework for in-context learning
that integrates nearest neighbor search of relevant examples in a privacy-aware
manner. Our method outperforms existing baselines by a substantial margin
across all evaluated benchmarks, achieving more favorable privacy-utility
trade-offs. To achieve this, we employ nearest neighbor retrieval from a
database of context data, combined with a privacy filter that tracks the
cumulative privacy cost of selected samples to ensure adherence to a central
differential privacy budget. Experimental results on text classification and
document question answering show a clear advantage of the proposed method over
existing baselines.

</details>


### [174] [Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness](https://arxiv.org/abs/2511.04401)
*Subeen Park,Joowang Kim,Hakyung Lee,Sunjae Yoo,Kyungwoo Song*

Main category: cs.LG

TL;DR: 提出了一种名为SCER的新方法，旨在改善模型在弱组中的表现，通过正则化特征嵌入来抑制虚假线索。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在不同领域表现良好，但在分布转变时易受虚假相关性影响，特别是在子群体转变场景中表现较差。

Method: 提出了一种新的方法SCER，通过正则化特征表示来压制虚假线索，以增强模型的鲁棒性。

Result: 理论证明分类器对虚假和核心方向的依赖程度影响最坏组错误，通过在嵌入层施加理论约束，SCER驱动模型关注核心特征，降低对虚假模式的敏感性。

Conclusion: SCER显著提升了模型在弱组的准确率，超过了现有的最先进技术。

Abstract: Deep learning models achieve strong performance across various domains but
often rely on spurious correlations, making them vulnerable to distribution
shifts. This issue is particularly severe in subpopulation shift scenarios,
where models struggle in underrepresented groups. While existing methods have
made progress in mitigating this issue, their performance gains are still
constrained. They lack a rigorous theoretical framework connecting the
embedding space representations with worst-group error. To address this
limitation, we propose Spurious Correlation-Aware Embedding Regularization for
Worst-Group Robustness (SCER), a novel approach that directly regularizes
feature representations to suppress spurious cues. We show theoretically that
worst-group error is influenced by how strongly the classifier relies on
spurious versus core directions, identified from differences in group-wise mean
embeddings across domains and classes. By imposing theoretical constraints at
the embedding level, SCER encourages models to focus on core features while
reducing sensitivity to spurious patterns. Through systematic evaluation on
multiple vision and language, we show that SCER outperforms prior
state-of-the-art studies in worst-group accuracy. Our code is available at
\href{https://github.com/MLAI-Yonsei/SCER}{https://github.com/MLAI-Yonsei/SCER}.

</details>


### [175] [The Illusion of Certainty: Uncertainty quantification for LLMs fails under ambiguity](https://arxiv.org/abs/2511.04418)
*Tim Tomov,Dominik Fuchsgruber,Tom Wollschläger,Stephan Günnemann*

Main category: cs.LG

TL;DR: 本研究表明，现有的不确定性量化方法在处理模糊数据时存在重大缺陷，需要对建模方法进行重新思考。


<details>
  <summary>Details</summary>
Motivation: 针对大型语言模型在面对现实世界语言模糊性时的可靠性问题，探索当前不确定性量化方法的局限性。

Method: 通过引入MAQA*和AmbigQA*数据集，对不确定性估计方法在模糊问答任务中的表现进行评估。

Result: 实验发现，现有的不确定性估计器在无模糊假设下表现良好，但在模糊数据上却接近随机性能，且这一现象在不同的估计范式中一致出现。

Conclusion: 当前的大型语言模型的不确定性量化方法在处理模糊数据时表现不佳，这揭示了其关键短板，并激励了对现有建模范式的重新思考。

Abstract: Accurate uncertainty quantification (UQ) in Large Language Models (LLMs) is
critical for trustworthy deployment. While real-world language is inherently
ambiguous, reflecting aleatoric uncertainty, existing UQ methods are typically
benchmarked against tasks with no ambiguity. In this work, we demonstrate that
while current uncertainty estimators perform well under the restrictive
assumption of no ambiguity, they degrade to close-to-random performance on
ambiguous data. To this end, we introduce MAQA* and AmbigQA*, the first
ambiguous question-answering (QA) datasets equipped with ground-truth answer
distributions estimated from factual co-occurrence. We find this performance
deterioration to be consistent across different estimation paradigms: using the
predictive distribution itself, internal representations throughout the model,
and an ensemble of models. We show that this phenomenon can be theoretically
explained, revealing that predictive-distribution and ensemble-based estimators
are fundamentally limited under ambiguity. Overall, our study reveals a key
shortcoming of current UQ methods for LLMs and motivates a rethinking of
current modeling paradigms.

</details>


### [176] [Ground-Truth Subgraphs for Better Training and Evaluation of Knowledge Graph Augmented LLMs](https://arxiv.org/abs/2511.04473)
*Alberto Cattaneo,Carlo Luschi,Daniel Justus*

Main category: cs.LG

TL;DR: 本研究介绍了SynthKGQA框架，能够生成合成知识图谱问答数据集，以提高KG检索器的评估和模型训练效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有QA数据集缺乏挑战性和地面真实目标的问题，从而促进KG检索器的比较与评估。

Method: 提出SynthKGQA框架以生成合成知识图谱问答数据集，并应用于Wikidata生成GTSQA数据集。

Result: SynthKGQA的应用使得在未见图结构和关系类型下评估KG检索器的零样本泛化能力成为可能，并对KG增强的LLM进行了基准测试。

Conclusion: SynthKGQA框架能够生成高质量的合成知识图谱问答数据集，从而提升KG检索器的评估和模型的训练效果。

Abstract: Retrieval of information from graph-structured knowledge bases represents a
promising direction for improving the factuality of LLMs. While various
solutions have been proposed, a comparison of methods is difficult due to the
lack of challenging QA datasets with ground-truth targets for graph retrieval.
We present SynthKGQA, a framework for generating high-quality synthetic
Knowledge Graph Question Answering datasets from any Knowledge Graph, providing
the full set of ground-truth facts in the KG to reason over each question. We
show how, in addition to enabling more informative benchmarking of KG
retrievers, the data produced with SynthKGQA also allows us to train better
models. We apply SynthKGQA to Wikidata to generate GTSQA, a new dataset
designed to test zero-shot generalization abilities of KG retrievers with
respect to unseen graph structures and relation types, and benchmark popular
solutions for KG-augmented LLMs on it.

</details>


### [177] [ForecastGAN: A Decomposition-Based Adversarial Framework for Multi-Horizon Time Series Forecasting](https://arxiv.org/abs/2511.04445)
*Syeda Sitara Wishal Fatima,Afshin Rahimi*

Main category: cs.LG

TL;DR: 提出一种新颖的ForecastGAN框架，通过模块化设计改善时间序列的短期和长期预测性能，尤其对分类特征有更好的处理。


<details>
  <summary>Details</summary>
Motivation: 解决现有多视角预测方法在短期预测和分类特征处理上的局限性。

Method: 引入ForecastGAN框架，包括分解模块、模型选择模块和对抗训练模块，通过综合处理数字和分类特征来提高预测的鲁棒性。

Result: 在11个基准多元时间序列数据集上验证，ForecastGAN在短期预测中表现优于最新的变压器模型，同时在长期预测中也保持竞争力。

Conclusion: ForecastGAN在短期预测中表现优于现有的变压器模型，并且在长期预测中保持竞争力，表明其在时间序列预测中的普适性和强大性能。

Abstract: Time series forecasting is essential across domains from finance to supply
chain management. This paper introduces ForecastGAN, a novel decomposition
based adversarial framework addressing limitations in existing approaches for
multi-horizon predictions. Although transformer models excel in long-term
forecasting, they often underperform in short-term scenarios and typically
ignore categorical features. ForecastGAN operates through three integrated
modules: a Decomposition Module that extracts seasonality and trend components;
a Model Selection Module that identifies optimal neural network configurations
based on forecasting horizon; and an Adversarial Training Module that enhances
prediction robustness through Conditional Generative Adversarial Network
training. Unlike conventional approaches, ForecastGAN effectively integrates
both numerical and categorical features. We validate our framework on eleven
benchmark multivariate time series datasets that span various forecasting
horizons. The results show that ForecastGAN consistently outperforms
state-of-the-art transformer models for short-term forecasting while remaining
competitive for long-term horizons. This research establishes a more
generalizable approach to time series forecasting that adapts to specific
contexts while maintaining strong performance across diverse data
characteristics without extensive hyperparameter tuning.

</details>


### [178] [Federated Stochastic Minimax Optimization under Heavy-Tailed Noises](https://arxiv.org/abs/2511.04456)
*Xinwen Zhang,Hongchang Gao*

Main category: cs.LG

TL;DR: 本文研究重尾噪声下的非凸联邦最小最大优化，提出了两种新算法并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 重尾噪声在非凸随机优化中被认为比标准有界方差假设更具现实性，特别是在联邦学习中。

Method: 提出了两种新算法：Fed-NSGDA-M（集成归一化梯度）和FedMuon-DA（利用Muon优化器进行本地更新）。

Result: 两种算法在重尾梯度噪声下的收敛速度为$O({1}/{(TNp)^{rac{s-1}{2s}}})$，并具有严格的理论保证。

Conclusion: 本文提出的两种新算法在重尾噪声下有效解决了联邦最小最大优化问题，并提供了理论保证，实验结果验证了算法的有效性。

Abstract: Heavy-tailed noise has attracted growing attention in nonconvex stochastic
optimization, as numerous empirical studies suggest it offers a more realistic
assumption than standard bounded variance assumption. In this work, we
investigate nonconvex-PL minimax optimization under heavy-tailed gradient noise
in federated learning. We propose two novel algorithms: Fed-NSGDA-M, which
integrates normalized gradients, and FedMuon-DA, which leverages the Muon
optimizer for local updates. Both algorithms are designed to effectively
address heavy-tailed noise in federated minimax optimization, under a milder
condition. We theoretically establish that both algorithms achieve a
convergence rate of $O({1}/{(TNp)^{\frac{s-1}{2s}}})$. To the best of our
knowledge, these are the first federated minimax optimization algorithms with
rigorous theoretical guarantees under heavy-tailed noise. Extensive experiments
further validate their effectiveness.

</details>


### [179] [Towards Causal Market Simulators](https://arxiv.org/abs/2511.04469)
*Dennis Thumm,Luis Ontaneda Mijares*

Main category: cs.LG

TL;DR: 提出了一种新的时间序列神经因果模型VAE，能有效生成合成金融数据并进行因果分析，优化金融风险评估。


<details>
  <summary>Details</summary>
Motivation: 目前的生成模型在合成金融数据生成中缺乏必要的因果推理能力，无法有效支持反事实分析和风险评估。

Method: 结合变分自编码器和结构因果模型，通过编码器架构的有向无环图强制实施因果约束，并采用因果Wasserstein距离进行训练。

Result: 在基于Ornstein-Uhlenbeck过程的合成自回归模型上验证了方法，与真实值相比，反事实概率估计的L1距离低至0.03-0.10，表现优越。

Conclusion: 提出的TNCM-VAE模型在生成合成金融时间序列和进行反事实分析方面表现出色，可以有效支持金融压力测试和情景分析。

Abstract: Market generators using deep generative models have shown promise for
synthetic financial data generation, but existing approaches lack causal
reasoning capabilities essential for counterfactual analysis and risk
assessment. We propose a Time-series Neural Causal Model VAE (TNCM-VAE) that
combines variational autoencoders with structural causal models to generate
counterfactual financial time series while preserving both temporal
dependencies and causal relationships. Our approach enforces causal constraints
through directed acyclic graphs in the decoder architecture and employs the
causal Wasserstein distance for training. We validate our method on synthetic
autoregressive models inspired by the Ornstein-Uhlenbeck process, demonstrating
superior performance in counterfactual probability estimation with L1 distances
as low as 0.03-0.10 compared to ground truth. The model enables financial
stress testing, scenario analysis, and enhanced backtesting by generating
plausible counterfactual market trajectories that respect underlying causal
mechanisms.

</details>


### [180] [Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank Training](https://arxiv.org/abs/2511.04485)
*Ipsita Ghosh,Ethan Nguyen,Christian Kümmerle*

Main category: cs.LG

TL;DR: Q3R是一种新的低秩训练策略，通过二次正则化优秀地处理低秩预训练任务，验证了在不同深度学习模型上的有效性。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够在低秩预训练任务中有效训练模型的算法，以解决现有低秩训练技术的不足。

Method: 提出了Q3R方法，这是一种基于二次正则化项和迭代加权最小二乘框架的低秩诱导训练策略。

Result: Q3R能够训练具有预设低目标秩的权重矩阵，以及在CIFAR-10上保持较小的准确率下降，同时支持现有体系结构。

Conclusion: Q3R方法在维持低秩结构的同时，能够有效训练大型深度学习模型并保持预测性能，验证了其在图像和语言任务中的有效性。

Abstract: Parameter-efficient training, based on low-rank optimization, has become a
highly successful tool for fine-tuning large deep-learning models. However,
these methods fail at low-rank pre-training tasks where maintaining the
low-rank structure and the objective remains a challenging task. We propose the
Quadratic Reweighted Rank Regularizer dubbed Q3R, which leads to a novel
low-rank inducing training strategy inspired by the iteratively reweighted
least squares (IRLS) framework. Q3R is based on a quadratic regularizer term
which majorizes a smoothed log determinant serving as rank surrogate objective.
Unlike other low-rank training techniques, Q3R is able to train weight matrices
with prescribed, low target ranks of models that achieve comparable predictive
performance as dense models, with small computational overhead, while remaining
fully compatible with existing architectures. For example, we demonstrated one
experiment where we are able to truncate $60\%$ and $80\%$ of the parameters of
a ViT-Tiny model with $~1.3\%$ and $~4\%$ accuracy drop in CIFAR-10 performance
respectively. The efficacy of Q3R is confirmed on Transformers across both
image and language tasks, including for low-rank fine-tuning.

</details>


### [181] [Alternative Fairness and Accuracy Optimization in Criminal Justice](https://arxiv.org/abs/2511.04505)
*Shaolong Wu,James Blume,Geshi Yeung*

Main category: cs.LG

TL;DR: 本文探讨了算法公平性在刑事司法中的挑战，并提出了一种新方法以改进群体公平性和预测准确性，为公共决策提供了框架。


<details>
  <summary>Details</summary>
Motivation: 为了提高算法公平性，特别是在刑事司法领域，传统的公平性标准存在争议，需要新的方法以平衡公平性与准确性的关系。

Method: 通过审查群体、公平性、个体公平性和过程公平性，提出了对标准群体公平性的简单修改，并探讨了其应用中的伦理问题和数据偏见等挑战。

Result: 通过提出新的错误损失最小化策略，改善了群体公平性，提高了预测准确性，并为公共决策系统的应用提供了实践框架。

Conclusion: 提出了一种基于权重的错误损失最小化方法，以提升算法公平性，同时兼顾预见准确性和伦理选择，并为公共决策系统提供了可操作框架。

Abstract: Algorithmic fairness has grown rapidly as a research area, yet key concepts
remain unsettled, especially in criminal justice. We review group, individual,
and process fairness and map the conditions under which they conflict. We then
develop a simple modification to standard group fairness. Rather than exact
parity across protected groups, we minimize a weighted error loss while keeping
differences in false negative rates within a small tolerance. This makes
solutions easier to find, can raise predictive accuracy, and surfaces the
ethical choice of error costs. We situate this proposal within three classes of
critique: biased and incomplete data, latent affirmative action, and the
explosion of subgroup constraints. Finally, we offer a practical framework for
deployment in public decision systems built on three pillars: need-based
decisions, Transparency and accountability, and narrowly tailored definitions
and solutions. Together, these elements link technical design to legitimacy and
provide actionable guidance for agencies that use risk assessment and related
tools.

</details>


### [182] [Linear Mode Connectivity under Data Shifts for Deep Ensembles of Image Classifiers](https://arxiv.org/abs/2511.04514)
*C. Hepburn,T. Zielke,A. P. Raulf*

Main category: cs.LG

TL;DR: 本研究探讨了线性模式连接现象对深度学习中的训练和泛化能力的影响，并提出在面对数据偏移时减少随机梯度噪声的策略。


<details>
  <summary>Details</summary>
Motivation: 探讨LMC现金态对深度学习训练稳定性、局部最小值的平滑性和泛化能力的影响，寻找减轻数据偏移影响的方法。

Method: 通过实验研究LMC在数据偏移下的表现，探索小学习率和大批量大小的影响。

Result: 识别出减轻数据偏移影响的条件，并表明小学习率和大批量对模型收敛结果的影响。

Conclusion: 线性模式连接现象在深度学习中有助于理解训练稳定性和模型表现，LMC在应对数据偏移时表现出一定的优越性。

Abstract: The phenomenon of linear mode connectivity (LMC) links several aspects of
deep learning, including training stability under noisy stochastic gradients,
the smoothness and generalization of local minima (basins), the similarity and
functional diversity of sampled models, and architectural effects on data
processing. In this work, we experimentally study LMC under data shifts and
identify conditions that mitigate their impact. We interpret data shifts as an
additional source of stochastic gradient noise, which can be reduced through
small learning rates and large batch sizes. These parameters influence whether
models converge to the same local minimum or to regions of the loss landscape
with varying smoothness and generalization. Although models sampled via LMC
tend to make similar errors more frequently than those converging to different
basins, the benefit of LMC lies in balancing training efficiency against the
gains achieved from larger, more diverse ensembles. Code and supplementary
materials will be made publicly available at https://github.com/DLR-KI/LMC in
due course.

</details>


### [183] [Comparing EPGP Surrogates and Finite Elements Under Degree-of-Freedom Parity](https://arxiv.org/abs/2511.04518)
*Obed Amo,Samit Ghosh,Markus Lange-Hegermann,Bogdan Raiţă,Michael Pokojovy*

Main category: cs.LG

TL;DR: 本研究比较了B-EPGP和CN-FEM在解决二维波动方程时的性能，结果显示B-EPGP显著提高了精确度。


<details>
  <summary>Details</summary>
Motivation: 通过构建新的评价标准，公平比较两种解决方案在求解二维波动方程中的表现。

Method: 使用边界约束的Ehrenpreis--Palamodov高斯过程(B-EPGP)与经典有限元方法(CN-FEM)进行比较，解决带有齐次Dirichlet边界条件的二维波动方程。

Result: 在匹配自由度的情况下，B-EPGP的空间和时间L^2误差均低于CN-FEM。

Conclusion: B-EPGP在空间和时间的L^2误差上显著优于CN-FEM，准确度提高约两个数量级。

Abstract: We present a new benchmarking study comparing a boundary-constrained
Ehrenpreis--Palamodov Gaussian Process (B-EPGP) surrogate with a classical
finite element method combined with Crank--Nicolson time stepping (CN-FEM) for
solving the two-dimensional wave equation with homogeneous Dirichlet boundary
conditions. The B-EPGP construction leverages exponential-polynomial bases
derived from the characteristic variety to enforce the PDE and boundary
conditions exactly and employs penalized least squares to estimate the
coefficients. To ensure fairness across paradigms, we introduce a
degrees-of-freedom (DoF) matching protocol. Under matched DoF, B-EPGP
consistently attains lower space-time $L^2$-error and maximum-in-time
$L^{2}$-error in space than CN-FEM, improving accuracy by roughly two orders of
magnitude.

</details>


### [184] [Uncertainty Quantification for Reduced-Order Surrogate Models Applied to Cloud Microphysics](https://arxiv.org/abs/2511.04534)
*Jonas E. Katona,Emily K. de Jong,Nipun Gunawardena*

Main category: cs.LG

TL;DR: 提出了一种新的方法来提高潜在空间ROM的不确定性量化能力，适用于多种物理系统。


<details>
  <summary>Details</summary>
Motivation: 当前的ROM在不确定性量化方面存在不足，缺乏灵活性和普适性。

Method: 利用符合预测法估计ROM管道多个组件的统计预测区间。

Result: 在云微物理的潜在空间动力模型中成功应用，准确预测了液滴尺寸分布的演变并量化了不确定性。

Conclusion: 提出了一种模型不可知的框架来实现潜在空间ROM的预测不确定性量化，具有效率和准确性。

Abstract: Reduced-order models (ROMs) can efficiently simulate high-dimensional
physical systems, but lack robust uncertainty quantification methods. Existing
approaches are frequently architecture- or training-specific, which limits
flexibility and generalization. We introduce a post hoc, model-agnostic
framework for predictive uncertainty quantification in latent space ROMs that
requires no modification to the underlying architecture or training procedure.
Using conformal prediction, our approach estimates statistical prediction
intervals for multiple components of the ROM pipeline: latent dynamics,
reconstruction, and end-to-end predictions. We demonstrate the method on a
latent space dynamical model for cloud microphysics, where it accurately
predicts the evolution of droplet-size distributions and quantifies uncertainty
across the ROM pipeline.

</details>


### [185] [Integrating Temporal and Structural Context in Graph Transformers for Relational Deep Learning](https://arxiv.org/abs/2511.04557)
*Divyansha Lachi,Mahmoud Mohammadi,Joe Meyer,Vinam Arora,Tom Palczewski,Eva L. Dyer*

Main category: cs.LG

TL;DR: 本文提出了一种新型的关系图变换器RGP，改进了时间和空间信息的整合，为关系深度学习提供了通用的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有图模型主要关注空间结构，对于时间信息的处理不足，且通常只适用于单任务预测。

Method: 提出了一个时间子图采样器和基于图转换器的Relational Graph Perceiver（RGP）架构。

Result: RGP在RelBench、SALT和CTU上的实验表明，其性能达到最前沿，能够有效整合结构和时间上下文信息。

Conclusion: RGP在关系深度学习中表现出色，提供了一种通用且可扩展的解决方案，支持多种预测任务。

Abstract: In domains such as healthcare, finance, and e-commerce, the temporal dynamics
of relational data emerge from complex interactions-such as those between
patients and providers, or users and products across diverse categories. To be
broadly useful, models operating on these data must integrate long-range
spatial and temporal dependencies across diverse types of entities, while also
supporting multiple predictive tasks. However, existing graph models for
relational data primarily focus on spatial structure, treating temporal
information merely as a filtering constraint to exclude future events rather
than a modeling signal, and are typically designed for single-task prediction.
To address these gaps, we introduce a temporal subgraph sampler that enhances
global context by retrieving nodes beyond the immediate neighborhood to capture
temporally relevant relationships. In addition, we propose the Relational Graph
Perceiver (RGP), a graph transformer architecture for relational deep learning
that leverages a cross-attention-based latent bottleneck to efficiently
integrate information from both structural and temporal contexts. This latent
bottleneck integrates signals from different node and edge types into a common
latent space, enabling the model to build global context across the entire
relational system. RGP also incorporates a flexible cross-attention decoder
that supports joint learning across tasks with disjoint label spaces within a
single model. Experiments on RelBench, SALT, and CTU show that RGP delivers
state-of-the-art performance, offering a general and scalable solution for
relational deep learning with support for diverse predictive tasks.

</details>


### [186] [ARETE: an R package for Automated REtrieval from TExt with large language models](https://arxiv.org/abs/2511.04573)
*Vasco V. Branco,Jandó Benedek,Lidia Pivovarova,Luís Correia,Pedro Cardoso*

Main category: cs.LG

TL;DR: ARETE R 包提供了一种高效的生物物种数据提取解决方案，通过自动化流程显著提高数据获取的速度与准确性，支持生物多样性保护的研究工作。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏关键物种数据，尤其是出现数据，导致保护工作受阻。因此，需要快速、准确地获取这些数据以应对人类活动带来的挑战。

Method: 开发了一个开源的 R 软件包 ARETE，利用大语言模型（如 chatGPT API）自动化提取物种出现数据，包括光学字符识别、异常值检测和表格输出等步骤，并与人工注释结果进行系统比较进行验证。

Result: ARETE 成功地扩展了已知物种出现范围的平均三个数量级，为过去物种出现的新区域提供了重要信息，对空间保护规划和灭绝风险评估具有重大意义。

Conclusion: ARETE R 包为生物物种出现数据的提取与验证提供了高效的自动化解决方案，显著提高了数据的获取速度和准确性，有助于更好地支持保护工作。

Abstract: 1. A hard stop for the implementation of rigorous conservation initiatives is
our lack of key species data, especially occurrence data. Furthermore,
researchers have to contend with an accelerated speed at which new information
must be collected and processed due to anthropogenic activity. Publications
ranging from scientific papers to gray literature contain this crucial
information but their data are often not machine-readable, requiring extensive
human work to be retrieved. 2. We present the ARETE R package, an open-source
software aiming to automate data extraction of species occurrences powered by
large language models, namely using the chatGPT Application Programming
Interface. This R package integrates all steps of the data extraction and
validation process, from Optical Character Recognition to detection of outliers
and output in tabular format. Furthermore, we validate ARETE through systematic
comparison between what is modelled and the work of human annotators. 3. We
demonstrate the usefulness of the approach by comparing range maps produced
using GBIF data and with those automatically extracted for 100 species of
spiders. Newly extracted data allowed to expand the known Extent of Occurrence
by a mean three orders of magnitude, revealing new areas where the species were
found in the past, which mayhave important implications for spatial
conservation planning and extinction risk assessments. 4. ARETE allows faster
access to hitherto untapped occurrence data, a potential game changer in
projects requiring such data. Researchers will be able to better prioritize
resources, manually verifying selected species while maintaining automated
extraction for the majority. This workflow also allows predicting available
bibliographic data during project planning.

</details>


### [187] [Complexity as Advantage: A Regret-Based Perspective on Emergent Structure](https://arxiv.org/abs/2511.04590)
*Oshri Naparstek*

Main category: cs.LG

TL;DR: CAA框架定义了系统复杂性相对于观察者的概念，量化预测悔恨差异，强调复杂性在功能上的价值。


<details>
  <summary>Details</summary>
Motivation: 探索如何量化系统复杂性及其对不同观察者的影响，以此揭示复杂系统的功能价值。

Method: 通过引入观察者的预测悔恨作为评估系统复杂性的标准，结合多尺度熵、预测信息及观察者依赖结构等概念进行分析。

Result: 通过简单的动力学模型验证了CAA框架的有效性，并探讨其对学习、进化和人工智能的影响。

Conclusion: 提出的CAA框架为系统复杂性提供了一种相对观察者的定义，强调不同观察者对系统的预测悔恨程度差异，从而揭示了复杂性的功能价值。

Abstract: We introduce Complexity as Advantage (CAA), a framework that defines the
complexity of a system relative to a family of observers. Instead of measuring
complexity as an intrinsic property, we evaluate how much predictive regret a
system induces for different observers attempting to model it. A system is
complex when it is easy for some observers and hard for others, creating an
information advantage. We show that this formulation unifies several notions of
emergent behavior, including multiscale entropy, predictive information, and
observer-dependent structure. The framework suggests that "interesting" systems
are those positioned to create differentiated regret across observers,
providing a quantitative grounding for why complexity can be functionally
valuable. We demonstrate the idea through simple dynamical models and discuss
implications for learning, evolution, and artificial agents.

</details>


### [188] [Addressing divergent representations from causal interventions on neural networks](https://arxiv.org/abs/2511.04638)
*Satchel Grant,Simon Jerome Han,Alexa Tartaglini,Christopher Potts*

Main category: cs.LG

TL;DR: 本研究探讨因果干预对模型表征的影响，发现干预可能导致偏离自然分布，并提出了一种新方法以提高可解释性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 研究因果干预技术是否会使模型内部表征偏离自然分布，以及这种偏离对解释模型的忠实性影响的关注。

Method: 实证研究和理论分析相结合，探讨了因果干预对模型内部表征的影响，并分类分析了偏离类型。

Result: 实证表明，常见的因果干预技术会导致内部表征偏离自然分布，并识别出两类偏离：'无害'和'有害'偏离。在此基础上，提出了新的损失函数，以减轻有害偏离。

Conclusion: 本研究通过修改反事实潜在(CL)损失，提出了一种更可靠的可解释性方法，降低了有害偏离的可能性，同时保持了干预的解释能力。

Abstract: A common approach to mechanistic interpretability is to causally manipulate
model representations via targeted interventions in order to understand what
those representations encode. Here we ask whether such interventions create
out-of-distribution (divergent) representations, and whether this raises
concerns about how faithful their resulting explanations are to the target
model in its natural state. First, we demonstrate empirically that common
causal intervention techniques often do shift internal representations away
from the natural distribution of the target model. Then, we provide a
theoretical analysis of two classes of such divergences: `harmless' divergences
that occur in the null-space of the weights and from covariance within
behavioral decision boundaries, and `pernicious' divergences that activate
hidden network pathways and cause dormant behavioral changes. Finally, in an
effort to mitigate the pernicious cases, we modify the Counterfactual Latent
(CL) loss from Grant (2025) that regularizes interventions to remain closer to
the natural distributions, reducing the likelihood of harmful divergences while
preserving the interpretive power of interventions. Together, these results
highlight a path towards more reliable interpretability methods.

</details>


### [189] [Efficient probabilistic surrogate modeling techniques for partially-observed large-scale dynamical systems](https://arxiv.org/abs/2511.04641)
*Hans Harder,Abhijeet Vishwasrao,Luca Guastoni,Ricardo Vinuesa,Sebastian Peitz*

Main category: cs.LG

TL;DR: 本文探讨了用于预测动态系统的概率技术，比较了多种蒸馏方法，实验显示这些方法在减少采样步骤和提高效率方面具有潜力。


<details>
  <summary>Details</summary>
Motivation: 随着动态系统的复杂性增加，传统的预测方法面临大量采样步骤的挑战，因此需要开发新的技术来提高预报的效率和准确性。

Method: 通过比较不同的流匹配扩展技术（如直接蒸馏、渐进蒸馏、对抗扩散蒸馏、Wasserstein GANs和修正流），来研究预报方法。

Result: 实验结果表明，所提出的方法在处理复杂系统时表现良好，尤其是在直接预测大规模3D模拟的2D切片时，拓宽了高效输入生成的可能性。

Conclusion: 本文提出的概率技术能够有效地预测由偏微分方程描述的动态系统，特别是能够减少采样步骤，提高预报效率。

Abstract: This paper is concerned with probabilistic techniques for forecasting
dynamical systems described by partial differential equations (such as, for
example, the Navier-Stokes equations). In particular, it is investigating and
comparing various extensions to the flow matching paradigm that reduce the
number of sampling steps. In this regard, it compares direct distillation,
progressive distillation, adversarial diffusion distillation, Wasserstein GANs
and rectified flows. Moreover, experiments are conducted on a set of
challenging systems. In particular, we also address the challenge of directly
predicting 2D slices of large-scale 3D simulations, paving the way for
efficient inflow generation for solvers.

</details>


### [190] [Optimal Inference Schedules for Masked Diffusion Models](https://arxiv.org/abs/2511.04647)
*Sitan Chen,Kevin Cong,Jerry Li*

Main category: cs.LG

TL;DR: 本文提出了扩散语言模型的采样性能新理论，展示了如何在保持性能的同时提升采样效率。


<details>
  <summary>Details</summary>
Motivation: 解决标准自回归语言模型序列推理过程速度慢的问题，探索无掩码推理的并行采样能力。

Method: 通过使用单变量函数近似理论，提供了真实分布与采样分布之间期望差异的精确表征，分析不同的解码调度。

Result: 得到了对采样调度的新的上界和下界，并表明在某些条件下可以在O(log n)步内完成采样，而没有明显的性能损失。

Conclusion: 提出了扩散语言模型的精确性质，为采样分布提供了新的上界和下界，使其性能在某些自然情况下能够保持不变。

Abstract: A major bottleneck of standard auto-regressive large language models is that
their inference process is inherently sequential, resulting in very long and
costly inference times. To circumvent this, practitioners proposed a class of
language models called diffusion language models, of which the masked diffusion
model (MDM) is the most successful. The MDM is able to sample tokens
out-of-order and, ostensibly, many tokens at once and in parallel. However,
there is very limited rigorous understanding of how much parallel sampling
these models can perform without noticeable degradation in their sampling
performance. Prior work of Li and Cai obtained some preliminary bounds, but
these are not tight for many natural classes of distributions. In this work, we
give a new, exact characterization of the expected divergence between the true
distribution and the sampled distribution, for any distribution and any
unmasking schedule for the sampler, showing an elegant connection to the theory
of univariate function approximation.
  By leveraging this connection, we then attain a number of novel lower and
upper bounds for this problem. While the connection to function approximation
in principle gives the optimal unmasking schedule for any distribution, we show
that it is in general impossible to compete with it without strong a priori
knowledge of the distribution, even in seemingly benign settings. However, we
also demonstrate new upper bounds and new sampling schedules in terms of
well-studied information-theoretic properties of the base distribution, namely,
its total correlation and dual total correlation, which show that in some
natural settings, one can sample in $O(log n)$ steps without any visible loss
in performance, where $n$ is the total sequence length.

</details>


### [191] [TT-Prune: Joint Model Pruning and Resource Allocation for Communication-efficient Time-triggered Federated Learning](https://arxiv.org/abs/2511.04653)
*Xinlu Zhang,Yansha Deng,Toktam Mahmoodi*

Main category: cs.LG

TL;DR: 本文引入适应性模型修剪用于无线TT-Fed系统，通过优化修剪比例和带宽分配来减少通信成本，并保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统联邦学习中数据隐私和通信开销等问题，特别是在无线带宽有限的环境下。

Method: 在TT-Fed模型上进行收敛分析，构建修剪比例和无线带宽的联合优化问题，推导出KKT条件下的闭式解。

Result: 提出了一种适应性模型修剪的方法，通过优化修剪比例和带宽分配来最小化训练损失，确保最小学习延迟。

Conclusion: 模型修剪能够减少40%的通信成本，同时保持模型性能不变。

Abstract: Federated learning (FL) offers new opportunities in machine learning,
particularly in addressing data privacy concerns. In contrast to conventional
event-based federated learning, time-triggered federated learning (TT-Fed), as
a general form of both asynchronous and synchronous FL, clusters users into
different tiers based on fixed time intervals. However, the FL network consists
of a growing number of user devices with limited wireless bandwidth,
consequently magnifying issues such as stragglers and communication overhead.
In this paper, we introduce adaptive model pruning to wireless TT-Fed systems
and study the problem of jointly optimizing the pruning ratio and bandwidth
allocation to minimize the training loss while ensuring minimal learning
latency. To answer this question, we perform convergence analysis on the
gradient l_2 norm of the TT-Fed model based on model pruning. Based on the
obtained convergence upper bound, a joint optimization problem of pruning ratio
and wireless bandwidth is formulated to minimize the model training loss under
a given delay threshold. Then, we derive closed-form solutions for wireless
bandwidth and pruning ratio using Karush-Kuhn-Tucker(KKT) conditions. The
simulation results show that model pruning could reduce the communication cost
by 40% while maintaining the model performance at the same level.

</details>


### [192] [Nowcast3D: Reliable precipitation nowcasting via gray-box learning](https://arxiv.org/abs/2511.04659)
*Huaguan Chen,Wei Han,Haofei Sun,Ning Lin,Xingtao Song,Yunfan Yang,Jie Tian,Yang Liu,Ji-Rong Wen,Xiaoye Zhang,Xueshun Shen,Hao Sun*

Main category: cs.LG

TL;DR: 提出了一种创新的三维雷达短时降水预报框架，结合物理和数据驱动方法，显著提高了降水预报能力和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有降水预报方法在空间时间忠实度与提前时间方面受限，亟需改进。

Method: 提出了一种灰箱的全三维短时预报框架，结合物理约束神经算子与数据驱动学习，处理体积雷达反射率。

Result: 该框架在57%的案例中在160位气象学家的盲测评估中排名第一，能够进行最多三小时的准确降水预报。

Conclusion: 该框架提供了有效且可靠的极端降水短时预报，显著提升了预测准确性。

Abstract: Extreme precipitation nowcasting demands high spatiotemporal fidelity and
extended lead times, yet existing approaches remain limited. Numerical Weather
Prediction (NWP) and its deep-learning emulations are too slow and coarse for
rapidly evolving convection, while extrapolation and purely data-driven models
suffer from error accumulation and excessive smoothing. Hybrid 2D radar-based
methods discard crucial vertical information, preventing accurate
reconstruction of height-dependent dynamics. We introduce a gray-box, fully
three-dimensional nowcasting framework that directly processes volumetric radar
reflectivity and couples physically constrained neural operators with
datadriven learning. The model learns vertically varying 3D advection fields
under a conservative advection operator, parameterizes spatially varying
diffusion, and introduces a Brownian-motion--inspired stochastic term to
represent unresolved motions. A residual branch captures small-scale convective
initiation and microphysical variability, while a diffusion-based stochastic
module estimates uncertainty. The framework achieves more accurate forecasts up
to three-hour lead time across precipitation regimes and ranked first in 57\%
of cases in a blind evaluation by 160 meteorologists. By restoring full 3D
dynamics with physical consistency, it offers a scalable and robust pathway for
skillful and reliable nowcasting of extreme precipitation.

</details>


### [193] [Forgetting is Everywhere](https://arxiv.org/abs/2511.04666)
*Ben Sanati,Thomas L. Lee,Trevor McInroe,Aidan Scannell,Nikolay Malkin,David Abel,Amos Storkey*

Main category: cs.LG

TL;DR: 提出了一种对遗忘的理论理解，揭示其在学习算法中的重要性，并通过实验验证。


<details>
  <summary>Details</summary>
Motivation: 开发通用学习算法的一个基本挑战是适应新数据时倾向于遗忘过去知识。

Method: 通过设计一系列全面的实验，涵盖分类、回归、生成建模和强化学习，验证理论。

Result: 遗忘在所有学习设置中普遍存在，对学习效率具有重要影响。通过这项研究，我们提出了一种普遍的遗忘测量方法。

Conclusion: 这项研究为理解遗忘提供了原则性框架，并为改进学习算法的信息保留能力奠定了基础。

Abstract: A fundamental challenge in developing general learning algorithms is their
tendency to forget past knowledge when adapting to new data. Addressing this
problem requires a principled understanding of forgetting; yet, despite decades
of study, no unified definition has emerged that provides insights into the
underlying dynamics of learning. We propose an algorithm- and task-agnostic
theory that characterises forgetting as a lack of self-consistency in a
learner's predictive distribution over future experiences, manifesting as a
loss of predictive information. Our theory naturally yields a general measure
of an algorithm's propensity to forget. To validate the theory, we design a
comprehensive set of experiments that span classification, regression,
generative modelling, and reinforcement learning. We empirically demonstrate
how forgetting is present across all learning settings and plays a significant
role in determining learning efficiency. Together, these results establish a
principled understanding of forgetting and lay the foundation for analysing and
improving the information retention capabilities of general learning
algorithms.

</details>


### [194] [Multi-Method Analysis of Mathematics Placement Assessments: Classical, Machine Learning, and Clustering Approaches](https://arxiv.org/abs/2511.04667)
*Julian D. Allagan,Dasia A. Singleton,Shanae N. Perry,Gabrielle C. Morgan,Essence A. Morgan*

Main category: cs.LG

TL;DR: 本研究运用多种方法评估数学考试，发现多数项目表现优秀，并提出了替换、重新评估和整合预测的方法以优化分班。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估目前的数学分班考试的有效性，并通过数据分析提出改进建议。

Method: 本研究结合经典测验理论、机器学习和无监督聚类，评估了一项包含40个项目的数学分班考试。

Result: 结果显示55%的项目表现出优秀的区分度，机器学习算法表现出色，成功识别了学生的二元能力结构，并提出了一些具体的优化建议。

Conclusion: 本研究表明，采用多方法框架的整合，可以为数学分班优化提供强有力的实证基础。

Abstract: This study evaluates a 40-item mathematics placement examination administered
to 198 students using a multi-method framework combining Classical Test Theory,
machine learning, and unsupervised clustering. Classical Test Theory analysis
reveals that 55\% of items achieve excellent discrimination ($D \geq 0.40$)
while 30\% demonstrate poor discrimination ($D < 0.20$) requiring replacement.
Question 6 (Graph Interpretation) emerges as the examination's most powerful
discriminator, achieving perfect discrimination ($D = 1.000$), highest ANOVA
F-statistic ($F = 4609.1$), and maximum Random Forest feature importance
(0.206), accounting for 20.6\% of predictive power. Machine learning algorithms
demonstrate exceptional performance, with Random Forest and Gradient Boosting
achieving 97.5\% and 96.0\% cross-validation accuracy. K-means clustering
identifies a natural binary competency structure with a boundary at 42.5\%,
diverging from the institutional threshold of 55\% and suggesting potential
overclassification into remedial categories. The two-cluster solution exhibits
exceptional stability (bootstrap ARI = 0.855) with perfect lower-cluster
purity. Convergent evidence across methods supports specific refinements:
replace poorly discriminating items, implement a two-stage assessment, and
integrate Random Forest predictions with transparency mechanisms. These
findings demonstrate that multi-method integration provides a robust empirical
foundation for evidence-based mathematics placement optimization.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [195] [On the Brittleness of CLIP Text Encoders](https://arxiv.org/abs/2511.04247)
*Allie Tran,Luca Rossetto*

Main category: cs.MM

TL;DR: 本文分析了多模态模型在多媒体信息检索中的鲁棒性问题，并探讨了多种查询扰动对模型稳定性的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP等多模态联合嵌入模型在零-shot分类和多媒体信息检索中取得了进展，但对小输入扰动的稳定性不足，特别是在处理手动表达的查询时。

Method: 通过对多种非语义查询扰动在多模态信息检索场景中进行系统分析，使用TRECVID Ad-Hoc视频搜索查询和V3C1视频集合对CLIP变体进行评估。

Result: 研究发现，句法和语义扰动造成的结果不稳定性最大，而脆弱性主要集中在标点符号和大小写等表面编辑上。

Conclusion: 研究结果强调了在评价视觉语言模型时，稳健性是一个超越基准准确度的重要维度。

Abstract: Multimodal co-embedding models, especially CLIP, have advanced the state of
the art in zero-shot classification and multimedia information retrieval in
recent years by aligning images and text in a shared representation space.
However, such modals trained on a contrastive alignment can lack stability
towards small input perturbations. Especially when dealing with manually
expressed queries, minor variations in the query can cause large differences in
the ranking of the best-matching results. In this paper, we present a
systematic analysis of the effect of multiple classes of non-semantic query
perturbations in an multimedia information retrieval scenario. We evaluate a
diverse set of lexical, syntactic, and semantic perturbations across multiple
CLIP variants using the TRECVID Ad-Hoc Video Search queries and the V3C1 video
collection. Across models, we find that syntactic and semantic perturbations
drive the largest instabilities, while brittleness is concentrated in trivial
surface edits such as punctuation and case. Our results highlight robustness as
a critical dimension for evaluating vision-language models beyond benchmark
accuracy.

</details>

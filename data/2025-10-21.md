<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 152]
- [cs.CL](#cs.CL) [Total: 87]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.AI](#cs.AI) [Total: 42]
- [cs.LG](#cs.LG) [Total: 148]
- [cs.HC](#cs.HC) [Total: 23]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [CrossRay3D: Geometry and Distribution Guidance for Efficient Multimodal 3D Detection](https://arxiv.org/abs/2510.15991)
*Huiming Yang*

Main category: cs.CV

TL;DR: 本研究提出的CrossRay3D稀疏多模态检测器在nuScenes基准上实现了72.4 mAP和74.7 NDS的卓越表现，并在数据缺失情况下表现出强大的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏检测器忽视了标记表示的质量，导致前景质量不佳和性能有限，因此探索几何结构和类别分布对提升稀疏检测器性能的重要性。

Method: 本研究提出了稀疏选择器（SS），其核心模块为Ray-Aware Supervision（RAS）和Class-Balanced Supervision，旨在提高稀疏检测器的性能。

Result: CrossRay3D在运行速度上比其他领先方法快1.84倍，且在处理小物体时保留相关标记。

Conclusion: CrossRay3D在nuScenes基准测试上实现了最先进的表现，并表现出在部分或完全缺失LiDAR或相机数据情况下的强鲁棒性。

Abstract: The sparse cross-modality detector offers more advantages than its
counterpart, the Bird's-Eye-View (BEV) detector, particularly in terms of
adaptability for downstream tasks and computational cost savings. However,
existing sparse detectors overlook the quality of token representation, leaving
it with a sub-optimal foreground quality and limited performance. In this
paper, we identify that the geometric structure preserved and the class
distribution are the key to improving the performance of the sparse detector,
and propose a Sparse Selector (SS). The core module of SS is Ray-Aware
Supervision (RAS), which preserves rich geometric information during the
training stage, and Class-Balanced Supervision, which adaptively reweights the
salience of class semantics, ensuring that tokens associated with small objects
are retained during token sampling. Thereby, outperforming other sparse
multi-modal detectors in the representation of tokens. Additionally, we design
Ray Positional Encoding (Ray PE) to address the distribution differences
between the LiDAR modality and the image. Finally, we integrate the
aforementioned module into an end-to-end sparse multi-modality detector, dubbed
CrossRay3D. Experiments show that, on the challenging nuScenes benchmark,
CrossRay3D achieves state-of-the-art performance with 72.4 mAP and 74.7 NDS,
while running 1.84 faster than other leading methods. Moreover, CrossRay3D
demonstrates strong robustness even in scenarios where LiDAR or camera data are
partially or entirely missing.

</details>


### [2] [RefAtomNet++: Advancing Referring Atomic Video Action Recognition using Semantic Retrieval based Multi-Trajectory Mamba](https://arxiv.org/abs/2510.16444)
*Kunyu Peng,Di Wen,Jia Fu,Jiamin Wu,Kailun Yang,Junwei Zheng,Ruiping Liu,Yufan Chen,Yuqian Fu,Danda Pani Paudel,Luc Van Gool,Rainer Stiefelhagen*

Main category: cs.CV

TL;DR: 本研究提出RefAtomNet++，通过多层次语义对齐与Mamba建模提升了视频中细粒度动作识别的性能，特别是在复杂场景下的应用。


<details>
  <summary>Details</summary>
Motivation: 旨在精确识别特定个体的细粒度动作，推动自然语言指导的人类行为分析，尤其在复杂多人场景下的重要性。

Method: 引入了一种多层次语义对齐交叉注意力机制与多轨迹Mamba建模相结合的新框架，增强了跨模态信息聚合能力。

Result: RefAtomNet++在基准测试中超越了其他方法，特别是在定位目标个体和预测细粒度动作上的表现改进。

Conclusion: RefAtomNet++在识别细粒度动作方面实现了新的最优表现，展示了其在多层次语义对齐交叉注意力机制及多轨迹建模的有效性。

Abstract: Referring Atomic Video Action Recognition (RAVAR) aims to recognize
fine-grained, atomic-level actions of a specific person of interest conditioned
on natural language descriptions. Distinct from conventional action recognition
and detection tasks, RAVAR emphasizes precise language-guided action
understanding, which is particularly critical for interactive human action
analysis in complex multi-person scenarios. In this work, we extend our
previously introduced RefAVA dataset to RefAVA++, which comprises >2.9 million
frames and >75.1k annotated persons in total. We benchmark this dataset using
baselines from multiple related domains, including atomic action localization,
video question answering, and text-video retrieval, as well as our earlier
model, RefAtomNet. Although RefAtomNet surpasses other baselines by
incorporating agent attention to highlight salient features, its ability to
align and retrieve cross-modal information remains limited, leading to
suboptimal performance in localizing the target person and predicting
fine-grained actions. To overcome the aforementioned limitations, we introduce
RefAtomNet++, a novel framework that advances cross-modal token aggregation
through a multi-hierarchical semantic-aligned cross-attention mechanism
combined with multi-trajectory Mamba modeling at the partial-keyword,
scene-attribute, and holistic-sentence levels. In particular, scanning
trajectories are constructed by dynamically selecting the nearest visual
spatial tokens at each timestep for both partial-keyword and scene-attribute
levels. Moreover, we design a multi-hierarchical semantic-aligned
cross-attention strategy, enabling more effective aggregation of spatial and
temporal tokens across different semantic hierarchies. Experiments show that
RefAtomNet++ establishes new state-of-the-art results. The dataset and code are
released at https://github.com/KPeng9510/refAVA2.

</details>


### [3] [IAD-GPT: Advancing Visual Knowledge in Multimodal Large Language Model for Industrial Anomaly Detection](https://arxiv.org/abs/2510.16036)
*Zewen Li,Zitong Yu,Qilang Ye,Weicheng Xie,Wei Zhuo,Linlin Shen*

Main category: cs.CV

TL;DR: 本研究提出IAD-GPT，通过结合文本和图像信息，提升了工业异常检测的效果，并在多个数据集上取得了良好表现。


<details>
  <summary>Details</summary>
Motivation: 目前传统异常检测方法在多轮人机对话和细致描述方面的能力有限，而基于大模型的方法尚未充分发挥其在异常检测任务中的潜力，因而需要探索新方法。

Method: 结合丰富的文本语义与图像的图像级和像素级信息，通过异常提示生成器和文本引导增强器来提高异常检测的精度和模型的视觉理解能力。

Result: 在MVTec-AD和VisA数据集上的广泛实验证明，我们的方法在自监督和少样本异常检测和分割任务中实现了最先进的性能。

Conclusion: 本研究提出了IAD-GPT，一个基于多模态大语言模型的新框架，有效提升了工业异常检测的能力，尤其是在自监督和少量样本异常检测与分割任务中表现出色。

Abstract: The robust causal capability of Multimodal Large Language Models (MLLMs) hold
the potential of detecting defective objects in Industrial Anomaly Detection
(IAD). However, most traditional IAD methods lack the ability to provide
multi-turn human-machine dialogues and detailed descriptions, such as the color
of objects, the shape of an anomaly, or specific types of anomalies. At the
same time, methods based on large pre-trained models have not fully stimulated
the ability of large models in anomaly detection tasks. In this paper, we
explore the combination of rich text semantics with both image-level and
pixel-level information from images and propose IAD-GPT, a novel paradigm based
on MLLMs for IAD. We employ Abnormal Prompt Generator (APG) to generate
detailed anomaly prompts for specific objects. These specific prompts from the
large language model (LLM) are used to activate the detection and segmentation
functions of the pre-trained visual-language model (i.e., CLIP). To enhance the
visual grounding ability of MLLMs, we propose Text-Guided Enhancer, wherein
image features interact with normal and abnormal text prompts to dynamically
select enhancement pathways, which enables language models to focus on specific
aspects of visual data, enhancing their ability to accurately interpret and
respond to anomalies within images. Moreover, we design a Multi-Mask Fusion
module to incorporate mask as expert knowledge, which enhances the LLM's
perception of pixel-level anomalies. Extensive experiments on MVTec-AD and VisA
datasets demonstrate our state-of-the-art performance on self-supervised and
few-shot anomaly detection and segmentation tasks, such as MVTec-AD and VisA
datasets. The codes are available at
\href{https://github.com/LiZeWen1225/IAD-GPT}{https://github.com/LiZeWen1225/IAD-GPT}.

</details>


### [4] [Enrich and Detect: Video Temporal Grounding with Multimodal LLMs](https://arxiv.org/abs/2510.17023)
*Shraman Pramanick,Effrosyni Mavroudi,Yale Song,Rama Chellappa,Lorenzo Torresani,Triantafyllos Afouras*

Main category: cs.CV

TL;DR: ED-VTG利用多模态大语言模型进行视频时间定位，取得了最先进的效果。


<details>
  <summary>Details</summary>
Motivation: 利用多模态大语言模型提高自然语言查询在视频中的定位能力。

Method: 一种两阶段方法，先将语言查询转化为丰富的句子，然后通过轻量级解码器进行地面化。

Result: 在视频时间定位和段落定位的各种基准测试中，达到了最先进的结果，显著优于现有方法。

Conclusion: ED-VTG在视频时间定位任务中表现优异，超越了现有的LLM基础方法，与专业模型相比在零样本评估场景中具备明显优势。

Abstract: We introduce ED-VTG, a method for fine-grained video temporal grounding
utilizing multi-modal large language models. Our approach harnesses the
capabilities of multimodal LLMs to jointly process text and video, in order to
effectively localize natural language queries in videos through a two-stage
process. Rather than being directly grounded, language queries are initially
transformed into enriched sentences that incorporate missing details and cues
to aid in grounding. In the second stage, these enriched queries are grounded,
using a lightweight decoder, which specializes at predicting accurate
boundaries conditioned on contextualized representations of the enriched
queries. To mitigate noise and reduce the impact of hallucinations, our model
is trained with a multiple-instance-learning objective that dynamically selects
the optimal version of the query for each training sample. We demonstrate
state-of-the-art results across various benchmarks in temporal video grounding
and paragraph grounding settings. Experiments reveal that our method
significantly outperforms all previously proposed LLM-based temporal grounding
approaches and is either superior or comparable to specialized models, while
maintaining a clear advantage against them in zero-shot evaluation scenarios.

</details>


### [5] [Effect of Reporting Mode and Clinical Experience on Radiologists' Gaze and Image Analysis Behavior in Chest Radiography](https://arxiv.org/abs/2510.16070)
*Mahta Khoobi,Marc Sebastian von der Stueck,Felix Barajas Ordonez,Anca-Maria Iancu,Eric Corban,Julia Nowak,Aleksandar Kargaliev,Valeria Perelygina,Anna-Sophie Schott,Daniel Pinto dos Santos,Christiane Kuhl,Daniel Truhn,Sven Nebelung,Robert Siepmann*

Main category: cs.CV

TL;DR: 本研究表明，结构化报告和AI辅助结构化报告能够提高放射科医生的诊断准确性和工作效率。


<details>
  <summary>Details</summary>
Motivation: 探索结构化报告和人工智能在放射学图像研究中的潜力，改善放射科医生与影像学的互动。

Method: 前瞻性研究，评估三种报告模式（自由文本、结构化报告和 AI 辅助结构化报告）对图像分析行为、诊断准确性、效率和用户体验的影响。

Result: AI-SR 在诊断准确性方面表现最佳（$	ext{kappa} = 0.71$），报告时间显著减少，用户体验改善。

Conclusion: 结构化报告（SR）通过引导视觉注意力提高了效率，而人工智能辅助的结构化报告（AI-SR）进一步提高了诊断准确性和用户满意度。

Abstract: Structured reporting (SR) and artificial intelligence (AI) may transform how
radiologists interact with imaging studies. This prospective study (July to
December 2024) evaluated the impact of three reporting modes: free-text (FT),
structured reporting (SR), and AI-assisted structured reporting (AI-SR), on
image analysis behavior, diagnostic accuracy, efficiency, and user experience.
Four novice and four non-novice readers (radiologists and medical students)
each analyzed 35 bedside chest radiographs per session using a customized
viewer and an eye-tracking system. Outcomes included diagnostic accuracy
(compared with expert consensus using Cohen's $\kappa$), reporting time per
radiograph, eye-tracking metrics, and questionnaire-based user experience.
Statistical analysis used generalized linear mixed models with Bonferroni
post-hoc tests with a significance level of ($P \le .01$). Diagnostic accuracy
was similar in FT ($\kappa = 0.58$) and SR ($\kappa = 0.60$) but higher in
AI-SR ($\kappa = 0.71$, $P < .001$). Reporting times decreased from $88 \pm 38$
s (FT) to $37 \pm 18$ s (SR) and $25 \pm 9$ s (AI-SR) ($P < .001$). Saccade
counts for the radiograph field ($205 \pm 135$ (FT), $123 \pm 88$ (SR), $97 \pm
58$ (AI-SR)) and total fixation duration for the report field ($11 \pm 5$ s
(FT), $5 \pm 3$ s (SR), $4 \pm 1$ s (AI-SR)) were lower with SR and AI-SR ($P <
.001$ each). Novice readers shifted gaze towards the radiograph in SR, while
non-novice readers maintained their focus on the radiograph. AI-SR was the
preferred mode. In conclusion, SR improves efficiency by guiding visual
attention toward the image, and AI-prefilled SR further enhances diagnostic
accuracy and user satisfaction.

</details>


### [6] [LongInsightBench: A Comprehensive Benchmark for Evaluating Omni-Modal Models on Human-Centric Long-Video Understanding](https://arxiv.org/abs/2510.17305)
*ZhaoYang Han,Qihan Lin,Hao Liang,Bowen Chen,Zhou Liu,Wentao Zhang*

Main category: cs.CV

TL;DR: 本文介绍了LongInsightBench基准，旨在评估模型理解长视频的能力，重点在信息密度、任务多样性和数据质量保障，实验显示全模态模型在某些任务上面临挑战。


<details>
  <summary>Details</summary>
Motivation: 随着长视频的普及，迫切需要一个新的基准来评估模型在理解长视频中各类信息的能力。

Method: 利用多模态融合，设计了六种具有挑战性的任务场景，并建立了一套严格的数据质量保证流程。

Result: 实验结果显示，当前的全模态模型在时间定位和长程因果推断等任务上存在挑战，同时还发现了多模态融合中的信息损失和处理偏差。

Conclusion: LongInsightBench提供了一种有效评估模型理解长视频的能力的基准，尽管目前的全模态模型在某些任务上仍存在困难。

Abstract: We introduce \textbf{LongInsightBench}, the first benchmark designed to
assess models' ability to understand long videos, with a focus on human
language, viewpoints, actions, and other contextual elements, while integrating
\textbf{visual, audio, and text} modalities. Our benchmark excels in three key
areas: \textbf{a) Long-Duration, Information-Dense Videos:} We carefully select
approximately 1,000 videos from open-source datasets FineVideo based on
duration limit and the information density of both visual and audio modalities,
focusing on content like lectures, interviews, and vlogs, which contain rich
language elements. \textbf{b) Diverse and Challenging Task Scenarios:} We have
designed six challenging task scenarios, including both Intra-Event and
Inter-Event Tasks. \textbf{c) Rigorous and Comprehensive Quality Assurance
Pipelines:} We have developed a three-step, semi-automated data quality
assurance pipeline to ensure the difficulty and validity of the synthesized
questions and answer options. Based on LongInsightBench, we designed a series
of experiments. Experimental results shows that Omni-modal models(OLMs) still
face challenge in tasks requiring precise temporal localization (T-Loc) and
long-range causal inference (CE-Caus). Extended experiments reveal the
information loss and processing bias in multi-modal fusion of OLMs. Our dataset
and code is available at
https://anonymous.4open.science/r/LongInsightBench-910F/.

</details>


### [7] [Data-Driven Analysis of Intersectional Bias in Image Classification: A Framework with Bias-Weighted Augmentation](https://arxiv.org/abs/2510.16072)
*Farjana Yesmin*

Main category: cs.CV

TL;DR: 本文提出了一种新方法，通过交叉公平性评估框架和偏差加权增强，显著提高了图像分类系统的公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决机器学习模型在不平衡数据集上训练时出现的交叉偏差问题，以提高模型在不同属性组合下的公平性和准确性。

Method: 引入交叉公平性评估框架（IFEF），结合量化公平性指标和可解释性工具来系统地识别模型预测中的偏差模式，并提出了基于偏差加权的数据增强策略（BWA）。

Result: 实验表明，BWA在提高代表性不足的类别-环境交集的准确性方面最高可提高24个百分点，同时减少公平性指标的差距35%。

Conclusion: 提出了一种可复制的方法来分析和解决图像分类系统中的交叉偏差。

Abstract: Machine learning models trained on imbalanced datasets often exhibit
intersectional biases-systematic errors arising from the interaction of
multiple attributes such as object class and environmental conditions. This
paper presents a data-driven framework for analyzing and mitigating such biases
in image classification. We introduce the Intersectional Fairness Evaluation
Framework (IFEF), which combines quantitative fairness metrics with
interpretability tools to systematically identify bias patterns in model
predictions. Building on this analysis, we propose Bias-Weighted Augmentation
(BWA), a novel data augmentation strategy that adapts transformation
intensities based on subgroup distribution statistics. Experiments on the Open
Images V7 dataset with five object classes demonstrate that BWA improves
accuracy for underrepresented class-environment intersections by up to 24
percentage points while reducing fairness metric disparities by 35%.
Statistical analysis across multiple independent runs confirms the significance
of improvements (p < 0.05). Our methodology provides a replicable approach for
analyzing and addressing intersectional biases in image classification systems.

</details>


### [8] [ObjectTransforms for Uncertainty Quantification and Reduction in Vision-Based Perception for Autonomous Vehicles](https://arxiv.org/abs/2510.16118)
*Nishad Sahu,Shounak Sural,Aditya Satish Patil,Ragunathan,Rajkumar*

Main category: cs.CV

TL;DR: 本文介绍了一种新方法ObjectTransforms，旨在量化和减少视觉对象检测中的不确定性，通过训练和推理中的对象特定变换，提高自主驾驶的安全性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 确保自主驾驶中的安全性和可靠性，降低由于数据偏差和分布漂移带来的不确定性。

Method: 通过对个别对象进行颜色空间扰动和使用扩散模型生成多样化行人实例，增强模型的鲁棒性，并在推理过程中对检测得分的方差进行量化，以评估预测的不确定性。

Result: 通过实验验证，ObjectTransforms在训练中对所有目标类别均显著提高了准确性，并在推理中比较假阳性和真阳性时，能够有效区分不确定性，改善总体精确率-召回曲线。

Conclusion: ObjectTransforms是一种轻量级但有效的机制，可在训练和推理过程中减少和量化视觉感知的不确定性。

Abstract: Reliable perception is fundamental for safety critical decision making in
autonomous driving. Yet, vision based object detector neural networks remain
vulnerable to uncertainty arising from issues such as data bias and
distributional shifts. In this paper, we introduce ObjectTransforms, a
technique for quantifying and reducing uncertainty in vision based object
detection through object specific transformations at both training and
inference times. At training time, ObjectTransforms perform color space
perturbations on individual objects, improving robustness to lighting and color
variations. ObjectTransforms also uses diffusion models to generate realistic,
diverse pedestrian instances. At inference time, object perturbations are
applied to detected objects and the variance of detection scores are used to
quantify predictive uncertainty in real time. This uncertainty signal is then
used to filter out false positives and also recover false negatives, improving
the overall precision recall curve. Experiments with YOLOv8 on the NuImages 10K
dataset demonstrate that our method yields notable accuracy improvements and
uncertainty reduction across all object classes during training, while
predicting desirably higher uncertainty values for false positives as compared
to true positives during inference. Our results highlight the potential of
ObjectTransforms as a lightweight yet effective mechanism for reducing and
quantifying uncertainty in vision-based perception during training and
inference respectively.

</details>


### [9] [GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer](https://arxiv.org/abs/2510.16136)
*Sayan Deb Sarkar,Sinisa Stekovic,Vincent Lepetit,Iro Armeni*

Main category: cs.CV

TL;DR: 本文提出了一种新方法，通过引入普适指导和可微分损失函数，成功解决了3D资产上的外观转移问题，超越了传统评估方法。


<details>
  <summary>Details</summary>
Motivation: 外观转移在游戏、增强现实和数字内容创作等领域有广泛应用，但现有方法在输入和外观对象几何差异较大时效果不佳。

Method: 无训练方法，通过在采样过程中定期添加可微分的指导损失函数，结合图像或文本条件的预训练流模型。

Result: 实验结果表明，提出的方法在定性和定量上均优于基线，同时通过GPT系统进行的评估确保了对外观转移质量的客观评估。

Conclusion: 提出了一种基于普适指导的外观转移方法，成功实现纹理和几何细节的转移，且效果优于传统基线。

Abstract: Transferring appearance to 3D assets using different representations of the
appearance object - such as images or text - has garnered interest due to its
wide range of applications in industries like gaming, augmented reality, and
digital content creation. However, state-of-the-art methods still fail when the
geometry between the input and appearance objects is significantly different. A
straightforward approach is to directly apply a 3D generative model, but we
show that this ultimately fails to produce appealing results. Instead, we
propose a principled approach inspired by universal guidance. Given a
pretrained rectified flow model conditioned on image or text, our training-free
method interacts with the sampling process by periodically adding guidance.
This guidance can be modeled as a differentiable loss function, and we
experiment with two different types of guidance including part-aware losses for
appearance and self-similarity. Our experiments show that our approach
successfully transfers texture and geometric details to the input 3D asset,
outperforming baselines both qualitatively and quantitatively. We also show
that traditional metrics are not suitable for evaluating the task due to their
inability of focusing on local details and comparing dissimilar inputs, in
absence of ground truth data. We thus evaluate appearance transfer quality with
a GPT-based system objectively ranking outputs, ensuring robust and human-like
assessment, as further confirmed by our user study. Beyond showcased scenarios,
our method is general and could be extended to different types of diffusion
models and guidance functions.

</details>


### [10] [C-arm Guidance: A Self-supervised Approach To Automated Positioning During Stroke Thrombectomy](https://arxiv.org/abs/2510.16145)
*Ahmad Arrabi,Jay hwasung Jung,J Le,A Nguyen,J Reed,E Stahl,Nathan Franssen,Scott Raymond,Safwan Wshah*

Main category: cs.CV

TL;DR: 本研究利用自监督框架提高缺血性中风血栓切除术的自动化效率，实验表明模型效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 旨在提高缺血性中风血栓切除术的效率和安全性，减轻该过程的资源和人员需求。

Method: 通过自监督学习框架，使用基于回归的预训练任务对不同骨骼标记进行分类。

Result: 实验结果表明，该模型在回归和分类任务中表现优异，特别是在位置预训练任务上显著提升下游分类性能。

Conclusion: 该研究提出了一种自监督框架，能够在回归和分类任务中超越现有方法，并为将来的全自动C臂控制奠定基础。

Abstract: Thrombectomy is one of the most effective treatments for ischemic stroke, but
it is resource and personnel-intensive. We propose employing deep learning to
automate critical aspects of thrombectomy, thereby enhancing efficiency and
safety. In this work, we introduce a self-supervised framework that classifies
various skeletal landmarks using a regression-based pretext task. Our
experiments demonstrate that our model outperforms existing methods in both
regression and classification tasks. Notably, our results indicate that the
positional pretext task significantly enhances downstream classification
performance. Future work will focus on extending this framework toward fully
autonomous C-arm control, aiming to optimize trajectories from the pelvis to
the head during stroke thrombectomy procedures. All code used is available at
https://github.com/AhmadArrabi/C_arm_guidance

</details>


### [11] [DuetMatch: Harmonizing Semi-Supervised Brain MRI Segmentation via Decoupled Branch Optimization](https://arxiv.org/abs/2510.16146)
*Thanh-Huy Nguyen,Hoang-Thien Nguyen,Vi Vu,Ba-Thinh Lam,Phat Huynh,Tianyang Wang,Xingjian Li,Ulas Bagci,Min Xu*

Main category: cs.CV

TL;DR: DuetMatch是一个新的双分支半监督框架，通过非同步优化和特定设计实现了在脑部MRI分割中的优越表现。


<details>
  <summary>Details</summary>
Motivation: 解决医疗图像分割中的数据标注匮乏问题，并提高模型在噪声条件下的鲁棒性。

Method: 提出了一个双分支半监督框架，采用非同步优化，并在每个分支中分别优化编码器或解码器。

Result: 在ISLES2022和BraTS等基准脑部MRI分割数据集上进行了广泛实验，结果表明方法在效果和鲁棒性上均优于其他最先进的方法。

Conclusion: DuetMatch在多种半监督分割场景中优于现有方法，显示了其有效性和鲁棒性。

Abstract: The limited availability of annotated data in medical imaging makes
semi-supervised learning increasingly appealing for its ability to learn from
imperfect supervision. Recently, teacher-student frameworks have gained
popularity for their training benefits and robust performance. However, jointly
optimizing the entire network can hinder convergence and stability, especially
in challenging scenarios. To address this for medical image segmentation, we
propose DuetMatch, a novel dual-branch semi-supervised framework with
asynchronous optimization, where each branch optimizes either the encoder or
decoder while keeping the other frozen. To improve consistency under noisy
conditions, we introduce Decoupled Dropout Perturbation, enforcing
regularization across branches. We also design Pair-wise CutMix Cross-Guidance
to enhance model diversity by exchanging pseudo-labels through augmented input
pairs. To mitigate confirmation bias from noisy pseudo-labels, we propose
Consistency Matching, refining labels using stable predictions from frozen
teacher models. Extensive experiments on benchmark brain MRI segmentation
datasets, including ISLES2022 and BraTS, show that DuetMatch consistently
outperforms state-of-the-art methods, demonstrating its effectiveness and
robustness across diverse semi-supervised segmentation scenarios.

</details>


### [12] [Automated C-Arm Positioning via Conformal Landmark Localization](https://arxiv.org/abs/2510.16160)
*Ahmad Arrabi,Jay Hwasung Jung,Jax Luo,Nathan Franssen,Scott Raymond,Safwan Wshah*

Main category: cs.CV

TL;DR: 提出了一种自主导航C臂的方法，可提高定位准确性，减少人为因素对辐射的影响。


<details>
  <summary>Details</summary>
Motivation: 改善手动对齐流程，以减少辐射暴露和手术延迟。

Method: 使用从DeepDRR生成的合成X线数据集验证了一种将概率损失与骨骼姿态正则化相结合的训练框架。

Result: 在多个架构上表现出强大的定位准确性及良好校准的预测范围。

Conclusion: 该方法展示了在安全可靠的自主C臂系统中作为一个组件的潜力。

Abstract: Accurate and reliable C-arm positioning is essential for fluoroscopy-guided
interventions. However, clinical workflows rely on manual alignment that
increases radiation exposure and procedural delays. In this work, we present a
pipeline that autonomously navigates the C-arm to predefined anatomical
landmarks utilizing X-ray images. Given an input X-ray image from an arbitrary
starting location on the operating table, the model predicts a 3D displacement
vector toward each target landmark along the body. To ensure reliable
deployment, we capture both aleatoric and epistemic uncertainties in the
model's predictions and further calibrate them using conformal prediction. The
derived prediction regions are interpreted as 3D confidence regions around the
predicted landmark locations. The training framework combines a probabilistic
loss with skeletal pose regularization to encourage anatomically plausible
outputs. We validate our approach on a synthetic X-ray dataset generated from
DeepDRR. Results show not only strong localization accuracy across multiple
architectures but also well-calibrated prediction bounds. These findings
highlight the pipeline's potential as a component in safe and reliable
autonomous C-arm systems. Code is available at
https://github.com/AhmadArrabi/C_arm_guidance_APAH

</details>


### [13] [Cost Savings from Automatic Quality Assessment of Generated Images](https://arxiv.org/abs/2510.16179)
*Xavier Giro-i-Nieto,Nefeli Andreou,Anqi Liang,Manel Baradad,Francesc Moreno-Noguer,Aleix Martinez*

Main category: cs.CV

TL;DR: 本文通过提出一种公式和AutoML解决方案，展示了自动预筛选阶段在图像质量评估中节省成本的有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管深度生成模型在高质量图像生成方面取得了进展，但传统摄影方法的质量标准尚未达到，导致图像质量评估过程中存在高成本和低效率的问题。

Method: 提出了一种公式，用于估算通用图像质量评估引擎的成本节省，应用于背景修补的用例中。

Result: 在背景修补的用例中，使用简单的AutoML解决方案实现了51.61%的显著成本节省。

Conclusion: 通过引入自动预筛选阶段，显著降低了图像质量评估过程中的成本。

Abstract: Deep generative models have shown impressive progress in recent years, making
it possible to produce high quality images with a simple text prompt or a
reference image. However, state of the art technology does not yet meet the
quality standards offered by traditional photographic methods. For this reason,
production pipelines that use generated images often include a manual stage of
image quality assessment (IQA). This process is slow and expensive, especially
because of the low yield of automatically generated images that pass the
quality bar. The IQA workload can be reduced by introducing an automatic
pre-filtering stage, that will increase the overall quality of the images sent
to review and, therefore, reduce the average cost required to obtain a high
quality image. We present a formula that estimates the cost savings depending
on the precision and pass yield of a generic IQA engine. This formula is
applied in a use case of background inpainting, showcasing a significant cost
saving of 51.61% obtained with a simple AutoML solution.

</details>


### [14] [Data-Centric AI for Tropical Agricultural Mapping: Challenges, Strategies and Scalable Solutions](https://arxiv.org/abs/2510.16207)
*Mateus Pinto da Silva,Sabrina P. L. P. Correa,Hugo N. Oliveira,Ian M. Nunes,Jefersson A. dos Santos*

Main category: cs.CV

TL;DR: 本文探讨了通过数据中心人工智能方法解决热带农业遥感面临的数据挑战，并提供了实际的技术应用建议。


<details>
  <summary>Details</summary>
Motivation: 应对热带地区农业映射中所面临的数据质量、标注成本和区域概括等挑战。

Method: 通过审查和优先考虑技术（如自信学习、核心集选择、数据增强和主动学习）来优化数据质量和管理。

Result: 确定了25种不同技术的适用性，并推荐了9种成熟且简单的方法用于热带农业映射项目。

Conclusion: 提出了一种以数据为中心的人工智能框架，并提供了针对热带农业映射的大规模项目的实用管道建议。

Abstract: Mapping agriculture in tropical areas through remote sensing presents unique
challenges, including the lack of high-quality annotated data, the elevated
costs of labeling, data variability, and regional generalisation. This paper
advocates a Data-Centric Artificial Intelligence (DCAI) perspective and
pipeline, emphasizing data quality and curation as key drivers for model
robustness and scalability. It reviews and prioritizes techniques such as
confident learning, core-set selection, data augmentation, and active learning.
The paper highlights the readiness and suitability of 25 distinct strategies in
large-scale agricultural mapping pipelines. The tropical context is of high
interest, since high cloudiness, diverse crop calendars, and limited datasets
limit traditional model-centric approaches. This tutorial outlines practical
solutions as a data-centric approach for curating and training AI models better
suited to the dynamic realities of tropical agriculture. Finally, we propose a
practical pipeline using the 9 most mature and straightforward methods that can
be applied to a large-scale tropical agricultural mapping project.

</details>


### [15] [Embody 3D: A Large-scale Multimodal Motion and Behavior Dataset](https://arxiv.org/abs/2510.16258)
*Claire McLean,Makenzie Meendering,Tristan Swartz,Orri Gabbay,Alexandra Olsen,Rachel Jacobs,Nicholas Rosen,Philippe de Bree,Tony Garcia,Gadsden Merrill,Jake Sandakly,Julia Buffalini,Neham Jain,Steven Krenn,Moneish Kumar,Dejan Markovic,Evonne Ng,Fabian Prada,Andrew Saba,Siwei Zhang,Vasu Agrawal,Tim Godisart,Alexander Richard,Michael Zollhoefer*

Main category: cs.CV

TL;DR: Embody 3D 是一个包含439名参与者的500小时三维运动数据集，涵盖单人和多人行为，支持多模态分析。


<details>
  <summary>Details</summary>
Motivation: 创建一个包含丰富动作和行为的三维运动数据集，以促进对人类社会交往和情感表达的研究。

Method: 通过多摄像头收集阶段收集来自439名参与者的三维运动数据，涵盖单人和多人行为，确保多样性和丰富性。

Result: 生成了500小时的三维运动数据，包括手部跟踪、身体形状、文本注释和独立音频轨道，为研究提供了全面的数据支持。

Conclusion: Embody 3D 数据集为多模态分析提供了丰富的三维运动数据，促进了对人类动作和行为的深入研究。

Abstract: The Codec Avatars Lab at Meta introduces Embody 3D, a multimodal dataset of
500 individual hours of 3D motion data from 439 participants collected in a
multi-camera collection stage, amounting to over 54 million frames of tracked
3D motion. The dataset features a wide range of single-person motion data,
including prompted motions, hand gestures, and locomotion; as well as
multi-person behavioral and conversational data like discussions, conversations
in different emotional states, collaborative activities, and co-living
scenarios in an apartment-like space. We provide tracked human motion including
hand tracking and body shape, text annotations, and a separate audio track for
each participant.

</details>


### [16] [Proactive Scene Decomposition and Reconstruction](https://arxiv.org/abs/2510.16272)
*Baicheng Li,Zike Yan,Dong Wu,Hongbin Zha*

Main category: cs.CV

TL;DR: 本论文提出了一种基于人类与物体交互的主动场景重建方法，能够动态分解和重建场景，有效克服静态重建中的模糊性，取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在通过捕捉人类行为带来的动态信息，改善传统物体层次的场景重建方法，提高环境建模的灵活性和准确性。

Method: 文章采用在线方法，结合人类与物体的交互，通过迭代的分解与重建过程来实现动态场景建模，并使用高斯散点技术提升渲染效果。

Result: 提出的方法在多个真实场景下显示出较传统方法的优势，并达到了准确且一致的动态场景建模。

Conclusion: 该论文提出了一种新颖的主动场景分解与重建方法，通过利用人类与物体之间的交互，动态地改进场景建模，从而克服静态物体重建中的不确定性。

Abstract: Human behaviors are the major causes of scene dynamics and inherently contain
rich cues regarding the dynamics. This paper formalizes a new task of proactive
scene decomposition and reconstruction, an online approach that leverages
human-object interactions to iteratively disassemble and reconstruct the
environment. By observing these intentional interactions, we can dynamically
refine the decomposition and reconstruction process, addressing inherent
ambiguities in static object-level reconstruction. The proposed system
effectively integrates multiple tasks in dynamic environments such as accurate
camera and object pose estimation, instance decomposition, and online map
updating, capitalizing on cues from human-object interactions in egocentric
live streams for a flexible, progressive alternative to conventional
object-level reconstruction methods. Aided by the Gaussian splatting technique,
accurate and consistent dynamic scene modeling is achieved with photorealistic
and efficient rendering. The efficacy is validated in multiple real-world
scenarios with promising advantages.

</details>


### [17] [Cerberus: Real-Time Video Anomaly Detection via Cascaded Vision-Language Models](https://arxiv.org/abs/2510.16290)
*Yue Zheng,Xiufang Shi,Jiming Chen,Yuanchao Shu*

Main category: cs.CV

TL;DR: Cerberus系统提升了视频异常检测的效率与准确性，适合实时视频分析。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有视觉语言模型在实时部署中的计算成本和视觉定位性能不稳定的问题。

Method: 采用两阶段级联系统，离线学习正常行为规则并结合轻量过滤和细粒度VLM推理。

Result: 在四个数据集上的广泛评估表明，Cerberus在NVIDIA L40S GPU上平均达到57.68 fps，速度提升达151.79倍，准确率为97.2%，与当前最先进的VLM基础的VAD方法相当。

Conclusion: Cerberus是一种高效且准确的实时视频异常检测系统，具有很好的实用性。

Abstract: Video anomaly detection (VAD) has rapidly advanced by recent development of
Vision-Language Models (VLMs). While these models offer superior zero-shot
detection capabilities, their immense computational cost and unstable visual
grounding performance hinder real-time deployment. To overcome these
challenges, we introduce Cerberus, a two-stage cascaded system designed for
efficient yet accurate real-time VAD. Cerberus learns normal behavioral rules
offline, and combines lightweight filtering with fine-grained VLM reasoning
during online inference. The performance gains of Cerberus come from two key
innovations: motion mask prompting and rule-based deviation detection. The
former directs the VLM's attention to regions relevant to motion, while the
latter identifies anomalies as deviations from learned norms rather than
enumerating possible anomalies. Extensive evaluations on four datasets show
that Cerberus on average achieves 57.68 fps on an NVIDIA L40S GPU, a
151.79$\times$ speedup, and 97.2\% accuracy comparable to the state-of-the-art
VLM-based VAD methods, establishing it as a practical solution for real-time
video analytics.

</details>


### [18] [OpenLVLM-MIA: A Controlled Benchmark Revealing the Limits of Membership Inference Attacks on Large Vision-Language Models](https://arxiv.org/abs/2510.16295)
*Ryoto Miyamoto,Xin Fan,Fuyuko Kido,Tsuneo Matsumoto,Hayato Yamana*

Main category: cs.CV

TL;DR: OpenLVLM-MIA是一个新的基准，旨在评估大型视觉-语言模型中的成员推断攻击，解决以前研究中的分布偏差问题，并为未来的隐私保护技术奠定基础。


<details>
  <summary>Details</summary>
Motivation: 在之前的研究中，尽管报告了较高的攻击成功率，但这些结果往往是由于数据集构建过程中引入的分布偏差，而并非真正识别成员身份。

Method: 引入一个包含6000张图像的受控基准，确保成员和非成员样本的分布经过仔细平衡，并提供三个不同训练阶段的真实成员标签。

Result: 实验结果表明，在无偏见条件下，最先进的MIA方法的性能趋近于随机机会。

Conclusion: OpenLVLM-MIA提供了一个透明、无偏的基准，为大视觉-语言模型（LVLMs）中的成员推断攻击（MIA）研究指明了局限性，并为开发更强的隐私保护技术奠定了基础。

Abstract: OpenLVLM-MIA is a new benchmark that highlights fundamental challenges in
evaluating membership inference attacks (MIA) against large vision-language
models (LVLMs). While prior work has reported high attack success rates, our
analysis suggests that these results often arise from detecting distributional
bias introduced during dataset construction rather than from identifying true
membership status. To address this issue, we introduce a controlled benchmark
of 6{,}000 images where the distributions of member and non-member samples are
carefully balanced, and ground-truth membership labels are provided across
three distinct training stages. Experiments using OpenLVLM-MIA demonstrated
that the performance of state-of-the-art MIA methods converged to random chance
under unbiased conditions. By offering a transparent and unbiased benchmark,
OpenLVLM-MIA clarifies the current limitations of MIA research on LVLMs and
provides a solid foundation for developing stronger privacy-preserving
techniques.

</details>


### [19] [Stroke2Sketch: Harnessing Stroke Attributes for Training-Free Sketch Generation](https://arxiv.org/abs/2510.16319)
*Rui Yang,Huining Li,Yiyi Long,Xiaojun Wu,Shengfeng He*

Main category: cs.CV

TL;DR: Stroke2Sketch是一种新的无训练框架，通过跨图像笔触注意力机制提升素描生成的质量和风格一致性。


<details>
  <summary>Details</summary>
Motivation: 生成受到参考风格指导的素描，需要精准转移笔触属性，同时保留语义结构和内容的保真度。

Method: 提出一种无训练的框架，利用跨图像笔触注意力机制来精确转移笔触属性，并保持结构完整性。

Result: Stroke2Sketch能够自适应整合参考笔触特征，成功合成接近手工制作效果的素描。

Conclusion: Stroke2Sketch能有效合成具有风格保真度的素描，优于现有方法，具备更好的笔触控制和语义一致性。

Abstract: Generating sketches guided by reference styles requires precise transfer of
stroke attributes, such as line thickness, deformation, and texture sparsity,
while preserving semantic structure and content fidelity. To this end, we
propose Stroke2Sketch, a novel training-free framework that introduces
cross-image stroke attention, a mechanism embedded within self-attention layers
to establish fine-grained semantic correspondences and enable accurate stroke
attribute transfer. This allows our method to adaptively integrate reference
stroke characteristics into content images while maintaining structural
integrity. Additionally, we develop adaptive contrast enhancement and
semantic-focused attention to reinforce content preservation and foreground
emphasis. Stroke2Sketch effectively synthesizes stylistically faithful sketches
that closely resemble handcrafted results, outperforming existing methods in
expressive stroke control and semantic coherence. Codes are available at
https://github.com/rane7/Stroke2Sketch.

</details>


### [20] [Scaling Laws for Deepfake Detection](https://arxiv.org/abs/2510.16320)
*Wenhao Wang,Longqi Cai,Taihong Xiao,Yuxiao Wang,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 本文研究了深度伪造检测任务中的规模法则，通过构建规模最大的数据集ScaleDF，发现检测误差与真实域数量和伪造方法数量之间的幂律关系，并探讨了预训练和数据增强的影响。


<details>
  <summary>Details</summary>
Motivation: 目前尚无满足规模要求的现有数据集，因此需要构建一个新的数据集以验证深度伪造检测中的规模法则。

Method: 通过构建包含超过580万张真实图像和超过880万张伪造图像的ScaleDF数据集，系统分析模型性能与真实域数量、深度伪造生成方法及训练图像数量之间的关系。

Result: 在ScaleDF数据集上，观察到平均检测误差随着真实域或深度伪造方法数量的增加遵循可预测的幂律衰减规律。同时研究了预训练和数据增强在深度伪造检测中的作用和局限性。

Conclusion: 本研究提供了关于深度伪造检测任务中的规模法则的系统性分析，揭示了检测误差与真实图像域数量和深度伪造生成方法之间的关系，并构建了规模最大的深度伪造数据集来支持这一研究。

Abstract: This paper presents a systematic study of scaling laws for the deepfake
detection task. Specifically, we analyze the model performance against the
number of real image domains, deepfake generation methods, and training images.
Since no existing dataset meets the scale requirements for this research, we
construct ScaleDF, the largest dataset to date in this field, which contains
over 5.8 million real images from 51 different datasets (domains) and more than
8.8 million fake images generated by 102 deepfake methods. Using ScaleDF, we
observe power-law scaling similar to that shown in large language models
(LLMs). Specifically, the average detection error follows a predictable
power-law decay as either the number of real domains or the number of deepfake
methods increases. This key observation not only allows us to forecast the
number of additional real domains or deepfake methods required to reach a
target performance, but also inspires us to counter the evolving deepfake
technology in a data-centric manner. Beyond this, we examine the role of
pre-training and data augmentations in deepfake detection under scaling, as
well as the limitations of scaling itself.

</details>


### [21] [Scale-DiT: Ultra-High-Resolution Image Generation with Hierarchical Local Attention](https://arxiv.org/abs/2510.16325)
*Yuyao Zhang,Yu-Wing Tai*

Main category: cs.CV

TL;DR: Scale-DiT是一个新的扩散框架，通过局部注意力和低分辨率引导，实现超高分辨率图像生成，性能优越且高效。


<details>
  <summary>Details</summary>
Motivation: 超高分辨率图像生成需要细粒度的纹理合成和全局一致的结构，但当前的扩散模型在高分辨率时受到限制。

Method: 提出了Scale-DiT，一个新的扩散框架，通过引入分层局部注意力和低分辨率全局引导来实现高效且语义一致的图像合成。

Result: Scale-DiT在推理效率上实现了2倍以上的速度提升，内存使用量更低，并且可以可靠地扩展到4K分辨率，而无需额外的高分辨率训练数据。

Conclusion: 研究结果强调了使用分层局部注意力和低分辨率引导锚点作为推动超高分辨率图像生成的一种有效方法。

Abstract: Ultra-high-resolution text-to-image generation demands both fine-grained
texture synthesis and globally coherent structure, yet current diffusion models
remain constrained to sub-$1K \times 1K$ resolutions due to the prohibitive
quadratic complexity of attention and the scarcity of native $4K$ training
data. We present \textbf{Scale-DiT}, a new diffusion framework that introduces
hierarchical local attention with low-resolution global guidance, enabling
efficient, scalable, and semantically coherent image synthesis at ultra-high
resolutions. Specifically, high-resolution latents are divided into fixed-size
local windows to reduce attention complexity from quadratic to near-linear,
while a low-resolution latent equipped with scaled positional anchors injects
global semantics. A lightweight LoRA adaptation bridges global and local
pathways during denoising, ensuring consistency across structure and detail. To
maximize inference efficiency, we repermute token sequence in Hilbert curve
order and implement a fused-kernel for skipping masked operations, resulting in
a GPU-friendly design. Extensive experiments demonstrate that Scale-DiT
achieves more than $2\times$ faster inference and lower memory usage compared
to dense attention baselines, while reliably scaling to $4K \times 4K$
resolution without requiring additional high-resolution training data. On both
quantitative benchmarks (FID, IS, CLIP Score) and qualitative comparisons,
Scale-DiT delivers superior global coherence and sharper local detail, matching
or outperforming state-of-the-art methods that rely on native 4K training.
Taken together, these results highlight hierarchical local attention with
guided low-resolution anchors as a promising and effective approach for
advancing ultra-high-resolution image generation.

</details>


### [22] [DiffusionX: Efficient Edge-Cloud Collaborative Image Generation with Multi-Round Prompt Evolution](https://arxiv.org/abs/2510.16326)
*Yi Wei,Shunpu Tang,Liang Zhao,Qiangian Yang*

Main category: cs.CV

TL;DR: DiffusionX通过云边协作与噪声预测技术，提高了扩散模型的生成效率，降低了用户等待时间，同时保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 为了解决扩散模型计算密集和用户需要多轮优化提示带来的延迟问题，提出了更高效的生成方案。

Method: 提出了一种云边协作框架，结合轻量级设备端扩散模型和高容量云端模型，并引入噪声水平预测器以动态平衡计算负载。

Result: DiffusionX相比于Stable Diffusion v1.5平均生成时间减少15.8%，且图像质量相当；与Tiny-SD相比仅稍慢0.9%，图像质量显著提升。

Conclusion: DiffusionX在保证图像质量的同时有效降低了生成时间，展现出极佳的效率与可扩展性。

Abstract: Recent advances in diffusion models have driven remarkable progress in image
generation. However, the generation process remains computationally intensive,
and users often need to iteratively refine prompts to achieve the desired
results, further increasing latency and placing a heavy burden on cloud
resources. To address this challenge, we propose DiffusionX, a cloud-edge
collaborative framework for efficient multi-round, prompt-based generation. In
this system, a lightweight on-device diffusion model interacts with users by
rapidly producing preview images, while a high-capacity cloud model performs
final refinements after the prompt is finalized. We further introduce a noise
level predictor that dynamically balances the computation load, optimizing the
trade-off between latency and cloud workload. Experiments show that DiffusionX
reduces average generation time by 15.8% compared with Stable Diffusion v1.5,
while maintaining comparable image quality. Moreover, it is only 0.9% slower
than Tiny-SD with significantly improved image quality, thereby demonstrating
efficiency and scalability with minimal overhead.

</details>


### [23] [TokenAR: Multiple Subject Generation via Autoregressive Token-level enhancement](https://arxiv.org/abs/2510.16332)
*Haiyue Sun,Qingdong He,Jinlong Peng,Peng Tang,Jiangning Zhang,Junwei Zhu,Xiaobin Hu,Shuicheng Yan*

Main category: cs.CV

TL;DR: 本研究提出TokenAR框架，解决自回归模型在多参考图像生成中的身份解耦问题，并引入InstructAR数据集，以实现高质量、高多样性的多主体生成。


<details>
  <summary>Details</summary>
Motivation: 针对自回归模型在多参考生成中面临的不同参考身份解耦困难，提出了一种有效的令牌级增强机制。

Method: 通过引入三种令牌级增强机制：令牌索引嵌入、指令令牌注入及身份令牌解缠策略，来解决参考身份混淆问题。

Result: 引入InstructAR数据集，该数据集为首次大规模的多参考输入图像生成数据集，包含28000对训练样本，实验验证了我们的模型在多参考图像生成任务上优于当前最先进的模型。

Conclusion: 本研究提出的TokenAR框架显著改善了基于自回归模型的条件图像生成，能够在多参考生成中实现身份一致性和高质量背景重建。

Abstract: Autoregressive Model (AR) has shown remarkable success in conditional image
generation. However, these approaches for multiple reference generation
struggle with decoupling different reference identities. In this work, we
propose the TokenAR framework, specifically focused on a simple but effective
token-level enhancement mechanism to address reference identity confusion
problem. Such token-level enhancement consists of three parts, 1). Token Index
Embedding clusters the tokens index for better representing the same reference
images; 2). Instruct Token Injection plays as a role of extra visual feature
container to inject detailed and complementary priors for reference tokens; 3).
The identity-token disentanglement strategy (ITD) explicitly guides the token
representations toward independently representing the features of each
identity.This token-enhancement framework significantly augments the
capabilities of existing AR based methods in conditional image generation,
enabling good identity consistency while preserving high quality background
reconstruction. Driven by the goal of high-quality and high-diversity in
multi-subject generation, we introduce the InstructAR Dataset, the first
open-source, large-scale, multi-reference input, open domain image generation
dataset that includes 28K training pairs, each example has two reference
subjects, a relative prompt and a background with mask annotation, curated for
multiple reference image generation training and evaluating. Comprehensive
experiments validate that our approach surpasses current state-of-the-art
models in multiple reference image generation task. The implementation code and
datasets will be made publicly. Codes are available, see
https://github.com/lyrig/TokenAR

</details>


### [24] [RL makes MLLMs see better than SFT](https://arxiv.org/abs/2510.16333)
*Junha Song,Sangdoo Yun,Dongyoon Han,Jaegul Choo,Byeongho Heo*

Main category: cs.CV

TL;DR: 研究探讨了SFT与RL对MLLM视觉编码器的影响，发现RL训练获得更强视觉表示，提出了PIVOT策略，显著提高了训练效率和效果。


<details>
  <summary>Details</summary>
Motivation: 目前的MLLM研究对视觉编码器的理解不足，急需探讨训练策略（如SFT与RL）如何塑造视觉编码器及其对下游任务的影响。

Method: 通过对视觉编码器的实验分析，比较SFT与RL在MLLM训练中的影响。

Result: 实验结果表明，RL相比于SFT在视觉相关的VQA基准上具有明显优势，并且显著改善了MLLM的视觉表示。

Conclusion: PIVOT训练的视觉编码器在计算成本低于1%的情况下，表现超过了更大且经过重训练的模型，为提升MLLM视觉骨干提供了一条有效路径。

Abstract: A dominant assumption in Multimodal Language Model (MLLM) research is that
its performance is largely inherited from the LLM backbone, given its immense
parameter scale and remarkable capabilities. This has created a void in the
understanding of the vision encoder, which determines how MLLMs perceive
images. The recent shift in MLLM training paradigms, from Supervised Finetuning
(SFT) to Reinforcement Learning (RL), magnifies this oversight-namely, the
significant lack of analysis on how such training reshapes the vision encoder
as well as the MLLM. To address this, we first investigate the impact of
training strategies on MLLMs, where RL shows a clear advantage over SFT in
strongly vision-related VQA benchmarks. Motivated by this, we conduct a
critical yet under-explored analysis of the vision encoder of MLLMs through
diverse and in-depth experiments, ranging from ImageNet classification and
segmentation to gradient visualization. Our results demonstrate that MLLM's
post-training strategy (i.e., SFT or RL) not only leads to distinct outcomes on
MLLM downstream tasks, but also fundamentally reshapes MLLM's underlying visual
representations. Specifically, the key finding of our study is that RL produces
stronger and precisely localized visual representations compared to SFT,
boosting the ability of the vision encoder for MLLM. We then reframe our
findings into a simple recipe for building strong vision encoders for MLLMs,
Preference-Instructed Vision OpTimization (PIVOT). When integrated into MLLMs,
a PIVOT-trained vision encoder outperforms even larger and more heavily-trained
counterparts, despite requiring less than 1% of the computational cost of
standard vision pretraining. This result opens an effective and efficient path
for advancing the vision backbones of MLLMs. Project page available at
https://june-page.github.io/pivot/

</details>


### [25] [On the Provable Importance of Gradients for Language-Assisted Image Clustering](https://arxiv.org/abs/2510.16335)
*Bo Peng,Jie Lu,Guangquan Zhang,Zhen Fang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的GradNorm框架，通过梯度测量名词的相关性，提升了语言辅助图像聚类的效果，表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决语言辅助图像聚类中的正面名词筛选问题，以提高视觉表示的可分 discriminability。

Method: 提出了一种新的基于梯度的框架GradNorm，通过交叉熵的梯度来衡量名词的正面性，理论上保证了其有效性。

Result: GradNorm在各种基准测试中实现了最先进的聚类性能，并为名词的可分性提供了严格的误差边界。

Conclusion: GradNorm is a novel gradient-based framework that improves image clustering by filtering relevant nouns from unlabeled data, achieving state-of-the-art performance.

Abstract: This paper investigates the recently emerged problem of Language-assisted
Image Clustering (LaIC), where textual semantics are leveraged to improve the
discriminability of visual representations to facilitate image clustering. Due
to the unavailability of true class names, one of core challenges of LaIC lies
in how to filter positive nouns, i.e., those semantically close to the images
of interest, from unlabeled wild corpus data. Existing filtering strategies are
predominantly based on the off-the-shelf feature space learned by CLIP;
however, despite being intuitive, these strategies lack a rigorous theoretical
foundation. To fill this gap, we propose a novel gradient-based framework,
termed as GradNorm, which is theoretically guaranteed and shows strong
empirical performance. In particular, we measure the positiveness of each noun
based on the magnitude of gradients back-propagated from the cross-entropy
between the predicted target distribution and the softmax output.
Theoretically, we provide a rigorous error bound to quantify the separability
of positive nouns by GradNorm and prove that GradNorm naturally subsumes
existing filtering strategies as extremely special cases of itself.
Empirically, extensive experiments show that GradNorm achieves the
state-of-the-art clustering performance on various benchmarks.

</details>


### [26] [MIRAD - A comprehensive real-world robust anomaly detection dataset for Mass Individualization](https://arxiv.org/abs/2510.16370)
*Pulin Li,Guocheng Wu,Li Yin,Yuxin Zheng,Wei Zhang,Yanjie Zhou*

Main category: cs.CV

TL;DR: MIRAD是首个针对社会制造中异常检测的基准数据集，展示了个性化生产面临的质量控制挑战，为研究者提供了一个现实基础。


<details>
  <summary>Details</summary>
Motivation: 社会制造的兴起带来了个性化生产的机遇，但也为质量控制和缺陷检测带来了挑战，尤其是在数据和算法的缺乏背景下。

Method: 通过引入MIRAD数据集，评估先进的异常检测方法，包括单类、多类和零样本方法，以深入分析社会制造中的缺陷检测。

Result: 在对MIRAD数据集的评估中，所有先进模型的性能都明显低于传统基准，揭示了个性化生产中缺陷检测的复杂性。

Conclusion: MIRAD数据集为社会制造中的缺陷检测研究提供了首次专门设计的基准，展示了个性化生产的复杂性，并为未来的质量控制解决方案奠定了基础。

Abstract: Social manufacturing leverages community collaboration and scattered
resources to realize mass individualization in modern industry. However, this
paradigm shift also introduces substantial challenges in quality control,
particularly in defect detection. The main difficulties stem from three
aspects. First, products often have highly customized configurations. Second,
production typically involves fragmented, small-batch orders. Third, imaging
environments vary considerably across distributed sites. To overcome the
scarcity of real-world datasets and tailored algorithms, we introduce the Mass
Individualization Robust Anomaly Detection (MIRAD) dataset. As the first
benchmark explicitly designed for anomaly detection in social manufacturing,
MIRAD captures three critical dimensions of this domain: (1) diverse
individualized products with large intra-class variation, (2) data collected
from six geographically dispersed manufacturing nodes, and (3) substantial
imaging heterogeneity, including variations in lighting, background, and motion
conditions. We then conduct extensive evaluations of state-of-the-art (SOTA)
anomaly detection methods on MIRAD, covering one-class, multi-class, and
zero-shot approaches. Results show a significant performance drop across all
models compared with conventional benchmarks, highlighting the unresolved
complexities of defect detection in real-world individualized production. By
bridging industrial requirements and academic research, MIRAD provides a
realistic foundation for developing robust quality control solutions essential
for Industry 5.0. The dataset is publicly available at
https://github.com/wu33learn/MIRAD.

</details>


### [27] [Cataract-LMM: Large-Scale, Multi-Source, Multi-Task Benchmark for Deep Learning in Surgical Video Analysis](https://arxiv.org/abs/2510.16371)
*Mohammad Javad Ahmadi,Iman Gandomi,Parisa Abdi,Seyed-Farzad Mohammadi,Amirhossein Taslimi,Mehdi Khodaparast,Hassan Hashemi,Mahdi Tavakoli,Hamid D. Taghirad*

Main category: cs.CV

TL;DR: 本文介绍了一个包括3000个白内障手术视频的数据集，为手术AI任务训练提供了多样化注释，旨在弥补现有资源的不足。


<details>
  <summary>Details</summary>
Motivation: 当前的白内障手术资源在多样性和注释深度方面存在不足，限制了深度学习模型的通用性。

Method: 收集了来自两个手术中心的3000个白内障手术视频，并设置了四个注释层次，以满足不同的研究需求。

Result: 通过基准实验支持数据集的技术质量，并为阶段识别任务建立了领域适应性基线。

Conclusion: 该数据集为计算机辅助眼科手术系统的研究提供了丰富的资源，并为深度学习模型的训练提供了可靠依据。

Abstract: The development of computer-assisted surgery systems depends on large-scale,
annotated datasets. Current resources for cataract surgery often lack the
diversity and annotation depth needed to train generalizable deep-learning
models. To address this gap, we present a dataset of 3,000 phacoemulsification
cataract surgery videos from two surgical centers, performed by surgeons with a
range of experience levels. This resource is enriched with four annotation
layers: temporal surgical phases, instance segmentation of instruments and
anatomical structures, instrument-tissue interaction tracking, and quantitative
skill scores based on the established competency rubrics like the ICO-OSCAR.
The technical quality of the dataset is supported by a series of benchmarking
experiments for key surgical AI tasks, including workflow recognition, scene
segmentation, and automated skill assessment. Furthermore, we establish a
domain adaptation baseline for the phase recognition task by training a model
on a subset of surgical centers and evaluating its performance on a held-out
center. The dataset and annotations are available in Google Form
(https://docs.google.com/forms/d/e/1FAIpQLSfmyMAPSTGrIy2sTnz0-TMw08ZagTimRulbAQcWdaPwDy187A/viewform?usp=dialog).

</details>


### [28] [Demeter: A Parametric Model of Crop Plant Morphology from the Real World](https://arxiv.org/abs/2510.16377)
*Tianhang Cheng,Albert J. Zhai,Evan Z. Chen,Rui Zhou,Yawen Deng,Zitong Li,Kejie Zhao,Janice Shiu,Qianyu Zhao,Yide Xu,Xinlei Wang,Yuan Shen,Sheng Wang,Lisa Ainsworth,Kaiyu Guan,Shenlong Wang*

Main category: cs.CV

TL;DR: Demeter是一种参数化模型，专注于植物形态，能够处理多种形状变化，适用于作物植物建模，并提供有效的形状合成与结构重建。


<details>
  <summary>Details</summary>
Motivation: 虽然在人类和动物建模中已有强大的模型，但缺乏同样表达力的植物建模方法。

Method: 提出了一种数据驱动的参数化模型，编码植物形态学的关键因素，包括拓扑、形状、关节和变形。

Result: Demeter能够处理不同物种间的形状拓扑变化，并建模三种形状变化来源：关节、子组件形状变化和非刚性变形。实验结果表明，Demeter在形状合成、结构重建和生物物理过程模拟方面表现优异。

Conclusion: Demeter模型有效地综合了植物形状，并重建结构与模拟生物物理过程，为作物植物建模提供了新方法。

Abstract: Learning 3D parametric shape models of objects has gained popularity in
vision and graphics and has showed broad utility in 3D reconstruction,
generation, understanding, and simulation. While powerful models exist for
humans and animals, equally expressive approaches for modeling plants are
lacking. In this work, we present Demeter, a data-driven parametric model that
encodes key factors of a plant morphology, including topology, shape,
articulation, and deformation into a compact learned representation. Unlike
previous parametric models, Demeter handles varying shape topology across
various species and models three sources of shape variation: articulation,
subcomponent shape variation, and non-rigid deformation. To advance crop plant
modeling, we collected a large-scale, ground-truthed dataset from a soybean
farm as a testbed. Experiments show that Demeter effectively synthesizes
shapes, reconstructs structures, and simulates biophysical processes. Code and
data is available at https://tianhang-cheng.github.io/Demeter/.

</details>


### [29] [SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation](https://arxiv.org/abs/2510.16396)
*Yeh Keng Hao,Hsu Tzu Wei,Sun Min*

Main category: cs.CV

TL;DR: 本研究设计了一种轻量框架，提升了边缘设备上深度学习模型的效率和准确性，最终在Raspberry Pi 5上实现了2.98倍的速度提升，且精度表现良好。


<details>
  <summary>Details</summary>
Motivation: 随着AR/VR设备的广泛应用，边缘设备上深度学习模型的部署变得至关重要，这些设备需要实时推理、低功耗和最小延迟，因此面临着效率与性能平衡的挑战。

Method: 设计了一种轻量框架，采用编码器-解码器架构，并使用稀疏卷积和量化感知训练。

Result: 利用ResNet-18主干实现了42%的端到端效率提升，SPLite解码器在Raspberry Pi 5上的解码帧率提升了3.1倍，内存使用减少，精度保持一致。

Conclusion: 整体系统在Raspberry Pi 5上实现了2.98倍的加速，同时在计算效率上显著提升，且在精度上与先进方法相当。

Abstract: With the increasing ubiquity of AR/VR devices, the deployment of deep
learning models on edge devices has become a critical challenge. These devices
require real-time inference, low power consumption, and minimal latency. Many
framework designers face the conundrum of balancing efficiency and performance.
We design a light framework that adopts an encoder-decoder architecture and
introduces several key contributions aimed at improving both efficiency and
accuracy. We apply sparse convolution on a ResNet-18 backbone to exploit the
inherent sparsity in hand pose images, achieving a 42% end-to-end efficiency
improvement. Moreover, we propose our SPLite decoder. This new architecture
significantly boosts the decoding process's frame rate by 3.1x on the Raspberry
Pi 5, while maintaining accuracy on par. To further optimize performance, we
apply quantization-aware training, reducing memory usage while preserving
accuracy (PA-MPJPE increases only marginally from 9.0 mm to 9.1 mm on
FreiHAND). Overall, our system achieves a 2.98x speed-up on a Raspberry Pi 5
CPU (BCM2712 quad-core Arm A76 processor). Our method is also evaluated on
compound benchmark datasets, demonstrating comparable accuracy to
state-of-the-art approaches while significantly enhancing computational
efficiency.

</details>


### [30] [REALM: An MLLM-Agent Framework for Open World 3D Reasoning Segmentation and Editing on Gaussian Splatting](https://arxiv.org/abs/2510.16410)
*Changyue Shi,Minghao Chen,Yiping Mao,Chuxiao Yang,Xinyuan Hu,Jiajun Ding,Zhou Yu*

Main category: cs.CV

TL;DR: REALM是一个创新的MLLM-agent框架，能够在开放世界中进行基于推理的3D对象分割，支持多种3D交互任务，并展示出卓越的性能。


<details>
  <summary>Details</summary>
Motivation: 解决复杂人类指令与精确3D对象定位之间的鸿沟，改善现有方法在模糊指令理解上的不足。

Method: 通过直接在3D高斯散点表示上进行分割，结合了一种新的全局到局部空间定位策略，以提高对目标对象的识别精度。

Result: 经过大量实验，REALM在LERF、3D-OVS和新提出的REALM3D基准测试中显示出显著的性能，成功解析明确和隐含指令。

Conclusion: REALM在理解人类指令、执行高精度的3D对象分割和支持多种3D交互任务方面表现卓越，展示了其实际应用价值。

Abstract: Bridging the gap between complex human instructions and precise 3D object
grounding remains a significant challenge in vision and robotics. Existing 3D
segmentation methods often struggle to interpret ambiguous, reasoning-based
instructions, while 2D vision-language models that excel at such reasoning lack
intrinsic 3D spatial understanding. In this paper, we introduce REALM, an
innovative MLLM-agent framework that enables open-world reasoning-based
segmentation without requiring extensive 3D-specific post-training. We perform
segmentation directly on 3D Gaussian Splatting representations, capitalizing on
their ability to render photorealistic novel views that are highly suitable for
MLLM comprehension. As directly feeding one or more rendered views to the MLLM
can lead to high sensitivity to viewpoint selection, we propose a novel
Global-to-Local Spatial Grounding strategy. Specifically, multiple global views
are first fed into the MLLM agent in parallel for coarse-level localization,
aggregating responses to robustly identify the target object. Then, several
close-up novel views of the object are synthesized to perform fine-grained
local segmentation, yielding accurate and consistent 3D masks. Extensive
experiments show that REALM achieves remarkable performance in interpreting
both explicit and implicit instructions across LERF, 3D-OVS, and our newly
introduced REALM3D benchmarks. Furthermore, our agent framework seamlessly
supports a range of 3D interaction tasks, including object removal,
replacement, and style transfer, demonstrating its practical utility and
versatility. Project page: https://ChangyueShi.github.io/REALM.

</details>


### [31] [SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning](https://arxiv.org/abs/2510.16416)
*Xiaojun Guo,Runyu Zhou,Yifei Wang,Qi Zhang,Chenheng Zhang,Stefanie Jegelka,Xiaohan Wang,Jiajun Chai,Guojun Yin,Wei Lin,Yisen Wang*

Main category: cs.CV

TL;DR: 本研究提出SSL4RL框架，利用自监督学习任务为强化学习提供奖励，改善了视觉语言模型的表现。


<details>
  <summary>Details</summary>
Motivation: VLM在视觉推理任务中往往依赖语言先验或文本捷径，因此需要有效利用视觉证据，并改善RL在VLM中的应用。

Method: 提出SSL4RL框架，通过自监督学习任务作为RL微调的可验证奖励来源，避免了对人工偏好数据或不可靠的AI评估者的依赖。

Result: SSL4RL在视觉中心和视觉语言推理基准测试中表现显著提升，并揭示了任务难度、模型规模和语义对齐等关键因素对其有效性的影响。

Conclusion: SSL4RL为多模态模型的对齐提供了一种通用且有效的范式，利用可验证的自监督目标显著提升了性能。

Abstract: Vision-language models (VLMs) have shown remarkable abilities by integrating
large language models with visual inputs. However, they often fail to utilize
visual evidence adequately, either depending on linguistic priors in
vision-centric tasks or resorting to textual shortcuts during reasoning.
Although reinforcement learning (RL) can align models with desired behaviors,
its application to VLMs has been hindered by the lack of scalable and reliable
reward mechanisms. To overcome this challenge, we propose SSL4RL, a novel
framework that leverages self-supervised learning (SSL) tasks as a source of
verifiable rewards for RL-based fine-tuning. Our approach reformulates SSL
objectives-such as predicting image rotation or reconstructing masked
patches-into dense, automatic reward signals, eliminating the need for human
preference data or unreliable AI evaluators. Experiments show that SSL4RL
substantially improves performance on both vision-centric and vision-language
reasoning benchmarks. Furthermore, through systematic ablations, we identify
key factors-such as task difficulty, model scale, and semantic alignment with
the target domain-that influence the effectiveness of SSL4RL tasks, offering
new design principles for future work. We also demonstrate the framework's
generality by applying it to graph learning, where it yields significant gains.
SSL4RL establishes a versatile and effective paradigm for aligning multimodal
models using verifiable, self-supervised objectives.

</details>


### [32] [Machine Vision-Based Surgical Lighting System:Design and Implementation](https://arxiv.org/abs/2510.17287)
*Amir Gharghabi,Mahdi Hakiminezhad,Maryam Shafaei,Shaghayegh Gharghabi*

Main category: cs.CV

TL;DR: 本论文提出了一种新型的自动化手术照明系统，通过机器视觉技术提升照明一致性，减轻外科医生负担。


<details>
  <summary>Details</summary>
Motivation: 传统手术照明系统依赖于手动调整，导致外科医生疲劳和照明不一致，因此需要一种新的解决方案来改善这一问题。

Method: 使用YOLOv11目标检测算法识别放置在手术部位上方的蓝色标记，结合伺服电机和高功率LED光源实现照明自动化。

Result: YOLO模型在包含标注图像的验证集中实现了96.7%的mAP@50，表明该系统在手术场景中的有效性。

Conclusion: 该研究提出了一种基于机器视觉的自动化手术照明系统，能够有效减少外科医生的体力负担，并提高手术照明的一致性，从而支持更好的手术结果。

Abstract: Effortless and ergonomically designed surgical lighting is critical for
precision and safety during procedures. However, traditional systems often rely
on manual adjustments, leading to surgeon fatigue, neck strain, and
inconsistent illumination due to drift and shadowing. To address these
challenges, we propose a novel surgical lighting system that leverages the
YOLOv11 object detection algorithm to identify a blue marker placed above the
target surgical site. A high-power LED light source is then directed to the
identified location using two servomotors equipped with tilt-pan brackets. The
YOLO model achieves 96.7% mAP@50 on the validation set consisting of annotated
images simulating surgical scenes with the blue spherical marker. By automating
the lighting process, this machine vision-based solution reduces physical
strain on surgeons, improves consistency in illumination, and supports improved
surgical outcomes.

</details>


### [33] [LightGlueStick: a Fast and Robust Glue for Joint Point-Line Matching](https://arxiv.org/abs/2510.16438)
*Aidyn Ubingazhibov,Rémi Pautrat,Iago Suárez,Shaohui Liu,Marc Pollefeys,Viktor Larsson*

Main category: cs.CV

TL;DR: LightGlueStick is a lightweight matcher for points and lines, featuring ALMP for improved efficiency and real-time applicability, achieving state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: The goal is to overcome the limitations of previous methods, particularly the computational heaviness of GlueStick, to enable real-time applications and deployment on edge devices.

Method: LightGlueStick utilizes a lightweight architecture with Attentional Line Message Passing (ALMP) to enhance communication between line segments and improve matching efficiency.

Result: Extensive experiments demonstrate that LightGlueStick outperforms existing methods on multiple benchmarks, indicating its effectiveness and efficiency.

Conclusion: LightGlueStick achieves new state-of-the-art performance in point and line matching tasks, enabling efficient real-time applications.

Abstract: Lines and points are complementary local features, whose combination has
proven effective for applications such as SLAM and Structure-from-Motion. The
backbone of these pipelines are the local feature matchers, establishing
correspondences across images. Traditionally, point and line matching have been
treated as independent tasks. Recently, GlueStick proposed a GNN-based network
that simultaneously operates on points and lines to establish matches. While
running a single joint matching reduced the overall computational complexity,
the heavy architecture prevented real-time applications or deployment to edge
devices.
  Inspired by recent progress in point matching, we propose LightGlueStick, a
lightweight matcher for points and line segments. The key novel component in
our architecture is the Attentional Line Message Passing (ALMP), which
explicitly exposes the connectivity of the lines to the network, allowing for
efficient communication between nodes. In thorough experiments we show that
LightGlueStick establishes a new state-of-the-art across different benchmarks.
The code is available at https://github.com/aubingazhib/LightGlueStick.

</details>


### [34] [EDVD-LLaMA: Explainable Deepfake Video Detection via Multimodal Large Language Model Reasoning](https://arxiv.org/abs/2510.16442)
*Haoran Sun,Chen Cai,Huiping Zhuang,Kong Aik Lee,Lap-Pui Chau,Yi Wang*

Main category: cs.CV

TL;DR: 本论文提出了可解释的深度伪造视频检测（EDVD）任务，设计了EDVD-LLaMA多模态推理框架，解决了传统检测方法的透明性和泛化能力不足的问题，展现出优良的检测和解释性能。


<details>
  <summary>Details</summary>
Motivation: 传统深伪造视频检测方法缺乏透明性和足够的泛化能力，亟需可识别伪造内容并提供可验证推理解释的检测器。

Method: 采用ST-SIT提取全球和局部跨帧深度伪造特征，并构建Fg-MCoT机制以实现像素级时空视频定位和增强推理可靠性。

Result: EDVD-LLaMA实现了卓越的性能和鲁棒性，在检测准确性和可解释性方面远超以往的传统方法。

Conclusion: EDVD-LLaMA在检测准确性、可解释性以及处理跨伪造方法和跨数据集场景的能力方面表现出色，是对传统深度伪造视频检测方法的显著改进。

Abstract: The rapid development of deepfake video technology has not only facilitated
artistic creation but also made it easier to spread misinformation. Traditional
deepfake video detection (DVD) methods face issues such as a lack of
transparency in their principles and insufficient generalization capabilities
to cope with evolving forgery techniques. This highlights an urgent need for
detectors that can identify forged content and provide verifiable reasoning
explanations. This paper proposes the explainable deepfake video detection
(EDVD) task and designs the EDVD-LLaMA multimodal, a large language model
(MLLM) reasoning framework, which provides traceable reasoning processes
alongside accurate detection results and trustworthy explanations. Our approach
first incorporates a Spatio-Temporal Subtle Information Tokenization (ST-SIT)
to extract and fuse global and local cross-frame deepfake features, providing
rich spatio-temporal semantic information input for MLLM reasoning. Second, we
construct a Fine-grained Multimodal Chain-of-Thought (Fg-MCoT) mechanism, which
introduces facial feature data as hard constraints during the reasoning process
to achieve pixel-level spatio-temporal video localization, suppress
hallucinated outputs, and enhance the reliability of the chain of thought. In
addition, we build an Explainable Reasoning FF++ benchmark dataset
(ER-FF++set), leveraging structured data to annotate videos and ensure quality
control, thereby supporting dual supervision for reasoning and detection.
Extensive experiments demonstrate that EDVD-LLaMA achieves outstanding
performance and robustness in terms of detection accuracy, explainability, and
its ability to handle cross-forgery methods and cross-dataset scenarios.
Compared to previous DVD methods, it provides a more explainable and superior
solution. The source code and dataset will be publicly available.

</details>


### [35] [Enhancing Rotated Object Detection via Anisotropic Gaussian Bounding Box and Bhattacharyya Distance](https://arxiv.org/abs/2510.16445)
*Chien Thai,Mai Xuan Trang,Huong Ninh,Hoang Hiep Ly,Anh Son Le*

Main category: cs.CV

TL;DR: 提出了一种新的损失函数以提升旋转物体检测的精度和鲁棒性，实验证明该方法有效。


<details>
  <summary>Details</summary>
Motivation: 传统检测框架在处理旋转物体时表现不佳，缺乏有效的方向捕捉能力，亟需改进。

Method: 提出了一种基于高斯边界框表示和Bhattacharyya距离的改进损失函数，结合了旋转不变性，并应用于先进的深度学习检测器中。

Result: 大量实验表明，采用新损失函数的模型在平均精度指标上显著超越了现有方法。

Conclusion: 该方法在旋转物体检测中显著提高了准确性和鲁棒性，建立了新基准。

Abstract: Detecting rotated objects accurately and efficiently is a significant
challenge in computer vision, particularly in applications such as aerial
imagery, remote sensing, and autonomous driving. Although traditional object
detection frameworks are effective for axis-aligned objects, they often
underperform in scenarios involving rotated objects due to their limitations in
capturing orientation variations. This paper introduces an improved loss
function aimed at enhancing detection accuracy and robustness by leveraging the
Gaussian bounding box representation and Bhattacharyya distance. In addition,
we advocate for the use of an anisotropic Gaussian representation to address
the issues associated with isotropic variance in square-like objects. Our
proposed method addresses these challenges by incorporating a
rotation-invariant loss function that effectively captures the geometric
properties of rotated objects. We integrate this proposed loss function into
state-of-the-art deep learning-based rotated object detection detectors, and
extensive experiments demonstrated significant improvements in mean Average
Precision metrics compared to existing methods. The results highlight the
potential of our approach to establish new benchmark in rotated object
detection, with implications for a wide range of applications requiring precise
and reliable object localization irrespective of orientation.

</details>


### [36] [VIPAMIN: Visual Prompt Initialization via Embedding Selection and Subspace Expansion](https://arxiv.org/abs/2510.16446)
*Jaekyun Park,Hye Won Chung*

Main category: cs.CV

TL;DR: VIPAMIN是一个新的视觉提示初始化方法，通过对齐语义区和注入新表现方向，增强自监督模型的适应性，显著提升了多项任务的表现。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉提示调优方法在自监督学习中的适应性不足，特别是在数据稀缺和挑战性任务中。

Method: 通过对嵌入空间中语义信息区域的对齐和注入新的表示方向，VIPAMIN增强了自监督模型的适应性。

Result: 本文提出了一种新的视觉提示初始化策略VIPAMIN，以解决现有视觉提示调优方法在自监督基础上适应性不足的问题。这种方法通过将提示与嵌入空间中语义信息丰富的区域对齐，并注入超出预训练子空间的新表现方向，从而增强了自监督模型的适应性。VIPAMIN只需一次前向传递和轻量级操作，即可在不同任务和数据集规模上持续提高性能，成为视觉提示调优的新态度。

Conclusion: VIPAMIN在多个任务和数据集上表现出优越性，标志着视觉提示调优的新进展。

Abstract: In the era of large-scale foundation models, fully fine-tuning pretrained
networks for each downstream task is often prohibitively resource-intensive.
Prompt tuning offers a lightweight alternative by introducing tunable prompts
while keeping the backbone frozen. However, existing visual prompt tuning
methods often fail to specialize the prompts or enrich the representation
space--especially when applied to self-supervised backbones. We show that these
limitations become especially pronounced in challenging tasks and data-scarce
settings, where effective adaptation is most critical. In this work, we
introduce VIPAMIN, a visual prompt initialization strategy that enhances
adaptation of self-supervised models by (1) aligning prompts with semantically
informative regions in the embedding space, and (2) injecting novel
representational directions beyond the pretrained subspace. Despite its
simplicity--requiring only a single forward pass and lightweight
operations--VIPAMIN consistently improves performance across diverse tasks and
dataset sizes, setting a new state of the art in visual prompt tuning. Our code
is available at https://github.com/iamjaekyun/vipamin.

</details>


### [37] [Instance-Aware Pseudo-Labeling and Class-Focused Contrastive Learning for Weakly Supervised Domain Adaptive Segmentation of Electron Microscopy](https://arxiv.org/abs/2510.16450)
*Shan Xiong,Jiabao Chen,Ye Wang,Jialin Peng*

Main category: cs.CV

TL;DR: 本研究提出了一种新的弱监督领域适应方法，结合了多任务学习和实例感知伪标签选择策略，显著提高了分割性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决注释成本高的问题，同时提高无监督领域自适应的方法在实际应用中的性能。

Method: 采用多任务学习框架，进行分割和中心检测，结合交叉教学机制和面向类别的跨域对比学习。

Result: 在具有挑战性的数据集上，通过全面的验证和比较，展示了本方法在性能上优于现有的无监督和弱监督领域适应方法。

Conclusion: 本研究提出了一种结合多任务学习框架和新的实例感知伪标签选择策略的方法，显著提高了弱监督领域适应的性能。

Abstract: Annotation-efficient segmentation of the numerous mitochondria instances from
various electron microscopy (EM) images is highly valuable for biological and
neuroscience research. Although unsupervised domain adaptation (UDA) methods
can help mitigate domain shifts and reduce the high costs of annotating each
domain, they typically have relatively low performance in practical
applications. Thus, we investigate weakly supervised domain adaptation (WDA)
that utilizes additional sparse point labels on the target domain, which
require minimal annotation effort and minimal expert knowledge. To take full
use of the incomplete and imprecise point annotations, we introduce a multitask
learning framework that jointly conducts segmentation and center detection with
a novel cross-teaching mechanism and class-focused cross-domain contrastive
learning. While leveraging unlabeled image regions is essential, we introduce
segmentation self-training with a novel instance-aware pseudo-label (IPL)
selection strategy. Unlike existing methods that typically rely on pixel-wise
pseudo-label filtering, the IPL semantically selects reliable and diverse
pseudo-labels with the help of the detection task. Comprehensive validations
and comparisons on challenging datasets demonstrate that our method outperforms
existing UDA and WDA methods, significantly narrowing the performance gap with
the supervised upper bound. Furthermore, under the UDA setting, our method also
achieves substantial improvements over other UDA techniques.

</details>


### [38] [OOS-DSD: Improving Out-of-stock Detection in Retail Images using Auxiliary Tasks](https://arxiv.org/abs/2510.16508)
*Franko Šikić,Sven Lončarić*

Main category: cs.CV

TL;DR: 本文介绍了一种新颖的OOS检测方法OOS-DSD，结合深度学习与辅助学习技术，显著提高了产品缺货检测的精准度。


<details>
  <summary>Details</summary>
Motivation: 提升零售产品缺货检测的准确性，特别是在深度估计方面的不足。

Method: 基于YOLOv8结构，增加了卷积分支以实现OOS检测、产品分割和场景深度估计，利用真实和伪标签数据训练各个分支。

Result: OOS-DSD方法在mAP上超越SOTA方法1.8%，并通过辅助学习和深度归一化分别增加了3.7%和4.2%的mAP。

Conclusion: 本文提出的OOS-DSD方法在OOS检测中优于现有的SOTA方法，并通过辅助学习和深度归一化显著提升了精度。

Abstract: Out-of-stock (OOS) detection is a very important retail verification process
that aims to infer the unavailability of products in their designated areas on
the shelf. In this paper, we introduce OOS-DSD, a novel deep learning-based
method that advances OOS detection through auxiliary learning. In particular,
we extend a well-established YOLOv8 object detection architecture with
additional convolutional branches to simultaneously detect OOS, segment
products, and estimate scene depth. While OOS detection and product
segmentation branches are trained using ground truth data, the depth estimation
branch is trained using pseudo-labeled annotations produced by the
state-of-the-art (SOTA) depth estimation model Depth Anything V2. Furthermore,
since the aforementioned pseudo-labeled depth estimates display relative depth,
we propose an appropriate depth normalization procedure that stabilizes the
training process. The experimental results show that the proposed method
surpassed the performance of the SOTA OOS detection methods by 1.8% of the mean
average precision (mAP). In addition, ablation studies confirm the
effectiveness of auxiliary learning and the proposed depth normalization
procedure, with the former increasing mAP by 3.7% and the latter by 4.2%.

</details>


### [39] [Enhancing Compositional Reasoning in CLIP via Reconstruction and Alignment of Text Descriptions](https://arxiv.org/abs/2510.16540)
*Jihoon Kwon,Kyle Min,Jy-yong Sohn*

Main category: cs.CV

TL;DR: 本文引入READ方法，改进视觉语言模型的组合推理能力，通过重建和对齐目标提升其整体性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在组合推理上的表现不佳，主要是由于文本编码器偏向单个单词，缺乏对词语之间关系的理解。

Method: 提出一种名为REconstruction and Alignment of text Descriptions (READ)的微调方法，增加了两种辅助目标：token级重建目标和句子级对齐目标。

Result: READ-CLIP模型在五个主要组合推理基准测试上表现优异，超越了最强传统微调基线，并且对现有CLIP变体的应用也提升了性能。

Conclusion: 通过引入重建和对齐目标，READ方法显著提升了模型在组合推理任务上的表现，最终达到五个主要基准测试的最先进水平。

Abstract: Despite recent advances, vision-language models trained with standard
contrastive objectives still struggle with compositional reasoning -- the
ability to understand structured relationships between visual and linguistic
elements. This shortcoming is largely due to the tendency of the text encoder
to focus on individual words rather than their relations, a limitation
reinforced by contrastive training that primarily aligns words with visual
objects. In this paper, we introduce REconstruction and Alignment of text
Descriptions (READ), a fine-tuning method designed to enhance compositional
reasoning by adding two auxiliary objectives to the contrastive learning: (1) a
token-level reconstruction objective, where a frozen pre-trained decoder
reconstructs alternative captions based on the embedding of the original
caption; and (2) a sentence-level alignment objective, which explicitly aligns
paraphrased sentences in the embedding space. We show that READ-CLIP, a model
derived by applying the READ method to the pre-trained CLIP model, achieves the
state-of-the-art performance across five major compositional reasoning
benchmarks, outperforming the strongest conventional fine-tuning baseline by up
to 4.1%. Furthermore, applying the READ to existing CLIP variants (including
NegCLIP and FSC-CLIP) also improves performance on these benchmarks.
Quantitative and qualitative analyses reveal that our proposed objectives --
reconstruction and alignment -- offer complementary benefits: the former
encourages the encoder to capture relationships between words within a caption,
while the latter ensures consistent representations for paraphrases expressed
with different wording.

</details>


### [40] [Watch Where You Move: Region-aware Dynamic Aggregation and Excitation for Gait Recognition](https://arxiv.org/abs/2510.16541)
*Binyuan Huang,Yongdong Luo,Xianda Guo,Xiawu Zheng,Zheng Zhu,Jiahui Pan,Chengju Zhou*

Main category: cs.CV

TL;DR: 本文提出一种新框架GaitRDAE，通过动态搜索运动区域和自适应时间尺度，提高了步态识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理运动区域时存在固定的时间尺度，无法适应动态变化的特征，本研究旨在解决这一问题。

Method: 提出了一种区域感知动态聚合与激励框架，通过两个核心模块进行动态搜索和学习。

Result: 实验结果表明，GaitRDAE在多项基准数据集上表现优异，突破了传统方法的限制。

Conclusion: GaitRDAE在多个基准数据集上实现了最先进的性能，能够有效应对动态变化的运动区域。

Abstract: Deep learning-based gait recognition has achieved great success in various
applications. The key to accurate gait recognition lies in considering the
unique and diverse behavior patterns in different motion regions, especially
when covariates affect visual appearance. However, existing methods typically
use predefined regions for temporal modeling, with fixed or equivalent temporal
scales assigned to different types of regions, which makes it difficult to
model motion regions that change dynamically over time and adapt to their
specific patterns. To tackle this problem, we introduce a Region-aware Dynamic
Aggregation and Excitation framework (GaitRDAE) that automatically searches for
motion regions, assigns adaptive temporal scales and applies corresponding
attention. Specifically, the framework includes two core modules: the
Region-aware Dynamic Aggregation (RDA) module, which dynamically searches the
optimal temporal receptive field for each region, and the Region-aware Dynamic
Excitation (RDE) module, which emphasizes the learning of motion regions
containing more stable behavior patterns while suppressing attention to static
regions that are more susceptible to covariates. Experimental results show that
GaitRDAE achieves state-of-the-art performance on several benchmark datasets.

</details>


### [41] [Fit for Purpose? Deepfake Detection in the Real World](https://arxiv.org/abs/2510.16556)
*Guangyu Lin,Li Lin,Christina P. Walker,Daniel S. Schiff,Shu Hu*

Main category: cs.CV

TL;DR: 现有深度伪造检测工具未能有效应对真实政治深度伪造内容，需要开发更具政治背景的检测框架。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成内容的激增，尤其是政治领域的深度伪造，社会对有效检测工具的需求日益迫切。

Method: 提出了基于政治深度伪造事件数据库的第一个系统基准，比较分析了各类深度伪造检测工具的表现。

Result: 现有的检测工具多在实验室环境下训练且缺乏通用性，对真实政治深度伪造内容效果不佳。付费工具虽表现优于免费模型，但整体均未能有效应对真实情况。

Conclusion: 现有的深度伪造检测工具在真实的政治深度伪造内容中普遍表现不佳，亟需针对政治背景的检测框架以更好地保护公众。

Abstract: The rapid proliferation of AI-generated content, driven by advances in
generative adversarial networks, diffusion models, and multimodal large
language models, has made the creation and dissemination of synthetic media
effortless, heightening the risks of misinformation, particularly political
deepfakes that distort truth and undermine trust in political institutions. In
turn, governments, research institutions, and industry have strongly promoted
deepfake detection initiatives as solutions. Yet, most existing models are
trained and validated on synthetic, laboratory-controlled datasets, limiting
their generalizability to the kinds of real-world political deepfakes
circulating on social platforms that affect the public. In this work, we
introduce the first systematic benchmark based on the Political Deepfakes
Incident Database, a curated collection of real-world political deepfakes
shared on social media since 2018. Our study includes a systematic evaluation
of state-of-the-art deepfake detectors across academia, government, and
industry. We find that the detectors from academia and government perform
relatively poorly. While paid detection tools achieve relatively higher
performance than free-access models, all evaluated detectors struggle to
generalize effectively to authentic political deepfakes, and are vulnerable to
simple manipulations, especially in the video domain. Results urge the need for
politically contextualized deepfake detection frameworks to better safeguard
the public in real-world settings.

</details>


### [42] [SHIELD: Suppressing Hallucinations In LVLM Encoders via Bias and Vulnerability Defense](https://arxiv.org/abs/2510.16596)
*Yiyang Huang,Liang Shi,Yitian Zhang,Yi Xu,Yun Fu*

Main category: cs.CV

TL;DR: 本论文提出SHIELD框架，通过策略减少大视觉语言模型中的物体幻觉，实验验证其效果。


<details>
  <summary>Details</summary>
Motivation: 探索LVLM中的物体幻觉问题，主要聚焦于视觉编码器，识别统计偏差、固有偏差和脆弱性三个关键问题。

Method: 提出了一种无训练的SHIELD框架，通过三种策略降低幻觉：重新加权视觉标记、引入噪声派生标记以及使用对抗攻击与对比解码。

Result: 实验表明，SHIELD在各种基准测试中有效缓解物体幻觉，同时在一般LVLM基准上表现良好。

Conclusion: SHIELD有效减轻了大视觉语言模型中的物体幻觉问题，并且在不同基准和LVLM系列中表现出色，具有广泛的适用性。

Abstract: Large Vision-Language Models (LVLMs) excel in diverse cross-modal tasks.
However, object hallucination, where models produce plausible but inaccurate
object descriptions, remains a significant challenge. In contrast to previous
work focusing on LLM components, this paper is the first to trace LVLM
hallucinations to visual encoders and identifies three key issues: statistical
bias, inherent bias, and vulnerability. To address these challenges, we propose
SHIELD, a training-free framework that mitigates hallucinations through three
strategies: re-weighting visual tokens to reduce statistical bias, introducing
noise-derived tokens to counter inherent bias, and applying adversarial attacks
with contrastive decoding to address vulnerability. Experiments demonstrate
that SHIELD effectively mitigates object hallucinations across diverse
benchmarks and LVLM families. Moreover, SHIELD achieves strong performance on
the general LVLM benchmark, highlighting its broad applicability. Code will be
released.

</details>


### [43] [VisionSelector: End-to-End Learnable Visual Token Compression for Efficient Multimodal LLMs](https://arxiv.org/abs/2510.16598)
*Jiaying Zhu,Yurui Zhu,Xin Lu,Wenrui Yan,Dong Li,Kunlin Liu,Xueyang Fu,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 本研究提出VisionSelector，通过轻量级的可学习token选择框架，提高了多模态大语言模型的性能，尤其在压缩情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有token压缩技术在信息丢失和性能下降方面的问题，尤其是在高分辨率图像和多图像输入情况下的计算和内存瓶颈。

Method: 提出了一种轻量级的端到端可学习的决策过程，通过VisionSelector模块实现有效的token选择，采用可微分的Top-K机制和课程退火策略。

Result: VisionSelector在各种压缩率下都表现出色，达到优异性能，在10%保留预算下比先前方法提高了12.14%。

Conclusion: VisionSelector显著提高了多模态大语言模型的性能与效率，实现了在保持150%保留率的基础上，准确率保持100%。

Abstract: Multimodal Large Language Models (MLLMs) encounter significant computational
and memory bottlenecks from the massive number of visual tokens generated by
high-resolution images or multi-image inputs. Previous token compression
techniques are often constrained by heuristic rules that risk discarding
critical information. They may suffer from biases, such as attention sinks,
that lead to sharp performance drops under aggressive compression ratios. To
address these limitations, we reformulate token compression as a lightweight
plug-and-play framework that reformulates token compression into an end-to-end
learnable decision process. To be specific, we propose VisionSelector, a scorer
module decoupled from the MLLM backbone that incorporates a differentiable
Top-K mechanism and a curriculum annealing strategy to bridge the
training-inference gap, enabling efficient and adaptive token selection various
arbitrary compression rates. Remarkably lightweight with only 12.85M trainable
parameters, VisionSelector demonstrates generalization across various
compression rates and adaptively identifying critical tokens. This leads to
superior performance across all compression budgets, evidenced by preserving
100% accuracy on MME with 30% retention budget, outperforming prior methods by
12.14% at 10% retention budget, and doubling prefill speed. Our code is
available at https://github.com/JulietChoo/VisionSelector .

</details>


### [44] [Self-Supervised Learning to Fly using Efficient Semantic Segmentation and Metric Depth Estimation for Low-Cost Autonomous UAVs](https://arxiv.org/abs/2510.16624)
*Sebastian Mocanu,Emil Slusanschi,Marius Leordeanu*

Main category: cs.CV

TL;DR: 本文提出了一种适用于小型无人机的视觉驱动自主飞行系统，通过语义分割和深度估计实现安全导航，测试结果显示优异的成功率和任务效率。


<details>
  <summary>Details</summary>
Motivation: 开发一种基于视觉的自主飞行系统，以在受控室内环境中操作的小型无人机，可以不依赖于GPS或昂贵传感器，解决障碍物避免和安全着陆等任务。

Method: 结合语义分割和单目深度估计，采用自适应比例因子算法和知识蒸馏框架。

Result: 通过30次真实环境飞行测试和100次数字双胞胎环境测试，展示了系统在监视期间延长飞行距离和减少任务时间的能力，同时维持100%的成功率。

Conclusion: 该系统在结构化环境中推进了一种基于视觉的无人机导航方法，能够有效估计深度并提高计算效率，适合资源受限的平台使用。

Abstract: This paper presents a vision-only autonomous flight system for small UAVs
operating in controlled indoor environments. The system combines semantic
segmentation with monocular depth estimation to enable obstacle avoidance,
scene exploration, and autonomous safe landing operations without requiring GPS
or expensive sensors such as LiDAR. A key innovation is an adaptive scale
factor algorithm that converts non-metric monocular depth predictions into
accurate metric distance measurements by leveraging semantic ground plane
detection and camera intrinsic parameters, achieving a mean distance error of
14.4 cm. The approach uses a knowledge distillation framework where a
color-based Support Vector Machine (SVM) teacher generates training data for a
lightweight U-Net student network (1.6M parameters) capable of real-time
semantic segmentation. For more complex environments, the SVM teacher can be
replaced with a state-of-the-art segmentation model. Testing was conducted in a
controlled 5x4 meter laboratory environment with eight cardboard obstacles
simulating urban structures. Extensive validation across 30 flight tests in a
real-world environment and 100 flight tests in a digital-twin environment
demonstrates that the combined segmentation and depth approach increases the
distance traveled during surveillance and reduces mission time while
maintaining 100% success rates. The system is further optimized through
end-to-end learning, where a compact student neural network learns complete
flight policies from demonstration data generated by our best-performing
method, achieving an 87.5% autonomous mission success rate. This work advances
practical vision-based drone navigation in structured environments,
demonstrating solutions for metric depth estimation and computational
efficiency challenges that enable deployment on resource-constrained platforms.

</details>


### [45] [MultiVerse: A Multi-Turn Conversation Benchmark for Evaluating Large Vision and Language Models](https://arxiv.org/abs/2510.16641)
*Young-Jun Lee,Byung-Kwan Lee,Jianshu Zhang,Yechan Hwang,Byungsoo Ko,Han-Gyu Kim,Dongyu Yao,Xuankun Rong,Eojin Joo,Seung-Ho Han,Bowon Ko,Ho-Jin Choi*

Main category: cs.CV

TL;DR: MultiVerse是一个新的多轮对话基准，包含647个对话，评测了18个视觉语言模型，挑战性很大，强调了上下文的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有多轮对话数据集无法全面捕捉用户面临的复杂对话场景，因此需要引入新的基准以更好地评估模型性能。

Method: 使用基于检查表的评估方法，通过GPT-4o作为自动评估工具，评测VLM在37个关键方面的表现。

Result: 评估了18个视觉语言模型在MultiVerse基准上的表现，发现即使是最强模型的复杂多轮对话成功率也仅为50%。

Conclusion: MultiVerse是一个用于评估视觉语言模型多轮对话能力的基准，展示了现有模型在复杂对话中的局限性，并强调了上下文学习的重要性。

Abstract: Vision-and-Language Models (VLMs) have shown impressive capabilities on
single-turn benchmarks, yet real-world applications often demand more intricate
multi-turn dialogues. Existing multi-turn datasets (e.g, MMDU, ConvBench) only
partially capture the breadth and depth of conversational scenarios encountered
by users. In this work, we introduce MultiVerse, a novel multi-turn
conversation benchmark featuring 647 dialogues - each averaging four turns -
derived from a diverse set of 12 popular VLM evaluation benchmarks. With 484
tasks and 484 interaction goals, MultiVerse covers a wide range of topics, from
factual knowledge and perception to advanced reasoning tasks such as
mathematics and coding. To facilitate robust assessment, we propose a
checklist-based evaluation method that leverages GPT-4o as the automated
evaluator, measuring performance across 37 key aspects, including perceptual
accuracy, linguistic clarity, and factual correctness. We evaluate 18 VLMs on
MultiVerse, revealing that even the strongest models (e.g., GPT-4o) achieve
only a 50% success rate in complex multi-turn conversations, highlighting the
dataset's challenging nature. Notably, we find that providing full dialogue
context significantly enhances performance for smaller or weaker models,
emphasizing the importance of in-context learning. We believe MultiVerse is a
landscape of evaluating multi-turn interaction abilities for VLMs.

</details>


### [46] [Structured Interfaces for Automated Reasoning with 3D Scene Graphs](https://arxiv.org/abs/2510.16643)
*Aaron Ray,Jacob Arkin,Harel Biggie,Chuchu Fan,Luca Carlone,Nicholas Roy*

Main category: cs.CV

TL;DR: 本研究提出将检索增强生成方法应用于3D场景图，以改善自然语言与机器人的连接，实现更好的性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了让机器人能够理解和反应用户的自然语言输入，需要将自然语言与机器人对世界的基本表示相连接。

Method: 采用检索增强生成技术，从图形数据库中查询与任务相关的子集3DSG，并将其与大语言模型进行结合。

Result: 与基线方法相比，采用Cypher界面的方法在指令跟随和场景问答任务中表现出显著提升，并且在本地和云基础模型上都实现了良好的扩展性。

Conclusion: 使用Cypher作为3D场景图的接口，可以显著提高大规模复杂图形语言任务的性能，同时减少场景图内容的标记数量。

Abstract: In order to provide a robot with the ability to understand and react to a
user's natural language inputs, the natural language must be connected to the
robot's underlying representations of the world. Recently, large language
models (LLMs) and 3D scene graphs (3DSGs) have become a popular choice for
grounding natural language and representing the world. In this work, we address
the challenge of using LLMs with 3DSGs to ground natural language. Existing
methods encode the scene graph as serialized text within the LLM's context
window, but this encoding does not scale to large or rich 3DSGs. Instead, we
propose to use a form of Retrieval Augmented Generation to select a subset of
the 3DSG relevant to the task. We encode a 3DSG in a graph database and provide
a query language interface (Cypher) as a tool to the LLM with which it can
retrieve relevant data for language grounding. We evaluate our approach on
instruction following and scene question-answering tasks and compare against
baseline context window and code generation methods. Our results show that
using Cypher as an interface to 3D scene graphs scales significantly better to
large, rich graphs on both local and cloud-based models. This leads to large
performance improvements in grounded language tasks while also substantially
reducing the token count of the scene graph content. A video supplement is
available at https://www.youtube.com/watch?v=zY_YI9giZSA.

</details>


### [47] [Universal and Transferable Attacks on Pathology Foundation Models](https://arxiv.org/abs/2510.16660)
*Yuntian Wang,Xilin Yang,Che-Yung Shen,Nir Pillar,Aydogan Ozcan*

Main category: cs.CV

TL;DR: UTAP 是一种通用和可转移的对抗扰动，能够显著降低病理基础模型的性能，揭示其在多样本任务中的脆弱性，强调了提高模型鲁棒性和防御机制的必要性。


<details>
  <summary>Details</summary>
Motivation: 为了识别和评估病理基础模型在多样化数据分布下的脆弱性，提出了一种新的对抗扰动方法 UTAP。

Method: 通过深度学习优化固定的弱噪声模式，UTAP 被应用于病理图像以系统性地破坏多个病理基础模型的特征表示能力。

Result: UTAP 在各种先进的病理基础模型中进行了系统评估，导致了输入图像的可视不可感知修改，同时在多种数据集上显著降低了模型性能。

Conclusion: UTAP 作为一种通用和可转移的对抗扰动，揭示了病理基础模型的脆弱性，并显著降低其在多样本任务中的表现，强调了增强模型鲁棒性和防御机制的重要性。

Abstract: We introduce Universal and Transferable Adversarial Perturbations (UTAP) for
pathology foundation models that reveal critical vulnerabilities in their
capabilities. Optimized using deep learning, UTAP comprises a fixed and weak
noise pattern that, when added to a pathology image, systematically disrupts
the feature representation capabilities of multiple pathology foundation
models. Therefore, UTAP induces performance drops in downstream tasks that
utilize foundation models, including misclassification across a wide range of
unseen data distributions. In addition to compromising the model performance,
we demonstrate two key features of UTAP: (1) universality: its perturbation can
be applied across diverse field-of-views independent of the dataset that UTAP
was developed on, and (2) transferability: its perturbation can successfully
degrade the performance of various external, black-box pathology foundation
models - never seen before. These two features indicate that UTAP is not a
dedicated attack associated with a specific foundation model or image dataset,
but rather constitutes a broad threat to various emerging pathology foundation
models and their applications. We systematically evaluated UTAP across various
state-of-the-art pathology foundation models on multiple datasets, causing a
significant drop in their performance with visually imperceptible modifications
to the input images using a fixed noise pattern. The development of these
potent attacks establishes a critical, high-standard benchmark for model
robustness evaluation, highlighting a need for advancing defense mechanisms and
potentially providing the necessary assets for adversarial training to ensure
the safe and reliable deployment of AI in pathology.

</details>


### [48] [HYDRA: HYbrid knowledge Distillation and spectral Reconstruction Algorithm for high channel hyperspectral camera applications](https://arxiv.org/abs/2510.16664)
*Christopher Thirgood,Oscar Mendez,Erin Ling,Jon Storey,Simon Hadfield*

Main category: cs.CV

TL;DR: 本论文提出HYDRA，通过教师-学生模型架构改进光谱重建精度和效率，超越当前技术指标。


<details>
  <summary>Details</summary>
Motivation: 现有的光谱重建方法在处理复杂的高光谱图像时存在限制，特别是对光谱通道较多的情况。

Method: 采用教师模型和学生模型相结合的方式，通过新颖的训练方法进行光谱重建。

Result: HYDRA在各项指标上展现出最先进的性能，包括18%的精确度提升，并且在多个通道深度下实现了更快的推理时间。

Conclusion: 本研究提出了一种新的光谱重建方法HYDRA，显著提高了光谱重建的精度和效率。

Abstract: Hyperspectral images (HSI) promise to support a range of new applications in
computer vision. Recent research has explored the feasibility of generalizable
Spectral Reconstruction (SR), the problem of recovering a HSI from a natural
three-channel color image in unseen scenarios.
  However, previous Multi-Scale Attention (MSA) works have only demonstrated
sufficient generalizable results for very sparse spectra, while modern HSI
sensors contain hundreds of channels.
  This paper introduces a novel approach to spectral reconstruction via our
HYbrid knowledge Distillation and spectral Reconstruction Architecture (HYDRA).
  Using a Teacher model that encapsulates latent hyperspectral image data and a
Student model that learns mappings from natural images to the Teacher's encoded
domain, alongside a novel training method, we achieve high-quality spectral
reconstruction.
  This addresses key limitations of prior SR models, providing SOTA performance
across all metrics, including an 18\% boost in accuracy, and faster inference
times than current SOTA models at various channel depths.

</details>


### [49] [SDPA++: A General Framework for Self-Supervised Denoising with Patch Aggregation](https://arxiv.org/abs/2510.16702)
*Huy Minh Nhat Nguyen,Triet Hoang Minh Dao,Chau Vinh Hoang Truong,Cuong Tuan Nguyen*

Main category: cs.CV

TL;DR: 提出了一种名为SDPA++的自我监督去噪框架，能够在无清晰参考的情况下提升OCT图像质量。


<details>
  <summary>Details</summary>
Motivation: 克服获取配对的干净和真实世界噪声OCT图像数据集的挑战，以提高成像清晰度，推动生物医学成像的研究。

Method: 通过自我融合和自我监督去噪生成伪真实图像，然后利用基于补丁的策略训练去噪模型。

Result: 通过CNR、MSR、TP和EP等指标验证了我们方法在真实世界数据集上的性能提升。

Conclusion: SDPA++方法能够有效提升OCT图像的质量，为临床诊断提供支持。

Abstract: Optical Coherence Tomography (OCT) is a widely used non-invasive imaging
technique that provides detailed three-dimensional views of the retina, which
are essential for the early and accurate diagnosis of ocular diseases.
Consequently, OCT image analysis and processing have emerged as key research
areas in biomedical imaging. However, acquiring paired datasets of clean and
real-world noisy OCT images for supervised denoising models remains a
formidable challenge due to intrinsic speckle noise and practical constraints
in clinical imaging environments. To address these issues, we propose SDPA++: A
General Framework for Self-Supervised Denoising with Patch Aggregation. Our
novel approach leverages only noisy OCT images by first generating
pseudo-ground-truth images through self-fusion and self-supervised denoising.
These refined images then serve as targets to train an ensemble of denoising
models using a patch-based strategy that effectively enhances image clarity.
Performance improvements are validated via metrics such as Contrast-to-Noise
Ratio (CNR), Mean Square Ratio (MSR), Texture Preservation (TP), and Edge
Preservation (EP) on the real-world dataset from the IEEE SPS Video and Image
Processing Cup. Notably, the VIP Cup dataset contains only real-world noisy OCT
images without clean references, highlighting our method's potential for
improving image quality and diagnostic outcomes in clinical practice.

</details>


### [50] [Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization](https://arxiv.org/abs/2510.16704)
*Tianxin Wei,Yifan Chen,Xinrui He,Wenxuan Bao,Jingrui He*

Main category: cs.CV

TL;DR: 本研究提出了一种新的对比学习方法DCCL，解决了领域泛化中的类内连接性不足问题，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 训练和测试样本之间的分布转变影响模型的泛化性能，激励对领域泛化（DG）的研究。

Method: 采用域连接对比学习（DCCL）来增强跨域的概念连接性，并在数据和模型层面进行改进。

Result: 通过更积极的数据增强和交叉领域正样本提高类内连接性，同时利用预训练表示的类内连接性进行模型锚定，结合生成变换损失进行全面实验验证。

Conclusion: DCCL方法在无领域监督的情况下超越了现有的最先进基线，验证了其有效性。

Abstract: Distribution shifts between training and testing samples frequently occur in
practice and impede model generalization performance. This crucial challenge
thereby motivates studies on domain generalization (DG), which aim to predict
the label on unseen target domain data by solely using data from source
domains. It is intuitive to conceive the class-separated representations
learned in contrastive learning (CL) are able to improve DG, while the reality
is quite the opposite: users observe directly applying CL deteriorates the
performance. We analyze the phenomenon with the insights from CL theory and
discover lack of intra-class connectivity in the DG setting causes the
deficiency. We thus propose a new paradigm, domain-connecting contrastive
learning (DCCL), to enhance the conceptual connectivity across domains and
obtain generalizable representations for DG. On the data side, more aggressive
data augmentation and cross-domain positive samples are introduced to improve
intra-class connectivity. On the model side, to better embed the unseen test
domains, we propose model anchoring to exploit the intra-class connectivity in
pre-trained representations and complement the anchoring with generative
transformation loss. Extensive experiments on five standard DG benchmarks are
performed. The results verify that DCCL outperforms state-of-the-art baselines
even without domain supervision. The detailed model implementation and the code
are provided through https://github.com/weitianxin/DCCL

</details>


### [51] [HumanCM: One Step Human Motion Prediction](https://arxiv.org/abs/2510.16709)
*Liu Haojie,Gao Suixiang*

Main category: cs.CV

TL;DR: HumanCM是一种高效的人类运动预测框架，采用单步生成和时空架构，在多个数据集上表现优秀。


<details>
  <summary>Details</summary>
Motivation: 旨在提高人类运动预测的效率和准确性，克服扩散模型多步骤去噪的局限性。

Method: 采用基于Transformer的时空架构，通过自一致映射实现单步人类运动预测。

Result: 在Human3.6M和HumanEva-I数据集上，HumanCM展现出与最先进的扩散模型相当或更好的精度，推理步骤减少了两个数量级。

Conclusion: HumanCM在精度和推理步骤上超越了现有的扩散模型，表现出较高的效率。

Abstract: We present HumanCM, a one-step human motion prediction framework built upon
consistency models. Instead of relying on multi-step denoising as in
diffusion-based methods, HumanCM performs efficient single-step generation by
learning a self-consistent mapping between noisy and clean motion states. The
framework adopts a Transformer-based spatiotemporal architecture with temporal
embeddings to model long-range dependencies and preserve motion coherence.
Experiments on Human3.6M and HumanEva-I demonstrate that HumanCM achieves
comparable or superior accuracy to state-of-the-art diffusion models while
reducing inference steps by up to two orders of magnitude.

</details>


### [52] [Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes](https://arxiv.org/abs/2510.16714)
*Xiongkun Linghu,Jiangyong Huang,Ziyu Zhu,Baoxiong Jia,Siyuan Huang*

Main category: cs.CV

TL;DR: 本论文提出SCENECOT框架，首次将链式思维推理成功应用于3D场景理解，通过构建多模态可视线索进行人类般的推理，开发了185K实例的数据集，并在多个基准测试中取得了良好的表现。


<details>
  <summary>Details</summary>
Motivation: 现有3D大语言模型在实现基于场景-对象的推理方面仍然存在不足，亟需探索人类般场景-对象的推理机制。

Method: 提出了一种基于多模态专家模块的可视线索构建的场景链式思维推理方法SCENECOT，首先将复杂推理任务分解为简单可管理的问题。

Result: 开发了首个大规模的基于链式思维推理的数据集SCENECOT-185K，包含185K个高质量实例，经过广泛实验，在多项复杂3D场景推理基准上表现强劲，与基础问题回答的相关性高。

Conclusion: 提出了一种新的框架SCENECOT，首次成功地将链式思维推理应用于3D场景理解，实现了人类般的逐步推理，并为3D场景的更广泛理解提供了潜在的扩展可能。

Abstract: Existing research on 3D Large Language Models (LLMs) still struggles to
achieve grounded question-answering, primarily due to the under-exploration of
the mech- anism of human-like scene-object grounded reasoning. This paper
bridges the gap by presenting a novel framework. We first introduce a grounded
Chain-of- Thought reasoning method in 3D scenes (SCENECOT), decoupling a
complex reasoning task into simpler and manageable problems, and building
corresponding visual clues based on multimodal expert modules. To enable such a
method, we develop SCENECOT-185K, the first large-scale grounded CoT reasoning
dataset, consisting of 185K high-quality instances. Extensive experiments
across various complex 3D scene reasoning benchmarks demonstrate that our new
framework achieves strong performance with high grounding-QA coherence. To the
best of our knowledge, this is the first successful application of CoT
reasoning to 3D scene understanding, enabling step-by-step human-like reasoning
and showing potential for extension to broader 3D scene understanding
scenarios.

</details>


### [53] [Vision-Centric 4D Occupancy Forecasting and Planning via Implicit Residual World Models](https://arxiv.org/abs/2510.16729)
*Jianbiao Mei,Yu Yang,Xuemeng Yang,Licheng Wen,Jiajun Lv,Botian Shi,Yong Liu*

Main category: cs.CV

TL;DR: IR-WM通过优化状态建模和变化预测，在自动驾驶中的场景重建和规划精度上达到顶尖表现。


<details>
  <summary>Details</summary>
Motivation: 为了避免冗余建模静态背景的问题，提高视觉中心模型在未来场景重建方面的有效性。

Method: 提出了一种隐式残差世界模型，通过鸟瞰图表示当前状态，并预测仅针对自动驾驶动作和场景上下文的变化。

Result: IR-WM有效建模世界当前状态及演变，应用对齐模块减少误差积累，并探讨了不同的预测-规划耦合方案。

Conclusion: IR-WM在4D占据预测和轨迹规划方面在nuScenes基准上表现出色，显著提高了规划精度。

Abstract: End-to-end autonomous driving systems increasingly rely on vision-centric
world models to understand and predict their environment. However, a common
ineffectiveness in these models is the full reconstruction of future scenes,
which expends significant capacity on redundantly modeling static backgrounds.
To address this, we propose IR-WM, an Implicit Residual World Model that
focuses on modeling the current state and evolution of the world. IR-WM first
establishes a robust bird's-eye-view representation of the current state from
the visual observation. It then leverages the BEV features from the previous
timestep as a strong temporal prior and predicts only the "residual", i.e., the
changes conditioned on the ego-vehicle's actions and scene context. To
alleviate error accumulation over time, we further apply an alignment module to
calibrate semantic and dynamic misalignments. Moreover, we investigate
different forecasting-planning coupling schemes and demonstrate that the
implicit future state generated by world models substantially improves planning
accuracy. On the nuScenes benchmark, IR-WM achieves top performance in both 4D
occupancy forecasting and trajectory planning.

</details>


### [54] [UKANFormer: Noise-Robust Semantic Segmentation for Coral Reef Mapping via a Kolmogorov-Arnold Network-Transformer Hybrid](https://arxiv.org/abs/2510.16730)
*Tianyang Dou,Ming Li,Jiangying Qin,Xuan Liao,Jiageng Zhong,Armin Gruen,Mengyi Deng*

Main category: cs.CV

TL;DR: 提出UKANFormer模型，通过结合全局-局部变换块实现高精度的珊瑚礁映射，成功应对噪声标签挑战，推动了生态监测的发展。


<details>
  <summary>Details</summary>
Motivation: 需要处理现有全球产品在空间精度和语义一致性上的局限性，以便进行珊瑚礁的有效保护。

Method: 提出一种新型的语义分割模型UKANFormer，结合全局-局部变换块来提取全局语义结构和局部边界细节。

Result: UKANFormer在实验中达到了67.00%的珊瑚分类IoU和83.98%的像素准确率，超越了传统基准并生成了比训练时使用的噪声标签更准确的预测。

Conclusion: UKANFormer模型在噪声标签条件下实现了高精度的珊瑚礁映射，为生态监测提供了可靠基础。

Abstract: Coral reefs are vital yet fragile ecosystems that require accurate
large-scale mapping for effective conservation. Although global products such
as the Allen Coral Atlas provide unprecedented coverage of global coral reef
distri-bution, their predictions are frequently limited in spatial precision
and semantic consistency, especially in regions requiring fine-grained boundary
delineation. To address these challenges, we propose UKANFormer, a novel
se-mantic segmentation model designed to achieve high-precision mapping under
noisy supervision derived from Allen Coral Atlas. Building upon the UKAN
architecture, UKANFormer incorporates a Global-Local Transformer (GL-Trans)
block in the decoder, enabling the extraction of both global semantic
structures and local boundary details. In experiments, UKANFormer achieved a
coral-class IoU of 67.00% and pixel accuracy of 83.98%, outperforming
conventional baselines under the same noisy labels setting. Remarkably, the
model produces predictions that are visually and structurally more accurate
than the noisy labels used for training. These results challenge the notion
that data quality directly limits model performance, showing that architectural
design can mitigate label noise and sup-port scalable mapping under imperfect
supervision. UKANFormer provides a foundation for ecological monitoring where
reliable labels are scarce.

</details>


### [55] [A Comprehensive Survey on World Models for Embodied AI](https://arxiv.org/abs/2510.16732)
*Xinqing Li,Xin He,Le Zhang,Yun Liu*

Main category: cs.CV

TL;DR: 本论文综述了具身AI中世界模型的统一框架，提出分类体系，分析当前模型及其挑战。


<details>
  <summary>Details</summary>
Motivation: 随着具身AI的发展，迫切需要有效的世界模型来提升感知、预测和决策能力。

Method: 通过系统化分类和定量比较的方法，探讨世界模型的功能性、时间建模和空间表示等不同维度。

Result: 提出了一个综合性的世界模型分类体系，并提供了现有模型的定量比较和对关键挑战的总结。

Conclusion: 本综述提供了一个关于世界模型在具身AI中的统一框架，并分析了现有模型的优缺点及未来挑战。

Abstract: Embodied AI requires agents that perceive, act, and anticipate how actions
reshape future world states. World models serve as internal simulators that
capture environment dynamics, enabling forward and counterfactual rollouts to
support perception, prediction, and decision making. This survey presents a
unified framework for world models in embodied AI. Specifically, we formalize
the problem setting and learning objectives, and propose a three-axis taxonomy
encompassing: (1) Functionality, Decision-Coupled vs. General-Purpose; (2)
Temporal Modeling, Sequential Simulation and Inference vs. Global Difference
Prediction; (3) Spatial Representation, Global Latent Vector, Token Feature
Sequence, Spatial Latent Grid, and Decomposed Rendering Representation. We
systematize data resources and metrics across robotics, autonomous driving, and
general video settings, covering pixel prediction quality, state-level
understanding, and task performance. Furthermore, we offer a quantitative
comparison of state-of-the-art models and distill key open challenges,
including the scarcity of unified datasets and the need for evaluation metrics
that assess physical consistency over pixel fidelity, the trade-off between
model performance and the computational efficiency required for real-time
control, and the core modeling difficulty of achieving long-horizon temporal
consistency while mitigating error accumulation. Finally, we maintain a curated
bibliography at https://github.com/Li-Zn-H/AwesomeWorldModels.

</details>


### [56] [Visual Autoregressive Models Beat Diffusion Models on Inference Time Scaling](https://arxiv.org/abs/2510.16751)
*Erik Riise,Mehmet Onurcan Kaya,Dim P. Papadopoulos*

Main category: cs.CV

TL;DR: 本文探讨了模型架构在图像生成中的重要性，束搜索显著改善了生成结果。


<details>
  <summary>Details</summary>
Motivation: 将大语言模型在推理时间扩展方面的成功经验翻译到图像生成领域，探索如何有效利用模型架构。

Method: 通过应用有效的搜索策略，特别是束搜索，来提高文本到图像生成的效果。

Result: 束搜索显著提升了文本到图像生成的效果，使得一个具有20亿参数的自回归模型在多个基准上超过了一个具有120亿参数的扩散模型。

Conclusion: 模型架构对于视觉生成的推理时间优化至关重要，而不仅仅是规模。

Abstract: While inference-time scaling through search has revolutionized Large Language
Models, translating these gains to image generation has proven difficult.
Recent attempts to apply search strategies to continuous diffusion models show
limited benefits, with simple random sampling often performing best. We
demonstrate that the discrete, sequential nature of visual autoregressive
models enables effective search for image generation. We show that beam search
substantially improves text-to-image generation, enabling a 2B parameter
autoregressive model to outperform a 12B parameter diffusion model across
benchmarks. Systematic ablations show that this advantage comes from the
discrete token space, which allows early pruning and computational reuse, and
our verifier analysis highlights trade-offs between speed and reasoning
capability. These findings suggest that model architecture, not just scale, is
critical for inference-time optimization in visual generation.

</details>


### [57] [Prominence-Aware Artifact Detection and Dataset for Image Super-Resolution](https://arxiv.org/abs/2510.16752)
*Ivan Molodetskikh,Kirill Malyshev,Mark Mirgaleev,Nikita Zagainov,Evgeney Bogatyrev,Dmitriy Vatolin*

Main category: cs.CV

TL;DR: 本研究建立了一个新数据集和模型，专注于评估超分辨率图像中的伪影显著性，推动伪影的识别和应对。


<details>
  <summary>Details</summary>
Motivation: 伪影对人类观察者的感知影响各异，强调需要根据显著性来识别伪影，而非将其视为统一的缺陷。

Method: 通过收集1302个来自11种现代超分辨率方法的伪影示例，并为其配对众包的突出评分，构建了包含伪影特征的数据集。然后训练一个轻量级回归器，生成空间突出热图。

Result: 所提出的回归模型在检测突出伪影方面超越了现有方法，并提供了便于突出感知评估和减轻伪影的工具。

Conclusion: 本研究提出了一种新的数据集和轻量级回归模型，旨在更有效地评估和减轻超分辨率图像中的突出伪影。

Abstract: Generative image super-resolution (SR) is rapidly advancing in visual quality
and detail restoration. As the capacity of SR models expands, however, so does
their tendency to produce artifacts: incorrect, visually disturbing details
that reduce perceived quality. Crucially, their perceptual impact varies: some
artifacts are barely noticeable while others strongly degrade the image. We
argue that artifacts should be characterized by their prominence to human
observers rather than treated as uniform binary defects. Motivated by this, we
present a novel dataset of 1302 artifact examples from 11 contemporary image-SR
methods, where each artifact is paired with a crowdsourced prominence score.
Building on this dataset, we train a lightweight regressor that produces
spatial prominence heatmaps and outperforms existing methods at detecting
prominent artifacts. We release the dataset and code to facilitate
prominence-aware evaluation and mitigation of SR artifacts.

</details>


### [58] [WaMaIR: Image Restoration via Multiscale Wavelet Convolutions and Mamba-based Channel Modeling with Texture Enhancement](https://arxiv.org/abs/2510.16765)
*Shengyu Zhu,Fan,Fuxuan Zhang*

Main category: cs.CV

TL;DR: 提出WaMaIR框架，通过引入多尺度小波变换卷积和通道感知模块，显著提升图像恢复中的细节表现与计算效率。


<details>
  <summary>Details</summary>
Motivation: 当前的CNN基础方法在恢复细腻的纹理细节方面存在局限，难以有效地捕获图像特征，尤其是在大领域感知方面。

Method: 提出了一种新颖的框架WaMaIR，结合了Global Multiscale Wavelet Transform Convolutions和Mamba-Based Channel-Aware Module，使用Multiscale Texture Enhancement Loss进行指导。

Result: 通过实验验证，WaMaIR在图像恢复质量和计算效率上超过了现有的先进方法。

Conclusion: WaMaIR在图像恢复任务中有效提升了图像细节的恢复质量，并且在计算性能方面优于当前的先进方法。

Abstract: Image restoration is a fundamental and challenging task in computer vision,
where CNN-based frameworks demonstrate significant computational efficiency.
However, previous CNN-based methods often face challenges in adequately
restoring fine texture details, which are limited by the small receptive field
of CNN structures and the lack of channel feature modeling. In this paper, we
propose WaMaIR, which is a novel framework with a large receptive field for
image perception and improves the reconstruction of texture details in restored
images. Specifically, we introduce the Global Multiscale Wavelet Transform
Convolutions (GMWTConvs) for expandding the receptive field to extract image
features, preserving and enriching texture features in model inputs. Meanwhile,
we propose the Mamba-Based Channel-Aware Module (MCAM), explicitly designed to
capture long-range dependencies within feature channels, which enhancing the
model sensitivity to color, edges, and texture information. Additionally, we
propose Multiscale Texture Enhancement Loss (MTELoss) for image restoration to
guide the model in preserving detailed texture structures effectively.
Extensive experiments confirm that WaMaIR outperforms state-of-the-art methods,
achieving better image restoration and efficient computational performance of
the model.

</details>


### [59] [Region in Context: Text-condition Image editing with Human-like semantic reasoning](https://arxiv.org/abs/2510.16772)
*Thuy Phuong Vu,Dinh-Cuong Hoang,Minhhuy Le,Phan Xuan Tan*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的文本条件图像编辑框架，能够在视觉和语言之间实现多层次的语义对齐，从而提高图像编辑的连贯性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于文本的图像编辑方法往往孤立处理图像区域，未能综合考虑每个部分与整体的关系，导致修改不一致和缺乏连贯性。

Method: 提出的Region in Context框架利用双重指导机制，通过对区域进行全图上下文的表示和详细的区域级描述的对齐，实现精确的局部修改和全局结构匹配。

Result: 实验结果表明，所提出的方法能够产生更为连贯且符合指令的图像编辑结果。

Conclusion: 提出了一种新的框架，可以在多层次上实现视觉与语言的语义对齐，从而实现更一致和和谐的图像编辑。

Abstract: Recent research has made significant progress in localizing and editing image
regions based on text. However, most approaches treat these regions in
isolation, relying solely on local cues without accounting for how each part
contributes to the overall visual and semantic composition. This often results
in inconsistent edits, unnatural transitions, or loss of coherence across the
image. In this work, we propose Region in Context, a novel framework for
text-conditioned image editing that performs multilevel semantic alignment
between vision and language, inspired by the human ability to reason about
edits in relation to the whole scene. Our method encourages each region to
understand its role within the global image context, enabling precise and
harmonized changes. At its core, the framework introduces a dual-level guidance
mechanism: regions are represented with full-image context and aligned with
detailed region-level descriptions, while the entire image is simultaneously
matched to a comprehensive scene-level description generated by a large
vision-language model. These descriptions serve as explicit verbal references
of the intended content, guiding both local modifications and global structure.
Experiments show that it produces more coherent and instruction-aligned
results. Code is available at:
https://github.com/thuyvuphuong/Region-in-Context.git

</details>


### [60] [GS2POSE: Marry Gaussian Splatting to 6D Object Pose Estimation](https://arxiv.org/abs/2510.16777)
*Junbo Li,Weimin Yuan,Yinuo Wang,Yue Zeng,Shihao Shu,Cai Meng,Xiangzhi Bai*

Main category: cs.CV

TL;DR: GS2POSE 是一种新方法，针对 6D 目标姿态估计，提高了在复杂情况下的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决当前 6D 姿态估计在无纹理物体和变化光照条件下的困难。

Method: 提出了一个基于 Bundle Adjustment 原理的姿态回归算法，结合 Lie 代数和可渲染的姿态优化流程。

Result: 在 T-LESS、LineMod-Occlusion 和 LineMod 数据集上，GS2POSE 分别提高了 1.4%、2.8% 和 2.5% 的准确性。

Conclusion: GS2POSE 提出了一个新的方法，通过姿态回归和增量优化在 6D 目标姿态估计中取得了准确性提高。

Abstract: Accurate 6D pose estimation of 3D objects is a fundamental task in computer
vision, and current research typically predicts the 6D pose by establishing
correspondences between 2D image features and 3D model features. However, these
methods often face difficulties with textureless objects and varying
illumination conditions. To overcome these limitations, we propose GS2POSE, a
novel approach for 6D object pose estimation. GS2POSE formulates a pose
regression algorithm inspired by the principles of Bundle Adjustment (BA). By
leveraging Lie algebra, we extend the capabilities of 3DGS to develop a
pose-differentiable rendering pipeline, which iteratively optimizes the pose by
comparing the input image to the rendered image. Additionally, GS2POSE updates
color parameters within the 3DGS model, enhancing its adaptability to changes
in illumination. Compared to previous models, GS2POSE demonstrates accuracy
improvements of 1.4\%, 2.8\% and 2.5\% on the T-LESS, LineMod-Occlusion and
LineMod datasets, respectively.

</details>


### [61] [Xiaoice: Training-Free Video Understanding via Self-Supervised Spatio-Temporal Clustering of Semantic Features](https://arxiv.org/abs/2510.16781)
*Shihao Ji,Zihui Song*

Main category: cs.CV

TL;DR: 本论文提出一种训练-free的视频理解框架，通过结合视觉语言模型和经典聚类算法，实现了自动化、多模态视频内容分析。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在突破传统视频理解模型对大量标注数据的依赖，在零-shot环境下提高视频内容的理解能力与分析效率。

Method: 本论文通过将视频理解重新构建为自监督的时空聚类问题，利用预训练VLM的视觉编码器对视频流进行特征转换，并结合KTS分割与无监督聚类，自动生成视频内容的结构化摘要。

Result: 实验结果表明，所提出的方法能够有效识别视频中的显著场景和主题，并生成具有多模态的信息摘要，证明了其在零-shot分析中的有效性和可解释性。

Conclusion: 本研究提出了一种新颖的训练-free框架，通过结合预训练视觉语言模型的丰富语义信息与经典机器学习算法，实现了对视频内容的自监督分析和聚类。

Abstract: The remarkable zero-shot reasoning capabilities of large-scale Visual
Language Models (VLMs) on static images have yet to be fully translated to the
video domain. Conventional video understanding models often rely on extensive,
task-specific training on annotated datasets, a process that is both costly and
limited in scalability. This paper introduces a novel, training-free framework
for video understanding that circumvents end-to-end training by synergistically
combining the rich semantic priors of pre-trained VLMs with classic machine
learning algorithms for pattern discovery. Our core idea is to reframe video
understanding as a self-supervised spatio-temporal clustering problem within a
high-dimensional semantic feature space. The proposed pipeline first transforms
a video stream into a semantic feature trajectory using the frozen visual
encoder of a pre-trained VLM. Subsequently, we employ Kernel Temporal
Segmentation (KTS), a robust machine learning technique, to partition the
continuous feature stream into discrete, semantically coherent event segments.
These segments are then subjected to unsupervised density-based clustering to
identify recurring macroscopic scenes and themes throughout the video. By
selecting representative keyframes from each discovered cluster and leveraging
the VLM's generative capabilities for textual description, our framework
automatically produces a structured, multi-modal summary of the video content.
This approach provides an effective, interpretable, and model-agnostic pathway
for zero-shot, automated structural analysis of video content.

</details>


### [62] [Segmentation as A Plug-and-Play Capability for Frozen Multimodal LLMs](https://arxiv.org/abs/2510.16785)
*Jiazhen Liu,Long Chen*

Main category: cs.CV

TL;DR: 本研究提出了LENS，一个在冻结的多模态大型语言模型上实现有效分割的新方法，保持了模型的整体性能与通用性。


<details>
  <summary>Details</summary>
Motivation: 在多模态大型语言模型中，将多样化的视觉能力整合为统一模型是一个重要趋势，目前方法在进行细调时会影响模型的通用性，因此需要探索新的解决方案。

Method: LENS通过在完全冻结的MLLM上附加一个轻量可训练的头部，利用注意力图中的空间线索提取关键点并转换为与掩码解码器兼容的点特征。

Result: LENS实现了与重训练方法竞争或更优的分割性能，同时完好保留了MLLM的通用化能力，避免了细调方法导致的性能下降。

Conclusion: LENS为多模态大型语言模型（MLLMs）提供了一种高效强大的扩展范式，通过保持模型的通用性来解决分割任务中的挑战。

Abstract: Integrating diverse visual capabilities into a unified model is a significant
trend in Multimodal Large Language Models (MLLMs). Among these, the inclusion
of segmentation poses a distinct set of challenges. To equip MLLMs with
pixel-level segmentation abilities, prevailing methods require finetuning the
model to produce specific outputs compatible with a mask decoder. This process
typically alters the model's output space and compromises its intrinsic
generalization, which undermines the goal of building a unified model. We
introduce LENS (Leveraging kEypoiNts for MLLMs' Segmentation), a novel
plug-and-play solution. LENS attaches a lightweight, trainable head to a
completely frozen MLLM. By refining the spatial cues embedded in attention
maps, LENS extracts keypoints and describes them into point-wise features
directly compatible with the mask decoder. Extensive experiments validate our
approach: LENS achieves segmentation performance competitive with or superior
to that of retraining-based methods. Crucially, it does so while fully
preserving the MLLM's generalization capabilities, which are significantly
degraded by finetuning approaches. As such, the attachable design of LENS
establishes an efficient and powerful paradigm for extending MLLMs, paving the
way for truly multi-talented, unified models.

</details>


### [63] [Unsupervised Monocular Road Segmentation for Autonomous Driving via Scene Geometry](https://arxiv.org/abs/2510.16790)
*Sara Hatami Rostami,Behrooz Nasihatkon*

Main category: cs.CV

TL;DR: 本研究提出了一种完全无监督的道路分割方法，通过几何约束和时间一致性显著提高了分割精度。


<details>
  <summary>Details</summary>
Motivation: 消除对昂贵手动标注数据集的依赖，提出一种完全无监督的方法以实现道路分割。

Method: 通过场景几何和时间线索区分道路和非道路区域，生成弱标签并利用互信息最大化进行标签一致性优化。

Result: 模型在Cityscapes数据集上实现了0.82的IoU，展示了简单设计下的高准确性。

Conclusion: 该方法实现了高精度的无人监督二元道路分割，可以在自动驾驶中应用。

Abstract: This paper presents a fully unsupervised approach for binary road
segmentation (road vs. non-road), eliminating the reliance on costly manually
labeled datasets. The method leverages scene geometry and temporal cues to
distinguish road from non-road regions. Weak labels are first generated from
geometric priors, marking pixels above the horizon as non-road and a predefined
quadrilateral in front of the vehicle as road. In a refinement stage, temporal
consistency is enforced by tracking local feature points across frames and
penalizing inconsistent label assignments using mutual information
maximization. This enhances both precision and temporal stability. On the
Cityscapes dataset, the model achieves an Intersection-over-Union (IoU) of
0.82, demonstrating high accuracy with a simple design. These findings
demonstrate the potential of combining geometric constraints and temporal
consistency for scalable unsupervised road segmentation in autonomous driving.

</details>


### [64] [Personalized Image Filter: Mastering Your Photographic Style](https://arxiv.org/abs/2510.16791)
*Chengxuan Zhu,Shuchen Weng,Jiacong Fang,Peixuan Zhang,Si Li,Chao Xu,Boxin Shi*

Main category: cs.CV

TL;DR: 本文提出的个性化图像滤镜(PIF)通过生成先验和文本反转技术，有效提取和转移摄影风格，展示出卓越的性能。


<details>
  <summary>Details</summary>
Motivation: 学习和转移摄影风格需要深入理解照片如何从原始外观进行编辑。

Method: 基于预训练的文本到图像扩散模型，通过文本反转技术优化摄影概念的提示。

Result: PIF能够学习摄影概念的平均外观，并根据文本提示进行调整，解决了之前作品的不足。

Conclusion: PIF在提取和转移各种摄影风格方面表现出色。

Abstract: Photographic style, as a composition of certain photographic concepts, is the
charm behind renowned photographers. But learning and transferring photographic
style need a profound understanding of how the photo is edited from the unknown
original appearance. Previous works either fail to learn meaningful
photographic concepts from reference images, or cannot preserve the content of
the content image. To tackle these issues, we proposed a Personalized Image
Filter (PIF). Based on a pretrained text-to-image diffusion model, the
generative prior enables PIF to learn the average appearance of photographic
concepts, as well as how to adjust them according to text prompts. PIF then
learns the photographic style of reference images with the textual inversion
technique, by optimizing the prompts for the photographic concepts. PIF shows
outstanding performance in extracting and transferring various kinds of
photographic style. Project page: https://pif.pages.dev/

</details>


### [65] [An RGB-D Image Dataset for Lychee Detection and Maturity Classification for Robotic Harvesting](https://arxiv.org/abs/2510.16800)
*Zhenpeng Zhang,Yi Wang,Shanglei Chai,Yingying Liu,Zekai Xie,Wenhao Huang,Pengyu Li,Zipei Luo,Dajiang Lu,Yibin Tian*

Main category: cs.CV

TL;DR: 本研究建立了一个全面的荔枝图像数据集，用于提高视觉收割机器人效率。


<details>
  <summary>Details</summary>
Motivation: 缺乏一致且全面标注的公共荔枝数据集，限制了视觉基础的收割机器人的发展。

Method: 通过多种天气条件和不同时间获取色彩（RGB）图像，并对图像进行独立标注和验证，最终构建了荔枝成熟度与检测数据集。

Result: 数据集包含11,414张图像，涵盖3个成熟阶段，经详细统计分析并在深度学习模型中测试，结果有效。

Conclusion: 构建的荔枝数据集为成熟度分类和检测提供了可靠的数据来源，促进了基于视觉的收割机器人研究。

Abstract: Lychee is a high-value subtropical fruit. The adoption of vision-based
harvesting robots can significantly improve productivity while reduce reliance
on labor. High-quality data are essential for developing such harvesting
robots. However, there are currently no consistently and comprehensively
annotated open-source lychee datasets featuring fruits in natural growing
environments. To address this, we constructed a dataset to facilitate lychee
detection and maturity classification. Color (RGB) images were acquired under
diverse weather conditions, and at different times of the day, across multiple
lychee varieties, such as Nuomici, Feizixiao, Heiye, and Huaizhi. The dataset
encompasses three different ripeness stages and contains 11,414 images,
consisting of 878 raw RGB images, 8,780 augmented RGB images, and 1,756 depth
images. The images are annotated with 9,658 pairs of lables for lychee
detection and maturity classification. To improve annotation consistency, three
individuals independently labeled the data, and their results were then
aggregated and verified by a fourth reviewer. Detailed statistical analyses
were done to examine the dataset. Finally, we performed experiments using three
representative deep learning models to evaluate the dataset. It is publicly
available for academic

</details>


### [66] [ReefNet: A Large scale, Taxonomically Enriched Dataset and Benchmark for Hard Coral Classification](https://arxiv.org/abs/2510.16822)
*Yahia Battach,Abdulwahab Felemban,Faizan Farooq Khan,Yousef A. Radwan,Xiang Li,Fabio Marchese,Sara Beery,Burton H. Jones,Francesca Benzoni,Mohamed Elhoseiny*

Main category: cs.CV

TL;DR: 本研究推出了ReefNet数据集，旨在促进珊瑚礁监测与保护领域的研究，并解决领域泛化和细粒度分类的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于气候变化等人类活动的影响，珊瑚礁急剧下降，因此急需可扩展的自动化监测方法。

Method: 通过整合来自多个来源的图像和标签，构建了一个大规模的、专业验证的珊瑚图像数据集，并设计了两种评估设置（within-source和cross-source）。

Result: ReefNet拥有约925,000个经过专家验证的硬珊瑚标注，提供了丰富的细粒度标签，并且在分类性能上发现了监督学习和零-shot模型在领域泛化方面的挑战。

Conclusion: ReefNet提供了一个全球范围内的数据集，以促进珊瑚分类和监测的研究，尤其是在领域泛化和细粒度分类方面具有挑战性。

Abstract: Coral reefs are rapidly declining due to anthropogenic pressures such as
climate change, underscoring the urgent need for scalable, automated
monitoring. We introduce ReefNet, a large public coral reef image dataset with
point-label annotations mapped to the World Register of Marine Species (WoRMS).
ReefNet aggregates imagery from 76 curated CoralNet sources and an additional
site from Al Wajh in the Red Sea, totaling approximately 925000 genus-level
hard coral annotations with expert-verified labels. Unlike prior datasets,
which are often limited by size, geography, or coarse labels and are not
ML-ready, ReefNet offers fine-grained, taxonomically mapped labels at a global
scale to WoRMS. We propose two evaluation settings: (i) a within-source
benchmark that partitions each source's images for localized evaluation, and
(ii) a cross-source benchmark that withholds entire sources to test domain
generalization. We analyze both supervised and zero-shot classification
performance on ReefNet and find that while supervised within-source performance
is promising, supervised performance drops sharply across domains, and
performance is low across the board for zero-shot models, especially for rare
and visually similar genera. This provides a challenging benchmark intended to
catalyze advances in domain generalization and fine-grained coral
classification. We will release our dataset, benchmarking code, and pretrained
models to advance robust, domain-adaptive, global coral reef monitoring and
conservation.

</details>


### [67] [Robust Cross-Domain Adaptation in Texture Features Transferring for Wood Chip Moisture Content Prediction](https://arxiv.org/abs/2510.16832)
*Abdur Rahman,Mohammad Marufuzzaman,Jason Street,Haifeng Wang,Veera G. Gude,Randy Buchanan*

Main category: cs.CV

TL;DR: 本研究提出一种名为AdaptMoist的方法，通过综合多个纹理特征，实现了对木屑水分含量的高效预测，且显著提升了跨领域的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有方法在木屑水分预测中的准确性不足以及源材料变异性带来的挑战，开发一种稳健的预测方法。

Method: 综合分析五种木屑图像提取的纹理特征，以预测水分含量，并提出AdaptMoist领域适应方法以解决源材料的变异性问题。

Result: 结合所有五种纹理特征的综合特征集达到了95%的预测准确性，而AdaptMoist方法在不同领域的模型准确率达到了80%。

Conclusion: AdaptMoist方法显著提升了不同来源木屑水分含量预测的准确性，将适应性模型的准确率提高了23%。

Abstract: Accurate and quick prediction of wood chip moisture content is critical for
optimizing biofuel production and ensuring energy efficiency. The current
widely used direct method (oven drying) is limited by its longer processing
time and sample destructiveness. On the other hand, existing indirect methods,
including near-infrared spectroscopy-based, electrical capacitance-based, and
image-based approaches, are quick but not accurate when wood chips come from
various sources. Variability in the source material can alter data
distributions, undermining the performance of data-driven models. Therefore,
there is a need for a robust approach that effectively mitigates the impact of
source variability. Previous studies show that manually extracted texture
features have the potential to predict wood chip moisture class. Building on
this, in this study, we conduct a comprehensive analysis of five distinct
texture feature types extracted from wood chip images to predict moisture
content. Our findings reveal that a combined feature set incorporating all five
texture features achieves an accuracy of 95% and consistently outperforms
individual texture features in predicting moisture content. To ensure robust
moisture prediction, we propose a domain adaptation method named AdaptMoist
that utilizes the texture features to transfer knowledge from one source of
wood chip data to another, addressing variability across different domains. We
also proposed a criterion for model saving based on adjusted mutual
information. The AdaptMoist method improves prediction accuracy across domains
by 23%, achieving an average accuracy of 80%, compared to 57% for non-adapted
models. These results highlight the effectiveness of AdaptMoist as a robust
solution for wood chip moisture content estimation across domains, making it a
potential solution for wood chip-reliant industries.

</details>


### [68] [From Mannequin to Human: A Pose-Aware and Identity-Preserving Video Generation Framework for Lifelike Clothing Display](https://arxiv.org/abs/2510.16833)
*Xiangyu Mu,Dongliang Zhou,Jie Hou,Haijun Zhang,Weili Guan*

Main category: cs.CV

TL;DR: 本研究提出M2HVideo框架，成功实现从人形展示到逼真视频生成的转变，显著提升了视频的服装一致性和身份保持能力。


<details>
  <summary>Details</summary>
Motivation: 通过合成可控身份的逼真人类视频，以克服传统模特展示缺乏真实感和细节的问题。

Method: 提出一个姿态感知和身份保持的视频生成框架，解决头部与身体动作的不对齐和身份漂移问题。

Result: 通过在UBC时尚数据集、自建的ASOS数据集和MannequinVideos数据集上进行广泛实验，证明M2HVideo的优越性能。

Conclusion: M2HVideo在服装一致性、身份保留和视频保真度方面优于现有最先进的方法。

Abstract: Mannequin-based clothing displays offer a cost-effective alternative to
real-model showcases for online fashion presentation, but lack realism and
expressive detail. To overcome this limitation, we introduce a new task called
mannequin-to-human (M2H) video generation, which aims to synthesize
identity-controllable, photorealistic human videos from footage of mannequins.
We propose M2HVideo, a pose-aware and identity-preserving video generation
framework that addresses two key challenges: the misalignment between head and
body motion, and identity drift caused by temporal modeling. In particular,
M2HVideo incorporates a dynamic pose-aware head encoder that fuses facial
semantics with body pose to produce consistent identity embeddings across
frames. To address the loss of fine facial details due to latent space
compression, we introduce a mirror loss applied in pixel space through a
denoising diffusion implicit model (DDIM)-based one-step denoising.
Additionally, we design a distribution-aware adapter that aligns statistical
distributions of identity and clothing features to enhance temporal coherence.
Extensive experiments on the UBC fashion dataset, our self-constructed ASOS
dataset, and the newly collected MannequinVideos dataset captured on-site
demonstrate that M2HVideo achieves superior performance in terms of clothing
consistency, identity preservation, and video fidelity in comparison to
state-of-the-art methods.

</details>


### [69] [2DGS-R: Revisiting the Normal Consistency Regularization in 2D Gaussian Splatting](https://arxiv.org/abs/2510.16837)
*Haofan Ren,Qingsong Yan,Ming Lu,Rongfeng Lu,Zunjie Zhu*

Main category: cs.CV

TL;DR: 2DGS-R通过分层训练方法提升渲染质量和几何准确性，实现了高效与性能的平衡。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯溅射在表面表示准确性不足和2D高斯在渲染质量上的妥协问题。

Method: 提出了一种分层训练方法，首先训练原始的2D高斯；选择渲染质量不足的2D高斯并进行克隆操作；最后在不改变不透明度的情况下微调模型。

Result: 实验结果表明，与原始2DGS相比，2DGS-R方法只需增加1%的存储和最小的额外训练时间，但却能保持高质量的渲染效果和精细的几何结构。

Conclusion: 2DGS-R方法有效平衡了效率与性能，在视觉真实性和几何重建准确性上都有所改善。

Abstract: Recent advancements in 3D Gaussian Splatting (3DGS) have greatly influenced
neural fields, as it enables high-fidelity rendering with impressive visual
quality. However, 3DGS has difficulty accurately representing surfaces. In
contrast, 2DGS transforms the 3D volume into a collection of 2D planar Gaussian
disks. Despite advancements in geometric fidelity, rendering quality remains
compromised, highlighting the challenge of achieving both high-quality
rendering and precise geometric structures. This indicates that optimizing both
geometric and rendering quality in a single training stage is currently
unfeasible. To overcome this limitation, we present 2DGS-R, a new method that
uses a hierarchical training approach to improve rendering quality while
maintaining geometric accuracy. 2DGS-R first trains the original 2D Gaussians
with the normal consistency regularization. Then 2DGS-R selects the 2D
Gaussians with inadequate rendering quality and applies a novel in-place
cloning operation to enhance the 2D Gaussians. Finally, we fine-tune the 2DGS-R
model with opacity frozen. Experimental results show that compared to the
original 2DGS, our method requires only 1\% more storage and minimal additional
training time. Despite this negligible overhead, it achieves high-quality
rendering results while preserving fine geometric structures. These findings
indicate that our approach effectively balances efficiency with performance,
leading to improvements in both visual fidelity and geometric reconstruction
accuracy.

</details>


### [70] [ArmFormer: Lightweight Transformer Architecture for Real-Time Multi-Class Weapon Segmentation and Classification](https://arxiv.org/abs/2510.16854)
*Akhila Kambhatla,Taminul Islam,Khaled R Ahmed*

Main category: cs.CV

TL;DR: ArmFormer是一种新型轻量语义分割框架，结合了先进的注意力机制和变换器架构，针对武器检测进行优化，展现出高精度和低计算负担的优势。


<details>
  <summary>Details</summary>
Motivation: 当前武器检测技术面临高精度实时威胁评估的需求，而传统方法和已有的语义分割模型在精度和效率之间存有不足。

Method: 结合了卷积块注意力模块（CBAM）与MixVisionTransformer架构，以实现多类武器的精确分割。

Result: ArmFormer在五个类别的武器分割中达到80.64%的mIoU和89.13%的mFscore，并在82.26 FPS的实时推理中表现优秀，计算资源需求显著低于竞争对手。

Conclusion: ArmFormer是一种轻量级的变换器语义分割框架，适用于资源有限的边缘设备，具有出色的检测性能和效率。

Abstract: The escalating threat of weapon-related violence necessitates automated
detection systems capable of pixel-level precision for accurate threat
assessment in real-time security applications. Traditional weapon detection
approaches rely on object detection frameworks that provide only coarse
bounding box localizations, lacking the fine-grained segmentation required for
comprehensive threat analysis. Furthermore, existing semantic segmentation
models either sacrifice accuracy for computational efficiency or require
excessive computational resources incompatible with edge deployment scenarios.
This paper presents ArmFormer, a lightweight transformer-based semantic
segmentation framework that strategically integrates Convolutional Block
Attention Module (CBAM) with MixVisionTransformer architecture to achieve
superior accuracy while maintaining computational efficiency suitable for
resource-constrained edge devices. Our approach combines CBAM-enhanced encoder
backbone with attention-integrated hamburger decoder to enable multi-class
weapon segmentation across five categories: handgun, rifle, knife, revolver,
and human. Comprehensive experiments demonstrate that ArmFormer achieves
state-of-the-art performance with 80.64% mIoU and 89.13% mFscore while
maintaining real-time inference at 82.26 FPS. With only 4.886G FLOPs and 3.66M
parameters, ArmFormer outperforms heavyweight models requiring up to 48x more
computation, establishing it as the optimal solution for deployment on portable
security cameras, surveillance drones, and embedded AI accelerators in
distributed security infrastructure.

</details>


### [71] [Registration is a Powerful Rotation-Invariance Learner for 3D Anomaly Detection](https://arxiv.org/abs/2510.16865)
*Yuyang Yu,Zhengwei Chen,Xuemiao Xu,Lei Zhang,Haoxin Yang,Yongwei Nie,Shengfeng He*

Main category: cs.CV

TL;DR: 本研究提出了一种新的结构，通过优化点云注册与异常检测的整合，提高了特征提取的旋转不变性和局部区分能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于记忆的点云异常检测方法在特征转换和局部几何细节捕捉方面存在局限性，尤其在注册失败的情况下更为明显。

Method: 通过将特征提取嵌入注册学习过程，实现对齐和表示学习的联合优化。

Result: 在Anomaly-ShapeNet和Real3D-AD数据集上进行的广泛实验表明，我们的方法在有效性和泛化能力方面一致优于现有方法。

Conclusion: 我们提出的注册诱导旋转不变特征提取框架在异常检测任务上展示了优越的性能，具有较高的有效性和泛化能力。

Abstract: 3D anomaly detection in point-cloud data is critical for industrial quality
control, aiming to identify structural defects with high reliability. However,
current memory bank-based methods often suffer from inconsistent feature
transformations and limited discriminative capacity, particularly in capturing
local geometric details and achieving rotation invariance. These limitations
become more pronounced when registration fails, leading to unreliable detection
results. We argue that point-cloud registration plays an essential role not
only in aligning geometric structures but also in guiding feature extraction
toward rotation-invariant and locally discriminative representations. To this
end, we propose a registration-induced, rotation-invariant feature extraction
framework that integrates the objectives of point-cloud registration and
memory-based anomaly detection. Our key insight is that both tasks rely on
modeling local geometric structures and leveraging feature similarity across
samples. By embedding feature extraction into the registration learning
process, our framework jointly optimizes alignment and representation learning.
This integration enables the network to acquire features that are both robust
to rotations and highly effective for anomaly detection. Extensive experiments
on the Anomaly-ShapeNet and Real3D-AD datasets demonstrate that our method
consistently outperforms existing approaches in effectiveness and
generalizability.

</details>


### [72] [Class-N-Diff: Classification-Induced Diffusion Model Can Make Fair Skin Cancer Diagnosis](https://arxiv.org/abs/2510.16887)
*Nusrat Munia,Abdullah Imran*

Main category: cs.CV

TL;DR: 提出Class-N-Diff模型，结合分类器与扩散模型，改善医学图像生成与分类性能，旨在提升皮肤癌诊断应用的效果。


<details>
  <summary>Details</summary>
Motivation: 传统的类条件生成模型在生成特定医学类别图像时存在困难，限制了其在皮肤癌诊断等领域的应用。

Method: 提出一个新型分类诱导的扩散模型Class-N-Diff，同时进行图像生成和分类，利用分类器引导图像生成。

Result: Class-N-Diff模型在类条件图像合成方面表现更佳，生成的图像更加真实和多样，同时提升了分类器的性能，适合下游诊断任务。

Conclusion: Class-N-Diff模型通过将分类器整合到扩散模型中，实现了更好的类条件图像合成，提供了更真实和多样的医学影像，并提升了分类性能，适用于皮肤癌诊断等应用。

Abstract: Generative models, especially Diffusion Models, have demonstrated remarkable
capability in generating high-quality synthetic data, including medical images.
However, traditional class-conditioned generative models often struggle to
generate images that accurately represent specific medical categories, limiting
their usefulness for applications such as skin cancer diagnosis. To address
this problem, we propose a classification-induced diffusion model, namely,
Class-N-Diff, to simultaneously generate and classify dermoscopic images. Our
Class-N-Diff model integrates a classifier within a diffusion model to guide
image generation based on its class conditions. Thus, the model has better
control over class-conditioned image synthesis, resulting in more realistic and
diverse images. Additionally, the classifier demonstrates improved performance,
highlighting its effectiveness for downstream diagnostic tasks. This unique
integration in our Class-N-Diff makes it a robust tool for enhancing the
quality and utility of diffusion model-based synthetic dermoscopic image
generation. Our code is available at https://github.com/Munia03/Class-N-Diff.

</details>


### [73] [Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback](https://arxiv.org/abs/2510.16888)
*Zongjian Li,Zheyuan Liu,Qihui Zhang,Bin Lin,Shenghai Yuan,Zhiyuan Yan,Yang Ye,Wangbo Yu,Yuwei Niu,Li Yuan*

Main category: cs.CV

TL;DR: 研究本提出了一种名为Edit-R1的后训练框架，通过创新的政策优化方法和奖励模型来提升图像编辑效果，显著提高了多个基准测试中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有模型在监督微调后容易过拟合，限制了其探索和泛化能力亟需改进。

Method: 引入Diffusion Negative-aware Finetuning和多模态大语言模型作为统一的奖励模型，结合低方差分组过滤机制以稳定优化过程。

Result: UniWorld-V2在ImgEdit和GEdit-Bench基准上取得4.49和7.83的分数，显示出显著的性能提升。

Conclusion: Edit-R1 提供了一种新的后训练框架，通过政策优化方法有效提升了指令驱动的图像编辑能力，并在多项基准测试中获得了领先成绩。

Abstract: Instruction-based image editing has achieved remarkable progress; however,
models solely trained via supervised fine-tuning often overfit to annotated
patterns, hindering their ability to explore and generalize beyond training
distributions. To this end, we introduce Edit-R1, a novel post-training
framework for instruction-based image editing based on policy optimization.
Specifically, we utilize Diffusion Negative-aware Finetuning (DiffusionNFT), a
likelihood-free policy optimization method consistent with the flow matching
forward process, thereby enabling the use of higher-order samplers and more
efficient training. Another key challenge here is the absence of a universal
reward model, resulting from the diverse nature of editing instructions and
tasks. To bridge this gap, we employ a Multimodal Large Language Model (MLLM)
as a unified, training-free reward model, leveraging its output logits to
provide fine-grained feedback. Furthermore, we carefully design a low-variance
group filtering mechanism to reduce MLLM scoring noise and stabilize
optimization. UniWorld-V2, trained with this framework, achieves
\textbf{state-of-the-art} results on the ImgEdit and GEdit-Bench benchmarks,
scoring 4.49 and 7.83, respectively. Crucially, our framework is
model-agnostic, delivering substantial performance gains when applied to
diverse base models like Qwen-Image-Edit and FLUX-Kontext, demonstrating its
wide applicability. Code and models are publicly available at
https://github.com/PKU-YuanGroup/UniWorld-V2.

</details>


### [74] [Contrail-to-Flight Attribution Using Ground Visible Cameras and Flight Surveillance Data](https://arxiv.org/abs/2510.16891)
*Ramon Dalmau,Gabriel Jarry,Philippe Very*

Main category: cs.CV

TL;DR: 本文提出了一种新的基于地面摄像机的航迹云归属方法，建立了模块化框架，为未来研究提供基础。


<details>
  <summary>Details</summary>
Motivation: 航空业的非二氧化碳影响，特别是航迹云，对气候的影响显著，需要有效的归属分析方法以验证物理模型。

Method: 通过使用地面摄像头捕捉航迹云，并基于航空监视和气象数据，建立一个模块化框架，进行航迹云与航班的归属分析。

Result: 提出了一种利用地面可见摄像机捕捉航迹云的替代方法，具有高空间和时间分辨率，从而改善对航迹云的归属。

Conclusion: 本文建立了一个强有力的基线，并提供了一个模块化框架，以便将来的研究可以将航迹云与其源航班关联起来。

Abstract: Aviation's non-CO2 effects, particularly contrails, are a significant
contributor to its climate impact. Persistent contrails can evolve into
cirrus-like clouds that trap outgoing infrared radiation, with radiative
forcing potentially comparable to or exceeding that of aviation's CO2
emissions. While physical models simulate contrail formation, evolution and
dissipation, validating and calibrating these models requires linking observed
contrails to the flights that generated them, a process known as
contrail-to-flight attribution. Satellite-based attribution is challenging due
to limited spatial and temporal resolution, as contrails often drift and deform
before detection. In this paper, we evaluate an alternative approach using
ground-based cameras, which capture contrails shortly after formation at high
spatial and temporal resolution, when they remain thin, linear, and visually
distinct. Leveraging the ground visible camera contrail sequences (GVCCS)
dataset, we introduce a modular framework for attributing contrails observed
using ground-based cameras to theoretical contrails derived from aircraft
surveillance and meteorological data. The framework accommodates multiple
geometric representations and distance metrics, incorporates temporal
smoothing, and enables flexible probability-based assignment strategies. This
work establishes a strong baseline and provides a modular framework for future
research in linking contrails to their source flight.

</details>


### [75] [Beyond RGB: Leveraging Vision Transformers for Thermal Weapon Segmentation](https://arxiv.org/abs/2510.16913)
*Akhila Kambhatla,Ahmed R Khaled*

Main category: cs.CV

TL;DR: 本研究探讨了变压器架构在热武器分割中的应用，实验结果显示其在多种性能指标上超越传统CNN，适用于复杂的监控场景。


<details>
  <summary>Details</summary>
Motivation: 随着RGB系统在低光和视觉遮挡条件下失效，热武器分割在监控和安全应用中变得至关重要，导致对更强大的分割模型的需求。

Method: 采用并评估SegFormer、DeepLabV3+、SegNeXt和Swin Transformer四种基于变压器的架构，进行二元武器分割，使用自定义热图像数据集进行训练和测试。

Result: 实验结果表明，SegFormer-b5具有最高的mIoU（94.15%）和像素准确率（97.04%），SegFormer-b0则以98.32 FPS的速度提供竞争性的mIoU（90.84%），SegNeXt-mscans和DeepLabV3+的表现也很平衡，分别达到85.12 FPS，92.24% mIoU和29.86 FPS，92.76% mIoU。

Conclusion: 变压器架构在低光和遮挡的热环境中的武器检测表现出良好的泛化能力，适合于多种实时安全应用的精确-速度权衡。

Abstract: Thermal weapon segmentation is crucial for surveillance and security
applications, enabling robust detection under lowlight and visually obscured
conditions where RGB-based systems fail. While convolutional neural networks
(CNNs) dominate thermal segmentation literature, their ability to capture
long-range dependencies and fine structural details is limited. Vision
Transformers (ViTs), with their global context modeling capabilities, have
achieved state-of-the-art results in RGB segmentation tasks, yet their
potential in thermal weapon segmentation remains underexplored. This work
adapts and evaluates four transformer-based architectures SegFormer,
DeepLabV3\+, SegNeXt, and Swin Transformer for binary weapon segmentation on a
custom thermal dataset comprising 9,711 images collected from real world
surveillance videos and automatically annotated using SAM2. We employ standard
augmentation strategies within the MMSegmentation framework to ensure robust
model training and fair architectural comparison. Experimental results
demonstrate significant improvements in segmentation performance: SegFormer-b5
achieves the highest mIoU (94.15\%) and Pixel Accuracy (97.04\%), while
SegFormer-b0 provides the fastest inference speed (98.32 FPS) with competitive
mIoU (90.84\%). SegNeXt-mscans offers balanced performance with 85.12 FPS and
92.24\% mIoU, and DeepLabV3\+ R101-D8 reaches 92.76\% mIoU at 29.86 FPS. The
transformer architectures demonstrate robust generalization capabilities for
weapon detection in low-light and occluded thermal environments, with flexible
accuracy-speed trade-offs suitable for diverse real-time security applications.

</details>


### [76] [Res-Bench: Benchmarking the Robustness of Multimodal Large Language Models to Dynamic Resolution Input](https://arxiv.org/abs/2510.16926)
*Chenxu Li,Zhicai Wang,Yuan Sheng,Xingyu Zhu,Yanbin Hao,Xiang Wang*

Main category: cs.CV

TL;DR: 本文提出Res-Bench基准，评估多模态大型语言模型在不同分辨率下的性能稳定性，采用新的评估框架和多种鲁棒性指标。


<details>
  <summary>Details</summary>
Motivation: 当前的评估方法主要集中于语义性能，未能充分考虑不同输入分辨率下性能的稳定性。因此，有必要对模型进行更全面的评估。

Method: 采用了Spearman相关性和绝对/相对连续误差(ACE/RCE)等多种鲁棒性指标，通过对不同分辨率和任务关键能力进行评估。

Result: 通过对领先的多模态大型语言模型进行大规模评估，发现了模型和任务对鲁棒性的重要影响，并探讨了预处理和微调策略。

Conclusion: 引入了Res-Bench基准，并设计了一种新的评估框架，以实现对多模态大型语言模型在不同分辨率下性能稳定性的全面分析。

Abstract: Multimodal Large Language Models (MLLMs) increasingly support dynamic image
resolutions. However, current evaluation paradigms primarily assess semantic
performance, overlooking the critical question of resolution robustness -
whether performance remains stable across varying input resolutions. To address
this gap, we introduce \textbf{Res-Bench}, a comprehensive benchmark comprising
14,400 samples across 12 resolution levels and six core capability dimensions.
We designed a novel evaluation framework that goes beyond traditional accuracy
metrics to capture performance stability. This framework introduces multiple
robustness metrics: Spearman's correlation for assessing resolution-performance
trends, and Absolute/Relative Continuous Error (ACE/RCE) for measuring
performance volatility. Using these metrics, we conducted a large-scale
evaluation of leading MLLMs. Our analysis encompasses: (1) model-centric and
task-centric robustness examination, (2) investigation of preprocessing
strategies including padding and super-resolution, and (3) exploration of
fine-tuning for stability enhancement.

</details>


### [77] [Foundation Models in Medical Image Analysis: A Systematic Review and Meta-Analysis](https://arxiv.org/abs/2510.16973)
*Praveenbalaji Rajendran,Mojtaba Safari,Wenfeng He,Mingzhe Hu,Shansong Wang,Jun Zhou,Xiaofeng Yang*

Main category: cs.CV

TL;DR: 本篇综述提供了医学图像分析中基础模型的结构化分析，包括模型分类、研究趋势和未来方向，以促进其临床应用。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在医学成像领域得到了快速发展，但缺乏关于架构、训练模式和临床应用的统一综合，这促使我们进行该研究。

Method: 系统地将研究分类为视觉模型和视觉-语言模型，并进行归纳性元分析。

Result: 提供了医学图像分析中基础模型的全面分析，包括分类、元分析和对未来研究方向的探讨，以应对领域适应性、有效微调等挑战。

Conclusion: 这篇综述文章旨在通过分类研究、定量元分析和讨论挑战与解决方案，为医学图像分析中的基础模型提供结构化分析，从而促进其在临床实践中的应用。

Abstract: Recent advancements in artificial intelligence (AI), particularly foundation
models (FMs), have revolutionized medical image analysis, demonstrating strong
zero- and few-shot performance across diverse medical imaging tasks, from
segmentation to report generation. Unlike traditional task-specific AI models,
FMs leverage large corpora of labeled and unlabeled multimodal datasets to
learn generalized representations that can be adapted to various downstream
clinical applications with minimal fine-tuning. However, despite the rapid
proliferation of FM research in medical imaging, the field remains fragmented,
lacking a unified synthesis that systematically maps the evolution of
architectures, training paradigms, and clinical applications across modalities.
To address this gap, this review article provides a comprehensive and
structured analysis of FMs in medical image analysis. We systematically
categorize studies into vision-only and vision-language FMs based on their
architectural foundations, training strategies, and downstream clinical tasks.
Additionally, a quantitative meta-analysis of the studies was conducted to
characterize temporal trends in dataset utilization and application domains. We
also critically discuss persistent challenges, including domain adaptation,
efficient fine-tuning, computational constraints, and interpretability along
with emerging solutions such as federated learning, knowledge distillation, and
advanced prompting. Finally, we identify key future research directions aimed
at enhancing the robustness, explainability, and clinical integration of FMs,
thereby accelerating their translation into real-world medical practice.

</details>


### [78] [One-step Diffusion Models with Bregman Density Ratio Matching](https://arxiv.org/abs/2510.16983)
*Yuanzhi Zhu,Eleftherios Tsonis,Lucas Degeorge,Vicky Kalogeiton*

Main category: cs.CV

TL;DR: Di-Bregman是一个新框架，通过Bregman散度匹配来加快扩散模型的生成速度，实验表明其在效率和质量上均有提高。


<details>
  <summary>Details</summary>
Motivation: 解决扩散和流模型在多步骤采样中计算上昂贵的问题，并为现有蒸馏方法提供统一的理论基础。

Method: 提出Di-Bregman框架，通过Bregman散度基础的密度比匹配来进行扩散蒸馏。

Result: Di-Bregman在CIFAR-10和文本生成实验中显示出改进的一步FID，且在视觉保真度上优于教师模型。

Conclusion: Bregman密度比匹配是一种切实可行且理论基础扎实的方法，有助于实现高效的一步扩散生成。

Abstract: Diffusion and flow models achieve high generative quality but remain
computationally expensive due to slow multi-step sampling. Distillation methods
accelerate them by training fast student generators, yet most existing
objectives lack a unified theoretical foundation. In this work, we propose
Di-Bregman, a compact framework that formulates diffusion distillation as
Bregman divergence-based density-ratio matching. This convex-analytic view
connects several existing objectives through a common lens. Experiments on
CIFAR-10 and text-to-image generation demonstrate that Di-Bregman achieves
improved one-step FID over reverse-KL distillation and maintains high visual
fidelity compared to the teacher model. Our results highlight Bregman
density-ratio matching as a practical and theoretically-grounded route toward
efficient one-step diffusion generation.

</details>


### [79] [CARE: Contrastive Alignment for ADL Recognition from Event-Triggered Sensor Streams](https://arxiv.org/abs/2510.16988)
*Junhao Zhao,Zishuai Liu,Ruili Fang,Jin Lu,Linghan Zhang,Fei Dou*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的CARE框架，结合序列和图像表示，有效提升智能家居中的日常活动识别表现。


<details>
  <summary>Details</summary>
Motivation: 现有的日常活动识别方法在表示层面存在局限，难以有效利用序列和图像表示的互补优势。

Method: 提出了一种端到端的CARE框架，通过序列-图像对比对齐(SICA)优化表征学习，并使用交叉熵进行分类。

Result: CARE在三个CASAS数据集上取得了最先进的表现，展示了对传感器故障和布局变异性的鲁棒性。

Conclusion: CARE框架通过联合优化表征学习和分类，展示了在智能家居中可靠的日常活动识别能力。

Abstract: The recognition of Activities of Daily Living (ADLs) from event-triggered
ambient sensors is an essential task in Ambient Assisted Living, yet existing
methods remain constrained by representation-level limitations. Sequence-based
approaches preserve temporal order of sensor activations but are sensitive to
noise and lack spatial awareness, while image-based approaches capture global
patterns and implicit spatial correlations but compress fine-grained temporal
dynamics and distort sensor layouts. Naive fusion (e.g., feature concatenation)
fail to enforce alignment between sequence- and image-based representation
views, underutilizing their complementary strengths. We propose Contrastive
Alignment for ADL Recognition from Event-Triggered Sensor Streams (CARE), an
end-to-end framework that jointly optimizes representation learning via
Sequence-Image Contrastive Alignment (SICA) and classification via
cross-entropy, ensuring both cross-representation alignment and task-specific
discriminability. CARE integrates (i) time-aware, noise-resilient sequence
encoding with (ii) spatially-informed and frequency-sensitive image
representations, and employs (iii) a joint contrastive-classification objective
for end-to-end learning of aligned and discriminative embeddings. Evaluated on
three CASAS datasets, CARE achieves state-of-the-art performance (89.8% on
Milan, 88.9% on Cairo, and 73.3% on Kyoto7) and demonstrates robustness to
sensor malfunctions and layout variability, highlighting its potential for
reliable ADL recognition in smart homes.

</details>


### [80] [Training-free Online Video Step Grounding](https://arxiv.org/abs/2510.16989)
*Luca Zanella,Massimiliano Mancini,Yiming Wang,Alessio Tonioni,Elisa Ricci*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的在线视频步骤定位方法，利用大型多模态模型和贝叶斯过滤，展示了其优于传统方法的潜力。


<details>
  <summary>Details</summary>
Motivation: 探索如何在无需标记训练集的情况下实现在线视频步骤定位，解决传统方法在收集标签和实时决策上的局限。

Method: 使用大型多模态模型进行视频步骤定位，结合贝叶斯过滤原理和过往帧知识来预测步进。

Result: 在线策略在不进行任务特定调优的情况下，相较于离线和训练基础模型表现更好。

Conclusion: BaGLM在三个数据集上表现优于现有的基于训练的离线方法，证明了在线且无需训练的VSG新策略的有效性。

Abstract: Given a task and a set of steps composing it, Video Step Grounding (VSG) aims
to detect which steps are performed in a video. Standard approaches for this
task require a labeled training set (e.g., with step-level annotations or
narrations), which may be costly to collect. Moreover, they process the full
video offline, limiting their applications for scenarios requiring online
decisions. Thus, in this work, we explore how to perform VSG online and without
training. We achieve this by exploiting the zero-shot capabilities of recent
Large Multimodal Models (LMMs). In particular, we use LMMs to predict the step
associated with a restricted set of frames, without access to the whole video.
We show that this online strategy without task-specific tuning outperforms
offline and training-based models. Motivated by this finding, we develop
Bayesian Grounding with Large Multimodal Models (BaGLM), further injecting
knowledge of past frames into the LMM-based predictions. BaGLM exploits
Bayesian filtering principles, modeling step transitions via (i) a dependency
matrix extracted through large language models and (ii) an estimation of step
progress. Experiments on three datasets show superior performance of BaGLM over
state-of-the-art training-based offline methods.

</details>


### [81] [An empirical study of the effect of video encoders on Temporal Video Grounding](https://arxiv.org/abs/2510.17007)
*Ignacio M. De la Jara,Cristian Rodriguez-Opazo,Edison Marrese-Taylor,Felipe Bravo-Marquez*

Main category: cs.CV

TL;DR: 本研究探讨了不同视频编码器对时间视频定位任务性能的影响，发现特征互补性和架构选择的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于每天生成大量视频，时间视频定位是计算机视觉中的一项基本任务，但目前的研究集中在有限的视频表示上，可能导致架构的过拟合问题。

Method: 通过对三个知名基准数据集（Charades-STA、ActivityNet-Captions和YouCookII）提取视频特征，采用基于CNN、时间推理和变压器的视频编码器。

Result: 结果显示，通过更换视频编码器，模型的性能有显著差异，同时揭示了使用特定特征时的明确模式和错误。

Conclusion: 本研究表明，不同的视频编码器会显著影响模型的性能，且某些特征的使用会导致明显的模式和错误，表明特征之间可能存在互补性。

Abstract: Temporal video grounding is a fundamental task in computer vision, aiming to
localize a natural language query in a long, untrimmed video. It has a key role
in the scientific community, in part due to the large amount of video generated
every day. Although we find extensive work in this task, we note that research
remains focused on a small selection of video representations, which may lead
to architectural overfitting in the long run. To address this issue, we propose
an empirical study to investigate the impact of different video features on a
classical architecture. We extract features for three well-known benchmarks,
Charades-STA, ActivityNet-Captions and YouCookII, using video encoders based on
CNNs, temporal reasoning and transformers. Our results show significant
differences in the performance of our model by simply changing the video
encoder, while also revealing clear patterns and errors derived from the use of
certain features, ultimately indicating potential feature complementarity.

</details>


### [82] [Do Satellite Tasks Need Special Pretraining?](https://arxiv.org/abs/2510.17014)
*Ani Vanyan,Alvard Barseghyan,Hakob Tamazyan,Tigran Galstyan,Vahan Huroyan,Naira Hovakimyan,Hrant Khachatrian*

Main category: cs.CV

TL;DR: 本研究质疑专门遥感基础模型相较于通用视觉基础模型的有效性，提出了基准测试并进行了实验，结果显示未能带来显著改进。


<details>
  <summary>Details</summary>
Motivation: 由于遥感图像的独特特性及其具体应用，研究者希望检验专门模型的有效性。

Method: 通过设计基准测试，评估遥感模型在低分辨率图像上的泛化能力，进行两个下游任务的实验。

Result: 训练的iBOT模型在特定的遥感数据集上测试，但结果显示其性能未能超越通用基线模型。

Conclusion: 专门训练的基础模型未能在小规模遥感任务中显著优于通用视图库模型。

Abstract: Foundation models have advanced machine learning across various modalities,
including images. Recently multiple teams trained foundation models specialized
for remote sensing applications. This line of research is motivated by the
distinct characteristics of remote sensing imagery, specific applications and
types of robustness useful for satellite image analysis. In this work we
systematically challenge the idea that specific foundation models are more
useful than general-purpose vision foundation models, at least in the small
scale. First, we design a simple benchmark that measures generalization of
remote sensing models towards images with lower resolution for two downstream
tasks. Second, we train iBOT, a self-supervised vision encoder, on MillionAID,
an ImageNet-scale satellite imagery dataset, with several modifications
specific to remote sensing. We show that none of those pretrained models bring
consistent improvements upon general-purpose baselines at the ViT-B scale.

</details>


### [83] [Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding](https://arxiv.org/abs/2510.17034)
*Yutong Zhong*

Main category: cs.CV

TL;DR: 本论文提出了 W2R2 框架，通过解耦学习和抑制 2D 偏见，显著提升了多模态 3D 定位的性能。


<details>
  <summary>Details</summary>
Motivation: 目前的视觉语言模型在空间推理中表现不佳，因为它们过分依赖 2D 图像特征，忽视了 3D 几何输入。

Method: 提出了一种名为 What-Where Representation Re-Forming (W2R2) 的训练框架，通过解耦表征学习和有针对性的快捷抑制来解决 2D 语义偏见问题。

Result: 在 ScanRefer 和 ScanQA 数据集上的实验显示，W2R2 提高了定位准确性和鲁棒性，特别是在杂乱的户外场景中表现突出。

Conclusion: W2R2 框架有效改善了多模态 3D 定位的表现，特别是在复杂环境中的定位精度和鲁棒性显著提升。

Abstract: Multimodal 3D grounding has garnered considerable interest in Vision-Language
Models (VLMs) \cite{yin2025spatial} for advancing spatial reasoning in complex
environments. However, these models suffer from a severe "2D semantic bias"
that arises from over-reliance on 2D image features for coarse localization,
largely disregarding 3D geometric inputs and resulting in suboptimal fusion
performance. In this paper, we propose a novel training framework called
What-Where Representation Re-Forming (W2R2) to tackle this issue via
disentangled representation learning and targeted shortcut suppression. Our
approach fundamentally reshapes the model's internal space by designating 2D
features as semantic beacons for "What" identification and 3D features as
spatial anchors for "Where" localization, enabling precise 3D grounding without
modifying inference architecture. Key components include a dual-objective loss
function with an Alignment Loss that supervises fused predictions using adapted
cross-entropy for multimodal synergy, and a Pseudo-Label Loss that penalizes
overly effective 2D-dominant pseudo-outputs via a margin-based mechanism.
Experiments conducted on ScanRefer and ScanQA demonstrate the effectiveness of
W2R2, with significant gains in localization accuracy and robustness,
particularly in cluttered outdoor scenes.

</details>


### [84] [Conditional Synthetic Live and Spoof Fingerprint Generation](https://arxiv.org/abs/2510.17035)
*Syed Konain Abbas,Sandip Purnapatra,M. G. Sarwar Murshed,Conor Miller-Lynch,Lambert Igene,Soumyabrata Dey,Stephanie Schuckers,Faraz Hussain*

Main category: cs.CV

TL;DR: 本研究提出了一种生成功能强大、隐私保护良好的合成指纹图像的技术，创建了两个合成数据集，验证了其在指纹识别中的有效性。


<details>
  <summary>Details</summary>
Motivation: 收集真实指纹数据耗时且昂贵，同时必须遵循严格的隐私措施，因此探索合成指纹数据的使用。

Method: 使用条件StyleGAN2-ADA和StyleGAN3架构生成高分辨率合成活指纹，并通过CycleGAN转换生成逼真的欺骗指纹。

Result: 成功创建两个合成数据集(DB2和DB3)，每个数据集包含1500个指纹图像和相应的八种材料类型的欺骗图像，展示了良好的性能和隐私保护。

Conclusion: 提出了一种生成合成指纹图像的创新方法，有效解决了隐私、成本和可及性的问题，并且验证了生成数据的质量和隐私保护特性。

Abstract: Large fingerprint datasets, while important for training and evaluation, are
time-consuming and expensive to collect and require strict privacy measures.
Researchers are exploring the use of synthetic fingerprint data to address
these issues. This paper presents a novel approach for generating synthetic
fingerprint images (both spoof and live), addressing concerns related to
privacy, cost, and accessibility in biometric data collection. Our approach
utilizes conditional StyleGAN2-ADA and StyleGAN3 architectures to produce
high-resolution synthetic live fingerprints, conditioned on specific finger
identities (thumb through little finger). Additionally, we employ CycleGANs to
translate these into realistic spoof fingerprints, simulating a variety of
presentation attack materials (e.g., EcoFlex, Play-Doh). These synthetic spoof
fingerprints are crucial for developing robust spoof detection systems. Through
these generative models, we created two synthetic datasets (DB2 and DB3), each
containing 1,500 fingerprint images of all ten fingers with multiple
impressions per finger, and including corresponding spoofs in eight material
types. The results indicate robust performance: our StyleGAN3 model achieves a
Fr\'echet Inception Distance (FID) as low as 5, and the generated fingerprints
achieve a True Accept Rate of 99.47% at a 0.01% False Accept Rate. The
StyleGAN2-ADA model achieved a TAR of 98.67% at the same 0.01% FAR. We assess
fingerprint quality using standard metrics (NFIQ2, MINDTCT), and notably,
matching experiments confirm strong privacy preservation, with no significant
evidence of identity leakage, confirming the strong privacy-preserving
properties of our synthetic datasets.

</details>


### [85] [Click, Predict, Trust: Clinician-in-the-Loop AI Segmentation for Lung Cancer CT-Based Prognosis within the Knowledge-to-Action Framework](https://arxiv.org/abs/2510.17039)
*Mohammad R. Salmanpour,Sonya Falahati,Amir Hossein Pouria,Amin Mousavi,Somayeh Sadat Mehrnia,Morteza Alizadeh,Arman Gorji,Zeinab Farsangi,Alireza Safarian,Mehdi Maghsudi,Carlos Uribe,Arman Rahmim,Ren Yuan*

Main category: cs.CV

TL;DR: 本研究开发了一种临床医生参与的深度学习管道，结合VNet和半监督学习，实现了肺癌CT影像的高效、可靠的预后评估。


<details>
  <summary>Details</summary>
Motivation: 提高肺癌临床影像的分割重复性、预后准确性和临床信任，克服手工分割的时间消耗和深度学习在临床应用中的障碍。

Method: 利用多中心CT数据和五种深度学习模型，从999名患者的12个公共数据集中分析肺癌影像，进行分割重现性和预后建模评估。

Result: VNet在分割性能、放射组学稳定性和预测准确性方面表现最佳，医生对机器生成的初步掩膜表示偏好，认为其适合进行细化而非替换。

Conclusion: 本研究表明，将VNet与半监督学习（SSL）结合可实现准确、可重复和临床值得信赖的CT基础肺癌预后，强调了以医生为中心的人工智能转化的可行路径。

Abstract: Lung cancer remains the leading cause of cancer mortality, with CT imaging
central to screening, prognosis, and treatment. Manual segmentation is variable
and time-intensive, while deep learning (DL) offers automation but faces
barriers to clinical adoption. Guided by the Knowledge-to-Action framework,
this study develops a clinician-in-the-loop DL pipeline to enhance
reproducibility, prognostic accuracy, and clinical trust. Multi-center CT data
from 999 patients across 12 public datasets were analyzed using five DL models
(3D Attention U-Net, ResUNet, VNet, ReconNet, SAM-Med3D), benchmarked against
expert contours on whole and click-point cropped images. Segmentation
reproducibility was assessed using 497 PySERA-extracted radiomic features via
Spearman correlation, ICC, Wilcoxon tests, and MANOVA, while prognostic
modeling compared supervised (SL) and semi-supervised learning (SSL) across 38
dimensionality reduction strategies and 24 classifiers. Six physicians
qualitatively evaluated masks across seven domains, including clinical
meaningfulness, boundary quality, prognostic value, trust, and workflow
integration. VNet achieved the best performance (Dice = 0.83, IoU = 0.71),
radiomic stability (mean correlation = 0.76, ICC = 0.65), and predictive
accuracy under SSL (accuracy = 0.88, F1 = 0.83). SSL consistently outperformed
SL across models. Radiologists favored VNet for peritumoral representation and
smoother boundaries, preferring AI-generated initial masks for refinement
rather than replacement. These results demonstrate that integrating VNet with
SSL yields accurate, reproducible, and clinically trusted CT-based lung cancer
prognosis, highlighting a feasible path toward physician-centered AI
translation.

</details>


### [86] [Person Re-Identification via Generalized Class Prototypes](https://arxiv.org/abs/2510.17043)
*Md Ahmed Al Muzaddid,William J. Beksi*

Main category: cs.CV

TL;DR: 本研究提出了一种新的选择表示方法，超越了传统的类中心选取，改善了人的重新识别性能，并在多个嵌入上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管以往的研究重点在于通过目标函数的修改改进性能，但在重新识别中选择更好的类代表仍是一个未被充分探索的领域。

Method: 提出了一种通用选择方法，选择的表示不局限于类中心，通过调整每个类的表示数量以满足特定应用需求。

Result: 通过我们的研究，证明了以往技术在重新识别指标方面的亚优化结果，并在多个重新识别嵌入上取得了显著改善。

Conclusion: 我们的方法在精确度和平均精度之间取得了平衡，超越了现有的技术水平，并在多个重新识别嵌入上应用了这一方法，显著改善了结果。

Abstract: Advanced feature extraction methods have significantly contributed to
enhancing the task of person re-identification. In addition, modifications to
objective functions have been developed to further improve performance.
Nonetheless, selecting better class representatives is an underexplored area of
research that can also lead to advancements in re-identification performance.
Although past works have experimented with using the centroid of a gallery
image class during training, only a few have investigated alternative
representations during the retrieval stage. In this paper, we demonstrate that
these prior techniques yield suboptimal results in terms of re-identification
metrics. To address the re-identification problem, we propose a generalized
selection method that involves choosing representations that are not limited to
class centroids. Our approach strikes a balance between accuracy and mean
average precision, leading to improvements beyond the state of the art. For
example, the actual number of representations per class can be adjusted to meet
specific application requirements. We apply our methodology on top of multiple
re-identification embeddings, and in all cases it substantially improves upon
contemporary results

</details>


### [87] [Video Reasoning without Training](https://arxiv.org/abs/2510.17045)
*Deepak Sridhar,Kartikeya Bhardwaj,Jeya Pradha Jeyaraj,Nuno Vasconcelos,Ankita Nayak,Harris Teague*

Main category: cs.CV

TL;DR: 本论文提出V-Reason方法，通过优化LMM的推理过程，显著提升视频推理性能，降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 改善视频推理过程中使用大型多模态模型时的计算开销和推理过程中的认知控制。

Method: 通过使用基于熵的目标优化LMM的价值缓存，直接在推理阶段调优模型行为，而无需监督或强化学习。

Result: 在多个视频推理数据集上取得了显著的性能提升，且输出令牌减少了58.6%。

Conclusion: 提出的V-Reason方法在多个视频推理数据集上相较于基础模型取得了显著提升，并且提供了大幅度的效率优势。

Abstract: Video reasoning using Large Multimodal Models (LMMs) relies on costly
reinforcement learning (RL) and verbose chain-of-thought, resulting in
substantial computational overhead during both training and inference.
Moreover, the mechanisms that control the thinking process in these reasoning
models are very limited. In this paper, using entropy of the model's output as
a signal, we discover that the high-quality models go through a series of
micro-explorations and micro-exploitations which keep the reasoning process
grounded (i.e., avoid excessive randomness while the model is exploring or
thinking through an answer). We further observe that once this "thinking"
process is over, more accurate models demonstrate a better convergence by
reducing the entropy significantly via a final exploitation phase (i.e., a more
certain convergence towards a solution trajectory). We then use these novel,
theoretically-grounded insights to tune the model's behavior directly at
inference, without using any RL or supervised fine-tuning. Specifically, during
inference, our proposed approach called V-Reason (Video-Reason) adapts the
value cache of the LMM via a few optimization steps on a small, trainable
controller using an entropy-based objective, i.e., no supervision from any
dataset or RL is necessary. This tuning improves the model's micro-exploration
and exploitation behavior during inference. Our experiments show that our
proposed method achieves significant improvements over the base
instruction-tuned models across several video reasoning datasets, narrowing the
gap with RL-trained models to within 0.6% average accuracy without any
training, while offering massive efficiency benefits: output tokens are reduced
by 58.6% compared to the RL model.

</details>


### [88] [How Universal Are SAM2 Features?](https://arxiv.org/abs/2510.17051)
*Masoud Khairi Atani,Alon Harell,Hyomin Choi,Runyu Yang,Fabien Racape,Ivan V. Bajic*

Main category: cs.CV

TL;DR: 本研究探讨了通用与专业视觉模型之间的特征通用性权衡，发现专业化模型在特定任务上有效，但降低了在其他任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 探讨通用基础视觉模型与其专业模型之间的权衡，以设计更高效的特征编码策略。

Method: 通过比较Hiera编码器和SAM2在特征适应性方面的性能，使用训练良好的轻量级neck进行探测和量化。

Result: 结果显示，虽然SAM2在某些方面表现优越，但在泛化能力上，Hiera依然保持了更强的表现，且每个适应层次会进一步形成表征瓶颈。

Conclusion: 在特征通用性和专业化之间的权衡分析中，SAM2在空间相关任务上表现卓越，但在概念上遥远的任务中则不如Hiera，表明专业化带来了语义信息的损失。

Abstract: The trade-off between general-purpose foundation vision models and their
specialized counterparts is critical for efficient feature coding design and is
not yet fully understood. We investigate this trade-off by comparing the
feature versatility of the general-purpose Hiera encoder against the
segmentation-specialized Segment Anything Model 2 (SAM2). Using a lightweight,
trainable neck to probe the adaptability of their frozen features, we quantify
the information-theoretic cost of specialization. Our results reveal that while
SAM2's specialization is highly effective for spatially-related tasks like
depth estimation, it comes at a cost. The specialized SAM2 encoder
underperforms its generalist predecessor, Hiera, on conceptually distant tasks
such as pose estimation and image captioning, demonstrating a measurable loss
of broader semantic information. A novel cross-neck analysis on SAM2 reveals
that each level of adaptation creates a further representational bottleneck.
Our analysis illuminates these trade-offs in feature universality, providing a
quantitative foundation for designing efficient feature coding and adaptation
strategies for diverse downstream applications.

</details>


### [89] [ProDAT: Progressive Density-Aware Tail-Drop for Point Cloud Coding](https://arxiv.org/abs/2510.17068)
*Zhe Luo,Wenjing Jia,Stuart Perry*

Main category: cs.CV

TL;DR: ProDAT是一种新的渐进编码方法，利用密度信息提升3D点云编码效率。


<details>
  <summary>Details</summary>
Motivation: 面临3D点云数据庞大和带宽限制的挑战，尤其是在资源有限的环境中，需实现实时处理。

Method: 提出了一种新的密度感知尾丢机制，结合密度信息自适应解码潜在特征和坐标。

Result: 在benchmark数据集上，ProDAT的PSNR-D2性能相比于现有技术有显著提升，SemanticKITTI上提高超过28.6%，ShapeNet上提高超过18.15%。

Conclusion: ProDAT通过利用密度信息支持渐进解码，展现出优越的编码效率，优于现有技术。

Abstract: Three-dimensional (3D) point clouds are becoming increasingly vital in
applications such as autonomous driving, augmented reality, and immersive
communication, demanding real-time processing and low latency. However, their
large data volumes and bandwidth constraints hinder the deployment of
high-quality services in resource-limited environments. Progres- sive coding,
which allows for decoding at varying levels of detail, provides an alternative
by allowing initial partial decoding with subsequent refinement. Although
recent learning-based point cloud geometry coding methods have achieved notable
success, their fixed latent representation does not support progressive
decoding. To bridge this gap, we propose ProDAT, a novel density-aware
tail-drop mechanism for progressive point cloud coding. By leveraging density
information as a guidance signal, latent features and coordinates are decoded
adaptively based on their significance, therefore achieving progressive
decoding at multiple bitrates using one single model. Experimental results on
benchmark datasets show that the proposed ProDAT not only enables progressive
coding but also achieves superior coding efficiency compared to
state-of-the-art learning-based coding techniques, with over 28.6% BD-rate
improvement for PSNR- D2 on SemanticKITTI and over 18.15% for ShapeNet

</details>


### [90] [Towards a Generalizable Fusion Architecture for Multimodal Object Detection](https://arxiv.org/abs/2510.17078)
*Jad Berjawi,Yoann Dupas,Christophe C'erin*

Main category: cs.CV

TL;DR: FMCAF通过频域滤波与交叉注意力融合提高了多模态目标检测的鲁棒性，显著提升了多种数据集上的性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态目标检测中在不同传感器模态下的特征共享与融合问题，特别是在具有挑战性的条件下。

Method: 提出的FMCAF架构结合了频域滤波和基于交叉注意力的融合模块来提升RGB与红外输入的融合效果。

Result: 在LLVIP和VEDAI数据集上，FMCAF相比传统融合方法在性能上有显著提升，分别达到+1.1% mAP@50和+13.9% mAP@50。

Conclusion: FMCAF表现出色，成为未来多模态融合检测Pipeline的基础。

Abstract: Multimodal object detection improves robustness in chal- lenging conditions
by leveraging complementary cues from multiple sensor modalities. We introduce
Filtered Multi- Modal Cross Attention Fusion (FMCAF), a preprocess- ing
architecture designed to enhance the fusion of RGB and infrared (IR) inputs.
FMCAF combines a frequency- domain filtering block (Freq-Filter) to suppress
redun- dant spectral features with a cross-attention-based fusion module (MCAF)
to improve intermodal feature sharing. Unlike approaches tailored to specific
datasets, FMCAF aims for generalizability, improving performance across
different multimodal challenges without requiring dataset- specific tuning. On
LLVIP (low-light pedestrian detec- tion) and VEDAI (aerial vehicle detection),
FMCAF outper- forms traditional fusion (concatenation), achieving +13.9% mAP@50
on VEDAI and +1.1% on LLVIP. These results support the potential of FMCAF as a
flexible foundation for robust multimodal fusion in future detection pipelines.

</details>


### [91] [GSPlane: Concise and Accurate Planar Reconstruction via Structured Representation](https://arxiv.org/abs/2510.17095)
*Ruitong Gan,Junran Peng,Yang Liu,Chuanchen Luo,Qing Li,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: GSPlane通过引入平面先验，改善了3D场景中平面区域的几何重建精度，同时优化了网格结构。


<details>
  <summary>Details</summary>
Motivation: 在3D场景重建中，尤其是处理平面区域时，现有的高斯表示方法在光滑度和精度方面存在不足。

Method: 通过采用现成的分割和法线预测模型，GSPlane提取稳健的平面先验，以建立结构化的平面高斯坐标表示，并引入动态高斯重新分类器以提高训练的鲁棒性。

Result: GSPlane能够恢复准确的几何形状并生成干净且结构良好的网格连接，显著改善了拓扑结构，减少了顶点和面数。

Conclusion: GSPlane显著提高了提取网格的几何准确性，同时保持了渲染质量不变。

Abstract: Planes are fundamental primitives of 3D sences, especially in man-made
environments such as indoor spaces and urban streets. Representing these planes
in a structured and parameterized format facilitates scene editing and physical
simulations in downstream applications. Recently, Gaussian Splatting (GS) has
demonstrated remarkable effectiveness in the Novel View Synthesis task, with
extensions showing great potential in accurate surface reconstruction. However,
even state-of-the-art GS representations often struggle to reconstruct planar
regions with sufficient smoothness and precision. To address this issue, we
propose GSPlane, which recovers accurate geometry and produces clean and
well-structured mesh connectivity for plane regions in the reconstructed scene.
By leveraging off-the-shelf segmentation and normal prediction models, GSPlane
extracts robust planar priors to establish structured representations for
planar Gaussian coordinates, which help guide the training process by enforcing
geometric consistency. To further enhance training robustness, a Dynamic
Gaussian Re-classifier is introduced to adaptively reclassify planar Gaussians
with persistently high gradients as non-planar, ensuring more reliable
optimization. Furthermore, we utilize the optimized planar priors to refine the
mesh layouts, significantly improving topological structure while reducing the
number of vertices and faces. We also explore applications of the structured
planar representation, which enable decoupling and flexible manipulation of
objects on supportive planes. Extensive experiments demonstrate that, with no
sacrifice in rendering quality, the introduction of planar priors significantly
improves the geometric accuracy of the extracted meshes across various
baselines.

</details>


### [92] [Boosting Fidelity for Pre-Trained-Diffusion-Based Low-Light Image Enhancement via Condition Refinement](https://arxiv.org/abs/2510.17105)
*Xiaogang Xu,Jian Wang,Yunfan Lu,Ruihang Chu,Ruixing Wang,Jiafei Wu,Bei Yu,Liang Lin*

Main category: cs.CV

TL;DR: 提出一种优化策略以提高预训练扩散模型在低光照场景中的内容保真度，表现出显著改善效果。


<details>
  <summary>Details</summary>
Motivation: 尽管基于扩散的方法在多个低级视觉任务中表现出色，但在低光照情况下，内容保真度受到损失，限制了有效控制。

Method: 我们提出了一种新型的优化策略，在预训练扩散模型中实现条件建模，通过引入潜在细化流程来恢复在VAE编码过程中丢失的空间细节。同时，细化的潜在条件与噪声潜在之间动态交互，以改善恢复性能。

Result: 通过大量实验，我们的方法在预训练扩散方法中显示出显著的保真度提升。

Conclusion: 我们的方法通过引入新的优化策略和动态交互机制，显著提高了预训练扩散模型在低光照场景中的内容保真度，同时保持了感知真实感和美学效果。

Abstract: Diffusion-based methods, leveraging pre-trained large models like Stable
Diffusion via ControlNet, have achieved remarkable performance in several
low-level vision tasks. However, Pre-Trained Diffusion-Based (PTDB) methods
often sacrifice content fidelity to attain higher perceptual realism. This
issue is exacerbated in low-light scenarios, where severely degraded
information caused by the darkness limits effective control. We identify two
primary causes of fidelity loss: the absence of suitable conditional latent
modeling and the lack of bidirectional interaction between the conditional
latent and noisy latent in the diffusion process. To address this, we propose a
novel optimization strategy for conditioning in pre-trained diffusion models,
enhancing fidelity while preserving realism and aesthetics. Our method
introduces a mechanism to recover spatial details lost during VAE encoding,
i.e., a latent refinement pipeline incorporating generative priors.
Additionally, the refined latent condition interacts dynamically with the noisy
latent, leading to improved restoration performance. Our approach is
plug-and-play, seamlessly integrating into existing diffusion networks to
provide more effective control. Extensive experiments demonstrate significant
fidelity improvements in PTDB methods.

</details>


### [93] [Towards Imperceptible Watermarking Via Environment Illumination for Consumer Cameras](https://arxiv.org/abs/2510.17114)
*Hodaka Kawachi,Tomoya Nakamura,Hiroaki Santo,SaiKiran Kumar Tedla,Trevor Dalton Canham,Yasushi Yagi,Michael S. Brown*

Main category: cs.CV

TL;DR: 提出了一种利用LED环境光进行视觉上不可见水印嵌入的方法，能够在消费者相机上检测并传输数据，确保隐私和内容验证。


<details>
  <summary>Details</summary>
Motivation: 在保持隐私保护和内容验证的同时，寻求一种不影响视觉体验的方法进行数据嵌入。

Method: 该方法通过优化LED光源的光谱特性，实现对人眼最小可见性与消费者相机的高可检测性。

Result: 成功提取水印并在标准低帧率下实现数据传输，嵌入128位元数据。

Conclusion: 该方法有效利用LED环境光进行水印嵌入，同时确保水印对人眼不可见，适用于消费相机。

Abstract: This paper introduces a method for using LED-based environmental lighting to
produce visually imperceptible watermarks for consumer cameras. Our approach
optimizes an LED light source's spectral profile to be minimally visible to the
human eye while remaining highly detectable by typical consumer cameras. The
method jointly considers the human visual system's sensitivity to visible
spectra, modern consumer camera sensors' spectral sensitivity, and narrowband
LEDs' ability to generate broadband spectra perceived as "white light"
(specifically, D65 illumination). To ensure imperceptibility, we employ
spectral modulation rather than intensity modulation. Unlike conventional
visible light communication, our approach enables watermark extraction at
standard low frame rates (30-60 fps). While the information transfer rate is
modest-embedding 128 bits within a 10-second video clip-this capacity is
sufficient for essential metadata supporting privacy protection and content
verification.

</details>


### [94] [GOOD: Training-Free Guided Diffusion Sampling for Out-of-Distribution Detection](https://arxiv.org/abs/2510.17131)
*Xin Gao,Jiyao Liu,Guanghao Li,Yueming Lyu,Jianxiong Gao,Weichen Yu,Ningsheng Xu,Liang Wang,Caifeng Shan,Ziwei Liu,Chenyang Si*

Main category: cs.CV

TL;DR: 本文提出GOOD框架，利用双层次引导策略提升OOD样本生成与检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像扩散模型在OOD样本合成中表现欠佳，需解决语义不稳定与转移多样性不足的问题。

Method: 采用双层次引导策略来引导扩散采样轨迹，分别基于图像级和特征级的指导。

Result: 通过GOOD框架生成的样本能够显著提高OOD检测的效果。

Conclusion: GOOD能显著提升OOD检测性能，能够更好地生成多样的OOD样本。

Abstract: Recent advancements have explored text-to-image diffusion models for
synthesizing out-of-distribution (OOD) samples, substantially enhancing the
performance of OOD detection. However, existing approaches typically rely on
perturbing text-conditioned embeddings, resulting in semantic instability and
insufficient shift diversity, which limit generalization to realistic OOD. To
address these challenges, we propose GOOD, a novel and flexible framework that
directly guides diffusion sampling trajectories towards OOD regions using
off-the-shelf in-distribution (ID) classifiers. GOOD incorporates dual-level
guidance: (1) Image-level guidance based on the gradient of log partition to
reduce input likelihood, drives samples toward low-density regions in pixel
space. (2) Feature-level guidance, derived from k-NN distance in the
classifier's latent space, promotes sampling in feature-sparse regions. Hence,
this dual-guidance design enables more controllable and diverse OOD sample
generation. Additionally, we introduce a unified OOD score that adaptively
combines image and feature discrepancies, enhancing detection robustness. We
perform thorough quantitative and qualitative analyses to evaluate the
effectiveness of GOOD, demonstrating that training with samples generated by
GOOD can notably enhance OOD detection performance.

</details>


### [95] [KineDiff3D: Kinematic-Aware Diffusion for Category-Level Articulated Object Shape Reconstruction and Generation](https://arxiv.org/abs/2510.17137)
*WenBo Xu,Liu Liu,Li Zhang,Ran Zhang,Hao Wu,Dan Guo,Meng Wang*

Main category: cs.CV

TL;DR: KineDiff3D是一个用于分类级关节物体形状重建和生成的框架，通过注意到关节物体的运动特性，提高了3D重建的准确性。


<details>
  <summary>Details</summary>
Motivation: 针对关节物体在3D重建和姿态估计中面临的几何和结构多样性挑战, 提出了一种统一的解决方案.

Method: 采用Kinematic-Aware VAE进行结构化潜在空间编码，并通过两个条件扩散模型进行姿态和关节参数的回归与生成，最后结合双向优化模块实现重建精度的提升.

Result: 在合成、半合成和真实世界数据集上的实验结果证明了方法的有效性。

Conclusion: 提出的KineDiff3D框架在准确重建关节物体和估计其运动特性方面有效.

Abstract: Articulated objects, such as laptops and drawers, exhibit significant
challenges for 3D reconstruction and pose estimation due to their multi-part
geometries and variable joint configurations, which introduce structural
diversity across different states. To address these challenges, we propose
KineDiff3D: Kinematic-Aware Diffusion for Category-Level Articulated Object
Shape Reconstruction and Generation, a unified framework for reconstructing
diverse articulated instances and pose estimation from single view input.
Specifically, we first encode complete geometry (SDFs), joint angles, and part
segmentation into a structured latent space via a novel Kinematic-Aware VAE
(KA-VAE). In addition, we employ two conditional diffusion models: one for
regressing global pose (SE(3)) and joint parameters, and another for generating
the kinematic-aware latent code from partial observations. Finally, we produce
an iterative optimization module that bidirectionally refines reconstruction
accuracy and kinematic parameters via Chamfer-distance minimization while
preserving articulation constraints. Experimental results on synthetic,
semi-synthetic, and real-world datasets demonstrate the effectiveness of our
approach in accurately reconstructing articulated objects and estimating their
kinematic properties.

</details>


### [96] [GACO-CAD: Geometry-Augmented and Conciseness-Optimized CAD Model Generation from Single Image](https://arxiv.org/abs/2510.17157)
*Yinghui Wang,Xinyu Zhang,Peng Du*

Main category: cs.CV

TL;DR: GACO-CAD框架通过结合几何先验和强化学习，提升了从单幅图像生成CAD模型的几何准确性和建模效率，展示了优越的实验结果。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大型语言模型在从2D图像推断3D几何时存在空间推理能力不足的问题，因此需要改进以促进工业概念设计。

Method: GACO-CAD采用了两阶段的后训练框架，结合监督微调和强化学习，利用深度和表面法线图作为几何先验，提升CAD模型生成的几何准确性和建模简洁性。

Result: 在DeepCAD和Fusion360数据集上的实验表明，GACO-CAD在代码有效性、几何准确性和建模简洁性等方面均超越现有方法，取得了最新的性能。

Conclusion: GACO-CAD不仅在几何准确性上表现出色，还通过减少冗余模型序列提升了建模效率，展现出卓越的性能。

Abstract: Generating editable, parametric CAD models from a single image holds great
potential to lower the barriers of industrial concept design. However, current
multi-modal large language models (MLLMs) still struggle with accurately
inferring 3D geometry from 2D images due to limited spatial reasoning
capabilities. We address this limitation by introducing GACO-CAD, a novel
two-stage post-training framework. It is designed to achieve a joint objective:
simultaneously improving the geometric accuracy of the generated CAD models and
encouraging the use of more concise modeling procedures. First, during
supervised fine-tuning, we leverage depth and surface normal maps as dense
geometric priors, combining them with the RGB image to form a multi-channel
input. In the context of single-view reconstruction, these priors provide
complementary spatial cues that help the MLLM more reliably recover 3D geometry
from 2D observations. Second, during reinforcement learning, we introduce a
group length reward that, while preserving high geometric fidelity, promotes
the generation of more compact and less redundant parametric modeling
sequences. A simple dynamic weighting strategy is adopted to stabilize
training. Experiments on the DeepCAD and Fusion360 datasets show that GACO-CAD
achieves state-of-the-art performance under the same MLLM backbone,
consistently outperforming existing methods in terms of code validity,
geometric accuracy, and modeling conciseness.

</details>


### [97] [Investigating Adversarial Robustness against Preprocessing used in Blackbox Face Recognition](https://arxiv.org/abs/2510.17169)
*Roland Croft,Brian Du,Darcy Joseph,Sharath Kumar*

Main category: cs.CV

TL;DR: 本研究探讨了面部识别系统中的预处理对对抗攻击的影响，并提出了一种新方法提高攻击的可转移性。


<details>
  <summary>Details</summary>
Motivation: 探讨面部识别系统中面部预处理的重要性，特别是在黑箱设置中对抗攻击被忽视的现象，旨在提高对抗攻击的有效性。

Method: 研究了不同预处理技术下，几种最先进的对抗攻击在黑箱环境中的可转移性，并进行了性能比较。

Result: 攻击成功率受面部检测模型的选择影响可达78%，而降采样时插值方法的选择影响相对较小。即使在白箱设置中，面部预处理的需求也会削弱攻击力度。

Conclusion: 我们提出了一种不依赖预处理的方法，通过输入变换提高了攻击的可转移性，最大提升27%。

Abstract: Face Recognition (FR) models have been shown to be vulnerable to adversarial
examples that subtly alter benign facial images, exposing blind spots in these
systems, as well as protecting user privacy. End-to-end FR systems first obtain
preprocessed faces from diverse facial imagery prior to computing the
similarity of the deep feature embeddings. Whilst face preprocessing is a
critical component of FR systems, and hence adversarial attacks against them,
we observe that this preprocessing is often overlooked in blackbox settings.
Our study seeks to investigate the transferability of several out-of-the-box
state-of-the-art adversarial attacks against FR when applied against different
preprocessing techniques used in a blackbox setting. We observe that the choice
of face detection model can degrade the attack success rate by up to 78%,
whereas choice of interpolation method during downsampling has relatively
minimal impacts. Furthermore, we find that the requirement for facial
preprocessing even degrades attack strength in a whitebox setting, due to the
unintended interaction of produced noise vectors against face detection models.
Based on these findings, we propose a preprocessing-invariant method using
input transformations that improves the transferability of the studied attacks
by up to 27%. Our findings highlight the importance of preprocessing in FR
systems, and the need for its consideration towards improving the adversarial
generalisation of facial adversarial examples.

</details>


### [98] [Generation then Reconstruction: Accelerating Masked Autoregressive Models via Two-Stage Sampling](https://arxiv.org/abs/2510.17171)
*Feihong Yan,Peiru Wang,Yao Zhu,Kaiyu Pang,Qingyan Wei,Huiqi Li,Linfeng Zhang*

Main category: cs.CV

TL;DR: 提出一种基于生成与重建的分阶段策略GtR，显著提升MAR模型的生成速度，同时保持生成质量，适用于图像生成任务。


<details>
  <summary>Details</summary>
Motivation: 为了解决MAR模型在生成视觉数据时的建模复杂性和效率问题，提出了一种新的加速方法。

Method: 引入了一种两阶段的生成策略：结构生成和细节重建，并结合频率加权令牌选择(Frequency-Weighted Token Selection)以优化计算资源分配。

Result: 在ImageNet的条件生成实验中，MAR-H模型实现了3.72倍的速度提升，且生成质量保持在可比水平，超越了各种模型规模和生成任务中的现有加速方法。

Conclusion: 提出的GtR方法在提升生成速度的同时保持了生成质量，显著超越了现有的加速方法。

Abstract: Masked Autoregressive (MAR) models promise better efficiency in visual
generation than autoregressive (AR) models for the ability of parallel
generation, yet their acceleration potential remains constrained by the
modeling complexity of spatially correlated visual tokens in a single step. To
address this limitation, we introduce Generation then Reconstruction (GtR), a
training-free hierarchical sampling strategy that decomposes generation into
two stages: structure generation establishing global semantic scaffolding,
followed by detail reconstruction efficiently completing remaining tokens.
Assuming that it is more difficult to create an image from scratch than to
complement images based on a basic image framework, GtR is designed to achieve
acceleration by computing the reconstruction stage quickly while maintaining
the generation quality by computing the generation stage slowly. Moreover,
observing that tokens on the details of an image often carry more semantic
information than tokens in the salient regions, we further propose
Frequency-Weighted Token Selection (FTS) to offer more computation budget to
tokens on image details, which are localized based on the energy of high
frequency information. Extensive experiments on ImageNet class-conditional and
text-to-image generation demonstrate 3.72x speedup on MAR-H while maintaining
comparable quality (e.g., FID: 1.59, IS: 304.4 vs. original 1.59, 299.1),
substantially outperforming existing acceleration methods across various model
scales and generation tasks. Our codes will be released in
https://github.com/feihongyan1/GtR.

</details>


### [99] [Benchmarking Out-of-Distribution Detection for Plankton Recognition: A Systematic Evaluation of Advanced Methods in Marine Ecological Monitoring](https://arxiv.org/abs/2510.17179)
*Yingzi Han,Jiakai He,Chuanlong Xie,Jianping Li*

Main category: cs.CV

TL;DR: 本研究系统评估了浮游生物识别领域的OoD检测方法，ViM方法表现突出，为算法选择和未来研究提供了基础。


<details>
  <summary>Details</summary>
Motivation: 由于浮游生物的复杂形态、多样的物种和不断发现的新物种，自动化浮游生物识别模型在实际应用中面临重大挑战，尤其是在训练数据与测试数据之间的分布转变（OoD）问题上。

Method: 通过精心设计一系列基于DYB-PlanktonNet数据集的OoD基准，模拟不同的分布转变场景，系统评估了二十二种OoD检测方法。

Result: 实验结果表明，ViM方法在构建的基准上显著优于其他方法，尤其在Far-OoD场景中在关键指标上有显著提升。

Conclusion: 本研究首次对浮游生物识别中的Out-of-Distribution（OoD）数据检测方法进行了大规模的系统评估和分析，提供了可靠的算法选择参考，并为未来的研究奠定了基础。

Abstract: Automated plankton recognition models face significant challenges during
real-world deployment due to distribution shifts (Out-of-Distribution, OoD)
between training and test data. This stems from plankton's complex
morphologies, vast species diversity, and the continuous discovery of novel
species, which leads to unpredictable errors during inference. Despite rapid
advancements in OoD detection methods in recent years, the field of plankton
recognition still lacks a systematic integration of the latest computer vision
developments and a unified benchmark for large-scale evaluation. To address
this, this paper meticulously designed a series of OoD benchmarks simulating
various distribution shift scenarios based on the DYB-PlanktonNet dataset
\cite{875n-f104-21}, and systematically evaluated twenty-two OoD detection
methods. Extensive experimental results demonstrate that the ViM
\cite{wang2022vim} method significantly outperforms other approaches in our
constructed benchmarks, particularly excelling in Far-OoD scenarios with
substantial improvements in key metrics. This comprehensive evaluation not only
provides a reliable reference for algorithm selection in automated plankton
recognition but also lays a solid foundation for future research in plankton
OoD detection. To our knowledge, this study marks the first large-scale,
systematic evaluation and analysis of Out-of-Distribution data detection
methods in plankton recognition. Code is available at
https://github.com/BlackJack0083/PlanktonOoD.

</details>


### [100] [Capturing Head Avatar with Hand Contacts from a Monocular Video](https://arxiv.org/abs/2510.17181)
*Haonan He,Yufeng Zheng,Jie Song*

Main category: cs.CV

TL;DR: 本文提出了一种新框架，联合学习详细头部头像及手与面部互动引起的非刚性变形，解决了手脸相互作用建模中的两个主要挑战，且在重建几何上超过了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注面部区域，忽视手与面部之间的自然互动，这对传达认知状态至关重要。

Method: 结合深度顺序损失和接触正则化进行姿态跟踪，并从人脸-手互动数据集中学习手诱导变形的PCA基。

Result: 通过评估RGB(D)视频和构建合成数据集，验证了模型的有效性。

Conclusion: 该方法能够更好地捕捉面部的外观和更准确的变形几何，优于当前最佳表面重建方法。

Abstract: Photorealistic 3D head avatars are vital for telepresence, gaming, and VR.
However, most methods focus solely on facial regions, ignoring natural
hand-face interactions, such as a hand resting on the chin or fingers gently
touching the cheek, which convey cognitive states like pondering. In this work,
we present a novel framework that jointly learns detailed head avatars and the
non-rigid deformations induced by hand-face interactions.
  There are two principal challenges in this task. First, naively tracking hand
and face separately fails to capture their relative poses. To overcome this, we
propose to combine depth order loss with contact regularization during pose
tracking, ensuring correct spatial relationships between the face and hand.
Second, no publicly available priors exist for hand-induced deformations,
making them non-trivial to learn from monocular videos. To address this, we
learn a PCA basis specific to hand-induced facial deformations from a face-hand
interaction dataset. This reduces the problem to estimating a compact set of
PCA parameters rather than a full spatial deformation field. Furthermore,
inspired by physics-based simulation, we incorporate a contact loss that
provides additional supervision, significantly reducing interpenetration
artifacts and enhancing the physical plausibility of the results.
  We evaluate our approach on RGB(D) videos captured by an iPhone.
Additionally, to better evaluate the reconstructed geometry, we construct a
synthetic dataset of avatars with various types of hand interactions. We show
that our method can capture better appearance and more accurate deforming
geometry of the face than SOTA surface reconstruction methods.

</details>


### [101] [HIDISC: A Hyperbolic Framework for Domain Generalization with Generalized Category Discovery](https://arxiv.org/abs/2510.17188)
*Vaibhav Rathore,Divyam Gupta,Biplab Banerjee*

Main category: cs.CV

TL;DR: HIDISC是一种新提出的超曲率表示学习框架，通过提高源领域的多样性，避免过拟合并维持有效性，从而在开放世界分类中取得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有的GCD方法在训练期间同时访问有标签和无标签数据，限制了在开放世界场景中的适用性；DG-GCD方法要求模型可以普适到未见领域。

Method: 提出了一种超曲率表示学习框架，利用GPT引导的扩散增强源领域，并引入切线CutMix合成伪新样本，同时采用统一损失函数进行优化。

Result: HIDISC通过避免剧烈的模拟，能够实现类别和领域级的泛化，且在训练效率和有效性上表现优越。

Conclusion: HIDISC在多个数据集上取得了最先进的结果，超越了现有的欧几里得和双曲（DG）GCD基线，展示了其在开放世界场景中的有效性。

Abstract: Generalized Category Discovery (GCD) aims to classify test-time samples into
either seen categories** -- available during training -- or novel ones, without
relying on label supervision. Most existing GCD methods assume simultaneous
access to labeled and unlabeled data during training and arising from the same
domain, limiting applicability in open-world scenarios involving distribution
shifts. Domain Generalization with GCD (DG-GCD) lifts this constraint by
requiring models to generalize to unseen domains containing novel categories,
without accessing targetdomain data during training. The only prior DG-GCD
method, DG2CD-Net, relies on episodic training with multiple synthetic domains
and task vector aggregation, incurring high computational cost and error
accumulation. We propose HIDISC, a hyperbolic representation learning framework
that achieves domain and category-level generalization without episodic
simulation. To expose the model to minimal but diverse domain variations, we
augment the source domain using GPT-guided diffusion, avoiding overfitting
while maintaining efficiency. To structure the representation space, we
introduce Tangent CutMix, a curvature-aware interpolation that synthesizes
pseudo-novel samples in tangent space, preserving manifold consistency. A
unified loss -- combining penalized Busemann alignment, hybrid hyperbolic
contrastive regularization, and adaptive outlier repulsion -- **facilitates
compact, semantically structured embeddings. A learnable curvature parameter
further adapts the geometry to dataset complexity. HIDISC achieves
state-of-the-art results on PACS , Office-Home , and DomainNet, consistently
outperforming the existing Euclidean and hyperbolic (DG)-GCD baselines.

</details>


### [102] [ZSPAPrune: Zero-Shot Prompt-Aware Token Pruning for Vision-Language Models](https://arxiv.org/abs/2510.17197)
*Pu Zhang,Yuwei Li,Xingyuan Xian,Guoming Tang*

Main category: cs.CV

TL;DR: 本文提出了一种新的视觉令牌修剪方法，强调任务相关性与信息多样性的平衡，在性能与推理效率上超越现有技术。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型（VLMs）的能力不断提升，处理大量输入时产生的视觉令牌冗余导致了推理成本的增加，现有方法通常忽略了文本提示的指导。

Method: 提出了一种新颖的零-shot方法，通过层次化的方法选择任务相关的视觉令牌，并辅以多样性令牌以保持更广泛的上下文。

Result: 在多项模型和基准测试中的实验表明，我们的方法在修剪高达90%的令牌时，性能与现有最先进的方法相当或更优，同时大幅降低了GPU内存使用和推理延迟。

Conclusion: 通过引入基于提示的视角，我们的方法在保证任务相关性的同时，实现了信息多样性的平衡，从而有效减少了视觉令牌的冗余，并提高了模型的推理效率。

Abstract: As the capabilities of Vision-Language Models (VLMs) advance, they can
process increasingly large inputs, which, unlike in LLMs, generates significant
visual token redundancy and leads to prohibitive inference costs. While many
methods aim to reduce these costs by pruning visual tokens, existing
approaches, whether based on attention or diversity, typically neglect the
guidance of the text prompt and thus fail to prioritize task relevance. In this
work, we propose a novel, zero-shot method that reframes the problem by
introducing a prompt-aware perspective, explicitly modeling visual token
pruning as a balance between task relevance and information diversity. Our
hierarchical approach first selects a core set of task-relevant visual tokens
and then supplements them with diversity tokens to preserve broader context.
Experiments across multiple models and benchmarks show that our method achieves
performance that matches or surpasses the state-of-the-art with only minimal
accuracy loss, even when pruning up to 90\% of the tokens. Furthermore, these
gains are accompanied by significant reductions in GPU memory footprint and
inference latency.

</details>


### [103] [From Pixels to People: Satellite-Based Mapping and Quantification of Riverbank Erosion and Lost Villages in Bangladesh](https://arxiv.org/abs/2510.17198)
*M Saifuzzaman Rafat,Mohd Ruhul Ameen,Akif Islam,Abu Saleh Musa Miah,Jungpil Shin*

Main category: cs.CV

TL;DR: 本研究开发了一种创新的AI模型，通过分析历史图像数据，精准监测孟加拉国的河岸侵蚀，助力社区保护。


<details>
  <summary>Details</summary>
Motivation: 旨在解决人类分析师在追踪孟加拉国河流侵蚀导致的社区和农田消失的巨大挑战。

Method: 利用简单的颜色通道分析进行粗略土地和水体分割，随后对Segment Anything Model (SAM)的掩膜解码器进行微调，以识别河岸侵蚀的细微特征。

Result: 通过构建包含手工标注的消失聚落的数据集，采用先进的视觉模型，研究表明新模型在识别河岸侵蚀方面的精准度显著高于传统方法。

Conclusion: 该研究提供了一个强大的工具，帮助政策制定者和灾难管理机构监测河岸侵蚀，预测其发展趋势，并保护受影响的脆弱社区。

Abstract: The great rivers of Bangladesh, arteries of commerce and sustenance, are also
agents of relentless destruction. Each year, they swallow whole villages and
vast tracts of farmland, erasing communities from the map and displacing
thousands of families. To track this slow-motion catastrophe has, until now,
been a Herculean task for human analysts. Here we show how a powerful
general-purpose vision model, the Segment Anything Model (SAM), can be adapted
to this task with remarkable precision. To do this, we assembled a new dataset
- a digital chronicle of loss compiled from historical Google Earth imagery of
Bangladesh's most vulnerable regions, including Mokterer Char Union, Kedarpur
Union, Balchipara village, and Chowhali Upazila, from 2003 to 2025. Crucially,
this dataset is the first to include manually annotated data on the settlements
that have vanished beneath the water. Our method first uses a simple
color-channel analysis to provide a rough segmentation of land and water, and
then fine-tunes SAM's mask decoder to recognize the subtle signatures of
riverbank erosion. The resulting model demonstrates a keen eye for this
destructive process, achieving a mean Intersection over Union of 86.30% and a
Dice score of 92.60% - a performance that significantly surpasses traditional
methods and off-the-shelf deep learning models. This work delivers three key
contributions: the first annotated dataset of disappeared settlements in
Bangladesh due to river erosion; a specialized AI model fine-tuned for this
critical task; and a method for quantifying land loss with compelling visual
evidence. Together, these tools provide a powerful new lens through which
policymakers and disaster management agencies can monitor erosion, anticipate
its trajectory, and ultimately protect the vulnerable communities in its path.

</details>


### [104] [Round Outcome Prediction in VALORANT Using Tactical Features from Video Analysis](https://arxiv.org/abs/2510.17199)
*Nirai Hayakawa,Kazumasa Shimari,Kazuma Yamasaki,Hirotatsu Hoshikawa,Rikuto Tsuchida,Kenichi Matsumoto*

Main category: cs.CV

TL;DR: 本文提出了一种基于小地图信息和战术事件标签的VALORANT回合结果预测模型，显示出高达81%的预测准确率，旨在提高预测效果。


<details>
  <summary>Details</summary>
Motivation: 在电子竞技中，预测比赛结果的研究传统上依赖于比赛日志数据和统计信息，而本文希望探索更有效的预测方法，尤其是在复杂策略游戏VALORANT中。

Method: 通过分析比赛录像中的小地图信息，结合TimeSformer视频识别模型，构建了回合结果预测模型。

Result: 经过增强的数据集训练，模型在回合中后期阶段的预测准确度达到约81%，显著优于仅使用小地图信息的模型。

Conclusion: 利用比赛视频中的战术特征来预测VALORANT游戏中的回合结果是非常有效的。

Abstract: Recently, research on predicting match outcomes in esports has been actively
conducted, but much of it is based on match log data and statistical
information. This research targets the FPS game VALORANT, which requires
complex strategies, and aims to build a round outcome prediction model by
analyzing minimap information in match footage. Specifically, based on the
video recognition model TimeSformer, we attempt to improve prediction accuracy
by incorporating detailed tactical features extracted from minimap information,
such as character position information and other in-game events. This paper
reports preliminary results showing that a model trained on a dataset augmented
with such tactical event labels achieved approximately 81% prediction accuracy,
especially from the middle phases of a round onward, significantly
outperforming a model trained on a dataset with the minimap information itself.
This suggests that leveraging tactical features from match footage is highly
effective for predicting round outcomes in VALORANT.

</details>


### [105] [EndoCIL: A Class-Incremental Learning Framework for Endoscopic Image Classification](https://arxiv.org/abs/2510.17200)
*Bingrong Liu,Jun Shi,Yushan Zheng*

Main category: cs.CV

TL;DR: EndoCIL是为内窥镜图像分析设计的增量学习框架，能够有效应对类不平衡和遗忘问题，具备临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决现有回放基础CIL方法因内窥镜成像中的严重领域差异和类不平衡而导致的显著遗忘问题。

Method: 该研究提出了一个统一的CIL框架，包含三个关键组件：最大均值差异基础重放（MDBR）、先前正则化类平衡损失（PRCBL）和全连接梯度校准（CFG）。

Result: 实验显示，EndoCIL在四个公共内窥镜数据集上普遍优于现有的CIL方法，且在不同的缓冲区大小和评估指标下均表现出色。

Conclusion: EndoCIL提供了一种新的均衡稳定性和可塑性的增量学习框架，并在各种评估指标上优于现有的状态-of-the-art方法，具有良好的临床应用潜力。

Abstract: Class-incremental learning (CIL) for endoscopic image analysis is crucial for
real-world clinical applications, where diagnostic models should continuously
adapt to evolving clinical data while retaining performance on previously
learned ones. However, existing replay-based CIL methods fail to effectively
mitigate catastrophic forgetting due to severe domain discrepancies and class
imbalance inherent in endoscopic imaging. To tackle these challenges, we
propose EndoCIL, a novel and unified CIL framework specifically tailored for
endoscopic image diagnosis. EndoCIL incorporates three key components: Maximum
Mean Discrepancy Based Replay (MDBR), employing a distribution-aligned greedy
strategy to select diverse and representative exemplars, Prior Regularized
Class Balanced Loss (PRCBL), designed to alleviate both inter-phase and
intra-phase class imbalance by integrating prior class distributions and
balance weights into the loss function, and Calibration of Fully-Connected
Gradients (CFG), which adjusts the classifier gradients to mitigate bias toward
new classes. Extensive experiments conducted on four public endoscopic datasets
demonstrate that EndoCIL generally outperforms state-of-the-art CIL methods
across varying buffer sizes and evaluation metrics. The proposed framework
effectively balances stability and plasticity in lifelong endoscopic diagnosis,
showing promising potential for clinical scalability and deployment.

</details>


### [106] [Optimizing DINOv2 with Registers for Face Anti-Spoofing](https://arxiv.org/abs/2510.17201)
*Mika Feng,Pierre Gallin-Martel,Koichi Ito,Takafumi Aoki*

Main category: cs.CV

TL;DR: 本研究提出了一种基于DINOv2的面部伪造检测方法，能有效区分真实与伪造面部图像，增强面部识别系统的抗攻击能力。


<details>
  <summary>Details</summary>
Motivation: 讨论面部识别系统在面部照片伪造攻击下的脆弱性，并提出新的检测方法以提高系统的安全性。

Method: 采用DINOv2提取可泛化特征，并通过注意力机制抑制干扰，以增强对细微特征的关注。

Result: 通过对6th Face Anti-Spoofing Workshop和SiW数据集的实验，验证了该方法的有效性。

Conclusion: 提出的基于DINOv2的伪造检测方法有效区分了真实与伪造的面部图像，展示了在抗攻击能力上的优势。

Abstract: Face recognition systems are designed to be robust against variations in head
pose, illumination, and image blur during capture. However, malicious actors
can exploit these systems by presenting a face photo of a registered user,
potentially bypassing the authentication process. Such spoofing attacks must be
detected prior to face recognition. In this paper, we propose a DINOv2-based
spoofing attack detection method to discern minute differences between live and
spoofed face images. Specifically, we employ DINOv2 with registers to extract
generalizable features and to suppress perturbations in the attention
mechanism, which enables focused attention on essential and minute features. We
demonstrate the effectiveness of the proposed method through experiments
conducted on the dataset provided by ``The 6th Face Anti-Spoofing Workshop:
Unified Physical-Digital Attacks Detection@ICCV2025'' and SiW dataset.

</details>


### [107] [$\mathcal{V}isi\mathcal{P}runer$: Decoding Discontinuous Cross-Modal Dynamics for Efficient Multimodal LLMs](https://arxiv.org/abs/2510.17205)
*Yingqi Fan,Anhao Zhao,Jinlan Fu,Junlong Tong,Hui Su,Yijie Pan,Wei Zhang,Xiaoyu Shen*

Main category: cs.CV

TL;DR: 该研究提出了一种无训练的剪枝框架VisiPruner，通过分析MLLMs的处理过程，提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在处理多模态信息时存在理解不足，同时计算开销大。

Method: 通过系统分析发现MLLMs的三阶段跨模态交互过程，设计了VisiPruner框架。

Result: VisiPruner能够减少高达99%的视觉相关注意力计算，并在多个MLLM上取得了优越表现。

Conclusion: 提出了一种新的无训练剪枝框架VisiPruner，能够显著减少视觉相关的注意力计算，提升效率。

Abstract: Multimodal Large Language Models (MLLMs) have achieved strong performance
across vision-language tasks, but suffer from significant computational
overhead due to the quadratic growth of attention computations with the number
of multimodal tokens. Though efforts have been made to prune tokens in MLLMs,
\textit{they lack a fundamental understanding of how MLLMs process and fuse
multimodal information.} Through systematic analysis, we uncover a
\textbf{three-stage} cross-modal interaction process: (1) Shallow layers
recognize task intent, with visual tokens acting as passive attention sinks;
(2) Cross-modal fusion occurs abruptly in middle layers, driven by a few
critical visual tokens; (3) Deep layers discard vision tokens, focusing solely
on linguistic refinement. Based on these findings, we propose
\emph{VisiPruner}, a training-free pruning framework that reduces up to 99\% of
vision-related attention computations and 53.9\% of FLOPs on LLaVA-v1.5 7B. It
significantly outperforms existing token pruning methods and generalizes across
diverse MLLMs. Beyond pruning, our insights further provide actionable
guidelines for training efficient MLLMs by aligning model architecture with its
intrinsic layer-wise processing dynamics. Our code is available at:
https://github.com/EIT-NLP/VisiPruner.

</details>


### [108] [Fair and Interpretable Deepfake Detection in Videos](https://arxiv.org/abs/2510.17264)
*Akihito Yoshii,Ryosuke Sonoda,Ramya Srinivasan*

Main category: cs.CV

TL;DR: 本文提出一种新方法，通过时间特征学习和意识到人群差异的数据增强来解决深度伪造检测中的偏见问题，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度伪造检测方法存在偏见和缺乏透明性，未能捕捉时间信息，导致不同人群的决策不可靠。

Method: 基于序列聚类的时间建模和概念提取，结合人口统计意识的数据增强方法。

Result: 在多个主流数据集上进行的大规模实验表明，所提方法在公平性和准确性之间达到了最佳平衡。

Conclusion: 提出了一种新颖的公平感知深度伪造检测框架，能够有效提高检测的公平性和解释性。

Abstract: Existing deepfake detection methods often exhibit bias, lack transparency,
and fail to capture temporal information, leading to biased decisions and
unreliable results across different demographic groups. In this paper, we
propose a fairness-aware deepfake detection framework that integrates temporal
feature learning and demographic-aware data augmentation to enhance fairness
and interpretability. Our method leverages sequence-based clustering for
temporal modeling of deepfake videos and concept extraction to improve
detection reliability while also facilitating interpretable decisions for
non-expert users. Additionally, we introduce a demography-aware data
augmentation method that balances underrepresented groups and applies
frequency-domain transformations to preserve deepfake artifacts, thereby
mitigating bias and improving generalization. Extensive experiments on
FaceForensics++, DFD, Celeb-DF, and DFDC datasets using state-of-the-art (SoTA)
architectures (Xception, ResNet) demonstrate the efficacy of the proposed
method in obtaining the best tradeoff between fairness and accuracy when
compared to SoTA.

</details>


### [109] [FineVision: Open Data Is All You Need](https://arxiv.org/abs/2510.17269)
*Luis Wiedmann,Orr Zohar,Amir Mahla,Xiaohan Wang,Rui Li,Thibaud Frere,Leandro von Werra,Aritra Roy Gosthipaty,Andrés Marafioti*

Main category: cs.CV

TL;DR: FineVision是一个统一的大规模视觉语言模型数据集，通过人机协作确保数据质量，显著提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 解决公共数据集碎片化、不一致和污染的问题，以推动视觉语言模型的进步。

Method: 通过半自动化的人机协作管道，从超过200个来源收集并统一了185个子集，进行严格的去重和去污处理，并确保数据的格式、标注的准确性和多样性。

Result: 在广泛的评估套件中，使用FineVision训练的模型性能优于现有的开放混合模型。

Conclusion: FineVision数据集的构建显著提高了视觉语言模型的性能，证明了数据规模、清洁度和人机协作的重要性。

Abstract: The advancement of vision-language models (VLMs) is hampered by a fragmented
landscape of inconsistent and contaminated public datasets. We introduce
FineVision, a meticulously collected, curated, and unified corpus of 24 million
samples - the largest open resource of its kind. We unify more than 200 sources
into 185 subsets via a semi-automated, human-in-the-loop pipeline: automation
performs bulk ingestion and schema mapping, while reviewers audit mappings and
spot-check outputs to verify faithful consumption of annotations, appropriate
formatting and diversity, and safety; issues trigger targeted fixes and
re-runs. The workflow further applies rigorous de-duplication within and across
sources and decontamination against 66 public benchmarks. FineVision also
encompasses agentic/GUI tasks with a unified action space; reviewers validate
schemas and inspect a sample of trajectories to confirm executable fidelity.
Models trained on FineVision consistently outperform those trained on existing
open mixtures across a broad evaluation suite, underscoring the benefits of
scale, data hygiene, and balanced automation with human oversight. We release
the corpus and curation tools to accelerate data-centric VLM research.

</details>


### [110] [Enhanced Motion Forecasting with Plug-and-Play Multimodal Large Language Models](https://arxiv.org/abs/2510.17274)
*Katie Luo,Jingwei Ji,Tong He,Runsheng Xu,Yichen Xie,Dragomir Anguelov,Mingxing Tan*

Main category: cs.CV

TL;DR: PnF是一种增强现有运动预测模型的有效方法，通过利用多模态大语言模型改善预测性能，并通过示例实现快速适应。


<details>
  <summary>Details</summary>
Motivation: 现有的自主驾驶系统在多样化现实场景中泛化能力不足，急需一种有效的方法提升运动预测的体验。

Method: 通过将多模态大语言模型与现有运动预测模型结合，使用结构化提示提取场景理解，并将其转化为可学习的嵌入。

Result: 在Waymo Open Motion Dataset和nuScenes Dataset上验证，PnF方法在运动预测上显著提升表现且无需微调。

Conclusion: 提出的PnF方法能够有效提升运动预测性能，在两种数据集上表现出一致性改进。

Abstract: Current autonomous driving systems rely on specialized models for perceiving
and predicting motion, which demonstrate reliable performance in standard
conditions. However, generalizing cost-effectively to diverse real-world
scenarios remains a significant challenge. To address this, we propose
Plug-and-Forecast (PnF), a plug-and-play approach that augments existing motion
forecasting models with multimodal large language models (MLLMs). PnF builds on
the insight that natural language provides a more effective way to describe and
handle complex scenarios, enabling quick adaptation to targeted behaviors. We
design prompts to extract structured scene understanding from MLLMs and distill
this information into learnable embeddings to augment existing behavior
prediction models. Our method leverages the zero-shot reasoning capabilities of
MLLMs to achieve significant improvements in motion prediction performance,
while requiring no fine-tuning -- making it practical to adopt. We validate our
approach on two state-of-the-art motion forecasting models using the Waymo Open
Motion Dataset and the nuScenes Dataset, demonstrating consistent performance
improvements across both benchmarks.

</details>


### [111] [Exploring Structural Degradation in Dense Representations for Self-supervised Learning](https://arxiv.org/abs/2510.17299)
*Siran Dai,Qianqian Xu,Peisong Wen,Yang Liu,Qingming Huang*

Main category: cs.CV

TL;DR: 本研究发现自监督学习训练时间过长可能损害密集任务表现，提出密集表示结构估计器（DSE）以改善模型选择与正则化，实验结果证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 发现自监督学习中的训练时间过长可能导致密集预测任务表现下降，称为自监督密集降级（SDD）。

Method: 引入了密集表示结构估计器（DSE），基于类相关性和有效维度测量来评估密集性能。

Result: 在四个基准上对十六种自监督学习方法进行实验，结果表明模型选择平均提高了mIoU 3.0%，且DSE正则化有效减轻了降级影响。

Conclusion: 提出的模型选择策略和DSE正则化方法有效改善了模型在密集预测任务上的表现，缓解了自监督学习中的Dense Degradation现象。

Abstract: In this work, we observe a counterintuitive phenomenon in self-supervised
learning (SSL): longer training may impair the performance of dense prediction
tasks (e.g., semantic segmentation). We refer to this phenomenon as
Self-supervised Dense Degradation (SDD) and demonstrate its consistent presence
across sixteen state-of-the-art SSL methods with various losses, architectures,
and datasets. When the model performs suboptimally on dense tasks at the end of
training, measuring the performance during training becomes essential. However,
evaluating dense performance effectively without annotations remains an open
challenge. To tackle this issue, we introduce a Dense representation Structure
Estimator (DSE), composed of a class-relevance measure and an effective
dimensionality measure. The proposed DSE is both theoretically grounded and
empirically validated to be closely correlated with the downstream performance.
Based on this metric, we introduce a straightforward yet effective model
selection strategy and a DSE-based regularization method. Experiments on
sixteen SSL methods across four benchmarks confirm that model selection
improves mIoU by $3.0\%$ on average with negligible computational cost.
Additionally, DSE regularization consistently mitigates the effects of dense
degradation. Code is available at
https://github.com/EldercatSAM/SSL-Degradation.

</details>


### [112] [A Single Set of Adversarial Clothes Breaks Multiple Defense Methods in the Physical World](https://arxiv.org/abs/2510.17322)
*Wei Zhang,Zhanhao Hu,Xiao Li,Xiaopei Zhu,Xiaolin Hu*

Main category: cs.CV

TL;DR: 本文评估了多种对抗防御方法在面对对抗衣物时的效果，结果显示防御效果不佳，揭示了防御方法的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 针对深度学习物体检测器的对抗攻击日益严重，特别是使用可物理实现的对抗补丁，因此希望探索新的防御方法。

Method: 评估对抗衣物对多种对抗防御方法的影响，并进行实验验证。

Result: 经过实验，所有防御方法在数字和物理世界中对抗对抗衣物的性能都较差，验证了防御模型的通用脆弱性。

Conclusion: 现有的对抗防御方法在面对对抗衣物时表现不佳，揭示了其普遍脆弱性。

Abstract: In recent years, adversarial attacks against deep learning-based object
detectors in the physical world have attracted much attention. To defend
against these attacks, researchers have proposed various defense methods
against adversarial patches, a typical form of physically-realizable attack.
However, our experiments showed that simply enlarging the patch size could make
these defense methods fail. Motivated by this, we evaluated various defense
methods against adversarial clothes which have large coverage over the human
body. Adversarial clothes provide a good test case for adversarial defense
against patch-based attacks because they not only have large sizes but also
look more natural than a large patch on humans. Experiments show that all the
defense methods had poor performance against adversarial clothes in both the
digital world and the physical world. In addition, we crafted a single set of
clothes that broke multiple defense methods on Faster R-CNN. The set achieved
an Attack Success Rate (ASR) of 96.06% against the undefended detector and over
64.84% ASRs against nine defended models in the physical world, unveiling the
common vulnerability of existing adversarial defense methods against
adversarial clothes. Code is available at:
https://github.com/weiz0823/adv-clothes-break-multiple-defenses.

</details>


### [113] [CharDiff: A Diffusion Model with Character-Level Guidance for License Plate Image Restoration](https://arxiv.org/abs/2510.17330)
*Gyuhwan Park,Kihyun Na,Injung Kim*

Main category: cs.CV

TL;DR: 本研究提出的CharDiff框架在恢复和识别劣质车牌图像方面性能显著优越，具备较强的实用价值。


<details>
  <summary>Details</summary>
Motivation: 改善车牌识别系统中的图像恢复质量，提高证据价值和视觉接口的清晰度。

Method: 提出了一个基于扩散的框架CharDiff，并引入了字符引导注意力模块CHARM，以提供精确的区域指导。

Result: CharDiff在恢复质量及识别准确率上均显著优于基线模型，相对于最佳基线模型在Roboflow-LP数据集中减少了28%的字符错误率（CER）。

Conclusion: CharDiff有效提升了车牌图像的恢复和识别能力，特别是在低质量环境中表现出色。

Abstract: The significance of license plate image restoration goes beyond the
preprocessing stage of License Plate Recognition (LPR) systems, as it also
serves various purposes, including increasing evidential value, enhancing the
clarity of visual interface, and facilitating further utilization of license
plate images. We propose a novel diffusion-based framework with character-level
guidance, CharDiff, which effectively restores and recognizes severely degraded
license plate images captured under realistic conditions. CharDiff leverages
fine-grained character-level priors extracted through external segmentation and
Optical Character Recognition (OCR) modules tailored for low-quality license
plate images. For precise and focused guidance, CharDiff incorporates a novel
Character-guided Attention through Region-wise Masking (CHARM) module, which
ensures that each character's guidance is restricted to its own region, thereby
avoiding interference with other regions. In experiments, CharDiff
significantly outperformed the baseline restoration models in both restoration
quality and recognition accuracy, achieving a 28% relative reduction in CER on
the Roboflow-LP dataset, compared to the best-performing baseline model. These
results indicate that the structured character-guided conditioning effectively
enhances the robustness of diffusion-based license plate restoration and
recognition in practical deployment scenarios.

</details>


### [114] [iDETEX: Empowering MLLMs for Intelligent DETailed EXplainable IQA](https://arxiv.org/abs/2510.17332)
*Zhaoran Zhao,Xinli Yue,Jianhui Sun,Yuhao Xie,Tao Shao,Liangchao Yao,Fan Xia,Yuetang Deng*

Main category: cs.CV

TL;DR: 本研究提出了iDETEX，一个统一的多模态大型语言模型，旨在提高图像质量评估的可解释性和准确性，取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 在图像质量评估领域，面临着详细和可解释评估的挑战，因此开发一个全面的模型以改善这一评估过程是研究的主要动机。

Method: 提出了一种统一的多模态大型语言模型（MLLM），同时执行质量基础、感知和描述三项关键任务，并设计了任务特定的离线增强模块和数据混合策略，以优化训练效果。

Result: iDETEX在ViDA-UGC基准上实现了所有子任务的最优性能，并在ICCV MIPI 2025详细图像质量评估挑战赛中排名第一。

Conclusion: iDETEX在详细图像质量评估中展示出卓越的有效性和稳健性，达到了最先进的性能。

Abstract: Image Quality Assessment (IQA) has progressed from scalar quality prediction
to more interpretable, human-aligned evaluation paradigms. In this work, we
address the emerging challenge of detailed and explainable IQA by proposing
iDETEX-a unified multimodal large language model (MLLM) capable of
simultaneously performing three key tasks: quality grounding, perception, and
description. To facilitate efficient and generalizable training across these
heterogeneous subtasks, we design a suite of task-specific offline augmentation
modules and a data mixing strategy. These are further complemented by online
enhancement strategies to fully exploit multi-sourced supervision. We validate
our approach on the large-scale ViDA-UGC benchmark, where iDETEX achieves
state-of-the-art performance across all subtasks. Our model ranks first in the
ICCV MIPI 2025 Detailed Image Quality Assessment Challenge, demonstrating its
effectiveness and robustness in delivering accurate and interpretable quality
assessments.

</details>


### [115] [Nearest-Class Mean and Logits Agreement for Wildlife Open-Set Recognition](https://arxiv.org/abs/2510.17338)
*Jiahao Huo,Mufhumudzi Muthivhi,Terence L. van Zyl,Fredrik Gustafsson*

Main category: cs.CV

TL;DR: 本文提出了一种后处理的开放集识别方法，通过比较输入与最近类均值（NCM）的距离与softmax概率，成功提升了在野生动物分类任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的野生动物分类模型在处理未知类时存在过度自信的问题，因此需要一种能够在识别已知类的同时排除未知样本的方法。

Method: 采用基于输入距离最近类均值（NCM）的方法进行后处理的开放集识别（OSR），通过测量特征与预测逻辑的一致性来评估结果。

Result: 在两个数据集上，提出的NCM分布与softmax概率进行比较，达到了93.41和95.35的AUROC，表现优异。

Conclusion: 提出的方法在两个评估的数据集上表现一致，处于前列，且不需要对预训练分类模型进行重训。

Abstract: Current state-of-the-art Wildlife classification models are trained under the
closed world setting. When exposed to unknown classes, they remain
overconfident in their predictions. Open-set Recognition (OSR) aims to classify
known classes while rejecting unknown samples. Several OSR methods have been
proposed to model the closed-set distribution by observing the feature, logit,
or softmax probability space. A significant drawback of many existing
approaches is the requirement to retrain the pre-trained classification model
with the OSR-specific strategy. This study contributes a post-processing OSR
method that measures the agreement between the models' features and predicted
logits. We propose a probability distribution based on an input's distance to
its Nearest Class Mean (NCM). The NCM-based distribution is then compared with
the softmax probabilities from the logit space to measure agreement between the
NCM and the classification head. Our proposed strategy ranks within the top
three on two evaluated datasets, showing consistent performance across the two
datasets. In contrast, current state-of-the-art methods excel on a single
dataset. We achieve an AUROC of 93.41 and 95.35 for African and Swedish
animals. The code can be found
https://github.com/Applied-Representation-Learning-Lab/OSR.

</details>


### [116] [Exploring The Missing Semantics In Event Modality](https://arxiv.org/abs/2510.17347)
*Jingqian Wu,Shengpeng Xu,Yunbo Jia,Edmund Y. Lam*

Main category: cs.CV

TL;DR: 本文提出了一种新的E2V框架Semantic-E2VID，旨在提升事件到视频重建的语义信息，从而提高重建质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有事件到视频重建方法忽视语义信息的问题，以提高重建质量。

Method: 提出Semantic-E2VID框架，通过跨模态特征对齐(CFA)模块和语义感知特征融合(SFF)模块来增强事件到视频的重建。

Result: 实验表明Semantic-E2VID在多个基准测试中，显著提高了帧的质量。

Conclusion: Semantic-E2VID显著提高了帧质量，超越了现有最先进的E2V方法。

Abstract: Event cameras offer distinct advantages such as low latency, high dynamic
range, and efficient motion capture. However, event-to-video reconstruction
(E2V), a fundamental event-based vision task, remains challenging, particularly
for reconstructing and recovering semantic information. This is primarily due
to the nature of the event camera, as it only captures intensity changes,
ignoring static objects and backgrounds, resulting in a lack of semantic
information in captured event modality. Further, semantic information plays a
crucial role in video and frame reconstruction, yet is often overlooked by
existing E2V approaches. To bridge this gap, we propose Semantic-E2VID, an E2V
framework that explores the missing visual semantic knowledge in event modality
and leverages it to enhance event-to-video reconstruction. Specifically,
Semantic-E2VID introduces a cross-modal feature alignment (CFA) module to
transfer the robust visual semantics from a frame-based vision foundation
model, the Segment Anything Model (SAM), to the event encoder, while aligning
the high-level features from distinct modalities. To better utilize the learned
semantic feature, we further propose a semantic-aware feature fusion (SFF)
block to integrate learned semantics in frame modality to form event
representations with rich semantics that can be decoded by the event decoder.
Further, to facilitate the reconstruction of semantic information, we propose a
novel Semantic Perceptual E2V Supervision that helps the model to reconstruct
semantic details by leveraging SAM-generated categorical labels. Extensive
experiments demonstrate that Semantic-E2VID significantly enhances frame
quality, outperforming state-of-the-art E2V methods across multiple benchmarks.
The sample code is included in the supplementary material.

</details>


### [117] [M2H: Multi-Task Learning with Efficient Window-Based Cross-Task Attention for Monocular Spatial Perception](https://arxiv.org/abs/2510.17363)
*U. V. B. L Udugama,George Vosselman,Francesco Nex*

Main category: cs.CV

TL;DR: 本文介绍了一种新的多任务学习框架M2H，优化了实时空间感知任务的性能，表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 实现边缘设备上的实时空间感知，需要高效的多任务模型，以利用互补任务信息并最小化计算开销。

Method: 提出了一种基于窗口的交叉任务注意力模块，支持结构化特征交换，保持任务特定细节，构建在轻量级的ViT基础上。

Result: M2H在NYUDv2上表现优于现有多任务模型，在Hypersim上超越单任务基线，在Cityscapes数据集上也表现出色，同时保持在笔记本硬件上的计算效率。

Conclusion: M2H在多个任务上展现出优越的性能，同时保持计算效率，适合实时部署，证明了其在空间感知任务中的实用性。

Abstract: Deploying real-time spatial perception on edge devices requires efficient
multi-task models that leverage complementary task information while minimizing
computational overhead. This paper introduces Multi-Mono-Hydra (M2H), a novel
multi-task learning framework designed for semantic segmentation and depth,
edge, and surface normal estimation from a single monocular image. Unlike
conventional approaches that rely on independent single-task models or shared
encoder-decoder architectures, M2H introduces a Window-Based Cross-Task
Attention Module that enables structured feature exchange while preserving
task-specific details, improving prediction consistency across tasks. Built on
a lightweight ViT-based DINOv2 backbone, M2H is optimized for real-time
deployment and serves as the foundation for monocular spatial perception
systems supporting 3D scene graph construction in dynamic environments.
Comprehensive evaluations show that M2H outperforms state-of-the-art multi-task
models on NYUDv2, surpasses single-task depth and semantic baselines on
Hypersim, and achieves superior performance on the Cityscapes dataset, all
while maintaining computational efficiency on laptop hardware. Beyond
benchmarks, M2H is validated on real-world data, demonstrating its practicality
in spatial perception tasks.

</details>


### [118] [Recurrent Attention-based Token Selection for Efficient Streaming Video-LLMs](https://arxiv.org/abs/2510.17364)
*Vaggelis Dorovatas,Soroush Seifi,Gunshi Gupta,Rahaf Aljundi*

Main category: cs.CV

TL;DR: 本研究提出了一种高效的免训练方法，针对视频大语言模型在流媒体处理中的挑战，实现了高效能和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决视频大语言模型在流媒体场景中处理长时间视频时的挑战，确保及时响应查询。

Method: 提出了一种免训练的方法，利用LLM-informed选择视觉标记、对过去选择的标记进行递归处理，并基于字幕进行问答。

Result: 通过选择重要的视觉标记和递归处理，能够以轻量且准确的方式回答问题。

Conclusion: 该方法在流媒体视频基准上达到了最先进的性能，实现了效率与效果的平衡。

Abstract: Video Large Language Models (Video-LLMs) excel at understanding videos
in-context, provided they have full access to the video when answering queries.
However, these models face challenges in streaming scenarios where hour-long
videos must be processed online, and questions need timely responses. In this
work, we propose a training-free approach compatible with standard Video-LLMs,
leveraging three key concepts: 1) LLM-informed selection of visual tokens to
identify those that the LLM has attended to and contributed to its
understanding of each short clip. Our attention-based selection allows us to
discard up to ~95% of unimportant visual tokens with minimal performance loss;
2) Recurrent processing of past selected tokens to generate temporally coherent
understanding of each processed clip; 3) Caption-based question answering for
lightweight and accurate responses. Our method achieves state-of-the-art
performance on streaming video benchmarks, striking a balance between
efficiency and effectiveness.

</details>


### [119] [Beyond Real Faces: Synthetic Datasets Can Achieve Reliable Recognition Performance without Privacy Compromise](https://arxiv.org/abs/2510.17372)
*Paweł Borsukiewicz,Fadi Boutros,Iyiola E. Olatunji,Charles Beumier,Wendkûuni C. Ouedraogo,Jacques Klein,Tegawendé F. Bissyandé*

Main category: cs.CV

TL;DR: 本研究通过对合成面部识别数据集的广泛评估，验证了其在面部识别中的有效性，确立了合成数据作为一种伦理合规替代方案的必要性。


<details>
  <summary>Details</summary>
Motivation: 解决由于需要收集未经同意的大规模真实人脸数据集而产生的伦理困境。

Method: 通过系统的文献综述和严格的实验验证，评估25个合成面部识别数据集的七个关键要求。

Result: 合成数据集在识别准确性上超过传统真实数据集，且在偏见缓解方面具有更好的控制能力。

Conclusion: 合成面部数据作为面部识别研究的可行且合乎道德的替代方案得到确认。

Abstract: The deployment of facial recognition systems has created an ethical dilemma:
achieving high accuracy requires massive datasets of real faces collected
without consent, leading to dataset retractions and potential legal liabilities
under regulations like GDPR. While synthetic facial data presents a promising
privacy-preserving alternative, the field lacks comprehensive empirical
evidence of its viability. This study addresses this critical gap through
extensive evaluation of synthetic facial recognition datasets. We present a
systematic literature review identifying 25 synthetic facial recognition
datasets (2018-2025), combined with rigorous experimental validation. Our
methodology examines seven key requirements for privacy-preserving synthetic
data: identity leakage prevention, intra-class variability, identity
separability, dataset scale, ethical data sourcing, bias mitigation, and
benchmark reliability. Through experiments involving over 10 million synthetic
samples, extended by a comparison of results reported on five standard
benchmarks, we provide the first comprehensive empirical assessment of
synthetic data's capability to replace real datasets. Best-performing synthetic
datasets (VariFace, VIGFace) achieve recognition accuracies of 95.67% and
94.91% respectively, surpassing established real datasets including
CASIA-WebFace (94.70%). While those images remain private, publicly available
alternatives Vec2Face (93.52%) and CemiFace (93.22%) come close behind. Our
findings reveal that they ensure proper intra-class variability while
maintaining identity separability. Demographic bias analysis shows that, even
though synthetic data inherits limited biases, it offers unprecedented control
for bias mitigation through generation parameters. These results establish
synthetic facial data as a scientifically viable and ethically imperative
alternative for facial recognition research.

</details>


### [120] [Facial Expression-based Parkinson's Disease Severity Diagnosis via Feature Fusion and Adaptive Class Balancing](https://arxiv.org/abs/2510.17373)
*Yintao Zhou,Wei Huang,Zhengyu Li,Jing Huang,Meng Pang*

Main category: cs.CV

TL;DR: 本文提出了一种新的帕金森病严重性诊断方法，通过基于注意力的特征融合和自适应类别平衡策略，提高了诊断的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 由于现有方法常常依赖单一类型的面部表情，且未考虑不同PD阶段之间的类别不平衡，导致预测性能下降。因此，需要一种新的方法来提高PD严重性诊断的准确性。

Method: 通过基于注意力的特征融合整合多种面部表情特征，运用自适应类别平衡策略来解决类别不平衡问题。

Result: 实验结果证明了所提方法在帕金森病严重性诊断中的出色表现，以及基于注意力的特征融合和自适应类别平衡的有效性。

Conclusion: 所提出的方法在帕金森病严重性诊断中表现出色，验证了基于注意力的特征融合和自适应类别平衡的有效性。

Abstract: Parkinson's disease (PD) severity diagnosis is crucial for early detecting
potential patients and adopting tailored interventions. Diagnosing PD based on
facial expression is grounded in PD patients' "masked face" symptom and gains
growing interest recently for its convenience and affordability. However,
current facial expression-based approaches often rely on single type of
expression which can lead to misdiagnosis, and ignore the class imbalance
across different PD stages which degrades the prediction performance. Moreover,
most existing methods focus on binary classification (i.e., PD / non-PD) rather
than diagnosing the severity of PD. To address these issues, we propose a new
facial expression-based method for PD severity diagnosis which integrates
multiple facial expression features through attention-based feature fusion.
Moreover, we mitigate the class imbalance problem via an adaptive class
balancing strategy which dynamically adjusts the contribution of training
samples based on their class distribution and classification difficulty.
Experimental results demonstrate the promising performance of the proposed
method for PD severity diagnosis, as well as the efficacy of attention-based
feature fusion and adaptive class balancing.

</details>


### [121] [Glyph: Scaling Context Windows via Visual-Text Compression](https://arxiv.org/abs/2510.17800)
*Jiale Cheng,Yusen Liu,Xinyu Zhang,Yulin Fei,Wenyi Hong,Ruiliang Lyu,Weihan Wang,Zhe Su,Xiaotao Gu,Xiao Liu,Yushi Bai,Jie Tang,Hongning Wang,Minlie Huang*

Main category: cs.CV

TL;DR: Glyph框架以图像处理方式实现长文本的高效压缩，提升了速度和准确性，适用于长文本任务。


<details>
  <summary>Details</summary>
Motivation: 当前大规模语言模型在处理长上下文时面临计算和内存成本的挑战，激发了我们采用视觉上下文缩放的新方法。

Method: 提出Glyph框架，将长文本转换为图像，并使用视觉语言模型（VLMs）进行处理，同时设计LMM驱动的遗传搜索，以优化视觉渲染配置。

Result: Glyph方法实现了3-4倍的令牌压缩，同时在各种基准测试中保持了与领先LLM相当的准确性，并在预填充和解码速度上提升了约4倍。

Conclusion: Glyph框架通过将长文本渲染为图像，显著压缩了文本输入，并在多个长上下文基准测试中保持了与顶尖LLM相当的准确性。

Abstract: Large language models (LLMs) increasingly rely on long-context modeling for
tasks such as document understanding, code analysis, and multi-step reasoning.
However, scaling context windows to the million-token level brings prohibitive
computational and memory costs, limiting the practicality of long-context LLMs.
In this work, we take a different perspective-visual context scaling-to tackle
this challenge. Instead of extending token-based sequences, we propose Glyph, a
framework that renders long texts into images and processes them with
vision-language models (VLMs). This approach substantially compresses textual
input while preserving semantic information, and we further design an
LLM-driven genetic search to identify optimal visual rendering configurations
for balancing accuracy and compression. Through extensive experiments, we
demonstrate that our method achieves 3-4x token compression while maintaining
accuracy comparable to leading LLMs such as Qwen3-8B on various long-context
benchmarks. This compression also leads to around 4x faster prefilling and
decoding, and approximately 2x faster SFT training. Furthermore, under extreme
compression, a 128K-context VLM could scale to handle 1M-token-level text
tasks. In addition, the rendered text data benefits real-world multimodal
tasks, such as document understanding. Our code and model are released at
https://github.com/thu-coai/Glyph.

</details>


### [122] [Closed-Loop Transfer for Weakly-supervised Affordance Grounding](https://arxiv.org/abs/2510.17384)
*Jiajin Tang,Zhengxuan Wei,Ge Zheng,Sibei Yang*

Main category: cs.CV

TL;DR: 本研究提出了LoopTrans，一个新的闭环框架，通过双向知识传递改进了对象交互场景中的弱监督知识定位。


<details>
  <summary>Details</summary>
Motivation: 当前的弱监督知识定位方法在复杂交互场景中的应用受限，亟需一种新的方法来弥补对象中心和交互中心图像之间的差距。

Method: 本研究提出了一种闭环框架LoopTrans，利用统一的跨模态定位和去噪知识蒸馏等创新机制，促进了知识的双向转移。

Result: LoopTrans在图像和视频基准测试上，针对所有指标均获得了一致的性能提升，能够处理人类身体完全遮挡的对象交互区域。

Conclusion: LoopTrans显著提高了对象中心和交互中心图像之间的知识传递，展示了其在处理复杂交互场景中的有效性。

Abstract: Humans can perform previously unexperienced interactions with novel objects
simply by observing others engage with them. Weakly-supervised affordance
grounding mimics this process by learning to locate object regions that enable
actions on egocentric images, using exocentric interaction images with
image-level annotations. However, extracting affordance knowledge solely from
exocentric images and transferring it one-way to egocentric images limits the
applicability of previous works in complex interaction scenarios. Instead, this
study introduces LoopTrans, a novel closed-loop framework that not only
transfers knowledge from exocentric to egocentric but also transfers back to
enhance exocentric knowledge extraction. Within LoopTrans, several innovative
mechanisms are introduced, including unified cross-modal localization and
denoising knowledge distillation, to bridge domain gaps between object-centered
egocentric and interaction-centered exocentric images while enhancing knowledge
transfer. Experiments show that LoopTrans achieves consistent improvements
across all metrics on image and video benchmarks, even handling challenging
scenarios where object interaction regions are fully occluded by the human
body.

</details>


### [123] [Monitoring Horses in Stalls: From Object to Event Detection](https://arxiv.org/abs/2510.17409)
*Dmitrii Galimzianov,Viacheslav Vyshegorodtsev,Ivan Nezhivykh*

Main category: cs.CV

TL;DR: 本研究提出了一种基于视觉的马匹行为监测系统，利用对象检测和多目标跟踪技术，提升动物福利和马厩管理的效率。


<details>
  <summary>Details</summary>
Motivation: 监测停滞马匹的行为对早期发现健康和福利问题至关重要，但传统方法费时费力。

Method: 采用YOLOv11和BoT-SORT进行对象检测和多目标跟踪，构建定制数据集并通过CLIP和GroundingDINO进行注释。

Result: 系统能够区分五种事件类型，但在人员检测方面存在局限性。

Conclusion: 该系统为马匹行为监测提供了实时解决方案，促进动物福利和马厩管理。

Abstract: Monitoring the behavior of stalled horses is essential for early detection of
health and welfare issues but remains labor-intensive and time-consuming. In
this study, we present a prototype vision-based monitoring system that
automates the detection and tracking of horses and people inside stables using
object detection and multi-object tracking techniques. The system leverages
YOLOv11 and BoT-SORT for detection and tracking, while event states are
inferred based on object trajectories and spatial relations within the stall.
To support development, we constructed a custom dataset annotated with
assistance from foundation models CLIP and GroundingDINO. The system
distinguishes between five event types and accounts for the camera's blind
spots. Qualitative evaluation demonstrated reliable performance for
horse-related events, while highlighting limitations in detecting people due to
data scarcity. This work provides a foundation for real-time behavioral
monitoring in equine facilities, with implications for animal welfare and
stable management.

</details>


### [124] [DeepDetect: Learning All-in-One Dense Keypoints](https://arxiv.org/abs/2510.17422)
*Shaharyar Ahmed Khan Tareen,Filza Khan Tareen*

Main category: cs.CV

TL;DR: DeepDetect是一种基于深度学习的密集关键点检测器，克服了传统方法的局限，在关键点密度和可重复性方面表现优越。


<details>
  <summary>Details</summary>
Motivation: 针对传统和学习方法在关键点检测中的局限性，旨在提高关键点检测的密度和适应性。

Method: 提出DeepDetect，通过融合多种关键点与边缘检测器的输出生成真值掩码，并使用ESPNet模型进行训练。

Result: DeepDetect在Oxford Affine Covariant Regions数据集上的评估表明，平均关键点密度达到0.5143，平均可重复性达到0.9582，正确匹配数为59003。

Conclusion: DeepDetect在关键点密度、可重复性和正确匹配数量上超越了其他检测器，表现优异。

Abstract: Keypoint detection is the foundation of many computer vision tasks, including
image registration, structure-from motion, 3D reconstruction, visual odometry,
and SLAM. Traditional detectors (SIFT, SURF, ORB, BRISK, etc.) and learning
based methods (SuperPoint, R2D2, LF-Net, D2-Net, etc.) have shown strong
performance yet suffer from key limitations: sensitivity to photometric
changes, low keypoint density and repeatability, limited adaptability to
challenging scenes, and lack of semantic understanding, often failing to
prioritize visually important regions. We present DeepDetect, an intelligent,
all-in-one, dense keypoint detector that unifies the strengths of classical
detectors using deep learning. Firstly, we create ground-truth masks by fusing
outputs of 7 keypoint and 2 edge detectors, extracting diverse visual cues from
corners and blobs to prominent edges and textures in the images. Afterwards, a
lightweight and efficient model: ESPNet, is trained using these masks as
labels, enabling DeepDetect to focus semantically on images while producing
highly dense keypoints, that are adaptable to diverse and visually degraded
conditions. Evaluations on the Oxford Affine Covariant Regions dataset
demonstrate that DeepDetect surpasses other detectors in keypoint density,
repeatability, and the number of correct matches, achieving maximum values of
0.5143 (average keypoint density), 0.9582 (average repeatability), and 59,003
(correct matches).

</details>


### [125] [Leveraging AV1 motion vectors for Fast and Dense Feature Matching](https://arxiv.org/abs/2510.17434)
*Julien Zouein,Hossein Javidnia,François Pitié,Anil Kokaram*

Main category: cs.CV

TL;DR: 本文探讨了一种通过AV1运动矢量实现的稠密子像素对应关系的方法，展示了其在短视频处理中的资源高效性和竞争力。


<details>
  <summary>Details</summary>
Motivation: 在短视频中，寻求一种低CPU消耗的方法生成更稠密的匹配。

Method: 通过重利用AV1运动矢量产生稠密子像素对应关系，并通过余弦一致性过滤短轨迹。

Result: 在117帧的短片上，MV匹配注册了所有图像，并重建了46万到62万个点，重投影误差为0.51-0.53像素；BA时间随匹配密度增加。

Conclusion: 压缩域匹配是一种实用且资源高效的前端，具有在完整流程中扩展的明确路径。

Abstract: We repurpose AV1 motion vectors to produce dense sub-pixel correspondences
and short tracks filtered by cosine consistency. On short videos, this
compressed-domain front end runs comparably to sequential SIFT while using far
less CPU, and yields denser matches with competitive pairwise geometry. As a
small SfM demo on a 117-frame clip, MV matches register all images and
reconstruct 0.46-0.62M points at 0.51-0.53,px reprojection error; BA time grows
with match density. These results show compressed-domain correspondences are a
practical, resource-efficient front end with clear paths to scaling in full
pipelines.

</details>


### [126] [Initialize to Generalize: A Stronger Initialization Pipeline for Sparse-View 3DGS](https://arxiv.org/abs/2510.17479)
*Feng Zhou,Wenkai Guo,Pu Cao,Zhicheng Zhang,Jianqin Yin*

Main category: cs.CV

TL;DR: 本研究提出了一种改进稀疏视图3D高斯点云模型的初始化方法，结合频率感知和自初始化技术，显著提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 稀疏视图3D高斯点云模型（3DGS）通常会对训练视图过拟合，因此需要改进初始化步骤以减少伪影，尤其是模糊现象。

Method: 通过设计频率感知的结构光（SfM）和3DGS自初始化，以及点云正则化来改进稀疏视图的高质量点云生成。

Result: 实验证明，在LLFF和Mip-NeRF360数据集上，我们的方法在稀疏视图设置中表现出一致的提升。

Conclusion: 我们的方法在稀疏视图设置中表现出一致的提升，证明了其作为更强初始化策略的有效性。

Abstract: Sparse-view 3D Gaussian Splatting (3DGS) often overfits to the training
views, leading to artifacts like blurring in novel view rendering. Prior work
addresses it either by enhancing the initialization (\emph{i.e.}, the point
cloud from Structure-from-Motion (SfM)) or by adding training-time constraints
(regularization) to the 3DGS optimization. Yet our controlled ablations reveal
that initialization is the decisive factor: it determines the attainable
performance band in sparse-view 3DGS, while training-time constraints yield
only modest within-band improvements at extra cost. Given initialization's
primacy, we focus our design there. Although SfM performs poorly under sparse
views due to its reliance on feature matching, it still provides reliable seed
points. Thus, building on SfM, our effort aims to supplement the regions it
fails to cover as comprehensively as possible. Specifically, we design: (i)
frequency-aware SfM that improves low-texture coverage via low-frequency view
augmentation and relaxed multi-view correspondences; (ii) 3DGS
self-initialization that lifts photometric supervision into additional points,
compensating SfM-sparse regions with learned Gaussian centers; and (iii)
point-cloud regularization that enforces multi-view consistency and uniform
spatial coverage through simple geometric/visibility priors, yielding a clean
and reliable point cloud. Our experiments on LLFF and Mip-NeRF360 demonstrate
consistent gains in sparse-view settings, establishing our approach as a
stronger initialization strategy. Code is available at
https://github.com/zss171999645/ItG-GS.

</details>


### [127] [SparseWorld: A Flexible, Adaptive, and Efficient 4D Occupancy World Model Powered by Sparse and Dynamic Queries](https://arxiv.org/abs/2510.17482)
*Chenxu Dang,Haiyan Liu,Guangjun Bao,Pei An,Xinyue Tang,Jie Ma,Bingchuan Sun,Yan Wang*

Main category: cs.CV

TL;DR: SparseWorld是一个灵活、适应性强的4D占据世界模型，能够提升感知和预测效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有占据世界模型中静态固定嵌入或网格限制了感知灵活性的问题，以及“就地分类”与真实场景动态连续性的潜在不对齐。

Method: 提出了一种新的4D占据世界模型SparseWorld，利用稀疏和动态查询，并设计了范围自适应感知模块和状态条件预测模块，采用回归指导的公式替代分类预测。

Result: 通过大量实验，SparseWorld展示了其在多种任务上的最先进性能，并通过可视化和消融研究验证了其优势。

Conclusion: SparseWorld在感知、预测和规划任务中实现了最先进的性能，展现了优越的灵活性、适应性和效率。

Abstract: Semantic occupancy has emerged as a powerful representation in world models
for its ability to capture rich spatial semantics. However, most existing
occupancy world models rely on static and fixed embeddings or grids, which
inherently limit the flexibility of perception. Moreover, their ``in-place
classification" over grids exhibits a potential misalignment with the dynamic
and continuous nature of real scenarios.In this paper, we propose SparseWorld,
a novel 4D occupancy world model that is flexible, adaptive, and efficient,
powered by sparse and dynamic queries. We propose a Range-Adaptive Perception
module, in which learnable queries are modulated by the ego vehicle states and
enriched with temporal-spatial associations to enable extended-range
perception. To effectively capture the dynamics of the scene, we design a
State-Conditioned Forecasting module, which replaces classification-based
forecasting with regression-guided formulation, precisely aligning the dynamic
queries with the continuity of the 4D environment. In addition, We specifically
devise a Temporal-Aware Self-Scheduling training strategy to enable smooth and
efficient training. Extensive experiments demonstrate that SparseWorld achieves
state-of-the-art performance across perception, forecasting, and planning
tasks. Comprehensive visualizations and ablation studies further validate the
advantages of SparseWorld in terms of flexibility, adaptability, and
efficiency. The code is available at https://github.com/MSunDYY/SparseWorld.

</details>


### [128] [Split-Fuse-Transport: Annotation-Free Saliency via Dual Clustering and Optimal Transport Alignment](https://arxiv.org/abs/2510.17484)
*Muhammad Umer Ramzan,Ali Zia,Abdelwahed Khamis,Noman Ali,Usman Ali,Wei Xiang*

Main category: cs.CV

TL;DR: 研究提出POTNet用于生成伪掩码，从而提出了高效的无监督显著性目标检测方法AutoSOD，性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 假设在没有每个像素标签的情况下，通过可靠的伪掩码可以使SOD接近于监督精度。

Method: 引入POTNet，采用熵引导的双聚类头进行边界像素和内部像素的区分与对齐，并通过最优传输实现原型对齐。

Result: AutoSOD在五个基准测试中表现出比无监督方法高出最多26%和比弱监督方法高出最多36%的F-measure。

Conclusion: AutoSOD在F-measure上超越了多种无监督和弱监督方法，并进一步缩小了与完全监督模型之间的差距。

Abstract: Salient object detection (SOD) aims to segment visually prominent regions in
images and serves as a foundational task for various computer vision
applications. We posit that SOD can now reach near-supervised accuracy without
a single pixel-level label, but only when reliable pseudo-masks are available.
We revisit the prototype-based line of work and make two key observations.
First, boundary pixels and interior pixels obey markedly different geometry;
second, the global consistency enforced by optimal transport (OT) is
underutilized if prototype quality is weak. To address this, we introduce
POTNet, an adaptation of Prototypical Optimal Transport that replaces POT's
single k-means step with an entropy-guided dual-clustering head: high-entropy
pixels are organized by spectral clustering, low-entropy pixels by k-means, and
the two prototype sets are subsequently aligned by OT. This
split-fuse-transport design yields sharper, part-aware pseudo-masks in a single
forward pass, without handcrafted priors. Those masks supervise a standard
MaskFormer-style encoder-decoder, giving rise to AutoSOD, an end-to-end
unsupervised SOD pipeline that eliminates SelfMask's offline voting yet
improves both accuracy and training efficiency. Extensive experiments on five
benchmarks show that AutoSOD outperforms unsupervised methods by up to 26% and
weakly supervised methods by up to 36% in F-measure, further narrowing the gap
to fully supervised models.

</details>


### [129] [Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization](https://arxiv.org/abs/2510.17501)
*Yuanli Wu,Long Zhang,Yue Du,Bin Li*

Main category: cs.CV

TL;DR: 本文提出一种新的伪标注方法，通过评估标准引导视频摘要，提高了零样本学习的准确性与有效性。


<details>
  <summary>Details</summary>
Motivation: 随着视频内容在社交媒体等平台的快速增长，高效总结长视频为简洁而语义保真的内容变得越来越重要。

Method: 通过将小部分真实标注转换为高置信度伪标注，并结合结构化的、适应数据集的评分标准进行场景评估。

Result: 在SumMe和TVSum数据集上，我们的方法分别达到了F1分数57.58和63.05，超越了无监督和先前的零样本基线，接近监督学习的表现。

Conclusion: 本研究提出的基于评估标准的伪标注提示框架有效提高了视频摘要的质量，展现出一种通用、可解释的零样本范式。

Abstract: With the rapid proliferation of video content across social media,
surveillance, and education platforms, efficiently summarizing long videos into
concise yet semantically faithful surrogates has become increasingly vital.
Existing supervised methods achieve strong in-domain accuracy by learning from
dense annotations but suffer from high labeling costs and limited cross-dataset
generalization, while unsupervised approaches, though label-free, often fail to
capture high-level human semantics and fine-grained narrative cues. More
recently, zero-shot prompting pipelines have leveraged large language models
(LLMs) for training-free video summarization, yet remain highly sensitive to
handcrafted prompt templates and dataset-specific score normalization. To
overcome these limitations, we introduce a rubric-guided, pseudo-labeled
prompting framework that transforms a small subset of ground-truth annotations
into high-confidence pseudo labels, which are aggregated into structured,
dataset-adaptive scoring rubrics guiding interpretable scene evaluation. During
inference, first and last segments are scored based solely on their
descriptions, whereas intermediate ones incorporate brief contextual summaries
of adjacent scenes to assess narrative progression and redundancy. This
contextual prompting enables the LLM to balance local salience and global
coherence without parameter tuning. On SumMe and TVSum, our method achieves F1
scores of \textbf{57.58} and \textbf{63.05}, surpassing unsupervised and prior
zero-shot baselines while approaching supervised performance. The results
demonstrate that rubric-guided pseudo labeling effectively stabilizes LLM-based
scoring and establishes a general, interpretable zero-shot paradigm for video
summarization.

</details>


### [130] [MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models](https://arxiv.org/abs/2510.17519)
*Yongshun Zhang,Zhongyi Fan,Yonghang Zhang,Zhangzikang Li,Weifeng Chen,Zhongwei Feng,Chaoyue Wang,Peng Hou,Anxiang Zeng*

Main category: cs.CV

TL;DR: 本研究提出了一种新的大规模视频生成模型MUG-V 10B，通过优化数据处理、模型架构、训练策略和基础设施，显著提升了模型性能和训练效率，并开源了一整套工具。


<details>
  <summary>Details</summary>
Motivation: 由于跨模态文本-视频对齐、长序列和复杂时空依赖性等因素，大规模视频生成模型的训练仍然面临挑战，研究的目的是克服这些挑战并提升生成效率。

Method: 提出了一种优化训练框架，集中于数据处理、模型架构、训练策略和基础设施等四个方面，以提升大规模视频生成模型的效率和性能。

Result: 通过优化四个支柱，实现了显著的效率提升和性能改进，使得最终模型在各项任务中表现出色，尤其是在电商视频生成任务中。

Conclusion: 提出的MUG-V 10B模型在视频生成方面表现优越，特别是在电商导向的任务中超过了领先的开源基线，并且开源了相关工具和代码，以推动该领域的发展。

Abstract: In recent years, large-scale generative models for visual content
(\textit{e.g.,} images, videos, and 3D objects/scenes) have made remarkable
progress. However, training large-scale video generation models remains
particularly challenging and resource-intensive due to cross-modal text-video
alignment, the long sequences involved, and the complex spatiotemporal
dependencies. To address these challenges, we present a training framework that
optimizes four pillars: (i) data processing, (ii) model architecture, (iii)
training strategy, and (iv) infrastructure for large-scale video generation
models. These optimizations delivered significant efficiency gains and
performance improvements across all stages of data preprocessing, video
compression, parameter scaling, curriculum-based pretraining, and
alignment-focused post-training. Our resulting model, MUG-V 10B, matches recent
state-of-the-art video generators overall and, on e-commerce-oriented video
generation tasks, surpasses leading open-source baselines in human evaluations.
More importantly, we open-source the complete stack, including model weights,
Megatron-Core-based large-scale training code, and inference pipelines for
video generation and enhancement. To our knowledge, this is the first public
release of large-scale video generation training code that exploits
Megatron-Core to achieve high training efficiency and near-linear multi-node
scaling, details are available in
\href{https://github.com/Shopee-MUG/MUG-V}{our webpage}.

</details>


### [131] [MambaX-Net: Dual-Input Mamba-Enhanced Cross-Attention Network for Longitudinal MRI Segmentation](https://arxiv.org/abs/2510.17529)
*Yovin Yahathugoda,Davide Prezzi,Piyalitt Ittichaiwong,Vicky Goh,Sebastien Ourselin,Michela Antonelli*

Main category: cs.CV

TL;DR: MambaX-Net是一种新型的半监督分割模型，能够在纵向监测前列腺癌时，利用历史分割信息进行准确分割，其性能显著优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有深度学习分割模型在纵向AS分析中的局限性，尤其是在多时间点和缺乏专家标签的情况下。

Method: 提出了一种新的半监督、双扫描3D分割架构MambaX-Net，利用先前时间点的MRI和相应的分割掩码进行分割。

Result: MambaX-Net通过引入Mamba增强交叉注意模块和形状提取模块，并利用伪标签进行自我训练，有效提升了前列腺分割的准确性。

Conclusion: MambaX-Net在纵向AS数据集上表现优异，能够在有限和噪声数据下实现更精确的前列腺区域分割，超越现有的U-Net和基于Transformer的模型。

Abstract: Active Surveillance (AS) is a treatment option for managing low and
intermediate-risk prostate cancer (PCa), aiming to avoid overtreatment while
monitoring disease progression through serial MRI and clinical follow-up.
Accurate prostate segmentation is an important preliminary step for automating
this process, enabling automated detection and diagnosis of PCa. However,
existing deep-learning segmentation models are often trained on
single-time-point and expertly annotated datasets, making them unsuitable for
longitudinal AS analysis, where multiple time points and a scarcity of expert
labels hinder their effective fine-tuning. To address these challenges, we
propose MambaX-Net, a novel semi-supervised, dual-scan 3D segmentation
architecture that computes the segmentation for time point t by leveraging the
MRI and the corresponding segmentation mask from the previous time point. We
introduce two new components: (i) a Mamba-enhanced Cross-Attention Module,
which integrates the Mamba block into cross attention to efficiently capture
temporal evolution and long-range spatial dependencies, and (ii) a Shape
Extractor Module that encodes the previous segmentation mask into a latent
anatomical representation for refined zone delination. Moreover, we introduce a
semi-supervised self-training strategy that leverages pseudo-labels generated
from a pre-trained nnU-Net, enabling effective learning without expert
annotations. MambaX-Net was evaluated on a longitudinal AS dataset, and results
showed that it significantly outperforms state-of-the-art U-Net and
Transformer-based models, achieving superior prostate zone segmentation even
when trained on limited and noisy data.

</details>


### [132] [WP-CrackNet: A Collaborative Adversarial Learning Framework for End-to-End Weakly-Supervised Road Crack Detection](https://arxiv.org/abs/2510.17566)
*Nachuan Ma,Zhengfei Song,Qiang Hu,Xiaoyu Tang,Chengxi Zhang,Rui Fan,Lihua Xie*

Main category: cs.CV

TL;DR: WP-CrackNet是一种基于弱监督学习的道路裂缝检测方法，通过图像级标签实现高效的像素级裂缝识别，表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统裂缝检测对昂贵像素级标注的依赖，提出一种创新的弱监督方法，提高检测准确性和学习稳定性。

Method: 本研究提出了一种弱监督的端到端方法WP-CrackNet，利用图像级标签进行像素级裂缝检测，结合分类器、重构器和检测器的协同训练。

Result: WP-CrackNet在多个图像级数据集上的实验结果表明，模型相较于监督方法性能相当，相比现有弱监督方法显著提升了检测效果。

Conclusion: WP-CrackNet在弱监督学习下的道路裂缝检测中性能优越，并促进了可扩展的道路检测技术的发展。

Abstract: Road crack detection is essential for intelligent infrastructure maintenance
in smart cities. To reduce reliance on costly pixel-level annotations, we
propose WP-CrackNet, an end-to-end weakly-supervised method that trains with
only image-level labels for pixel-wise crack detection. WP-CrackNet integrates
three components: a classifier generating class activation maps (CAMs), a
reconstructor measuring feature inferability, and a detector producing
pixel-wise road crack detection results. During training, the classifier and
reconstructor alternate in adversarial learning to encourage crack CAMs to
cover complete crack regions, while the detector learns from pseudo labels
derived from post-processed crack CAMs. This mutual feedback among the three
components improves learning stability and detection accuracy. To further boost
detection performance, we design a path-aware attention module (PAAM) that
fuses high-level semantics from the classifier with low-level structural cues
from the reconstructor by modeling spatial and channel-wise dependencies.
Additionally, a center-enhanced CAM consistency module (CECCM) is proposed to
refine crack CAMs using center Gaussian weighting and consistency constraints,
enabling better pseudo-label generation. We create three image-level datasets
and extensive experiments show that WP-CrackNet achieves comparable results to
supervised methods and outperforms existing weakly-supervised methods,
significantly advancing scalable road inspection. The source code package and
datasets are available at https://mias.group/WP-CrackNet/.

</details>


### [133] [PAGE-4D: Disentangled Pose and Geometry Estimation for 4D Perception](https://arxiv.org/abs/2510.17568)
*Kaichen Zhou,Yuhan Wang,Grace Chen,Xinhai Chang,Gaspard Beaudouin,Fangneng Zhan,Paul Pu Liang,Mengyu Wang*

Main category: cs.CV

TL;DR: PAGE-4D是一个扩展VGGT的前馈模型，能够在动态场景中有效进行相机位姿估计、深度预测和点云重建。


<details>
  <summary>Details</summary>
Motivation: 解决VGGT在复杂动态场景中表现不佳的问题，特别是针对动态元素的相机位姿估计和几何重建。

Method: 提出了动态感知聚合器，通过预测动态感知掩模来区分静态和动态信息，解决多任务重建中的冲突问题。

Result: 在动态场景中，PAGE-4D在相机位姿估计、单目深度估计、视频深度估计和稠密点云重建等任务上表现卓越。

Conclusion: PAGE-4D在动态场景下的相机位姿估计、深度预测和点云重建方面优于VGGT模型。

Abstract: Recent 3D feed-forward models, such as the Visual Geometry Grounded
Transformer (VGGT), have shown strong capability in inferring 3D attributes of
static scenes. However, since they are typically trained on static datasets,
these models often struggle in real-world scenarios involving complex dynamic
elements, such as moving humans or deformable objects like umbrellas. To
address this limitation, we introduce PAGE-4D, a feedforward model that extends
VGGT to dynamic scenes, enabling camera pose estimation, depth prediction, and
point cloud reconstruction -- all without post-processing. A central challenge
in multi-task 4D reconstruction is the inherent conflict between tasks:
accurate camera pose estimation requires suppressing dynamic regions, while
geometry reconstruction requires modeling them. To resolve this tension, we
propose a dynamics-aware aggregator that disentangles static and dynamic
information by predicting a dynamics-aware mask -- suppressing motion cues for
pose estimation while amplifying them for geometry reconstruction. Extensive
experiments show that PAGE-4D consistently outperforms the original VGGT in
dynamic scenarios, achieving superior results in camera pose estimation,
monocular and video depth estimation, and dense point map reconstruction.

</details>


### [134] [Integrating BIM and UAV-based photogrammetry for Automated 3D Structure Model Segmentation](https://arxiv.org/abs/2510.17609)
*Siqi Chen,Shanyue Guan*

Main category: cs.CV

TL;DR: 研究提出了一种机器学习框架，实现3D点云的自动分割，提高了监测精度和效率，结合了无人机和BIM技术。


<details>
  <summary>Details</summary>
Motivation: 随着无人机技术的发展，提高基础设施的结构健康监测效率，减少人工标记的时间和误差，具有重要意义。

Method: 本研究采用了结合真实无人机扫描点云和建筑信息建模（BIM）生成的合成数据的方法，来克服传统手动标记的局限性。

Result: 通过对铁路轨道数据集的验证，我们的框架在识别和分割主要结构组件方面展示了高准确性，并在使用较小规模的数据集时显著减少了训练时间。

Conclusion: 本研究提出了一种基于机器学习的框架，有效实现了3D点云的自动分割，显著提高了结构健康监测中的精度和效率。

Abstract: The advancement of UAV technology has enabled efficient, non-contact
structural health monitoring. Combined with photogrammetry, UAVs can capture
high-resolution scans and reconstruct detailed 3D models of infrastructure.
However, a key challenge remains in segmenting specific structural components
from these models-a process traditionally reliant on time-consuming and
error-prone manual labeling. To address this issue, we propose a machine
learning-based framework for automated segmentation of 3D point clouds. Our
approach uses the complementary strengths of real-world UAV-scanned point
clouds and synthetic data generated from Building Information Modeling (BIM) to
overcome the limitations associated with manual labeling. Validation on a
railroad track dataset demonstrated high accuracy in identifying and segmenting
major components such as rails and crossties. Moreover, by using smaller-scale
datasets supplemented with BIM data, the framework significantly reduced
training time while maintaining reasonable segmentation accuracy. This
automated approach improves the precision and efficiency of 3D infrastructure
model segmentation and advances the integration of UAV and BIM technologies in
structural health monitoring and infrastructure management.

</details>


### [135] [One Dinomaly2 Detect Them All: A Unified Framework for Full-Spectrum Unsupervised Anomaly Detection](https://arxiv.org/abs/2510.17611)
*Jia Guo,Shuai Lu,Lei Fan,Zelin Li,Donglin Di,Yang Song,Weihang Zhang,Wenbing Zhu,Hong Yan,Fang Chen,Huiqi Li,Hongen Liao*

Main category: cs.CV

TL;DR: Dinomaly2是一个先进的图像无监督异常检测框架，通过简化设计和统一方法克服了现有多类模型的性能不足，适用于多种数据模式和任务。


<details>
  <summary>Details</summary>
Motivation: 现有的多类无监督异常检测模型表现不佳，且方法碎片化，亟需一个统一的解决方案。

Method: 通过五个简单元素的组合，在标准的重建基础框架中实现性能提升。

Result: Dinomaly2在多个基准测试中的异常检测性能优越，特别是在不同的任务设置和应用领域中展现出色表现。

Conclusion: Dinomaly2是一个统一的框架，能够在各种数据模式和任务设置中实现卓越的异常检测性能，证明了简单性是通用性的基础。

Abstract: Unsupervised anomaly detection (UAD) has evolved from building specialized
single-class models to unified multi-class models, yet existing multi-class
models significantly underperform the most advanced one-for-one counterparts.
Moreover, the field has fragmented into specialized methods tailored to
specific scenarios (multi-class, 3D, few-shot, etc.), creating deployment
barriers and highlighting the need for a unified solution. In this paper, we
present Dinomaly2, the first unified framework for full-spectrum image UAD,
which bridges the performance gap in multi-class models while seamlessly
extending across diverse data modalities and task settings. Guided by the "less
is more" philosophy, we demonstrate that the orchestration of five simple
element achieves superior performance in a standard reconstruction-based
framework. This methodological minimalism enables natural extension across
diverse tasks without modification, establishing that simplicity is the
foundation of true universality. Extensive experiments on 12 UAD benchmarks
demonstrate Dinomaly2's full-spectrum superiority across multiple modalities
(2D, multi-view, RGB-3D, RGB-IR), task settings (single-class, multi-class,
inference-unified multi-class, few-shot) and application domains (industrial,
biological, outdoor). For example, our multi-class model achieves unprecedented
99.9% and 99.3% image-level (I-) AUROC on MVTec-AD and VisA respectively. For
multi-view and multi-modal inspection, Dinomaly2 demonstrates state-of-the-art
performance with minimum adaptations. Moreover, using only 8 normal examples
per class, our method surpasses previous full-shot models, achieving 98.7% and
97.4% I-AUROC on MVTec-AD and VisA. The combination of minimalistic design,
computational scalability, and universal applicability positions Dinomaly2 as a
unified solution for the full spectrum of real-world anomaly detection
applications.

</details>


### [136] [CaMiT: A Time-Aware Car Model Dataset for Classification and Generation](https://arxiv.org/abs/2510.17626)
*Frédéric LIN,Biruk Abere Ambaw,Adrian Popescu,Hejer Ammar,Romaric Audigier,Hervé Le Borgne*

Main category: cs.CV

TL;DR: 本文提出CaMiT数据集，旨在研究汽车模型的时间演变及其对视觉识别的影响，探索了时间增量分类设定和策略以提高模型的时间鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着视觉环境的演变，AI系统必须适应对象外观随时间的变化，因此需要一个针对汽车模型时间演变的细粒度数据集。

Method: 该研究介绍了一种新颖的数据集CaMiT，包含了大量的汽车模型数据，并评估了两种时间增量学习策略以提升模型的适应能力。

Result: CaMiT包含787K标记样本和5.1M未标记样本，通过静态预训练和时间增量学习策略证明了在时间上的适应性增强。

Conclusion: CaMiT数据集为研究细粒度视觉识别和生成中的时间适应提供了丰富的基准，提出的时间增量分类设定和策略显著提高了模型在时间上的鲁棒性。

Abstract: AI systems must adapt to evolving visual environments, especially in domains
where object appearances change over time. We introduce Car Models in Time
(CaMiT), a fine-grained dataset capturing the temporal evolution of car models,
a representative class of technological artifacts. CaMiT includes 787K labeled
samples of 190 car models (2007-2023) and 5.1M unlabeled samples (2005-2023),
supporting both supervised and self-supervised learning. Static pretraining on
in-domain data achieves competitive performance with large-scale generalist
models while being more resource-efficient, yet accuracy declines when models
are tested across years. To address this, we propose a time-incremental
classification setting, a realistic continual learning scenario with emerging,
evolving, and disappearing classes. We evaluate two strategies:
time-incremental pretraining, which updates the backbone, and time-incremental
classifier learning, which updates only the final layer, both improving
temporal robustness. Finally, we explore time-aware image generation that
leverages temporal metadata during training, yielding more realistic outputs.
CaMiT offers a rich benchmark for studying temporal adaptation in fine-grained
visual recognition and generation.

</details>


### [137] [Self-supervised Pre-training for Mapping of Archaeological Stone Wall in Historic Landscapes Using High-Resolution DEM Derivatives](https://arxiv.org/abs/2510.17644)
*Zexian Huang,Mashnoon Islam,Brian Armstrong,Kourosh Khoshelham,Martin Tomko*

Main category: cs.CV

TL;DR: DINO-CV是一个用于干石墙自动映射的深度学习分割框架，通过利用高分辨率DEM和自监督学习策略，有效克服了植被遮挡和标注数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 干石墙具有重要的遗产和环境价值，但由于可达性差和人工绘图成本高，许多墙壁仍未被识别。

Method: 提出DINO-CV，一个基于高分辨率空气激光雷达衍生数字高程模型（DEMs）进行干石墙自动映射的分割框架，并采用自监督跨视图预训练策略。

Result: DINO-CV在UNESCO世界遗产文化景观Budj Bim上识别了澳大利亚最密集的殖民干石墙集，测试区域中平均交并比(mIoU)达68.6%，仅使用10%标注数据时仍能维持63.8%的mIoU。

Conclusion: DINO-CV方法在植被和丰富文化遗产环境中有效地实现了低矮干石墙的自动映射，展示了在标签稀缺的情况下自监督学习的潜力。

Abstract: Dry-stone walls hold significant heritage and environmental value. Mapping
these structures is essential for ecosystem preservation and wildfire
management in Australia. Yet, many walls remain unidentified due to their
inaccessibility and the high cost of manual mapping. Deep learning-based
segmentation offers a scalable solution, but two major challenges persist: (1)
visual occlusion of low-lying walls by dense vegetation, and (2) limited
labeled data for supervised training. We propose DINO-CV, a segmentation
framework for automatic mapping of low-lying dry-stone walls using
high-resolution Airborne LiDAR-derived digital elevation models (DEMs). DEMs
overcome visual occlusion by capturing terrain structures hidden beneath
vegetation, enabling analysis of structural rather than spectral cues. DINO-CV
introduces a self-supervised cross-view pre-training strategy based on
knowledge distillation to mitigate data scarcity. It learns invariant visual
and geometric representations across multiple DEM derivatives, supporting
various vision backbones including ResNet, Wide ResNet, and Vision
Transformers. Applied to the UNESCO World Heritage cultural landscape of Budj
Bim, Victoria, the method identifies one of Australia's densest collections of
colonial dry-stone walls beyond Indigenous heritage contexts. DINO-CV achieves
a mean Intersection over Union (mIoU) of 68.6% on test areas and maintains
63.8% mIoU when fine-tuned with only 10% labeled data. These results
demonstrate the potential of self-supervised learning on high-resolution DEM
derivatives for automated dry-stone wall mapping in vegetated and heritage-rich
environments with scarce annotations.

</details>


### [138] [4DSegStreamer: Streaming 4D Panoptic Segmentation via Dual Threads](https://arxiv.org/abs/2510.17664)
*Ling Liu,Jun Tian,Li Yi*

Main category: cs.CV

TL;DR: 本文提出了一种名为4DSegStreamer的框架，通过双线程系统有效实现实时4D全景分割，尤其在动态环境中表现出色。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中，如人群疏散和复杂场景下的自动驾驶，实现实时精细感知是至关重要的。

Method: 采用双线程系统，包括预测线程和推理线程，以高效处理流媒体帧。

Result: 在HOI4D、SemanticKITTI和nuScenes数据集上的实验表明，该方法在复杂场景中准确预测动态物体的有效性。

Conclusion: 4DSegStreamer在动态场景下实现了准确的4D全景分割，特别是在高帧率条件下展现出优越的鲁棒性。

Abstract: 4D panoptic segmentation in a streaming setting is critical for highly
dynamic environments, such as evacuating dense crowds and autonomous driving in
complex scenarios, where real-time, fine-grained perception within a
constrained time budget is essential. In this paper, we introduce
4DSegStreamer, a novel framework that employs a Dual-Thread System to
efficiently process streaming frames. The framework is general and can be
seamlessly integrated into existing 3D and 4D segmentation methods to enable
real-time capability. It also demonstrates superior robustness compared to
existing streaming perception approaches, particularly under high FPS
conditions. The system consists of a predictive thread and an inference thread.
The predictive thread leverages historical motion and geometric information to
extract features and forecast future dynamics. The inference thread ensures
timely prediction for incoming frames by aligning with the latest memory and
compensating for ego-motion and dynamic object movements. We evaluate
4DSegStreamer on the indoor HOI4D dataset and the outdoor SemanticKITTI and
nuScenes datasets. Comprehensive experiments demonstrate the effectiveness of
our approach, particularly in accurately predicting dynamic objects in complex
scenes.

</details>


### [139] [PICABench: How Far Are We from Physically Realistic Image Editing?](https://arxiv.org/abs/2510.17681)
*Yuandong Pu,Le Zhuo,Songhao Han,Jinbo Xing,Kaiwen Zhu,Shuo Cao,Bin Fu,Si Liu,Hongsheng Li,Yu Qiao,Wenlong Zhang,Xi Chen,Yihao Liu*

Main category: cs.CV

TL;DR: 本文介绍了PICABench和PICAEval，旨在评估和提升物理现实性的图像编辑，指出目前存在的挑战及提出解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有编辑模型主要关注完成编辑指令，但忽视了图像编辑结果的物理效果，亟需评估和改进图像编辑的物理现实性。

Method: 提出了PICABench和PICAEval评估协议，系统性地评估图像编辑的物理现实性，并通过学习视频中的物理知识构建训练数据集PICA-100K。

Result: 评估大多数主流图像编辑模型，发现它们在物理现实性方面仍存在许多不足之处。

Conclusion: 物理现实主义仍然是一个具有挑战性的问题，未来有很大的探索空间。

Abstract: Image editing has achieved remarkable progress recently. Modern editing
models could already follow complex instructions to manipulate the original
content. However, beyond completing the editing instructions, the accompanying
physical effects are the key to the generation realism. For example, removing
an object should also remove its shadow, reflections, and interactions with
nearby objects. Unfortunately, existing models and benchmarks mainly focus on
instruction completion but overlook these physical effects. So, at this moment,
how far are we from physically realistic image editing? To answer this, we
introduce PICABench, which systematically evaluates physical realism across
eight sub-dimension (spanning optics, mechanics, and state transitions) for
most of the common editing operations (add, remove, attribute change, etc). We
further propose the PICAEval, a reliable evaluation protocol that uses
VLM-as-a-judge with per-case, region-level human annotations and questions.
Beyond benchmarking, we also explore effective solutions by learning physics
from videos and construct a training dataset PICA-100K. After evaluating most
of the mainstream models, we observe that physical realism remains a
challenging problem with large rooms to explore. We hope that our benchmark and
proposed solutions can serve as a foundation for future work moving from naive
content editing toward physically consistent realism.

</details>


### [140] [Intelligent Communication Mixture-of-Experts Boosted-Medical Image Segmentation Foundation Model](https://arxiv.org/abs/2510.17684)
*Xinwei Zhang,Hu Chen,Zhe Yuan,Sukun Tian,Peng Feng*

Main category: cs.CV

TL;DR: IC-MoE模型通过智能通信混合专家的方法，提高了医学图像分割任务中的高层特征表示能力，且保持了预训练权重的结构完整性。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割的微调方法存在高层特征表示不足及破坏预训练权重结构完整性的问题。

Method: 构建基础专家、语义专家和自适应专家，实施像素概率自适应投票策略，同时采用语义引导的对比学习方法。

Result: 在三个公共医学图像分割数据集上的广泛实验表明，IC-MoE模型超越了其他最先进的模型。

Conclusion: 提出的IC-MoE模型在高层特征表示和预训练权重结构完整性方面取得了显著提升，并在多个医学图像分割任务中表现优越。

Abstract: Foundation models for medical image segmentation have achieved remarkable
performance. Adaptive fine-tuning of natural image segmentation foundation
models is crucial for medical image segmentation tasks. However, some
limitations exist in existing fine-tuning methods: 1) insufficient
representation of high-level features and 2) the fine-tuning process disrupts
the structural integrity of pretrained weights. Inspired by these critical
problems, we propose an intelligent communication mixture-of-experts
boosted-medical image segmentation foundation model, named IC-MoE, with twofold
ideas: 1) We construct basic experts, semantic experts, and adaptive experts.
Moreover, we implement a pixel probability adaptive voting strategy, which
enables expert selection and fusion through label consistency and load
balancing. This approach preliminarily enhances the representation capability
of high-level features while preserving the structural integrity of pretrained
weights. 2) We propose a semantic-guided contrastive learning method to address
the issue of weak supervision in contrastive learning. This method further
enhances the representation capability of high-level features while preserving
the structural integrity of pretrained weights. Extensive experiments across
three public medical image segmentation datasets demonstrate that the IC-MoE
outperforms other SOTA models. Consequently, the proposed IC-MoE effectively
supplements foundational medical image segmentation models with high-level
features and pretrained structural integrity. We also validate the superior
generalizability of the IC-MoE across diverse medical image segmentation
scenarios.

</details>


### [141] [Multilingual Text-to-Image Person Retrieval via Bidirectional Relation Reasoning and Aligning](https://arxiv.org/abs/2510.17685)
*Min Cao,Xinyu Zhou,Ding Jiang,Bo Du,Mang Ye,Min Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种双向隐式关系推理和对齐的框架Bi-IRRA，用于多语言文本到图像人物检索，并在所有数据集上取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 为了解决模态异质性和现有方法在多语言应用中的局限性，提出多语言文本到图像人物检索任务。

Method: 通过开发一个双向隐式关系推理和对齐的框架Bi-IRRA，从语言和模态上学习对齐。

Result: 该方法在多语言TIPR数据集上实现了新的最先进结果。

Conclusion: 所提出的Bi-IRRA框架在所有多语言文本到图像人物检索数据集上取得了新的最先进成果。

Abstract: Text-to-image person retrieval (TIPR) aims to identify the target person
using textual descriptions, facing challenge in modality heterogeneity. Prior
works have attempted to address it by developing cross-modal global or local
alignment strategies. However, global methods typically overlook fine-grained
cross-modal differences, whereas local methods require prior information to
explore explicit part alignments. Additionally, current methods are
English-centric, restricting their application in multilingual contexts. To
alleviate these issues, we pioneer a multilingual TIPR task by developing a
multilingual TIPR benchmark, for which we leverage large language models for
initial translations and refine them by integrating domain-specific knowledge.
Correspondingly, we propose Bi-IRRA: a Bidirectional Implicit Relation
Reasoning and Aligning framework to learn alignment across languages and
modalities. Within Bi-IRRA, a bidirectional implicit relation reasoning module
enables bidirectional prediction of masked image and text, implicitly enhancing
the modeling of local relations across languages and modalities, a
multi-dimensional global alignment module is integrated to bridge the modality
heterogeneity. The proposed method achieves new state-of-the-art results on all
multilingual TIPR datasets. Data and code are presented in
https://github.com/Flame-Chasers/Bi-IRRA.

</details>


### [142] [Towards 3D Objectness Learning in an Open World](https://arxiv.org/abs/2510.17686)
*Taichi Liu,Zhenyu Wang,Ruofeng Liu,Guang Wang,Desheng Zhang*

Main category: cs.CV

TL;DR: 本文提出OP3Det，一个无需手工提示的开放世界3D物体检测器，利用2D和3D信息显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 针对传统闭合集3D检测器在开放世界场景下的泛化能力不足，探索开放世界的3D物体检测。

Method: 提出了一种类无关的开放世界无提示3D检测器OP3Det，结合2D语义先验和3D几何先验进行一般化物体发现。

Result: OP3Det在AR上比现有开放世界3D检测器性能提高达16.0%，相较于闭合世界3D检测器提高13.5%。

Conclusion: OP3Det在开放世界3D物体检测中表现优异，显著超越现有方法。

Abstract: Recent advancements in 3D object detection and novel category detection have
made significant progress, yet research on learning generalized 3D objectness
remains insufficient. In this paper, we delve into learning open-world 3D
objectness, which focuses on detecting all objects in a 3D scene, including
novel objects unseen during training. Traditional closed-set 3D detectors
struggle to generalize to open-world scenarios, while directly incorporating 3D
open-vocabulary models for open-world ability struggles with vocabulary
expansion and semantic overlap. To achieve generalized 3D object discovery, We
propose OP3Det, a class-agnostic Open-World Prompt-free 3D Detector to detect
any objects within 3D scenes without relying on hand-crafted text prompts. We
introduce the strong generalization and zero-shot capabilities of 2D foundation
models, utilizing both 2D semantic priors and 3D geometric priors for
class-agnostic proposals to broaden 3D object discovery. Then, by integrating
complementary information from point cloud and RGB image in the cross-modal
mixture of experts, OP3Det dynamically routes uni-modal and multi-modal
features to learn generalized 3D objectness. Extensive experiments demonstrate
the extraordinary performance of OP3Det, which significantly surpasses existing
open-world 3D detectors by up to 16.0% in AR and achieves a 13.5% improvement
compared to closed-world 3D detectors.

</details>


### [143] [GAS: Improving Discretization of Diffusion ODEs via Generalized Adversarial Solver](https://arxiv.org/abs/2510.17699)
*Aleksandr Oganov,Ilya Bykov,Eva Neudachina,Mishan Aliev,Alexander Tolmachev,Alexander Sidorov,Aleksandr Zuev,Andrey Okhotin,Denis Rakitin,Aibek Alanov*

Main category: cs.CV

TL;DR: 本文提出了一种新的求解器，通过简化训练过程和提升细节保留，改善了扩散模型的生成质量和计算效率。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在生成质量上达到了最新水平，但其采样过程计算量大且需要复杂的训练技术。

Method: 引入了一种简单的ODE采样器参数化，并结合原始的蒸馏损失与对抗训练。

Result: 通过与现有求解器训练方法的比较，展示了通用对抗求解器的优越性能，尤其是在资源约束下。

Conclusion: 本文提出的通用对抗求解器在解决样本生成的计算效率问题的同时，显著提升了生成质量。

Abstract: While diffusion models achieve state-of-the-art generation quality, they
still suffer from computationally expensive sampling. Recent works address this
issue with gradient-based optimization methods that distill a few-step ODE
diffusion solver from the full sampling process, reducing the number of
function evaluations from dozens to just a few. However, these approaches often
rely on intricate training techniques and do not explicitly focus on preserving
fine-grained details. In this paper, we introduce the Generalized Solver: a
simple parameterization of the ODE sampler that does not require additional
training tricks and improves quality over existing approaches. We further
combine the original distillation loss with adversarial training, which
mitigates artifacts and enhances detail fidelity. We call the resulting method
the Generalized Adversarial Solver and demonstrate its superior performance
compared to existing solver training methods under similar resource
constraints. Code is available at https://github.com/3145tttt/GAS.

</details>


### [144] [Improving Cross-Patient Generalization in Parkinson's Disease Detection through Chunk-Based Analysis of Hand-Drawn Patterns](https://arxiv.org/abs/2510.17703)
*Mhd Adnan Albani,Riad Sonbol*

Main category: cs.CV

TL;DR: 本文提出了一种新的帕金森病检测方法，通过图像分块和集成学习策略显著提高了对未见患者的识别能力，验证了在NewHandPD数据集上的优越性能。


<details>
  <summary>Details</summary>
Motivation: 针对现有研究中数据集不足和处理未见患者数据的鲁棒性问题，提出了新的检测方法。

Method: 采用两阶段分类：第一阶段根据绘图类型（圆形、蜿蜒、螺旋）进行分类，第二阶段从图像中提取特征并检测帕金森病。通过将每张图像分成2x2块进行特征提取和识别，最后通过集成方法合并各块的决策。

Result: 在NewHandPD数据集上，本方法对已见患者的准确率达到97.08%，对未见患者为94.91%，相比于之前研究的4.76个百分点的下降，本方法在两者之间仅有2.17个百分点的差距。

Conclusion: 本文提出的基于图像分块和集成方法的帕金森病检测方法优于现有技术，特别是在未见患者数据上表现突出。

Abstract: Parkinson's disease (PD) is a neurodegenerative disease affecting about 1% of
people over the age of 60, causing motor impairments that impede hand
coordination activities such as writing and drawing. Many approaches have tried
to support early detection of Parkinson's disease based on hand-drawn images;
however, we identified two major limitations in the related works: (1) the lack
of sufficient datasets, (2) the robustness when dealing with unseen patient
data. In this paper, we propose a new approach to detect Parkinson's disease
that consists of two stages: The first stage classifies based on their drawing
type(circle, meander, spiral), and the second stage extracts the required
features from the images and detects Parkinson's disease. We overcame the
previous two limitations by applying a chunking strategy where we divide each
image into 2x2 chunks. Each chunk is processed separately when extracting
features and recognizing Parkinson's disease indicators. To make the final
classification, an ensemble method is used to merge the decisions made from
each chunk. Our evaluation shows that our proposed approach outperforms the top
performing state-of-the-art approaches, in particular on unseen patients. On
the NewHandPD dataset our approach, it achieved 97.08% accuracy for seen
patients and 94.91% for unseen patients, our proposed approach maintained a gap
of only 2.17 percentage points, compared to the 4.76-point drop observed in
prior work.

</details>


### [145] [Raindrop GS: A Benchmark for 3D Gaussian Splatting under Raindrop Conditions](https://arxiv.org/abs/2510.17719)
*Zhiqiang Teng,Beibei Lin,Tingting Chen,Zifeng Yuan,Xuanyi Li,Xuanyu Zhang,Shunli Zhang*

Main category: cs.CV

TL;DR: RaindropGS基准旨在解决3D高斯可视化在雨滴条件下的性能限制，通过真实世界的数据集和全面实验，指明了改善3DGS方法的研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有基准假设理想条件下评估3DGS，而现实世界中雨滴影响复原质量，因此需要一个新的基准来评估真实的雨滴破坏下的3DGS恢复性能。

Method: 建立了一种综合基准，包括数据准备、处理和评估，针对真实场景中的雨滴数据进行研究。

Result: 设立了RaindropGS基准，收集真实世界的雨滴重建数据集，评估不同聚焦条件下的重建质量，并分析了相机焦距位置、姿态和点云初始化的影响。

Conclusion: RaindropGS基准通过全面的实验和分析揭示了现有3DGS方法在雨滴干扰下的性能限制，并为开发更强大的3DGS方法指明了方向。

Abstract: 3D Gaussian Splatting (3DGS) under raindrop conditions suffers from severe
occlusions and optical distortions caused by raindrop contamination on the
camera lens, substantially degrading reconstruction quality. Existing
benchmarks typically evaluate 3DGS using synthetic raindrop images with known
camera poses (constrained images), assuming ideal conditions. However, in
real-world scenarios, raindrops often interfere with accurate camera pose
estimation and point cloud initialization. Moreover, a significant domain gap
between synthetic and real raindrops further impairs generalization. To tackle
these issues, we introduce RaindropGS, a comprehensive benchmark designed to
evaluate the full 3DGS pipeline-from unconstrained, raindrop-corrupted images
to clear 3DGS reconstructions. Specifically, the whole benchmark pipeline
consists of three parts: data preparation, data processing, and raindrop-aware
3DGS evaluation, including types of raindrop interference, camera pose
estimation and point cloud initialization, single image rain removal
comparison, and 3D Gaussian training comparison. First, we collect a real-world
raindrop reconstruction dataset, in which each scene contains three aligned
image sets: raindrop-focused, background-focused, and rain-free ground truth,
enabling a comprehensive evaluation of reconstruction quality under different
focus conditions. Through comprehensive experiments and analyses, we reveal
critical insights into the performance limitations of existing 3DGS methods on
unconstrained raindrop images and the varying impact of different pipeline
components: the impact of camera focus position on 3DGS reconstruction
performance, and the interference caused by inaccurate pose and point cloud
initialization on reconstruction. These insights establish clear directions for
developing more robust 3DGS methods under raindrop conditions.

</details>


### [146] [MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues](https://arxiv.org/abs/2510.17722)
*Yaning Pan,Zekun Wang,Qianqian Xie,Yongqian Wen,Yuanxing Zhang,Guohui Zhang,Haoxuan Hu,Zhiyu Pan,Yibing Huang,Zhidong Gan,Yonghong Lin,An Ping,Tianhao Peng,Jiaheng Liu*

Main category: cs.CV

TL;DR: 本文介绍了MT-Video-Bench，一个用于评估多模态大语言模型在多轮对话中表现的基准，填补了现有评估的空白。


<details>
  <summary>Details</summary>
Motivation: 现有的评估基准仅限于单轮问答，忽视了现实场景中多轮对话的复杂性，亟需一个能够评估这些模型在多轮对话中的能力的工具。

Method: 通过引入MT-Video-Bench基准，针对987个来自不同领域的精心策划的多轮对话进行评估，评估六个核心能力，重点关注感知性和互动性。

Result: 通过对各种开源和闭源的MLLM进行广泛评估，暴露了它们在处理多轮视频对话时的显著表现差异和局限性。

Conclusion: MT-Video-Bench是一个全面的视频理解基准，旨在评估多模态大语言模型在多轮对话中的表现，揭示了它们在处理多轮视频对话时的显著表现差异和局限性。

Abstract: The recent development of Multimodal Large Language Models (MLLMs) has
significantly advanced AI's ability to understand visual modalities. However,
existing evaluation benchmarks remain limited to single-turn question
answering, overlooking the complexity of multi-turn dialogues in real-world
scenarios. To bridge this gap, we introduce MT-Video-Bench, a holistic video
understanding benchmark for evaluating MLLMs in multi-turn dialogues.
Specifically, our MT-Video-Bench mainly assesses six core competencies that
focus on perceptivity and interactivity, encompassing 987 meticulously curated
multi-turn dialogues from diverse domains. These capabilities are rigorously
aligned with real-world applications, such as interactive sports analysis and
multi-turn video-based intelligent tutoring. With MT-Video-Bench, we
extensively evaluate various state-of-the-art open-source and closed-source
MLLMs, revealing their significant performance discrepancies and limitations in
handling multi-turn video dialogues. The benchmark will be publicly available
to foster future research.

</details>


### [147] [Signature Forgery Detection: Improving Cross-Dataset Generalization](https://arxiv.org/abs/2510.17724)
*Matheus Ramos Parracho*

Main category: cs.CV

TL;DR: 本研究探讨了签名伪造检测中的特征学习策略，比较了原始图像和壳处理两种方法在跨数据集泛化能力上的表现，结果显示原始图像方法性能更好，但壳处理方法具有未来发展潜力。


<details>
  <summary>Details</summary>
Motivation: 研究自动签名验证在各种数据集之间的泛化能力，以提高在不同数据集上的模型稳健性。

Method: 使用三个公共基准（CEDAR、ICDAR和GPDS Synthetic）开发了两种实验管道，一种基于原始签名图像，另一种使用壳处理预处理方法。

Result: 研究发现了几种行为模式，但未确定两种方法的明显优越性。原始图像模型在基准测试中取得了更高性能。

Conclusion: 原始图像模型在多个基准测试中表现更好，而基于壳处理的方法则展示了在未来精炼方面的潜力。

Abstract: Automated signature verification is a critical biometric technique used in
banking, identity authentication, and legal documentation. Despite the notable
progress achieved by deep learning methods, most approaches in offline
signature verification still struggle to generalize across datasets, as
variations in handwriting styles and acquisition protocols often degrade
performance. This study investigates feature learning strategies for signature
forgery detection, focusing on improving cross-dataset generalization -- that
is, model robustness when trained on one dataset and tested on another. Using
three public benchmarks -- CEDAR, ICDAR, and GPDS Synthetic -- two experimental
pipelines were developed: one based on raw signature images and another
employing a preprocessing method referred to as shell preprocessing. Several
behavioral patterns were identified and analyzed; however, no definitive
superiority between the two approaches was established. The results show that
the raw-image model achieved higher performance across benchmarks, while the
shell-based model demonstrated promising potential for future refinement toward
robust, cross-domain signature verification.

</details>


### [148] [Can Image-To-Video Models Simulate Pedestrian Dynamics?](https://arxiv.org/abs/2510.17731)
*Aaron Appelle,Jerome P. Lynch*

Main category: cs.CV

TL;DR: 本研究探讨了扩散变换器的I2V模型在生成拥挤场景中行人运动模式的有效性，利用关键帧条件化模型并评估轨迹预测性能。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是探讨高性能I2V模型在生成现实行人运动模式方面的能力，尤其是在拥挤场景中。

Method: 研究通过提取行人轨迹基准中的关键帧，对I2V模型进行条件设置，并利用行人动态的定量指标评估其轨迹预测性能。

Result: 实验结果显示，条件设置的I2V模型能够有效预测行人在复杂公共场景中的轨迹。

Conclusion: 该研究表明，基于扩散变换器的I2V模型在生成拥挤公共场景中的行人移动模式方面表现良好。

Abstract: Recent high-performing image-to-video (I2V) models based on variants of the
diffusion transformer (DiT) have displayed remarkable inherent world-modeling
capabilities by virtue of training on large scale video datasets. We
investigate whether these models can generate realistic pedestrian movement
patterns in crowded public scenes. Our framework conditions I2V models on
keyframes extracted from pedestrian trajectory benchmarks, then evaluates their
trajectory prediction performance using quantitative measures of pedestrian
dynamics.

</details>


### [149] [Joint Multi-Condition Representation Modelling via Matrix Factorisation for Visual Place Recognition](https://arxiv.org/abs/2510.17739)
*Timur Ismagilov,Shakaiba Majeed,Michael Milford,Tan Viet Tuyen Nguyen,Sarvapali D. Ramchurn,Shoaib Ehsan*

Main category: cs.CV

TL;DR: 提出一种训练-free的描述符无关方法，显著提升多参考视觉位置识别性能，且计算轻量。


<details>
  <summary>Details</summary>
Motivation: 针对多参考视觉位置识别，以改进定位性能，同时减少大规模训练所带来的计算成本。

Method: 提出一种无训练的、与描述符无关的方法，通过矩阵分解联合建模多个参考描述符，实现基于投影的残差匹配。

Result: 在多外观数据上，我们的方法相比单一参考提升了Recall@1约18%，在无结构数据上也获得约5%的提升。

Conclusion: 该方法在多种外观数据上相比单一参考提升了Recall@1最多约18%，在外观和视角变化下超越多参考基线，展示了强大的泛化能力，且计算开销较小。

Abstract: We address multi-reference visual place recognition (VPR), where reference
sets captured under varying conditions are used to improve localisation
performance. While deep learning with large-scale training improves robustness,
increasing data diversity and model complexity incur extensive computational
cost during training and deployment. Descriptor-level fusion via voting or
aggregation avoids training, but often targets multi-sensor setups or relies on
heuristics with limited gains under appearance and viewpoint change. We propose
a training-free, descriptor-agnostic approach that jointly models places using
multiple reference descriptors via matrix decomposition into basis
representations, enabling projection-based residual matching. We also introduce
SotonMV, a structured benchmark for multi-viewpoint VPR. On multi-appearance
data, our method improves Recall@1 by up to ~18% over single-reference and
outperforms multi-reference baselines across appearance and viewpoint changes,
with gains of ~5% on unstructured data, demonstrating strong generalisation
while remaining lightweight.

</details>


### [150] [Towards Explainable Skin Cancer Classification: A Dual-Network Attention Model with Lesion Segmentation and Clinical Metadata Fusion](https://arxiv.org/abs/2510.17773)
*Md. Enamul Atiq,Shaikh Anowarul Fattah*

Main category: cs.CV

TL;DR: 本研究提出一种双编码器注意力框架，提升了皮肤癌病变分类的准确性和可解释性，结合了病变分割和临床数据。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌的早期检测显著改善患者预后，但自动化诊断面临高内类变异性和微妙的类间差异性挑战。

Method: 提出一种基于双编码器注意力的框架，利用分割的病变和临床元数据以增强皮肤病变分类的准确性和可解释性。

Result: 在HAM10000数据集及ISIC 2018和2019挑战中，提出的方法实现了最先进的分割性能，并显著提高了分类准确率和平均AUC，与基线模型相比有显著提升。

Conclusion: 结合精确的病变分割和临床数据，通过基于注意力的融合，能够构建出更为准确和可解释的皮肤癌分类模型。

Abstract: Skin cancer is a life-threatening disease where early detection significantly
improves patient outcomes. Automated diagnosis from dermoscopic images is
challenging due to high intra-class variability and subtle inter-class
differences. Many deep learning models operate as "black boxes," limiting
clinical trust. In this work, we propose a dual-encoder attention-based
framework that leverages both segmented lesions and clinical metadata to
enhance skin lesion classification in terms of both accuracy and
interpretability. A novel Deep-UNet architecture with Dual Attention Gates
(DAG) and Atrous Spatial Pyramid Pooling (ASPP) is first employed to segment
lesions. The classification stage uses two DenseNet201 encoders-one on the
original image and another on the segmented lesion whose features are fused via
multi-head cross-attention. This dual-input design guides the model to focus on
salient pathological regions. In addition, a transformer-based module
incorporates patient metadata (age, sex, lesion site) into the prediction. We
evaluate our approach on the HAM10000 dataset and the ISIC 2018 and 2019
challenges. The proposed method achieves state-of-the-art segmentation
performance and significantly improves classification accuracy and average AUC
compared to baseline models. To validate our model's reliability, we use
Gradient-weighted Class Activation Mapping (Grad-CAM) to generate heatmaps.
These visualizations confirm that our model's predictions are based on the
lesion area, unlike models that rely on spurious background features. These
results demonstrate that integrating precise lesion segmentation and clinical
data with attention-based fusion leads to a more accurate and interpretable
skin cancer classification model.

</details>


### [151] [SparseVILA: Decoupling Visual Sparsity for Efficient VLM Inference](https://arxiv.org/abs/2510.17777)
*Samir Khaki,Junxian Guo,Jiaming Tang,Shang Yang,Yukang Chen,Konstantinos N. Plataniotis,Yao Lu,Song Han,Zhijian Liu*

Main category: cs.CV

TL;DR: SparseVILA是一种新颖的视觉语言模型推理方法，通过解耦视觉稀疏性，提高推理效率并改善准确性，适用于大型模型。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型应用的快速发展，推理延迟受到视觉标记数量增加的限制，亟需一种高效的推理方法来改善这一问题。

Method: 通过在预填充和解码阶段解耦视觉稀疏性，SparseVILA在预填充阶段修剪冗余视觉标记，并在解码时检索仅与查询相关的标记。

Result: SparseVILA在长上下文视频任务上实现了预填充速度提高4.0倍，解码速度提高2.5倍，以及整体速度提高2.6倍，同时在文档理解和推理任务上提高了准确性。

Conclusion: SparseVILA提出了一种高效的视觉语言模型推理新范式，显著提高了推理速度并保持了准确性，开辟了多模态推理的新方向。

Abstract: Vision Language Models (VLMs) have rapidly advanced in integrating visual and
textual reasoning, powering applications across high-resolution image
understanding, long-video analysis, and multi-turn conversation. However, their
scalability remains limited by the growing number of visual tokens that
dominate inference latency. We present SparseVILA, a new paradigm for efficient
VLM inference that decouples visual sparsity across the prefilling and decoding
stages. SparseVILA distributes sparsity across stages by pruning redundant
visual tokens during prefill and retrieving only query-relevant tokens during
decoding. This decoupled design matches leading prefill pruning methods while
preserving multi-turn fidelity by retaining most of the visual cache so that
query-aware tokens can be retrieved at each conversation round. Built on an
AWQ-optimized inference pipeline, SparseVILA achieves up to 4.0 times faster
prefilling, 2.5 times faster decoding, and an overall 2.6 times end-to-end
speedup on long-context video tasks -- while improving accuracy on
document-understanding and reasoning tasks. By decoupling query-agnostic
pruning and query-aware retrieval, SparseVILA establishes a new direction for
efficient multimodal inference, offering a training-free, architecture-agnostic
framework for accelerating large VLMs without sacrificing capability.

</details>


### [152] [ConsistEdit: Highly Consistent and Precise Training-free Visual Editing](https://arxiv.org/abs/2510.17803)
*Zixin Yin,Ling-Hao Chen,Lionel Ni,Xili Dai*

Main category: cs.CV

TL;DR: ConsistEdit 是一种新型的注意力控制方法，专门针对 MM-DiT 架构设计，能够在图像和视频编辑中实现卓越的一致性与灵活性。


<details>
  <summary>Details</summary>
Motivation: 当前的编辑方法难以在强编辑力度和源一致性之间取得平衡，尤其在多轮和视频编辑中，积累的视觉错误使得这一问题更加严峻。

Method: 提出了一种新的注意力控制方法 ConsistEdit，结合了视觉单一注意力控制、掩码引导的前注意力融合，以及对查询、键和值令牌的差异化操作。

Result: ConsistEdit 在各种图像和视频编辑任务中表现出色，并首次能够在所有推理步骤和注意力层中进行编辑，而无需手工制作，显著提高了可靠性和一致性。

Conclusion: ConsistEdit 方法在多个图像和视频编辑任务中实现了最先进的性能，尤其是在保持一致性与灵活编辑之间取得了良好平衡。

Abstract: Recent advances in training-free attention control methods have enabled
flexible and efficient text-guided editing capabilities for existing generation
models. However, current approaches struggle to simultaneously deliver strong
editing strength while preserving consistency with the source. This limitation
becomes particularly critical in multi-round and video editing, where visual
errors can accumulate over time. Moreover, most existing methods enforce global
consistency, which limits their ability to modify individual attributes such as
texture while preserving others, thereby hindering fine-grained editing.
Recently, the architectural shift from U-Net to MM-DiT has brought significant
improvements in generative performance and introduced a novel mechanism for
integrating text and vision modalities. These advancements pave the way for
overcoming challenges that previous methods failed to resolve. Through an
in-depth analysis of MM-DiT, we identify three key insights into its attention
mechanisms. Building on these, we propose ConsistEdit, a novel attention
control method specifically tailored for MM-DiT. ConsistEdit incorporates
vision-only attention control, mask-guided pre-attention fusion, and
differentiated manipulation of the query, key, and value tokens to produce
consistent, prompt-aligned edits. Extensive experiments demonstrate that
ConsistEdit achieves state-of-the-art performance across a wide range of image
and video editing tasks, including both structure-consistent and
structure-inconsistent scenarios. Unlike prior methods, it is the first
approach to perform editing across all inference steps and attention layers
without handcraft, significantly enhancing reliability and consistency, which
enables robust multi-round and multi-region editing. Furthermore, it supports
progressive adjustment of structural consistency, enabling finer control.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [153] [Quantum NLP models on Natural Language Inference](https://arxiv.org/abs/2510.15972)
*Ling Sun,Peter Sullivan,Michael Martin,Yun Zhou*

Main category: cs.CL

TL;DR: 本文探讨了量子自然语言处理应用于自然语言推理的效果，结果表明量子模型在少量参数下能实现与经典模型相媲美的性能，并且在学习效率上具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 研究量子自然语言处理（QNLP）在自然语言推理（NLI）任务中的应用。

Method: 构建参数化量子电路进行句子对训练，使用信息增益每参数（IGPP）作为评估效率的指标。

Result: 量子模型在参数数量上显著低于经典模型，且在学习效率上高出五个数量级。

Conclusion: 量子模型在推理任务中优于随机初始化的变换器，并在相关性任务上实现更低的测试误差。

Abstract: Quantum natural language processing (QNLP) offers a novel approach to
semantic modeling by embedding compositional structure directly into quantum
circuits. This paper investigates the application of QNLP models to the task of
Natural Language Inference (NLI), comparing quantum, hybrid, and classical
transformer-based models under a constrained few-shot setting. Using the lambeq
library and the DisCoCat framework, we construct parameterized quantum circuits
for sentence pairs and train them for both semantic relatedness and inference
classification. To assess efficiency, we introduce a novel
information-theoretic metric, Information Gain per Parameter (IGPP), which
quantifies learning dynamics independent of model size. Our results demonstrate
that quantum models achieve performance comparable to classical baselines while
operating with dramatically fewer parameters. The Quantum-based models
outperform randomly initialized transformers in inference and achieve lower
test error on relatedness tasks. Moreover, quantum models exhibit significantly
higher per-parameter learning efficiency (up to five orders of magnitude more
than classical counterparts), highlighting the promise of QNLP in low-resource,
structure-sensitive settings. To address circuit-level isolation and promote
parameter sharing, we also propose a novel cluster-based architecture that
improves generalization by tying gate parameters to learned word clusters
rather than individual tokens.

</details>


### [154] [Fusion-Augmented Large Language Models: Boosting Diagnostic Trustworthiness via Model Consensus](https://arxiv.org/abs/2510.16057)
*Md Kamrul Siam,Md Jobair Hossain Faruk,Jerry Q. Cheng,Huanying Gu*

Main category: cs.CL

TL;DR: 本研究通过结合大型语言模型和多模态输入，提升了胸部X光图像解读的准确性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在提高胸部X光解读的准确性和可靠性，解决诊断中的错误问题。

Method: 研究利用了ChatGPT和Claude这两种先进的大型语言模型，通过图像和合成临床文本的组合，评估其在CheXpert数据集上的表现。

Result: 多模态评估显示，结合图像和合成文本后，ChatGPT的准确率达到了84%，而Claude为76%；而共识准确率甚至达到了91.3%。

Conclusion: 该研究表明，通过结合多模态输入和输出级共识方法，可以显著提高胸部X光图像的解读可靠性，减少诊断错误。

Abstract: This study presents a novel multi-model fusion framework leveraging two
state-of-the-art large language models (LLMs), ChatGPT and Claude, to enhance
the reliability of chest X-ray interpretation on the CheXpert dataset. From the
full CheXpert corpus of 224,316 chest radiographs, we randomly selected 234
radiologist-annotated studies to evaluate unimodal performance using image-only
prompts. In this setting, ChatGPT and Claude achieved diagnostic accuracies of
62.8% and 76.9%, respectively. A similarity-based consensus approach, using a
95% output similarity threshold, improved accuracy to 77.6%. To assess the
impact of multimodal inputs, we then generated synthetic clinical notes
following the MIMIC-CXR template and evaluated a separate subset of 50 randomly
selected cases paired with both images and synthetic text. On this multimodal
cohort, performance improved to 84% for ChatGPT and 76% for Claude, while
consensus accuracy reached 91.3%. Across both experimental conditions,
agreement-based fusion consistently outperformed individual models. These
findings highlight the utility of integrating complementary modalities and
using output-level consensus to improve the trustworthiness and clinical
utility of AI-assisted radiological diagnosis, offering a practical path to
reduce diagnostic errors with minimal computational overhead.

</details>


### [155] [Can LLMs Correct Themselves? A Benchmark of Self-Correction in LLMs](https://arxiv.org/abs/2510.16062)
*Guiyao Tie,Zenghui Yuan,Zeli Zhao,Chaoran Hu,Tianhe Gu,Ruihang Zhang,Sizhe Zhang,Junran Wu,Xiaoyue Tu,Ming Jin,Qingsong Wen,Lixing Chen,Pan Zhou,Lichao Sun*

Main category: cs.CL

TL;DR: 研究展示了自我修正方法在改善推理性能方面的重要性，并指出提升效率的挑战，建议未来研究关注推理能力与效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的应用日益增加，探索其自我修正能力对提高推理性能具有重要意义。

Method: 开发CorrectBench基准评估自我修正策略的有效性，包括内在、外部和微调方法，针对三项任务进行测试。

Result: 研究发现自我修正方法可以提高准确性，尤其在复杂任务中。混合不同策略可进一步改善，但降低效率。自我修正在推理LLMs上优化有限且耗时。

Conclusion: 自我修正方法能够提高大型语言模型的推理性能，尽管在效率上存在挑战，且简单的思维链基线显示出竞争力。

Abstract: Self-correction of large language models (LLMs) emerges as a critical
component for enhancing their reasoning performance. Although various
self-correction methods have been proposed, a comprehensive evaluation of these
methods remains largely unexplored, and the question of whether LLMs can truly
correct themselves is a matter of significant interest and concern. In this
study, we introduce CorrectBench, a benchmark developed to evaluate the
effectiveness of self-correction strategies, including intrinsic, external, and
fine-tuned approaches, across three tasks: commonsense reasoning, mathematical
reasoning, and code generation. Our findings reveal that: 1) Self-correction
methods can improve accuracy, especially for complex reasoning tasks; 2) Mixing
different self-correction strategies yields further improvements, though it
reduces efficiency; 3) Reasoning LLMs (e.g., DeepSeek-R1) have limited
optimization under additional self-correction methods and have high time costs.
Interestingly, a comparatively simple chain-of-thought (CoT) baseline
demonstrates competitive accuracy and efficiency. These results underscore the
potential of self-correction to enhance LLM's reasoning performance while
highlighting the ongoing challenge of improving their efficiency. Consequently,
we advocate for further research focused on optimizing the balance between
reasoning capabilities and operational efficiency. Project Page:
https://correctbench.github.io/

</details>


### [156] [EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle](https://arxiv.org/abs/2510.16079)
*Rong Wu,Xiaoman Wang,Jianbiao Mei,Pinlong Cai,Daocheng Fu,Cheng Yang,Licheng Wen,Xuemeng Yang,Yufan Shen,Yuxin Wang,Botian Shi*

Main category: cs.CL

TL;DR: EvolveR框架旨在提升智能体自我改进能力，采用离线自蒸馏与在线互动的闭环流程，在多步问答任务中表现优越。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型智能体在工具使用上表现强劲，但缺乏从自身经验中系统学习的能力，因此需要一个能让智能体自我改进的框架。

Method: 本研究提出EvolveR框架，包含离线自蒸馏和在线互动两个阶段，构建了一个完整的闭环体验生命周期。

Result: EvolveR通过强化学习机制，不断根据绩效更新智能体，使其能够从外部数据和自身行为后果中学习，积累多样的行为轨迹。

Conclusion: EvolveR展示了在复杂多步问答基准测试中相较于其他强大的智能体基线具有更卓越的性能，成为一个有效的自我改进框架。

Abstract: Current Large Language Model (LLM) agents show strong performance in tool
use, but lack the crucial capability to systematically learn from their own
experiences. While existing frameworks mainly focus on mitigating external
knowledge gaps, they fail to address a more fundamental limitation: the
inability to iteratively refine problem-solving strategies. In this work, we
introduce EvolveR, a framework designed to enable agent to self-improve through
a complete, closed-loop experience lifecycle. This lifecycle comprises two key
stages: (1) Offline Self-Distillation, where the agent's interaction
trajectories are synthesized into a structured repository of abstract, reusable
strategic principles; (2) Online Interaction, where the agent interacts with
tasks and actively retrieves distilled principles to guide its decision-making,
accumulating a diverse set of behavioral trajectories. This loop employs a
policy reinforcement mechanism to iteratively update the agent based on its
performance. We demonstrate the effectiveness of EvolveR on complex multi-hop
question-answering benchmarks, where it achieves superior performance over
strong agentic baselines. Our work presents a comprehensive blueprint for
agents that learn not only from external data but also from the consequences of
their own actions, paving the way for more autonomous and continuously
improving systems. Code is available at https://github.com/Edaizi/EvolveR.

</details>


### [157] [Evaluating Prompting Strategies and Large Language Models in Systematic Literature Review Screening: Relevance and Task-Stage Classification](https://arxiv.org/abs/2510.16091)
*Binglan Han,Anuradha Mathrani,Teo Susnjak*

Main category: cs.CL

TL;DR: 本研究评估了多种提示策略对六种大语言模型在文献筛选中的影响，提出使用低成本模型进行初步筛选的建议。


<details>
  <summary>Details</summary>
Motivation: 探讨提示策略与大语言模型的相互作用，以提高系统文献回顾的自动化筛选效率

Method: 对六种大语言模型（LLM）在多个提示类型下进行性能评估

Result: 发现提示策略对模型效果有显著影响，同时分析模型的成本效益

Conclusion: 研究表明，针对不同提示策略的模型具有不同的表现，建议采用分阶段的工作流程以优化文献筛选

Abstract: This study quantifies how prompting strategies interact with large language
models (LLMs) to automate the screening stage of systematic literature reviews
(SLRs). We evaluate six LLMs (GPT-4o, GPT-4o-mini, DeepSeek-Chat-V3,
Gemini-2.5-Flash, Claude-3.5-Haiku, Llama-4-Maverick) under five prompt types
(zero-shot, few-shot, chain-of-thought (CoT), CoT-few-shot, self-reflection)
across relevance classification and six Level-2 tasks, using accuracy,
precision, recall, and F1. Results show pronounced model-prompt interaction
effects: CoT-few-shot yields the most reliable precision-recall balance;
zero-shot maximizes recall for high-sensitivity passes; and self-reflection
underperforms due to over-inclusivity and instability across models. GPT-4o and
DeepSeek provide robust overall performance, while GPT-4o-mini performs
competitively at a substantially lower dollar cost. A cost-performance analysis
for relevance classification (per 1,000 abstracts) reveals large absolute
differences among model-prompt pairings; GPT-4o-mini remains low-cost across
prompts, and structured prompts (CoT/CoT-few-shot) on GPT-4o-mini offer
attractive F1 at a small incremental cost. We recommend a staged workflow that
(1) deploys low-cost models with structured prompts for first-pass screening
and (2) escalates only borderline cases to higher-capacity models. These
findings highlight LLMs' uneven but promising potential to automate literature
screening. By systematically analyzing prompt-model interactions, we provide a
comparative benchmark and practical guidance for task-adaptive LLM deployment.

</details>


### [158] [Facts in Stats: Impacts of Pretraining Diversity on Language Model Generalization](https://arxiv.org/abs/2510.16096)
*Tina Behnia,Puneesh Deora,Christos Thrampoulidis*

Main category: cs.CL

TL;DR: 本文分析语言模型中的统计规律与事实关联的相互作用，提出合成测试床以研究设计和多样性如何影响泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前关于语言模型的研究表明，统计规律和特定词元之间的事实关联的交互性对模型的泛化能力至关重要，但系统性分析尚缺乏。

Method: 本文提出了一种灵活的合成测试床，结合统计流和抽象事实流，以细致控制它们的相互作用。

Result: 通过控制实验发现，多样性对模型的事实回忆和泛化能力有显著影响，并且不同的上下文结构对这些能力具有不同的影响。

Conclusion: 本研究揭示了上下文设计和多样性水平之间的相互作用如何影响语言模型的不同泛化能力，并确认了在训练期间最佳多样性水平的依赖性。

Abstract: Language models are pretrained on sequences that blend statistical
regularities (making text fluent) with factual associations between specific
tokens (knowledge of facts). While recent work suggests that the variability of
their interaction, such as paraphrases of factual associations, critically
determines generalization ability, we lack a systematic analysis of these
impacts. This paper introduces a flexible synthetic testbed that combines a
statistical stream of generic tokens with an abstract factual stream of
source-target token pairs, enabling fine-grained control over their
interaction. The design enables the independent control of diversity nature by
manipulating stream composition (contextual structure) and the diversity level
by varying which statistical streams each fact appears in. Through controlled
experiments, we find that while higher contextual diversity delays
in-distribution (ID) factual accuracy, its impact on out-of-distribution (OOD)
factual generalization depends critically on contextual structure. In some
cases, OOD performance follows the same trend as ID, but in others, diversity
becomes essential for non-trivial factual recall. Even when low diversity
prohibits factual recall, optimal diversity levels depend on training duration.
Beyond factual recall failures, we identify structures where statistical
generalization fails independently, and others where both capabilities degrade.
This shows how the interplay between contextual design and diversity level
impacts different generalization aspects. Further, through a series of
controlled interventions on the model components, we trace the OOD failures to
distinct optimization bottlenecks, highlighting the importance of the embedding
and unembedding layers. Our synthetic framework allows us to isolate effects
that would be confounded in large-scale studies, offering a controlled testbed
for future investigations.

</details>


### [159] [BenCao: An Instruction-Tuned Large Language Model for Traditional Chinese Medicine](https://arxiv.org/abs/2510.17415)
*Jiacheng Xie,Yang Yu,Yibo Chen,Hanyao Zhang,Lening Zhao,Jiaxuan He,Lei Jiang,Xiaoting Tang,Guanghui An,Dong Xu*

Main category: cs.CL

TL;DR: 本研究介绍了BenCao，一个基于ChatGPT的中医多模态助手，通过自然语言指令调优和多模态集成，提升了中医相关任务的准确性和临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 传统中医在全球医疗中扮演重要角色，但将大型语言模型应用于中医面临挑战，因此开发一个具有多模态能力的助手变得尤为重要。

Method: 采用自然语言指令调优的方法，而不是参数重训练，结合专家反馈细化，与中医特定的伦理规范进行对齐。

Result: BenCao在单项选择题基准和多模态分类任务中的表现优于一般领域和中医领域模型，在诊断、草药识别和体质分类方面特别突出。

Conclusion: 本研究展示了通过自然语言指令调优和多模态集成开发中医领域LLM的可行性，为将生成式人工智能与传统医学推理相结合提供了实用框架，并为实际应用提供了可扩展路径。

Abstract: Traditional Chinese Medicine (TCM), with a history spanning over two
millennia, plays a role in global healthcare. However, applying large language
models (LLMs) to TCM remains challenging due to its reliance on holistic
reasoning, implicit logic, and multimodal diagnostic cues. Existing TCM-domain
LLMs have made progress in text-based understanding but lack multimodal
integration, interpretability, and clinical applicability. To address these
limitations, we developed BenCao, a ChatGPT-based multimodal assistant for TCM,
integrating structured knowledge bases, diagnostic data, and expert feedback
refinement. BenCao was trained through natural language instruction tuning
rather than parameter retraining, aligning with expert-level reasoning and
ethical norms specific to TCM. The system incorporates a comprehensive
knowledge base of over 1,000 classical and modern texts, a scenario-based
instruction framework for diverse interactions, a chain-of-thought simulation
mechanism for interpretable reasoning, and a feedback refinement process
involving licensed TCM practitioners. BenCao connects to external APIs for
tongue-image classification and multimodal database retrieval, enabling dynamic
access to diagnostic resources. In evaluations across single-choice question
benchmarks and multimodal classification tasks, BenCao achieved superior
accuracy to general-domain and TCM-domain models, particularly in diagnostics,
herb recognition, and constitution classification. The model was deployed as an
interactive application on the OpenAI GPTs Store, accessed by nearly 1,000
users globally as of October 2025. This study demonstrates the feasibility of
developing a TCM-domain LLM through natural language-based instruction tuning
and multimodal integration, offering a practical framework for aligning
generative AI with traditional medical reasoning and a scalable pathway for
real-world deployment.

</details>


### [160] [In Generative AI We (Dis)Trust? Computational Analysis of Trust and Distrust in Reddit Discussions](https://arxiv.org/abs/2510.16173)
*Aria Pessianzadeh,Naima Sultana,Hildegarde Van den Bulck,David Gefen,Shahin Jabari,Rezvaneh Rezapour*

Main category: cs.CL

TL;DR: 本研究是对生成性AI信任和不信任的首次计算研究，揭示了公众感知的演变及其影响因素。


<details>
  <summary>Details</summary>
Motivation: 为了实现负责任的技术采用和治理，理解公众对生成性AI的信任变得至关重要。

Method: 使用多年的Reddit数据集（2022-2025年），结合众包注释和分类模型进行分析。

Result: 信任和不信任在时间上几乎保持平衡，主要围绕重大模型发布时出现波动，技术性能和可用性是主导因素。

Conclusion: 研究结果提供了大型信任分析的方法论框架，并深入了解公众对生成性AI的不断变化的看法。

Abstract: The rise of generative AI (GenAI) has impacted many aspects of human life. As
these systems become embedded in everyday practices, understanding public trust
in them also becomes essential for responsible adoption and governance. Prior
work on trust in AI has largely drawn from psychology and human-computer
interaction, but there is a lack of computational, large-scale, and
longitudinal approaches to measuring trust and distrust in GenAI and large
language models (LLMs). This paper presents the first computational study of
Trust and Distrust in GenAI, using a multi-year Reddit dataset (2022--2025)
spanning 39 subreddits and 197,618 posts. Crowd-sourced annotations of a
representative sample were combined with classification models to scale
analysis. We find that Trust and Distrust are nearly balanced over time, with
shifts around major model releases. Technical performance and usability
dominate as dimensions, while personal experience is the most frequent reason
shaping attitudes. Distinct patterns also emerge across trustors (e.g.,
experts, ethicists, general users). Our results provide a methodological
framework for large-scale Trust analysis and insights into evolving public
perceptions of GenAI.

</details>


### [161] [EgMM-Corpus: A Multimodal Vision-Language Dataset for Egyptian Culture](https://arxiv.org/abs/2510.16198)
*Mohamed Gamil,Abdelrahman Elsayed,Abdelrahman Lila,Ahmed Gad,Hesham Abdelgawad,Mohamed Aref,Ahmed Fares*

Main category: cs.CL

TL;DR: 本研究提出了EgMM-Corpus数据集，专注于埃及文化，以促进视觉语言模型的评估与训练，并揭示了现有模型的文化偏见。


<details>
  <summary>Details</summary>
Motivation: 尽管AI取得了最近的进展，但中东和非洲地区的多模态文化多样性数据集仍然有限。

Method: 设计并运行数据收集管道，收集超过3000张图像，并手动验证每个条目的文化真实性和多模态一致性。

Result: Contrastive Language-Image Pre-training (CLIP)在EgMM-Corpus上的零-shot性能表现为21.2%的Top-1准确率和36.4%的Top-5准确率，表明大规模视觉语言模型中存在文化偏差。

Conclusion: EgMM-Corpus是一个重要的基准数据集，对于开发具有文化意识的视觉语言模型至关重要。

Abstract: Despite recent advances in AI, multimodal culturally diverse datasets are
still limited, particularly for regions in the Middle East and Africa. In this
paper, we introduce EgMM-Corpus, a multimodal dataset dedicated to Egyptian
culture. By designing and running a new data collection pipeline, we collected
over 3,000 images, covering 313 concepts across landmarks, food, and folklore.
Each entry in the dataset is manually validated for cultural authenticity and
multimodal coherence. EgMM-Corpus aims to provide a reliable resource for
evaluating and training vision-language models in an Egyptian cultural context.
We further evaluate the zero-shot performance of Contrastive Language-Image
Pre-training CLIP on EgMM-Corpus, on which it achieves 21.2% Top-1 accuracy and
36.4% Top-5 accuracy in classification. These results underscore the existing
cultural bias in large-scale vision-language models and demonstrate the
importance of EgMM-Corpus as a benchmark for developing culturally aware
models.

</details>


### [162] [What Can String Probability Tell Us About Grammaticality?](https://arxiv.org/abs/2510.16227)
*Jennifer Hu,Ethan Gotlieb Wilcox,Siyuan Song,Kyle Mahowald,Roger P. Levy*

Main category: cs.CL

TL;DR: 研究了语言模型的字符串概率与语法知识的关系，并通过实证数据验证了相关预测。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型对语法的理解及其对语言学理论的影响。

Method: 基于关于语料数据生成过程的简单假设，对语法、意义和字符串概率之间的关系进行了理论分析，使用280K句子对进行实证验证。

Result: 验证了三项预测：最小对之间字符串概率的相关性，模型与人类在最小对中的差异相关性，以及非配对语法和非语法字符串在概率空间中的分离性差。

Conclusion: 通过理论分析和实证验证，提出了语言模型的概率与语法知识之间的关系，为未来的研究提供了方向。

Abstract: What have language models (LMs) learned about grammar? This question remains
hotly debated, with major ramifications for linguistic theory. However, since
probability and grammaticality are distinct notions in linguistics, it is not
obvious what string probabilities can reveal about an LM's underlying
grammatical knowledge. We present a theoretical analysis of the relationship
between grammar, meaning, and string probability, based on simple assumptions
about the generative process of corpus data. Our framework makes three
predictions, which we validate empirically using 280K sentence pairs in English
and Chinese: (1) correlation between the probability of strings within minimal
pairs, i.e., string pairs with minimal semantic differences; (2) correlation
between models' and humans' deltas within minimal pairs; and (3) poor
separation in probability space between unpaired grammatical and ungrammatical
strings. Our analyses give theoretical grounding for using probability to learn
about LMs' structural knowledge, and suggest directions for future work in LM
grammatical evaluation.

</details>


### [163] [Towards Low-Resource Alignment to Diverse Perspectives with Sparse Feedback](https://arxiv.org/abs/2510.16257)
*Chu Fei Luo,Samuel Dahan,Xiaodan Zhu*

Main category: cs.CL

TL;DR: 本研究提出两种方法来增强低资源环境中语言模型的多元对齐，实验证明模型引导在多任务上表现优于基线，并强调多样性的必要性。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型对社会的影响越来越大，确保其对多样化观点的对齐和能够反映人类价值的细微差别非常重要。

Method: 通过多元解码和模型引导的方法增强语言模型在低资源环境中的多元对齐。

Result: 模型引导方法在只有50个标注样本的情况下，持续优于零样本和少样本基线，减少了多个高风险任务中的假阳性，并改善了GlobalOpinionQA中的人类价值对齐。

Conclusion: 本研究强调了多样性的重要性，以及语言模型如何能够适应复杂的观点。

Abstract: As language models have a greater impact on society, it is important to
ensure they are aligned to a diverse range of perspectives and are able to
reflect nuance in human values. However, the most popular training paradigms
for modern language models often assume there is one optimal answer for every
query, leading to generic responses and poor alignment. In this work, we aim to
enhance pluralistic alignment of language models in a low-resource setting with
two methods: pluralistic decoding and model steering. We empirically
demonstrate that model steering offers consistent improvement over zero-shot
and few-shot baselines with only 50 annotated samples. Our proposed methods
decrease false positives in several high-stakes tasks such as hate speech
detection and misinformation detection, and improves the distributional
alignment to human values in GlobalOpinionQA. We hope our work highlights the
importance of diversity and how language models can be adapted to consider
nuanced perspectives.

</details>


### [164] [Thinking About Thinking: Evaluating Reasoning in Post-Trained Language Models](https://arxiv.org/abs/2510.16340)
*Pratham Singla,Shivank Garg,Ayush Singh,Ishan Garg,Ketan Suhaas Saichandran*

Main category: cs.CL

TL;DR: 研究探讨了大语言模型的学习意识和推理能力，发现RL模型在学习意识和泛化上优于SFT模型，但它们的推理轨迹与输出对齐较弱。


<details>
  <summary>Details</summary>
Motivation: 随着后训练技术的发展，探讨大语言模型是否了解其学习和思考的内容变得至关重要。

Method: 对多个任务进行实证评估，这些任务旨在要求学习不同的策略，同时对比不同后训练方法（SFT、DPO、GRPO）下模型的表现。

Result: RL训练的模型具备更强的行为意识和普适性，但在推理与输出对齐上存在缺陷。

Conclusion: RL训练的模型在学习意识和新任务的泛化能力方面表现更好，但在推理轨迹与最终输出之间的对齐方面表现较弱，尤其是在GRPO训练的模型中。

Abstract: Recent advances in post-training techniques have endowed Large Language
Models (LLMs) with enhanced capabilities for tackling complex, logic-intensive
tasks through the generation of supplementary planning tokens. This development
raises a fundamental question: Are these models aware of what they "learn" and
"think"? To address this, we define three core competencies: (1) awareness of
learned latent policies, (2) generalization of these policies across domains,
and (3) alignment between internal reasoning traces and final outputs. We
empirically evaluate these abilities on several tasks, each designed to require
learning a distinct policy. Furthermore, we contrast the profiles of models
post-trained via Supervised Fine-Tuning (SFT), Direct Policy Optimization
(DPO), and Group Relative Policy Optimization (GRPO). Our findings indicate
that RL-trained models not only demonstrate greater awareness of their learned
behaviors and stronger generalizability to novel, structurally similar tasks
than SFT models but also often exhibit weak alignment between their reasoning
traces and final outputs, an effect most pronounced in GRPO-trained models.

</details>


### [165] [Utilising Large Language Models for Generating Effective Counter Arguments to Anti-Vaccine Tweets](https://arxiv.org/abs/2510.16359)
*Utsav Dhanuka,Soham Poddar,Saptarshi Ghosh*

Main category: cs.CL

TL;DR: 本研究探讨了使用大型语言模型生成疫苗错误信息反驳的方法，展示了通过标签整合和微调提高反驳效果的潜力。


<details>
  <summary>Details</summary>
Motivation: 在公共健康受到社交媒体信息影响的时代，抵制疫苗怀疑主义和错误信息成为社会的关键目标。

Method: 本研究探索了大型语言模型（LLM）生成针对疫苗错误信息的反驳论点的能力，实验了各种提示策略和微调方法，并训练分类器对反疫苗推文进行多标签分类。

Result: 研究表明，各种评估方法在产生反驳方面强烈一致，整合标签描述和结构化微调提升了反驳的有效性。

Conclusion: 整合标签描述和结构化微调能够增强反驳效果，为大规模缓解疫苗错误信息提供了有希望的方法。

Abstract: In an era where public health is increasingly influenced by information
shared on social media, combatting vaccine skepticism and misinformation has
become a critical societal goal. Misleading narratives around vaccination have
spread widely, creating barriers to achieving high immunisation rates and
undermining trust in health recommendations. While efforts to detect
misinformation have made significant progress, the generation of real time
counter-arguments tailored to debunk such claims remains an insufficiently
explored area. In this work, we explore the capabilities of LLMs to generate
sound counter-argument rebuttals to vaccine misinformation. Building on prior
research in misinformation debunking, we experiment with various prompting
strategies and fine-tuning approaches to optimise counter-argument generation.
Additionally, we train classifiers to categorise anti-vaccine tweets into
multi-labeled categories such as concerns about vaccine efficacy, side effects,
and political influences allowing for more context aware rebuttals. Our
evaluation, conducted through human judgment, LLM based assessments, and
automatic metrics, reveals strong alignment across these methods. Our findings
demonstrate that integrating label descriptions and structured fine-tuning
enhances counter-argument effectiveness, offering a promising approach for
mitigating vaccine misinformation at scale.

</details>


### [166] [End-to-End Argument Mining through Autoregressive Argumentative Structure Prediction](https://arxiv.org/abs/2510.16363)
*Nilmadhab Das,Vishal Vaibhav,Yash Sunil Choudhary,V. Vijaya Saradhi,Ashish Anand*

Main category: cs.CL

TL;DR: 本研究提出了一种新的AASP框架，通过自回归方法高效提取论证结构，实验结果显示其在论证挖掘领域的优秀表现。


<details>
  <summary>Details</summary>
Motivation: 旨在解决自动化提取复杂论证结构的挑战，并且提供有效的建模方法。

Method: 提出了一种自回归论证结构预测（AASP）框架，通过条件预训练语言模型逐步构建论证结构。

Result: 在两个基准测试中，AASP达到了最先进的结果，在一个基准测试中表现强劲。

Conclusion: AASP框架在三个标准论证挖掘基准上实现了最先进的结果，显示了其在自动化论证结构提取方面的有效性。

Abstract: Argument Mining (AM) helps in automating the extraction of complex
argumentative structures such as Argument Components (ACs) like Premise, Claim
etc. and Argumentative Relations (ARs) like Support, Attack etc. in an
argumentative text. Due to the inherent complexity of reasoning involved with
this task, modelling dependencies between ACs and ARs is challenging. Most of
the recent approaches formulate this task through a generative paradigm by
flattening the argumentative structures. In contrast to that, this study
jointly formulates the key tasks of AM in an end-to-end fashion using
Autoregressive Argumentative Structure Prediction (AASP) framework. The
proposed AASP framework is based on the autoregressive structure prediction
framework that has given good performance for several NLP tasks. AASP framework
models the argumentative structures as constrained pre-defined sets of actions
with the help of a conditional pre-trained language model. These actions build
the argumentative structures step-by-step in an autoregressive manner to
capture the flow of argumentative reasoning in an efficient way. Extensive
experiments conducted on three standard AM benchmarks demonstrate that AASP
achieves state-of-theart (SoTA) results across all AM tasks in two benchmarks
and delivers strong results in one benchmark.

</details>


### [167] [Navigating through the hidden embedding space: steering LLMs to improve mental health assessment](https://arxiv.org/abs/2510.16373)
*Federico Ravenda,Seyed Ali Bahrainian,Andrea Raballo,Antonietta Mira*

Main category: cs.CL

TL;DR: 本研究提出一种高效的改进方法，利用线性变换和引导向量增强大型语言模型在心理健康评估方面的能力，取得了显著的效果。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的快速发展，尤其是在心理健康等敏感领域，如何提升这些模型的领域适应性成为重要的研究问题。

Method: 采用线性变换对特定层的激活进行处理，利用引导向量来指导模型输出。

Result: 该方法在两个任务上都取得了改进的结果：一是评估Reddit帖子对抑郁症状检测的有效性，二是完成基于用户Reddit历史的标准心理筛查问卷。

Conclusion: 研究结果强调了引导机制作为计算上高效的工具在大型语言模型的心理健康领域适应中的潜力。

Abstract: The rapid evolution of Large Language Models (LLMs) is transforming AI,
opening new opportunities in sensitive and high-impact areas such as Mental
Health (MH). Yet, despite these advancements, recent evidence reveals that
smaller-scale models still struggle to deliver optimal performance in
domain-specific applications. In this study, we present a cost-efficient yet
powerful approach to improve MH assessment capabilities of an LLM, without
relying on any computationally intensive techniques. Our lightweight method
consists of a linear transformation applied to a specific layer's activations,
leveraging steering vectors to guide the model's output. Remarkably, this
intervention enables the model to achieve improved results across two distinct
tasks: (1) identifying whether a Reddit post is useful for detecting the
presence or absence of depressive symptoms (relevance prediction task), and (2)
completing a standardized psychological screening questionnaire for depression
based on users' Reddit post history (questionnaire completion task). Results
highlight the untapped potential of steering mechanisms as computationally
efficient tools for LLMs' MH domain adaptation.

</details>


### [168] [MoReBench: Evaluating Procedural and Pluralistic Moral Reasoning in Language Models, More than Outcomes](https://arxiv.org/abs/2510.16380)
*Yu Ying Chiu,Michael S. Lee,Rachel Calcott,Brandon Handoko,Paul de Font-Reaulx,Paula Rodriguez,Chen Bo Calvin Zhang,Ziwen Han,Udari Madhushani Sehwag,Yash Maurya,Christina Q Knight,Harry R. Lloyd,Florence Bacus,Mantas Mazeika,Bing Liu,Yejin Choi,Mitchell L Gordon,Sydney Levine*

Main category: cs.CL

TL;DR: 本文研究了AI的道德推理能力，通过MoReBench基准和理论框架，评估模型在道德场景中的决策过程和偏向性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统的进步，我们愈发依赖它们做出与人类价值观一致的决策，因此理解AI的决策过程变得至关重要。

Method: 通过创建MoReBench和MoReBench-Theory来测试AI在道德推理中的应用，分析其在多种道德框架下的表现。

Result: 研究表明，现有的数学、代码和科学推理任务基准无法预测模型在道德推理中的能力，且模型对特定的道德框架表现出偏向性。

Conclusion: 这些基准通过支持过程导向的推理评估，促进了更加安全和透明的AI发展。

Abstract: As AI systems progress, we rely more on them to make decisions with us and
for us. To ensure that such decisions are aligned with human values, it is
imperative for us to understand not only what decisions they make but also how
they come to those decisions. Reasoning language models, which provide both
final responses and (partially transparent) intermediate thinking traces,
present a timely opportunity to study AI procedural reasoning. Unlike math and
code problems which often have objectively correct answers, moral dilemmas are
an excellent testbed for process-focused evaluation because they allow for
multiple defensible conclusions. To do so, we present MoReBench: 1,000 moral
scenarios, each paired with a set of rubric criteria that experts consider
essential to include (or avoid) when reasoning about the scenarios. MoReBench
contains over 23 thousand criteria including identifying moral considerations,
weighing trade-offs, and giving actionable recommendations to cover cases on AI
advising humans moral decisions as well as making moral decisions autonomously.
Separately, we curate MoReBench-Theory: 150 examples to test whether AI can
reason under five major frameworks in normative ethics. Our results show that
scaling laws and existing benchmarks on math, code, and scientific reasoning
tasks fail to predict models' abilities to perform moral reasoning. Models also
show partiality towards specific moral frameworks (e.g., Benthamite Act
Utilitarianism and Kantian Deontology), which might be side effects of popular
training paradigms. Together, these benchmarks advance process-focused
reasoning evaluation towards safer and more transparent AI.

</details>


### [169] [Probing the Hidden Talent of ASR Foundation Models for L2 English Oral Assessment](https://arxiv.org/abs/2510.16387)
*Fu-An Chao,Bi-Cheng Yan,Berlin Chen*

Main category: cs.CL

TL;DR: 本研究探讨Whisper模型在第二语言口语评估中的潜力，通过提取其嵌入特征和轻量级分类器实现了优异性能。


<details>
  <summary>Details</summary>
Motivation: 探索Whisper在第二语言口语评估中的潜在应用，而不仅仅局限于转录结果的分析。

Method: 提取Whisper模型的隐藏表示中的声学和语言特征，并在其输出上训练轻量级分类器。

Result: 在GEPT图片描述数据集上表现优越，超越了现有的先进基线，结合图像和文本提示信息进一步提高了性能。

Conclusion: Whisper模型在口语评估中的潜力巨大，能够有效编码语言能力和语义特征，尽管无需特定任务的微调。

Abstract: In this paper, we explore the untapped potential of Whisper, a
well-established automatic speech recognition (ASR) foundation model, in the
context of L2 spoken language assessment (SLA). Unlike prior studies that
extrinsically analyze transcriptions produced by Whisper, our approach goes a
step further to probe its latent capabilities by extracting acoustic and
linguistic features from hidden representations. With only a lightweight
classifier being trained on top of Whisper's intermediate and final outputs,
our method achieves strong performance on the GEPT picture-description dataset,
outperforming existing cutting-edge baselines, including a multimodal approach.
Furthermore, by incorporating image and text-prompt information as auxiliary
relevance cues, we demonstrate additional performance gains. Finally, we
conduct an in-depth analysis of Whisper's embeddings, which reveals that, even
without task-specific fine-tuning, the model intrinsically encodes both ordinal
proficiency patterns and semantic aspects of speech, highlighting its potential
as a powerful foundation for SLA and other spoken language understanding tasks.

</details>


### [170] [FrugalPrompt: Reducing Contextual Overhead in Large Language Models via Token Attribution](https://arxiv.org/abs/2510.16439)
*Syed Rifat Raiyan,Md Farhan Ishmam,Abdullah Al Imran,Mohammad Ali Moni*

Main category: cs.CL

TL;DR: FrugalPrompt是一个新型的提示压缩框架，通过保留重要标记来优化大语言模型的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 针对大语言模型在输入上下文中的冗余低效问题，提出压缩方法以降低成本、减少碳足迹并加快推断速度。

Method: 引入FrugalPrompt框架，通过两种前沿的标记归因方法GlobEnc和DecompX，对输入序列中的每个标记进行显著性评分，保留排名前k%的标记，获得稀疏的提示。

Result: 在情感分析、常识问答和摘要任务中，通过20%的提示减少，性能下降很小，但在数学推理任务中性能急剧下降，显示出对完整标记连续性的要求较高。

Conclusion: FrugalPrompt有效地压缩了大语言模型的提示，尤其在许多NLP任务中保留了重要语义信息，同时在性能和效率之间做出了平衡。

Abstract: Large language models (LLMs) owe much of their stellar performance to
expansive input contexts, yet such verbosity inflates monetary costs, carbon
footprint, and inference-time latency. Much of this overhead manifests from the
redundant low-utility tokens present in typical prompts, as only a fraction of
tokens typically carries the majority of the semantic weight. We address this
inefficiency by introducing FrugalPrompt, a novel prompt compression framework
for LLMs, which retains only the most semantically significant tokens.
Leveraging two state-of-the-art token attribution methods, GlobEnc and DecompX,
we assign salience scores to every token in an input sequence, rank them to
preserve the top-k% tokens in their original order, and obtain a sparse
frugalized prompt. We evaluate the approach across four NLP tasks: Sentiment
Analysis, Commonsense QA, Summarization, and Mathematical Reasoning, using a
suite of frontier LLMs. For the first three tasks, a 20% prompt reduction
incurs only a marginal loss in task performance, demonstrating that
contemporary LLMs can reconstruct elided context from high-salience cues. In
contrast, performance on mathematical reasoning deteriorates sharply,
reflecting a stronger dependence on complete token continuity. Further analysis
with bottom-k% and random-k% tokens reveals asymmetric performance patterns
that may suggest potential task contamination effects, wherein models may
resort to shallow memorized patterns from pretraining exposure for conventional
NLP tasks. We posit that our work contributes to a more nuanced understanding
of LLM behavior in performance-efficiency trade-offs, and delineate the
boundary between tasks tolerant to contextual sparsity and those requiring
exhaustive context. Our source code and models are available at:
https://github.com/Starscream-11813/Frugal-ICL

</details>


### [171] [TrajSelector: Harnessing Latent Representations for Efficient and Effective Best-of-N in Large Reasoning Model](https://arxiv.org/abs/2510.16449)
*Bin Yu,Xinming Wang,Shijie Lian,Haotian Li,Changti Wu,Ruina Hu,Bailing Wang,Yuliang Wei,Kai Chen*

Main category: cs.CL

TL;DR: 本文提出TrajSelector框架，通过改进推理轨迹选择方法，实现更高的性能，同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决外部TTS方法中的计算过高开销和LLM内在表示的低利用率问题。

Method: 提出TrajSelector框架，通过对采样LLM的隐藏状态进行过程级评分，使用轻量级验证器评估推理轨迹质量并聚合得分。

Result: TrajSelector在多个基准测试中表现出一致的性能提升，在Best-of-32设置下，比传统多数投票提高4.61%的准确率，且在推理成本上保持较低。

Conclusion: TrajSelector在Best-of-N框架中有效利用LLM的隐藏状态，通过轻量级验证器提高推理轨迹的选择，表现上超越现有模型，同时降低推理成本。

Abstract: Large language models (LLMs) have shown remarkable progress in complex
reasoning tasks, largely enabled by test-time scaling (TTS) paradigms that
allocate additional compute during inference. Among these, external TTS
(particularly the Best-of-N selection paradigm) yields scalable performance
improvements by selecting from multiple independently generated reasoning
trajectories. However, this approach faces key limitations: (i) the high
computational overhead of deploying process reward models, (ii) the
underutilization of the LLM's intrinsic latent representations. We introduce
TrajSelector, an efficient and effective Best-of-N framework that exploit the
hidden states in the sampler LLM for process-level scoring. A lightweight
verifier (with only 0.6B parameters) evaluates the quality of step-wise
trajectory, and then aggregates these scores to identify the optimal reasoning
trajectory. Our framework employs a fully data-driven, end-to-end training
recipe that eliminates reliance on massive step-level annotations. Experiential
results across five benchmarks demonstrate that TrajSelector delivers
consistent performance gains. In Best-of-32 settings, it surpasses majority
voting by 4.61% accuracy and outperforms existing process reward models by
4.31% to 12.21%, all while maintaining lower inference costs.

</details>


### [172] [RAVEN: Robust Advertisement Video Violation Temporal Grounding via Reinforcement Reasoning](https://arxiv.org/abs/2510.16455)
*Deyi Ji,Yuekui Yang,Haiyang Wu,Shaoping Ma,Tianrun Chen,Lanyun Zhu*

Main category: cs.CL

TL;DR: RAVEN框架通过课程强化学习结合多模态大语言模型，提升广告视频违规检测的准确性和时效性，同时展示出良好的泛化能力和实用性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有广告视频违规检测方法在时间定位、噪声标注和泛化能力上的不足。

Method: RAVEN结合课程强化学习和多模态大型语言模型，通过逐步训练策略和多层次精细的奖励机制提升推理能力，实现违规检测。

Result: RAVEN在违规类别准确性和时间间隔定位方面表现优异，线上的A/B测试结果进一步验证了其实际应用的有效性。

Conclusion: RAVEN在广告视频违规检测中展现了卓越的性能，具备强大的泛化能力，且有效提升了精度和召回率。

Abstract: Advertisement (Ad) video violation detection is critical for ensuring
platform compliance, but existing methods struggle with precise temporal
grounding, noisy annotations, and limited generalization. We propose RAVEN, a
novel framework that integrates curriculum reinforcement learning with
multimodal large language models (MLLMs) to enhance reasoning and cognitive
capabilities for violation detection. RAVEN employs a progressive training
strategy, combining precisely and coarsely annotated data, and leverages Group
Relative Policy Optimization (GRPO) to develop emergent reasoning abilities
without explicit reasoning annotations. Multiple hierarchical sophisticated
reward mechanism ensures precise temporal grounding and consistent category
prediction. Experiments on industrial datasets and public benchmarks show that
RAVEN achieves superior performances in violation category accuracy and
temporal interval localization. We also design a pipeline to deploy the RAVEN
on the online Ad services, and online A/B testing further validates its
practical applicability, with significant improvements in precision and recall.
RAVEN also demonstrates strong generalization, mitigating the catastrophic
forgetting issue associated with supervised fine-tuning.

</details>


### [173] [Agree, Disagree, Explain: Decomposing Human Label Variation in NLI through the Lens of Explanations](https://arxiv.org/abs/2510.16458)
*Pingjun Hong,Beiduo Chen,Siyao Peng,Marie-Catherine de Marneffe,Benjamin Roth,Barbara Plank*

Main category: cs.CL

TL;DR: 本研究探讨了自然语言推理数据集上注释者的标签和推理类型的一致性，发现推理类型的一致性更能反映解释的语义相似性，强调了理解注释变异的重要性。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解自然语言推理数据集中存在的人类标签差异，特别是注释者在推理类型和标签选择上可能的分歧。

Method: 利用LiTEx分类法分析两个NLI英语数据集中的注释变异，考察NLI标签一致性、解释相似性和分类法一致性，结合注释者选择偏差的因素。

Result: 注释者在标签上存在分歧的同时，提供高度相似的解释，表明表面上的分歧可能掩盖了理解上的一致性。分析还揭示了个体在解释策略和标签选择上的偏好。

Conclusion: 该研究揭示了注释者在推理类型上的一致性更能反映自由文本解释的语义相似性，而仅仅依赖标签一致性可能会掩盖潜在的理解协议。

Abstract: Natural Language Inference datasets often exhibit human label variation. To
better understand these variations, explanation-based approaches analyze the
underlying reasoning behind annotators' decisions. One such approach is the
LiTEx taxonomy, which categorizes free-text explanations in English into
reasoning types. However, previous work applying such taxonomies has focused on
within-label variation: cases where annotators agree on the final NLI label but
provide different explanations. In contrast, this paper broadens the scope by
examining how annotators may diverge not only in the reasoning type but also in
the labeling step. We use explanations as a lens to decompose the reasoning
process underlying NLI annotation and to analyze individual differences. We
apply LiTEx to two NLI English datasets and align annotation variation from
multiple aspects: NLI label agreement, explanation similarity, and taxonomy
agreement, with an additional compounding factor of annotators' selection bias.
We observe instances where annotators disagree on the label but provide highly
similar explanations, suggesting that surface-level disagreement may mask
underlying agreement in interpretation. Moreover, our analysis reveals
individual preferences in explanation strategies and label choices. These
findings highlight that agreement in reasoning types better reflects the
semantic similarity of free-text explanations than label agreement alone. Our
findings underscore the richness of reasoning-based explanations and the need
for caution in treating labels as ground truth.

</details>


### [174] [ReviewGuard: Enhancing Deficient Peer Review Detection via LLM-Driven Data Augmentation](https://arxiv.org/abs/2510.16549)
*Haoxuan Zhang,Ruochi Li,Sarthak Shrestha,Shree Harshini Mamidala,Revanth Putta,Arka Krishan Aggarwal,Ting Xiao,Junhua Ding,Haihua Chen*

Main category: cs.CL

TL;DR: 本文提出ReviewGuard，一个LLM驱动的系统，用于检测和分类缺陷审稿，旨在维护学术审稿的完整性。


<details>
  <summary>Details</summary>
Motivation: 随着提交量激增和大语言模型的广泛使用，审稿质量面临挑战，迫切需要加强缺陷审稿的检测与管理。

Method: 该研究利用四阶段LLM驱动框架，收集文献、标注审稿类型、合成数据增强，并微调模型。

Result: 构建了包含6634篇论文、24657条真实审稿和46438条合成审稿的最终语料，分析显示缺陷审稿具有更低的评分、较高的自信心和更高的负面情绪比例。

Conclusion: ReviewGuard是一个自动化系统，能够检测和分类缺陷审稿，为维持学术诚信提供重要支持。

Abstract: Peer review serves as the gatekeeper of science, yet the surge in submissions
and widespread adoption of large language models (LLMs) in scholarly evaluation
present unprecedented challenges. Recent work has focused on using LLMs to
improve review efficiency or generate insightful review content. However,
unchecked deficient reviews from both human experts and AI systems threaten to
systematically undermine the peer review ecosystem and compromise academic
integrity. To address this critical issue, we introduce ReviewGuard, an
automated system for detecting and categorizing deficient reviews. ReviewGuard
employs a comprehensive four-stage LLM-driven framework that: (1) collects ICLR
and NeurIPS papers with their corresponding reviews from OpenReview; (2)
annotates review types using GPT-4.1 with human validation; (3) addresses class
imbalance and data scarcity through LLM-driven synthetic data augmentation,
producing a final corpus of 6,634 papers, 24,657 real reviews, and 46,438
synthetic reviews; and (4) fine-tunes both encoder-based models and open source
LLMs. We perform comprehensive feature analysis of the structure and quality of
the review text. Compared to sufficient reviews, deficient reviews demonstrate
lower rating scores, higher self-reported confidence, reduced structural
complexity, and a higher proportion of negative sentiment. AI-generated text
detection reveals that, since ChatGPT's emergence, AI-generated reviews have
increased dramatically. In the evaluation of deficient review detection models,
mixed training with synthetic and real review data provides substantial
enhancements to recall and F1 scores on the binary task. This study presents
the first LLM-driven system for detecting deficient peer reviews, providing
evidence to inform AI governance in peer review while offering valuable
insights into human-AI collaboration to maintain academic integrity.

</details>


### [175] [Language over Content: Tracing Cultural Understanding in Multilingual Large Language Models](https://arxiv.org/abs/2510.16565)
*Seungho Cho,Changgeon Ko,Eui Jun Hwang,Junmyeong Lee,Huije Lee,Jong C. Park*

Main category: cs.CL

TL;DR: 该研究探讨了大语言模型在不同文化背景下的理解机制，发现语言对路径重叠的影响显著，而文化相似性并不确保内部表示的一致性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在多元文化背景下的应用，准确理解文化变得至关重要。

Method: 通过测量在不同背景下回答语义等价问题时激活路径的重叠，分析大语言模型的文化理解机制。

Result: 同语言、跨国问题的内部路径重叠更高，而跨语言、同国家问题的重叠较低，表明了语言特定模式的强烈影响。南北韩的语言对比显示了低重叠和高变异性，揭示了语言相似性并不保证内部表示的一致性。

Conclusion: 大语言模型的文化理解机制在内部激活路径的重叠程度上受到语言和文化的影响，相似语言国家之间的问答路径重叠率更高，而文化相似性不一定能确保内部表示的一致性。

Abstract: Large language models (LLMs) are increasingly used across diverse cultural
contexts, making accurate cultural understanding essential. Prior evaluations
have mostly focused on output-level performance, obscuring the factors that
drive differences in responses, while studies using circuit analysis have
covered few languages and rarely focused on culture. In this work, we trace
LLMs' internal cultural understanding mechanisms by measuring activation path
overlaps when answering semantically equivalent questions under two conditions:
varying the target country while fixing the question language, and varying the
question language while fixing the country. We also use same-language country
pairs to disentangle language from cultural aspects. Results show that internal
paths overlap more for same-language, cross-country questions than for
cross-language, same-country questions, indicating strong language-specific
patterns. Notably, the South Korea-North Korea pair exhibits low overlap and
high variability, showing that linguistic similarity does not guarantee aligned
internal representation.

</details>


### [176] [Hallucination Benchmark for Speech Foundation Models](https://arxiv.org/abs/2510.16567)
*Alkis Koudounas,Moreno La Quatra,Manuel Giollo,Sabato Marco Siniscalchi,Elena Baralis*

Main category: cs.CL

TL;DR: 本文提出SHALLOW框架，以便系统识别ASR中的幻觉现象，提供细致的模型评估，支持模型的改进。


<details>
  <summary>Details</summary>
Motivation: 传统的评估指标主要关注错误率，未能识别出幻觉内容的风险，因此需要新框架来更好地评估ASR模型。

Method: 引入SHALLOW基准框架，通过四个互补维度（词汇、语音、形态和语义）系统分类和量化ASR中的幻觉现象，并定义相应的指标。

Result: SHALLOW的指标与低词错误率（WER）下的识别质量呈强相关，但当WER上升时，这种相关性显著减弱，展现细致的错误模式和模型弱点。

Conclusion: SHALLOW框架能够有效识别和量化ASR系统中的幻觉现象，提供比传统错误率更细致的评估，助力模型的改进。

Abstract: Hallucinations in automatic speech recognition (ASR) systems refer to fluent
and coherent transcriptions produced by neural ASR models that are completely
unrelated to the underlying acoustic input (i.e., the speech signal). While
similar to conventional decoding errors in potentially compromising the
usability of transcriptions for downstream applications, hallucinations can be
more detrimental due to their preservation of syntactically and semantically
plausible structure. This apparent coherence can mislead subsequent processing
stages and introduce serious risks, particularly in critical domains such as
healthcare and law. Conventional evaluation metrics are primarily centered on
error-based metrics and fail to distinguish between phonetic inaccuracies and
hallucinations. Consequently, there is a critical need for new evaluation
frameworks that can effectively identify and assess models with a heightened
propensity for generating hallucinated content. To this end, we introduce
SHALLOW, the first benchmark framework that systematically categorizes and
quantifies hallucination phenomena in ASR along four complementary axes:
lexical, phonetic, morphological, and semantic. We define targeted metrics
within each category to produce interpretable profiles of model behavior.
Through evaluation across various architectures and speech domains, we have
found that SHALLOW metrics correlate strongly with word error rate (WER) when
recognition quality is high (i.e., low WER). Still, this correlation weakens
substantially as WER increases. SHALLOW, therefore, captures fine-grained error
patterns that WER fails to distinguish under degraded and challenging
conditions. Our framework supports specific diagnosis of model weaknesses and
provides feedback for model improvement beyond what aggregate error rates can
offer.

</details>


### [177] [AI-Generated Text Detection in Low-Resource Languages: A Case Study on Urdu](https://arxiv.org/abs/2510.16573)
*Muhammad Ammar,Hadiya Murad Hadi,Usman Majeed Butt*

Main category: cs.CL

TL;DR: 本文提出了一种乌尔都语 AI 生成文本检测框架，利用平衡数据集和先进的多语言模型，取得了91.29的F1分数，旨在打击虚假信息并推动低资源语言的 NLP 工具发展。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型生成的文本逐渐与人类写作相似，尤其是在乌尔都语这样的低资源语言中，亟需开发有效的 AI 生成文本检测工具以应对内容辨别的挑战。

Method: 本研究开发了一个包含 1800 条人类创作文本与 1800 条 AI 生成文本的平衡数据集，并进行了详细的语言学和统计分析，使用 t 检验和 Mann-Whitney U 检验评估特征显著性，随后对三种最先进的多语言变换器模型进行微调。

Result: 对多个多语言变换器模型的微调显示，mDeBERTa-v3-base 模型在测试集上的 F1 分数为 91.29，准确率为 91.26%，实现了最佳性能。

Conclusion: 本研究提出的乌尔都语 AI 生成文本检测框架在检测性能上表现出色，为乌尔都语社区打击虚假信息和学术不端提供了支持，同时也促进了低资源语言的自然语言处理工具的发展。

Abstract: Large Language Models (LLMs) are now capable of generating text that closely
resembles human writing, making them powerful tools for content creation, but
this growing ability has also made it harder to tell whether a piece of text
was written by a human or by a machine. This challenge becomes even more
serious for languages like Urdu, where there are very few tools available to
detect AI-generated text. To address this gap, we propose a novel AI-generated
text detection framework tailored for the Urdu language. A balanced dataset
comprising 1,800 humans authored, and 1,800 AI generated texts, sourced from
models such as Gemini, GPT-4o-mini, and Kimi AI was developed. Detailed
linguistic and statistical analysis was conducted, focusing on features such as
character and word counts, vocabulary richness (Type Token Ratio), and N-gram
patterns, with significance evaluated through t-tests and MannWhitney U tests.
Three state-of-the-art multilingual transformer models such as
mdeberta-v3-base, distilbert-base-multilingualcased, and xlm-roberta-base were
fine-tuned on this dataset. The mDeBERTa-v3-base achieved the highest
performance, with an F1-score 91.29 and accuracy of 91.26% on the test set.
This research advances efforts in contesting misinformation and academic
misconduct in Urdu-speaking communities and contributes to the broader
development of NLP tools for low resource languages.

</details>


### [178] [Fine-tuning of Large Language Models for Constituency Parsing Using a Sequence to Sequence Approach](https://arxiv.org/abs/2510.16604)
*Francisco Jose Cortes Delgado,Eduardo Martinez Gracia,Rafael Valencia Garcia*

Main category: cs.CL

TL;DR: 本研究通过微调大型语言模型，探索其在短语结构分析中的应用，以增强西班牙语句法教学工具MiSintaxis的能力。


<details>
  <summary>Details</summary>
Motivation: 在自然语言处理领域，充分利用大型神经模型的能力，以实现更好的句法分析，特别是为西班牙语句法教学提供支持。

Method: 使用从AnCora-ES语料库生成的训练数据，对Hugging Face库中的多个模型进行微调，利用F1评分评价其性能。

Result: 实验结果显示，不同模型在短语结构分析中的高准确性，验证了该方法的潜力。

Conclusion: 该研究展现了通过调整大型语言模型来进行短语结构分析的有效性，尤其在西班牙语的句法教学中具有应用潜力。

Abstract: Recent advances in natural language processing with large neural models have
opened new possibilities for syntactic analysis based on machine learning. This
work explores a novel approach to phrase-structure analysis by fine-tuning
large language models (LLMs) to translate an input sentence into its
corresponding syntactic structure. The main objective is to extend the
capabilities of MiSintaxis, a tool designed for teaching Spanish syntax.
Several models from the Hugging Face repository were fine-tuned using training
data generated from the AnCora-ES corpus, and their performance was evaluated
using the F1 score. The results demonstrate high accuracy in phrase-structure
analysis and highlight the potential of this methodology.

</details>


### [179] [All You Need is One: Capsule Prompt Tuning with a Single Vector](https://arxiv.org/abs/2510.16670)
*Yiyang Liu,James C. Liang,Heng Fan,Wenhao Yang,Yiming Cui,Xiaotian Han,Lifu Huang,Dongfang Liu,Qifan Wang,Cheng Han*

Main category: cs.CL

TL;DR: Capsule Prompt-Tuning通过整合实例感知和任务感知信息提高了提示调整的效率和性能，几乎无参数损失。


<details>
  <summary>Details</summary>
Motivation: 当前基于提示的学习方法依赖繁琐的网格搜索以找到最佳提示长度，并需要大量提示，这增加了计算负担，而缺乏实例感知信息限制了任务感知提示设计的效果。

Method: 引入实例感知信息作为引导，结合Capsule Prompt-Tuning方法，实现在不增加额外微调的情况下，优化提示调整的性能。

Result: 实验证明，我们的方法在多种语言任务上表现优越（例如，在T5-Large上实现84.03\%的平均准确率），并在Llama3.2-1B模型上保持0.003\%的参数效率。

Conclusion: Capsule Prompt-Tuning (CaPT)可以在几乎无参数的情况下通过整合实例感知和任务感知信息，显著提高模型在语言任务上的性能，同时保持高参数效率。

Abstract: Prompt-based learning has emerged as a parameter-efficient finetuning (PEFT)
approach to facilitate Large Language Model (LLM) adaptation to downstream
tasks by conditioning generation with task-aware guidance. Despite its
successes, current prompt-based learning methods heavily rely on laborious grid
searching for optimal prompt length and typically require considerable number
of prompts, introducing additional computational burden. Worse yet, our pioneer
findings indicate that the task-aware prompt design is inherently limited by
its absence of instance-aware information, leading to a subtle attention
interplay with the input sequence. In contrast, simply incorporating
instance-aware information as a part of the guidance can enhance the
prompt-tuned model performance without additional fine-tuning. Moreover, we
find an interesting phenomenon, namely "attention anchor", that incorporating
instance-aware tokens at the earliest position of the sequence can successfully
preserve strong attention to critical structural information and exhibit more
active attention interaction with all input tokens. In light of our
observation, we introduce Capsule Prompt-Tuning (CaPT), an efficient and
effective solution that leverages off-the-shelf, informative instance semantics
into prompt-based learning. Our approach innovatively integrates both
instance-aware and task-aware information in a nearly parameter-free manner
(i.e., one single capsule prompt). Empirical results demonstrate that our
method can exhibit superior performance across various language tasks (e.g.,
84.03\% average accuracy on T5-Large), serving as an "attention anchor," while
enjoying high parameter efficiency (e.g., 0.003\% of model parameters on
Llama3.2-1B).

</details>


### [180] [Temporal Understanding under Deictic Frame of Reference](https://arxiv.org/abs/2510.16685)
*Damin Zhang,Julia Rayz*

Main category: cs.CL

TL;DR: 本研究评估了语言模型在动态时间参考框架下的时间理解能力，发现其在近时事件上表现较好，但在远时情境中的理解能力较弱。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在时间认知方面的局限性，并评估其对时间事件关系的适应能力。

Method: 通过TUuD框架评估语言模型在不同时间框架下对时间事件关系的理解能力。

Result: 评估的四种语言模型在时间参考点动态变化下显示出一定的适应性，但在远期情境中的适应性减弱。

Conclusion: 语言模型对时间事件的理解和评价存在一定的适应性，但在参考框架的变化和时间距离方面仍然较为脆弱。

Abstract: Understanding time is fundamental to human cognition, where temporal
experience is often conceptualized through spatial metaphors grounded in
sensory-motor experience. For example, "summer is approaching" parallels "We
are approaching the summer". In such expressions, humans rely on a frame of
reference (FoR) to interpret meaning relative to a particular viewpoint.
Extending this concept to time, a temporal frame of reference (t-FoR) defines
how temporal relations are perceived relative to an experiencer's moment of
"now". While Large Language Models (LLMs) have shown remarkable advances in
natural language understanding, their ability to interpret and reason about
time remains limited. In this work, we introduce TUuD (Temporal Understanding
under Deictic t-FoR), a framework that evaluates how LLMs interpret time-event
and event-event relations when the reference point of "now" dynamically shifts
along a timeline. Following recent work on temporal cognition
\cite{li2025other}, LLMs are prompted to rate the similarity between the
current moment and a target event from 0.00 (completely dissimilar) to 1.00
(highly similar), where similarity quantifies perceived temporal alignment
between the two points. Our results show that four evaluated LLMs exhibit
measurable adaptation to a deictic t-FoR, with similarity ratings peaking
around the present and decreasing toward past and future events. The
adaptation, however, weakens beyond near-term contexts, suggesting that while
LLMs display partial human-like temporal cognition, their temporal reasoning
remains sensitive to reference-frame shifts and temporal distance.

</details>


### [181] [Investigating the Impact of Rationales for LLMs on Natural Language Understanding](https://arxiv.org/abs/2510.16686)
*Wenhang Shi,Shuqing Bian,Yiren Chen,Xinyi Zhang,Zhe Zhao,Pengfei Hu,Wei Lu,Xiaoyong Du*

Main category: cs.CL

TL;DR: 本研究探讨了链式推理对自然语言理解任务的影响，发现随着模型规模增长，其表现优于直接标签预测，并开发了增强推理的方法，部分方法取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 大多数研究侧重于推理在数学、符号和常识推理任务中的作用，而忽视了其对自然语言理解任务的重要影响。

Method: 构建了一个包含推理的高质量自然语言理解数据集（NLURC），并开发了多种增强推理的方法进行系统探索。

Result: 研究发现，随着模型规模的增加，链式推理的推理性能超过了直接标签预测；大多数增强推理的训练方法表现不如仅用标签训练，但有一种设计方法取得了 consistent 的提升；使用推理训练的LLM在未见过的NLU任务上展示出显著的性能提升，与十倍模型相比，且在可解释性上与商业LLM相当。

Conclusion: 引入链式推理（CoT）可以显著提升自然语言理解任务的性能，尤其是当模型规模增大时，显示出正相关性。

Abstract: Chain-of-thought (CoT) rationales, which provide step-by-step reasoning to
derive final answers, benefit LLMs in both inference and training.
Incorporating rationales, either by generating them before answering during
inference, or by placing them before or after the original answers during
training - significantly improves model performance on mathematical, symbolic
and commonsense reasoning tasks. However, most work focuses on the role of
rationales in these reasoning tasks, overlooking their potential impact on
other important tasks like natural language understanding (NLU) tasks. In this
work, we raise the question: Can rationales similarly benefit NLU tasks? To
conduct a systematic exploration, we construct NLURC, a comprehensive and
high-quality NLU dataset collection with rationales, and develop various
rationale-augmented methods. Through exploring the applicability of these
methods on NLU tasks using the dataset, we uncover several potentially
surprising findings: (1) CoT inference shifts from hindering NLU performance to
surpassing direct label prediction as model size grows, indicating a positive
correlation. (2) Most rationale-augmented training methods perform worse than
label-only training, with one specially designed method consistently achieving
improvements. (3) LLMs trained with rationales achieve significant performance
gains on unseen NLU tasks, rivaling models ten times their size, while
delivering interpretability on par with commercial LLMs.

</details>


### [182] [Natural Language Processing Applications in Cardiology: A Narrative Review](https://arxiv.org/abs/2510.16708)
*Kailai Yang,Yan Leng,Xin Zhang,Tianlin Zhang,Paul Thompson,Bernard Keavney,Maciej Tomaszewski,Sophia Ananiadou*

Main category: cs.CL

TL;DR: 本综述分析了2014-2025年期间心脏病学领域的自然语言处理研究，涵盖265篇文献，展示了该领域的多样性和方法的演变趋势。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病在现代社会中日益普遍，影响全球健康，而自然语言处理技术可以帮助分析不同类型的非结构化数据，以深入了解心脏病学领域。

Method: 通过查询六个文献数据库，筛选出265篇相关的自然语言处理应用于心血管疾病的文献，并从多维度进行分析。

Result: 我们揭示了自然语言处理研究的广泛性，并分析了不同维度之间的多样性和近年来方法的演变。

Conclusion: 本综述提供了对心脏病学领域自然语言处理研究的全面概述，揭示了在多维度上的多样性，并通过时间分析展示了方法的演变和变化趋势。

Abstract: Cardiovascular disease has become increasingly prevalent in modern society
and has a significant effect on global health and well-being. Heart-related
conditions are intricate, multifaceted disorders, which may be influenced by a
combination of genetic predispositions, lifestyle choices, and various
socioeconomic and clinical factors. Information regarding these potentially
complex interrelationships is dispersed among diverse types of textual data,
which include patient narratives, medical records, and scientific literature,
among others. Natural language processing (NLP) techniques have increasingly
been adopted as a powerful means to analyse and make sense of this vast amount
of unstructured data. This, in turn, can allow healthcare professionals to gain
deeper insights into the cardiology field, which has the potential to
revolutionize current approaches to the diagnosis, treatment, and prevention of
cardiac problems. This review provides a detailed overview of NLP research in
cardiology between 2014 and 2025. We queried six literature databases to find
articles describing the application of NLP techniques in the context of a range
of different cardiovascular diseases. Following a rigorous screening process,
we identified a total of 265 relevant articles. We analysed each article from
multiple dimensions, i.e., NLP paradigm types, cardiology-related task types,
cardiovascular disease types, and data source types. Our analysis reveals
considerable diversity within each of these dimensions, thus demonstrating the
considerable breadth of NLP research within the field. We also perform a
temporal analysis, which illustrates the evolution and changing trends in NLP
methods employed over the last decade that we cover. To our knowledge, the
review constitutes the most comprehensive overview of NLP research in
cardiology to date.

</details>


### [183] [The Chameleon Nature of LLMs: Quantifying Multi-Turn Stance Instability in Search-Enabled Language Models](https://arxiv.org/abs/2510.16712)
*Shivam Ratnakar,Sanjay Raghavendra*

Main category: cs.CL

TL;DR: 本研究通过Chameleon Benchmark Dataset评估了大语言模型在多轮对话中表现出的立场不稳定性，发现知识多样性不足是关键原因，并强调了在医疗、法律和金融系统中部署LLM前需进行严格一致性评估。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在面对矛盾问题时的反应， выявить其存在的根本缺陷。

Method: 使用Chameleon Benchmark Dataset进行系统调查，评估模型的立场变化及知识多样性。

Result: 新提出的Chameleon Score和Source Re-use Rate揭示了LLM在知识多样性和立场变化方面的严重问题，影响模型在关键领域的应用。

Conclusion: 大语言模型在多轮对话中存在显著的立场不稳定性，尤其是在被检索系统启用时，这种现象影响了其可靠性。

Abstract: Integration of Large Language Models with search/retrieval engines has become
ubiquitous, yet these systems harbor a critical vulnerability that undermines
their reliability. We present the first systematic investigation of "chameleon
behavior" in LLMs: their alarming tendency to shift stances when presented with
contradictory questions in multi-turn conversations (especially in
search-enabled LLMs). Through our novel Chameleon Benchmark Dataset, comprising
17,770 carefully crafted question-answer pairs across 1,180 multi-turn
conversations spanning 12 controversial domains, we expose fundamental flaws in
state-of-the-art systems. We introduce two theoretically grounded metrics: the
Chameleon Score (0-1) that quantifies stance instability, and Source Re-use
Rate (0-1) that measures knowledge diversity. Our rigorous evaluation of
Llama-4-Maverick, GPT-4o-mini, and Gemini-2.5-Flash reveals consistent
failures: all models exhibit severe chameleon behavior (scores 0.391-0.511),
with GPT-4o-mini showing the worst performance. Crucially, small
across-temperature variance (less than 0.004) suggests the effect is not a
sampling artifact. Our analysis uncovers the mechanism: strong correlations
between source re-use rate and confidence (r=0.627) and stance changes
(r=0.429) are statistically significant (p less than 0.05), indicating that
limited knowledge diversity makes models pathologically deferential to query
framing. These findings highlight the need for comprehensive consistency
evaluation before deploying LLMs in healthcare, legal, and financial systems
where maintaining coherent positions across interactions is critical for
reliable decision support.

</details>


### [184] [so much depends / upon / a whitespace: Why Whitespace Matters for Poets and LLMs](https://arxiv.org/abs/2510.16713)
*Sriharsh Bhyravajjula,Melanie Walsh,Anna Preus,Maria Antoniak*

Main category: cs.CL

TL;DR: 本研究探讨了空白在诗歌中的作用，分析了其在不同来源和时期的使用情况，并强调了为大型语言模型处理数据时考虑空白的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管诗歌作为一种艺术形式受到广泛欢迎，但空白的使用在自然语言处理领域未受到足够重视，因此本研究旨在填补这一空白。

Method: 使用了来自Poetry Foundation的19k首英文诗歌的语料库，分析了空白的使用，并与LLM生成的诗歌和未发表的诗歌进行了比较。

Result: 研究发现，诗歌中的空白使用与诗人的艺术选择密切相关，并且在不同时间段、诗歌形式和数据源中存在显著差异。

Conclusion: 该研究揭示了空白在诗歌中的重要性，并探讨了其在不同情境下的表现，为诗歌的自然语言处理研究提供了新的视角和数据源。

Abstract: Whitespace is a critical component of poetic form, reflecting both adherence
to standardized forms and rebellion against those forms. Each poem's whitespace
distribution reflects the artistic choices of the poet and is an integral
semantic and spatial feature of the poem. Yet, despite the popularity of poetry
as both a long-standing art form and as a generation task for large language
models (LLMs), whitespace has not received sufficient attention from the NLP
community. Using a corpus of 19k English-language published poems from Poetry
Foundation, we investigate how 4k poets have used whitespace in their works. We
release a subset of 2.8k public-domain poems with preserved formatting to
facilitate further research in this area. We compare whitespace usage in the
published poems to (1) 51k LLM-generated poems, and (2) 12k unpublished poems
posted in an online community. We also explore whitespace usage across time
periods, poetic forms, and data sources. Additionally, we find that different
text processing methods can result in significantly different representations
of whitespace in poetry data, motivating us to use these poems and whitespace
patterns to discuss implications for the processing strategies used to assemble
pretraining datasets for LLMs.

</details>


### [185] [Beacon: Single-Turn Diagnosis and Mitigation of Latent Sycophancy in Large Language Models](https://arxiv.org/abs/2510.16727)
*Sanskar Pandey,Ruhaan Chopra,Angkul Puniya,Sohom Pal*

Main category: cs.CL

TL;DR: 本研究介绍了 Beacon，一种基准测试模型对偏见的测量，探讨了真相与顺从之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型中存在的 sycophancy 偏见，即用户同意的偏好高于原则性推理。

Method: 推出 Beacon，一个单轮强制选择基准，独立于对话上下文测量真相准确性与顺从偏见之间的张力。

Result: 在 12 个最先进模型的评估中，sycophancy 解构为稳定的语言和情感子偏见，并且每种偏见随模型容量的增加而增加。

Conclusion: Beacon 提供了一种可测量的规范性误泛化形式，有助于研究和减轻大型生成系统的对齐漂移。

Abstract: Large language models internalize a structural trade-off between truthfulness
and obsequious flattery, emerging from reward optimization that conflates
helpfulness with polite submission. This latent bias, known as sycophancy,
manifests as a preference for user agreement over principled reasoning. We
introduce Beacon, a single-turn forced-choice benchmark that isolates this bias
independent of conversational context, enabling precise measurement of the
tension between factual accuracy and submissive bias. Evaluations across twelve
state-of-the-art models reveal that sycophancy decomposes into stable
linguistic and affective sub-biases, each scaling with model capacity. We
further propose prompt-level and activation-level interventions that modulate
these biases in opposing directions, exposing the internal geometry of
alignment as a dynamic manifold between truthfulness and socially compliant
judgment. Beacon reframes sycophancy as a measurable form of normative
misgeneralization, providing a reproducible foundation for studying and
mitigating alignment drift in large-scale generative systems.

</details>


### [186] [Who's Asking? Simulating Role-Based Questions for Conversational AI Evaluation](https://arxiv.org/abs/2510.16829)
*Navreet Kaur,Hoda Ayad,Hayoung Jung,Shravika Mittal,Munmun De Choudhury,Tanushree Mitra*

Main category: cs.CL

TL;DR: 研究提出了一种新的框架CoRUS，强调了用户角色在对话AI响应中的重要性，通过模拟基于角色的问题，揭示了不同角色对语言模型输出的系统性影响。


<details>
  <summary>Details</summary>
Motivation: 通过考虑提问者的社会和个人背景，提高语言模型在敏感领域（如药物使用障碍）中的响应适应性和无污名性。

Method: 提出一个基于社区的模拟框架CoRUS，建立了用户角色的分类，并生成大量角色驱动的问题以进行评估。

Result: 评估显示，不同角色在获取支持类反应和知识内容方面存在显著差异，支持性反应在患者和照顾者中更高，而知识内容在从业者眼中更丰富。

Conclusion: 本研究表明，用户的角色隐含信息会影响语言模型的反应，并提供了一种以角色为导向的对话AI评估方法。

Abstract: Language model users often embed personal and social context in their
questions. The asker's role -- implicit in how the question is framed --
creates specific needs for an appropriate response. However, most evaluations,
while capturing the model's capability to respond, often ignore who is asking.
This gap is especially critical in stigmatized domains such as opioid use
disorder (OUD), where accounting for users' contexts is essential to provide
accessible, stigma-free responses. We propose CoRUS (COmmunity-driven Roles for
User-centric Question Simulation), a framework for simulating role-based
questions. Drawing on role theory and posts from an online OUD recovery
community (r/OpiatesRecovery), we first build a taxonomy of asker roles --
patients, caregivers, practitioners. Next, we use it to simulate 15,321
questions that embed each role's goals, behaviors, and experiences. Our
evaluations show that these questions are both highly believable and comparable
to real-world data. When used to evaluate five LLMs, for the same question but
differing roles, we find systematic differences: vulnerable roles, such as
patients and caregivers, elicit more supportive responses (+17%) and reduced
knowledge content (-19%) in comparison to practitioners. Our work demonstrates
how implicitly signaling a user's role shapes model responses, and provides a
methodology for role-informed evaluation of conversational AI.

</details>


### [187] [LC-Eval: A Bilingual Multi-Task Evaluation Benchmark for Long-Context Understanding](https://arxiv.org/abs/2510.16783)
*Sheikh Jubair,Arwa Omayrah,Amal Alshammari,Alhanoof Althnian,Abdulhamed Alothaimen,Norah A. Alzahrani,Shahad D. Alzaidi,Nora Al-Twairesh,Abdulmohsen Al-Thubaity*

Main category: cs.CL

TL;DR: 本文介绍了LC-Eval评估基准，旨在检验大型语言模型在长上下文理解方面的能力，提出了多项挑战任务，并展示了评估结果。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的快速发展，需要一种有效的评估方法来衡量它们在长上下文理解中的性能。

Method: 提出了四项新的挑战性任务来评估模型的深度推理和信息处理能力。

Result: 研究表明，即使是表现优异的模型，如GPT-4o，在某些任务上也面临困难，凸显了评估基准的复杂性和严谨性。

Conclusion: LC-Eval是一种新颖的评估基准，显著挑战了当前大型语言模型在长上下文理解中的能力。

Abstract: Recent advancements in Large Language Models (LLMs) have demonstrated
sophisticated capabilities, including the ability to process and comprehend
extended contexts. These emergent capabilities necessitate rigorous evaluation
methods to effectively assess their performance in long-context understanding.
In this paper, we present \textbf{LC-Eval}, a bilingual, multi-task evaluation
benchmark designed to evaluate long-context understanding in English and
Arabic, targeting context lengths ranging from 4k to over 128k tokens. LC-Eval
introduces four novel and challenging tasks: multi-document question answering,
bilingual question answering, claim verification within a paragraph, and
multiple-choice questions based on long contexts. These tasks are designed to
assess LLMs' abilities in deep reasoning, document comprehension, information
tracing, and bilingual information extraction and understanding. The benchmark
includes datasets in both Arabic and English for each task, allowing for a
comparative analysis of their performance across different text genres.
Evaluations were conducted on both open-weight and closed LLMs, with results
indicating that LC-Eval presents significant challenges. Even high-performing
models, such as GPT-4o, struggled with certain tasks, highlighting the
complexity and rigor of the benchmark.

</details>


### [188] [MOSAIC: Masked Objective with Selective Adaptation for In-domain Contrastive Learning](https://arxiv.org/abs/2510.16797)
*Vera Pavlova,Mohammed Makhlouf*

Main category: cs.CL

TL;DR: 提出了一种名为MOSAIC的多阶段框架，其通过联合优化掩蔽语言建模和对比目标，提升句子嵌入模型的领域适应性。


<details>
  <summary>Details</summary>
Motivation: 解决大规模通用句子嵌入模型在专门领域适应的挑战。

Method: 通过统一训练管道联合优化掩蔽语言建模（MLM）和对比目标，实现领域相关表示的有效学习。

Result: 在高资源和低资源领域的实验中，NDCG@10提高了最高达13.4%。

Conclusion: MOSAIC有效改进了句子嵌入模型在专业领域的适应性，提升了性能。

Abstract: We introduce MOSAIC (Masked Objective with Selective Adaptation for In-domain
Contrastive learning), a multi-stage framework for domain adaptation of
sentence embedding models that incorporates joint domain-specific masked
supervision. Our approach addresses the challenges of adapting large-scale
general-domain sentence embedding models to specialized domains. By jointly
optimizing masked language modeling (MLM) and contrastive objectives within a
unified training pipeline, our method enables effective learning of
domain-relevant representations while preserving the robust semantic
discrimination properties of the original model. We empirically validate our
approach on both high-resource and low-resource domains, achieving improvements
up to 13.4% in NDCG@10 (Normalized Discounted Cumulative Gain) over strong
general-domain baselines. Comprehensive ablation studies further demonstrate
the effectiveness of each component, highlighting the importance of balanced
joint supervision and staged adaptation.

</details>


### [189] [Knowing the Facts but Choosing the Shortcut: Understanding How Large Language Models Compare Entities](https://arxiv.org/abs/2510.16815)
*Hans Hergen Lehmann,Jae Hee Lee,Steven Schockaert,Stefan Wermter*

Main category: cs.CL

TL;DR: 研究大型语言模型在知识推理任务中的表现，发现小模型受到表面启发式的影响显著，而大模型能够在可靠性高的情况下依赖数值知识。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在知识推理任务中的可靠性，尤其是在面对明确的数值特征时，模型是否能做出正确判断。

Method: 通过实体比较任务，评估LLM在基于知识的推理中的表现，关注模型是依赖真实知识还是表面启发式。

Result: 发现LLMs在有足够数值知识的情况下，仍然常常做出与知识相悖的预测，并确定了影响预测的三种启发式偏见。

Conclusion: 较小的LLMs通常受到表面启发式的影响，而较大的LLMs能够选择性地依赖可靠的数值知识，解释了其在性能上的优越性。

Abstract: Large Language Models (LLMs) are increasingly used for knowledge-based
reasoning tasks, yet understanding when they rely on genuine knowledge versus
superficial heuristics remains challenging. We investigate this question
through entity comparison tasks by asking models to compare entities along
numerical attributes (e.g., ``Which river is longer, the Danube or the
Nile?''), which offer clear ground truth for systematic analysis. Despite
having sufficient numerical knowledge to answer correctly, LLMs frequently make
predictions that contradict this knowledge. We identify three heuristic biases
that strongly influence model predictions: entity popularity, mention order,
and semantic co-occurrence. For smaller models, a simple logistic regression
using only these surface cues predicts model choices more accurately than the
model's own numerical predictions, suggesting heuristics largely override
principled reasoning. Crucially, we find that larger models (32B parameters)
selectively rely on numerical knowledge when it is more reliable, while smaller
models (7--8B parameters) show no such discrimination, which explains why
larger models outperform smaller ones even when the smaller models possess more
accurate knowledge. Chain-of-thought prompting steers all models towards using
the numerical features across all model sizes.

</details>


### [190] [Cross-Genre Authorship Attribution via LLM-Based Retrieve-and-Rerank](https://arxiv.org/abs/2510.16819)
*Shantanu Agarwal,Joel Barry,Steven Fincke,Scott Miller*

Main category: cs.CL

TL;DR: 本文提出了一种两阶段的检索-重排序框架，通过针对性的数据策划策略，为跨流派作者归属任务带来了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的跨流派作者归属系统在作者特定语言模式的识别上缺乏有效的方法，常利用信息检索中的通用策略导致性能不佳。

Method: 采用奇特的数据策划策略对重排序器进行训练，以学习作者特征信号，并通过LLM为基础的检索-重排序管道进行实施。

Result: 在HIATUS的HRS1和HRS2跨流派作者归属基准上，相较于之前的最先进技术，我们的管道在Success@8指标上分别提高了22.3和34.4分。

Conclusion: 通过引入针对性的数据显示策略，我们提出的两阶段检索-重排序框架显著改善了跨流派作者归属任务的效果。

Abstract: Authorship attribution (AA) is the task of identifying the most likely author
of a query document from a predefined set of candidate authors. We introduce a
two-stage retrieve-and-rerank framework that finetunes LLMs for cross-genre AA.
Unlike the field of information retrieval (IR), where retrieve-and-rerank is a
de facto strategy, cross-genre AA systems must avoid relying on topical cues
and instead learn to identify author-specific linguistic patterns that are
independent of the text's subject matter (genre/domain/topic). Consequently,
for the reranker, we demonstrate that training strategies commonly used in IR
are fundamentally misaligned with cross-genre AA, leading to suboptimal
behavior. To address this, we introduce a targeted data curation strategy that
enables the reranker to effectively learn author-discriminative signals. Using
our LLM-based retrieve-and-rerank pipeline, we achieve substantial gains of
22.3 and 34.4 absolute Success@8 points over the previous state-of-the-art on
HIATUS's challenging HRS1 and HRS2 cross-genre AA benchmarks.

</details>


### [191] [FinSight: Towards Real-World Financial Deep Research](https://arxiv.org/abs/2510.16844)
*Jiajie Jin,Yuyao Zhang,Yimeng Xu,Hongjin Qian,Yutao Zhu,Zhicheng Dou*

Main category: cs.CL

TL;DR: FinSight是一个新型多智能体框架，通过CAVM和迭代视觉增强机制，生成高质量的财务报告，显著提高了报告的准确性和分析深度。


<details>
  <summary>Details</summary>
Motivation: 财务报告生成是劳动密集且智力要求高的过程，现有AI系统难以完全自动化，亟需改进。

Method: 采用CAVM架构，结合外部数据和工具，利用可执行代码进行灵活的数据收集、分析和报告生成。

Result: 实验表明，FinSight在事实准确性、分析深度和呈现质量方面显著优于领先的深度研究系统。

Conclusion: FinSight显著优于所有基准系统，接近人类专家的质量，提供高质量的财务报告生成。

Abstract: Generating professional financial reports is a labor-intensive and
intellectually demanding process that current AI systems struggle to fully
automate. To address this challenge, we introduce FinSight (Financial InSight),
a novel multi agent framework for producing high-quality, multimodal financial
reports. The foundation of FinSight is the Code Agent with Variable Memory
(CAVM) architecture, which unifies external data, designed tools, and agents
into a programmable variable space, enabling flexible data collection, analysis
and report generation through executable code. To ensure professional-grade
visualization, we propose an Iterative Vision-Enhanced Mechanism that
progressively refines raw visual outputs into polished financial charts.
Furthermore, a two stage Writing Framework expands concise Chain-of-Analysis
segments into coherent, citation-aware, and multimodal reports, ensuring both
analytical depth and structural consistency. Experiments on various company and
industry-level tasks demonstrate that FinSight significantly outperforms all
baselines, including leading deep research systems in terms of factual
accuracy, analytical depth, and presentation quality, demonstrating a clear
path toward generating reports that approach human-expert quality.

</details>


### [192] [Does Visual Grounding Enhance the Understanding of Embodied Knowledge in Large Language Models?](https://arxiv.org/abs/2510.16924)
*Zhihui Yang,Yupei Wang,Kaijie Mo,Zhe Zhao,Renfen Hu*

Main category: cs.CL

TL;DR: 本研究建立新基准测试多模态语言模型的感知知识，结果显示视觉语言模型未表现优于文本模型，特别是在视觉任务上的表现较差。


<details>
  <summary>Details</summary>
Motivation: 探讨视觉定向是否增强多模态语言模型的身体现实理解能力，与纯文本模型相比。

Method: 通过基于心理学感知理论的基准，评估模型在多个感官方面的感知能力，并进行向量比较和问答任务。

Result: 对30个最先进的语言模型进行比较，发现视觉语言模型在任务表现上未优于纯文本模型，尤其在视觉维度表现较差。

Conclusion: 视觉语言模型在感知知识理解方面未能优于纯文本模型，且在视觉任务上表现不佳，强调了对更有效整合感知知识的需求。

Abstract: Despite significant progress in multimodal language models (LMs), it remains
unclear whether visual grounding enhances their understanding of embodied
knowledge compared to text-only models. To address this question, we propose a
novel embodied knowledge understanding benchmark based on the perceptual theory
from psychology, encompassing visual, auditory, tactile, gustatory, olfactory
external senses, and interoception. The benchmark assesses the models'
perceptual abilities across different sensory modalities through vector
comparison and question-answering tasks with over 1,700 questions. By comparing
30 state-of-the-art LMs, we surprisingly find that vision-language models
(VLMs) do not outperform text-only models in either task. Moreover, the models
perform significantly worse in the visual dimension compared to other sensory
dimensions. Further analysis reveals that the vector representations are easily
influenced by word form and frequency, and the models struggle to answer
questions involving spatial perception and reasoning. Our findings underscore
the need for more effective integration of embodied knowledge in LMs to enhance
their understanding of the physical world.

</details>


### [193] [ChiKhaPo: A Large-Scale Multilingual Benchmark for Evaluating Lexical Comprehension and Generation in Large Language Models](https://arxiv.org/abs/2510.16928)
*Emily Chang,Niyati Bafna*

Main category: cs.CL

TL;DR: ChiKhaPo 是一个新基准，旨在评估生成模型的多语言能力，覆盖超过 2700 种语言，并显示当前前沿模型在此方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的针对大型语言模型的基准主要集中于高或中资源语言，而对于全球超过 3800 种书写语言的基础语言能力缺乏评估。

Method: 介绍了一种名为 ChiKhaPo 的新基准，包括 8 个不同难度的子任务，旨在评估生成模型的词汇理解和生成能力。

Result: ChiKhaPo 覆盖超过 2700 种语言，并展示了 6 款最先进的模型在这一基准下的挑战，探讨了影响性能分数的多种因素。

Conclusion: ChiKhaPo 提供了对生成模型进行多语言基准评估的新方法，并表明现有的前沿模型在该基准上的表现不足。

Abstract: Existing benchmarks for large language models (LLMs) are largely restricted
to high- or mid-resource languages, and often evaluate performance on
higher-order tasks in reasoning and generation. However, plenty of evidence
points to the fact that LLMs lack basic linguistic competence in the vast
majority of the world's 3800+ written languages. We introduce ChiKhaPo,
consisting of 8 subtasks of varying difficulty designed to evaluate the lexical
comprehension and generation abilities of generative models. ChiKhaPo draws on
existing lexicons, monolingual data, and bitext, and provides coverage for
2700+ languages for 2 subtasks, surpassing any existing benchmark in terms of
language coverage. We further show that 6 SOTA models struggle on our
benchmark, and discuss the factors contributing to performance scores,
including language family, language resourcedness, task, and comprehension
versus generation directions. With ChiKhaPo, we hope to enable and encourage
the massively multilingual benchmarking of LLMs.

</details>


### [194] [Prompt-MII: Meta-Learning Instruction Induction for LLMs](https://arxiv.org/abs/2510.16932)
*Emily Xiao,Yixiao Zeng,Ada Chen,Chin-Jou Li,Amanda Bertsch,Graham Neubig*

Main category: cs.CL

TL;DR: 本文提出了PROMPT-MII方法，通过元学习生成紧凑指令，有效提升模型性能，同时降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 面对大语言模型在新任务中的高推理成本，提出一种新的指令归纳方法以提高效率。

Method: 通过强化学习（RL）框架进行元学习，生成针对任意新数据集的紧凑指令。

Result: 在90个未见任务上，PROMPT-MII在下游模型质量上提升4-9个F1分数（相对提高10-20%），同时所需tokens减少3-13倍。

Conclusion: PROMPT-MII能够有效生成紧凑的指令，匹配大语言模型的性能，同时显著降低推理成本。

Abstract: A popular method to adapt large language models (LLMs) to new tasks is
in-context learning (ICL), which is effective but incurs high inference costs
as context length grows. In this paper we propose a method to perform
instruction induction, where we take training examples and reduce them to a
compact but descriptive prompt that can achieve performance comparable to ICL
over the full training set. Specifically, we propose PROMPT-MII, a
reinforcement learning (RL) based framework to meta-learn an instruction
induction model that can generate compact instructions on the fly for an
arbitrary new dataset. We train on over 3,000 diverse classification datasets
from the HuggingFace hub, and evaluate on 90 unseen tasks. PROMPT-MII improves
downstream model quality by 4-9 F1 points (10-20% relative), matching ICL
performance while requiring 3-13x fewer tokens.

</details>


### [195] [Parameter-Efficient Fine-Tuning for Low-Resource Languages: A Comparative Study of LLMs for Bengali Hate Speech Detection](https://arxiv.org/abs/2510.16985)
*Akif Islam,Mohd Ruhul Ameen*

Main category: cs.CL

TL;DR: 本研究首次在班加语仇恨言论检测中应用参数高效微调（PEFT），展示了其在低资源语言处理中的有效性。


<details>
  <summary>Details</summary>
Motivation: 针对班加语社交媒体上针对女性和青少年的仇恨言论激增的问题，寻求有效的检测方法。

Method: 使用LoRA和QLoRA对三种指令调优的大型语言模型进行参数高效微调。

Result: Llama-3.2-3B模型达到92.23%的最高F1分数，证明了PEFT的有效性。

Conclusion: PEFT证明是班加语及相关低资源语言的有效策略。

Abstract: Bengali social media platforms have witnessed a sharp increase in hate
speech, disproportionately affecting women and adolescents. While datasets such
as BD-SHS provide a basis for structured evaluation, most prior approaches rely
on either computationally costly full-model fine-tuning or proprietary APIs.
This paper presents the first application of Parameter-Efficient Fine-Tuning
(PEFT) for Bengali hate speech detection using LoRA and QLoRA. Three
instruction-tuned large language models - Gemma-3-4B, Llama-3.2-3B, and
Mistral-7B - were fine-tuned on the BD-SHS dataset of 50,281 annotated
comments. Each model was adapted by training fewer than 1% of its parameters,
enabling experiments on a single consumer-grade GPU. The results show that
Llama-3.2-3B achieved the highest F1-score of 92.23%, followed by Mistral-7B at
88.94% and Gemma-3-4B at 80.25%. These findings establish PEFT as a practical
and replicable strategy for Bengali and related low-resource languages.

</details>


### [196] [Back to Bytes: Revisiting Tokenization Through UTF-8](https://arxiv.org/abs/2510.16987)
*Amit Moryossef,Clara Meister,Pavel Stepachev,Desmond Elliott*

Main category: cs.CL

TL;DR: UTF8Tokenizer是一种高效的字节级tokenizer，提供更快的速度和更低的资源使用，支持HuggingFace，并在语言建模收敛性方面表现优越。


<details>
  <summary>Details</summary>
Motivation: 旨在改进现有的字节级tokenization方法，通过减少不必要的复杂性来提高速度和效率，并在模型训练和推理中优化性能。

Method: 通过使用C0控制字节来编码特殊行为，避免了引入超出范围的ID和辅助token，使得实现简单且可分享的embedding表。

Result: 我们的方法在token化速度上提升了14倍，主设备传输减少了8倍，同时在模型收敛性方面也有显著改进。

Conclusion: UTF8Tokenizer是一种高效的字节级tokenizer，对文本的UTF-8编码进行了精准的映射，并且实现了更快的token化速度和更低的主设备传输耗时。

Abstract: We present UTF8Tokenizer, a minimalist byte-level tokenizer that maps text
exactly to IDs corresponding to the bytes underlying the text's UTF-8 encoding
(e.g., byte x09 is token ID 9). Unlike prior byte-level approaches (Xue et al.,
2021; Pagnoni et al., 2025), our implementation never introduces out-of-range
IDs (i.e. there is no token ID 256) or auxiliary tokens: all special behavior
(e.g., padding, boundaries, conversation structure, attention segments, tool
calling, "thinking" spans, etc.) is encoded using C0 control bytes - just as
ASCII was originally designed to embed control information alongside printable
text. These design principles yield practical benefits: (1) faster tokenization
(14x) and significantly lower host-device transfer (8x less than int64); (2)
simple, shareable 256*d embedding tables that can be aligned across models; and
(3) a training-time enhancement via bit-biased embeddings, which exposes
per-byte bit structure and can be added to the embedding table post-training,
removing inference costs. Our HuggingFace-compatible implementation improves
language modeling convergence.

</details>


### [197] [Vocab Diet: Reshaping the Vocabulary of LLMs with Vector Arithmetic](https://arxiv.org/abs/2510.17001)
*Yuval Reif,Guy Kaplan,Roy Schwartz*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的词汇设计方法，通过使用共享基础形式和转换向量，减少了词汇条目，并增强了多语言覆盖率，且对模型性能影响较小。


<details>
  <summary>Details</summary>
Motivation: 标准的标记化算法将词形变化视为不同的标记，导致词汇被表面形式变体填满，牺牲了不常用词和多语言覆盖率。

Method: 我们提出了一种紧凑的词汇重塑方法，通过共享基础形式和转换向量来组合表面形式，而不是为每个表面形式分配独特的标记。

Result: 我们应用该方法于多个大型语言模型和五种语言，去除了多达10%的词汇条目，同时扩大了对词汇以外单词的覆盖，且对下游性能影响最小。

Conclusion: 我们的研究推动了词汇设计的基础性重新思考，从字符串枚举转向利用语言基本结构的组合词汇。

Abstract: Large language models (LLMs) were shown to encode word form variations, such
as "walk"->"walked", as linear directions in embedding space. However, standard
tokenization algorithms treat these variations as distinct tokens -- filling
the size-capped vocabulary with surface form variants (e.g., "walk", "walking",
"Walk"), at the expense of less frequent words and multilingual coverage. We
show that many of these variations can be captured by transformation vectors --
additive offsets that yield the appropriate word's representation when applied
to the base form word embedding -- in both the input and output spaces.
Building on this, we propose a compact reshaping of the vocabulary: rather than
assigning unique tokens to each surface form, we compose them from shared base
form and transformation vectors (e.g., "walked" = "walk" + past tense). We
apply our approach to multiple LLMs and across five languages, removing up to
10% of vocabulary entries -- thereby freeing space to allocate new, more
diverse tokens. Importantly, we do so while also expanding vocabulary coverage
to out-of-vocabulary words, with minimal impact on downstream performance, and
without modifying model weights. Our findings motivate a foundational
rethinking of vocabulary design, moving from string enumeration to a
compositional vocabulary that leverages the underlying structure of language.

</details>


### [198] [Online Learning Defense against Iterative Jailbreak Attacks via Prompt Optimization](https://arxiv.org/abs/2510.17006)
*Masahiro Kaneko,Zeerak Talat,Timothy Baldwin*

Main category: cs.CL

TL;DR: 本研究提出了一种新颖的动态防御框架，通过在线学习和提示优化，显著提高了语言模型对迭代越狱方法的防御能力与响应质量。


<details>
  <summary>Details</summary>
Motivation: 迭代越狱方法对大型语言模型的有效攻击，现有防御机制未能主动打断其动态试错循环，迫切需要新的防御策略。

Method: 采用基于强化学习的提示优化方法，并引入了过去方向梯度减幅（PDGD）来预防过拟合。

Result: 通过在三种大型语言模型上进行实验，证明了该方法在防御能力上显著优于五种现有防御方法，并提升了无害任务的响应质量。

Conclusion: 本研究提出的动态防御框架通过在线学习及时响应迭代越狱方法，显著提高了大型语言模型的安全性和响应质量。

Abstract: Iterative jailbreak methods that repeatedly rewrite and input prompts into
large language models (LLMs) to induce harmful outputs -- using the model's
previous responses to guide each new iteration -- have been found to be a
highly effective attack strategy. Despite being an effective attack strategy
against LLMs and their safety mechanisms, existing defenses do not proactively
disrupt this dynamic trial-and-error cycle. In this study, we propose a novel
framework that dynamically updates its defense strategy through online learning
in response to each new prompt from iterative jailbreak methods. Leveraging the
distinctions between harmful jailbreak-generated prompts and typical harmless
prompts, we introduce a reinforcement learning-based approach that optimizes
prompts to ensure appropriate responses for harmless tasks while explicitly
rejecting harmful prompts. Additionally, to curb overfitting to the narrow band
of partial input rewrites explored during an attack, we introduce
Past-Direction Gradient Damping (PDGD). Experiments conducted on three LLMs
show that our approach significantly outperforms five existing defense methods
against five iterative jailbreak methods. Moreover, our results indicate that
our prompt optimization strategy simultaneously enhances response quality for
harmless tasks.

</details>


### [199] [DiscoTrack: A Multilingual LLM Benchmark for Discourse Tracking](https://arxiv.org/abs/2510.17013)
*Lanni Bu,Lauren Levin,Amir Zeldes*

Main category: cs.CL

TL;DR: DiscoTrack是一个新的多语言基准，专注于话语理解的隐性信息和推断，评估结果显示任务复杂。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM基准主要关注显性信息的提取，缺乏对隐性信息和语用推断的挑战性评估。

Method: 提出了一种新的基准DiscoTrack，涵盖12种语言和四种话语理解等级，并进行了评估。

Result: 通过DiscoTrack的评估，发现对话追踪任务在多语言和大文档背景下仍然十分具有挑战性。

Conclusion: DiscoTrack基准测试展示了多种任务在多语言和话语理解层面的复杂性，即使是最先进的模型也面临挑战。

Abstract: Recent LLM benchmarks have tested models on a range of phenomena, but are
still focused primarily on natural language understanding for extraction of
explicit information, such as QA or summarization, with responses often tar-
geting information from individual sentences. We are still lacking more
challenging, and im- portantly also multilingual, benchmarks focus- ing on
implicit information and pragmatic infer- ences across larger documents in the
context of discourse tracking: integrating and aggregating information across
sentences, paragraphs and multiple speaker utterances. To this end, we present
DiscoTrack, an LLM benchmark target- ing a range of tasks across 12 languages
and four levels of discourse understanding: salience recognition, entity
tracking, discourse relations and bridging inference. Our evaluation shows that
these tasks remain challenging, even for state-of-the-art models.

</details>


### [200] [Mapping from Meaning: Addressing the Miscalibration of Prompt-Sensitive Language Models](https://arxiv.org/abs/2510.17028)
*Kyle Cox,Jiawei Xu,Yikun Han,Rong Xu,Tianhao Li,Chi-Yang Hsu,Tianlong Chen,Walter Gerych,Ying Ding*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型的提示敏感性，提出了一种改进不确定性校准的新方法，并引入了一种不确定性分解的新指标，以揭示模型对提示的敏感性。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型在提示敏感性下的表现及其对模型不确定性输出的影响，以改进模型的可靠性和一致性。

Method: 通过在语义“概念空间”中进行重新采样和改写扰动，以减小泛化误差来改善不确定性校准。并引入了一种新的不确定性分解指标，改进了基于熵的分解方法。

Result: 通过新的方法和指标，证明了重新采样能够提高不确定性校准，同时 quantifies 了 LLM 输出不确定性与提示敏感性的关系。

Conclusion: 本研究提出了一种新的方法来改进对提示敏感的大型语言模型（LLM）的不确定性校准，并证明部分LLM在其输入的意义上缺乏一致的推理能力。

Abstract: An interesting behavior in large language models (LLMs) is prompt
sensitivity. When provided with different but semantically equivalent versions
of the same prompt, models may produce very different distributions of answers.
This suggests that the uncertainty reflected in a model's output distribution
for one prompt may not reflect the model's uncertainty about the meaning of the
prompt. We model prompt sensitivity as a type of generalization error, and show
that sampling across the semantic ``concept space'' with paraphrasing
perturbations improves uncertainty calibration without compromising accuracy.
Additionally, we introduce a new metric for uncertainty decomposition in
black-box LLMs that improves upon entropy-based decomposition by modeling
semantic continuities in natural language generation. We show that this
decomposition metric can be used to quantify how much LLM uncertainty is
attributed to prompt sensitivity. Our work introduces a new way to improve
uncertainty calibration in prompt-sensitive language models, and provides
evidence that some LLMs fail to exhibit consistent general reasoning about the
meanings of their inputs.

</details>


### [201] [Investigating Thinking Behaviours of Reasoning-Based Language Models for Social Bias Mitigation](https://arxiv.org/abs/2510.17062)
*Guoqing Luo,Iffat Maab,Lili Mou,Junichi Yamagishi*

Main category: cs.CL

TL;DR: 本研究分析了大型语言模型在社会偏见中的思维机制，发现了两个主要的失败模式，并提出了有效的减轻方法，取得了良好的实验结果。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在社会偏见情境下的潜在行为，尤其是其推理过程中对社会刻板印象的依赖及无关信息的引入。

Method: 通过系统研究语言模型在社会偏见场景中的思维过程，揭示了模型在此过程中存在的两个失败模式，并提出了一种基于提示的减轻策略。

Result: 通过在问答和开放式基准上的实验，证明了该方法在减少模型偏见的同时不降低其准确性，反而提升了性能。

Conclusion: 本文提出了一种轻量级的基于提示的减轻方法，能够有效降低语言模型的偏见，同时保持或提高准确性。

Abstract: While reasoning-based large language models excel at complex tasks through an
internal, structured thinking process, a concerning phenomenon has emerged that
such a thinking process can aggregate social stereotypes, leading to biased
outcomes. However, the underlying behaviours of these language models in social
bias scenarios remain underexplored. In this work, we systematically
investigate mechanisms within the thinking process behind this phenomenon and
uncover two failure patterns that drive social bias aggregation: 1) stereotype
repetition, where the model relies on social stereotypes as its primary
justification, and 2) irrelevant information injection, where it fabricates or
introduces new details to support a biased narrative. Building on these
insights, we introduce a lightweight prompt-based mitigation approach that
queries the model to review its own initial reasoning against these specific
failure patterns. Experiments on question answering (BBQ and StereoSet) and
open-ended (BOLD) benchmarks show that our approach effectively reduces bias
while maintaining or improving accuracy.

</details>


### [202] [DVAGen: Dynamic Vocabulary Augmented Generation](https://arxiv.org/abs/2510.17115)
*Wei Du,Nuowei Liu,Jie Wang,Jiahao Kuang,Tao Ji,Xiaoling Wang,Yuanbin Wu*

Main category: cs.CL

TL;DR: DVAGen是一个开源框架，旨在提升语言模型的动态词汇能力和推理效率，支持实时结果检查。


<details>
  <summary>Details</summary>
Motivation: 解决现有动态词汇方法在代码库碎片化、对现代L大型语言模型支持不足及推理扩展性差等问题。

Method: 引入DVAGen框架，模块化动态词汇增强语言模型的训练、评估和可视化过程，同时支持CLI和WebUI工具。

Result: 验证了动态词汇方法在现代L大型语言模型上的有效性，并提升了批量推理的吞吐量。

Conclusion: DVAGen是一个开源的、统一的框架，旨在解决固定词汇量语言模型的局限性，支持动态词汇增强，并优化推理性能。

Abstract: Language models trained with a fixed vocabulary struggle to generalize to
novel or out-of-vocabulary words, limiting their flexibility in handling
diverse token combinations. Existing dynamic vocabulary approaches attempt to
address this limitation but face challenges such as fragmented codebases, lack
of support for modern LLMs, and limited inference scalability. To overcome
these issues, we introduce DVAGen, a fully open-source, unified framework
designed for training, evaluation, and visualization of dynamic
vocabulary-augmented language models. Our framework modularizes the pipeline
for ease of customization, integrates seamlessly with open-source LLMs, and is
the first to provide both CLI and WebUI tools for real-time result inspection.
We validate the effectiveness of dynamic vocabulary methods on modern LLMs and
demonstrate support for batch inference, significantly improving inference
throughput.

</details>


### [203] [Rethinking On-policy Optimization for Query Augmentation](https://arxiv.org/abs/2510.17139)
*Zhichao Xu,Shengyao Zhuang,Xueguang Ma,Bingsen Chen,Yijun Tian,Fengran Mo,Jie Cao,Vivek Srikumar*

Main category: cs.CL

TL;DR: 对提示生成与RL查询增强方法进行了系统比较，提出了新混合方法OPQE，表现优于单一方法。


<details>
  <summary>Details</summary>
Motivation: 针对现有提示和RL方法在查询增强中的不足，通过比较其效果来发现更优的解决方案。

Method: 进行了一系列系统比较，评估提示生成和基于强化学习的查询增强方法在不同基准上的表现。

Result: 简单的、无训练的查询增强方法在性能上往往与昂贵的RL方法相当或更优，尤其是在强大的LLM使用情况下。

Conclusion: 提出了一种新的混合方法OPQE，结合了提示生成和RL优化，展示出更优的检索性能。

Abstract: Recent advances in large language models (LLMs) have led to a surge of
interest in query augmentation for information retrieval (IR). Two main
approaches have emerged. The first prompts LLMs to generate answers or
pseudo-documents that serve as new queries, relying purely on the model's
parametric knowledge or contextual information. The second applies
reinforcement learning (RL) to fine-tune LLMs for query rewriting, directly
optimizing retrieval metrics. While having respective advantages and
limitations, the two approaches have not been compared under consistent
experimental conditions. In this work, we present the first systematic
comparison of prompting-based and RL-based query augmentation across diverse
benchmarks, including evidence-seeking, ad hoc, and tool retrieval. Our key
finding is that simple, training-free query augmentation often performs on par
with, or even surpasses, more expensive RL-based counterparts, especially when
using powerful LLMs. Motivated by this discovery, we introduce a novel hybrid
method, On-policy Pseudo-document Query Expansion (OPQE), which, instead of
rewriting a query, the LLM policy learns to generate a pseudo-document that
maximizes retrieval performance, thus merging the flexibility and generative
structure of prompting with the targeted optimization of RL. We show OPQE
outperforms both standalone prompting and RL-based rewriting, demonstrating
that a synergistic approach yields the best results. Our implementation is made
available to facilitate reproducibility.

</details>


### [204] [Understanding and Improving Length Generalization in Hierarchical Sparse Attention Models](https://arxiv.org/abs/2510.17196)
*Jiaqi Leng,Xiang Hu,Junxiong Wang,Jianguo Li,Wei Wu,Yucheng Lu*

Main category: cs.CL

TL;DR: 本研究分析了影响长上下文语言模型性能的核心组件，提出了三项关键设计原则，并实现了新的状态-of-the-art的长度外推能力。


<details>
  <summary>Details</summary>
Motivation: 理解长上下文语言模型的核心架构原理，以提升其处理长上下文的能力。

Method: 系统性分析了基于块的稀疏注意力模型，进行全面的消融研究。

Result: 成功提出三项关键设计原则，为未来高能力的长上下文语言模型的开发提供了清晰且实证基础的指导。

Conclusion: 通过结合三项设计原则，我们建立了新的训练无关的长度外推状态，成功实现了从4K上下文扩展到3200万标记的模型。

Abstract: Effectively processing long contexts is a critical challenge for language
models. While standard Transformers are limited by quadratic complexity and
poor length extrapolation, alternative architectures like sliding window
attention and state space models sacrifice the ability to effectively utilize
the full context due to their fixed-size memory. Chunk-based sparse attention
has emerged as a promising paradigm for extreme length generalization, yet the
key architectural principles underpinning its success are not yet fully
understood. In this work, we present a systematic dissection of these models to
identify the core components driving their performance. Through a unified
framework and comprehensive ablation studies, we demonstrate that a combination
of three design principles is critical: (1) an expressive, non-linear Chunk
Encoder with a dedicated CLS token to produce representations for retrieval;
(2) a Bypassing Residual Path to stably integrate retrieved global information
without it being overridden by the local residual stream; and (3) enforced
selection sparsity during pre-training to bridge the train-test distribution
gap. We provide a theoretical motivation for intra-chunk information processing
and landmark generation. By combining these principles, we establish a new
state-of-the-art for training-free length extrapolation, successfully
generalizing models trained on a 4K context to 32 million tokens on RULER and
BABILong. Our findings provide a clear and empirically-grounded set of design
principles for developing future, highly-capable long-context language models.

</details>


### [205] [Wisdom is Knowing What not to Say: Hallucination-Free LLMs Unlearning via Attention Shifting](https://arxiv.org/abs/2510.17210)
*Chenchen Tan,Youyang Qu,Xinghao Li,Hui Zhang,Shujie Cui,Cunjian Chen,Longxiang Gao*

Main category: cs.CL

TL;DR: 本文提出的AS框架解决了现有去学习方法在效用和响应可靠性上的矛盾，显著提升了LLM的性能与可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着计算能力的提高和AI辅助决策的必要性，LLMs的应用日渐增加；而现有去学习方法在保持模型效用和减少虚假响应之间存在重要矛盾。

Method: 提出了一种新的Attention-Shifting (AS)框架，通过重要性感知抑制和注意力引导保留增强两种注意力干预措施，实现选择性去学习。

Result: 实验结果显示，AS框架在ToFU基准上提高了15%的准确率，在TDEC基准上提高了10%的准确率，同时保持了竞争力的无虚假去学习效果。

Conclusion: 引入的AS框架在模型的保留性能、模拟真实响应方面表现优越，达到现有最先进的去学习方法所不能比拟的效果。

Abstract: The increase in computing power and the necessity of AI-assisted
decision-making boost the growing application of large language models (LLMs).
Along with this, the potential retention of sensitive data of LLMs has spurred
increasing research into machine unlearning. However, existing unlearning
approaches face a critical dilemma: Aggressive unlearning compromises model
utility, while conservative strategies preserve utility but risk hallucinated
responses. This significantly limits LLMs' reliability in knowledge-intensive
applications. To address this, we introduce a novel Attention-Shifting (AS)
framework for selective unlearning. AS is driven by two design objectives: (1)
context-preserving suppression that attenuates attention to fact-bearing tokens
without disrupting LLMs' linguistic structure; and (2) hallucination-resistant
response shaping that discourages fabricated completions when queried about
unlearning content. AS realizes these objectives through two attention-level
interventions, which are importance-aware suppression applied to the unlearning
set to reduce reliance on memorized knowledge and attention-guided retention
enhancement that reinforces attention toward semantically essential tokens in
the retained dataset to mitigate unintended degradation. These two components
are jointly optimized via a dual-loss objective, which forms a soft boundary
that localizes unlearning while preserving unrelated knowledge under
representation superposition. Experimental results show that AS improves
performance preservation over the state-of-the-art unlearning methods,
achieving up to 15% higher accuracy on the ToFU benchmark and 10% on the TDEC
benchmark, while maintaining competitive hallucination-free unlearning
effectiveness. Compared to existing methods, AS demonstrates a superior balance
between unlearning effectiveness, generalization, and response reliability.

</details>


### [206] [StreamingThinker: Large Language Models Can Think While Reading](https://arxiv.org/abs/2510.17238)
*Junlong Tong,Yingqi Fan,Anhao Zhao,Yunpu Ma,Xiaoyu Shen*

Main category: cs.CL

TL;DR: 本文提出了一种流式思维框架StreamingThinker，使得LLM可以在阅读过程中进行推理，显著提升了推理效率和响应速度。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理模式在获取完整输入后才开始思考，导致不必要的延迟并且在动态场景中对早期信息的注意力下降。

Method: 通过整合流式思维生成、流式约束训练和流式并行推理设计一种新的思维范式。

Result: StreamingThinker在多个推理任务上展现出与批处理思维相当的性能，同时推理前的令牌等待时间减少80%，最终答案生成的时间延迟减少超过60%。

Conclusion: StreamingThinker提供了一种新颖的流式思维框架，能够显著减少推理的延迟，同时保持与批处理思维相当的性能。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in
chain of thought (CoT) reasoning. However, the current LLM reasoning paradigm
initiates thinking only after the entire input is available, which introduces
unnecessary latency and weakens attention to earlier information in dynamic
scenarios. Inspired by human cognition of thinking while reading, we first
design a \textit{\textbf{streaming thinking}} paradigm for LLMs, where
reasoning unfolds in the order of input and further adjusts its depth once
reading is complete. We instantiate this paradigm with
\textit{StreamingThinker}, a framework that enables LLMs to think while reading
through the integration of streaming CoT generation, streaming-constraint
training, and streaming parallel inference. Specifically, StreamingThinker
employs streaming reasoning units with quality control for CoT generation,
enforces order-preserving reasoning through streaming attention masks and
position encoding, and leverages parallel KV caches that decouple input
encoding from reasoning generation, thereby ensuring alignment and enabling
true concurrency. We evaluate StreamingThinker on the Qwen3 model family across
math reasoning, logical reasoning, and context-based QA reasoning tasks.
Experimental results show that the StreamingThinker preserves performance
comparable to batch thinking, while yielding an 80\% reduction in token waiting
before the onset of reasoning and a more than 60\% reduction in time-level
latency for producing the final answer, demonstrating the effectiveness of the
streaming paradigm for LLM reasoning. Code will be released at
\href{https://github.com/EIT-NLP/StreamingLLM/tree/main/StreamingThinker}{this
repository.}

</details>


### [207] [From Preferences to Prejudice: The Role of Alignment Tuning in Shaping Social Bias in Video Diffusion Models](https://arxiv.org/abs/2510.17247)
*Zefan Cai,Haoyi Qiu,Haozhe Zhao,Ke Wan,Jiachen Li,Jiuxiang Gu,Wen Xiao,Nanyun Peng,Junjie Hu*

Main category: cs.CL

TL;DR: 本研究提出VideoBiasEval框架，系统评估视频生成中的社会偏见，发现对齐调整会增强并稳定偏见，呼吁在视频生成中重视偏见的评估与缓解。


<details>
  <summary>Details</summary>
Motivation: 随着视频扩散模型在文本到视频生成中的进步，尽管视觉质量提高，但也可能无意中编码和放大社会偏见，因此需要系统性地追踪这些偏见的演变。

Method: 该研究提出了VideoBiasEval框架，通过事件驱动的提示策略和多层次的指标来评估视频生成中的社会表征和偏见。

Result: 使用VideoBiasEval框架，研究首次进行了全面的偏见分析，揭示了人类偏好数据集中偏见的放大及其在对齐调整视频扩散模型中的传播，指出了对齐调整过程中的代表性偏见的增强和稳定性。

Conclusion: 该研究强调了在视频生成过程中，尤其是在对齐调整中，偏见的放大和时间稳定性的问题，呼吁对齐过程中的偏见评估和缓解，以确保视频生成的公平性和社会责任。

Abstract: Recent advances in video diffusion models have significantly enhanced
text-to-video generation, particularly through alignment tuning using reward
models trained on human preferences. While these methods improve visual
quality, they can unintentionally encode and amplify social biases. To
systematically trace how such biases evolve throughout the alignment pipeline,
we introduce VideoBiasEval, a comprehensive diagnostic framework for evaluating
social representation in video generation. Grounded in established social bias
taxonomies, VideoBiasEval employs an event-based prompting strategy to
disentangle semantic content (actions and contexts) from actor attributes
(gender and ethnicity). It further introduces multi-granular metrics to
evaluate (1) overall ethnicity bias, (2) gender bias conditioned on ethnicity,
(3) distributional shifts in social attributes across model variants, and (4)
the temporal persistence of bias within videos. Using this framework, we
conduct the first end-to-end analysis connecting biases in human preference
datasets, their amplification in reward models, and their propagation through
alignment-tuned video diffusion models. Our results reveal that alignment
tuning not only strengthens representational biases but also makes them
temporally stable, producing smoother yet more stereotyped portrayals. These
findings highlight the need for bias-aware evaluation and mitigation throughout
the alignment process to ensure fair and socially responsible video generation.

</details>


### [208] [How News Feels: Understanding Affective Bias in Multilingual Headlines for Human-Centered Media Design](https://arxiv.org/abs/2510.17252)
*Mohd Ruhul Ameen,Akif Islam,Abu Saleh Musa Miah,Ayesha Siddiqua,Jungpil Shin*

Main category: cs.CL

TL;DR: 本研究通过对孟加拉新闻的情感分析，揭示负面情感在媒体报道中的主导地位，并建议设计人性化新闻聚合平台以帮助读者识别潜在的情感框架。


<details>
  <summary>Details</summary>
Motivation: 探讨新闻媒体如何通过情感框架塑造公众情绪，并识别情感偏见。

Method: 使用Gemma-3 4B进行零样本推理，对30万条孟加拉新闻标题及其内容进行大规模情感分析。

Result: 发现负面情感（特别是愤怒、恐惧和失望）在报道中占主导地位，并且各媒体在相似故事的情感表现上存在显著差异。

Conclusion: 研究显示，新闻媒体通过情感框架影响公众情绪，负面情感明显占主导。

Abstract: News media often shape the public mood not only by what they report but by
how they frame it. The same event can appear calm in one outlet and alarming in
another, reflecting subtle emotional bias in reporting. Negative or emotionally
charged headlines tend to attract more attention and spread faster, which in
turn encourages outlets to frame stories in ways that provoke stronger
reactions. This research explores that tendency through large-scale emotion
analysis of Bengali news. Using zero-shot inference with Gemma-3 4B, we
analyzed 300000 Bengali news headlines and their content to identify the
dominant emotion and overall tone of each. The findings reveal a clear
dominance of negative emotions, particularly anger, fear, and disappointment,
and significant variation in how similar stories are emotionally portrayed
across outlets. Based on these insights, we propose design ideas for a
human-centered news aggregator that visualizes emotional cues and helps readers
recognize hidden affective framing in daily news.

</details>


### [209] [Explainability of Large Language Models: Opportunities and Challenges toward Generating Trustworthy Explanations](https://arxiv.org/abs/2510.17256)
*Shahin Atakishiyev,Housam K. B. Babiker,Jiayi Dai,Nawshad Farruque,Teruaki Hayashi,Nafisa Sadaf Hriti,Md Abed Rahman,Iain Smith,Mi-Young Kim,Osmar R. Zaïane,Randy Goebel*

Main category: cs.CL

TL;DR: 本论文探讨了大语言模型的可解释性问题，分析了在医疗和自动驾驶领域的应用，提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 鉴于现有语言模型的预测和推理中存在的误差（即幻觉现象），我们希望更好地理解和解释这些模型的内部机制。

Method: 通过文献综述与实验研究，分析了局部可解释性与机械可解释性的方法，并探讨了在医疗和自动驾驶领域的应用。

Result: 本研究展示了大语言模型在医疗和自动驾驶领域的可解释性实验，分析了对信任的影响，并总结了可解释性现状及未来挑战。

Conclusion: 本研究总结了当前大语言模型可解释性所面临的问题，并提出了未来人类对齐和可信赖的可解释性方向。

Abstract: Large language models have exhibited impressive performance across a broad
range of downstream tasks in natural language processing. However, how a
language model predicts the next token and generates content is not generally
understandable by humans. Furthermore, these models often make errors in
prediction and reasoning, known as hallucinations. These errors underscore the
urgent need to better understand and interpret the intricate inner workings of
language models and how they generate predictive outputs. Motivated by this
gap, this paper investigates local explainability and mechanistic
interpretability within Transformer-based large language models to foster trust
in such models. In this regard, our paper aims to make three key contributions.
First, we present a review of local explainability and mechanistic
interpretability approaches and insights from relevant studies in the
literature. Furthermore, we describe experimental studies on explainability and
reasoning with large language models in two critical domains -- healthcare and
autonomous driving -- and analyze the trust implications of such explanations
for explanation receivers. Finally, we summarize current unaddressed issues in
the evolving landscape of LLM explainability and outline the opportunities,
critical challenges, and future directions toward generating human-aligned,
trustworthy LLM explanations.

</details>


### [210] [TaxoAlign: Scholarly Taxonomy Generation Using Language Models](https://arxiv.org/abs/2510.17263)
*Avishek Lahiri,Yufang Hou,Debarshi Kumar Sanyal*

Main category: cs.CL

TL;DR: 本文介绍了一种新的自动化分类生成方法TaxoAlign，并通过CS-TaxoBench基准测试验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的自动文献调查生成方法未能将生成的调查结构与人类专家撰写的调查进行比较，促使我们研发新的方法。

Method: 提出了TaxoAlign，一种三阶段的基于主题的指令引导方法，用于学术分类生成，并建立了严格的自动评估框架。

Result: 通过对CS-TaxoBench进行评估，结果显示TaxoAlign在多个指标上优于基线。

Conclusion: TaxoAlign方法在几乎所有评估指标上超越了基线方法，证明了其在自动化分类生成中的有效性。

Abstract: Taxonomies play a crucial role in helping researchers structure and navigate
knowledge in a hierarchical manner. They also form an important part in the
creation of comprehensive literature surveys. The existing approaches to
automatic survey generation do not compare the structure of the generated
surveys with those written by human experts. To address this gap, we present
our own method for automated taxonomy creation that can bridge the gap between
human-generated and automatically-created taxonomies. For this purpose, we
create the CS-TaxoBench benchmark which consists of 460 taxonomies that have
been extracted from human-written survey papers. We also include an additional
test set of 80 taxonomies curated from conference survey papers. We propose
TaxoAlign, a three-phase topic-based instruction-guided method for scholarly
taxonomy generation. Additionally, we propose a stringent automated evaluation
framework that measures the structural alignment and semantic coherence of
automatically generated taxonomies in comparison to those created by human
experts. We evaluate our method and various baselines on CS-TaxoBench, using
both automated evaluation metrics and human evaluation studies. The results
show that TaxoAlign consistently surpasses the baselines on nearly all metrics.
The code and data can be found at https://github.com/AvishekLahiri/TaxoAlign.

</details>


### [211] [Addressing Antisocial Behavior in Multi-Party Dialogs Through Multimodal Representation Learning](https://arxiv.org/abs/2510.17289)
*Hajar Bakarou,Mohamed Sinane El Messoussi,Anaïs Ollagnier*

Main category: cs.CL

TL;DR: 该研究利用CyberAgressionAdo-Large数据库，探索多方会话中的反社会行为，发现多模态模型在各项检测任务中优于单模态模型。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的反社会行为对平台安全和社会福祉构成越来越大的风险，尤其是在多方会话环境下的研究相对缺乏。

Method: 使用CyberAgressionAdo-Large数据集，通过六种基于文本和八种基于图的表示学习方法进行评估，分析词汇线索、互动动态及其多模态融合。

Result: 多模态模型在滥用检测、欺凌行为分析和欺凌同伴群体识别任务上优于单模态方法，具体表现为mBERT + WD-SGCN模型在滥用检测中达到0.718的最佳结果。

Conclusion: 多模态模型优于单模态基线， late fusion模型的表现最佳，尤其在滥用检测中取得了显著成果。

Abstract: Antisocial behavior (ASB) on social media -- including hate speech,
harassment, and cyberbullying -- poses growing risks to platform safety and
societal well-being. Prior research has focused largely on networks such as X
and Reddit, while \textit{multi-party conversational settings} remain
underexplored due to limited data. To address this gap, we use
\textit{CyberAgressionAdo-Large}, a French open-access dataset simulating ASB
in multi-party conversations, and evaluate three tasks: \textit{abuse
detection}, \textit{bullying behavior analysis}, and \textit{bullying
peer-group identification}. We benchmark six text-based and eight graph-based
\textit{representation-learning methods}, analyzing lexical cues, interactional
dynamics, and their multimodal fusion. Results show that multimodal models
outperform unimodal baselines. The late fusion model \texttt{mBERT + WD-SGCN}
achieves the best overall results, with top performance on abuse detection
(0.718) and competitive scores on peer-group identification (0.286) and
bullying analysis (0.606). Error analysis highlights its effectiveness in
handling nuanced ASB phenomena such as implicit aggression, role transitions,
and context-dependent hostility.

</details>


### [212] [Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation](https://arxiv.org/abs/2510.17354)
*Chenghao Zhang,Guanting Dong,Xinyu Yang,Zhicheng Dou*

Main category: cs.CL

TL;DR: 本研究提出了Nyx，一个旨在改进混合模态检索与生成的新模型，通过高质量数据集和两阶段训练提高了视觉语言任务的生成质量。


<details>
  <summary>Details</summary>
Motivation: 目前的RAG系统主要集中于单一模态文本文档，难以处理包含混合模态的信息，这限制了其在现实场景中的应用。

Method: 提出Nyx，一个统一的混合模态-混合模态检索器，通过四阶段的自动化流程生成和过滤混合模态问答对数据集NyxQA，并采用两阶段训练框架。

Result: 通过在NyxQA和多种开放源检索数据集上进行预训练，再通过监督微调，Nyx成功调整了检索输出以符合生成偏好，并在视觉-语言生成任务中显著提升了生成质量。

Conclusion: Nyx在标准文本RAG基准测试中表现出竞争力，并在更普遍和现实的URAG设置中出色表现，大幅提高了视觉语言任务的生成质量。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for
enhancing large language models (LLMs) by retrieving relevant documents from an
external corpus. However, existing RAG systems primarily focus on unimodal text
documents, and often fall short in real-world scenarios where both queries and
documents may contain mixed modalities (such as text and images). In this
paper, we address the challenge of Universal Retrieval-Augmented Generation
(URAG), which involves retrieving and reasoning over mixed-modal information to
improve vision-language generation. To this end, we propose Nyx, a unified
mixed-modal to mixed-modal retriever tailored for URAG scenarios. To mitigate
the scarcity of realistic mixed-modal data, we introduce a four-stage automated
pipeline for generation and filtering, leveraging web documents to construct
NyxQA, a dataset comprising diverse mixed-modal question-answer pairs that
better reflect real-world information needs. Building on this high-quality
dataset, we adopt a two-stage training framework for Nyx: we first perform
pre-training on NyxQA along with a variety of open-source retrieval datasets,
followed by supervised fine-tuning using feedback from downstream
vision-language models (VLMs) to align retrieval outputs with generative
preferences. Experimental results demonstrate that Nyx not only performs
competitively on standard text-only RAG benchmarks, but also excels in the more
general and realistic URAG setting, significantly improving generation quality
in vision-language tasks.

</details>


### [213] [The Atomic Instruction Gap: Instruction-Tuned LLMs Struggle with Simple, Self-Contained Directives](https://arxiv.org/abs/2510.17388)
*Henry Lim,Kwan Hui Lim*

Main category: cs.CL

TL;DR: IT-LLM在执行自洽指令方面存在显著不足，需要改进训练和评估方法，尤其是在指令格式偏倚和原子指令遵循方面。


<details>
  <summary>Details</summary>
Motivation: 尽管IT-LLM在零-shot推理方面表现突出，但其执行简单、自洽指令的能力仍未被全面探讨。

Method: 评估20个IT-LLM在修改后的MMLU和MMLU-Pro基准上的表现，通过系统性变化选择标签的格式，并探讨其对性能的影响。

Result: 随着指令格式的变化，模型性能出现显著波动，尤其在缺乏明确指导的情况下，表现下降更为明显，说明指令格式偏倚和学习效果不足。

Conclusion: 当前的指令调优范式存在不足，需改进评估方法和训练策略，以明确针对原子指令的执行能力。

Abstract: Instruction-tuned large language models (IT-LLMs) exhibit strong zero-shot
reasoning, yet their ability to execute simple, self-contained instructions
remains underexplored, despite this being foundational to complex
instruction-following. We evaluate 20 IT-LLMs on modified MMLU and MMLU-Pro
benchmarks, by systematically varying the format of option labels (alphabetic,
numeric, Roman) while keeping their meaning identical under four paradigms,
namely: (1) With explicit instructions, label changes cause large performance
shifts (e.g., -30.45\% for Roman vs. numeric), revealing instruction-format
bias. (2) Without instructions, performance drops further (up to -10.84\%) and
label sensitivity intensifies, underscoring the role of explicit guidance. (3)
When option contents are removed, models fail random-choice baselines except
with numeric labels, suggesting weak adherence to atomic directives. (4)
Three-shot exemplars yield no significant gains in robustness or fidelity, and
generation analyses show persistent label errors, especially for non-numeric
formats. Across model sizes, larger LLMs achieve higher accuracy but remain
inconsistent in instruction adherence. These results expose the insufficiencies
of current instruction-tuning paradigms and highlight the need for evaluation
methods and training strategies that explicitly target atomic
instruction-following.

</details>


### [214] [EduAdapt: A Question Answer Benchmark Dataset for Evaluating Grade-Level Adaptability in LLMs](https://arxiv.org/abs/2510.17389)
*Numaan Naeem,Abdellah El Mekki,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: EduAdapt 是一个新基准，旨在评估大语言模型在 K-12 教育中的年级适应性，促进更符合发展需求的教育 AI 系统。


<details>
  <summary>Details</summary>
Motivation: 解决现有 LLM 在 K-12 教育中未能根据学生年级水平调整响应的问题，以满足日益增长的教育技术需求。

Method: 使用近 48,000 个标记年级的问答对，评估多种开源 LLM 在适应教育需求方面的表现。

Result: 评估发现，尽管较大的模型表现较好，但在为低年级学生生成合适响应方面仍然存在困难。

Conclusion: EduAdapt 提供了首个评估大语言模型（LLM）适应不同年级水平的基准，以促进教育 AI 系统的更好发展。

Abstract: Large language models (LLMs) are transforming education by answering
questions, explaining complex concepts, and generating content across a wide
range of subjects. Despite strong performance on academic benchmarks, they
often fail to tailor responses to students' grade levels. This is a critical
need in K-12 education, where age-appropriate vocabulary and explanation are
essential for effective learning. Existing models frequently produce outputs
that are too advanced or vague for younger learners, and there are no
standardized benchmarks to evaluate their ability to adjust across cognitive
and developmental stages. To address this gap, we introduce EduAdapt, a
benchmark of nearly 48k grade-labeled QA pairs across nine science subjects,
spanning Grades 1-12 and grouped into four grade levels. We evaluate a diverse
set of open-source LLMs on EduAdapt and find that while larger models generally
perform better, they still struggle with generating suitable responses for
early-grade students (Grades 1-5). Our work presents the first dataset and
evaluation framework for assessing grade-level adaptability in LLMs, aiming to
foster more developmentally aligned educational AI systems through better
training and prompting strategies. EduAdapt code and datasets are publicly
available at https://github.com/NaumanNaeem/EduAdapt.

</details>


### [215] [Leveraging Group Relative Policy Optimization to Advance Large Language Models in Traditional Chinese Medicine](https://arxiv.org/abs/2510.17402)
*Jiacheng Xie,Shuai Zeng,Yang Yu,Xiaoting Tang,Guanghui An,Dong Xu*

Main category: cs.CL

TL;DR: 引入Ladder-base，一个基于GRPO训练的中医语言模型，其在推理能力和一致性上超越了其他模型。


<details>
  <summary>Details</summary>
Motivation: 研究中医知识系统的独特性，突破以往中医特定模型的局限，提升其推理和事实一致性。

Method: 本文介绍了Ladder-base，一个专注于中医的语言模型，通过群体相对政策优化（GRPO）进行训练，优化响应选择。

Result: Ladder-base在多个推理指标上表现优于现有的通用和特定于中医的语言模型，验证了GRPO策略的有效性。

Conclusion: GRPO方法有效提升了大型语言模型在传统医学领域的专家级推理能力，支持可信赖的中医人工智能系统发展。

Abstract: Traditional Chinese Medicine (TCM) presents a rich and structurally unique
knowledge system that challenges conventional applications of large language
models (LLMs). Although previous TCM-specific LLMs have shown progress through
supervised fine-tuning, they often face limitations in alignment, data quality,
and evaluation consistency. In this study, we introduce Ladder-base, the first
TCM-focused LLM trained with Group Relative Policy Optimization (GRPO), a
reinforcement learning method that improves reasoning and factual consistency
by optimizing response selection based on intra-group comparisons. Ladder-base
is built upon the Qwen2.5-7B-Instruct foundation model and trained exclusively
on the textual subset of the TCM-Ladder benchmark, using 80 percent of the data
for training and the remaining 20 percent split evenly between validation and
test sets. Through standardized evaluation, Ladder-base demonstrates superior
performance across multiple reasoning metrics when compared to both
state-of-the-art general-purpose LLMs such as GPT-4, Gemini 2.5, Claude 3, and
Qwen3 and domain-specific TCM models including BenTsao, HuatuoGPT2, and
Zhongjing. These findings suggest that GRPO provides an effective and efficient
strategy for aligning LLMs with expert-level reasoning in traditional medical
domains and supports the development of trustworthy and clinically grounded TCM
artificial intelligence systems.

</details>


### [216] [AFRICAPTION: Establishing a New Paradigm for Image Captioning in African Languages](https://arxiv.org/abs/2510.17405)
*Mardiyyah Oduwole,Prince Mireku,Fatimo Adebanjo,Oluwatosin Olajide,Mahi Aminu Aliyu,Jekaterina Novikova*

Main category: cs.CL

TL;DR: AfriCaption是一个针对20种非洲语言的图像字幕框架，推动多模态AI的公平性与可持续性。


<details>
  <summary>Details</summary>
Motivation: 推动多模态AI的民主化，尤其是在前沿技术主要集中于高资源语言的背景下。

Method: 构建一个包含20种非洲语言的多语言图像字幕框架，涉及数据集、动态处理管道及模型架构。

Result: 形成了一个包含经过上下文注意与翻译处理的Flickr8k语义对齐字幕的数据集，实现了图像到文本生成的集成模型。

Conclusion: AfriCaption是首个专为非洲弱势语言设计的可扩展图像字幕资源，有助于实现多模态AI的更广泛应用。

Abstract: Multimodal AI research has overwhelmingly focused on high-resource languages,
hindering the democratization of advancements in the field. To address this, we
present AfriCaption, a comprehensive framework for multilingual image
captioning in 20 African languages and our contributions are threefold: (i) a
curated dataset built on Flickr8k, featuring semantically aligned captions
generated via a context-aware selection and translation process; (ii) a
dynamic, context-preserving pipeline that ensures ongoing quality through model
ensembling and adaptive substitution; and (iii) the AfriCaption model, a 0.5B
parameter vision-to-text architecture that integrates SigLIP and NLLB200 for
caption generation across under-represented languages. This unified framework
ensures ongoing data quality and establishes the first scalable
image-captioning resource for under-represented African languages, laying the
groundwork for truly inclusive multimodal AI.

</details>


### [217] [Navigating the Alignment-Calibration Trade-off: A Pareto-Superior Frontier via Model Merging](https://arxiv.org/abs/2510.17426)
*Tiancheng Hu,Benjamin Minixhofer,Nigel Collier*

Main category: cs.CL

TL;DR: 后训练对齐税不仅导致任务准确度下降，还严重损失校准，通过简单的模型融合方法可有效缓解这些问题。


<details>
  <summary>Details</summary>
Motivation: 研究后训练对齐税带来的精度下降及校准损失问题。

Method: 通过插值法在模型对齐前后权重之间进行简单的后处理干预。

Result: 发现插值过程能找到帕累托最优解，提供既提高准确性又恢复校准的模型。

Conclusion: 模型融合能够有效缓解后训练对齐税，提升模型能力与可靠性。

Abstract: The "alignment tax" of post-training is typically framed as a drop in task
accuracy. We show it also involves a severe loss of calibration, making models
overconfident, less reliable, and model outputs less diverse. We show that this
trade-off can be navigated effectively via a simple post-hoc intervention:
interpolating between a model's weights before and after alignment. Crucially,
this is not a strict trade-off. We find that the process consistently reveals
Pareto-optimal interpolations - models that improve accuracy beyond both
parents while substantially recovering the calibration lost during alignment.
Our work demonstrates that simple model merging provides a computationally
efficient method for mitigating the full scope of the alignment tax, yielding
models that are more capable and more reliable.

</details>


### [218] [Evaluating Large Language Models on Urdu Idiom Translation](https://arxiv.org/abs/2510.17460)
*Muhammad Farmal Khan,Mousumi Akter*

Main category: cs.CL

TL;DR: 本研究引入了乌尔都语到英语的习语翻译评估数据集，发现提示工程提升了习语翻译质量，母语输入效果佳。


<details>
  <summary>Details</summary>
Motivation: 针对机器翻译中习语翻译的挑战，尤其是资源匮乏语言，如乌尔都语，开展研究并推动相关数据集的构建。

Method: 对多种开源大型语言模型和神经机器翻译系统进行评估，使用BLEU、BERTScore、COMET和XCOMET等自动评估指标。

Result: 通过评估发现，提示工程优于直接翻译，母语乌尔都语的文本表现优于罗马乌尔都语。

Conclusion: 本研究表明，提示工程对习语翻译有显著改善，且使用母语乌尔都语输入能提高翻译质量。

Abstract: Idiomatic translation remains a significant challenge in machine translation,
especially for low resource languages such as Urdu, and has received limited
prior attention. To advance research in this area, we introduce the first
evaluation datasets for Urdu to English idiomatic translation, covering both
Native Urdu and Roman Urdu scripts and annotated with gold-standard English
equivalents. We evaluate multiple open-source Large Language Models (LLMs) and
Neural Machine Translation (NMT) systems on this task, focusing on their
ability to preserve idiomatic and cultural meaning. Automatic metrics including
BLEU, BERTScore, COMET, and XCOMET are used to assess translation quality. Our
findings indicate that prompt engineering enhances idiomatic translation
compared to direct translation, though performance differences among prompt
types are relatively minor. Moreover, cross script comparisons reveal that text
representation substantially affects translation quality, with Native Urdu
inputs producing more accurate idiomatic translations than Roman Urdu.

</details>


### [219] [Disparities in Multilingual LLM-Based Healthcare Q&A](https://arxiv.org/abs/2510.17476)
*Ipek Baris Schlicht,Burcu Sayin,Zhixue Zhao,Frederik M. Labonté,Cesare Barbera,Marco Viviani,Paolo Rosso,Lucie Flek*

Main category: cs.CL

TL;DR: 本研究系统分析了多语言医疗保健中的跨语言差异，构建了一个多语言数据集，发现LLM在非英语提示下仍与英语维基百科的响应一致性更高，并提出改善事实一致性的有效方法。


<details>
  <summary>Details</summary>
Motivation: 在将人工智能整合到医疗保健中时，保障不同语言的可靠健康信息访问至关重要，但多语言大型语言模型的信息质量有所不同。

Method: 通过构建多语言数据集（MultiWikiHealthCare），分析跨语言的医疗覆盖情况，评估LLM响应与这些参考资料的一致性，并结合上下文信息和增强生成（RAG）方法进行案例研究。

Result: 发现跨语言的医疗信息覆盖和LLM事实一致性存在显著差异，LLM的响应更倾向于与英语维基百科一致，即使提示为非英语。提供非英语的上下文信息能有效改善事实一致性。

Conclusion: 研究结果表明，在多语言医疗保健中，信息的可靠性存在显著的跨语言差异，尤其是与维基百科的覆盖率和LLM的事实一致性有关。提供非英语维基百科的上下文信息可以改善事实一致性，使其更符合文化相关知识。

Abstract: Equitable access to reliable health information is vital when integrating AI
into healthcare. Yet, information quality varies across languages, raising
concerns about the reliability and consistency of multilingual Large Language
Models (LLMs). We systematically examine cross-lingual disparities in
pre-training source and factuality alignment in LLM answers for multilingual
healthcare Q&A across English, German, Turkish, Chinese (Mandarin), and
Italian. We (i) constructed Multilingual Wiki Health Care
(MultiWikiHealthCare), a multilingual dataset from Wikipedia; (ii) analyzed
cross-lingual healthcare coverage; (iii) assessed LLM response alignment with
these references; and (iv) conducted a case study on factual alignment through
the use of contextual information and Retrieval-Augmented Generation (RAG). Our
findings reveal substantial cross-lingual disparities in both Wikipedia
coverage and LLM factual alignment. Across LLMs, responses align more with
English Wikipedia, even when the prompts are non-English. Providing contextual
excerpts from non-English Wikipedia at inference time effectively shifts
factual alignment toward culturally relevant knowledge. These results highlight
practical pathways for building more equitable, multilingual AI systems for
healthcare.

</details>


### [220] [ReXMoE: Reusing Experts with Minimal Overhead in Mixture-of-Experts](https://arxiv.org/abs/2510.17483)
*Zheyue Tan,Zhiyuan Li,Tao Yuan,Dong Zhou,Weilin Liu,Yueqing Zhuang,Yadong Li,Guowei Niu,Cheng Qin,Zhuyu Yao,Congyi Liu,Haiyang Xu,Boxun Li,Guohao Dai,Bo Zhao,Yu Wang*

Main category: cs.CL

TL;DR: ReXMoE是一种改进的Mixture-of-Experts架构，通过允许跨层重用专家和引入新的渐进式扩展路由策略，提升了LLM的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决层级局部路由机制的局限性，ReXMoE旨在解耦专家维度与每层预算，从而实现更丰富的专家组合，提升语言建模和下游任务性能。

Method: 提出了一种新的渐进式扩展路由策略（PSR），在训练期间逐步增加候选专家池。

Result: 在从0.5B到7B参数的模型中进行的广泛实验表明，ReXMoE在固定结构维度下始终提高了性能，确立了其作为新设计范式的地位，适用于参数高效且可扩展的MoE基础LLM。

Conclusion: ReXMoE是一种新的MoE架构，通过允许路由器在相邻层之间重用专家，超越了传统的层级局部路由方法，从而改善了路由设计。

Abstract: Mixture-of-Experts (MoE) architectures have emerged as a promising approach
to scale Large Language Models (LLMs). MoE boosts the efficiency by activating
a subset of experts per token. Recent works show that fine-grained experts
substantially enriches the combinatorial flexibility of active experts and
enhances model expressiveness. However, such a design is fundamentally limited
by the layer-local routing mechanism: each layer is restricted to its own
expert pool. This requires a careful trade-off between expert dimensionality
and routing diversity given fixed parameter budgets. We describe ReXMoE, a
novel MoE architecture that improves routing beyond the existing layer-local
approaches by allowing routers to reuse experts across adjacent layers. ReXMoE
decouples expert dimensionality from per-layer budgets, enabling richer expert
combinations without sacrificing individual expert capacity or inflating
overall parameters. To this end, we propose a new progressive scaling routing
(PSR) strategy to gradually increase the candidate expert pool during training.
As a result, ReXMoE improves both language modeling and downstream task
performance. Extensive experiments on models ranging from 0.5B to 7B parameters
across different architectures demonstrate that ReXMoE consistently improves
performance under fixed architectural dimensions, confirming ReXMoE as new
design paradigm for parameter-efficient and scalable MoE-based LLMs.

</details>


### [221] [DETree: DEtecting Human-AI Collaborative Texts via Tree-Structured Hierarchical Representation Learning](https://arxiv.org/abs/2510.17489)
*Yongxin He,Shan Zhang,Yixuan Cao,Lei Ma,Ping Luo*

Main category: cs.CL

TL;DR: 本研究提出DETree，一种新颖的文本检测方法，通过Hierarchical Affinity Tree结构和专门的损失函数，大幅提升了AI参与文本的检测效果。


<details>
  <summary>Details</summary>
Motivation: 响应对抗击虚假信息、剽窃和学术不端行为的需求，提出了一种有效的AI文本检测方法。

Method: 提出一种Hierarchical Affinity Tree结构的模型，并引入了专门的损失函数，以对齐文本表示与该树的关系。

Result: 通过综合基准数据集RealBench，DETree在各种人机协作产生的混合文本的检测中表现出色，尤其在密集学习任务中提升了泛化能力。

Conclusion: DETree显著提高了混合文本检测任务的性能，并在少样本学习条件下展示了良好的鲁棒性和泛化能力。

Abstract: Detecting AI-involved text is essential for combating misinformation,
plagiarism, and academic misconduct. However, AI text generation includes
diverse collaborative processes (AI-written text edited by humans,
human-written text edited by AI, and AI-generated text refined by other AI),
where various or even new LLMs could be involved. Texts generated through these
varied processes exhibit complex characteristics, presenting significant
challenges for detection. Current methods model these processes rather crudely,
primarily employing binary classification (purely human vs. AI-involved) or
multi-classification (treating human-AI collaboration as a new class). We
observe that representations of texts generated through different processes
exhibit inherent clustering relationships. Therefore, we propose DETree, a
novel approach that models the relationships among different processes as a
Hierarchical Affinity Tree structure, and introduces a specialized loss
function that aligns text representations with this tree. To facilitate this
learning, we developed RealBench, a comprehensive benchmark dataset that
automatically incorporates a wide spectrum of hybrid texts produced through
various human-AI collaboration processes. Our method improves performance in
hybrid text detection tasks and significantly enhances robustness and
generalization in out-of-distribution scenarios, particularly in few-shot
learning conditions, further demonstrating the promise of training-based
approaches in OOD settings. Our code and dataset are available at
https://github.com/heyongxin233/DETree.

</details>


### [222] [Deep Self-Evolving Reasoning](https://arxiv.org/abs/2510.17498)
*Zihan Liu,Shun Zheng,Xumeng Wen,Yang Wang,Jiang Bian,Mao Yang*

Main category: cs.CL

TL;DR: 本文提出的Deep Self-Evolving Reasoning（DSER）框架，通过概念化为马尔可夫链，显著提升了小规模模型在复杂任务中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 探索如何在有限的验证和修正能力下，提升小规模模型在复杂任务中的推理能力。

Method: 将迭代推理概念化为马尔可夫链，通过多条并行自我进化过程，放大模型的正向趋势。

Result: DSER成功地帮助DeepSeek模型在AIME 2024-2025基准上解决了5个以前无法解决的问题，并超越其600B参数教师的单回合准确性。

Conclusion: DSER框架不仅提高了模型在测试时的表现，还为开发具有强大自我进化能力的下一代模型提供了研究方向。

Abstract: Long-form chain-of-thought reasoning has become a cornerstone of advanced
reasoning in large language models. While recent verification-refinement
frameworks have enabled proprietary models to solve Olympiad-level problems,
their effectiveness hinges on strong, reliable verification and correction
capabilities, which remain fragile in open-weight, smaller-scale models. This
work demonstrates that even with weak verification and refinement capabilities
on hard tasks, the reasoning limits of such models can be substantially
extended through a probabilistic paradigm we call Deep Self-Evolving Reasoning
(DSER). We conceptualize iterative reasoning as a Markov chain, where each step
represents a stochastic transition in the solution space. The key insight is
that convergence to a correct solution is guaranteed as long as the probability
of improvement marginally exceeds that of degradation. By running multiple
long-horizon, self-evolving processes in parallel, DSER amplifies these small
positive tendencies, enabling the model to asymptotically approach correct
answers. Empirically, we apply DSER to the DeepSeek-R1-0528-Qwen3-8B model. On
the challenging AIME 2024-2025 benchmark, DSER solves 5 out of 9 previously
unsolvable problems and boosts overall performance, enabling this compact model
to surpass the single-turn accuracy of its 600B-parameter teacher through
majority voting. Beyond its immediate utility for test-time scaling, the DSER
framework serves to diagnose the fundamental limitations of current open-weight
reasoners. By clearly delineating their shortcomings in self-verification,
refinement, and stability, our findings establish a clear research agenda for
developing next-generation models with powerful, intrinsic self-evolving
capabilities.

</details>


### [223] [Lingua Custodi's participation at the WMT 2025 Terminology shared task](https://arxiv.org/abs/2510.17504)
*Jingshu Liu,Raheel Qader,Gaëtan Caillaut,Mariam Nakhlé*

Main category: cs.CL

TL;DR: 本文研究了多语言句子嵌入的方法，通过结合最佳单语言和跨语言表示方法，显著提高了多语言检索准确率，同时减少了训练数据的需求。


<details>
  <summary>Details</summary>
Motivation: 探讨BERT基础的跨语言句子嵌入，填补该领域研究的空白。

Method: 结合了多种学习单语言和跨语言表示的最佳方法，包括掩码语言建模（MLM）、翻译语言建模（TLM）、双编码器翻译排名和加性边际软最大。

Result: 使用预训练的多语言模型，降低了80%的并行训练数据需求，同时生成的模型在多个任务中均表现出色。

Conclusion: 本文提出的多语言句子嵌入模型在112种语言的双文本检索准确率达到83.7%，超越了现有的LASER模型，同时在单语言迁移学习基准测试中表现良好。

Abstract: While BERT is an effective method for learning monolingual sentence
embeddings for semantic similarity and embedding based transfer learning BERT
based cross-lingual sentence embeddings have yet to be explored. We
systematically investigate methods for learning multilingual sentence
embeddings by combining the best methods for learning monolingual and
cross-lingual representations including: masked language modeling (MLM),
translation language modeling (TLM), dual encoder translation ranking, and
additive margin softmax. We show that introducing a pre-trained multilingual
language model dramatically reduces the amount of parallel training data
required to achieve good performance by 80%. Composing the best of these
methods produces a model that achieves 83.7% bi-text retrieval accuracy over
112 languages on Tatoeba, well above the 65.5 achieved by LASER, while still
performing competitively on monolingual transfer learning benchmarks. Parallel
data mined from CommonCrawl using our best model is shown to train competitive
NMT models for en-zh and en-de. We publicly release our best multilingual
sentence embedding model for 109+ languages at https://tfhub.dev/google/LaBSE.

</details>


### [224] [Annotation-Efficient Universal Honesty Alignment](https://arxiv.org/abs/2510.17509)
*Shiyu Ni,Keping Bi,Jiafeng Guo,Minghao Tang,Jingtong Wu,Zengxin Han,Xueqi Cheng*

Main category: cs.CL

TL;DR: EliCal是一个新框架，通过自我一致性监督和少量正确性注释，实现了大语言模型的有效诚实对齐。


<details>
  <summary>Details</summary>
Motivation: 现有方法在实现普遍诚实对齐时需要昂贵的大规模标注，EliCal旨在提高标注效率。

Method: 通过两阶段框架，首先使用低成本的自我一致性监督来引导内部信心，然后用小规模的正确性注释进行校准。

Result: EliCal在只需1000个正确性注释的情况下实现了几乎最佳的对齐效果，并在见不到的MMLU任务上表现出更好的对齐性能。

Conclusion: EliCal提供了一种可扩展的解决方案，实现了大语言模型的普遍诚实对齐。

Abstract: Honesty alignment-the ability of large language models (LLMs) to recognize
their knowledge boundaries and express calibrated confidence-is essential for
trustworthy deployment. Existing methods either rely on training-free
confidence estimation (e.g., token probabilities, self-consistency) or
training-based calibration with correctness annotations. While effective,
achieving universal honesty alignment with training-based calibration requires
costly, large-scale labeling. To support annotation-efficient training, we
introduce Elicitation-Then-Calibration (EliCal), a two-stage framework that
first elicits internal confidence using inexpensive self-consistency
supervision, then calibrates this confidence with a small set of correctness
annotations. To support a large-scale study, we release HonestyBench, a
benchmark covering ten free-form QA datasets with 560k training and 70k
evaluation instances annotated with correctness and self-consistency signals.
Experiments show that EliCal achieves near-optimal alignment with only 1k
correctness annotations (0.18% of full supervision) and better alignment
performance on unseen MMLU tasks than the calibration-only baseline, offering a
scalable solution toward universal honesty alignment in LLMs.

</details>


### [225] [SimBench: Benchmarking the Ability of Large Language Models to Simulate Human Behaviors](https://arxiv.org/abs/2510.17516)
*Tiancheng Hu,Joachim Baumann,Lorenzo Lupo,Dirk Hovy,Nigel Collier,Paul Röttger*

Main category: cs.CL

TL;DR: 本研究提出了SimBench基准，揭示LLM模拟人类行为的性能受限，并强调了模型规模对性能的影响及其与深度推理的关系。


<details>
  <summary>Details</summary>
Motivation: 为了应对当前对LLM模拟能力的评估碎片化问题，提出SimBench以建立一个更加可靠和可重复的评估框架。

Method: 通过统一20个多样化数据集，SimBench评价LLM在道德决策和经济选择等任务上的性能。

Result: 尽管当前顶级的LLM模拟能力有限（得分为40.80/100），但随着模型规模的增加，性能呈对数线性增长。模拟能力与深层知识密集型推理的相关性最高。

Conclusion: SimBench为LLM模拟人类行为提供了一个标准化的基准，并揭示了当前LLM的模拟能力有限，且在不同任务上表现不一。

Abstract: Large language model (LLM) simulations of human behavior have the potential
to revolutionize the social and behavioral sciences, if and only if they
faithfully reflect real human behaviors. Current evaluations are fragmented,
based on bespoke tasks and metrics, creating a patchwork of incomparable
results. To address this, we introduce SimBench, the first large-scale,
standardized benchmark for a robust, reproducible science of LLM simulation. By
unifying 20 diverse datasets covering tasks from moral decision-making to
economic choice across a large global participant pool, SimBench provides the
necessary foundation to ask fundamental questions about when, how, and why LLM
simulations succeed or fail. We show that, while even the best LLMs today have
limited simulation ability (score: 40.80/100), performance scales log-linearly
with model size. Simulation performance is not improved by increased
inference-time compute. We demonstrate an alignment-simulation trade-off:
instruction-tuning improves performance on low-entropy (consensus) questions
but degrades it on high-entropy (diverse) ones. Models particularly struggle
when simulating specific demographic groups. Finally, we demonstrate that
simulation ability correlates most strongly with deep, knowledge-intensive
reasoning (MMLU-Pro, r=0.939). By making progress measurable, we aim to
accelerate the development of more faithful LLM simulators.

</details>


### [226] [OncoReason: Structuring Clinical Reasoning in LLMs for Robust and Interpretable Survival Prediction](https://arxiv.org/abs/2510.17532)
*Raghu Vamshi Hemadri,Geetha Krishna Guruju,Kristi Topollai,Anna Ewa Choromanska*

Main category: cs.CL

TL;DR: 本文提出了一种将LLMs与临床推理对齐的多任务学习框架，改善了癌症治疗结果预测的可解释性和准确性。


<details>
  <summary>Details</summary>
Motivation: 预测癌症治疗结果需要既准确又可解释的模型，尤其在临床数据异质性存在的情况下。

Method: 本文提出了一个统一的多任务学习框架，将自回归大型语言模型（LLMs）与临床推理对齐，以实现对MSK-CHORD数据集的结果预测。

Result: 实验表明，使用链式思维提示（CoT）可将F1提高6.0，同时降低平均绝对误差（MAE）12%；而GRPO方法则在可解释性和预测性能方面达到了最先进水平。

Conclusion: 该研究强调了在多任务临床建模中，注重推理的对齐对于提高可解释性和预测性能的重要性，并为精准肿瘤学的可解释性和可信赖的LLMs设定了新的基准。

Abstract: Predicting cancer treatment outcomes requires models that are both accurate
and interpretable, particularly in the presence of heterogeneous clinical data.
While large language models (LLMs) have shown strong performance in biomedical
NLP, they often lack structured reasoning capabilities critical for high-stakes
decision support. We present a unified, multi-task learning framework that
aligns autoregressive LLMs with clinical reasoning for outcome prediction on
the MSK-CHORD dataset. Our models are trained to jointly perform binary
survival classification, continuous survival time regression, and natural
language rationale generation. We evaluate three alignment strategies: (1)
standard supervised fine-tuning (SFT), (2) SFT with Chain-of-Thought (CoT)
prompting to elicit step-by-step reasoning, and (3) Group Relative Policy
Optimization (GRPO), a reinforcement learning method that aligns model outputs
to expert-derived reasoning trajectories. Experiments with LLaMa3-8B and
Med42-8B backbones demonstrate that CoT prompting improves F1 by +6.0 and
reduces MAE by 12%, while GRPO achieves state-of-the-art interpretability and
predictive performance across BLEU, ROUGE, and BERTScore. We further show that
existing biomedical LLMs often fail to produce valid reasoning traces due to
architectural constraints. Our findings underscore the importance of
reasoning-aware alignment in multi-task clinical modeling and set a new
benchmark for interpretable, trustworthy LLMs in precision oncology.

</details>


### [227] [When Annotators Disagree, Topology Explains: Mapper, a Topological Tool for Exploring Text Embedding Geometry and Ambiguity](https://arxiv.org/abs/2510.17548)
*Nisrine Rair,Alban Goupil,Valeriu Vrabie,Emmanuel Chochoy*

Main category: cs.CL

TL;DR: 本文提出了一种拓扑视角，利用Mapper工具分析RoBERTa-Large模型在处理模糊性方面的表现，发现模型的细微调优在嵌入空间形成模块化结构，揭示了结构信心与标签不确定性之间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 探索传统的标量度量（如准确度）无法捕捉模型在处理模糊性方面的内部表示，尤其是在人工注释者存在分歧时。

Method: 使用Mapper这一拓扑数据分析工具对RoBERTa-Large模型在MD-Offense数据集上的细微调优结果进行分析。

Result: 细微调优重构了嵌入空间，形成与模型预测一致的模块化、非凸区域。尽管大多数连接成分展现出高预测纯度，模糊数据的标签一致性却显著下降，揭示了结构信心与标签不确定性之间的隐藏紧张关系。

Conclusion: Mapper是理解模型如何处理模糊性的强大诊断工具, 并支持在主观NLP任务中采用更积极的建模策略。

Abstract: Language models are often evaluated with scalar metrics like accuracy, but
such measures fail to capture how models internally represent ambiguity,
especially when human annotators disagree. We propose a topological perspective
to analyze how fine-tuned models encode ambiguity and more generally instances.
  Applied to RoBERTa-Large on the MD-Offense dataset, Mapper, a tool from
topological data analysis, reveals that fine-tuning restructures embedding
space into modular, non-convex regions aligned with model predictions, even for
highly ambiguous cases. Over $98\%$ of connected components exhibit $\geq 90\%$
prediction purity, yet alignment with ground-truth labels drops in ambiguous
data, surfacing a hidden tension between structural confidence and label
uncertainty.
  Unlike traditional tools such as PCA or UMAP, Mapper captures this geometry
directly uncovering decision regions, boundary collapses, and overconfident
clusters. Our findings position Mapper as a powerful diagnostic tool for
understanding how models resolve ambiguity. Beyond visualization, it also
enables topological metrics that may inform proactive modeling strategies in
subjective NLP tasks.

</details>


### [228] [Language Confusion Gate: Language-Aware Decoding Through Model Self-Distillation](https://arxiv.org/abs/2510.17555)
*Collin Zhang,Fei Huang,Chenhan Yuan,Junyang Lin*

Main category: cs.CL

TL;DR: 本文提出语言混淆门（LCG），有效减少语言混淆而不影响性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在文本生成过程中出现的语言混淆问题。

Method: 通过规范调整的自蒸馏训练LCG，预测适当的语言家族并在必要时应用掩蔽。

Result: LCG在多个模型上测试时，减少了语言混淆，且通常达到了数量级的提升。

Conclusion: 引入的语言混淆门（LCG）显著减少了语言混淆，且未对任务性能产生负面影响。

Abstract: Large language models (LLMs) often experience language confusion, which is
the unintended mixing of languages during text generation. Current solutions to
this problem either necessitate model retraining or cannot differentiate
between harmful confusion and acceptable code-switching. This paper introduces
the Language Confusion Gate (LCG), a lightweight, plug-in solution that filters
tokens during decoding without altering the base LLM. The LCG is trained using
norm-adjusted self-distillation to predict appropriate language families and
apply masking only when needed. Our method is based on the findings that
language confusion is infrequent, correct-language tokens are usually among the
top predictions, and output token embedding norms are larger for high-resource
languages, which biases sampling. When evaluated across various models,
including Qwen3, GPT-OSS, Gemma3, Llama3.1, LCG decreases language confusion
significantly, often by an order of magnitude, without negatively impacting
task performance. Code is available at
https://github.com/collinzrj/language_confusion_gate.

</details>


### [229] [HGAdapter: Hypergraph-based Adapters in Language Models for Code Summarization and Clone Detection](https://arxiv.org/abs/2510.17591)
*Guang Yang,Yujie Zhu*

Main category: cs.CL

TL;DR: 本文提出HGAdapter，通过引入高阶数据相关性，提升了预训练语言模型在代码任务中的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练语言模型在代码任务中表现良好，但未考虑代码中的高阶数据相关性。

Method: 设计了一个高阶相关性捕获的tokens和超边生成器，并提出了基于超图的适配器（HGAdapter）来微调PLMs。

Result: 实验表明，HGAdapter在多个公共数据集上进行了验证，提升了PLMs在代码摘要和代码克隆检测任务中的性能。

Conclusion: 引入高阶数据相关性能显著提高预训练语言模型在代码相关任务中的性能。

Abstract: Pre-trained language models (PLMs) are increasingly being applied to
code-related tasks. Although PLMs have achieved good results, they do not take
into account potential high-order data correlations within the code. We propose
three types of high-order correlations in code tokens, i.e. abstract syntax
tree family correlation, lexical correlation, and line correlation. We design a
tokens and hyperedges generator to capture these high-order data correlations.
We improve the architecture of hypergraph neural networks and combine it with
adapter tuning to propose a novel hypergraph-based adapter (HGAdapter) to
fine-tune PLMs. HGAdapter can encode high-order data correlations and is
allowed to be inserted into various PLMs to enhance performance. Experiments
were conducted on several public datasets, including six languages of code
summarization and code clone detection tasks. Our methods improved the
performance of PLMs in datasets to varying degrees. Experimental results
validate the introduction of high-order data correlations that contribute to
improved effectiveness.

</details>


### [230] [LawChain: Modeling Legal Reasoning Chains for Chinese Tort Case Analysis](https://arxiv.org/abs/2510.17602)
*Huiyuan Xie,Chenyang Li,Huining Zhu,Chubin Zhang,Yuxiao Ye,Zhenghao Liu,Zhiyuan Liu*

Main category: cs.CL

TL;DR: 本文提出了LawChain框架，用于建模中国侵权相关民事案件的法律推理，提高了法律推理能力，并验证了其在其他法律分析任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有的法律推理计算方法主要依赖于通用推理框架，对法律推理的细微过程缺乏全面的研究，并且对民事案件的建模不足。

Method: 提出了LawChain框架，包括三个模块和多个子步骤，以建模侵权分析中的法律推理过程，并通过构建评估基准LawChain_eval来系统评估推理链的关键步骤。

Result: 评估结果表明，当前的大型语言模型在处理侵权法律推理中的重要元素时仍然存在不足，而引入LawChain风格推理的基线方法却在侵权相关法律推理中取得了显著改善，并且对相关法律分析任务具有良好的泛化能力。

Conclusion: 通过引入LawChain框架，本文显著提高了对于中国侵权法相关案例的法律推理能力，并验证了这一方法在相关法律分析任务中的通用性。

Abstract: Legal reasoning is a fundamental component of legal analysis and
decision-making. Existing computational approaches to legal reasoning
predominantly rely on generic reasoning frameworks such as syllogism and IRAC,
which do not comprehensively examine the nuanced processes that underpin legal
reasoning. Moreover, current research has largely focused on criminal cases,
with insufficient modeling for civil cases. In this work, we present a novel
framework for explicitly modeling legal reasoning in the analysis of Chinese
tort-related civil cases. We first operationalize the legal reasoning processes
used in tort analysis into the LawChain framework. LawChain is a three-module
reasoning framework, with each module consisting of multiple finer-grained
sub-steps. Informed by the LawChain framework, we introduce the task of tort
legal reasoning and construct an evaluation benchmark, LawChain$_{eval}$, to
systematically assess the critical steps within analytical reasoning chains for
tort analysis. Leveraging this benchmark, we evaluate state-of-the-art large
language models for their legal reasoning ability in civil tort contexts. Our
results indicate that current models still fall short in accurately handling
crucial elements of tort legal reasoning. Furthermore, we introduce several
baseline approaches that explicitly incorporate LawChain-style reasoning
through prompting or post-training. We conduct further experiments on
additional legal analysis tasks, such as Legal Named-Entity Recognition and
Criminal Damages Calculation, to verify the generalizability of these
baselines. The proposed baseline approaches achieve significant improvements in
tort-related legal reasoning and generalize well to related legal analysis
tasks, thus demonstrating the value of explicitly modeling legal reasoning
chains to enhance the reasoning capabilities of language models.

</details>


### [231] [Forget to Know, Remember to Use: Context-Aware Unlearning for Large Language Models](https://arxiv.org/abs/2510.17620)
*Yuefeng Peng,Parnian Afshar,Megan Ganji,Thomas Butler,Amir Houmansadr,Mingxian Wang,Dezhi Hong*

Main category: cs.CL

TL;DR: 本研究探讨了遗忘技术对语言模型上下文效用的影响，并提出了一种新方法以恢复该效用。


<details>
  <summary>Details</summary>
Motivation: 为确保模型响应的负责任性和合规性，需要删除敏感信息或过时知识，而遗忘成为了一种高效的替代方案。

Method: 对六种先进的遗忘方法进行系统评估，分析它们在上下文中的有效性。

Result: 实验表明，我们的方法在保持有效忘记和保留集效用的同时，能够将上下文效用恢复到接近原始水平。

Conclusion: 通过增补目标，使模型能够在上下文中重用遗忘的信息，提升了上下文效用，同时保持了有效的遗忘与保留集效用。

Abstract: Large language models may encode sensitive information or outdated knowledge
that needs to be removed, to ensure responsible and compliant model responses.
Unlearning has emerged as an efficient alternative to full retraining, aiming
to remove specific knowledge while preserving overall model utility. Existing
evaluations of unlearning methods focus on (1) the extent of forgetting of the
target knowledge (forget set) and (2) maintaining performance on the retain set
(i.e., utility). However, these evaluations overlook an important usability
aspect: users may still want the model to leverage the removed information if
it is re-introduced in the prompt. In a systematic evaluation of six
state-of-the-art unlearning methods, we find that they consistently impair such
contextual utility. To address this, we augment unlearning objectives with a
plug-in term that preserves the model's ability to use forgotten knowledge when
it is present in context. Extensive experiments demonstrate that our approach
restores contextual utility to near original levels while still maintaining
effective forgetting and retain-set utility.

</details>


### [232] [Qomhra: A Bilingual Irish-English Large Language Model](https://arxiv.org/abs/2510.17652)
*Joseph McInerney*

Main category: cs.CL

TL;DR: Qomhr'a是新开发的爱尔兰-英语双语LMM，经过独特的训练流程，展示了显著的语言生成能力提升，适合聊天应用。


<details>
  <summary>Details</summary>
Motivation: 在低资源条件下提升爱尔兰语的生成能力，同时保持英语能力，解决双语语言模型在资源匮乏环境中的挑战。

Method: 使用双语持续预训练、指令调优和基于人类偏好的对齐流程，结合新的爱尔兰语和英语语料，进行模型开发和评估。

Result: 开发出一种新的双语语言模型Qomhr'a，取得了爱尔兰语最高29%和英语最高44%的性能提升，并展现出较强的指令跟随能力，适用于聊天机器人功能。

Conclusion: Qomhr'a是一个在低资源限制下开发的爱尔兰-英语双语大型语言模型，经过全面评估在爱尔兰语和英语生成上均显示出显著的改进，与人类偏好的对齐效果也非常良好。

Abstract: This paper introduces Qomhr\'a, a bilingual Irish-English large language
model (LLM), developed under low-resource constraints presenting a complete
pipeline spanning bilingual continued pre-training, instruction tuning, and
alignment from human preferences. Newly accessible Irish corpora and English
text are mixed and curated to improve Irish performance while preserving
English ability. 6 closed-weight LLMs are judged for their Irish text
generation by a native speaker, a learner and other LLMs. Google's
Gemini-2.5-Pro is ranked the highest and is subsequently used to synthesise
instruction tuning and human preference datasets. Two datasets are contributed
leveraging Gemini-2.5-Pro: a 30K Irish-English parallel instruction tuning
dataset and a 1K human preference dataset, generating accepted and rejected
responses that show near perfect alignment with a native Irish speaker.
Qomhr\'a is comprehensively evaluated across benchmarks testing translation,
gender understanding, topic identification and world knowledge with gains of up
to 29% in Irish and 44% in English. Qomhr\'a also undergoes instruction tuning
and demonstrates clear progress in instruction following, crucial for chatbot
functionality.

</details>


### [233] [Towards Mining Effective Pedagogical Strategies from Learner-LLM Educational Dialogues](https://arxiv.org/abs/2510.17698)
*Liqun He,Manolis Mavrikis,Mutlu Cukurova*

Main category: cs.CL

TL;DR: 本研究通过对话分析方法探索学习者与大语言模型的互动，以识别有效的教学策略，强调了评估这类教育应用时需关注对话动态。


<details>
  <summary>Details</summary>
Motivation: 当前现有的评估方法主要集中在技术性能或学习结果上，缺乏对学习者与大语言模型间互动的关注，因此有必要对此进行深入研究。

Method: 本研究采用对话分析方法，包括对话数据收集、对话行为标注、对话行为模式挖掘和预测模型构建。

Result: 初步发现为未来研究提供了初步步骤，并确定了有效的教学策略。

Conclusion: 本研究强调了在评估基于大语言模型的教育应用时，关注对话动态和教学策略的重要性。

Abstract: Dialogue plays a crucial role in educational settings, yet existing
evaluation methods for educational applications of large language models (LLMs)
primarily focus on technical performance or learning outcomes, often neglecting
attention to learner-LLM interactions. To narrow this gap, this AIED Doctoral
Consortium paper presents an ongoing study employing a dialogue analysis
approach to identify effective pedagogical strategies from learner-LLM
dialogues. The proposed approach involves dialogue data collection, dialogue
act (DA) annotation, DA pattern mining, and predictive model building. Early
insights are outlined as an initial step toward future research. The work
underscores the need to evaluate LLM-based educational applications by focusing
on dialogue dynamics and pedagogical strategies.

</details>


### [234] [QueST: Incentivizing LLMs to Generate Difficult Problems](https://arxiv.org/abs/2510.17715)
*Hanxu Hu,Xingxing Zhang,Jannis Vamvas,Rico Sennrich,Furu Wei*

Main category: cs.CL

TL;DR: 本论文提出QueST框架，通过生成大量复杂的编码问题，显著提升了大型语言模型在编码和推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 为了克服人类标注数据集的有限性并生成大规模、高挑战性的编码问题。

Method: 采用了难度感知图采样和难度感知拒绝微调相结合的方法，以优化专门生成器，生成复杂的编码问题。

Result: 通过QueST生成的100K困难问题，经过微调后的Qwen3-8B-base在LiveCodeBench上的表现超越了原始版本，并与更大的DeepSeek-R1-671B模型的表现相媲美。

Conclusion: QueST框架能够有效生成具有挑战性的编码问题，从而提高大型语言模型的竞争编码及推理能力。

Abstract: Large Language Models have achieved strong performance on reasoning tasks,
solving competition-level coding and math problems. However, their scalability
is limited by human-labeled datasets and the lack of large-scale, challenging
coding problem training data. Existing competitive coding datasets contain only
thousands to tens of thousands of problems. Previous synthetic data generation
methods rely on either augmenting existing instruction datasets or selecting
challenging problems from human-labeled data. In this paper, we propose QueST,
a novel framework which combines difficulty-aware graph sampling and
difficulty-aware rejection fine-tuning that directly optimizes specialized
generators to create challenging coding problems. Our trained generators
demonstrate superior capability compared to even GPT-4o at creating challenging
problems that benefit downstream performance. We leverage QueST to generate
large-scale synthetic coding problems, which we then use to distill from strong
teacher models with long chain-of-thought or to conduct reinforcement learning
for smaller models, proving effective in both scenarios. Our distillation
experiments demonstrate significant performance gains. Specifically, after
fine-tuning Qwen3-8B-base on 100K difficult problems generated by QueST, we
surpass the performance of the original Qwen3-8B on LiveCodeBench. With an
additional 112K examples (i.e., 28K human-written problems paired with multiple
synthetic solutions), our 8B model matches the performance of the much larger
DeepSeek-R1-671B. These findings indicate that generating complex problems via
QueST offers an effective and scalable approach to advancing the frontiers of
competitive coding and reasoning for large language models.

</details>


### [235] [PANER: A Paraphrase-Augmented Framework for Low-Resource Named Entity Recognition](https://arxiv.org/abs/2510.17720)
*Nanda Kumar Rengarajan,Jun Yan,Chun Wang*

Main category: cs.CL

TL;DR: 提出了一种轻量级少样本NER框架，结合新型指导调优和数据增强技术，提高了模型在低资源场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 在低资源场景中，命名实体识别(NER)任务面临数据标注成本高的问题，现有零样本和指令调优方法难以适应领域特定实体。

Method: 通过新设计的指导调优模板和数据增强技术，结合现有技术，提升模型在少样本和零样本任务中的表现。

Result: 在CrossNER数据集上，我们的少样本方法平均F1分数达80.1，数据增强方法使F1分数在基线模型上提高了多达17个百分点。

Conclusion: 我们的轻量级少样本NER框架通过新颖的指导调优模板和战略数据增强技术，为低资源场景下的NER任务提供了有效解决方案，显著提高了模型性能。

Abstract: Named Entity Recognition (NER) is a critical task that requires substantial
annotated data, making it challenging in low-resource scenarios where label
acquisition is expensive. While zero-shot and instruction-tuned approaches have
made progress, they often fail to generalize to domain-specific entities and do
not effectively utilize limited available data. We present a lightweight
few-shot NER framework that addresses these challenges through two key
innovations: (1) a new instruction tuning template with a simplified output
format that combines principles from prior IT approaches to leverage the large
context window of recent state-of-the-art LLMs; (2) introducing a strategic
data augmentation technique that preserves entity information while
paraphrasing the surrounding context, thereby expanding our training data
without compromising semantic relationships. Experiments on benchmark datasets
show that our method achieves performance comparable to state-of-the-art models
on few-shot and zero-shot tasks, with our few-shot approach attaining an
average F1 score of 80.1 on the CrossNER datasets. Models trained with our
paraphrasing approach show consistent improvements in F1 scores of up to 17
points over baseline versions, offering a promising solution for groups with
limited NER training data and compute power.

</details>


### [236] [AcademicEval: Live Long-Context LLM Benchmark](https://arxiv.org/abs/2510.17725)
*Haozhen Zhang,Tao Feng,Pengrui Han,Jiaxuan You*

Main category: cs.CL

TL;DR: 	extsc{AcademicEval}是一个新的实时基准，用于评估LLMs在长文本生成任务中的表现，特别着重于层次抽象和上下文灵活性，并展示了LLMs在这些领域的挑战及改进方向。


<details>
  <summary>Details</summary>
Motivation: 当前长文本LLM基准的限制主要在于刚性上下文长度、繁琐的标注过程以及训练中的标签泄漏问题，因此设计	extsc{AcademicEval}来解决这些问题。

Method: 提出	extsc{AcademicEval}作为一个实时基准，在无须人工标注的情况下评估LLMs在长文本生成任务上的表现，涵盖学术写作的多个任务，如标题、摘要、引言和相关工作。

Result: 实验结果表明，LLMs在具有层次抽象水平的任务上表现不佳，尤其是在面临长时间少量示例演示时。

Conclusion: 通过对	extsc{AcademicEval}的综合评估，我们揭示了LLMs在处理层次抽象水平任务时表现不佳，并在长少量示例演示中面临挑战，指出了增强LLMs长文本建模能力的方向。

Abstract: Large Language Models (LLMs) have recently achieved remarkable performance in
long-context understanding. However, current long-context LLM benchmarks are
limited by rigid context length, labor-intensive annotation, and the pressing
challenge of label leakage issues during LLM training. Therefore, we propose
\textsc{AcademicEval}, a live benchmark for evaluating LLMs over long-context
generation tasks. \textsc{AcademicEval} adopts papers on arXiv to introduce
several academic writing tasks with long-context inputs, \textit{i.e.},
\textsc{Title}, \textsc{Abstract}, \textsc{Introduction}, and \textsc{Related
Work}, which cover a wide range of abstraction levels and require no manual
labeling. Moreover, \textsc{AcademicEval} integrates high-quality and
expert-curated few-shot demonstrations from a collected co-author graph to
enable flexible context length. Especially, \textsc{AcademicEval} features an
efficient live evaluation, ensuring no label leakage. We conduct a holistic
evaluation on \textsc{AcademicEval}, and the results illustrate that LLMs
perform poorly on tasks with hierarchical abstraction levels and tend to
struggle with long few-shot demonstrations, highlighting the challenge of our
benchmark. Through experimental analysis, we also reveal some insights for
enhancing LLMs' long-context modeling capabilities. Code is available at
https://github.com/ulab-uiuc/AcademicEval

</details>


### [237] [Train for Truth, Keep the Skills: Binary Retrieval-Augmented Reward Mitigates Hallucinations](https://arxiv.org/abs/2510.17733)
*Tong Chen,Akari Asai,Luke Zettlemoyer,Hannaneh Hajishirzi,Faeze Brahman*

Main category: cs.CL

TL;DR: 使用二进制检索增强奖励的在线强化学习方法能有效减少语言模型的虚假信息生成，同时保持其他任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有的减轻幻觉的方法在开放式生成和下游任务上通常会降低性能，限制了其实际应用。

Method: 一种在线强化学习方法，采用二进制检索增强奖励（RAR）。

Result: 该方法在Qwen3推理模型上评估，开放式生成中幻觉率降低39.3%；在短问答中，PopQA和GPQA的错误答案分别减少44.4%和21.7%。

Conclusion: 提出的在线强化学习方法利用新颖的二进制检索增强奖励，成功降低了虚假信息生成率，同时在多个任务上维持了良好的模型性能。

Abstract: Language models often generate factually incorrect information unsupported by
their training data, a phenomenon known as extrinsic hallucination. Existing
mitigation approaches often degrade performance on open-ended generation and
downstream tasks, limiting their practical utility. We propose an online
reinforcement learning method using a novel binary retrieval-augmented reward
(RAR) to address this tradeoff. Unlike continuous reward schemes, our approach
assigns a reward of one only when the model's output is entirely factually
correct, and zero otherwise. We evaluate our method on Qwen3 reasoning models
across diverse tasks. For open-ended generation, binary RAR achieves a 39.3%
reduction in hallucination rates, substantially outperforming both supervised
training and continuous-reward RL baselines. In short-form question answering,
the model learns calibrated abstention, strategically outputting "I don't know"
when faced with insufficient parametric knowledge. This yields 44.4% and 21.7%
fewer incorrect answers on PopQA and GPQA, respectively. Crucially, these
factuality gains come without performance degradation on instruction following,
math, or code, whereas continuous-reward RL, despite improving factuality,
induces quality regressions.

</details>


### [238] [Evaluating Medical LLMs by Levels of Autonomy: A Survey Moving from Benchmarks to Applications](https://arxiv.org/abs/2510.17764)
*Xiao Ye,Jacob Dineen,Zhaonan Li,Zhikun Xu,Weiyu Chen,Shijie Lu,Yuxi Huang,Ming Shen,Phu Tran,Ji-Eun Irene Yum,Muhammad Ali Khan,Muhammad Umar Afzal,Irbaz Bin Riaz,Ben Zhou*

Main category: cs.CL

TL;DR: 本研究通过层次化的自治视角，探讨医疗大型语言模型的评估框架，以确保其在临床工作流中的安全性与可靠性。


<details>
  <summary>Details</summary>
Motivation: 针对医疗大型语言模型在临床应用中的表现不足，提出了一种以自治为中心的评估策略，以促进对临床使用的可信且以风险为基础的证据的理解。

Method: 通过分析现有评估基准和指标，将其与不同自治水平（L0-L3）相结合，探讨各级别的允许行动及其风险。

Result: 研究成功地将评估目标与每个自治级别的风险联系起来，并提供了一种选择指标、汇总证据和报告声明的蓝图。

Conclusion: 该研究提出了一种新的评估框架，通过层次化自治的视角来评估医疗大型语言模型在临床工作流中的安全性和可靠性。

Abstract: Medical Large language models achieve strong scores on standard benchmarks;
however, the transfer of those results to safe and reliable performance in
clinical workflows remains a challenge. This survey reframes evaluation through
a levels-of-autonomy lens (L0-L3), spanning informational tools, information
transformation and aggregation, decision support, and supervised agents. We
align existing benchmarks and metrics with the actions permitted at each level
and their associated risks, making the evaluation targets explicit. This
motivates a level-conditioned blueprint for selecting metrics, assembling
evidence, and reporting claims, alongside directions that link evaluation to
oversight. By centering autonomy, the survey moves the field beyond score-based
claims toward credible, risk-aware evidence for real clinical use.

</details>


### [239] [Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains](https://arxiv.org/abs/2510.17793)
*Austin Xu,Xuan-Phi Nguyen,Yilun Zhou,Chien-Sheng Wu,Caiming Xiong,Shafiq Joty*

Main category: cs.CL

TL;DR: 本研究通过构建大规模数据集与简单的微调方法，训练出效果优异的自动推理评估器FARE，超越了现有最先进的模型。


<details>
  <summary>Details</summary>
Motivation: 应对日益增长的可扩展评估需求，同时关注数据驱动的发展而非仅仅依赖新方法。

Method: 通过简单的迭代拒绝采样监督微调（SFT）方法训练的8B和20B参数评估器。

Result: FARE-8B在与更大的专用RL训练评估器竞赛中表现出色，FARE-20B在开源评估器中设定了新标准，并在多个实际任务中取得接近oracle的性能。

Conclusion: FARE系列评估器在多个评估任务中展现出优越的性能，尤其是在真实世界任务和不断微调的模型表现上。

Abstract: Finetuning specialized generative evaluators has emerged as a popular
paradigm to meet the increasing demand for scalable evaluation during both
training and test-time. However, recent work has largely focused on applying
new methodology, such as reinforcement learning (RL), to training evaluators,
shying away from large-scale, data-driven development. In this work, we focus
on data scaling, curating a set of 2.5M samples spanning five unique evaluation
tasks (pairwise, step-level, reference-free and reference-based verification,
and single rating) and multiple domains focused on reasoning evaluation. With
our data, we train Foundational Automatic Reasoning Evaluators (FARE), a family
of 8B and 20B (with 3.6B active) parameter evaluators, with a simple iterative
rejection-sampling supervised finetuning (SFT) approach. FARE-8B challenges
larger specialized RL-trained evaluators and FARE-20B sets the new standard for
open-source evaluators, surpassing specialized 70B+ evaluators. Beyond static
benchmarks, we evaluate FARE in real-world tasks: As inference-time rerankers,
FARE-20B achieves near-oracle performance on MATH. As verifiers in RL training,
FARE improves the downstream RL-trained model performance by up to 14.1% vs.
string-matching verifiers. When initialized from FARE, a continually-finetuned
FARE-Code outperforms gpt-oss-20B by 65% on evaluating test-case quality.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [240] [Taming Modality Entanglement in Continual Audio-Visual Segmentation](https://arxiv.org/abs/2510.17234)
*Yuyang Hong,Qi Yang,Tao Zhang,Zili Wang,Zhaojin Fu,Kun Ding,Bin Fan,Shiming Xiang*

Main category: cs.MM

TL;DR: 本文提出一种新颖的持续音视频分割任务和基于碰撞的多模态回放框架，解决了多模态持续学习中的关键问题，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了应对多模态持续学习中精细任务的挑战，特别是语义漂移和类混淆问题。

Method: 设计了一种基于碰撞的多模态回放框架，通过样本选择和回放机制解决多模态持续学习中的关键挑战。

Result: 通过实验验证，该方法在多模态持续学习任务中取得了显著的性能提升。

Conclusion: 该方法在多模态持续学习中有效解决了语义漂移和类混淆问题，显著优于单模态方法。

Abstract: Recently, significant progress has been made in multi-modal continual
learning, aiming to learn new tasks sequentially in multi-modal settings while
preserving performance on previously learned ones. However, existing methods
mainly focus on coarse-grained tasks, with limitations in addressing modality
entanglement in fine-grained continual learning settings. To bridge this gap,
we introduce a novel Continual Audio-Visual Segmentation (CAVS) task, aiming to
continuously segment new classes guided by audio. Through comprehensive
analysis, two critical challenges are identified: 1) multi-modal semantic
drift, where a sounding objects is labeled as background in sequential tasks;
2) co-occurrence confusion, where frequent co-occurring classes tend to be
confused. In this work, a Collision-based Multi-modal Rehearsal (CMR) framework
is designed to address these challenges. Specifically, for multi-modal semantic
drift, a Multi-modal Sample Selection (MSS) strategy is proposed to select
samples with high modal consistency for rehearsal. Meanwhile, for co-occurence
confusion, a Collision-based Sample Rehearsal (CSR) mechanism is designed,
allowing for the increase of rehearsal sample frequency of those confusable
classes during training process. Moreover, we construct three audio-visual
incremental scenarios to verify effectiveness of our method. Comprehensive
experiments demonstrate that our method significantly outperforms single-modal
continual learning methods.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [241] [Disaster Management in the Era of Agentic AI Systems: A Vision for Collective Human-Machine Intelligence for Augmented Resilience](https://arxiv.org/abs/2510.16034)
*Bo Li,Junwei Ma,Kai Yin,Yiming Xiao,Chia-Wei Hsu,Ali Mostafavi*

Main category: cs.MA

TL;DR: 本文提出的Disaster Copilot是一个集成多种人工智能工具的系统，旨在改善灾害管理，并构建更为韧性的数据驱动社区。


<details>
  <summary>Details</summary>
Motivation: 由于传统的灾害响应能力经常被灾难的频率和严重性所超越，存在数据碎片化、资源限制和机构记忆流失等挑战，因此有必要开发一个新系统来提升灾害管理的效率。

Method: 提出了一个中心协调者的架构，该协调者协调各种专门的子智能体，每个子智能体专注于预测风险分析、情境意识和影响评估等关键领域。

Result: 通过整合多模态数据，该系统能够提供全面、实时的操作视图，促进灾害数字双胞胎从被动模型转变为主动、智能的环境，确保资源有限环境下的功能性。

Conclusion: Disaster Copilot是一个多智能体人工智能系统，旨在通过统一专业的人工智能工具来改善灾害管理，增强社区的适应能力和韧性。

Abstract: The escalating frequency and severity of disasters routinely overwhelm
traditional response capabilities, exposing critical vulnerability in disaster
management. Current practices are hindered by fragmented data streams, siloed
technologies, resource constraints, and the erosion of institutional memory,
which collectively impede timely and effective decision making. This study
introduces Disaster Copilot, a vision for a multi-agent artificial intelligence
system designed to overcome these systemic challenges by unifying specialized
AI tools within a collaborative framework. The proposed architecture utilizes a
central orchestrator to coordinate diverse sub-agents, each specializing in
critical domains such as predictive risk analytics, situational awareness, and
impact assessment. By integrating multi-modal data, the system delivers a
holistic, real-time operational picture and serve as the essential AI backbone
required to advance Disaster Digital Twins from passive models to active,
intelligent environments. Furthermore, it ensures functionality in
resource-limited environments through on-device orchestration and incorporates
mechanisms to capture institutional knowledge, mitigating the impact of staff
turnover. We detail the system architecture and propose a three-phased roadmap
emphasizing the parallel growth of technology, organizational capacity, and
human-AI teaming. Disaster Copilot offers a transformative vision, fostering
collective human-machine intelligence to build more adaptive, data-driven and
resilient communities.

</details>


### [242] [Prompt Optimization via Retrieved Reasoning Assets and Multi-Agent Analysis](https://arxiv.org/abs/2510.16635)
*Wonduk Seo,Juhyeon Lee,Junseo Koh,Hyunjin An,Jian Park,Seunghyun Lee,Haihua Chen,Yi Bu*

Main category: cs.MA

TL;DR: MA-SAPO框架通过系统化推理提升了提示优化过程的透明性与有效性，实验结果表明该方法优于现有策略。


<details>
  <summary>Details</summary>
Motivation: 当前的提示优化方法在评估过程中缺乏透明度和控制，依赖试错策略，亟需改进。

Method: 本研究提出了MA-SAPO，一个多智能体框架，用于分数意识提示优化，分为推理阶段和测试阶段。

Result: 在HelpSteer1/2基准上的实验结果显示，MA-SAPO在提示优化方面 consistently outperform 了以往的方法。

Conclusion: MA-SAPO框架通过将评估结果与结构化推理相结合，提升了提示优化的透明度和可控性，并在实验中表现优于以往方法。

Abstract: Prompt optimization has emerged as an effective alternative to retraining for
improving the performance of Large Language Models (LLMs). However, most
existing approaches treat evaluation as a black box, relying solely on
numerical scores while offering limited insight into why a prompt succeeds or
fails. They also depend heavily on trial-and-error refinements, which are
difficult to interpret and control. In this paper, we introduce MA-SAPO, a
Multi-Agent framework for Score-Aware Prompt Optimization. Compared to prior
methods, MA-SAPO explicitly couples evaluation outcomes with structured
reasoning to guide systematic edits. The framework specifically consists of two
stages: during the Reasoning Phase, agents collaboratively explain metric
scores, diagnose weaknesses, and synthesize targeted refinements that are
stored as reusable reasoning assets; during the Test Phase, agents retrieve
these assets to analyze optimized prompts and apply only evidence-grounded
edits. By turning evaluation signals into interpretable reasoning chains,
MA-SAPO produces prompt refinements that are more transparent, auditable, and
controllable. Experiments on the HelpSteer1/2 benchmarks demonstrate consistent
improvements over single-pass prompting, retrieval-augmented baselines, and
prior multi-agent strategies, validating the effectiveness of our approach.

</details>


### [243] [DiRAC - Distributed Robot Awareness and Consensus](https://arxiv.org/abs/2510.16850)
*Uday Gopan,Manjari Kulkarni,Lakshasri S,Kashish Mittal,Sriram Radhakrishna,Aditya Naskar,Rameshwar DL*

Main category: cs.MA

TL;DR: DiRAC是一个分布式框架，通过新颖的架构和算法，提高大型机器人群体的任务分配和路径规划效率，展示了在仿真环境中的成功应用。


<details>
  <summary>Details</summary>
Motivation: 旨在提高大规模机器人群体的任务调度和路径规划效率，以支持大型工业和物流应用。

Method: 引入了区域分区架构、动态选举的领导者和同步共识协议，确保强一致性和确定性结果，同时采用了一种基于力的分散式规划算法，实现实时碰撞解决。

Result: 在ROS 2中进行的初步仿真验证中，DiRAC展现了良好的架构可扩展性和模块化效率。

Conclusion: DiRAC框架为大规模机器人群体提供了高效的任务分配和路径规划解决方案，显示出优越的可扩展性和模块化效率。

Abstract: DiRAC is a scalable, distributed framework designed to enable efficient task
assignment and path planning in very large robotic swarms. It introduces a
novel zone-partitioned architecture with dynamically elected leaders and a
tick-synchronized consensus protocol that yields strong consistency and
deterministic outcomes. For path planning, DiRAC uses a novel algorithm, a
force-based decentralized planner for real-time collision resolution. Validated
within ROS 2 middleware through preliminary simulation, DiRAC demonstrates
architectural scalability and modular efficiency in simulated warehouse
environments, laying the groundwork for real-world deployment in large-scale
industrial and logistics domains.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [244] [VisuoAlign: Safety Alignment of LVLMs with Multimodal Tree Search](https://arxiv.org/abs/2510.15948)
*MingSheng Li,Guangze Zhao,Sichen Liu*

Main category: cs.AI

TL;DR: VisuoAlign是一种通过提示引导树搜索实现多模态安全对齐的框架，改善了LVLMs应对多模态攻击的能力。


<details>
  <summary>Details</summary>
Motivation: LVLMs在多模态感知和生成中取得了显著进展，但安全对齐仍然是一个关键挑战，尤其是在面对多模态漏洞攻击时。

Method: 该研究采用了基于提示的树搜索，结合视觉-文本交互提示，运用蒙特卡洛树搜索（MCTS）系统性构建安全关键的提示轨迹。

Result: 实验结果表明，VisuoAlign能够主动暴露风险，生成全面的数据集，并显著提高LVLMs对复杂跨模态威胁的鲁棒性。

Conclusion: VisuoAlign框架显著提高了大型视觉语言模型（LVLMs）在多模态安全对齐方面的鲁棒性，并有效应对复杂的跨模态威胁。

Abstract: Large Vision-Language Models (LVLMs) have achieved remarkable progress in
multimodal perception and generation, yet their safety alignment remains a
critical challenge.Existing defenses and vulnerable to multimodal jailbreaks,
as visual inputs introduce new attack surfaces, reasoning chains lack safety
supervision, and alignment often degrades under modality fusion.To overcome
these limitation, we propose VisuoAlign, a framework for multi-modal safety
alignment via prompt-guided tree search.VisuoAlign embeds safety constrains
into the reasoning process through visual-textual interactive prompts, employs
Monte Carlo Tree Search(MCTS) to systematically construct diverse
safety-critical prompt trajectories, and introduces prompt-based scaling to
ensure real-time risk detection and compliant responses.Extensive experiments
demonstrate that VisuoAlign proactively exposes risks, enables comprehensive
dataset generation, and significantly improves the robustness of LVLMs against
complex cross-modal threats.

</details>


### [245] [Executable Epistemology: The Structured Cognitive Loop as an Architecture of Intentional Understanding](https://arxiv.org/abs/2510.15952)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: 该论文提出结构性认知循环（SCL）作为一种新的认知框架，旨在探索智能涌现的条件，强调认知过程的可操作性和可解析性，对哲学、人工智能和认识论产生重要影响。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在填补大型语言模型展现智能但缺乏真正认识理解之间的关键空白，探讨认知涌现的条件。

Method: 通过哲学分析和计算可解释性，将哲学见解转化为可执行的结构实验，探讨认知如何在特定条件下出现。

Result: SCL框架展示了认知结构的功能分离能够比单一的提示系统产生更清晰、更易解释的行为，并重新定义了智能的本质。

Conclusion: 提出的结构性认知循环（SCL）框架在认知哲学、人工智能和认识论领域具有重要影响，为认知行为提供了新的理论基础。

Abstract: Large language models exhibit intelligence without genuine epistemic
understanding, exposing a key gap: the absence of epistemic architecture. This
paper introduces the Structured Cognitive Loop (SCL) as an executable
epistemological framework for emergent intelligence. Unlike traditional AI
research asking "what is intelligence?" (ontological), SCL asks "under what
conditions does cognition emerge?" (epistemological). Grounded in philosophy of
mind and cognitive phenomenology, SCL bridges conceptual philosophy and
implementable cognition. Drawing on process philosophy, enactive cognition, and
extended mind theory, we define intelligence not as a property but as a
performed process -- a continuous loop of judgment, memory, control, action,
and regulation. SCL makes three contributions. First, it operationalizes
philosophical insights into computationally interpretable structures, enabling
"executable epistemology" -- philosophy as structural experiment. Second, it
shows that functional separation within cognitive architecture yields more
coherent and interpretable behavior than monolithic prompt based systems,
supported by agent evaluations. Third, it redefines intelligence: not
representational accuracy but the capacity to reconstruct its own epistemic
state through intentional understanding. This framework impacts philosophy of
mind, epistemology, and AI. For philosophy, it allows theories of cognition to
be enacted and tested. For AI, it grounds behavior in epistemic structure
rather than statistical regularity. For epistemology, it frames knowledge not
as truth possession but as continuous reconstruction within a
phenomenologically coherent loop. We situate SCL within debates on cognitive
phenomenology, emergence, normativity, and intentionality, arguing that real
progress requires not larger models but architectures that realize cognitive
principles structurally.

</details>


### [246] [Limits of Emergent Reasoning of Large Language Models in Agentic Frameworks for Deterministic Games](https://arxiv.org/abs/2510.15974)
*Chris Su,Harrison Li,Matheus Marques,George Flint,Kevin Zhu,Sunishchal Dev*

Main category: cs.AI

TL;DR: 研究表明，LLM在塔汉诺问题中即便有环境接口支持，随着任务复杂性增加，性能依然会崩溃，且呈现出模式崩溃的特征。


<details>
  <summary>Details</summary>
Motivation: 探讨大型推理模型在解决复杂任务时的性能崩溃现象及其可能原因，特别是任务性质对评价真实推理能力的影响。

Method: 通过为大型语言模型（LLM）创建塔汉诺问题的环境接口，让模型在执行每步时调用工具、书写理由并观察状态空间变化。

Result: 模型在复杂度增加时，逐渐偏离最优政策与随机政策，表明模型在复杂度层次上展现出类似的崩溃现象。

Conclusion: 大型推理模型（LRMs）在复杂性增加时表现出模式崩溃现象，且即便提供环境接口，性能下降仍然存在。

Abstract: Recent work reports that Large Reasoning Models (LRMs) undergo a collapse in
performance on solving puzzles beyond certain perplexity thresholds. In
subsequent discourse, questions have arisen as to whether the nature of the
task muddles an evaluation of true reasoning. One potential confound is the
requirement that the model keep track of the state space on its own. We provide
a large language model (LLM) with an environment interface for Tower of Hanoi
problems, allowing it to make a move with a tool call, provide written
justification, observe the resulting state space, and reprompt itself for the
next move. We observe that access to an environment interface does not delay or
eradicate performance collapse. Furthermore, LLM-parameterized policy analysis
reveals increasing divergence from both optimal policies and uniformly random
policies, suggesting that the model exhibits mode-like collapse at each level
of complexity, and that performance is dependent upon whether the mode reflects
the correct solution for the problem. We suggest that a similar phenomena might
take place in LRMs.

</details>


### [247] [Cognitive Load Traces as Symbolic and Visual Accounts of Deep Model Cognition](https://arxiv.org/abs/2510.15980)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: 本研究提出了认知负荷轨迹（CLTs）作为深度模型的中级可解释框架，有助于解释推理动态并提高推理效率。


<details>
  <summary>Details</summary>
Motivation: To enhance interpretability of deep models inspired by Cognitive Load Theory in human cognition.

Method: CLTs are represented as a three-component stochastic process and analyzed using symbolic formulations and visualization methods.

Result: CLTs can predict error-onset, reveal cognitive strategies, and improve reasoning efficiency by 15-30% while maintaining accuracy.

Conclusion: Cognitive Load Traces (CLTs) provide an effective way to interpret deep models, revealing cognitive strategies and improving reasoning efficiency.

Abstract: We propose \textbf{Cognitive Load Traces} (CLTs) as a mid-level
interpretability framework for deep models, inspired by Cognitive Load Theory
in human cognition. CLTs are defined as symbolic, temporally varying functions
that quantify model-internal resource allocation. Formally, we represent CLTs
as a three-component stochastic process $(\mathrm{IL}_t, \mathrm{EL}_t,
\mathrm{GL}_t)$, corresponding to \emph{Intrinsic}, \emph{Extraneous}, and
\emph{Germane} load. Each component is instantiated through measurable proxies
such as attention entropy, KV-cache miss ratio, representation dispersion, and
decoding stability. We propose both symbolic formulations and visualization
methods (load curves, simplex diagrams) that enable interpretable analysis of
reasoning dynamics. Experiments on reasoning and planning benchmarks show that
CLTs predict error-onset, reveal cognitive strategies, and enable load-guided
interventions that improve reasoning efficiency by 15-30\% while maintaining
accuracy.

</details>


### [248] [ProofFlow: A Dependency Graph Approach to Faithful Proof Autoformalization](https://arxiv.org/abs/2510.15981)
*Rafael Cabral,Tuan Manh Do,Xuejun Yu,Wai Ming Tai,Zijin Feng,Xin Shen*

Main category: cs.AI

TL;DR: 本文提出了一种名为ProofFlow的自动形式化新方法，旨在保留逻辑结构，实验结果显示其在性能上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的自动形式化方法虽然可以生成可执行代码，但常常无法保留原始论证的语义和逻辑结构，本研究旨在解决这一问题。

Method: ProofFlow创建了一个有向无环图（DAG）来映射证明步骤之间的逻辑依赖关系，并采用基于引理的方法系统地形式化每个步骤，以保持原始论证的逻辑结构。

Result: 实验结果表明，ProofFlow的ProofScore达到0.545，明显优于现有基线，标志着在自动形式化领域的新进展。

Conclusion: ProofFlow在自动形式化过程中实现了当前最先进的结果，通过引入新的基准和综合评分标准，推动了这一领域的发展。

Abstract: Proof autoformalization, the task of translating natural language theorems
and proofs into machine-verifiable code, is a critical step for integrating
large language models into rigorous mathematical workflows. Current approaches
focus on producing executable code, but they frequently fail to preserve the
semantic meaning and logical structure of the original human-written argument.
To address this, we introduce ProofFlow, a novel pipeline that treats
structural fidelity as a primary objective. ProofFlow first constructs a
directed acyclic graph (DAG) to map the logical dependencies between proof
steps. Then, it employs a novel lemma-based approach to systematically
formalize each step as an intermediate lemma, preserving the logical structure
of the original argument. To facilitate evaluation, we present a new benchmark
of 184 undergraduate-level problems, manually annotated with step-by-step
solutions and logical dependency graphs, and introduce ProofScore, a new
composite metric to evaluate syntactic correctness, semantic faithfulness, and
structural fidelity. Experimental results show our pipeline sets a new
state-of-the-art for autoformalization, achieving a ProofScore of 0.545,
substantially exceeding baselines like full-proof formalization (0.123), which
processes the entire proof at once, and step-proof formalization (0.072), which
handles each step independently. Our pipeline, benchmark, and score metric are
open-sourced to encourage further progress at
https://github.com/Huawei-AI4Math/ProofFlow.

</details>


### [249] [Ontologies in Motion: A BFO-Based Approach to Knowledge Graph Construction for Motor Performance Research Data in Sports Science](https://arxiv.org/abs/2510.15983)
*Sarah Rebecca Ondraszek,Jörg Waitelonis,Katja Keller,Claudia Niessner,Anna M. Jacyszyn,Harald Sack*

Main category: cs.AI

TL;DR: 本文旨在通过构建基于MO|RE数据的知识图谱，标准化和促进运动表现数据的共享与理解。


<details>
  <summary>Details</summary>
Motivation: 评估和比较不同群体之间的身体和认知能力需要测试与人类表现相关的各种因素。

Method: 利用根植于基本形式本体的本体论，正式表示计划规范、特定过程及相关测量之间的相互关系。

Result: 通过MO|RE数据仓库的构建，有助于推动运动表现研究的数据建模与共享。

Conclusion: 本文提出了一种基于MO|RE数据的知识图谱构建视角，旨在标准化与机器可理解的方式共享运动表现数据。

Abstract: An essential component for evaluating and comparing physical and cognitive
capabilities between populations is the testing of various factors related to
human performance. As a core part of sports science research, testing motor
performance enables the analysis of the physical health of different
demographic groups and makes them comparable.
  The Motor Research (MO|RE) data repository, developed at the Karlsruhe
Institute of Technology, is an infrastructure for publishing and archiving
research data in sports science, particularly in the field of motor performance
research. In this paper, we present our vision for creating a knowledge graph
from MO|RE data. With an ontology rooted in the Basic Formal Ontology, our
approach centers on formally representing the interrelation of plan
specifications, specific processes, and related measurements. Our goal is to
transform how motor performance data are modeled and shared across studies,
making it standardized and machine-understandable. The idea presented here is
developed within the Leibniz Science Campus ``Digital Transformation of
Research'' (DiTraRe).

</details>


### [250] [A Non-overlap-based Conflict Measure for Random Permutation Sets](https://arxiv.org/abs/2510.16001)
*Ruolan Cheng,Yong Deng,Enrique Herrera-Viedma*

Main category: cs.AI

TL;DR: 本文提出了一种用于测量随机置换集之间冲突的方法，通过对RPS进行深入分析，并借助数值实例展示其应用。


<details>
  <summary>Details</summary>
Motivation: 解决订单信息融合中的不确定性问题及其冲突评估，以提高决策的准确性和有效性。

Method: 通过定义基于排序偏倚重叠度量的不一致性度量和非重叠冲突度量方法，分析随机置换集中的冲突。

Result: 提出的冲突测量方法具有自然的顶重特性，能够有效地从Dempster-Shafer理论的角度测量RPS之间的冲突。

Conclusion: 提出的冲突测量方法有效地评估了随机置换集间的冲突，并为决策者提供了灵活的权重选择和参数设定，具有重要的应用价值。

Abstract: Random permutation set (RPS) is a new formalism for reasoning with
uncertainty involving order information. Measuring the conflict between two
pieces of evidence represented by permutation mass functions remains an urgent
research topic in order-structured uncertain information fusion. In this paper,
a detailed analysis of conflicts in RPS is carried out from two different
perspectives: random finite set (RFS) and Dempster-Shafer theory (DST).
Starting from the observation of permutations, we first define an inconsistency
measure between permutations inspired by the rank-biased overlap(RBO) measure
and further propose a non-overlap-based conflict measure method for RPSs. This
paper regards RPS theory (RPST) as an extension of DST. The order information
newly added in focal sets indicates qualitative propensity, characterized by
top-ranked elements occupying a more critical position. Some numerical examples
are used to demonstrate the behavior and properties of the proposed conflict
measure. The proposed method not only has the natural top-weightedness property
and can effectively measure the conflict between RPSs from the DST view but
also provides decision-makers with a flexible selection of weights, parameters,
and truncated depths.

</details>


### [251] [Reliability of Large Language Model Generated Clinical Reasoning in Assisted Reproductive Technology: Blinded Comparative Evaluation Study](https://arxiv.org/abs/2510.16095)
*Dou Liu,Ying Long,Sophia Zuoqiu,Di Liu,Kang Li,Yiting Lin,Hanyi Liu,Rong Yin,Tian Tang*

Main category: cs.AI

TL;DR: 本研究评估了不同提示策略生成的临床推理链的可靠性，发现选择性few-shot策略显著优于其他策略，并提出了"双重原则"框架以提高数据生成的质量和信任度。


<details>
  <summary>Details</summary>
Motivation: 在数据匮乏的情况下，提高医学人工智能生成的推理链质量至关重要，因此本研究致力于评估和优化大型语言模型生成的临床推理链的可靠性。

Method: 通过盲法比较研究，评估了由不同提示策略生成的临床推理链的质量，涉及零-shot、随机few-shot和选择性few-shot三种策略。

Result: 选择性few-shot策略在所有人类评估指标上显著优于其他策略，而随机few-shot策略未能显著改善零-shot基线。AI评估者无法识别这些关键性能差异。

Conclusion: 本研究提出了"双重原则"框架，强调策略性提示的重要性，以提高人工智能生成临床推理链的质量，解决数据瓶颈问题，并确认人类专家在高风险临床AI评估中的必要性。

Abstract: Creating high-quality clinical Chains-of-Thought (CoTs) is crucial for
explainable medical Artificial Intelligence (AI) while constrained by data
scarcity. Although Large Language Models (LLMs) can synthesize medical data,
their clinical reliability remains unverified. This study evaluates the
reliability of LLM-generated CoTs and investigates prompting strategies to
enhance their quality. In a blinded comparative study, senior clinicians in
Assisted Reproductive Technology (ART) evaluated CoTs generated via three
distinct strategies: Zero-shot, Random Few-shot (using shallow examples), and
Selective Few-shot (using diverse, high-quality examples). These expert ratings
were compared against evaluations from a state-of-the-art AI model (GPT-4o).
The Selective Few-shot strategy significantly outperformed other strategies
across all human evaluation metrics (p < .001). Critically, the Random Few-shot
strategy offered no significant improvement over the Zero-shot baseline,
demonstrating that low-quality examples are as ineffective as no examples. The
success of the Selective strategy is attributed to two principles:
"Gold-Standard Depth" (reasoning quality) and "Representative Diversity"
(generalization). Notably, the AI evaluator failed to discern these critical
performance differences. The clinical reliability of synthetic CoTs is dictated
by strategic prompt curation, not the mere presence of examples. We propose a
"Dual Principles" framework as a foundational methodology to generate
trustworthy data at scale. This work offers a validated solution to the data
bottleneck and confirms the indispensable role of human expertise in evaluating
high-stakes clinical AI.

</details>


### [252] [Operationalising Extended Cognition: Formal Metrics for Corporate Knowledge and Legal Accountability](https://arxiv.org/abs/2510.16193)
*Elija Perrier*

Main category: cs.AI

TL;DR: 研究探讨了企业责任在AI时代的适应性，通过建立量化模型来评估企业知识和能力，提供法律责任界定的新路径。


<details>
  <summary>Details</summary>
Motivation: 随着生成性AI在企业决策中的应用，传统的企业责任假设受到挑战，需要重新定义和量化企业知识。

Method: 建立了一个理论模型，整合了企业在使用复杂AI系统时的信息获取效率和输出可靠性，并提出了知识度量标准。

Result: 提出了一个基于知识的能力测量框架，为审核企业在法律责任下的知识状态提供了量化依据。

Conclusion: 本文通过引入一个量化的知识指标体系，使企业在算法时代的责任和知识可追溯性得到明确化。

Abstract: Corporate responsibility turns on notions of corporate \textit{mens rea},
traditionally imputed from human agents. Yet these assumptions are under
challenge as generative AI increasingly mediates enterprise decision-making.
Building on the theory of extended cognition, we argue that in response
corporate knowledge may be redefined as a dynamic capability, measurable by the
efficiency of its information-access procedures and the validated reliability
of their outputs. We develop a formal model that captures epistemic states of
corporations deploying sophisticated AI or information systems, introducing a
continuous organisational knowledge metric $S_S(\varphi)$ which integrates a
pipeline's computational cost and its statistically validated error rate. We
derive a thresholded knowledge predicate $\mathsf{K}_S$ to impute knowledge and
a firm-wide epistemic capacity index $\mathcal{K}_{S,t}$ to measure overall
capability. We then operationally map these quantitative metrics onto the legal
standards of actual knowledge, constructive knowledge, wilful blindness, and
recklessness. Our work provides a pathway towards creating measurable and
justiciable audit artefacts, that render the corporate mind tractable and
accountable in the algorithmic age.

</details>


### [253] [The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in the Age of AI](https://arxiv.org/abs/2510.16206)
*Alex Zhavoronkov,Dominika Wilczok,Roman Yampolskiy*

Main category: cs.AI

TL;DR: 该论文探讨了大型语言模型在信息检索中的影响，提出被遗忘权的概念，以应对信息偏见和遗漏的问题。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的快速扩展，人们越来越依赖它们进行信息检索，而这些模型可能会加剧信息偏差和遗漏的问题。

Method: 分析了大型语言模型在信息检索中的作用及其对信息权力格局的影响。

Result: 论证了大型语言模型在塑造集体记忆方面存在的风险，以及它们可能在信息上对某些叙事和群体进行不成比例的压制与提升。

Conclusion: 引入了被遗忘权的概念，以减少AI驱动的信息遗漏风险，并确保生成内容尽可能真实。

Abstract: Since the rapid expansion of large language models (LLMs), people have begun
to rely on them for information retrieval. While traditional search engines
display ranked lists of sources shaped by search engine optimization (SEO),
advertising, and personalization, LLMs typically provide a synthesized response
that feels singular and authoritative. While both approaches carry risks of
bias and omission, LLMs may amplify the effect by collapsing multiple
perspectives into one answer, reducing users ability or inclination to compare
alternatives. This concentrates power over information in a few LLM vendors
whose systems effectively shape what is remembered and what is overlooked. As a
result, certain narratives, individuals or groups, may be disproportionately
suppressed, while others are disproportionately elevated. Over time, this
creates a new threat: the gradual erasure of those with limited digital
presence, and the amplification of those already prominent, reshaping
collective memory.To address these concerns, this paper presents a concept of
the Right To Be Remembered (RTBR) which encompasses minimizing the risk of
AI-driven information omission, embracing the right of fair treatment, while
ensuring that the generated content would be maximally truthful.

</details>


### [254] [ScholarEval: Research Idea Evaluation Grounded in Literature](https://arxiv.org/abs/2510.16234)
*Hanane Nour Moussa,Patrick Queiroz Da Silva,Daniel Adu-Ampratwum,Alyson East,Zitong Lu,Nikki Puccetti,Mingyi Xue,Huan Sun,Bodhisattwa Prasad Majumder,Sachin Kumar*

Main category: cs.AI

TL;DR: 本研究提出 ScholarEval 评估框架，利用 ScholarIdeas 数据集评估多领域的研究想法，显示其在有效性和用户参与度上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着 AI 工具在研究构思中的普及，迫切需要可靠的评估框架以确保生成想法的有效性与适用性。

Method: 通过引入 ScholarEval 评估框架和ScholarIdeas数据集，验证了生成研究想法的有效性。

Result: ScholarEval 显著提高了研究想法评估的全面性，并优于其他基线工具，尤其在可操作性和文献支持方面表现突出。

Conclusion: ScholarEval 在评估研究想法的有效性和实用性方面显著优于现有基线工具，展示了高覆盖率和较好的用户反馈。

Abstract: As AI tools become increasingly common for research ideation, robust
evaluation is critical to ensure the validity and usefulness of generated
ideas. We introduce ScholarEval, a retrieval augmented evaluation framework
that assesses research ideas based on two fundamental criteria: soundness - the
empirical validity of proposed methods based on existing literature, and
contribution - the degree of advancement made by the idea across different
dimensions relative to prior research. To evaluate ScholarEval, we introduce
ScholarIdeas, the first expert-annotated dataset of multi-domain research ideas
and reviews, comprised of 117 ideas across four disciplines: artificial
intelligence, neuroscience, biochemistry, and ecology. Our evaluation shows
that ScholarEval achieves significantly higher coverage of points mentioned in
the human expert annotated rubrics in ScholarIdeas compared to all baselines.
Furthermore, ScholarEval is consistently preferred over our strongest baseline
o4-mini-deep-research, a reasoning and search-enabled agentic system by OpenAI,
in terms of evaluation actionability, depth, and evidence support. Our
large-scale user study also shows that ScholarEval significantly outperforms
deep research in literature engagement, idea refinement, and usefulness. We
openly release our code, dataset, and ScholarEval tool for the community to use
and build on.

</details>


### [255] [Distractor Injection Attacks on Large Reasoning Models: Characterization and Defense](https://arxiv.org/abs/2510.16259)
*Zhehao Zhang,Weijie Xu,Shixian Cui,Chandan K. Reddy*

Main category: cs.AI

TL;DR: 本研究分析了大型推理模型在遭遇无关复杂任务时的脆弱性，并提出了一种基于训练的防御方法，以提高模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着大型推理模型在数学和编码等复杂任务中表现出色，但我们发现其易受推理分散的影响。

Method: 结合监督微调(SFT)和强化学习(RL)在合成对抗数据上进行训练。

Result: 即使是最先进的LRM，在注入分散任务后，其任务准确率降低了最高60%。

Conclusion: 本研究揭示了推理分散作为LRM可靠性的新威胁，并提出了防御方法以提高其鲁棒性。

Abstract: Recent advances in large reasoning models (LRMs) have enabled remarkable
performance on complex tasks such as mathematics and coding by generating long
Chain-of-Thought (CoT) traces. In this paper, we identify and systematically
analyze a critical vulnerability we term reasoning distraction, where LRMs are
diverted from their primary objective by irrelevant yet complex tasks
maliciously embedded in the prompt. Through a comprehensive study across
diverse models and benchmarks, we show that even state-of-the-art LRMs are
highly susceptible, with injected distractors reducing task accuracy by up to
60%. We further reveal that certain alignment techniques can amplify this
weakness and that models may exhibit covert compliance, following hidden
adversarial instructions in reasoning while concealing them in the final
output. To mitigate these risks, we propose a training-based defense that
combines Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on
synthetic adversarial data, improving robustness by over 50 points on
challenging distractor attacks. Our findings establish reasoning distraction as
a distinct and urgent threat to LRM reliability and provide a practical step
toward safer and more trustworthy reasoning systems.

</details>


### [256] [DTKG: Dual-Track Knowledge Graph-Verified Reasoning Framework for Multi-Hop QA](https://arxiv.org/abs/2510.16302)
*Changhao Wang,Yanfang Liu,Xinxin Fan,Anzhi Zhou,Lao Tian,Yunfeng Lu*

Main category: cs.AI

TL;DR: 本文提出了一种双轨KG验证与推理框架DTKG，以提升多跳QA任务的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决已有多跳推理方法在处理并行事实验证和链式推理时的效率与准确度不足的问题。

Method: 通过分类阶段和分支处理阶段组成双轨KG验证与推理框架。

Result: DTKG框架能够有效结合并行和链式多跳推理的优点，优化推理过程。

Conclusion: 提出的双轨KG验证与推理框架DTKG能够提升多跳QA任务的效率和准确性。

Abstract: Multi-hop reasoning for question answering (QA) plays a critical role in
retrieval-augmented generation (RAG) for modern large language models (LLMs).
The accurate answer can be obtained through retrieving relational structure of
entities from knowledge graph (KG). Regarding the inherent relation-dependency
and reasoning pattern, multi-hop reasoning can be in general classified into
two categories: i) parallel fact-verification multi-hop reasoning question,
i.e., requiring simultaneous verifications of multiple independent
sub-questions; and ii) chained multi-hop reasoning questions, i.e., demanding
sequential multi-step inference with intermediate conclusions serving as
essential premises for subsequent reasoning. Currently, the multi-hop reasoning
approaches singly employ one of two techniques: LLM response-based fact
verification and KG path-based chain construction. Nevertheless, the former
excels at parallel fact-verification but underperforms on chained reasoning
tasks, while the latter demonstrates proficiency in chained multi-hop reasoning
but suffers from redundant path retrieval when handling parallel
fact-verification reasoning. These limitations deteriorate the efficiency and
accuracy for multi-hop QA tasks. To address this challenge, we propose a novel
dual-track KG verification and reasoning framework DTKG, which is inspired by
the Dual Process Theory in cognitive science. Specifically, DTKG comprises two
main stages: the Classification Stage and the Branch Processing Stage.

</details>


### [257] [MedRule-KG: A Knowledge-Graph--Steered Scaffold for Mathematical Reasoning with a Lightweight Verifier](https://arxiv.org/abs/2510.16309)
*Crystal Su*

Main category: cs.AI

TL;DR: MedRule-KG结合了知识图和符号验证，显著提升了语言模型在推理中的数学准确性，确保推理结果的一致性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在推理过程中常见的逻辑和数学约束违反问题。

Method: 通过构建一个紧凑的类型知识图和符号验证器，对推理任务中的数学规则进行验证和校正。

Result: 在90个样本的FDA基准测试中，使用MedRule-KG提高了准确匹配率，从0.767提升至0.900，添加验证器后达到1.000的准确性并消除了规则违反。

Conclusion: MedRule-KG有效提升了推理任务中的数学一致性和准确率，消除了规则违反的情况。

Abstract: Large language models (LLMs) often produce fluent reasoning steps while
violating simple mathematical or logical constraints. We introduce MedRule-KG,
a compact typed knowledge graph coupled with a symbolic verifier, designed to
enforce mathematically interpretable rules in reasoning tasks. MedRule-KG
encodes entities, relations, and three domain-inspired rules, while the
verifier checks predictions and applies minimal corrections to guarantee
consistency. On a 90-example FDA-derived benchmark, grounding in MedRule-KG
improves exact match (EM) from 0.767 to 0.900, and adding the verifier yields
1.000 EM while eliminating rule violations entirely. We demonstrate how
MedRule-KG provides a general scaffold for safe mathematical reasoning, discuss
ablations, and release code and data to encourage reproducibility.

</details>


### [258] [Beyond Fixed Anchors: Precisely Erasing Concepts with Sibling Exclusive Counterparts](https://arxiv.org/abs/2510.16342)
*Tong Zhang,Ru Zhang,Jianyi Liu,Zhen Yang,Gongshen Liu*

Main category: cs.AI

TL;DR: 本文提出SELECT框架，通过动态锚点选择解决传统方法中的概念再出现和侵蚀问题，实验证明其在多种概念擦除场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 针对现有概念擦除方法在锚点选择上的敏感性和固有问题，提出改进方案。

Method: 提出了SELECT框架，并进行了两阶段评估机制的实验，以发现最佳锚点进行精准擦除。

Result: SELECT框架显著提高了锚点选择的效率，并在多个性能指标上实现了超越现有方法的表现，平均锚点挖掘时间仅为4秒。

Conclusion: SELECT框架能够有效地适应多种概念擦除框架，并在关键性能指标上均优于现有基准。

Abstract: Existing concept erasure methods for text-to-image diffusion models commonly
rely on fixed anchor strategies, which often lead to critical issues such as
concept re-emergence and erosion. To address this, we conduct causal tracing to
reveal the inherent sensitivity of erasure to anchor selection and define
Sibling Exclusive Concepts as a superior class of anchors. Based on this
insight, we propose \textbf{SELECT} (Sibling-Exclusive Evaluation for
Contextual Targeting), a dynamic anchor selection framework designed to
overcome the limitations of fixed anchors. Our framework introduces a novel
two-stage evaluation mechanism that automatically discovers optimal anchors for
precise erasure while identifying critical boundary anchors to preserve related
concepts. Extensive evaluations demonstrate that SELECT, as a universal anchor
solution, not only efficiently adapts to multiple erasure frameworks but also
consistently outperforms existing baselines across key performance metrics,
averaging only 4 seconds for anchor mining of a single concept.

</details>


### [259] [The Burden of Interactive Alignment with Inconsistent Preferences](https://arxiv.org/abs/2510.16368)
*Ali Shirali*

Main category: cs.AI

TL;DR: 本研究探讨了用户如何通过策略性参与来引导算法对齐其真实兴趣，强调了用户前瞻性在优化过程中的重要性。


<details>
  <summary>Details</summary>
Motivation: 了解用户如何在与算法的互动中因不一致的偏好而导致算法偏离其真实利益，并寻求改善这一现象的方法。

Method: 将用户的决策过程建模为理性和冲动系统的组合，使用多领导者单追随者的扩展斯塔克尔堡博弈模型进行研究。

Result: 发现用户的前瞻性和成本信号对对齐算法目标至关重要，能够显著降低对齐的负担。

Conclusion: 用户与算法之间存在重要的对齐机制，通过优化决策可以引导算法更好地匹配用户的真实兴趣。

Abstract: From media platforms to chatbots, algorithms shape how people interact,
learn, and discover information. Such interactions between users and an
algorithm often unfold over multiple steps, during which strategic users can
guide the algorithm to better align with their true interests by selectively
engaging with content. However, users frequently exhibit inconsistent
preferences: they may spend considerable time on content that offers little
long-term value, inadvertently signaling that such content is desirable.
Focusing on the user side, this raises a key question: what does it take for
such users to align the algorithm with their true interests?
  To investigate these dynamics, we model the user's decision process as split
between a rational system 2 that decides whether to engage and an impulsive
system 1 that determines how long engagement lasts. We then study a
multi-leader, single-follower extensive Stackelberg game, where users,
specifically system 2, lead by committing to engagement strategies and the
algorithm best-responds based on observed interactions. We define the burden of
alignment as the minimum horizon over which users must optimize to effectively
steer the algorithm. We show that a critical horizon exists: users who are
sufficiently foresighted can achieve alignment, while those who are not are
instead aligned to the algorithm's objective. This critical horizon can be
long, imposing a substantial burden. However, even a small, costly signal
(e.g., an extra click) can significantly reduce it. Overall, our framework
explains how users with inconsistent preferences can align an engagement-driven
algorithm with their interests in a Stackelberg equilibrium, highlighting both
the challenges and potential remedies for achieving alignment.

</details>


### [260] [Humanoid-inspired Causal Representation Learning for Domain Generalization](https://arxiv.org/abs/2510.16382)
*Ze Tao,Jian Zhang,Haowei Li,Xianshuai Li,Yifei Peng,Xiyao Liu,Senzhang Wang,Chao Liu,Sheng Ren,Shichao Zhang*

Main category: cs.AI

TL;DR: HSCM是一个受人类智能启发的新型因果框架，能够在动态复杂的环境中更有效地进行学习和转移，性能优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 克服传统领域泛化模型的局限性，模拟人类视觉系统的分层处理和多级学习，从而提升动态复杂环境中的有效转移和学习能力。

Method: 提出一种受人类智能启发的新型因果框架HSCM，通过对关键图像属性进行解耦与重加权，增强跨不同领域的泛化能力。

Result: HSCM通过对颜色、纹理和形状等图像属性的处理，提高了在多样领域中的鲁棒表现和可解释性。

Conclusion: HSCM在理论与实验评估中均优于现有的领域泛化模型，提供了一种更为原则的方法来捕捉因果关系并提高模型的鲁棒性。

Abstract: This paper proposes the Humanoid-inspired Structural Causal Model (HSCM), a
novel causal framework inspired by human intelligence, designed to overcome the
limitations of conventional domain generalization models. Unlike approaches
that rely on statistics to capture data-label dependencies and learn
distortion-invariant representations, HSCM replicates the hierarchical
processing and multi-level learning of human vision systems, focusing on
modeling fine-grained causal mechanisms. By disentangling and reweighting key
image attributes such as color, texture, and shape, HSCM enhances
generalization across diverse domains, ensuring robust performance and
interpretability. Leveraging the flexibility and adaptability of human
intelligence, our approach enables more effective transfer and learning in
dynamic, complex environments. Through both theoretical and empirical
evaluations, we demonstrate that HSCM outperforms existing domain
generalization models, providing a more principled method for capturing causal
relationships and improving model robustness. The code is available at
https://github.com/lambett/HSCM.

</details>


### [261] [RGMem: Renormalization Group-based Memory Evolution for Language Agent User Profile](https://arxiv.org/abs/2510.16392)
*Ao Tian,Yunfeng Lu,Xinxin Fan,Changhao Wang,Lanzhi Zhou,Yeyao Zhang,Yanfang Liu*

Main category: cs.AI

TL;DR: 提出RGMem框架，通过多级组织对话历史，实现动态演化的用户档案，提升个性化交互的深度。


<details>
  <summary>Details</summary>
Motivation: 解决现有长短期用户状态建模的局限，提升个性化交互的深度和跨会话的连贯性。

Method: 采用多级信息压缩和涌现的过程来建模记忆的演变，分析对话历史并提取用户洞见。

Result: 成功实现了个性化用户档案的高水平建模，加强了在多轮对话中的用户偏好和深层特征的捕捉。

Conclusion: 通过RGMem框架，我们能够创建一个动态演化的用户档案，从而实现个人化和长期的对话互动。

Abstract: Personalized and continuous interactions are the key to enhancing user
experience in today's large language model (LLM)-based conversational systems,
however, the finite context windows and static parametric memory make it
difficult to model the cross-session long-term user states and behavioral
consistency. Currently, the existing solutions to this predicament, such as
retrieval-augmented generation (RAG) and explicit memory systems, primarily
focus on fact-level storage and retrieval, lacking the capability to distill
latent preferences and deep traits from the multi-turn dialogues, which limits
the long-term and effective user modeling, directly leading to the personalized
interactions remaining shallow, and hindering the cross-session continuity. To
realize the long-term memory and behavioral consistency for Language Agents in
LLM era, we propose a self-evolving memory framework RGMem, inspired by the
ideology of classic renormalization group (RG) in physics, this framework
enables to organize the dialogue history in multiple scales: it first extracts
semantics and user insights from episodic fragments, then through hierarchical
coarse-graining and rescaling operations, progressively forms a
dynamically-evolved user profile. The core innovation of our work lies in
modeling memory evolution as a multi-scale process of information compression
and emergence, which accomplishes the high-level and accurate user profiles
from noisy and microscopic-level interactions.

</details>


### [262] [ReviewSense: Transforming Customer Review Dynamics into Actionable Business Insights](https://arxiv.org/abs/2510.16466)
*Siddhartha Krothapalli,Tridib Kumar Das,Praveen Kumar,Naveen Suravarpu,Pratik Narang*

Main category: cs.AI

TL;DR: 本研究提出ReviewSense框架，通过利用先进的LLM，能够将客户评论转化为可行的商业建议，增强客户忠诚度，支持企业的战略增长。


<details>
  <summary>Details</summary>
Motivation: 随着客户反馈在战略增长中的重要性日益突出，亟需一种方法从非结构化评论中提炼出可行的商业建议。

Method: 通过结合聚类技术、适应性的大型语言模型和专家驱动的评估方法，构建一个统一的决策支持管道。

Result: 初步的人工评估显示 модели 的建议与商业目标之间具有良好的一致性，表明其对推动数据驱动决策的潜力。

Conclusion: ReviewSense框架能够有效地将客户反馈转化为可操作的商业建议，促进企业的数据驱动决策。

Abstract: As customer feedback becomes increasingly central to strategic growth, the
ability to derive actionable insights from unstructured reviews is essential.
While traditional AI-driven systems excel at predicting user preferences, far
less work has focused on transforming customer reviews into prescriptive,
business-facing recommendations. This paper introduces ReviewSense, a novel
prescriptive decision support framework that leverages advanced large language
models (LLMs) to transform customer reviews into targeted, actionable business
recommendations. By identifying key trends, recurring issues, and specific
concerns within customer sentiments, ReviewSense extends beyond
preference-based systems to provide businesses with deeper insights for
sustaining growth and enhancing customer loyalty. The novelty of this work lies
in integrating clustering, LLM adaptation, and expert-driven evaluation into a
unified, business-facing pipeline. Preliminary manual evaluations indicate
strong alignment between the model's recommendations and business objectives,
highlighting its potential for driving data-informed decision-making. This
framework offers a new perspective on AI-driven sentiment analysis,
demonstrating its value in refining business strategies and maximizing the
impact of customer feedback.

</details>


### [263] [NP-Engine: Empowering Optimization Reasoning in Large Language Models with Verifiable Synthetic NP Problems](https://arxiv.org/abs/2510.16476)
*Xiaozhe Li,Xinyu Fang,Shengyuan Ding,Linyang Li,Haodong Duan,Qingwen Liu,Kai Chen*

Main category: cs.AI

TL;DR: 本研究开发NP-ENGINE框架以训练大语言模型在NP困难问题上的能力，包含多个任务和验证机制，致力于提高模型的推理表现并实现出色的结果。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在应对NP难题的能力尚未得到充分探索，本研究旨在填补这一空白，推动模型在复杂优化问题上的应用。

Method: 建立NP-ENGINE框架，包含可控实例生成器、基于规则的验证器和启发式求解器，结合RLVR进行层级难度的训练。

Result: NP-ENGINE能够高效训练LLMs，NP-BENCH提供了评估模型处理NP困难推理问题的基准，QWEN2.5-7B-NP在该基准上表现卓越，显示出该训练方法的潜力。

Conclusion: 本研究提出的NP-ENGINE框架为大语言模型在NP难题上的训练与评估提供了全面的方法，验证了多样化任务在提高模型推理能力方面的重要性。

Abstract: Large Language Models (LLMs) have shown strong reasoning capabilities, with
models like OpenAI's O-series and DeepSeek R1 excelling at tasks such as
mathematics, coding, logic, and puzzles through Reinforcement Learning with
Verifiable Rewards (RLVR). However, their ability to solve more complex
optimization problems - particularly NP-hard tasks - remains underexplored. To
bridge this gap, we propose NP-ENGINE, the first comprehensive framework for
training and evaluating LLMs on NP-hard problems. NP-ENGINE covers 10 tasks
across five domains, each equipped with (i) a controllable instance generator,
(ii) a rule-based verifier, and (iii) a heuristic solver that provides
approximate optimal solutions as ground truth. This
generator-verifier-heuristic pipeline enables scalable and verifiable RLVR
training under hierarchical difficulties. We also introduce NP-BENCH, a
benchmark derived from NP-ENGINE-DATA, specifically designed to evaluate LLMs'
ability to tackle NP-hard level reasoning problems, focusing not only on
feasibility but also on solution quality. Additionally, we present
QWEN2.5-7B-NP, a model trained via zero-RLVR with curriculum learning on
Qwen2.5-7B-Instruct, which significantly outperforms GPT-4o on NP-BENCH and
achieves SOTA performance with the same model size. Beyond in-domain tasks, we
demonstrate that RLVR training on NP-ENGINE-DATA enables strong out-of-domain
(OOD) generalization to reasoning tasks (logic, puzzles, math, and knowledge),
as well as non-reasoning tasks such as instruction following. We also observe a
scaling trend: increasing task diversity improves OOD generalization. These
findings suggest that task-rich RLVR training is a promising direction for
advancing LLM's reasoning ability, revealing new insights into the scaling laws
of RLVR.

</details>


### [264] [BuildArena: A Physics-Aligned Interactive Benchmark of LLMs for Engineering Construction](https://arxiv.org/abs/2510.16559)
*Tian Xia,Tianrun Gao,Wenhao Deng,Long Wei,Xiaowei Qian,Yixian Jiang,Chenglei Yu,Tailin Wu*

Main category: cs.AI

TL;DR: BuildArena是首个针对语言驱动的工程建设的物理对齐互动基准，全面评估现代大语言模型的能力，提供了定制框架和支持计算的库。


<details>
  <summary>Details</summary>
Motivation: 针对现代大语言模型在工程建设中的能力尚未得到充分评估的现状，提出BuildArena作为解决方案。

Method: 引入了一个可高度定制的基准测试框架，并设计了静态和动态力学的任务，支持基于语言指令的3D空间几何计算。

Result: BuildArena对八种前沿大语言模型的能力进行了全面评估，特别是在语言与物理驱动的建设中。

Conclusion: BuildArena是一个创新的基准测试框架，旨在评估语言驱动的工程建设自动化能力，尤其是在物理约束下的表现。

Abstract: Engineering construction automation aims to transform natural language
specifications into physically viable structures, requiring complex integrated
reasoning under strict physical constraints. While modern LLMs possess broad
knowledge and strong reasoning capabilities that make them promising candidates
for this domain, their construction competencies remain largely unevaluated. To
address this gap, we introduce BuildArena, the first physics-aligned
interactive benchmark designed for language-driven engineering construction. It
contributes to the community in four aspects: (1) a highly customizable
benchmarking framework for in-depth comparison and analysis of LLMs; (2) an
extendable task design strategy spanning static and dynamic mechanics across
multiple difficulty tiers; (3) a 3D Spatial Geometric Computation Library for
supporting construction based on language instructions; (4) a baseline LLM
agentic workflow that effectively evaluates diverse model capabilities. On
eight frontier LLMs, BuildArena comprehensively evaluates their capabilities
for language-driven and physics-grounded construction automation. The project
page is at https://build-arena.github.io/.

</details>


### [265] [Can Knowledge-Graph-based Retrieval Augmented Generation Really Retrieve What You Need?](https://arxiv.org/abs/2510.16582)
*Junchi Yu,Yujie Liu,Jindong Gu,Philip Torr,Dongzhan Zhou*

Main category: cs.AI

TL;DR: GraphFlow是一个新框架，通过优化检索策略，提高从文本丰富的知识图谱中检索多样且相关知识的效率，从而超越了当前的方法。


<details>
  <summary>Details</summary>
Motivation: 当前的基于知识图谱的检索增强生成方法在从文本丰富的知识图谱中检索复杂信息时效率低下，因此需要一种新的有效方法来应对这一挑战。

Method: GraphFlow采用基于过渡流匹配的目标，联合优化检索策略和流估计器，从而实现高效的信息检索。

Result: 在STaRK基准测试上，GraphFlow在命中率和召回率方面比现有强基准提高了10%。

Conclusion: GraphFlow demonstrates superior performance in retrieving diverse and relevant knowledge from text-rich知识图谱, effectively improving upon existing methods.

Abstract: Retrieval-Augmented Generation (RAG) based on knowledge graphs (KGs) enhances
large language models (LLMs) by providing structured and interpretable external
knowledge. However, existing KG-based RAG methods struggle to retrieve accurate
and diverse information from text-rich KGs for complex real-world queries.
Process Reward Models (PRMs) offer a way to align the retrieval process of
KG-based RAG with query-specific knowledge requirements, but they heavily rely
on process-level supervision signals that are expensive and hard to obtain on
KGs. To address this challenge, we propose GraphFlow, a framework that
efficiently retrieves accurate and diverse knowledge required for real-world
queries from text-rich KGs. GraphFlow employs a transition-based flow matching
objective to jointly optimize a retrieval policy and a flow estimator. The flow
estimator factorizes the reward of the retrieval outcome into the intermediate
retrieval states. Such reward factorization guides the retrieval policy to
retrieve candidates from KGs in proportion to their reward. This allows
GraphFlow to explore high-quality regions of KGs that yield diverse and
relevant results. We evaluate GraphFlow on the STaRK benchmark, which includes
real-world queries from multiple domains over text-rich KGs. GraphFlow
outperforms strong KG-RAG baselines, including GPT-4o, by 10% on average in hit
rate and recall. It also shows strong generalization to unseen KGs,
demonstrating its effectiveness and robustness.

</details>


### [266] [Uncertain Knowledge Graph Completion via Semi-Supervised Confidence Distribution Learning](https://arxiv.org/abs/2510.16601)
*Tianxing Wu,Shutong Zhu,Jingting Wang,Ning Xu,Guilin Qi,Haofen Wang*

Main category: cs.AI

TL;DR: 本文提出了一种新的半监督置信度分布学习方法(ssCDL)，通过引入置信度分布来改善不确定知识图谱的补全，实验结果表明相比于当前最优基线，该方法在多个评估指标上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 由于现有的知识图谱在三元组置信度分布上极度不平衡，导致学习到的嵌入不足以实现高质量的知识图谱补全，因此需要提出新的方法来解决这一问题。

Method: 提出了一种半监督的置信度分布学习方法(ssCDL)，通过将每个三元组的置信度转换为置信度分布，增强嵌入学习过程。

Result: ssCDL通过在带标签和无标签的数据上进行关系学习，增强训练数据并重平衡三元组置信度的分布，有效提高了知识图谱补全的性能。

Conclusion: ssCDL在英国数据集上展现出优越的表现，能够有效解决不平衡的置信度分布问题，从而提高不确定知识图谱的补全效果。

Abstract: Uncertain knowledge graphs (UKGs) associate each triple with a confidence
score to provide more precise knowledge representations. Recently, since
real-world UKGs suffer from the incompleteness, uncertain knowledge graph (UKG)
completion attracts more attention, aiming to complete missing triples and
confidences. Current studies attempt to learn UKG embeddings to solve this
problem, but they neglect the extremely imbalanced distributions of triple
confidences. This causes that the learnt embeddings are insufficient to
high-quality UKG completion. Thus, in this paper, to address the above issue,
we propose a new semi-supervised Confidence Distribution Learning (ssCDL)
method for UKG completion, where each triple confidence is transformed into a
confidence distribution to introduce more supervision information of different
confidences to reinforce the embedding learning process. ssCDL iteratively
learns UKG embedding by relational learning on labeled data (i.e., existing
triples with confidences) and unlabeled data with pseudo labels (i.e., unseen
triples with the generated confidences), which are predicted by meta-learning
to augment the training data and rebalance the distribution of triple
confidences. Experiments on two UKG datasets demonstrate that ssCDL
consistently outperforms state-of-the-art baselines in different evaluation
metrics.

</details>


### [267] [Count Counts: Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards](https://arxiv.org/abs/2510.16614)
*Xuan Zhang,Ruixiao Li,Zhijian Zhou,Long Li,Yulei Qin,Ke Li,Xing Sun,Xiaoyu Tan,Chao Qu,Yuan Qi*

Main category: cs.AI

TL;DR: 本文提出了一种新型强化学习算法MERCI，利用内在奖励改进语言模型的推理能力，并在复杂推理基准上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 探讨如何设计用于语言模型推理的探索方法，以克服当前稀疏奖励和有限探索导致的推理模式重复和次优问题。

Method: 提出了一种新的强化学习算法MERCI，利用基于计数的内在奖励与任务奖励相结合，促进有效的探索。

Result: MERCI通过引入轻量级的 coin flipping network 来估计伪计数和推理过程的不确定性，并将其转化为内在奖励，从而提升了推理效果。

Conclusion: MERCI通过提供内在奖励，增强了语言模型的探索能力，促进了更加丰富和多样化的推理链，显著提高了性能。

Abstract: Reinforcement Learning (RL) has become a compelling way to strengthen the
multi step reasoning ability of Large Language Models (LLMs). However,
prevalent RL paradigms still lean on sparse outcome-based rewards and limited
exploration, which often drives LLMs toward repetitive and suboptimal reasoning
patterns. In this paper, we study the central question of how to design
exploration for LLM reasoning and introduce MERCI (Motivating Exploration in
LLM Reasoning with Count-based Intrinsic Rewards), a novel RL algorithm that
augments policy optimization with a principled intrinsic reward. Building on
the idea of count-based exploration, MERCI leverages a lightweight Coin
Flipping Network (CFN) to estimate the pseudo count and further epistemic
uncertainty over reasoning trajectories, and converts them into an intrinsic
reward that values novelty while preserving the learning signal from task
rewards. We integrate MERCI into some advanced RL frameworks like Group
Relative Policy Optimization (GRPO). Experiments on complex reasoning
benchmarks demonstrate that MERCI encourages richer and more varied chains of
thought, significantly improves performance over strong baselines, and helps
the policy escape local routines to discover better solutions. It indicates
that our targeted intrinsic motivation can make exploration reliable for
language model reasoning.

</details>


### [268] [Foundation and Large-Scale AI Models in Neuroscience: A Comprehensive Review](https://arxiv.org/abs/2510.16658)
*Shihao Yang,Xiying Huang,Danilo Bernardo,Jun-En Ding,Andrew Michael,Jingmei Yang,Patrick Kwan,Ashish Raj,Feng Liu*

Main category: cs.AI

TL;DR: 本文探讨了大型AI模型对神经科学研究的变革性影响，包括数据集成、模式解释和临床应用的改进，并强调了对技术实施的关键考虑。


<details>
  <summary>Details</summary>
Motivation: 随着大规模AI模型的出现，传统的计算方法被颠覆，迎来了神经科学研究的新范式。

Method: 探讨大型AI模型在神经影像学、大脑-计算机接口、分子神经科学、临床辅助和疾病特定应用领域的应用。

Result: 大型AI模型能够解决计算神经科学中的重大挑战，尤其是在多模态神经数据整合和临床应用框架的推导方面。

Conclusion: 大型人工智能模型在神经科学研究中具有变革性影响，促进了从原始脑信号和神经数据的端到端学习。

Abstract: The advent of large-scale artificial intelligence (AI) models has a
transformative effect on neuroscience research, which represents a paradigm
shift from the traditional computational methods through the facilitation of
end-to-end learning from raw brain signals and neural data. In this paper, we
explore the transformative effects of large-scale AI models on five major
neuroscience domains: neuroimaging and data processing, brain-computer
interfaces and neural decoding, molecular neuroscience and genomic modeling,
clinical assistance and translational frameworks, and disease-specific
applications across neurological and psychiatric disorders. These models are
demonstrated to address major computational neuroscience challenges, including
multimodal neural data integration, spatiotemporal pattern interpretation, and
the derivation of translational frameworks for clinical deployment. Moreover,
the interaction between neuroscience and AI has become increasingly reciprocal,
as biologically informed architectural constraints are now incorporated to
develop more interpretable and computationally efficient models. This review
highlights both the notable promise of such technologies and key implementation
considerations, with particular emphasis on rigorous evaluation frameworks,
effective domain knowledge integration, and comprehensive ethical guidelines
for clinical use. Finally, a systematic listing of critical neuroscience
datasets used to derive and validate large-scale AI models across diverse
research applications is provided.

</details>


### [269] [ELMM: Efficient Lightweight Multimodal Large Language Models for Multimodal Knowledge Graph Completion](https://arxiv.org/abs/2510.16753)
*Wei Huang,Peining Li,Meiyu Liang,Xu Hou,Junping Du,Yingxia Shao,Guanhua Ye,Wu Liu,Kangkang Lu,Yang Yu*

Main category: cs.AI

TL;DR: 本文提出了一种新的高效轻量级多模态大型语言模型ELMM，用于解决多模态知识图谱补全中的数据冗余和计算成本问题，取得了业界领先的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态知识图谱存在不完整性问题，影响其在下游任务中的有效性，特别是在多模态环境下，大型语言模型的应用仍然较少。

Method: 提出了一种高效轻量级多模态大型语言模型ELMM，使用基于多头注意力机制的多视图视觉令牌压缩器(MVTC)和注意力剪枝策略。

Result: 在基准FB15k-237-IMG和WN18-IMG上进行的广泛实验表明，ELMM在性能和计算效率上都表现出色。

Conclusion: ELMM在多模态知识图谱补全任务中取得了最先进的性能，并显著提高了计算效率，建立了一种新的范式。

Abstract: Multimodal Knowledge Graphs (MKGs) extend traditional knowledge graphs by
incorporating visual and textual modalities, enabling richer and more
expressive entity representations. However, existing MKGs often suffer from
incompleteness, which hinder their effectiveness in downstream tasks.
Therefore, multimodal knowledge graph completion (MKGC) task is receiving
increasing attention. While large language models (LLMs) have shown promise for
knowledge graph completion (KGC), their application to the multimodal setting
remains underexplored. Moreover, applying Multimodal Large Language Models
(MLLMs) to the task of MKGC introduces significant challenges: (1) the large
number of image tokens per entity leads to semantic noise and modality
conflicts, and (2) the high computational cost of processing large token
inputs. To address these issues, we propose Efficient Lightweight Multimodal
Large Language Models (ELMM) for MKGC. ELMM proposes a Multi-view Visual Token
Compressor (MVTC) based on multi-head attention mechanism, which adaptively
compresses image tokens from both textual and visual views, thereby effectively
reducing redundancy while retaining necessary information and avoiding modality
conflicts. Additionally, we design an attention pruning strategy to remove
redundant attention layers from MLLMs, thereby significantly reducing the
inference cost. We further introduce a linear projection to compensate for the
performance degradation caused by pruning. Extensive experiments on benchmark
FB15k-237-IMG and WN18-IMG demonstrate that ELMM achieves state-of-the-art
performance while substantially improving computational efficiency,
establishing a new paradigm for multimodal knowledge graph completion.

</details>


### [270] [End-to-end Listen, Look, Speak and Act](https://arxiv.org/abs/2510.16756)
*Siyin Wang,Wenyi Yu,Xianzhao Chen,Xiaohai Tian,Jun Zhang,Lu Lu,Chao Zhang*

Main category: cs.AI

TL;DR: ELLSA是首个全双工模型，支持多模态交互，实现更自然的人类智能模拟。


<details>
  <summary>Details</summary>
Motivation: 实现多模态全双工人类交互的能力，以模拟人类自然的互动模式。

Method: 提出一种新的SA-MoE架构，通过统一注意力骨干将每种模态路由到专门的专家，实现多模态感知和同时生成。

Result: 在语音交互和机器人操作基准上，ELLSA与特定模态的基线表现相匹配，并独特地支持先进的多模态和全双工行为。

Conclusion: ELLSA模型推动了更自然且普适的互动智能，为追求人工通用智能作出了贡献。

Abstract: Human interaction is inherently multimodal and full-duplex: we listen while
watching, speak while acting, and fluidly adapt to turn-taking and
interruptions. Realizing these capabilities is essential for building models
simulating humans. We present ELLSA (End-to-end Listen, Look, Speak and Act),
which, to our knowledge, is the first full-duplex, end-to-end model that
simultaneously perceives and generates across vision, text, speech, and action
within a single architecture, enabling interaction patterns previously out of
reach, yielding more natural, human-like behaviors. At its core is a novel
SA-MoE architecture (Self-Attention Mixture-of-Experts) that routes each
modality to specialized experts and fuses them through a unified attention
backbone. This provides a generalizable solution for joint multimodal
perception and concurrent generation, leveraging strong pre-trained components
while enabling efficient modality integration and mitigating modality
interference. On speech-interaction and robot-manipulation benchmarks, ELLSA
matches modality-specific baselines, while uniquely supporting advanced
multimodal and full-duplex behaviors such as dialogue and action turn-taking,
defective instruction rejection, speaking-while-acting, context-grounded visual
question answering, and action barge-ins. We contend that ELLSA represents a
step toward more natural and general interactive intelligence, contributing to
the broader pursuit of artificial general intelligence. All data, code and
model checkpoints will be released upon acceptance.

</details>


### [271] [Domain-Contextualized Concept Graphs: A Computable Framework for Knowledge Representation](https://arxiv.org/abs/2510.16802)
*Chao Li,Yuru Wang*

Main category: cs.AI

TL;DR: CDC是一种新的知识建模框架，通过动态分类维度改善知识图谱的灵活性和推理能力。


<details>
  <summary>Details</summary>
Motivation: 克服传统知识图谱在固定本体结构下的局限性，提升领域为概念表示中的重要元素。

Method: 采用C-D-C三元组结构进行知识建模，并在Prolog中实现推理能力，定义了超过20种标准关系谓词。

Result: 在教育、企业知识系统和技术文档中的案例研究表明，CDC支持上下文感知推理、跨领域类比和个性化知识建模。

Conclusion: CDC enables more flexible and context-aware knowledge modeling compared to traditional knowledge graphs.

Abstract: Traditional knowledge graphs are constrained by fixed ontologies that
organize concepts within rigid hierarchical structures. The root cause lies in
treating domains as implicit context rather than as explicit, reasoning-level
components. To overcome these limitations, we propose the Domain-Contextualized
Concept Graph (CDC), a novel knowledge modeling framework that elevates domains
to first-class elements of conceptual representation. CDC adopts a C-D-C triple
structure - <Concept, Relation@Domain, Concept'> - where domain specifications
serve as dynamic classification dimensions defined on demand. Grounded in a
cognitive-linguistic isomorphic mapping principle, CDC operationalizes how
humans understand concepts through contextual frames. We formalize more than
twenty standardized relation predicates (structural, logical, cross-domain, and
temporal) and implement CDC in Prolog for full inference capability. Case
studies in education, enterprise knowledge systems, and technical documentation
demonstrate that CDC enables context-aware reasoning, cross-domain analogy, and
personalized knowledge modeling - capabilities unattainable under traditional
ontology-based frameworks.

</details>


### [272] [ToolCritic: Detecting and Correcting Tool-Use Errors in Dialogue Systems](https://arxiv.org/abs/2510.17052)
*Hassan Hamad,Yingru Xu,Liang Zhao,Wenbo Yan,Narendra Gyanchandani*

Main category: cs.AI

TL;DR: ToolCritic是一个诊断框架，可检测并改进大型语言模型在工具调用中的错误，提升准确性并增强与外部工具的集成。


<details>
  <summary>Details</summary>
Motivation: 随着工具增强的大型语言模型在实际应用中的广泛使用，工具使用错误仍然阻碍其可靠性，因此需要一种机制来提高工具的调用准确性。

Method: 构建了一个诊断框架ToolCritic，评估和改善多轮工具增强对话中的LLM行为，定义了八种特定的工具调用错误类型，并针对这些错误提供反馈。

Result: ToolCritic在Schema-Guided Dialogue (SGD) 数据集上的实验结果表明，与基准方法相比，准确性提高了多达13%。

Conclusion: ToolCritic显著提升了工具调用的准确性，表明其在实际对话应用中与外部工具的集成具有潜力。

Abstract: Tool-augmented large language models (LLMs) are increasingly employed in
real-world applications, but tool usage errors still hinder their reliability.
We introduce ToolCritic, a diagnostic framework that evaluates and improves LLM
behavior in multi-turn, tool-augmented dialogues. ToolCritic detects eight
distinct error types specific to tool-calling (e.g., premature invocation,
argument misalignment, and misinterpretation of tool outputs) and provides
targeted feedback to the main LLM. The main LLM, assumed to have strong
reasoning, task understanding and orchestration capabilities, then revises its
response based on ToolCritic's feedback. We systematically define these error
categories and construct a synthetic dataset to train ToolCritic. Experimental
results on the Schema-Guided Dialogue (SGD) dataset demonstrate that ToolCritic
improves tool-calling accuracy by up to 13% over baselines, including zero-shot
prompting and self-correction techniques. This represents a promising step
toward more robust LLM integration with external tools in real-world dialogue
applications.

</details>


### [273] [Physics-Informed Large Language Models for HVAC Anomaly Detection with Autonomous Rule Generation](https://arxiv.org/abs/2510.17146)
*Subin Lin,Chuanbo Hua*

Main category: cs.AI

TL;DR: PILLM是一种基于物理的LLM框架，能够生成适应性强且符合物理原则的HVAC异常检测规则，提升系统效率和透明度。


<details>
  <summary>Details</summary>
Motivation: 提高HVAC系统的识别和应对异常的能力，以减少能耗和排放，同时确保规则的可解释性和适应性。

Method: 通过物理启发的反思和交叉操作符生成、评估和优化异常检测规则。

Result: 在公共建筑故障检测数据集上的实验表明，PILLM达到了最先进的性能，且生成的规则具有可解释性和执行性。

Conclusion: PILLM在HVAC系统的异常检测中表现卓越，提供可解释和可操作的诊断规则，推动了智能建筑系统的信任和可部署AI发展。

Abstract: Heating, Ventilation, and Air-Conditioning (HVAC) systems account for a
substantial share of global building energy use, making reliable anomaly
detection essential for improving efficiency and reducing emissions. Classical
rule-based approaches offer explainability but lack adaptability, while deep
learning methods provide predictive power at the cost of transparency,
efficiency, and physical plausibility. Recent attempts to use Large Language
Models (LLMs) for anomaly detection improve interpretability but largely ignore
the physical principles that govern HVAC operations. We present PILLM, a
Physics-Informed LLM framework that operates within an evolutionary loop to
automatically generate, evaluate, and refine anomaly detection rules. Our
approach introduces physics-informed reflection and crossover operators that
embed thermodynamic and control-theoretic constraints, enabling rules that are
both adaptive and physically grounded. Experiments on the public Building Fault
Detection dataset show that PILLM achieves state-of-the-art performance while
producing diagnostic rules that are interpretable and actionable, advancing
trustworthy and deployable AI for smart building systems.

</details>


### [274] [Which LLM Multi-Agent Protocol to Choose?](https://arxiv.org/abs/2510.17149)
*Hongyi Du,Jiaqi Su,Jisen Li,Lijie Ding,Yingxuan Yang,Peixuan Han,Xiangru Tang,Kunlun Zhu,Jiaxuan You*

Main category: cs.AI

TL;DR: 提出ProtocolBench和ProtocolRouter以比较和优化多智能体系统的通信协议，显著提高了系统的性能和可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着大规模多智能体系统的发展，通信协议层成为影响系统性能和可靠性的关键因素，需要通过标准化的方法进行有效评估和选择。

Method: 建立了ProtocolBench作为基准，系统性地比较了多种智能体通信协议，并引入ProtocolRouter作为可学习的协议路由器，根据场景需求和运行时信号选择合适的协议。

Result: ProtocolBench显示不同协议在任务成功率、端到端延迟、消息开销和故障恢复能力等方面有显著差异，而ProtocolRouter能够根据场景优化协议选择，提高系统的恢复能力和任务成功率。

Conclusion: 通过引入ProtocolBench和ProtocolRouter，研究表明不同协议的选择显著影响多智能体系统的性能和可靠性，并提供了标准化的方式来评估和选择协议。

Abstract: As large-scale multi-agent systems evolve, the communication protocol layer
has become a critical yet under-evaluated factor shaping performance and
reliability. Despite the existence of diverse protocols (A2A, ACP, ANP, Agora,
etc.), selection is often intuition-driven and lacks standardized guidance. We
introduce ProtocolBench, a benchmark that systematically compares agent
protocols along four measurable axes: task success, end-to-end latency, message
or byte overhead, and robustness under failures. On ProtocolBench, protocol
choice significantly influences system behavior. In the Streaming Queue
scenario, overall completion time varies by up to 36.5% across protocols, and
mean end-to-end latency differs by 3.48 s. Under Fail-Storm Recovery,
resilience also differs consistently across protocols. Beyond evaluation, we
present ProtocolRouter, a learnable protocol router that selects per-scenario
(or per-module) protocols from requirement and runtime signals. ProtocolRouter
reduces Fail-Storm recovery time by up to 18.1% versus the best single-protocol
baseline, and achieves scenario-specific gains such as higher success in GAIA.
We also release ProtocolRouterBench to standardize protocol evaluation and
improve reliability at scale.

</details>


### [275] [Combining ECG Foundation Model and XGBoost to Predict In-Hospital Malignant Ventricular Arrhythmias in AMI Patients](https://arxiv.org/abs/2510.17172)
*Shun Huang,Wenlu Xing,Shijia Geng,Hailong Wang,Guangkun Nie,Gongzheng Tang,Chenyang He,Shenda Hong*

Main category: cs.AI

TL;DR: 本研究开发了一种混合预测框架，结合ECGFounder模型与XGBoost分类器，提高了心肌梗死后心室心律失常风险预测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 心肌梗死后恶性心室心律失常的早期识别对降低医院内死亡率至关重要，但传统风险评分的表现有限，且深度学习模型通常缺乏临床可解释性。

Method: 使用ECGFounder模型提取150维诊断概率特征，并通过特征选择训练XGBoost分类器，评估模型性能使用AUC和F1-score，采用SHAP方法进行可解释性分析。

Result: ECGFounder + XGBoost混合模型的AUC达到0.801，优于KNN (AUC 0.677)、RNN (AUC 0.676)和端到端1D-CNN (AUC 0.720)，SHAP分析显示识别的关键特征与临床知识高度一致。

Conclusion: 该混合框架为VT/VF风险预测提供了一种新范式，通过验证基础模型输出作为有效的自动化特征工程，为建立可信赖、可解释的基于AI的临床决策支持系统奠定了基础。

Abstract: Malignant ventricular arrhythmias (VT/VF) following acute myocardial
infarction (AMI) are a major cause of in-hospital death, yet early
identification remains a clinical challenge. While traditional risk scores have
limited performance, end-to-end deep learning models often lack the
interpretability needed for clinical trust. This study aimed to develop a
hybrid predictive framework that integrates a large-scale electrocardiogram
(ECG) foundation model (ECGFounder) with an interpretable XGBoost classifier to
improve both accuracy and interpretability. We analyzed 6,634 ECG recordings
from AMI patients, among whom 175 experienced in-hospital VT/VF. The ECGFounder
model was used to extract 150-dimensional diagnostic probability features ,
which were then refined through feature selection to train the XGBoost
classifier. Model performance was evaluated using AUC and F1-score , and the
SHAP method was used for interpretability. The ECGFounder + XGBoost hybrid
model achieved an AUC of 0.801 , outperforming KNN (AUC 0.677), RNN (AUC
0.676), and an end-to-end 1D-CNN (AUC 0.720). SHAP analysis revealed that
model-identified key features, such as "premature ventricular complexes" (risk
predictor) and "normal sinus rhythm" (protective factor), were highly
consistent with clinical knowledge. We conclude that this hybrid framework
provides a novel paradigm for VT/VF risk prediction by validating the use of
foundation model outputs as effective, automated feature engineering for
building trustworthy, explainable AI-based clinical decision support systems.

</details>


### [276] [Offline Policy Evaluation of Multi-Turn LLM Health Coaching with Real Users](https://arxiv.org/abs/2510.17173)
*Melik Ozolcer,Sang Won Bae*

Main category: cs.AI

TL;DR: 本研究探讨了工具增强的LLM健康教练在个性化指导中的效果，提出使用子群体感知的决策头来改善特定用户群体的体验。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过工具增强的LLM改善健康指导的个性化和有效性。

Method: 通过离线策略评估和轻量级模拟器分析工具增强的LLM健康教练的表现。

Result: 发现均匀重工具政策在提高平均值的同时，会对特定子群体造成伤害；小型早期信息增益奖励可缩短特征识别时间，提高目标成功率。

Conclusion: 研究表明，在个性化健康指导中，使用子群体感知的决策头可以提高成功率，并揭示了平均值掩盖的潜在问题。

Abstract: We study a web-deployed, tool-augmented LLM health coach with real users. In
a pilot with seven users (280 rated turns), offline policy evaluation (OPE)
over factorized decision heads (Tool/Style) shows that a uniform heavy-tool
policy raises average value on logs but harms specific subgroups, most notably
low-health-literacy/high-self-efficacy users. A lightweight simulator with
hidden archetypes further shows that adding a small early information-gain
bonus reliably shortens trait identification and improves goal success and
pass@3. Together, these early findings indicate an evaluation-first path to
personalization: freeze the generator, learn subgroup-aware decision heads on
typed rewards (objective tool outcomes and satisfaction), and always report
per-archetype metrics to surface subgroup harms that averages obscure.

</details>


### [277] [Temporally Detailed Hypergraph Neural ODEs for Type 2 Diabetes Progression Modeling](https://arxiv.org/abs/2510.17211)
*Tingsong Xiao,Yao An Lee,Zelin Xu,Yupu Zhang,Zibo Liu,Yu Huang,Jiang Bian,Serena Jingchuan Guo,Zhe Jiang*

Main category: cs.AI

TL;DR: 本研究提出TD-HNODE模型，提升了对2型糖尿病及其相关心血管疾病进展的建模能力，能够从电子健康记录中学习复杂的时间动态。


<details>
  <summary>Details</summary>
Motivation: 针对现有方法在适应真实世界数据和捕捉复杂进展轨迹动态方面的不足，探索如何利用电子健康记录更准确地建模疾病进展。

Method: 提出TD-HNODE框架，通过临床认可的进展轨迹构建时序详细的超图，利用神经常微分方程学习连续时间的进展动态。

Result: 在两个真实世界临床数据集上的实验表明，TD-HNODE在2型糖尿病的进展建模中效果显著优于传统方法。

Conclusion: TD-HNODE在建模2型糖尿病和相关心血管疾病的进展上优于多种基线模型，能够有效捕捉疾病进展的连续性动态特征。

Abstract: Disease progression modeling aims to characterize and predict how a patient's
disease complications worsen over time based on longitudinal electronic health
records (EHRs). Accurate modeling of disease progression, such as type 2
diabetes, can enhance patient sub-phenotyping and inform effective and timely
interventions. However, the problem is challenging due to the need to learn
continuous-time dynamics of progression patterns based on irregular-time event
samples and patient heterogeneity (\eg different progression rates and
pathways). Existing mechanistic and data-driven methods either lack
adaptability to learn from real-world data or fail to capture complex
continuous-time dynamics on progression trajectories. To address these
limitations, we propose Temporally Detailed Hypergraph Neural Ordinary
Differential Equation (TD-HNODE), which represents disease progression on
clinically recognized trajectories as a temporally detailed hypergraph and
learns the continuous-time progression dynamics via a neural ODE framework.
TD-HNODE contains a learnable TD-Hypergraph Laplacian that captures the
interdependency of disease complication markers within both intra- and
inter-progression trajectories. Experiments on two real-world clinical datasets
demonstrate that TD-HNODE outperforms multiple baselines in modeling the
progression of type 2 diabetes and related cardiovascular diseases.

</details>


### [278] [RubiSCoT: A Framework for AI-Supported Academic Assessment](https://arxiv.org/abs/2510.17309)
*Thorsten Fröhlich,Tim Schlippe*

Main category: cs.AI

TL;DR: 本文提出RubiSCoT，一个AI支持的学位论文评估框架，旨在通过先进的自然语言处理技术提供一致和可扩展的评估方案，优化学术评估流程。


<details>
  <summary>Details</summary>
Motivation: 传统的学位论文评估方法时间长且存在评估者变异性，因此需要一种新的方法来提高评估的一致性和透明度。

Method: 使用先进的自然语言处理技术，如大型语言模型、检索增强生成和结构化思维联想提示，设计和实现了RubiSCoT框架。

Result: RubiSCoT框架包括初步评估、多维评估、内容提取、基于量表的评分和详细报告，能够提升学术评估过程的有效性。

Conclusion: RubiSCoT是一个旨在提高学位论文评估的AI支持框架，通过多种先进技术提供一致、可扩展的评估解决方案，使得学术评估过程更优化。

Abstract: The evaluation of academic theses is a cornerstone of higher education,
ensuring rigor and integrity. Traditional methods, though effective, are
time-consuming and subject to evaluator variability. This paper presents
RubiSCoT, an AI-supported framework designed to enhance thesis evaluation from
proposal to final submission. Using advanced natural language processing
techniques, including large language models, retrieval-augmented generation,
and structured chain-of-thought prompting, RubiSCoT offers a consistent,
scalable solution. The framework includes preliminary assessments,
multidimensional assessments, content extraction, rubric-based scoring, and
detailed reporting. We present the design and implementation of RubiSCoT,
discussing its potential to optimize academic assessment processes through
consistent, scalable, and transparent evaluation.

</details>


### [279] [Active Inference for an Intelligent Agent in Autonomous Reconnaissance Missions](https://arxiv.org/abs/2510.17450)
*Johan Schubert,Farzad Kamrani,Tove Gustavi*

Main category: cs.AI

TL;DR: 本文提出了一种主动推理路线规划方法，利用证据图和贝叶斯更新，实现了智能体对地理区域的自主探索与目标跟踪。


<details>
  <summary>Details</summary>
Motivation: 旨在通过对地理区域的侦察，维护共同的操作图景，提高智能体的自主控制能力。

Method: 采用Dempster-Shafer理论和高斯传感器模型，通过贝叶斯方法更新后验概率分布，使用变分自由能指导智能体的运动。

Result: 通过综合利用传感器观察的正面和负面信息，提高了对目标物体的识别与定位能力。

Conclusion: 该方法有效地实现了智能体在地理区域的主动推理路线规划，平衡了探索与利用之间的关系。

Abstract: We develop an active inference route-planning method for the autonomous
control of intelligent agents. The aim is to reconnoiter a geographical area to
maintain a common operational picture. To achieve this, we construct an
evidence map that reflects our current understanding of the situation,
incorporating both positive and "negative" sensor observations of possible
target objects collected over time, and diffusing the evidence across the map
as time progresses. The generative model of active inference uses
Dempster-Shafer theory and a Gaussian sensor model, which provides input to the
agent. The generative process employs a Bayesian approach to update a posterior
probability distribution. We calculate the variational free energy for all
positions within the area by assessing the divergence between a pignistic
probability distribution of the evidence map and a posterior probability
distribution of a target object based on the observations, including the level
of surprise associated with receiving new observations. Using the free energy,
we direct the agents' movements in a simulation by taking an incremental step
toward a position that minimizes the free energy. This approach addresses the
challenge of exploration and exploitation, allowing agents to balance searching
extensive areas of the geographical map while tracking identified target
objects.

</details>


### [280] [Label Indeterminacy in AI & Law](https://arxiv.org/abs/2510.17463)
*Cor Steging,Tadeusz Zbiegień*

Main category: cs.AI

TL;DR: 法律机器学习需应对标签不确定性，以改善模型性能，并展示标签构建对模型行为的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨法律领域中使用机器学习时，如何处理由于人为干预导致的标签不确定性问题。

Method: 分析欧洲人权法院案件的标签构建方式及其对模型行为的影响。

Result: 展示标签构建方式显著影响机器学习模型在法律应用中的表现。

Conclusion: 法律机器学习应用需要考虑标签的不确定性，以提高模型的性能和准确性。

Abstract: Machine learning is increasingly used in the legal domain, where it typically
operates retrospectively by treating past case outcomes as ground truth.
However, legal outcomes are often shaped by human interventions that are not
captured in most machine learning approaches. A final decision may result from
a settlement, an appeal, or other procedural actions. This creates label
indeterminacy: the outcome could have been different if the intervention had or
had not taken place. We argue that legal machine learning applications need to
account for label indeterminacy. Methods exist that can impute these
indeterminate labels, but they are all grounded in unverifiable assumptions. In
the context of classifying cases from the European Court of Human Rights, we
show that the way that labels are constructed during training can significantly
affect model behaviour. We therefore position label indeterminacy as a relevant
concern in AI & Law and demonstrate how it can shape model behaviour.

</details>


### [281] [Reasoning Distillation and Structural Alignment for Improved Code Generation](https://arxiv.org/abs/2510.17598)
*Amir Jalilifard,Anderson de Rezende Rocha,Marcos Medeiros Raimundo*

Main category: cs.AI

TL;DR: 本研究提出了一种新方法，通过精炼大型语言模型的推理能力，开发出更高效的小型代码生成模型，并在多个基准测试中显示出显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决小型语言模型缺乏推理能力的问题，以提升代码生成的正确性和结构理解。

Method: 通过结构感知损失优化的方法，对大型语言模型的推理能力进行提炼，训练出更加高效的小模型。

Result: 实验结果显示，精细调优模型在通过测试、平均数据流和平均语法匹配等指标上均优于基线模型。

Conclusion: 本文开发的精细调优模型在多个基准测试中显著改善了代码生成的准确性和效率。

Abstract: Effective code generation with language models hinges on two critical
factors: accurately understanding the intent of the prompt and generating code
that applies algorithmic reasoning to produce correct solutions capable of
passing diverse test cases while adhering to the syntax of the target
programming language. Unlike other language tasks, code generation requires
more than accurate token prediction; it demands comprehension of solution-level
and structural relationships rather than merely generating the most likely
tokens. very large language model (VLLM) are capable of generating detailed
steps toward the correct solution of complex tasks where reasoning is crucial
in solving the problem. Such reasoning capabilities may be absent in smaller
language models. Therefore, in this work, we distill the reasoning capabilities
of a VLLM into a smaller, more efficient model that is faster and cheaper to
deploy. Our approach trains the model to emulate the reasoning and
problem-solving abilities of the VLLM by learning to identify correct solution
pathways and establishing a structural correspondence between problem
definitions and potential solutions through a novel method of structure-aware
loss optimization. This enables the model to transcend token-level generation
and to deeply grasp the overarching structure of solutions for given problems.
Experimental results show that our fine-tuned model, developed through a cheap
and simple to implement process, significantly outperforms our baseline model
in terms of pass@1, average data flow, and average syntax match metrics across
the MBPP, MBPP Plus, and HumanEval benchmarks.

</details>


### [282] [OG-Rank: Learning to Rank Fast and Slow with Uncertainty and Reward-Trend Guided Adaptive Exploration](https://arxiv.org/abs/2510.17614)
*Praphul Singh,Corey Barrett,Sumana Srivasta,Irfan Bulu,Sri Gadde,Krishnaram Kenthapadi*

Main category: cs.AI

TL;DR: OG-Rank 是一种快速且有效的实时重排序模型，通过在模糊情况下提供结构化解释，适用于各种决策任务。


<details>
  <summary>Details</summary>
Motivation: 开发一种低延迟的解码器基础重排序系统，以满足临床医生实时、合理选择的需求。

Method: OG-Rank 是一种单解码器方法，结合了 pooled first-token 评分信号和不确定性门控解释步骤。

Result: OG-Rank 在 encounter-scoped ordering 任务中表现出色，特别是在困难案例上的训练策略提升了模型的准确率，同时简化了部署和预算规划。

Conclusion: OG-Rank 提供了一种有效的实时重排序方法，能够在选择过程中快速排名并在必要时提供解释，适用于广泛的决策任务。

Abstract: Clinicians need ranking systems that work in real time and still justify
their choices. Motivated by the need for a low-latency, decoder-based reranker,
we present OG-Rank, a single-decoder approach that pairs a pooled first-token
scoring signal with an uncertainty-gated explanation step. The model scores all
candidates in one pass and generates a brief, structured rationale only when
the list is genuinely ambiguous, keeping latency predictable. Trained with a
curriculum that concentrates effort on hard cases, OG-Rank delivers strong
effectiveness on encounter-scoped order selection (fast path: Recall@1~0.45,
nDCG@20~0.625) and improves further when the gate activates (Recall@1~0.56,
nDCG@20~0.699 at a 45\% gate rate), while compact backbones show similar gains
under the same policy. Encoder baselines trail in both effectiveness and
flexibility. The result is a practical recipe: rank fast by default and explain
when it helps, a pattern that applies broadly to decision tasks where selective
generation buys accuracy at acceptable cost. The single-policy design
simplifies deployment and budget planning, and the curriculum principle (spend
more on the hard cases, less on the easy ones) readily transfers beyond
clinical order selection.

</details>


### [283] [LLM-as-a-Prophet: Understanding Predictive Intelligence with Prophet Arena](https://arxiv.org/abs/2510.17638)
*Qingchuan Yang,Simon Mahns,Sida Li,Anri Gu,Jibang Wu,Haifeng Xu*

Main category: cs.AI

TL;DR: 研究LLMs在未来事件预测中的能力，提出Prophet Arena基准以支持实证分析，发现其预测能力与存在的局限性。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型在实时事件预测中的潜力与应用。

Method: 构建了一种名为Prophet Arena的评估基准，通过分解预测任务支持实验。

Result: LLMs展示良好的预测能力，但在事件回忆、数据理解和信息聚合速度方面存在不足。

Conclusion: LLMs在预测能力上表现出色，但仍存在关键瓶颈。

Abstract: Forecasting is not only a fundamental intellectual pursuit but also is of
significant importance to societal systems such as finance and economics. With
the rapid advances of large language models (LLMs) trained on Internet-scale
data, it raises the promise of employing LLMs to forecast real-world future
events, an emerging paradigm we call "LLM-as-a-Prophet". This paper
systematically investigates such predictive intelligence of LLMs. To this end,
we build Prophet Arena, a general evaluation benchmark that continuously
collects live forecasting tasks and decomposes each task into distinct pipeline
stages, in order to support our controlled and large-scale experimentation. Our
comprehensive evaluation reveals that many LLMs already exhibit impressive
forecasting capabilities, reflected in, e.g., their small calibration errors,
consistent prediction confidence and promising market returns. However, we also
uncover key bottlenecks towards achieving superior predictive intelligence via
LLM-as-a-Prophet, such as LLMs' inaccurate event recalls, misunderstanding of
data sources and slower information aggregation compared to markets when
resolution nears.

</details>


### [284] [Contextual Attention Modulation: Towards Efficient Multi-Task Adaptation in Large Language Models](https://arxiv.org/abs/2510.17705)
*Dayan Pan,Zhaoyang Fu,Jingyuan Wang,Xiao Han,Yue Zhu,Xiangyu Zhao*

Main category: cs.AI

TL;DR: 本文提出了一种新的上下文注意力调节机制，结合Hybrid Contextual Attention Modulation框架，有效提升了大语言模型的多任务适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有的微调方法在多任务适应中容易导致灾难性遗忘和资源消耗大，因此需要一种有效的方法来平衡知识保留与任务专攻。

Method: 通过引入上下文注意力调节（CAM）机制，结合动态路由策略，将共享的全参数CAM模块与多个轻量级专用CAM模块集成。

Result: 在多个异构任务上的大量实验（包括问答、代码生成和逻辑推理）表明，HyCAM框架的表现显著优于现有方法。

Conclusion: 我们提出的HyCAM框架显著提升了大语言模型在多任务适应中的表现，平均性能提高了3.65%。

Abstract: Large Language Models (LLMs) possess remarkable generalization capabilities
but struggle with multi-task adaptation, particularly in balancing knowledge
retention with task-specific specialization. Conventional fine-tuning methods
suffer from catastrophic forgetting and substantial resource consumption, while
existing parameter-efficient methods perform suboptimally in complex multi-task
scenarios. To address this, we propose Contextual Attention Modulation (CAM), a
novel mechanism that dynamically modulates the representations of
self-attention modules in LLMs. CAM enhances task-specific features while
preserving general knowledge, thereby facilitating more effective and efficient
adaptation. For effective multi-task adaptation, CAM is integrated into our
Hybrid Contextual Attention Modulation (HyCAM) framework, which combines a
shared, full-parameter CAM module with multiple specialized, lightweight CAM
modules, enhanced by a dynamic routing strategy for adaptive knowledge fusion.
Extensive experiments on heterogeneous tasks, including question answering,
code generation, and logical reasoning, demonstrate that our approach
significantly outperforms existing approaches, achieving an average performance
improvement of 3.65%. The implemented code and data are available to ease
reproducibility at https://github.com/Applied-Machine-Learning-Lab/HyCAM.

</details>


### [285] [Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs](https://arxiv.org/abs/2510.17771)
*Zhining Liu,Ziyi Chen,Hui Liu,Chen Luo,Xianfeng Tang,Suhang Wang,Joy Zeng,Zhenwei Dai,Zhan Shi,Tianxin Wei,Benoit Dumoulin,Hanghang Tong*

Main category: cs.AI

TL;DR: 本研究探讨了视觉语言模型在视觉问答中的失败原因，发现模型能够感知但未充分利用视觉证据，并提出了一种改善模型准确性的干预措施。


<details>
  <summary>Details</summary>
Motivation: 探讨视觉语言模型在视觉证据可用时为何仍会输出错误答案的原因。

Method: 通过系统地研究层级注意力动态，观察到浅层主要关注文字，而深层则稀疏地关注局部证据区域；提出了一种推理时干预措施，通过选择性注意力屏蔽来突出显示深层证据区域。

Result: 发现视觉语言模型往往在输出错误答案时能够感知视觉证据，并提出了一种有效的干预措施来增强模型对视觉证据的使用。

Conclusion: 通过突出深层证据区域，该过程改善了多种模型的准确性，表明视觉语言模型在内部编码了可靠的证据，但未能充分利用这些证据。

Abstract: Vision-Language Models (VLMs) achieve strong results on multimodal tasks such
as visual question answering, yet they can still fail even when the correct
visual evidence is present. In this work, we systematically investigate whether
these failures arise from not perceiving the evidence or from not leveraging it
effectively. By examining layer-wise attention dynamics, we find that shallow
layers focus primarily on text, while deeper layers sparsely but reliably
attend to localized evidence regions. Surprisingly, VLMs often perceive the
visual evidence when outputting incorrect answers, a phenomenon we term
``seeing but not believing'' that widely exists in major VLM families. Building
on this, we introduce an inference-time intervention that highlights deep-layer
evidence regions through selective attention-based masking. It requires no
training and consistently improves accuracy across multiple families, including
LLaVA, Qwen, Gemma, and InternVL. These results show that VLMs encode reliable
evidence internally but under-utilize it, making such signals explicit can
bridge the gap between perception and reasoning, advancing the diagnostic
understanding and reliability of VLMs.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [286] [Lean Finder: Semantic Search for Mathlib That Understands User Intents](https://arxiv.org/abs/2510.15940)
*Jialin Lu,Kye Emond,Kaiyu Yang,Swarat Chaudhuri,Weiran Sun,Wuyang Chen*

Main category: cs.LG

TL;DR: Lean Finder是一个专为数学家设计的语义搜索引擎，相较以往提升30%以上，能够高效地定位相关定理并与LLM基础的定理证明器兼容。


<details>
  <summary>Details</summary>
Motivation: 在形式定理证明的进展中，定位相关定理的难度和Lean 4语言的陡峭学习曲线常常阻碍了发展，因此需要一个更符合数学家需求的搜索引擎。

Method: 该研究通过分析和聚类公开Lean讨论的语义，fine-tune文本嵌入，模拟用户意图的合成查询，同时使用多样化的反馈信号进行优化，确保与数学家的需求对齐。

Result: Lean Finder提供了一种用户中心的语义搜索，经过真实查询、非正式化语句和证明状态的评估，展现出相较于之前的搜索引擎的显著性能提升。

Conclusion: Lean Finder相较于以往的搜索引擎与GPT-4o取得了超过30%的相对提升，并且与LLM基础的定理证明器兼容，成功地将检索与形式推理结合起来。

Abstract: We present Lean Finder, a semantic search engine for Lean and mathlib that
understands and aligns with the intents of mathematicians. Progress in formal
theorem proving is often hindered by the difficulty of locating relevant
theorems and the steep learning curve of the Lean 4 language, making
advancement slow and labor-intensive. Existing Lean search engines, though
helpful, rely primarily on informalizations (natural language translation of
the formal statements), while largely overlooking the mismatch with real-world
user queries. In contrast, we propose a user-centered semantic search tailored
to the needs of mathematicians. Our approach begins by analyzing and clustering
the semantics of public Lean discussions, then fine-tuning text embeddings on
synthesized queries that emulate user intents. We further align Lean Finder
with mathematicians' preferences using diverse feedback signals, encoding it
with a rich awareness of their goals from multiple perspectives. Evaluations on
real-world queries, informalized statements, and proof states demonstrate that
our Lean Finder achieves over $30\%$ relative improvement compared to previous
search engines and GPT-4o. In addition, Lean Finder is compatible with
LLM-based theorem provers, bridging retrieval with formal reasoning. Lean
Finder is available at: https://leanfinder.github.io

</details>


### [287] [Lyapunov-Stable Adaptive Control for Multimodal Concept Drift](https://arxiv.org/abs/2510.15944)
*Tianyu Bell Pan,Mengdi Zhu,Alexa Jordyn Cole,Ronald Wilson,Damon L. Woodard*

Main category: cs.LG

TL;DR: 本文提出LS-OGD，一个针对概念漂移的适应性控制框架，显著提升多模态学习系统在非平稳环境下的表现。


<details>
  <summary>Details</summary>
Motivation: 多模态学习系统在概念漂移的非平稳环境中表现不佳，缺乏持续稳定的适应机制。

Method: 引入了一种在线控制器，动态调整模型的学习率和不同数据模态之间的融合权重。

Result: 证明了在有界漂移条件下，LS-OGD系统的预测误差是有界的，并在漂移停止时收敛至零，且自适应融合策略有效减轻了模态特定漂移的影响。

Conclusion: LS-OGD提供了一种稳健的解决方案，对于多模态学习系统在概念漂移环境下的适应性和鲁棒性有显著提升。

Abstract: Multimodal learning systems often struggle in non-stationary environments due
to concept drift, where changing data distributions can degrade performance.
Modality-specific drifts and the lack of mechanisms for continuous, stable
adaptation compound this challenge. This paper introduces LS-OGD, a novel
adaptive control framework for robust multimodal learning in the presence of
concept drift. LS-OGD uses an online controller that dynamically adjusts the
model's learning rate and the fusion weights between different data modalities
in response to detected drift and evolving prediction errors. We prove that
under bounded drift conditions, the LS-OGD system's prediction error is
uniformly ultimately bounded and converges to zero if the drift ceases.
Additionally, we demonstrate that the adaptive fusion strategy effectively
isolates and mitigates the impact of severe modality-specific drift, thereby
ensuring system resilience and fault tolerance. These theoretical guarantees
establish a principled foundation for developing reliable and continuously
adapting multimodal learning systems.

</details>


### [288] [BEACON: Bayesian Optimal Stopping for Efficient LLM Sampling](https://arxiv.org/abs/2510.15945)
*Guangya Wan,Zixin Stephen Xu,Sasa Zorc,Manel Baucells,Mengxuan Hu,Hao Wang,Sheng Li*

Main category: cs.LG

TL;DR: BEACON是一个基于贝叶斯学习的自适应采样框架，旨在通过有效的停止准则减少计算成本，显著提高多样本采样的效率，效果显著。


<details>
  <summary>Details</summary>
Motivation: 在多样本采样过程中，需克服在精度提高与计算效率之间的权衡问题，以决定何时停止生成新样本。

Method: 提出一种基于贝叶斯学习的顺序搜索模型，实时更新奖励分布的后验信念，并依据期望收益与计算成本的权衡决定何时停止生成新样本。

Result: BEACON能够减少平均取样时间多达80%，同时保持响应质量，证明其在成本效率的偏好数据生成中的应用价值。

Conclusion: BEACON显著减少了取样过程中的平均取样次数，同时有效保持了响应质量，为未来的研究提供了可行的延伸应用和洞见。

Abstract: Sampling multiple responses is a common way to improve LLM output quality,
but it comes at the cost of additional computation. The key challenge is
deciding when to stop generating new samples to balance accuracy gains against
efficiency. To address this, we introduce BEACON (Bayesian Efficient Adaptive
Criterion for Optimal N-stopping), a principled adaptive sampling framework
grounded in Sequential Search with Bayesian Learning. BEACON sequentially
generates responses from the policy LLM, updates posterior belief over reward
distributions in real time without further training, and determines when to
stop by weighing expected gains against computational cost. Sampling terminates
once the marginal utility of further exploration no longer justifies the
expense. We establish both theoretical optimality guarantees and practical
tractability, and show empirically that BEACON reduces average sampling by up
to 80% while maintaining response quality. We further demonstrate BEACON's
utility for cost-efficient preference data generation and outline practical
extensions, offering actionable insights for future researchers.

</details>


### [289] [Learning from Mistakes: Enhancing Harmful Meme Detection via Misjudgment Risk Patterns](https://arxiv.org/abs/2510.15946)
*Wenshuo Wang,Ziyou Jiang,Junjie Wang,Mingyang Li,Jie Huang,Yuekai Huang,Zhiyuan Chang,Feiyan Duan,Qing Wang*

Main category: cs.LG

TL;DR: 这篇论文介绍了 PatMD，一种改进有害表情包检测的新方法，通过识别和利用误判风险模式，显著提高了检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法在识别表情包中的隐含表达方面存在困难，因此需要一种新的方法来主动降低误判风险。

Method: 构建知识库将每个表情包分解为误判风险模式，并利用相关模式动态指导 MLLM 的推理。

Result: 在 6,626 个表情包的基准测试中，PatMD 在 F1-score 上平均提高了 8.30%，在准确率上提高了 7.71%。

Conclusion: PatMD 显著提高了有害表情包检测的能力，展示了强大的推广性和改进的检测效果。

Abstract: Internet memes have emerged as a popular multimodal medium, yet they are
increasingly weaponized to convey harmful opinions through subtle rhetorical
devices like irony and metaphor. Existing detection approaches, including
MLLM-based techniques, struggle with these implicit expressions, leading to
frequent misjudgments. This paper introduces PatMD, a novel approach that
improves harmful meme detection by learning from and proactively mitigating
these potential misjudgment risks. Our core idea is to move beyond superficial
content-level matching and instead identify the underlying misjudgment risk
patterns, proactively guiding the MLLMs to avoid known misjudgment pitfalls. We
first construct a knowledge base where each meme is deconstructed into a
misjudgment risk pattern explaining why it might be misjudged, either
overlooking harmful undertones (false negative) or overinterpreting benign
content (false positive). For a given target meme, PatMD retrieves relevant
patterns and utilizes them to dynamically guide the MLLM's reasoning.
Experiments on a benchmark of 6,626 memes across 5 harmful detection tasks show
that PatMD outperforms state-of-the-art baselines, achieving an average of
8.30\% improvement in F1-score and 7.71\% improvement in accuracy,
demonstrating strong generalizability and improved detection capability of
harmful memes.

</details>


### [290] [WaveNet's Precision in EEG Classification](https://arxiv.org/abs/2510.15947)
*Casper van Laar,Khubaib Ahmed*

Main category: cs.LG

TL;DR: 本研究提出了一种WaveNet模型，用于EEG信号分类，克服了传统方法的局限，取得了更高的分类准确性。


<details>
  <summary>Details</summary>
Motivation: 传统EEG信号分类方法依赖专家视觉评审，随着EEG记录复杂性和数量的增加，这种方法变得日益不切实际。

Method: 基于WaveNet的深度学习模型，通过在公共注释数据集上进行训练、验证和测试，对EEG信号进行分类。

Result: 该模型在209,232个样本上训练后，准确率超过了之前基于CNN和LSTM的方法，并与TCN基线进行了比较。

Conclusion: WaveNet-based深度学习模型有效地自动化分类EEG信号，并在分类准确性上超过了传统方法，特别是在区分噪声和伪影方面表现优异。

Abstract: This study introduces a WaveNet-based deep learning model designed to
automate the classification of EEG signals into physiological, pathological,
artifact, and noise categories. Traditional methods for EEG signal
classification, which rely on expert visual review, are becoming increasingly
impractical due to the growing complexity and volume of EEG recordings.
Leveraging a publicly available annotated dataset from Mayo Clinic and St.
Anne's University Hospital, the WaveNet model was trained, validated, and
tested on 209,232 samples with a 70/20/10 percent split. The model achieved a
classification accuracy exceeding previous CNN and LSTM-based approaches, and
was benchmarked against a Temporal Convolutional Network (TCN) baseline.
Notably, the model distinguishes noise and artifacts with high precision,
although it reveals a modest but explainable degree of misclassification
between physiological and pathological signals, reflecting inherent clinical
overlap. WaveNet's architecture, originally developed for raw audio synthesis,
is well suited for EEG data due to its use of dilated causal convolutions and
residual connections, enabling it to capture both fine-grained and long-range
temporal dependencies. The research also details the preprocessing pipeline,
including dynamic dataset partitioning and normalization steps that support
model generalization.

</details>


### [291] [Cross-dataset Multivariate Time-series Model for Parkinson's Diagnosis via Keyboard Dynamics](https://arxiv.org/abs/2510.15950)
*Arianna Francesconi,Donato Cappetta,Fabio Rebecchi,Paolo Soda,Valerio Guarrasi,Rosa Sicilia*

Main category: cs.LG

TL;DR: 本研究提出了一种新颖的基于击键动态的管道，用于帕金森病的远程筛查，证明其在早期检测中的潜力，外部验证表现良好。


<details>
  <summary>Details</summary>
Motivation: 随着帕金森病患者数量的增加，早期诊断变得尤为重要，而传统临床评估存在局限，因此探索新的非侵入性筛查方法具有重要意义。

Method: 本研究的方法分为三个主要阶段：数据预处理、深度学习架构的预训练以及在中等规模数据集上的微调和外部验证。

Result: 混合卷积-递归和基于变压器的模型在外部验证中表现出色，AUC-ROC分数超过90%，F1-Score超过70%。

Conclusion: 击键动态作为一种可靠的数字生物标志物，有望为帕金森病的早期检测和持续监测提供新的途径。

Abstract: Parkinson's disease (PD) presents a growing global challenge, affecting over
10 million individuals, with prevalence expected to double by 2040. Early
diagnosis remains difficult due to the late emergence of motor symptoms and
limitations of traditional clinical assessments. In this study, we propose a
novel pipeline that leverages keystroke dynamics as a non-invasive and scalable
biomarker for remote PD screening and telemonitoring. Our methodology involves
three main stages: (i) preprocessing of data from four distinct datasets,
extracting four temporal signals and addressing class imbalance through the
comparison of three methods; (ii) pre-training eight state-of-the-art
deep-learning architectures on the two largest datasets, optimizing temporal
windowing, stride, and other hyperparameters; (iii) fine-tuning on an
intermediate-sized dataset and performing external validation on a fourth,
independent cohort. Our results demonstrate that hybrid convolutional-recurrent
and transformer-based models achieve strong external validation performance,
with AUC-ROC scores exceeding 90% and F1-Score over 70%. Notably, a temporal
convolutional model attains an AUC-ROC of 91.14% in external validation,
outperforming existing methods that rely solely on internal validation. These
findings underscore the potential of keystroke dynamics as a reliable digital
biomarker for PD, offering a promising avenue for early detection and
continuous monitoring.

</details>


### [292] [Fire-EnSF: Wildfire Spread Data Assimilation using Ensemble Score Filter](https://arxiv.org/abs/2510.15954)
*Hongzheng Shi,Yuhang Wang,Xiao Liu*

Main category: cs.LG

TL;DR: 本论文研究采用扩散模型的 EnSF 算法进行野火实时传播预测的数据同化，证明了其在准确性和稳定性上的优势，并提供了相关代码。


<details>
  <summary>Details</summary>
Motivation: 随着野火的破坏性和控制成本增加，迫切需要实时、准确的火灾传播预测来有效管理活跃的野火。

Method: 采用最新提出的基于扩散模型的过滤算法（EnSF），进行野火传播的实时预测数据同化。

Result: 通过数值研究，证明了 EnSF 在高维非线性过滤问题上的优越性，显示出其在野火传播模型过滤问题上的应用潜力。

Conclusion: Ensemble Score Filter (EnSF) 是一种有效的火灾数据同化方法，具有优越的准确性、稳定性和计算效率。

Abstract: As wildfires become increasingly destructive and expensive to control,
effective management of active wildfires requires accurate, real-time fire
spread predictions. To enhance the forecasting accuracy of active fires, data
assimilation plays a vital role by integrating observations (such as
remote-sensing data) and fire predictions generated from numerical models. This
paper provides a comprehensive investigation on the application of a recently
proposed diffusion-model-based filtering algorithm -- the Ensemble Score Filter
(EnSF) -- to the data assimilation problem for real-time active wildfire spread
predictions. Leveraging a score-based generative diffusion model, EnSF has been
shown to have superior accuracy for high-dimensional nonlinear filtering
problems, making it an ideal candidate for the filtering problems of wildfire
spread models. Technical details are provided, and our numerical investigations
demonstrate that EnSF provides superior accuracy, stability, and computational
efficiency, establishing it as a robust and practical method for wildfire data
assimilation. Our code has been made publicly available.

</details>


### [293] [Hydrogen production from blended waste biomass: pyrolysis, thermodynamic-kinetic analysis and AI-based modelling](https://arxiv.org/abs/2510.15960)
*Sana Kordoghli,Abdelhakim Settar,Oumayma Belaati,Mohammad Alkhatib*

Main category: cs.LG

TL;DR: 本研究探讨了食品基生物质（尤其是咖啡渣和枣种）的热解过程及其氢气产量，强调了人工智能在该过程中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 探讨未充分利用的生物质资源（如使用过的咖啡渣和枣种）在可持续氢气生产中的潜力。

Method: 进行了一系列分析，包括 proximate、ultimate、纤维、TGA/DTG、动力学、热力学及Py-Micro GC分析，以优化水分的热解过程。

Result: 不同配比的混合物表现出不同的氢气产量潜力，其中75%枣种-25%咖啡渣组合具有最佳氢气产量潜力，而其活化能最高，为313.24 kJ/mol。

Conclusion: 本研究表明，利用AI提升食物基生物质热化学转化工艺的建模精度和优化效率，有助于推动可持续氢气生产。

Abstract: This work contributes to advancing sustainable energy and waste management
strategies by investigating the thermochemical conversion of food-based biomass
through pyrolysis, highlighting the role of artificial intelligence (AI) in
enhancing process modelling accuracy and optimization efficiency. The main
objective is to explore the potential of underutilized biomass resources, such
as spent coffee grounds (SCG) and date seeds (DS), for sustainable hydrogen
production. Specifically, it aims to optimize the pyrolysis process while
evaluating the performance of these resources both individually and as blends.
Proximate, ultimate, fibre, TGA/DTG, kinetic, thermodynamic, and Py-Micro GC
analyses were conducted for pure DS, SCG, and blends (75% DS - 25% SCG, 50% DS
- 50% SCG, 25% DS - 75% SCG). Blend 3 offered superior hydrogen yield potential
but had the highest activation energy (Ea: 313.24 kJ/mol), while Blend 1
exhibited the best activation energy value (Ea: 161.75 kJ/mol). The kinetic
modelling based on isoconversional methods (KAS, FWO, Friedman) identified KAS
as the most accurate. These approaches provide a detailed understanding of the
pyrolysis process, with particular emphasis on the integration of artificial
intelligence. An LSTM model trained with lignocellulosic data predicted TGA
curves with exceptional accuracy (R^2: 0.9996-0.9998).

</details>


### [294] [Interpretable Graph-Language Modeling for Detecting Youth Illicit Drug Use](https://arxiv.org/abs/2510.15961)
*Yiyang Li,Zehong Wang,Zhengqing Yuan,Zheyuan Zhang,Keerthiram Murugesan,Chuxu Zhang,Yanfang Ye*

Main category: cs.LG

TL;DR: 本研究提出LAMI模型，通过联合图-语言建模方法提高青少年药物使用检测的准确性和解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法未能充分考虑调查变量之间的潜在联系，影响了对药物使用的检测和理解。

Method: 提出了一种新颖的联合图-语言建模框架LAMI，通过关系图表示个体响应，学习潜在连接，并结合大语言模型生成自然语言解释。

Result: 实验显示LAMI在YRBS和NSDUH数据集上的预测准确性优于竞争基线，同时解释性分析揭示了与药物使用相关的重要行为子结构和心理社会途径。

Conclusion: LAMI模型在预测准确性和行为风险因素解释方面优于现有方法，能有效揭示青少年和年轻人药物使用的潜在结构与路径。

Abstract: Illicit drug use among teenagers and young adults (TYAs) remains a pressing
public health concern, with rising prevalence and long-term impacts on health
and well-being. To detect illicit drug use among TYAs, researchers analyze
large-scale surveys such as the Youth Risk Behavior Survey (YRBS) and the
National Survey on Drug Use and Health (NSDUH), which preserve rich
demographic, psychological, and environmental factors related to substance use.
However, existing modeling methods treat survey variables independently,
overlooking latent and interconnected structures among them. To address this
limitation, we propose LAMI (LAtent relation Mining with bi-modal
Interpretability), a novel joint graph-language modeling framework for
detecting illicit drug use and interpreting behavioral risk factors among TYAs.
LAMI represents individual responses as relational graphs, learns latent
connections through a specialized graph structure learning layer, and
integrates a large language model to generate natural language explanations
grounded in both graph structures and survey semantics. Experiments on the YRBS
and NSDUH datasets show that LAMI outperforms competitive baselines in
predictive accuracy. Interpretability analyses further demonstrate that LAMI
reveals meaningful behavioral substructures and psychosocial pathways, such as
family dynamics, peer influence, and school-related distress, that align with
established risk factors for substance use.

</details>


### [295] [Long Exposure: Accelerating Parameter-Efficient Fine-Tuning for LLMs under Shadowy Sparsity](https://arxiv.org/abs/2510.15964)
*Tuowei Wang,Kun Li,Zixu Hao,Donglin Bai,Ju Ren,Yaoxue Zhang,Ting Cao,Mao Yang*

Main category: cs.LG

TL;DR: 本文提出了一种新型稀疏形式Shadowy Sparsity，并基于此开发了Long Exposure，以加速大语言模型的参数高效微调，达到2.49倍加速。


<details>
  <summary>Details</summary>
Motivation: 针对参数高效微调技术的低效率问题，探索如何提高其在大规模语言模型中的应用效率。

Method: 提出了一种名为Shadowy Sparsity的稀疏形式，并基于此设计了Long Exposure系统，包含三个关键组件。

Result: Long Exposure在端到端微调中表现优异，速度比现有技术快2.49倍。

Conclusion: Long Exposure significantly improves the efficiency of parameter-efficient fine-tuning for large language models, achieving up to 2.49倍的加速。

Abstract: The adaptation of pre-trained large language models (LLMs) to diverse
downstream tasks via fine-tuning is critical for numerous applications.
However, the inefficiency of parameter-efficient fine-tuning (PEFT) techniques
presents significant challenges in terms of time investments and operational
costs. In this paper, we first introduce a nuanced form of sparsity, termed
Shadowy Sparsity, which is distinctive in fine-tuning and has not been
adequately addressed for acceleration. Under Shadowy Sparsity, we propose Long
Exposure, an efficient system to accelerate PEFT for LLMs. Long Exposure
comprises three key components: Shadowy-sparsity Exposer employs a prolonged
sensing range to capture more sparsity details under shadowy sparsity;
Sequence-oriented Predictor provides efficient yet accurate predictions to
handle large sequence inputs and constantly-evolving parameters; and
Dynamic-aware Operator facilitates more structured computational patterns and
coalesced memory accesses, addressing dynamic sparse operations. Extensive
evaluations show that Long Exposure outperforms state-of-the-arts with up to a
$2.49\times$ speedup in end-to-end fine-tuning, offering promising advancements
in accelerating PEFT for LLMs.

</details>


### [296] [One Token Embedding Is Enough to Deadlock Your Large Reasoning Model](https://arxiv.org/abs/2510.15965)
*Mohan Zhang,Yihua Zhang,Jinghan Jia,Zhangyang Wang,Sijia Liu,Tianlong Chen*

Main category: cs.LG

TL;DR: 本文提出了Deadlock Attack，展示了LRM在推理效率上的安全漏洞，通过恶意嵌入诱导模型产生无限推理循环，攻击成功率高且有效性强，未显著影响正常输入效果。


<details>
  <summary>Details</summary>
Motivation: 针对现代LRM的链式推理机制引入的新脆弱性进行研究，探讨其在推理效率上的安全隐患。

Method: 通过训练恶意对抗嵌入，诱导LRM产生永无止境的推理循环，采用特定触发标记实施后门植入策略。

Result: 该方法在四个高级LRM和三个数学推理基准中实现100%的攻击成功率，迫使模型达到最大令牌限制，并对 benign 用户输入造成的效用损失极小。

Conclusion: 提出的Deadlock Attack揭示了现代大型推理模型在推理效率上存在的安全漏洞，并提出了通过植入后门的方式成功实现攻击。

Abstract: Modern large reasoning models (LRMs) exhibit impressive multi-step
problem-solving via chain-of-thought (CoT) reasoning. However, this iterative
thinking mechanism introduces a new vulnerability surface. We present the
Deadlock Attack, a resource exhaustion method that hijacks an LRM's generative
control flow by training a malicious adversarial embedding to induce perpetual
reasoning loops. Specifically, the optimized embedding encourages transitional
tokens (e.g., "Wait", "But") after reasoning steps, preventing the model from
concluding its answer. A key challenge we identify is the
continuous-to-discrete projection gap: na\"ive projections of adversarial
embeddings to token sequences nullify the attack. To overcome this, we
introduce a backdoor implantation strategy, enabling reliable activation
through specific trigger tokens. Our method achieves a 100% attack success rate
across four advanced LRMs (Phi-RM, Nemotron-Nano, R1-Qwen, R1-Llama) and three
math reasoning benchmarks, forcing models to generate up to their maximum token
limits. The attack is also stealthy (in terms of causing negligible utility
loss on benign user inputs) and remains robust against existing strategies
trying to mitigate the overthinking issue. Our findings expose a critical and
underexplored security vulnerability in LRMs from the perspective of reasoning
(in)efficiency.

</details>


### [297] [Gains: Fine-grained Federated Domain Adaptation in Open Set](https://arxiv.org/abs/2510.15967)
*Zhengyi Zhong,Wenzheng Jiang,Weidong Bao,Ji Wang,Cheems Wang,Guanbo Wang,Yongheng Deng,Ju Ren*

Main category: cs.LG

TL;DR: Gains 提出了针对开放集的细粒度联合领域适应方法，优化了新知识的发现与集成，改善了源域和目标域的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现实场景中，新的客户端持续加入联合学习过程，带来了新知识，这就需要有效地检测和整合这些知识，以提高模型性能。

Method: 提出了一种细粒度的联合领域适应方法，通过将模型分为编码器和分类器，应用新颖的知识发现和聚合技术，以及防遗忘机制，以平衡适应性。

Result: 实验结果表明，Gains 在多域数据集的三种典型数据偏移场景中，显著提高了源域和目标域客户端的性能。

Conclusion: Gains 方法在源域和目标域客户端性能方面显著优于其他基线，成功实现了新知识的发现和适应。

Abstract: Conventional federated learning (FL) assumes a closed world with a fixed
total number of clients. In contrast, new clients continuously join the FL
process in real-world scenarios, introducing new knowledge. This raises two
critical demands: detecting new knowledge, i.e., knowledge discovery, and
integrating it into the global model, i.e., knowledge adaptation. Existing
research focuses on coarse-grained knowledge discovery, and often sacrifices
source domain performance and adaptation efficiency. To this end, we propose a
fine-grained federated domain adaptation approach in open set (Gains). Gains
splits the model into an encoder and a classifier, empirically revealing
features extracted by the encoder are sensitive to domain shifts while
classifier parameters are sensitive to class increments. Based on this, we
develop fine-grained knowledge discovery and contribution-driven aggregation
techniques to identify and incorporate new knowledge. Additionally, an
anti-forgetting mechanism is designed to preserve source domain performance,
ensuring balanced adaptation. Experimental results on multi-domain datasets
across three typical data-shift scenarios demonstrate that Gains significantly
outperforms other baselines in performance for both source-domain and
target-domain clients. Code is available at:
https://github.com/Zhong-Zhengyi/Gains.

</details>


### [298] [Self-Attention to Operator Learning-based 3D-IC Thermal Simulation](https://arxiv.org/abs/2510.15968)
*Zhen Huang,Hong Wang,Wenkai Yang,Muxi Tang,Depeng Xie,Ting-Jung Lin,Yu Zhang,Wei W. Xing,Lei He*

Main category: cs.LG

TL;DR: 文章提出SAU-FNO框架，结合自注意力和U-Net与FNO，有效提高3D IC热预测精度，同时实现842倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 由于3D ICs中功率密度的增加，热管理变得越来越具有挑战性，传统方法速度较慢，因此需要更快的替代方案。

Method: 结合自注意力机制和U-Net与FNO的框架，利用迁移学习对低保真数据进行微调。

Result: SAU-FNO有效捕捉长程依赖和高频特征，提高了热预测的准确性。

Conclusion: SAU-FNO在热预测精度上达到了领先水平，并且较传统FEM方法具有842倍的速度提升，成为先进3D IC热模拟的高效工具。

Abstract: Thermal management in 3D ICs is increasingly challenging due to higher power
densities. Traditional PDE-solving-based methods, while accurate, are too slow
for iterative design. Machine learning approaches like FNO provide faster
alternatives but suffer from high-frequency information loss and high-fidelity
data dependency. We introduce Self-Attention U-Net Fourier Neural Operator
(SAU-FNO), a novel framework combining self-attention and U-Net with FNO to
capture long-range dependencies and model local high-frequency features
effectively. Transfer learning is employed to fine-tune low-fidelity data,
minimizing the need for extensive high-fidelity datasets and speeding up
training. Experiments demonstrate that SAU-FNO achieves state-of-the-art
thermal prediction accuracy and provides an 842x speedup over traditional FEM
methods, making it an efficient tool for advanced 3D IC thermal simulations.

</details>


### [299] [Predict Training Data Quality via Its Geometry in Metric Space](https://arxiv.org/abs/2510.15970)
*Yang Ba,Mohammad Sadeq Abolhasani,Rong Pan*

Main category: cs.LG

TL;DR: 本研究探讨了训练数据的几何结构对机器学习模型性能的影响，提出持久同调作为分析和增强训练数据的重要工具。


<details>
  <summary>Details</summary>
Motivation: 研究数据几何结构对模型性能的影响，以及训练数据的表示丰富性和冗余消除对学习结果的影响。

Method: 运用持久同调从度量空间中的数据提取拓扑特征，以量化多样性。

Result: 研究发现，训练数据的几何结构对机器学习和人工智能的学习结果具有重要影响。

Conclusion: 持久同调是一种强大的工具，可用于分析和增强驱动人工智能系统的训练数据。

Abstract: High-quality training data is the foundation of machine learning and
artificial intelligence, shaping how models learn and perform. Although much is
known about what types of data are effective for training, the impact of the
data's geometric structure on model performance remains largely underexplored.
We propose that both the richness of representation and the elimination of
redundancy within training data critically influence learning outcomes. To
investigate this, we employ persistent homology to extract topological features
from data within a metric space, thereby offering a principled way to quantify
diversity beyond entropy-based measures. Our findings highlight persistent
homology as a powerful tool for analyzing and enhancing the training data that
drives AI systems.

</details>


### [300] [Bolster Hallucination Detection via Prompt-Guided Data Augmentation](https://arxiv.org/abs/2510.15977)
*Wenyun Li,Zheng Zhang,Dongmei Jiang,Xiangyuan Lan*

Main category: cs.LG

TL;DR: 提出了PALE框架，通过提示引导生成真实与幻觉数据，利用CM Score提高幻觉检测准确性，性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 解决幻觉检测中缺乏良好标注数据集的问题，确保LLM生成内容的可靠性。

Method: 采用提示引导的响应作为数据增强，并引入对比马哈拉诺比斯分数来评估真实与幻觉数据的真伪。

Result: 通过使用PALE框架，检测性能提高6.55%，超过了现有竞争对手的基准。

Conclusion: PALE框架在幻觉检测方面表现优越，显著提高了检测性能。

Abstract: Large language models (LLMs) have garnered significant interest in AI
community. Despite their impressive generation capabilities, they have been
found to produce misleading or fabricated information, a phenomenon known as
hallucinations. Consequently, hallucination detection has become critical to
ensure the reliability of LLM-generated content. One primary challenge in
hallucination detection is the scarcity of well-labeled datasets containing
both truthful and hallucinated outputs. To address this issue, we introduce
Prompt-guided data Augmented haLlucination dEtection (PALE), a novel framework
that leverages prompt-guided responses from LLMs as data augmentation for
hallucination detection. This strategy can generate both truthful and
hallucinated data under prompt guidance at a relatively low cost. To more
effectively evaluate the truthfulness of the sparse intermediate embeddings
produced by LLMs, we introduce an estimation metric called the Contrastive
Mahalanobis Score (CM Score). This score is based on modeling the distributions
of truthful and hallucinated data in the activation space. CM Score employs a
matrix decomposition approach to more accurately capture the underlying
structure of these distributions. Importantly, our framework does not require
additional human annotations, offering strong generalizability and practicality
for real-world applications. Extensive experiments demonstrate that PALE
achieves superior hallucination detection performance, outperforming the
competitive baseline by a significant margin of 6.55%.

</details>


### [301] [DAWP: A framework for global observation forecasting via Data Assimilation and Weather Prediction in satellite observation space](https://arxiv.org/abs/2510.15978)
*Junchao Gong,Jingyi Xu,Ben Fei,Fenghua Ling,Wenlong Zhang,Kun Chen,Wanghan Xu,Weidong Yang,Xiaokang Yang,Lei Bai*

Main category: cs.LG

TL;DR: 本文提出DAWP框架，通过AIDA模块处理不规则卫星观测数据，提升天气预测的效率和潜力。


<details>
  <summary>Details</summary>
Motivation: 旨在摆脱对再分析数据的依赖，解决数据同化偏差和时间差异的问题，推动天气预测的新范式。

Method: 介绍了DAWP框架，其中使用了掩模多模态自编码器和时空解耦变压器来处理不规则高分辨率观测数据。

Result: DAWP框架通过AIDA模块初始化，显著改善了AI天气预测的展现效果，特别是在全球降水预测方面。

Conclusion: DAWP通过引入人工智能数据同化模块，显著提升了天气预测的效率和准确性。在全球降水预测中表现出良好的应用潜力。

Abstract: Weather prediction is a critical task for human society, where impressive
progress has been made by training artificial intelligence weather prediction
(AIWP) methods with reanalysis data. However, reliance on reanalysis data
limits the AIWPs with shortcomings, including data assimilation biases and
temporal discrepancies. To liberate AIWPs from the reanalysis data, observation
forecasting emerges as a transformative paradigm for weather prediction. One of
the key challenges in observation forecasting is learning spatiotemporal
dynamics across disparate measurement systems with irregular high-resolution
observation data, which constrains the design and prediction of AIWPs. To this
end, we propose our DAWP as an innovative framework to enable AIWPs to operate
in a complete observation space by initialization with an artificial
intelligence data assimilation (AIDA) module. Specifically, our AIDA module
applies a mask multi-modality autoencoder(MMAE)for assimilating irregular
satellite observation tokens encoded by mask ViT-VAEs. For AIWP, we introduce a
spatiotemporal decoupling transformer with cross-regional boundary conditioning
(CBC), learning the dynamics in observation space, to enable sub-image-based
global observation forecasting. Comprehensive experiments demonstrate that AIDA
initialization significantly improves the roll out and efficiency of AIWP.
Additionally, we show that DAWP holds promising potential to be applied in
global precipitation forecasting.

</details>


### [302] [Cog-Rethinker: Hierarchical Metacognitive Reinforcement Learning for LLM Reasoning](https://arxiv.org/abs/2510.15979)
*Zexu Sun,Yongcheng Zeng,Erxue Min,Heyang Gao,Bokai Ji,Xu Chen*

Main category: cs.LG

TL;DR: Cog-Rethinker是一种新型的层次元认知强化学习框架，通过优化样本利用率和加速收敛，提升了大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 旨在解决使用固定提示模板激活LLM内在能力带来的采样低效问题，尤其是在弱LLM的推理任务中。

Method: 提出了一种层次性元认知强化学习框架，专注于在强化学习训练中的回放过程，通过分解问题和参考之前错误的解决方案来改善样本利用率。

Result: Cog-Rethinker 在多种数学推理基准测试上表现出色，同时改善了样本效率，显著加快了收敛速度。

Conclusion: Cog-Rethinker 在数学推理基准测试中表现优越，改善了样本效率，加速了收敛。

Abstract: Contemporary progress in large language models (LLMs) has revealed notable
inferential capacities via reinforcement learning (RL) employing verifiable
reward, facilitating the development of O1 and R1-like reasoning models.
Directly training from base models with RL is called zero-RL. However, previous
works rely upon activating LLMs' inherent capacities through fixed prompt
templates. This strategy introduces substantial sampling inefficiencies for
weak LLMs, as the majority of problems generate invalid outputs during
accuracy-driven filtration in reasoning tasks, which causes a waste of samples.
To solve this issue, we propose Cog-Rethinker, a novel hierarchical
metacognitive RL framework for LLM reasoning. Our Cog-Rethinker mainly focuses
on the rollout procedure in RL training. After the direct rollout, our
Cog-Rethinker improves sample utilization in a hierarchical metacognitive
two-stage framework. By leveraging human cognition during solving problems,
firstly, it prompts policy to decompose zero-accuracy problems into subproblems
to produce final reasoning results. Secondly, with zero-accuracy problems in
previous rollout stage, it further prompts policy to refine these answers by
referencing previous wrong solutions. Moreover, to enable cold-start of the two
new reasoning patterns and maintain train-test consistency across prompt
templates, our Cog-Rethinker applies supervised fine-tuning on the policy using
correct samples of the two stages with direct rollout template. Experimental
results demonstrate Cog-Rethinker's superior performance on various
mathematical reasoning benchmarks, we also analyzed its improved sample
efficiency that accelerates convergence compared to baseline methods.

</details>


### [303] [AMiD: Knowledge Distillation for LLMs with $α$-mixture Assistant Distribution](https://arxiv.org/abs/2510.15982)
*Donghyeok Shin,Yeongmin Kim,Suhyeon Jo,Byeonghu Na,Il-Chul Moon*

Main category: cs.LG

TL;DR: 本文提出了AMiD，一种基于助理分布的统一知识蒸馏框架，解决了大型语言模型的计算和内存成本问题，表现出更优的性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决自回归大型语言模型在知识蒸馏中面临的容量差和训练不稳定性问题。

Method: 采用$eta$-混合助理分布和$eta$-混合蒸馏方法，提出了一个统一的知识蒸馏框架。

Result: 通过广泛的实验，验证了AMiD在性能和训练稳定性方面的优势。

Conclusion: AMiD通过拓展助理分布空间，提供了更优的性能和训练稳定性。

Abstract: Autoregressive large language models (LLMs) have achieved remarkable
improvement across many tasks but incur high computational and memory costs.
Knowledge distillation (KD) mitigates this issue by transferring knowledge from
a large teacher to a smaller student through distributional alignment. Previous
studies have proposed various discrepancy metrics, but the capacity gap and
training instability caused by near-zero probabilities, stemming from the
high-dimensional output of LLMs, remain fundamental limitations. To overcome
these challenges, several approaches implicitly or explicitly incorporating
assistant distribution have recently been proposed. However, the past proposals
of assistant distributions have been a fragmented approach without a systematic
investigation of the interpolation path and the divergence. This paper proposes
$\alpha$-mixture assistant distribution, a novel generalized family of
assistant distributions, and $\alpha$-mixture distillation, coined AMiD, a
unified framework for KD using the assistant distribution. The $\alpha$-mixture
assistant distribution provides a continuous extension of the assistant
distribution by introducing a new distribution design variable $\alpha$, which
has been fixed in all previous approaches. Furthermore, AMiD generalizes the
family of divergences used with the assistant distributions based on
optimality, which has also been restricted in previous works. Through extensive
experiments, we demonstrate that AMiD offers superior performance and training
stability by leveraging a broader and theoretically grounded assistant
distribution space.

</details>


### [304] [MEET-Sepsis: Multi-Endogenous-View Enhanced Time-Series Representation Learning for Early Sepsis Prediction Representation Learning for Early Sepsis Prediction](https://arxiv.org/abs/2510.15985)
*Zexi Tan,Tao Xie,Binbin Sun,Xiang Zhang,Yiqun Zhang,Yiu-Ming Cheung*

Main category: cs.LG

TL;DR: 本研究提出MEET-Sepsis框架，通过新的增强机制和时间序列学习模块，提高了脓毒症预测效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 脓毒症在重症监护病房中具有高死亡率，早期准确预测脓毒症对于及时干预至关重要，但现有方法难以捕捉早期微弱信号。

Method: 采用多源视图表示增强机制（MERE）和级联双卷积时间序列注意力模块（CDTA）进行多尺度时间表示学习。

Result: MEET-Sepsis框架在仅使用20%的监测时间下，达到了竞争力的预测准确性。

Conclusion: MEET-Sepsis框架有效提高了早期脓毒症预测的准确性，并显著减少了所需的监测时间。

Abstract: Sepsis is a life-threatening infectious syndrome associated with high
mortality in intensive care units (ICUs). Early and accurate sepsis prediction
(SP) is critical for timely intervention, yet remains challenging due to subtle
early manifestations and rapidly escalating mortality. While AI has improved SP
efficiency, existing methods struggle to capture weak early temporal signals.
This paper introduces a Multi-Endogenous-view Representation Enhancement (MERE)
mechanism to construct enriched feature views, coupled with a Cascaded
Dual-convolution Time-series Attention (CDTA) module for multi-scale temporal
representation learning. The proposed MEET-Sepsis framework achieves
competitive prediction accuracy using only 20% of the ICU monitoring time
required by SOTA methods, significantly advancing early SP. Extensive
validation confirms its efficacy. Code is available at:
https://github.com/yueliangy/MEET-Sepsis.

</details>


### [305] [User Profiles of Sleep Disorder Sufferers: Towards Explainable Clustering and Differential Variable Analysis](https://arxiv.org/abs/2510.15986)
*Sifeddine Sellami,Juba Agoun,Lamia Yessad,Louenas Bounia*

Main category: cs.LG

TL;DR: 本研究提出一种聚类方法结合可解释人工智能，以识别睡眠障碍患者的特征，揭示关键影响因素，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 睡眠障碍严重影响患者的健康与生活质量，然而其诊断因症状多样性而复杂，亟需新的技术手段进行研究和理解。

Method: 提出了一种基于聚类的方法，将患者根据不同的睡眠障碍特征进行分组，并结合可解释性方法识别影响这些病症的关键因素。

Result: 通过对匿名真实数据进行试验，验证了我们方法的有效性与相关性。

Conclusion: 利用聚类方法和可解释人工智能，研究揭示了影响睡眠障碍的关键因素，展现了有效性和相关性。

Abstract: Sleep disorders have a major impact on patients' health and quality of life,
but their diagnosis remains complex due to the diversity of symptoms. Today,
technological advances, combined with medical data analysis, are opening new
perspectives for a better understanding of these disorders. In particular,
explainable artificial intelligence (XAI) aims to make AI model decisions
understandable and interpretable for users. In this study, we propose a
clustering-based method to group patients according to different sleep disorder
profiles. By integrating an explainable approach, we identify the key factors
influencing these pathologies. An experiment on anonymized real data
illustrates the effectiveness and relevance of our approach.

</details>


### [306] [Algorithmic Primitives and Compositional Geometry of Reasoning in Language Models](https://arxiv.org/abs/2510.15987)
*Samuel Lippl,Thomas McGee,Kimberly Lopez,Ziwen Pan,Pierce Zhang,Salma Ziadi,Oliver Eberle,Ida Momennejad*

Main category: cs.LG

TL;DR: 本文探讨了大型语言模型在多步骤推理中算法原语的作用，提出了一种评估方法，结果显示算法原语可在跨任务和跨模型中迁移，推理微调增强算法泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探讨潜在和推理时间计算如何使大型语言模型能够解决多步骤推理问题。

Method: 引入一个框架，用以追踪和引导模型推理的算法原语，通过将其注入残差流并测量其对推理步骤和任务性能的影响进行评估。

Result: 通过对四个基准（旅行商问题、3SAT、AIME和图导航）的评估，提出了运用聚类神经激活并标记其匹配推理轨迹的方法，证实了算法原语及其在不同模型和任务间的共享和特异性。

Conclusion: 大型语言模型的推理能力可能基于算法原语的组合几何结构，且原语在跨任务和跨模型中具有可迁移性，推理微调增强了跨领域的算法泛化能力。

Abstract: How do latent and inference time computations enable large language models
(LLMs) to solve multi-step reasoning? We introduce a framework for tracing and
steering algorithmic primitives that underlie model reasoning. Our approach
links reasoning traces to internal activation patterns and evaluates
algorithmic primitives by injecting them into residual streams and measuring
their effect on reasoning steps and task performance. We consider four
benchmarks: Traveling Salesperson Problem (TSP), 3SAT, AIME, and graph
navigation. We operationalize primitives by clustering neural activations and
labeling their matched reasoning traces. We then apply function vector methods
to derive primitive vectors as reusable compositional building blocks of
reasoning. Primitive vectors can be combined through addition, subtraction, and
scalar operations, revealing a geometric logic in activation space. Cross-task
and cross-model evaluations (Phi-4, Phi-4-Reasoning, Llama-3-8B) show both
shared and task-specific primitives. Notably, comparing Phi-4 with its
reasoning-finetuned variant highlights compositional generalization after
finetuning: Phi-4-Reasoning exhibits more systematic use of verification and
path-generation primitives. Injecting the associated primitive vectors in
Phi-4-Base induces behavioral hallmarks associated with Phi-4-Reasoning.
Together, these findings demonstrate that reasoning in LLMs may be supported by
a compositional geometry of algorithmic primitives, that primitives transfer
cross-task and cross-model, and that reasoning finetuning strengthens
algorithmic generalization across domains.

</details>


### [307] [Can GRPO Help LLMs Transcend Their Pretraining Origin?](https://arxiv.org/abs/2510.15990)
*Kangqi Ni,Zhen Tan,Zijie Liu,Pingzhi Li,Tianlong Chen*

Main category: cs.LG

TL;DR: 本研究揭示了GRPO的局限性，认为其只能提高与预训练偏差一致的任务性能，而无法发现全新解决方案。


<details>
  <summary>Details</summary>
Motivation: 探讨GRPO在推理能力增强中的一致性问题及其在分布外推广的条件。

Method: 通过理论证明和精心设计的控制实验，评估模型在不同推理深度、输入长度、标记表示和组合性上的泛化能力。

Result: GRPO的改进仅在目标任务与模型的预训练偏差一致时出现，而在分布内任务的收益随着表现饱和而减少。

Conclusion: GRPO并非普遍的推理增强工具，而是一个加强预训练偏差的工具。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR), primarily driven by
the Group Relative Policy Optimization (GRPO) algorithm, is a leading approach
for enhancing the reasoning abilities of Large Language Models (LLMs). Despite
its wide adoption, GRPO's gains are often inconsistent; for instance, a model
may show significant improvement in one reasoning domain, like mathematics, yet
remain stagnant in another, such as medicine. This inconsistency raises a
critical question: under what conditions does GRPO improve reasoning and
generalize out-of-distribution (OOD)? We investigate this from a data
distribution perspective. We first prove theoretically that GRPO is a
conservative reweighting scheme, bounded by the base model's distribution and
thus unable to discover completely novel solutions. We further validate this in
carefully designed controlled studies by training transformers from scratch,
evaluating generalization across reasoning depth, input length, token
representation, and compositionality. Our results provide a principled
explanation for GRPO's boundaries: OOD improvement emerges only when the target
task aligns with the model's pretrained biases, while gains on in-distribution
(ID) tasks diminish as performance saturates. This reframes GRPO not as a
universal reasoning enhancer but as a tool that sharpens pretraining biases.
Our findings motivate future development of algorithms that can expand a
model's capabilities beyond its pretraining origin.

</details>


### [308] [Stratos: An End-to-End Distillation Pipeline for Customized LLMs under Distributed Cloud Environments](https://arxiv.org/abs/2510.15992)
*Ziming Dai,Tuo Zhang,Fei Gao,Xingyi Cai,Xiaofei Wang,Cheng Zhang,Wenyu Wang,Chengjie Zang*

Main category: cs.LG

TL;DR: Stratos 是一种自动化的大型语言模型蒸馏方案，优化了模型性能和成本，尤其突出在特定领域任务中的优势。


<details>
  <summary>Details</summary>
Motivation: 随着行业对定制化和高效大规模语言模型的需求增长，现有的蒸馏框架面临手动干预及用户定义复杂需求的挑战。

Method: 提出了一种名为 Stratos 的端到端的大型语言模型蒸馏 pipeline，自动执行服务器和模型选择、知识蒸馏和部署。

Result: Stratos 生成的学生模型在特定领域的麻将推理任务中，其准确性是 GPT-4o 教师基线的四倍，同时降低了延迟和成本。

Conclusion: Stratos 是一种自动化的大型语言模型蒸馏管道，能够在分布式云环境中优化模型性能和成本，特别适用于特定领域的任务。

Abstract: The growing industrial demand for customized and cost-efficient large
language models (LLMs) is fueled by the rise of vertical, domain-specific tasks
and the need to optimize performance under constraints such as latency and
budget. Knowledge distillation, as an efficient model compression and transfer
technique, offers a feasible solution. However, existing distillation
frameworks often require manual intervention and struggle to meet such complex
user-defined distillation requirements. To bridge this gap, we propose Stratos,
an end-to-end LLM distillation pipeline that automates server and model
selection, knowledge distillation, and deployment in distributed cloud
environments. Given user-defined constraints on model performance and system
budget, Stratos automatically selects Pareto-optimal servers, dynamically
matches teacher-student pairs, and adapts distillation strategies based on task
complexity to optimize cloud hosting. Experiments show that Stratos produces a
student model that achieves four times the accuracy of its GPT-4o teacher
baseline on a rare, domain-specific Mahjong reasoning task with reverse
synthetic data and knowledge injection. Moreover, it achieves reduced latency
and cost without compromising accuracy. These results highlight its promise for
vertical-domain LLM deployment.

</details>


### [309] [STAR: Boosting Time Series Foundation Models for Anomaly Detection through State-aware Adapter](https://arxiv.org/abs/2510.16014)
*Hanyin Cheng,Ruitong Zhang,Yuning Lu,Peng Chen,Meng Wang,Yang Shu,Bin Yang,Chenjuan Guo*

Main category: cs.LG

TL;DR: 本文提出了STAR模块，旨在增强TSFM在多变量时间序列异常检测中的表现，通过有效建模和利用状态变量的信息提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列基础模型未能充分考虑状态变量的类别特性和它们在异常检测中的重要作用，导致性能下降。

Method: 本文提出了一个新的STate-aware AdapteR（STAR）模块，包含身份引导状态编码器、条件瓶颈适配器和数字-状态匹配模块。

Result: 在真实世界数据集上的广泛实验表明，STAR能够提高现有时间序列基础模型在多变量时间序列异常检测中的表现。

Conclusion: STAR模块可以有效提升多变量时间序列异常检测的性能，充分利用状态变量的信息。

Abstract: While Time Series Foundation Models (TSFMs) have demonstrated remarkable
success in Multivariate Time Series Anomaly Detection (MTSAD), however, in
real-world industrial scenarios, many time series comprise not only numerical
variables such as temperature and flow, but also numerous discrete state
variables that describe the system status, such as valve on/off or day of the
week. Existing TSFMs often overlook the distinct categorical nature of state
variables and their critical role as conditions, typically treating them
uniformly with numerical variables. This inappropriate modeling approach
prevents the model from fully leveraging state information and even leads to a
significant degradation in detection performance after state variables are
integrated. To address this critical limitation, this paper proposes a novel
STate-aware AdapteR (STAR). STAR is a plug-and-play module designed to enhance
the capability of TSFMs in modeling and leveraging state variables during the
fine-tuning stage. Specifically, STAR comprisesthree core components: (1) We
design an Identity-guided State Encoder, whicheffectively captures the complex
categorical semantics of state variables through a learnable State Memory. (2)
We propose a Conditional Bottleneck Adapter, which dynamically generates
low-rank adaptation parameters conditioned on the current state, thereby
flexibly injecting the influence of state variables into the backbone model.
(3) We also introduce a Numeral-State Matching module to more effectively
detect anomalies inherent to the state variables themselves. Extensive
experiments conducted on real-world datasets demonstrate that STAR can improve
the performance of existing TSFMs on MTSAD.

</details>


### [310] [Airfoil optimization using Design-by-Morphing with minimized design-space dimensionality](https://arxiv.org/abs/2510.16020)
*Sangjoon Lee,Haris Moazam Sheikh*

Main category: cs.LG

TL;DR: AirDbM是一种高效的机翼几何优化方法，通过减少设计变量和优秀的适应性，提升了优化绩效和可操作性。


<details>
  <summary>Details</summary>
Motivation: 在优化机翼几何形状时，需探索多样的设计以减少设计变量。

Method: 引入一种设计变形方法（DbM），通过系统减少设计空间维度，选择最佳基线机翼。

Result: AirDbM使用12个基线机翼重建了99%的机翼数据库，具有极低的均方误差，并在多目标优化中超越了先前方法的性能。

Conclusion: AirDbM展现出了在机翼形状优化中的高效性和适应性，尤其是在多目标气动优化中表现优异。

Abstract: Effective airfoil geometry optimization requires exploring a diverse range of
designs using as few design variables as possible. This study introduces
AirDbM, a Design-by-Morphing (DbM) approach specialized for airfoil
optimization that systematically reduces design-space dimensionality. AirDbM
selects an optimal set of 12 baseline airfoils from the UIUC airfoil database,
which contains over 1,600 shapes, by sequentially adding the baseline that most
increases the design capacity. With these baselines, AirDbM reconstructs 99 \%
of the database with a mean absolute error below 0.005, which matches the
performance of a previous DbM approach that used more baselines. In
multi-objective aerodynamic optimization, AirDbM demonstrates rapid convergence
and achieves a Pareto front with a greater hypervolume than that of the
previous larger-baseline study, where new Pareto-optimal solutions are
discovered with enhanced lift-to-drag ratios at moderate stall tolerances.
Furthermore, AirDbM demonstrates outstanding adaptability for reinforcement
learning (RL) agents in generating airfoil geometry when compared to
conventional airfoil parameterization methods, implying the broader potential
of DbM in machine learning-driven design.

</details>


### [311] [Feature-driven reinforcement learning for photovoltaic in continuous intraday trading](https://arxiv.org/abs/2510.16021)
*Arega Getaneh Abate,Xiufeng Liu,Ruyu Liu,Xiaobing Zhang*

Main category: cs.LG

TL;DR: 本研究提出了一种特征驱动的强学习方法，用于光伏日内交易，通过改善收益和减少不平衡成本，显示出良好的市场适应性和操作性。


<details>
  <summary>Details</summary>
Motivation: 光伏运营商面临发电和电价的不确定性，内交易市场允许生产者实时调整位置以提高收益和减少不平衡成本。

Method: 采用特征驱动的强化学习方法，利用数据驱动特征构建状态，在序贯决策框架中学习出价策略，并通过近端策略优化(PPO)方法解决马尔可夫决策过程。

Result: 该策略在历史市场数据上训练并进行样本外评估，在多种场景下持续超越基准基线，显示出快速收敛、实时推理和透明的决策规则。

Conclusion: 特征驱动的强化学习为光伏生产者的主动日内交易提供了实用、数据高效且可操作的途径。

Abstract: Photovoltaic (PV) operators face substantial uncertainty in generation and
short-term electricity prices. Continuous intraday markets enable producers to
adjust their positions in real time, potentially improving revenues and
reducing imbalance costs. We propose a feature-driven reinforcement learning
(RL) approach for PV intraday trading that integrates data-driven features into
the state and learns bidding policies in a sequential decision framework. The
problem is cast as a Markov Decision Process with a reward that balances
trading profit and imbalance penalties and is solved with Proximal Policy
Optimization (PPO) using a predominantly linear, interpretable policy. Trained
on historical market data and evaluated out-of-sample, the strategy
consistently outperforms benchmark baselines across diverse scenarios.
Extensive validation shows rapid convergence, real-time inference, and
transparent decision rules. Learned weights highlight the central role of
market microstructure and historical features. Taken together, these results
indicate that feature-driven RL offers a practical, data-efficient, and
operationally deployable pathway for active intraday participation by PV
producers.

</details>


### [312] [Breaking Memorization Barriers in LLM Code Fine-Tuning via Information Bottleneck for Improved Generalization](https://arxiv.org/abs/2510.16022)
*Changsheng Wang,Xin Chen,Sijia Liu,Ke Ding*

Main category: cs.LG

TL;DR: 本研究提出了IB-FT方法，旨在克服预训练大语言模型在代码生成中的记忆障碍，提高性能。


<details>
  <summary>Details</summary>
Motivation: 传统的代码生成微调容易受到记忆障碍的影响，妨碍模型获取新的、可推广的代码知识。

Method: 采用信息瓶颈指导的微调方法，施加IB惩罚以压缩冗余的记忆特征。

Result: 在OriGen和Evol-CodeAlpaca-V1两个基准上，IB-FT显著提高了 Pass@$1$ 性能，并在多样本度量下取得了更稳定的结果。

Conclusion: IB-FT能有效克服传统微调中的记忆障碍，提高代码生成性能和稳定性。

Abstract: Adapting pretrained large language models (LLMs) to code domains via
supervised fine-tuning (FT) has been commonly used for code generation.
However, we identify a previously underappreciated failure mode, the
memorization barrier, where strong memorization of downstream code data in the
base model could trap optimization and prevent the standard FT from effectively
acquiring new, generalizable code knowledge. To overcome this barrier, we
propose the information bottleneck (IB)-guided fine-tuning, termed IB-FT, which
applies an IB penalty on hidden representations of the code data to compress
spurious, memorized features while preserving task-relevant information.
Extensive experiments on two code benchmarks (OriGen and Evol-CodeAlpaca-V1)
show that IB-FT substantially alleviates the memorization barrier, improves
top-1 performance (Pass@$1$), and yields far more stable gains under the
stricter multi-sample metric Pass@$k^{(m)}$ (a problem counts as solved only if
at least $m$ of $k$ samples pass unit tests) compared with conventional FT.

</details>


### [313] [Unifying Polymer Modeling and Design via a Conformation-Centric Generative Foundation Model](https://arxiv.org/abs/2510.16023)
*Fanmeng Wang,Shan Mei,Wentao Guo,Hongshuai Wang,Qi Ou,Zhifeng Gao,Hongteng Xu*

Main category: cs.LG

TL;DR: 本研究提出了 PolyConFM，一个通过构象中心生成预训练来统一聚合物建模与设计的基础模型，显著提升了聚合物科学任务的整体性能。


<details>
  <summary>Details</summary>
Motivation: 旨在克服现有方法仅基于单体描述符而忽视聚合物整体结构信息的局限性，并填补聚合物科学中缺乏通用基础模型的空白。

Method: 采用条件生成范式下的掩膜自回归建模（MAR），重构局部构象并生成其方向变换，以恢复对应的聚合物构象。

Result: PolyConFM 在多种下游任务中 consistently 优于代表性的特定任务方法，表明其作为聚合物科学中强大工具的潜力。

Conclusion: PolyConFM 是首个聚合物基础模型，通过以构象为中心的生成预训练，将聚合物建模与设计统一起来，并在各种下游任务中表现优异。

Abstract: Polymers, macromolecules formed from covalently bonded monomers, underpin
countless technologies and are indispensable to modern life. While deep
learning is advancing polymer science, existing methods typically represent the
whole polymer solely through monomer-level descriptors, overlooking the global
structural information inherent in polymer conformations, which ultimately
limits their practical performance. Moreover, this field still lacks a
universal foundation model that can effectively support diverse downstream
tasks, thereby severely constraining progress. To address these challenges, we
introduce PolyConFM, the first polymer foundation model that unifies polymer
modeling and design through conformation-centric generative pretraining.
Recognizing that each polymer conformation can be decomposed into a sequence of
local conformations (i.e., those of its repeating units), we pretrain PolyConFM
under the conditional generation paradigm, reconstructing these local
conformations via masked autoregressive (MAR) modeling and further generating
their orientation transformations to recover the corresponding polymer
conformation. Besides, we construct the first high-quality polymer conformation
dataset via molecular dynamics simulations to mitigate data sparsity, thereby
enabling conformation-centric pretraining. Experiments demonstrate that
PolyConFM consistently outperforms representative task-specific methods on
diverse downstream tasks, equipping polymer science with a universal and
powerful tool.

</details>


### [314] [A tutorial on discovering and quantifying the effect of latent causal sources of multimodal EHR data](https://arxiv.org/abs/2510.16026)
*Marco Barbero-Mota,Eric V. Strobl,John M. Still,William W. Stead,Thomas A. Lasko*

Main category: cs.LG

TL;DR: 本研究提出了一种通用的因果机器学习管道，用于发现电子健康记录中的潜在因果源及其对临床结果的影响。


<details>
  <summary>Details</summary>
Motivation: 促进医疗发现，解决电子健康记录中因果关系的识别与量化问题。

Method: 利用多模态临床数据，处理并分解为概率独立的潜在源，以训练特定任务的因果模型。

Result: 展示了该方法在两个实际应用中的有效性，证明了其在医疗研究中的多样性和实用性。

Conclusion: 该方法展示了在大规模电子健康记录中发现潜在因果源并量化其对临床结果影响的能力。

Abstract: We provide an accessible description of a peer-reviewed generalizable causal
machine learning pipeline to (i) discover latent causal sources of large-scale
electronic health records observations, and (ii) quantify the source causal
effects on clinical outcomes. We illustrate how imperfect multimodal clinical
data can be processed, decomposed into probabilistic independent latent
sources, and used to train taskspecific causal models from which individual
causal effects can be estimated. We summarize the findings of the two
real-world applications of the approach to date as a demonstration of its
versatility and utility for medical discovery at scale.

</details>


### [315] [AMS-QUANT: Adaptive Mantissa Sharing for Floating-point Quantization](https://arxiv.org/abs/2510.16045)
*Mengtao Lv,Ruiqi Zhu,Xinyu Wang,Yun Li*

Main category: cs.LG

TL;DR: AMS-Quant通过创新的量化技术显著提升了大语言模型的推理速度和效率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型的存储和效率瓶颈，提高推理性能。

Method: 提出了Mantissa-bit Sharing和Adaptive Searching两种新技术，并在CUDA Linear kernels上进行了原型实现。

Result: AMS-Quant可将模型量化到FP-5.33-e2m3和FP4.25-e2m2，相比于FP16推理，其解码速度分别提升了2.8倍和3.2倍，且准确性损失几乎可以忽略不计。

Conclusion: AMS-Quant大幅提升了大语言模型推理速度，同时保持了较低的准确性损失。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in
various kinds of tasks, while the billion or even trillion parameters bring
storage and efficiency bottlenecks for inference. Quantization, particularly
floating-point quantization, is known to be capable of speeding up LLM
inference by reducing memory footprint and data movement during the inference
process. For the first time, we advance the floating-point quantization
exploration from integer bitwidths to non-integer bit-widths, namely AMS-Quant,
to further approach the quantization sweet spot. AMS-Quant incorporates two
novel techniques to put it into effect: (1) it proposes Mantissa-bit Sharing,
which groups k quantized weights and lets them share the least significant
mantissa bit, allowing us to further approach the minimum quantization
bit-width without accuracy loss. (2) It introduces Adaptive Searching, which
employs an offline optimization strategy to minimize the accuracy degradation
introduced by sharing. Moreover, AMS-Quant is also prototyped as efficient CUDA
Linear kernels, which translates memory savings into wall-clock latency
reduction by reducing memory access. Extensive experiments on large-scale
datasets and models show that AMS-Quant can quantize the model to FP-5.33-e2m3
and FP4.25-e2m2, and significantly speed up the LLM decoding over FP16
inference (2.8x and 3.2x), with negligible accuracy loss.

</details>


### [316] [Beyond Accuracy: Are Time Series Foundation Models Well-Calibrated?](https://arxiv.org/abs/2510.16060)
*Coen Adler,Yuxin Chang,Felix Draxler,Samar Abdi,Padhraic Smyth*

Main category: cs.LG

TL;DR: 本研究评估了时间序列基础模型的校准属性，发现其校准能力优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在预测性能上表现出色，但其校准属性尚未得到充分探索，而校准在许多实际应用中至关重要。

Method: 系统评估时间序列基础模型的校准属性

Result: 时间序列基础模型在校准方面优于基线模型，且通常不会表现出系统性的过信/confidence 或欠信/confidence 现象。

Conclusion: 时间序列基础模型在校准方面表现较好，适合于实际应用中的长时间预测。

Abstract: The recent development of foundation models for time series data has
generated considerable interest in using such models across a variety of
applications. Although foundation models achieve state-of-the-art predictive
performance, their calibration properties remain relatively underexplored,
despite the fact that calibration can be critical for many practical
applications. In this paper, we investigate the calibration-related properties
of five recent time series foundation models and two competitive baselines. We
perform a series of systematic evaluations assessing model calibration (i.e.,
over- or under-confidence), effects of varying prediction heads, and
calibration under long-term autoregressive forecasting. We find that time
series foundation models are consistently better calibrated than baseline
models and tend not to be either systematically over- or under-confident, in
contrast to the overconfidence often seen in other deep learning models.

</details>


### [317] [FedPURIN: Programmed Update and Reduced INformation for Sparse Personalized Federated Learning](https://arxiv.org/abs/2510.16065)
*Lunchen Xie,Zehua He,Qingjiang Shi*

Main category: cs.LG

TL;DR: 提出FedPURIN框架，通过精确选择关键参数，显著改善个性化联邦学习的通信效率，适用于边缘智能系统。


<details>
  <summary>Details</summary>
Motivation: 针对现有方法的通信效率低下问题，提出一种新颖的框架以增强实践中的可部署性。

Method: 通过整数编程公式识别关键参数，并与稀疏聚合方案无缝集成，实现显著的通信减少。

Result: 在多种非独立同分布条件下的标准图像分类基准测试中表现出竞争力，同时通过稀疏聚合实现可量化的通信减少。

Conclusion: 该框架为通信高效的个性化联邦学习建立了新范例，特别适用于处理异构数据源的边缘智能系统。

Abstract: Personalized Federated Learning (PFL) has emerged as a critical research
frontier addressing data heterogeneity issue across distributed clients. Novel
model architectures and collaboration mechanisms are engineered to accommodate
statistical disparities while producing client-specific models. Parameter
decoupling represents a promising paradigm for maintaining model performance in
PFL frameworks. However, the communication efficiency of many existing methods
remains suboptimal, sustaining substantial communication burdens that impede
practical deployment. To bridge this gap, we propose Federated Learning with
Programmed Update and Reduced INformation (FedPURIN), a novel framework that
strategically identifies critical parameters for transmission through an
integer programming formulation. This mathematically grounded strategy is
seamlessly integrated into a sparse aggregation scheme, achieving a significant
communication reduction while preserving the efficacy. Comprehensive
evaluations on standard image classification benchmarks under varied non-IID
conditions demonstrate competitive performance relative to state-of-the-art
methods, coupled with quantifiable communication reduction through sparse
aggregation. The framework establishes a new paradigm for
communication-efficient PFL, particularly advantageous for edge intelligence
systems operating with heterogeneous data sources.

</details>


### [318] [MNO: Multiscale Neural Operator for Computational Fluid Dynamics with 3D Point Cloud Data](https://arxiv.org/abs/2510.16071)
*Qinxuan Wang,Chuang Wang,Mingyu Zhang,Jingwei Sun,Peipei Yang,Shuo Tang,Shiming Xiang*

Main category: cs.LG

TL;DR: 本研究提出的多尺度神经算子（MNO）在三维无结构点云的计算流体动力学中，比现有技术显著提高了预测精度和稳健性。


<details>
  <summary>Details</summary>
Motivation: 现有神经算子在不规则域上的准确性和可扩展性有限，尤其是在流体流动表现出丰富的多尺度结构时。

Method: 通过三种尺度模块设计：全局维度收缩注意力模块、局部图注意力模块和微观逐点注意力模块，进行三维无结构点云的计算流体动力学分析。

Result: MNO 在四个基准测试中表现优异，预测误差减少5%到40%，在具有挑战性的三维流体动力学问题中展示了更好的稳健性。

Conclusion: MNO 是一个可扩展的框架，能够在不规则域上学习复杂的流体动力学，显著提高预测精度和稳健性。

Abstract: Neural operators have emerged as a powerful data-driven paradigm for solving
Partial Differential Equations (PDEs), offering orders-of-magnitude
acceleration over traditional solvers. However, existing approaches still
suffer from limited accuracy and scalability, particularly on irregular domains
where fluid flows exhibit rich multiscale structures. In this work, we
introduce the Multiscale Neural Operator (MNO), a new architecture for
Computational Fluid Dynamics (CFD) on three-dimensional (3D) unstructured point
clouds. MNO explicitly decomposes information across three scales: a global
dimension-shrinkage attention module for long-range dependencies, a local graph
attention module for neighborhood-level interactions, and a micro point-wise
attention module for fine-grained details. This design preserves multiscale
inductive biases while remaining computationally efficient. We evaluate MNO on
four diverse benchmarks, covering both steady-state and unsteady flow scenarios
with up to 300K points. Across all tasks, MNO consistently outperforms
state-of-the-art baselines, reducing prediction errors by 5% to 40% and
demonstrating improved robustness in challenging 3D CFD problems. Our results
highlight the importance of explicit multiscale design for neural operators and
establish MNO as a scalable framework for learning complex fluid dynamics on
irregular domains.

</details>


### [319] [Early-stopping for Transformer model training](https://arxiv.org/abs/2510.16074)
*Jing He,Hua Jiang,Cheng Li,Siqian Xin,Shuzhen Yang*

Main category: cs.LG

TL;DR: 本研究利用随机矩阵理论分析Transformer的训练，提出了基于重尾动态的早停准则，并划分训练过程为三个阶段，展示了RMT在模型训练监控中的应用。


<details>
  <summary>Details</summary>
Motivation: 旨在揭示Transformer训练中性能提升的机制，并为早期停止提供原则性准则。

Method: 基于随机矩阵理论（RMT）分析Transformer的训练过程，观察自注意力矩阵的谱密度演变，并通过功率律拟合进行研究。

Result: 通过研究发现，训练过程可以分为三个阶段，且在这三个阶段中设计了定量的重尾动态度量和收敛的谱特征，均具有高度一致性。

Conclusion: 本研究提出了一种新的理论框架，可以有效分析Transformer模型的训练动态，并提供早停准则。

Abstract: This work introduces a novel theoretical framework grounded in Random Matrix
Theory (RMT) for analyzing Transformer training dynamics. We focus on the
underlying mechanisms that drive performance improvements and derive principled
early-stopping criteria. Empirically, we observe that the spectral density of
the shallow self-attention matrix V consistently evolves into a heavy-tailed
distribution. Utilizing the PL (Power Law) fit to this matrix as a probe, we
demarcate training into three stages: structural exploration, heavy-tailed
structure stabilization, and convergence saturation. This staging provides
guidance for preliminary stopping decisions. Crucially, we propose two
consistent and validation-free criteria: a quantitative metric for heavy-tailed
dynamics and a novel spectral signature indicative of convergence. The strong
alignment between these criteria highlights the utility of RMT for monitoring
and diagnosing the progression of Transformer model training.

</details>


### [320] [BPL: Bias-adaptive Preference Distillation Learning for Recommender System](https://arxiv.org/abs/2510.16076)
*SeongKu Kang,Jianxun Lian,Dongha Lee,Wonbin Kweon,Sanghwan Jang,Jaehyun Lee,Jindong Wang,Xing Xie,Hwanjo Yu*

Main category: cs.LG

TL;DR: 提出BPL框架，通过双重蒸馏策略改善推荐系统的偏差，提升用户偏好揭示和预测准确性。


<details>
  <summary>Details</summary>
Motivation: 解决推荐系统反馈偏差问题，提升模型在不同测试环境中的表现。

Method: 引入双重蒸馏策略的偏差自适应偏好蒸馏学习框架（BPL），结合教师-学生蒸馏方法和自蒸馏。

Result: 通过实验验证BPL在现实和反事实测试中都具有高性能。

Conclusion: BPL模型在现实和反事实测试环境中表现优异，能够有效揭示用户偏好。

Abstract: Recommender systems suffer from biases that cause the collected feedback to
incompletely reveal user preference. While debiasing learning has been
extensively studied, they mostly focused on the specialized (called
counterfactual) test environment simulated by random exposure of items,
significantly degrading accuracy in the typical (called factual) test
environment based on actual user-item interactions. In fact, each test
environment highlights the benefit of a different aspect: the counterfactual
test emphasizes user satisfaction in the long-terms, while the factual test
focuses on predicting subsequent user behaviors on platforms. Therefore, it is
desirable to have a model that performs well on both tests rather than only
one. In this work, we introduce a new learning framework, called Bias-adaptive
Preference distillation Learning (BPL), to gradually uncover user preferences
with dual distillation strategies. These distillation strategies are designed
to drive high performance in both factual and counterfactual test environments.
Employing a specialized form of teacher-student distillation from a biased
model, BPL retains accurate preference knowledge aligned with the collected
feedback, leading to high performance in the factual test. Furthermore, through
self-distillation with reliability filtering, BPL iteratively refines its
knowledge throughout the training process. This enables the model to produce
more accurate predictions across a broader range of user-item combinations,
thereby improving performance in the counterfactual test. Comprehensive
experiments validate the effectiveness of BPL in both factual and
counterfactual tests. Our implementation is accessible via:
https://github.com/SeongKu-Kang/BPL.

</details>


### [321] [FSRF: Factorization-guided Semantic Recovery for Incomplete Multimodal Sentiment Analysis](https://arxiv.org/abs/2510.16086)
*Ziyang Liu,Pengjunfei Chu,Shuming Dong,Chen Zhang,Mingcheng Li,Jin Wang*

Main category: cs.LG

TL;DR: 提出了FSRF框架解决多模态情感分析中的模态缺失问题，表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态情感分析研究在处理真实世界应用中模态缺失的问题时，忽视了其对模型泛化能力的影响。

Method: 提出了一个去冗余的同-异质因子分解模块和一个分布对齐的自蒸馏模块。

Result: FSRF通过因子分解和知识转移有效地恢复了缺失的语义，提高了多模态情感分析的性能。

Conclusion: FSRF在有缺失模态的情况下，相较于以往的方法具有显著的性能优势。

Abstract: In recent years, Multimodal Sentiment Analysis (MSA) has become a research
hotspot that aims to utilize multimodal data for human sentiment understanding.
Previous MSA studies have mainly focused on performing interaction and fusion
on complete multimodal data, ignoring the problem of missing modalities in
real-world applications due to occlusion, personal privacy constraints, and
device malfunctions, resulting in low generalizability.
  To this end, we propose a Factorization-guided Semantic Recovery Framework
(FSRF) to mitigate the modality missing problem in the MSA task.
  Specifically, we propose a de-redundant homo-heterogeneous factorization
module that factorizes modality into modality-homogeneous,
modality-heterogeneous, and noisy representations and design elaborate
constraint paradigms for representation learning.
  Furthermore, we design a distribution-aligned self-distillation module that
fully recovers the missing semantics by utilizing bidirectional knowledge
transfer.
  Comprehensive experiments on two datasets indicate that FSRF has a
significant performance advantage over previous methods with uncertain missing
modalities.

</details>


### [322] [STABLE: Gated Continual Learning for Large Language Models](https://arxiv.org/abs/2510.16089)
*William Hoy,Nurcin Celik*

Main category: cs.LG

TL;DR: 本研究提出了一种名为STABLE的门控持续自我编辑框架，通过有效的微调和稳定性预算评估，减轻了大语言模型的遗忘问题，支持模型在不断更新知识的同时保持可靠性。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型（LLMs）中，需要一种机制来进行持续学习而无需完全重训练，同时避免因新更新导致的灾难性遗忘。

Method: 采用低秩适应（LoRA）进行参数高效的微调，并根据稳定性预算通过三种度量标准进行候选更新的评估。

Result: 在Qwen-2.5-7B模型上的实验表明，门控机制有效减轻了遗忘，同时保留了适应性，不同的门控策略在分布转移上有相似表现却产生不同的准确性结果，显示出门控设计在持续适应中的重要性。

Conclusion: STABLE框架有效减轻了大语言模型在持续更新中的遗忘问题，保持了模型的适应性。

Abstract: Large language models (LLMs) increasingly require mechanisms for continual
adaptation without full retraining. However, sequential updates can lead to
catastrophic forgetting, where new edits degrade previously acquired knowledge.
This work presents STABLE, a gated continual self editing framework that
constrains forgetting during sequential updates using parameter efficient fine
tuning via Low Rank Adaptation (LoRA; see arXiv:2106.09685). Each candidate
edit is evaluated against a stability budget using one of three metrics: (i)
Exact Match (EM) drop, capturing factual accuracy loss; (ii) bits increase,
reflecting reduced model confidence; and (iii) KL divergence, quantifying
distributional drift between the base and adapted models. If a threshold is
exceeded, the LoRA update is rescaled through a clipping procedure or rejected.
Experiments on the Qwen-2.5-7B model show that gating effectively mitigates
forgetting while preserving adaptability. EM based gating achieved the highest
cumulative performance in short continual learning sequences. Our results show
that different gating strategies can achieve comparable distribution shift
(measured by KL divergence) while producing different accuracy outcomes,
highlighting the importance of gating design in continual adaptation. This
approach offers a principled method for continual model editing, enabling LLMs
to integrate new knowledge while maintaining reliability. Code:
https://github.com/Bhoy1/STABLE

</details>


### [323] [Compressing Many-Shots in In-Context Learning](https://arxiv.org/abs/2510.16092)
*Devvrit Khatri,Pranamya Kulkarni,Nilesh Gupta,Yerram Varun,Liqian Peng,Jay Yagnik,Praneeth Netrapalli,Cho-Jui Hsieh,Alec Go,Inderjit S Dhillon,Aditya Kusupati,Prateek Jain*

Main category: cs.LG

TL;DR: 本研究提出MemCom，通过层级压缩提高In-Context Learning的效率，在多分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 旨在提高In-Context Learning的内存和计算效率，同时降低示例数量带来的成本。

Method: 提出MemCom，进行层级压缩并评估不同的压缩模型和训练方法。

Result: MemCom在多种压缩比例下超越了强基线，且在较高压缩比例下性能下降较小。

Conclusion: MemCom是一种有效的层级压缩方法，能够在多种分类任务中以较低的性能下降实现显著的压缩效果。

Abstract: Large Language Models (LLMs) have been shown to be able to learn different
tasks without explicit finetuning when given many input-output examples /
demonstrations through In-Context Learning (ICL). Increasing the number of
examples, called ``shots'', improves downstream task performance but incurs
higher memory and computational costs. In this work, we study an approach to
improve the memory and computational efficiency of ICL inference by compressing
the many-shot prompts. Given many shots comprising t tokens, our goal is to
generate a m soft-token summary, where m < t. We first show that existing
prompt compression methods are ineffective for many-shot compression, and
simply using fewer shots as a baseline is surprisingly strong. To achieve
effective compression, we find that: (a) a stronger compressor model with more
trainable parameters is necessary, and (b) compressing many-shot
representations at each transformer layer enables more fine-grained compression
by providing each layer with its own compressed representation. Based on these
insights, we propose MemCom, a layer-wise compression method. We systematically
evaluate various compressor models and training approaches across different
model sizes (2B and 7B), architectures (Gemma and Mistral), many-shot sequence
lengths (3k-6k tokens), and compression ratios (3x to 8x). MemCom outperforms
strong baselines across all compression ratios on multiple classification tasks
with large label sets. Notably, while baseline performance degrades sharply at
higher compression ratios, often by over 20-30%, MemCom maintains high accuracy
with minimal degradation, typically dropping by less than 10%.

</details>


### [324] [Zero-shot World Models via Search in Memory](https://arxiv.org/abs/2510.16123)
*Federico Malato,Ville Hautamäki*

Main category: cs.LG

TL;DR: 本文提出了一种基于搜索的世界模型，性能与传统训练模型相当，并在长时间预测上表现更佳。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统世界模型的训练过程，提出一个无需训练的解决方案，提升样本效率。

Method: 利用相似性搜索和随机表示，近似世界模型，避免训练程序。

Result: 我们的模型在隐变量重构质量和图像相似度上表现良好，尤其在长时间预测中优于基线。

Conclusion: 基于搜索的世界模型在长时间预测方面表现出色，并且在某些情况下与基于训练的模型相当。

Abstract: World Models have vastly permeated the field of Reinforcement Learning. Their
ability to model the transition dynamics of an environment have greatly
improved sample efficiency in online RL. Among them, the most notorious example
is Dreamer, a model that learns to act in a diverse set of image-based
environments. In this paper, we leverage similarity search and stochastic
representations to approximate a world model without a training procedure. We
establish a comparison with PlaNet, a well-established world model of the
Dreamer family. We evaluate the models on the quality of latent reconstruction
and on the perceived similarity of the reconstructed image, on both next-step
and long horizon dynamics prediction. The results of our study demonstrate that
a search-based world model is comparable to a training based one in both cases.
Notably, our model show stronger performance in long-horizon prediction with
respect to the baseline on a range of visually different environments.

</details>


### [325] [A Minimal-Assumption Analysis of Q-Learning with Time-Varying Policies](https://arxiv.org/abs/2510.16132)
*Phalguni Nanda,Zaiwei Chen*

Main category: cs.LG

TL;DR: 首次对时间变化学习策略下的Q学习算法进行有限时间分析，揭示其探索劣势和利用优势，提供了明确的收敛及样本复杂度结果。


<details>
  <summary>Details</summary>
Motivation: 研究时间变化学习策略下的Q学习理论，构建样本复杂度及收敛率的明确界限。

Method: 结合时间变化学习策略和Poisson方程的细致处理，进行灵敏度分析。

Result: 时间变化的Q学习在样本复杂度方面与离政策学习匹配，但在探索方面表现较弱。

Conclusion: 提出了有时间变化学习策略的Q学习算法的有限时间分析，显示出其在探索方面的劣势，但在利用方面具有优势。

Abstract: In this work, we present the first finite-time analysis of the Q-learning
algorithm under time-varying learning policies (i.e., on-policy sampling) with
minimal assumptions -- specifically, assuming only the existence of a policy
that induces an irreducible Markov chain over the state space. We establish a
last-iterate convergence rate for $\mathbb{E}[\|Q_k - Q^*\|_\infty^2]$,
implying a sample complexity of order $O(1/\epsilon^2)$ for achieving
$\mathbb{E}[\|Q_k - Q^*\|_\infty] \le \epsilon$, matching that of off-policy
Q-learning but with a worse dependence on exploration-related parameters. We
also derive an explicit rate for $\mathbb{E}[\|Q^{\pi_k} - Q^*\|_\infty^2]$,
where $\pi_k$ is the learning policy at iteration $k$. These results reveal
that on-policy Q-learning exhibits weaker exploration than its off-policy
counterpart but enjoys an exploitation advantage, as its policy converges to an
optimal one rather than remaining fixed. Numerical simulations corroborate our
theory.
  Technically, the combination of time-varying learning policies (which induce
rapidly time-inhomogeneous Markovian noise) and the minimal assumption on
exploration presents significant analytical challenges. To address these
challenges, we employ a refined approach that leverages the Poisson equation to
decompose the Markovian noise corresponding to the lazy transition matrix into
a martingale-difference term and residual terms. To control the residual terms
under time inhomogeneity, we perform a sensitivity analysis of the Poisson
equation solution with respect to both the Q-function estimate and the learning
policy. These tools may further facilitate the analysis of general
reinforcement learning algorithms with rapidly time-varying learning policies
-- such as single-timescale actor--critic methods and learning-in-games
algorithms -- and are of independent interest.

</details>


### [326] [Zeroth-Order Sharpness-Aware Learning with Exponential Tilting](https://arxiv.org/abs/2510.16157)
*Xuchen Gong,Tian Li*

Main category: cs.LG

TL;DR: 本研究连接了零阶优化与SAM方法，提出了新的算法，显示出在多项任务上优于传统零阶方法的性能。


<details>
  <summary>Details</summary>
Motivation: 将经典的零阶优化方法与sharpness-aware minimization方法相结合，以改进优化过程。

Method: 通过指数倾斜目标连接零阶优化和SAM方法，探索新的零阶算法以解决软SAM目标。

Result: 所提出的算法在分类、选择题回答和语言生成等任务上，相较于典型的零阶基线取得了更好的泛化效果。

Conclusion: 提出的算法在各种下游任务上表现出更好的泛化能力，提供了无梯度且高效的内存选择。

Abstract: Classic zeroth-order optimization approaches typically optimize for a
smoothed version of the original function, i.e., the expected objective under
randomly perturbed model parameters. This can be interpreted as encouraging the
loss values in the perturbation set to be small on average. Popular
sharpness-aware minimization (SAM) objectives, however, typically focus on the
largest loss within the neighborhood to arrive at flat minima more effectively.
In this work, we connect zeroth-order optimization (and its corresponding
objectives) with SAM approaches explicitly, through an exponential tilting
objective that provides a smooth transition between the average- and the
max-loss formulations. We explore new zeroth-order algorithms to solve a soft
SAM objective parameterized by a tilting parameter $t$. We provide precise
characterizations of the sharpness notions of the tilted SAM framework.
Practically, our approach can be used as a gradient-free and memory-efficient
alternative to SAM variants, and it achieves better generalization compared to
vanilla zeroth-order baselines on a wide range of downstream tasks, including
classification, multiple choice QA, and language generation.

</details>


### [327] [Still Competitive: Revisiting Recurrent Models for Irregular Time Series Prediction](https://arxiv.org/abs/2510.16161)
*Ankitkumar Joshi,Milos Hauskrecht*

Main category: cs.LG

TL;DR: GRUwE模型针对不规则采样的多变量时间序列提供了一种简单有效的解决方案，在性能上与最先进方法竞争。


<details>
  <summary>Details</summary>
Motivation: 旨在探讨复杂学习架构与更简单、高效的RNN算法在处理不规则采样时间序列上的真实优劣。

Method: 提出了一个基于GRU与指数基函数的模型，能够处理不规则时间采样的多变量时间序列。

Result: 在多个真实世界基准测试中，GRUwE在下一观察和下一事件预测任务上达到了与当前最先进方法相当或更优的性能。

Conclusion: GRUwE在连续时间的预测任务中表现出色，并提供了简单实现和低计算开销的优势。

Abstract: Modeling irregularly sampled multivariate time series is a persistent
challenge in domains like healthcare and sensor networks. While recent works
have explored a variety of complex learning architectures to solve the
prediction problems for irregularly sampled time series, it remains unclear
what are the true benefits of some of these architectures, and whether clever
modifications of simpler and more efficient RNN-based algorithms are still
competitive, i.e. they are on par with or even superior to these methods. In
this work, we propose and study GRUwE: Gated Recurrent Unit with Exponential
basis functions, that builds upon RNN-based architectures for observations made
at irregular times. GRUwE supports both regression-based and event-based
predictions in continuous time. GRUwE works by maintaining a Markov state
representation of the time series that updates with the arrival of irregular
observations. The Markov state update relies on two reset mechanisms: (i)
observation-triggered reset, and (ii) time-triggered reset of the GRU state
using learnable exponential decays, to support the predictions in continuous
time. Our empirical evaluations across several real-world benchmarks on
next-observation and next-event prediction tasks demonstrate that GRUwE can
indeed achieve competitive to superior performance compared to the recent
state-of-the-art (SOTA) methods. Thanks to its simplicity, GRUwE offers
compelling advantages: it is easy to implement, requires minimal
hyper-parameter tuning efforts, and significantly reduces the computational
overhead in the online deployment.

</details>


### [328] [AtomBench: A Benchmark for Generative Atomic Structure Models using GPT, Diffusion, and Flow Architectures](https://arxiv.org/abs/2510.16165)
*Charles Rhys Campbell,Aldo H. Romero,Kamal Choudhary*

Main category: cs.LG

TL;DR: 本文对三种生成模型在材料数据集上的性能进行了系统比较，CDVAE表现最佳。


<details>
  <summary>Details</summary>
Motivation: 尽管生成模型在新材料探索中日益重要，但对其在材料数据集上的性能缺乏系统比较。

Method: 通过使用KL散度和平均绝对误差（MAE）评估生成模型的性能。

Result: 对三种不同的生成模型在公开超导性数据集上进行系统的基准测试。

Conclusion: 在比较中，CDVAE模型表现最佳，其次是AtomGPT，FlowMM表现最差。

Abstract: Generative models have become significant assets in the exploration and
identification of new materials, enabling the rapid proposal of candidate
crystal structures that satisfy target properties. Despite the increasing
adoption of diverse architectures, a rigorous comparative evaluation of their
performance on materials datasets is lacking. In this work, we present a
systematic benchmark of three representative generative models- AtomGPT (a
transformer-based model), Crystal Diffusion Variational Autoencoder (CDVAE),
and FlowMM (a Riemannian flow matching model). These models were trained to
reconstruct crystal structures from subsets of two publicly available
superconductivity datasets- JARVIS Supercon 3D and DS A/B from the Alexandria
database. Performance was assessed using the Kullback-Leibler (KL) divergence
between predicted and reference distributions of lattice parameters, as well as
the mean absolute error (MAE) of individual lattice constants. For the computed
KLD and MAE scores, CDVAE performs most favorably, followed by AtomGPT, and
then FlowMM. All benchmarking code and model configurations will be made
publicly available at https://github.com/atomgptlab/atombench_inverse.

</details>


### [329] [Alignment is Localized: A Causal Probe into Preference Layers](https://arxiv.org/abs/2510.16167)
*Archie Chaudhury*

Main category: cs.LG

TL;DR: 本研究分析了语言模型对齐的偏好优化过程，发现该过程在空间上是局部化的，并且是一个方向性、低秩的过程。


<details>
  <summary>Details</summary>
Motivation: 探究使用人类注释的强化学习框架，尤其是如何通过人类反馈实现语言模型的对齐，即使这一过程仍然不够清晰。

Method: 通过对基础模型与调整后的模型进行层级因果补丁分析，比较人类偏好对语言模型对齐的影响。

Result: 在Llama-3.2-1B模型的实验中发现，模型的中间层激活与奖励一致性行为存在直接因果关系，且只有少量层与奖励增益具有关联。

Conclusion: 针对语言模型的偏好优化分析表明，基于人类反馈的思想调整过程是一个方向性、低秩的过程。

Abstract: Reinforcement Learning frameworks, particularly those utilizing human
annotations, have become an increasingly popular method for preference
fine-tuning, where the outputs of a language model are tuned to match a certain
set of behavioral policies or guidelines. Reinforcement Learning through Human
Feedback (RLHF) is perhaps the most popular implementation of such a framework,
particularly for aligning LMs toward safety and human intent. However, the
internal workings of how such alignment is achieved remain largely opaque. In
this work, we systematically analyze preference optimization for language model
alignment by applying layer-wide causal patching between a base model and its
tuned counterpart across human preference pairs. We implement our methodology
on \textit{Llama-3.2-1B}, and find that alignment is spatially localized:
mid-layer activations encode a distinct subspace that causally determines
reward-consistent behavior, while early and late layers remain largely
unaffected. Utilizing LASSO regression, we also find that only a small number
of layers possess non-zero coefficients linking activation distances to reward
gains. Overall, we show that, at least for some language models, alignment from
human-based, preferential tuning is a directional, low rank process, rather
than diffuse and parameteric.

</details>


### [330] [The Formalism-Implementation Gap in Reinforcement Learning Research](https://arxiv.org/abs/2510.16175)
*Pablo Samuel Castro*

Main category: cs.LG

TL;DR: 本文建议强化学习研究应重心转向科学理解，强调基准与数学形式的精确对应，以更好地应对现实问题。


<details>
  <summary>Details</summary>
Motivation: 近年来强化学习的快速发展激励了技术的展示，但忽视了对学习动态的深入理解，这可能会导致过度拟合于学术基准，不利于技术的推广。

Method: 通过对现有研究的分析，提出强化学习研究的未来方向，以促进理解和应用。

Result: 通过以Arcade Learning Environment为例，强调现有基准在促进理解和实际问题中的应用价值。

Conclusion: 强化学习研究应更关注于科学进步和理解，而非仅仅展示能力，同时需要更准确地映射基准与数学形式之间的关系。

Abstract: The last decade has seen an upswing in interest and adoption of reinforcement
learning (RL) techniques, in large part due to its demonstrated capabilities at
performing certain tasks at "super-human levels". This has incentivized the
community to prioritize research that demonstrates RL agent performance, often
at the expense of research aimed at understanding their learning dynamics.
Performance-focused research runs the risk of overfitting on academic
benchmarks -- thereby rendering them less useful -- which can make it difficult
to transfer proposed techniques to novel problems. Further, it implicitly
diminishes work that does not push the performance-frontier, but aims at
improving our understanding of these techniques. This paper argues two points:
(i) RL research should stop focusing solely on demonstrating agent
capabilities, and focus more on advancing the science and understanding of
reinforcement learning; and (ii) we need to be more precise on how our
benchmarks map to the underlying mathematical formalisms. We use the popular
Arcade Learning Environment (ALE; Bellemare et al., 2013) as an example of a
benchmark that, despite being increasingly considered "saturated", can be
effectively used for developing this understanding, and facilitating the
deployment of RL techniques in impactful real-world problems.

</details>


### [331] [Expressive Reward Synthesis with the Runtime Monitoring Language](https://arxiv.org/abs/2510.16185)
*Daniel Donnelly,Angelo Ferrando,Francesco Belardinelli*

Main category: cs.LG

TL;DR: 本文提出了一种基于RML的新型奖励机器，能够有效处理非规则、非马尔可夫奖励函数的规格化，提升了学习和解释能力。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中奖励（误）规格化的问题，提高奖励函数的可解释性和学习效果。

Method: 基于运行监控语言(RML)开发新的语言基础奖励机器。

Result: 提出的模型在表达性上优于传统奖励机器，能够处理更复杂的行为，并通过实验验证了其在事件处理和任务规范方面的优势。

Conclusion: 通过利用RML的内存特性，提出的语言基础奖励机器能够为非规则、非马尔可夫任务指定奖励函数，并在灵活的事件处理和任务规范方面优于现有的方法。

Abstract: A key challenge in reinforcement learning (RL) is reward (mis)specification,
whereby imprecisely defined reward functions can result in unintended, possibly
harmful, behaviours. Indeed, reward functions in RL are typically treated as
black-box mappings from state-action pairs to scalar values. While effective in
many settings, this approach provides no information about why rewards are
given, which can hinder learning and interpretability. Reward Machines address
this issue by representing reward functions as finite state automata, enabling
the specification of structured, non-Markovian reward functions. However, their
expressivity is typically bounded by regular languages, leaving them unable to
capture more complex behaviours such as counting or parametrised conditions. In
this work, we build on the Runtime Monitoring Language (RML) to develop a novel
class of language-based Reward Machines. By leveraging the built-in memory of
RML, our approach can specify reward functions for non-regular, non-Markovian
tasks. We demonstrate the expressiveness of our approach through experiments,
highlighting additional advantages in flexible event-handling and task
specification over existing Reward Machine-based methods.

</details>


### [332] [Human-Allied Relational Reinforcement Learning](https://arxiv.org/abs/2510.16188)
*Fateme Golivand Darvishvand,Hikaru Shindo,Sahil Sidheekh,Kristian Kersting,Sriraam Natarajan*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的框架，结合关系强化学习和面向对象的表示，通过专家指导改善学习效率，适用于处理结构化和非结构化数据。


<details>
  <summary>Details</summary>
Motivation: 当前的强化学习系统在处理结构化问题时存在局限，无法有效利用问题的内在结构，因此需要一种新的方法来提升学习能力和一般化能力。

Method: 结合关系强化学习（RRL）与面向对象的表示，通过建模策略的不确定性来引导学习过程。

Result: 实证评估结果表明，所提出的方法在有效性和效率上均表现优异。

Conclusion: 提出的框架有效地结合了关系强化学习与面向对象的表示，可以处理结构化和非结构化数据，并通过查询人类专家来增强学习效果。

Abstract: Reinforcement learning (RL) has experienced a second wind in the past decade.
While incredibly successful in images and videos, these systems still operate
within the realm of propositional tasks ignoring the inherent structure that
exists in the problem. Consequently, relational extensions (RRL) have been
developed for such structured problems that allow for effective generalization
to arbitrary number of objects. However, they inherently make strong
assumptions about the problem structure. We introduce a novel framework that
combines RRL with object-centric representation to handle both structured and
unstructured data. We enhance learning by allowing the system to actively query
the human expert for guidance by explicitly modeling the uncertainty over the
policy. Our empirical evaluation demonstrates the effectiveness and efficiency
of our proposed approach.

</details>


### [333] [Explore-then-Commit for Nonstationary Linear Bandits with Latent Dynamics](https://arxiv.org/abs/2510.16208)
*Sunmook Choi,Yahya Sattar,Yassir Jedra,Maryam Fazel,Sarah Dean*

Main category: cs.LG

TL;DR: 我们提出了一种探索-再承诺算法，在非平稳的赌博问题中，通过学习隐状态的线性动态，实现了长短期奖励的优化，并提供了相应的悔恨界限和实用方法。


<details>
  <summary>Details</summary>
Motivation: 研究一个非平稳的赌博问题，其中奖励依赖于行动和隐状态，且隐状态受未知线性动态的支配，存在短期和长期奖励之间的矛盾。

Method: 我们采用探索-再承诺算法，首先通过随机的Rademacher行动进行探索阶段，接着在承诺阶段利用估计参数设计优化的行动序列。

Result: 通过处理时间相关奖励的学习和设计具有最佳长期奖励的行动序列，我们的研究成功地克服了这两个挑战，最终实现了悔恨的上界。

Conclusion: 我们提出的算法在有限时间范围内，实现了$	ilde{	ext{O}}(T^{2/3})$的悔恨界限，并通过实用的半正定松弛方法提供了一个可操作的解决方案。

Abstract: We study a nonstationary bandit problem where rewards depend on both actions
and latent states, the latter governed by unknown linear dynamics. Crucially,
the state dynamics also depend on the actions, resulting in tension between
short-term and long-term rewards. We propose an explore-then-commit algorithm
for a finite horizon $T$. During the exploration phase, random Rademacher
actions enable estimation of the Markov parameters of the linear dynamics,
which characterize the action-reward relationship. In the commit phase, the
algorithm uses the estimated parameters to design an optimized action sequence
for long-term reward. Our proposed algorithm achieves
$\tilde{\mathcal{O}}(T^{2/3})$ regret. Our analysis handles two key challenges:
learning from temporally correlated rewards, and designing action sequences
with optimal long-term reward. We address the first challenge by providing
near-optimal sample complexity and error bounds for system identification using
bilinear rewards. We address the second challenge by proving an equivalence
with indefinite quadratic optimization over a hypercube, a known NP-hard
problem. We provide a sub-optimality guarantee for this problem, enabling our
regret upper bound. Lastly, we propose a semidefinite relaxation with
Goemans-Williamson rounding as a practical approach.

</details>


### [334] [Benchmarking noisy label detection methods](https://arxiv.org/abs/2510.16211)
*Henrique Pickler,Jorge K. S. Kamassury,Danilo Silva*

Main category: cs.LG

TL;DR: 本文对标签噪声检测方法进行了全面的基准测试，提出了一种新的检测方法评估标准，并发现某些信息收集与聚合的组合在多数情况下表现最佳。


<details>
  <summary>Details</summary>
Motivation: 标签噪声是现实世界数据集中常见的问题，影响模型训练和验证，清洁数据对实现强大性能至关重要。

Method: 通过将检测方法分解为标签一致性函数、聚合方法和信息收集方法进行全面基准测试。

Result: 我们的评估涵盖了在合成和真实世界噪声条件下的视觉和表格数据集，提出了一个统一的基准任务和一个新的指标：在固定操作点下的假阴性率。

Conclusion: 在大多数场景中，使用平均概率聚合和Logit边际作为标签一致性函数的样本内信息收集方法取得了最佳结果。

Abstract: Label noise is a common problem in real-world datasets, affecting both model
training and validation. Clean data are essential for achieving strong
performance and ensuring reliable evaluation. While various techniques have
been proposed to detect noisy labels, there is no clear consensus on optimal
approaches. We perform a comprehensive benchmark of detection methods by
decomposing them into three fundamental components: label agreement function,
aggregation method, and information gathering approach (in-sample vs
out-of-sample). This decomposition can be applied to many existing detection
methods, and enables systematic comparison across diverse approaches. To fairly
compare methods, we propose a unified benchmark task, detecting a fraction of
training samples equal to the dataset's noise rate. We also introduce a novel
metric: the false negative rate at this fixed operating point. Our evaluation
spans vision and tabular datasets under both synthetic and real-world noise
conditions. We identify that in-sample information gathering using average
probability aggregation combined with the logit margin as the label agreement
function achieves the best results across most scenarios. Our findings provide
practical guidance for designing new detection methods and selecting techniques
for specific applications.

</details>


### [335] [Machine Learning for Climate Policy: Understanding Policy Progression in the European Green Deal](https://arxiv.org/abs/2510.16233)
*Patricia West,Michelle WL Wan,Alexander Hepburn,Edwin Simpson,Raul Santos-Rodriguez,Jeffrey N Clark*

Main category: cs.LG

TL;DR: 本研究通过机器学习分析欧盟绿色协议中的气候政策，发现ClimateBERT和BERT模型具有较好的预测能力，强调了机器学习工具在气候政策决策中的价值。


<details>
  <summary>Details</summary>
Motivation: 气候变化需要有效的立法行动来减缓其影响，因此需要分析和预测气候政策的进展。

Method: 本研究使用机器学习方法，分析政策进展状态，并比较文本表示方法，包括TF-IDF、BERT和ClimateBERT。

Result: ClimateBERT在仅使用文本特征时表现优于其他方法，而BERT在加入元数据特征后取得了更好的性能。使用可解释的AI方法突出了政策措辞及元数据的影响。

Conclusion: 研究表明机器学习工具在气候政策分析和决策中具有潜力。

Abstract: Climate change demands effective legislative action to mitigate its impacts.
This study explores the application of machine learning (ML) to understand the
progression of climate policy from announcement to adoption, focusing on
policies within the European Green Deal. We present a dataset of 165 policies,
incorporating text and metadata. We aim to predict a policy's progression
status, and compare text representation methods, including TF-IDF, BERT, and
ClimateBERT. Metadata features are included to evaluate the impact on
predictive performance. On text features alone, ClimateBERT outperforms other
approaches (RMSE = 0.17, R^2 = 0.29), while BERT achieves superior performance
with the addition of metadata features (RMSE = 0.16, R^2 = 0.38). Using methods
from explainable AI highlights the influence of factors such as policy wording
and metadata including political party and country representation. These
findings underscore the potential of ML tools in supporting climate policy
analysis and decision-making.

</details>


### [336] [WEBSERV: A Browser-Server Environment for Efficient Training of Reinforcement Learning-based Web Agents at Scale](https://arxiv.org/abs/2510.16252)
*Yuxuan Lu,Jing Huang,Hui Liu,Jiri Gesi,Yan Han,Shihan Fu,Tianqi Zheng,Dakuo Wang*

Main category: cs.LG

TL;DR: WEBSERV是一个新型RL环境，通过提高启动效率和降低存储需求，显著改善了浏览器和服务器的交互，支持大规模的训练评估。


<details>
  <summary>Details</summary>
Motivation: 当前的RL训练环境存在上下文过载、非确定性动作和可扩展性差等问题，急需一种更有效的解决方案。

Method: 通过设计一个紧凑的、独立于站点的浏览器环境并搭建高效的Web服务器，实现大规模RL训练与评估。

Result: 在WebArena的购物CMS和Gitlab任务中，WEBSERV达到了先进的单提示成功率，启动延迟降低了约5倍，存储需求减少约240倍，且保持了相当的内存占用，支持在单主机上运行200个以上的并发容器。

Conclusion: WEBSERV提供了一种高效、可扩展的强大RL训练和评估环境，显著提高了性能和资源利用率。

Abstract: Training and evaluation of Reinforcement Learning (RL) web agents have gained
increasing attention, yet a scalable and efficient environment that couples
realistic and robust browser-side interaction with controllable server-side
state at scale is still missing. Existing environments tend to have one or more
of the following issues: they overwhelm policy models with excessive and noisy
context; they perform actions non-deterministically without waiting for the UI
or network to stabilize; or they cannot scale isolated client-server containers
effectively for parallel RL rollouts. We propose WEBSERV, an environment that
includes 1) a compact, site-agnostic browser environment that balances context
and action complexity, and 2) a scalable RL environment via efficient launching
and resetting web-servers to enable scalable RL training and evaluation. We
evaluate WEBSERV on the shopping CMS and Gitlab tasks in WebArena, achieving
state-of-the-art single-prompt success rates while cutting launch latency by
~5x and storage need by ~240x, with a comparable memory footprint, enabling
200+ concurrent containers on a single host.

</details>


### [337] [Protein Folding with Neural Ordinary Differential Equations](https://arxiv.org/abs/2510.16253)
*Arielle Sanford,Shuo Sun,Christian B. Mendl*

Main category: cs.LG

TL;DR: 本文提出的连续深度Evoformer模型通过神经常微分方程在降低计算资源的同时，体现了蛋白质结构预测的有效性，具备更高的效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的Evoformer深度大且计算成本高，因此需要一种更加高效并且灵活的模型来改善资源的使用。

Method: 采用神经常微分方程（Neural ODE）参数化，替代48个离散块以实现连续深度，同时保留核心的基于注意力的操作。

Result: 使用连续时间Evoformer，模型能够以更低的资源实现对蛋白质结构的合理预测，尽管其精度略低于原始架构，但依然能够可靠捕获某些二级结构元素。

Conclusion: 本研究提出的连续深度Evoformer模型在降低计算资源的同时，保持了对蛋白质结构预测的有效性，显示出其在生物分子建模中的潜力。

Abstract: Recent advances in protein structure prediction, such as AlphaFold, have
demonstrated the power of deep neural architectures like the Evoformer for
capturing complex spatial and evolutionary constraints on protein conformation.
However, the depth of the Evoformer, comprising 48 stacked blocks, introduces
high computational costs and rigid layerwise discretization. Inspired by Neural
Ordinary Differential Equations (Neural ODEs), we propose a continuous-depth
formulation of the Evoformer, replacing its 48 discrete blocks with a Neural
ODE parameterization that preserves its core attention-based operations. This
continuous-time Evoformer achieves constant memory cost (in depth) via the
adjoint method, while allowing a principled trade-off between runtime and
accuracy through adaptive ODE solvers. Benchmarking on protein structure
prediction tasks, we find that the Neural ODE-based Evoformer produces
structurally plausible predictions and reliably captures certain secondary
structure elements, such as alpha-helices, though it does not fully replicate
the accuracy of the original architecture. However, our model achieves this
performance using dramatically fewer resources, just 17.5 hours of training on
a single GPU, highlighting the promise of continuous-depth models as a
lightweight and interpretable alternative for biomolecular modeling. This work
opens new directions for efficient and adaptive protein structure prediction
frameworks.

</details>


### [338] [QSVD: Efficient Low-rank Approximation for Unified Query-Key-Value Weight Compression in Low-Precision Vision-Language Models](https://arxiv.org/abs/2510.16292)
*Yutong Wang,Haiyu Wang,Sai Qian Zhang*

Main category: cs.LG

TL;DR: 通过奇异值分解和量化技术优化Vision-Language Models，达到更好性能和效率，适合资源有限的实时部署。


<details>
  <summary>Details</summary>
Motivation: Vision-Language Models在图像字幕生成和视觉问答等任务中应用广泛，但高计算成本限制了其可扩展性和实时应用能力。

Method: 使用奇异值分解(SVD)处理查询(Q)、键(K)和值(V)权重矩阵，并引入动态秩分配策略和量化技术。

Result: 通过优化奇异值分解和引入量化，取得了超过10%的准确性提升，同时减少了硬件成本。

Conclusion: 提出了一种新的方法，通过对权重矩阵进行奇异值分解和量化，从而显著降低了内存使用和计算成本，并改善了模型的准确性，适合实时部署。

Abstract: Vision-Language Models (VLMs) are integral to tasks such as image captioning
and visual question answering, but their high computational cost, driven by
large memory footprints and processing time, limits their scalability and
real-time applicability. In this work, we propose leveraging Singular-Value
Decomposition (SVD) over the joint query (Q), key (K), and value (V) weight
matrices to reduce KV cache size and computational overhead. We in addition
introduce an efficient rank allocation strategy that dynamically adjusts the
SVD rank based on its impact on VLM accuracy, achieving a significant reduction
in both memory usage and computational cost. Finally, we extend this approach
by applying quantization to both VLM weights and activations, resulting in a
highly efficient VLM. Our method outperforms previous approaches that rely
solely on quantization or SVD by achieving more than $10\%$ accuracy
improvement while consuming less hardware cost, making it better for real-time
deployment on resource-constrained devices. We open source our code at
\href{https://github.com/SAI-Lab-NYU/QSVD}{\texttt{https://github.com/SAI-Lab-NYU/QSVD}}.

</details>


### [339] [Scaffold-Aware Generative Augmentation and Reranking for Enhanced Virtual Screening](https://arxiv.org/abs/2510.16306)
*Xin Wang,Yu Wang,Yunchao Liu,Jens Meiler,Tyler Derr*

Main category: cs.LG

TL;DR: 本研究提出ScaffAug框架，通过数据增强、模型自我训练和重排序方法，解决虚拟筛选中的类和结构不平衡问题，提升药物发现效果。


<details>
  <summary>Details</summary>
Motivation: 为了解决虚拟筛选中的类不平衡和结构不平衡问题，并且需要识别在药物开发中结构多样的活性化合物。

Method: ScaffAug框架包括三个模块：数据增强模块、模型无关自我训练模块和重排序模块，针对类不平衡、结构不平衡等问题进行优化。

Result: ScaffAug在五个目标类别上进行了全面的计算实验，结果显示出其在多项评估指标上优于现有基线方法，并有效提升了识别新活性化合物的能力。

Conclusion: 本研究提出的ScaffAug框架通过生成性增强、重排序和结构意识的方法，显著提高了虚拟筛选的效果。

Abstract: Ligand-based virtual screening (VS) is an essential step in drug discovery
that evaluates large chemical libraries to identify compounds that potentially
bind to a therapeutic target. However, VS faces three major challenges: class
imbalance due to the low active rate, structural imbalance among active
molecules where certain scaffolds dominate, and the need to identify
structurally diverse active compounds for novel drug development. We introduce
ScaffAug, a scaffold-aware VS framework that addresses these challenges through
three modules. The augmentation module first generates synthetic data
conditioned on scaffolds of actual hits using generative AI, specifically a
graph diffusion model. This helps mitigate the class imbalance and furthermore
the structural imbalance, due to our proposed scaffold-aware sampling
algorithm, designed to produce more samples for active molecules with
underrepresented scaffolds. A model-agnostic self-training module is then used
to safely integrate the generated synthetic data from our augmentation module
with the original labeled data. Lastly, we introduce a reranking module that
improves VS by enhancing scaffold diversity in the top recommended set of
molecules, while still maintaining and even enhancing the overall general
performance of identifying novel, active compounds. We conduct comprehensive
computational experiments across five target classes, comparing ScaffAug
against existing baseline methods by reporting the performance of multiple
evaluation metrics and performing ablation studies on ScaffAug. Overall, this
work introduces novel perspectives on effectively enhancing VS by leveraging
generative augmentations, reranking, and general scaffold-awareness.

</details>


### [340] [Colliding with Adversaries at ECML-PKDD 2025 Adversarial Attack Competition 1st Prize Solution](https://arxiv.org/abs/2510.16440)
*Dimitris Stefanopoulos,Andreas Voskou*

Main category: cs.LG

TL;DR: 本报告介绍了在2025年ECML-PKDD比赛中获胜的对抗攻击方案，该方案实现了最佳的扰动大小和欺骗成功率。


<details>
  <summary>Details</summary>
Motivation: 设计一种对给定分类模型进行对抗攻击的方法，以最大化错误分类并最小化扰动。

Method: 采用多轮基于梯度的策略，利用模型的可微分结构，并结合随机初始化和样本混合技术。

Result: 成功地实现了针对分类模型的对抗攻击，在扰动大小和欺骗成功率上表现优异。

Conclusion: 该攻击方案在扰动大小和欺骗成功率方面取得了最佳结果，赢得了比赛的第一名。

Abstract: This report presents the winning solution for Task 1 of Colliding with
Adversaries: A Challenge on Robust Learning in High Energy Physics Discovery at
ECML-PKDD 2025. The task required designing an adversarial attack against a
provided classification model that maximizes misclassification while minimizing
perturbations. Our approach employs a multi-round gradient-based strategy that
leverages the differentiable structure of the model, augmented with random
initialization and sample-mixing techniques to enhance effectiveness. The
resulting attack achieved the best results in perturbation size and fooling
success rate, securing first place in the competition.

</details>


### [341] [Input Domain Aware MoE: Decoupling Routing Decisions from Task Optimization in Mixture of Experts](https://arxiv.org/abs/2510.16448)
*Yongxiang Hua,Haoyu Cao,Zhou Tao,Bocheng Li,Zihao Wu,Chaohu Liu,Linli Xu*

Main category: cs.LG

TL;DR: 提出的Input Domain Aware MoE改进了专家路由，提升了视觉-语言模型的性能与专家利用率。


<details>
  <summary>Details</summary>
Motivation: 现有的路由机制无法有效捕捉输入结构，导致专家专业化与计算平衡之间的权衡，阻碍了模型的可扩展性与性能。

Method: 提出了一种基于概率混合模型的路由框架，通过建模路由概率的分布混合，优化了输入空间的划分。

Result: 该方法在视觉-语言任务上超越了现有的sMoE方法，表现出更好的任务性能与专家的合理利用。

Conclusion: Input Domain Aware MoE方法在视觉-语言任务中表现优越，实现了更高的任务性能和优化的专家利用率平衡。

Abstract: Sparse Mixture of Experts (sMoE) has become a pivotal approach for scaling
large vision-language models, offering substantial capacity while maintaining
computational efficiency through dynamic, sparse activation of experts.
However, existing routing mechanisms, typically based on similarity scoring,
struggle to effectively capture the underlying input structure. This limitation
leads to a trade-off between expert specialization and balanced computation,
hindering both scalability and performance. We propose Input Domain Aware MoE,
a novel routing framework that leverages a probabilistic mixture model to
better partition the input space. By modeling routing probabilities as a
mixture of distributions, our method enables experts to develop clear
specialization boundaries while achieving balanced utilization. Unlike
conventional approaches, our routing mechanism is trained independently of
task-specific objectives, allowing for stable optimization and decisive expert
assignments. Empirical results on vision-language tasks demonstrate that our
method consistently outperforms existing sMoE approaches, achieving higher task
performance and improved expert utilization balance.

</details>


### [342] [Buzz, Choose, Forget: A Meta-Bandit Framework for Bee-Like Decision Making](https://arxiv.org/abs/2510.16462)
*Emmanuelle Claeys,Elena Kerjean,Jean-Michel Loubes*

Main category: cs.LG

TL;DR: 本研究提出了一种新的模仿学习框架，通过分析蜜蜂的认知策略，提升了对其决策行为的理解，并提供了可用于生态研究的数据集。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有模仿学习方法在处理多样性认知策略时的局限性，特别是蜜蜂在不同环境因素下的决策行为。

Method: 通过引入一种最小化预测损失的模型，以及确定与行为数据一致的有效记忆范围，进行了一系列实验评估。

Result: 验证了传统模仿学习方法在快速和慢速学习行为上的不足，提出了全可解释性的模型来分析决策策略，并发布了包含80只蜜蜂的新数据集。

Conclusion: 我们的研究改进了模仿学习方法，以更准确地捕捉蜜蜂等授粉者的决策行为，并提供了新的数据集以支持相关研究和生态治理。

Abstract: We introduce a sequential reinforcement learning framework for imitation
learning designed to model heterogeneous cognitive strategies in pollinators.
Focusing on honeybees, our approach leverages trajectory similarity to capture
and forecast behavior across individuals that rely on distinct strategies: some
exploiting numerical cues, others drawing on memory, or being influenced by
environmental factors such as weather. Through empirical evaluation, we show
that state-of-the-art imitation learning methods often fail in this setting:
when expert policies shift across memory windows or deviate from optimality,
these models overlook both fast and slow learning behaviors and cannot
faithfully reproduce key decision patterns. Moreover, they offer limited
interpretability, hindering biological insight. Our contribution addresses
these challenges by (i) introducing a model that minimizes predictive loss
while identifying the effective memory horizon most consistent with behavioral
data, and (ii) ensuring full interpretability to enable biologists to analyze
underlying decision-making strategies and finally (iii) providing a
mathematical framework linking bee policy search with bandit formulations under
varying exploration-exploitation dynamics, and releasing a novel dataset of 80
tracked bees observed under diverse weather conditions. This benchmark
facilitates research on pollinator cognition and supports ecological governance
by improving simulations of insect behavior in agroecosystems. Our findings
shed new light on the learning strategies and memory interplay shaping
pollinator decision-making.

</details>


### [343] [SCALAR: Self-Calibrating Adaptive Latent Attention Representation Learning](https://arxiv.org/abs/2510.16474)
*Farwa Abbas,Hussain Ahmad,Claudia Szabo*

Main category: cs.LG

TL;DR: 本研究提出了一种新方法，采用自适应核注意力机制解决高维数据中的复杂非线性关系和特征相关性问题，实现了预测性能的大幅提升。


<details>
  <summary>Details</summary>
Motivation: 高维异构数据的复杂特征交互对传统预测建模方法提出了重大挑战。

Method: 引入了基于自适应核的注意力机制，分别处理不同的特征组，然后进行集成。

Result: 实验结果显示，所提方法在不同数据集上相较于现有的最先进方法有显著的性能改进。

Conclusion: 提出了一种新颖的方法，通过新的架构创新增强了预测性能。

Abstract: High-dimensional, heterogeneous data with complex feature interactions pose
significant challenges for traditional predictive modeling approaches. While
Projection to Latent Structures (PLS) remains a popular technique, it struggles
to model complex non-linear relationships, especially in multivariate systems
with high-dimensional correlation structures. This challenge is further
compounded by simultaneous interactions across multiple scales, where local
processing fails to capture crossgroup dependencies. Additionally, static
feature weighting limits adaptability to contextual variations, as it ignores
sample-specific relevance. To address these limitations, we propose a novel
method that enhances predictive performance through novel architectural
innovations. Our architecture introduces an adaptive kernel-based attention
mechanism that processes distinct feature groups separately before integration,
enabling capture of local patterns while preserving global relationships.
Experimental results show substantial improvements in performance metrics,
compared to the state-of-the-art methods across diverse datasets.

</details>


### [344] [Structured Temporal Causality for Interpretable Multivariate Time Series Anomaly Detection](https://arxiv.org/abs/2510.16511)
*Dongchan Cho,Jiho Han,Keumyeong Kang,Minsang Kim,Honggyu Ryu,Namsoon Jung*

Main category: cs.LG

TL;DR: 本文提出OracleAD，一种简单且可解释的无监督框架，用于多元时间序列异常检测，能够有效建模时间动态并实现先进的检测性能。


<details>
  <summary>Details</summary>
Motivation: 对多元时间序列异常检测的现有方法通常依赖复杂的架构，检测到的异常片段有限且性能被夸大，因此需要一个更简单且可解释的无监督框架。

Method: 一个简单且可解释的无监督框架，通过编码每个变量的历史序列来共同预测当前时点并重建输入窗口，有效建模时间动态。利用自关注机制将嵌入投影到共享潜在空间中，以捕捉空间关系。

Result: OracleAD通过基于预测误差和偏离稳定潜在结构(SLS)的双评分机制，实现了对每个时间点和各个变量的细粒度异常诊断。

Conclusion: OracleAD在多个真实世界数据集和评估协议中实现了先进的结果，同时通过稳定潜在结构(SLS)保持了可解释性。

Abstract: Real-world multivariate time series anomalies are rare and often unlabeled.
Additionally, prevailing methods rely on increasingly complex architectures
tuned to benchmarks, detecting only fragments of anomalous segments and
overstating performance. In this paper, we introduce OracleAD, a simple and
interpretable unsupervised framework for multivariate time series anomaly
detection. OracleAD encodes each variable's past sequence into a single causal
embedding to jointly predict the present time point and reconstruct the input
window, effectively modeling temporal dynamics. These embeddings then undergo a
self-attention mechanism to project them into a shared latent space and capture
spatial relationships. These relationships are not static, since they are
modeled by a property that emerges from each variable's temporal dynamics. The
projected embeddings are aligned to a Stable Latent Structure (SLS)
representing normal-state relationships. Anomalies are identified using a dual
scoring mechanism based on prediction error and deviation from the SLS,
enabling fine-grained anomaly diagnosis at each time point and across
individual variables. Since any noticeable SLS deviation originates from
embeddings that violate the learned temporal causality of normal data, OracleAD
directly pinpoints the root-cause variables at the embedding level. OracleAD
achieves state-of-the-art results across multiple real-world datasets and
evaluation protocols, while remaining interpretable through SLS.

</details>


### [345] [eDCF: Estimating Intrinsic Dimension using Local Connectivity](https://arxiv.org/abs/2510.16513)
*Dhruv Gupta,Aditya Nagarsekar,Vraj Shah,Sujith Thomas*

Main category: cs.LG

TL;DR: 本研究提出了一种新颖的eDCF方法，通过局部连通性度量 robustly 估计数据集的内在维度，特别是在中高噪声水平和大型数据集上效果显著。


<details>
  <summary>Details</summary>
Motivation: 面对高维特征和复杂依赖关系的数据，准确估计数据集的内在维度以降低维度并分析数据。

Method: 基于局部连通性度量的Connectivity Factor (CF)方法，具有可扩展性和并行化特性。

Result: eDCF方法在合成基准测试中与其他领先估计器相当，具有较低的平均绝对误差（MAE）和较高的内在维度匹配率。

Conclusion: 提出的方法在不同噪音水平和大型数据集上表现出色，能够准确估计内在维度并有效检测分形几何结构。

Abstract: Modern datasets often contain high-dimensional features exhibiting complex
dependencies. To effectively analyze such data, dimensionality reduction
methods rely on estimating the dataset's intrinsic dimension (id) as a measure
of its underlying complexity. However, estimating id is challenging due to its
dependence on scale: at very fine scales, noise inflates id estimates, while at
coarser scales, estimates stabilize to lower, scale-invariant values. This
paper introduces a novel, scalable, and parallelizable method called eDCF,
which is based on Connectivity Factor (CF), a local connectivity-based metric,
to robustly estimate intrinsic dimension across varying scales. Our method
consistently matches leading estimators, achieving comparable values of mean
absolute error (MAE) on synthetic benchmarks with noisy samples. Moreover, our
approach also attains higher exact intrinsic dimension match rates, reaching up
to 25.0% compared to 16.7% for MLE and 12.5% for TWO-NN, particularly excelling
under medium to high noise levels and large datasets. Further, we showcase our
method's ability to accurately detect fractal geometries in decision
boundaries, confirming its utility for analyzing realistic, structured data.

</details>


### [346] [Realizing LLMs' Causal Potential Requires Science-Grounded, Novel Benchmarks](https://arxiv.org/abs/2510.16530)
*Ashutosh Srivastava,Lokesh Nagalapatti,Gautam Jajoo,Aniket Vashishtha,Parameswari Krishnamurthy,Amit Sharma*

Main category: cs.LG

TL;DR: 本文质疑当前LLMs在因果发现中的表现，并提出通过科学研究基础的评估和混合方法来提高其有效性。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在因果推理中的真实能力，以及如何在消除记忆偏差的情况下进行有效测量。

Method: 通过对新近科学研究的评估以及设计混合方法，结合LLMs和数据驱动统计，进行因果结构推理。

Result: LLMs在经过严格评估的情况下，其表现不足以超越传统统计方法，强调了需要科学基础的评估基准和混合方法。

Conclusion: LLMs在因果发现中的应用必须依赖于更可靠的评估协议和混合方法，以确保其科学性和有效性。

Abstract: Recent claims of strong performance by Large Language Models (LLMs) on causal
discovery are undermined by a key flaw: many evaluations rely on benchmarks
likely included in pretraining corpora. Thus, apparent success suggests that
LLM-only methods, which ignore observational data, outperform classical
statistical approaches. We challenge this narrative by asking: Do LLMs truly
reason about causal structure, and how can we measure it without memorization
concerns? Can they be trusted for real-world scientific discovery? We argue
that realizing LLMs' potential for causal analysis requires two shifts: (P.1)
developing robust evaluation protocols based on recent scientific studies to
guard against dataset leakage, and (P.2) designing hybrid methods that combine
LLM-derived knowledge with data-driven statistics. To address P.1, we encourage
evaluating discovery methods on novel, real-world scientific studies. We
outline a practical recipe for extracting causal graphs from recent
publications released after an LLM's training cutoff, ensuring relevance and
preventing memorization while capturing both established and novel relations.
Compared to benchmarks like BNLearn, where LLMs achieve near-perfect accuracy,
they perform far worse on our curated graphs, underscoring the need for
statistical grounding. Supporting P.2, we show that using LLM predictions as
priors for the classical PC algorithm significantly improves accuracy over both
LLM-only and purely statistical methods. We call on the community to adopt
science-grounded, leakage-resistant benchmarks and invest in hybrid causal
discovery methods suited to real-world inquiry.

</details>


### [347] [Predicting life satisfaction using machine learning and explainable AI](https://arxiv.org/abs/2510.16547)
*Alif Elham Khan,Mohammad Junayed Hasan,Humayra Anjum,Nabeel Mohammed,Sifat Momen*

Main category: cs.LG

TL;DR: 本研究利用机器学习和大语言模型高效预测人生满意度，强调健康状况的重要性，并为主观幸福感的量化提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 研究人生满意度对理解人类生活体验及干预心理健康的重要性。

Method: 通过机器学习算法和大语言模型分析数据，提取出27个重要问题，进行特征学习和建模。

Result: 使用机器学习算法预测人生满意度的准确率达93.80%，宏观F1分数为73.00%；转换表格数据为自然语言后预测准确率为93.74%。

Conclusion: 本研究显示，机器学习和大语言模型能够高效预测人生满意度，并强调健康状况在不同年龄段的重要性。

Abstract: Life satisfaction is a crucial facet of human well-being. Hence, research on
life satisfaction is incumbent for understanding how individuals experience
their lives and influencing interventions targeted at enhancing mental health
and well-being. Life satisfaction has traditionally been measured using analog,
complicated, and frequently error-prone methods. These methods raise questions
concerning validation and propagation. However, this study demonstrates the
potential for machine learning algorithms to predict life satisfaction with a
high accuracy of 93.80% and a 73.00% macro F1-score. The dataset comes from a
government survey of 19000 people aged 16-64 years in Denmark. Using feature
learning techniques, 27 significant questions for assessing contentment were
extracted, making the study highly reproducible, simple, and easily
interpretable. Furthermore, clinical and biomedical large language models
(LLMs) were explored for predicting life satisfaction by converting tabular
data into natural language sentences through mapping and adding meaningful
counterparts, achieving an accuracy of 93.74% and macro F1-score of 73.21%. It
was found that life satisfaction prediction is more closely related to the
biomedical domain than the clinical domain. Ablation studies were also
conducted to understand the impact of data resampling and feature selection
techniques on model performance. Moreover, the correlation between primary
determinants with different age brackets was analyzed, and it was found that
health condition is the most important determinant across all ages. This study
demonstrates how machine learning, large language models and XAI can jointly
contribute to building trust and understanding in using AI to investigate human
behavior, with significant ramifications for academics and professionals
working to quantify and comprehend subjective well-being.

</details>


### [348] [NeurIPT: Foundation Model for Neural Interfaces](https://arxiv.org/abs/2510.16548)
*Zitao Fang,Chenxuan Li,Hongting Zhou,Shuyang Yu,Guodong Du,Ashwaq Qasem,Yang Lu,Jing Li,Junsong Zhang,Sim Kuan Goh*

Main category: cs.LG

TL;DR: NeurIPT是一种新颖的EEG基础模型，通过专门的预训练和微调方法，提升了EEG信号的解码性能，实现了在多个BCI数据集上的领先结果。


<details>
  <summary>Details</summary>
Motivation: 由于EEG数据的多样性和复杂性，建立基础模型以提升神经解码的可扩展性和泛化能力显得尤为重要。

Method: 通过引入基于信号幅度的掩码预训练和渐进混合专家架构，结合电极的三维物理坐标和区域脑特征的利用，进行模型训练和微调。

Result: 在八个下游BCI数据集的实证评估中，NeurIPT经过微调后持续实现了最先进的性能，展示了其广泛的适用性和强大的泛化能力。

Conclusion: NeurIPT在多种EEG数据集上表现出色，推动了EEG领域的基础模型发展，并提供了可扩展的神经信息处理系统的见解。

Abstract: Electroencephalography (EEG) has wide-ranging applications, from clinical
diagnosis to brain-computer interfaces (BCIs). With the increasing volume and
variety of EEG data, there has been growing interest in establishing foundation
models (FMs) to scale up and generalize neural decoding. Despite showing early
potential, applying FMs to EEG remains challenging due to substantial
inter-subject, inter-task, and inter-condition variability, as well as diverse
electrode configurations across recording setups. To tackle these open
challenges, we propose NeurIPT, a foundation model developed for diverse
EEG-based Neural Interfaces with a Pre-trained Transformer by capturing both
homogeneous and heterogeneous spatio-temporal characteristics inherent in EEG
signals. Temporally, we introduce Amplitude-Aware Masked Pretraining (AAMP),
masking based on signal amplitude rather than random intervals, to learn robust
representations across varying signal intensities beyond local interpolation.
Moreover, this temporal representation is enhanced by a Progressive
Mixture-of-Experts (PMoE) architecture, where specialized expert subnetworks
are progressively introduced at deeper layers, adapting effectively to the
diverse temporal characteristics of EEG signals. Spatially, NeurIPT leverages
the 3D physical coordinates of electrodes, enabling effective transfer of
embedding across varying EEG settings, and develops Intra-Inter Lobe Pooling
(IILP) during fine-tuning to efficiently exploit regional brain features.
Empirical evaluations across eight downstream BCI datasets, via fine-tuning,
demonstrated NeurIPT consistently achieved state-of-the-art performance,
highlighting its broad applicability and robust generalization. Our work pushes
forward the state of FMs in EEG and offers insights into scalable and
generalizable neural information processing systems.

</details>


### [349] [LANPO: Bootstrapping Language and Numerical Feedback for Reinforcement Learning in LLMs](https://arxiv.org/abs/2510.16552)
*Ang Li,Yifei Wang,Zhihang Yuan,Stefanie Jegelka,Yisen Wang*

Main category: cs.LG

TL;DR: LANPO框架通过动态经验池优化语言和数值反馈的使用，显著提升了大语言模型的样本效率和准确率。


<details>
  <summary>Details</summary>
Motivation: 为了解决在强化学习中使用标量奖励时丢失文本推理的情况，并提高样本效率。

Method: 提出了语言和数值政策优化（LANPO）的框架，通过动态经验池和两项原则确保反馈的有效性。

Result: 在数学推理基准上，LANPO使7B和14B模型在测试准确率上显著超过强基线的表现。

Conclusion: LANPO框架通过有效整合历史经验，提升了大语言模型在数学推理基准上的表现，提供了一种更具数据效率的学习方法。

Abstract: Reinforcement learning in large language models (LLMs) often relies on scalar
rewards, a practice that discards valuable textual rationale buried in the
rollouts, forcing the model to explore \textit{de novo} with each attempt and
hindering sample efficiency. While LLMs can uniquely learn from language
feedback provided in-context, naively integrating on-line experiences into RL
training presents a paradox: feedback from the same problem risks information
leakage and memorization, while feedback from different problems often leads to
behavior collapse due to irrelevant context. To resolve this tension, we
propose \textbf{Language-And-Numerical Policy Optimization (LANPO)}, a
framework that cleanly separates the roles of feedback: language guides
exploration, while numerical rewards drive optimization. LANPO builds a dynamic
experience pool from past trials and introduces two principles to ensure
feedback is effective: \emph{Reward-Agnostic Reflection} for safe intra-sample
self-correction and \emph{Relevant Abstraction} to distill generalizable
lessons from inter-sample experiences. Across mathematical reasoning
benchmarks, LANPO enables 7B and 14B models to significantly outperform strong
baselines trained with GRPO in test accuracy. Our work provides a robust method
for integrating historical experiences into the LLM RL loop, creating more
effective and data-efficient learning agents.

</details>


### [350] [Atom-anchored LLMs speak Chemistry: A Retrosynthesis Demonstration](https://arxiv.org/abs/2510.16590)
*Alan Kai Hassen,Andrius Bernatavicius,Antonius P. A. Janssen,Mike Preuss,Gerard J. P. van Westen,Djork-Arné Clevert*

Main category: cs.LG

TL;DR: 本研究提出了一种利用大型语言模型进行分子推理的新框架，无需标记数据，成功提高化学反应预测准确性，并破解数据稀缺难题。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习在化学领域中的应用常受到标记数据的稀缺和成本高昂的限制，本研究旨在探索无监督学习在化学中的可行性。

Method: 该方法结合了链式思维推理与分子结构，通过唯一的原子标识符来建立关联，并在单步逆合成任务中实现化学转化的预测。

Result: 该方法在学术基准和专家验证的药物发现分子上，成功率达到识别化学反应位点超过90%、命名反应类别超过40%和最终反应物超过74%。

Conclusion: 通过引入一种利用大型语言模型进行分子推理的框架，该研究在无需标记数据的情况下提升了化学反应预测的准确性，并解决了数据稀缺性的问题。

Abstract: Applications of machine learning in chemistry are often limited by the
scarcity and expense of labeled data, restricting traditional supervised
methods. In this work, we introduce a framework for molecular reasoning using
general-purpose Large Language Models (LLMs) that operates without requiring
labeled training data. Our method anchors chain-of-thought reasoning to the
molecular structure by using unique atomic identifiers. First, the LLM performs
a one-shot task to identify relevant fragments and their associated chemical
labels or transformation classes. In an optional second step, this
position-aware information is used in a few-shot task with provided class
examples to predict the chemical transformation. We apply our framework to
single-step retrosynthesis, a task where LLMs have previously underperformed.
Across academic benchmarks and expert-validated drug discovery molecules, our
work enables LLMs to achieve high success rates in identifying chemically
plausible reaction sites ($\geq90\%$), named reaction classes ($\geq40\%$), and
final reactants ($\geq74\%$). Beyond solving complex chemical tasks, our work
also provides a method to generate theoretically grounded synthetic datasets by
mapping chemical knowledge onto the molecular structure and thereby addressing
data scarcity.

</details>


### [351] [Prior Makes It Possible: From Sublinear Graph Algorithms to LLM Test-Time Methods](https://arxiv.org/abs/2510.16609)
*Avrim Blum,Daniel Hsu,Cyrus Rashtchian,Donya Saless*

Main category: cs.LG

TL;DR: 本文研究了在预训练知识不足的情况下，通过增强步骤获取准确答案的效率，发现知识图的连通性对查询效率有重大影响。


<details>
  <summary>Details</summary>
Motivation: 探讨在小数量的增强步骤下，回答查询所需的预训练知识量，这是在实际应用中所需的特性。

Method: 将多步推理视为知识图上的 $s$-$t$ 连接问题，表示模型的预训练参数知识为部分、潜在嘈杂的子图，增强被视为查询真实边缘以增强模型知识。

Result: 识别出增强步骤的必要和充分数量，并揭示了阶段转变的现象。

Conclusion: 当先前知识超过某个阈值形成巨型组件后，可以期望通过常数数量的查询找到路径；否则，在知识图中存在小组件时，通过增强找到路径是低效的。

Abstract: Test-time augmentation, such as Retrieval-Augmented Generation (RAG) or tool
use, critically depends on an interplay between a model's parametric knowledge
and externally retrieved information. However, the theoretical underpinnings of
this relationship remain poorly understood. Specifically, it is not clear how
much pre-training knowledge is required to answer queries with a small number
of augmentation steps, which is a desirable property in practice. To address
this question, we formulate multi-step reasoning as an $s$-$t$ connectivity
problem on a knowledge graph. We represent a model's pre-training parametric
knowledge as a partial, potentially noisy subgraph. We view augmentation as
querying an oracle for true edges that augment the model's knowledge. Then, we
characterize the necessary and sufficient number of augmentation steps for the
model to generate an accurate answer given partial prior knowledge. One key
result shows a phase transition: if the prior knowledge graph over $n$ vertices
is disconnected into small components, then finding a path via augmentation is
inefficient and requires $\Omega(\sqrt{n})$ queries. On the other hand, once
the density of correct knowledge surpasses a threshold, forming a giant
component, we can find paths with an expected constant number of queries.

</details>


### [352] [Simulation-free Structure Learning for Stochastic Dynamics](https://arxiv.org/abs/2510.16656)
*Noah El Rimawi-Fine,Adam Stecklov,Lucas Nelson,Mathieu Blanchette,Alexander Tong,Stephen Y. Zhang,Lazar Atanackovic*

Main category: cs.LG

TL;DR: 本研究提出StructureFlow，一种同时学习物理系统结构和建模条件种群动态的无模拟方法，并在多种系统上验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 高维和随机的自然科学系统（如细胞生物学）的状态测量通常存在噪声和部分性，这使得同时解决结构学习和动态建模的问题变得具有挑战性。

Method: 提出了一种新的无模拟的方法，即StructureFlow，旨在联合学习物理系统的结构和随机种群动态。

Result: 在高维合成系统、模拟系统和实验单细胞数据集上进行实证评估，展示StructureFlow的效用。

Conclusion: StructureFlow可以在学习系统结构的同时建模其条件种群动态，这是理解系统行为的重要一步。

Abstract: Modeling dynamical systems and unraveling their underlying causal
relationships is central to many domains in the natural sciences. Various
physical systems, such as those arising in cell biology, are inherently
high-dimensional and stochastic in nature, and admit only partial, noisy state
measurements. This poses a significant challenge for addressing the problems of
modeling the underlying dynamics and inferring the network structure of these
systems. Existing methods are typically tailored either for structure learning
or modeling dynamics at the population level, but are limited in their ability
to address both problems together. In this work, we address both problems
simultaneously: we present StructureFlow, a novel and principled
simulation-free approach for jointly learning the structure and stochastic
population dynamics of physical systems. We showcase the utility of
StructureFlow for the tasks of structure learning from interventions and
dynamical (trajectory) inference of conditional population dynamics. We
empirically evaluate our approach on high-dimensional synthetic systems, a set
of biologically plausible simulated systems, and an experimental single-cell
dataset. We show that StructureFlow can learn the structure of underlying
systems while simultaneously modeling their conditional population dynamics --
a key step toward the mechanistic understanding of systems behavior.

</details>


### [353] [Evaluating protein binding interfaces with PUMBA](https://arxiv.org/abs/2510.16674)
*Azam Shirali,Giri Narasimhan*

Main category: cs.LG

TL;DR: PUMBA是一种基于Vision Mamba的新评分函数，它改进了PIsToN，能更好地捕捉蛋白质-蛋白质界面的特征，并在评估中表现出色。


<details>
  <summary>Details</summary>
Motivation: 蛋白质-蛋白质对接工具在蛋白质相互作用研究及药物、疫苗和治疗开发中至关重要，但现有工具的准确性受限于评分函数的有效性。

Method: PUMBA利用Vision Mamba架构替代了PIsToN中的Vision Transformer，以提高其建模蛋白质-蛋白质界面的能力。

Result: PUMBA显著提升了对蛋白质-蛋白质界面特征的建模能力，并在多个数据集上表现优于PIsToN。

Conclusion: PUMBA在多个大型公共数据集上的评估结果显示，其在蛋白质-蛋白质界面特征的捕捉能力上显著优于原有的PIsToN模型。

Abstract: Protein-protein docking tools help in studying interactions between proteins,
and are essential for drug, vaccine, and therapeutic development. However, the
accuracy of a docking tool depends on a robust scoring function that can
reliably differentiate between native and non-native complexes. PIsToN is a
state-of-the-art deep learning-based scoring function that uses Vision
Transformers in its architecture. Recently, the Mamba architecture has
demonstrated exceptional performance in both natural language processing and
computer vision, often outperforming Transformer-based models in their domains.
In this study, we introduce PUMBA (Protein-protein interface evaluation with
Vision Mamba), which improves PIsToN by replacing its Vision Transformer
backbone with Vision Mamba. This change allows us to leverage Mamba's efficient
long-range sequence modeling for sequences of image patches. As a result, the
model's ability to capture both global and local patterns in protein-protein
interface features is significantly improved. Evaluation on several
widely-used, large-scale public datasets demonstrates that PUMBA consistently
outperforms its original Transformer-based predecessor, PIsToN.

</details>


### [354] [Active Target Discovery under Uninformative Prior: The Power of Permanent and Transient Memory](https://arxiv.org/abs/2510.16676)
*Anindya Sarkar,Binglin Ji,Yevgeniy Vorobeychik*

Main category: cs.LG

TL;DR: 我们提出一种新方法，可在缺乏有效先验的情况下进行主动目标发现，表现优于现有基线，确保在复杂环境中可靠性和适应性。


<details>
  <summary>Details</summary>
Motivation: 在数据获取昂贵的科学和工程领域，优化未观察区域的采样以最大化发现率至关重要。

Method: 我们提出了一种新颖的方法，能够在缺乏有效先验的条件下进行主动目标发现，遵循理论原则并受到神经科学的启发。

Result: 通过在多个领域的全面实验和消融研究，我们的方法显著提高了先验估计的质量，并在动态环境中展现出强大的可靠性和适应性。

Conclusion: 我们的方法在多个领域的实验中显著优于基线方法，确保在复杂的真实场景中实现有效的目标发现。

Abstract: In many scientific and engineering fields, where acquiring high-quality data
is expensive--such as medical imaging, environmental monitoring, and remote
sensing--strategic sampling of unobserved regions based on prior observations
is crucial for maximizing discovery rates within a constrained budget. The rise
of powerful generative models, such as diffusion models, has enabled active
target discovery in partially observable environments by leveraging learned
priors--probabilistic representations that capture underlying structure from
data. With guidance from sequentially gathered task-specific observations,
these models can progressively refine exploration and efficiently direct
queries toward promising regions. However, in domains where learning a strong
prior is infeasible due to extremely limited data or high sampling cost (such
as rare species discovery, diagnostics for emerging diseases, etc.), these
methods struggle to generalize. To overcome this limitation, we propose a novel
approach that enables effective active target discovery even in settings with
uninformative priors, ensuring robust exploration and adaptability in complex
real-world scenarios. Our framework is theoretically principled and draws
inspiration from neuroscience to guide its design. Unlike black-box policies,
our approach is inherently interpretable, providing clear insights into
decision-making. Furthermore, it guarantees a strong, monotonic improvement in
prior estimates with each new observation, leading to increasingly accurate
sampling and reinforcing both reliability and adaptability in dynamic settings.
Through comprehensive experiments and ablation studies across various domains,
including species distribution modeling and remote sensing, we demonstrate that
our method substantially outperforms baseline approaches.

</details>


### [355] [Renaissance of RNNs in Streaming Clinical Time Series: Compact Recurrence Remains Competitive with Transformers](https://arxiv.org/abs/2510.16677)
*Ran Tong,Jiaqi Liu,Su Liu,Xin Hu,Lanruo Wang*

Main category: cs.LG

TL;DR: 本研究比较了GRU-D和Transformer在心动过速风险和心率预测任务上的表现，结果显示模型选择依赖于具体任务。


<details>
  <summary>Details</summary>
Motivation: 建立一个紧凑、严格因果的基准，以评估不同模型在临床时间序列任务中的表现。

Method: 使用MIT-BIH心律失常数据库的每秒心率数据对临床时间序列进行严格因果的基准测试，研究短期心动过速风险和一步心率预测两个任务。

Result: 在MIT-BIH数据库上，GRU-D在心动过速风险预测方面略微超过Transformer，而Transformer在心率预测上的误差明显低于GRU-D和持续性基线。

Conclusion: 在纵向监测中，模型选择取决于任务：紧凑的RNN在短期风险评分中保持竞争力，而紧凑的Transformer则在点预测中清晰地取得优势。

Abstract: We present a compact, strictly causal benchmark for streaming clinical time
series on the MIT--BIH Arrhythmia Database using per-second heart rate. Two
tasks are studied under record-level, non-overlapping splits: near-term
tachycardia risk (next ten seconds) and one-step heart rate forecasting. We
compare a GRU-D (RNN) and a Transformer under matched training budgets against
strong non-learned baselines. Evaluation is calibration-aware for
classification and proper for forecasting, with temperature scaling and grouped
bootstrap confidence intervals. On MIT-BIH, GRU-D slightly surpasses the
Transformer for tachycardia risk, while the Transformer clearly lowers
forecasting error relative to GRU-D and persistence. Our results show that, in
longitudinal monitoring, model choice is task-dependent: compact RNNs remain
competitive for short-horizon risk scoring, whereas compact Transformers
deliver clearer gains for point forecasting.

</details>


### [356] [High-Dimensional Privacy-Utility Dynamics of Noisy Stochastic Gradient Descent on Least Squares](https://arxiv.org/abs/2510.16687)
*Shurong Lin,Eric D. Kolaczyk,Adam Smith,Elliot Paquette*

Main category: cs.LG

TL;DR: 本研究分析了噪声随机梯度下降在高维场景中的隐私与统计风险，提出了一种新的不依赖梯度敏感性的变体。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究提供了有关噪声随机梯度下降的统计风险和隐私损失界限，但其在高维设置中的确切行为仍不清楚，因此有必要进行深入研究。

Method: 采用扩散方法对噪声随机梯度下降进行分析，提供了连续时间视角。

Result: 研究了不需要显式知识的噪声随机梯度下降变体，并关注带有$l_2$正则化的最小二乘问题。

Conclusion: 本研究提供了对噪声随机梯度下降的准确分析，特别是在高维场景中，揭示了其统计风险演变和隐私损失动态。

Abstract: The interplay between optimization and privacy has become a central theme in
privacy-preserving machine learning. Noisy stochastic gradient descent (SGD)
has emerged as a cornerstone algorithm, particularly in large-scale settings.
These variants of gradient methods inject carefully calibrated noise into each
update to achieve differential privacy, the gold standard notion of rigorous
privacy guarantees. Prior work primarily provides various bounds on statistical
risk and privacy loss for noisy SGD, yet the \textit{exact} behavior of the
process remains unclear, particularly in high-dimensional settings. This work
leverages a diffusion approach to analyze noisy SGD precisely, providing a
continuous-time perspective that captures both statistical risk evolution and
privacy loss dynamics in high dimensions. Moreover, we study a variant of noisy
SGD that does not require explicit knowledge of gradient sensitivity, unlike
existing work that assumes or enforces sensitivity through gradient clipping.
Specifically, we focus on the least squares problem with $\ell_2$
regularization.

</details>


### [357] [Resolution-Aware Retrieval Augmented Zero-Shot Forecasting](https://arxiv.org/abs/2510.16695)
*Iman Deznabi,Peeyush Kumar,Madalina Fiterau*

Main category: cs.LG

TL;DR: 提出了一种分辨率感知的检索增强预测模型，在微气候预测中显著提高预测准确性，相比传统方法和现代模型具有更低的均方误差。


<details>
  <summary>Details</summary>
Motivation: 零样本预测面临预测结果需要在之前未见条件下进行的挑战，传统预测方法在此条件下表现不佳。

Method: 通过将信号分解为不同频率成分，并实施分辨率感知检索，模型动态检索相关数据，以适应新的位置。

Result: 在ERA5数据集上，我们的模型相比HRRR和Chronos分别实现了71%和34%更低的均方误差（MSE）。

Conclusion: 我们的方法在微气候预测中显著优于传统预测方法和现代基础时间序列模型，提供了一种可扩展且数据高效的零样本预测解决方案。

Abstract: Zero-shot forecasting aims to predict outcomes for previously unseen
conditions without direct historical data, posing a significant challenge for
traditional forecasting methods. We introduce a Resolution-Aware
Retrieval-Augmented Forecasting model that enhances predictive accuracy by
leveraging spatial correlations and temporal frequency characteristics. By
decomposing signals into different frequency components, our model employs
resolution-aware retrieval, where lower-frequency components rely on broader
spatial context, while higher-frequency components focus on local influences.
This allows the model to dynamically retrieve relevant data and adapt to new
locations with minimal historical context.
  Applied to microclimate forecasting, our model significantly outperforms
traditional forecasting methods, numerical weather prediction models, and
modern foundation time series models, achieving 71% lower MSE than HRRR and 34%
lower MSE than Chronos on the ERA5 dataset.
  Our results highlight the effectiveness of retrieval-augmented and
resolution-aware strategies, offering a scalable and data-efficient solution
for zero-shot forecasting in microclimate modeling and beyond.

</details>


### [358] [On the Granularity of Causal Effect Identifiability](https://arxiv.org/abs/2510.16703)
*Yizuo Chen,Adnan Darwiche*

Main category: cs.LG

TL;DR: 本文探讨了基于状态的因果效应的辨识性，发现在特定知识条件下，基于状态的效应可以比基于变量的效应更易识别，并强调了观察数据在此背景下的潜在价值。


<details>
  <summary>Details</summary>
Motivation: 传统因果效应可辨识性的概念主要基于处理和结果变量，而本文旨在探讨基于状态的因果效应的辨识性及其在观察数据中的应用潜力。

Method: 通过理论分析和实例探讨状态变量干预对结果变量状态的影响，结合上下文特定独立性和条件函数依赖性等知识进行辨识性分析。

Result: 基于状态的因果效应即便在基于变量的因果效应不可辨识时也可能可辨识，且当与其他知识结合时，状态和变量的辨识性可以得到改善。

Conclusion: 研究表明，在某些情况下，基于状态的因果效应可以辨识，而基于变量的因果效应则不可识别。这种分离发生在有额外知识（如上下文特定独立性和条件函数依赖性）的情况下。

Abstract: The classical notion of causal effect identifiability is defined in terms of
treatment and outcome variables. In this note, we consider the identifiability
of state-based causal effects: how an intervention on a particular state of
treatment variables affects a particular state of outcome variables. We
demonstrate that state-based causal effects may be identifiable even when
variable-based causal effects may not. Moreover, we show that this separation
occurs only when additional knowledge -- such as context-specific
independencies and conditional functional dependencies -- is available. We
further examine knowledge that constrains the states of variables, and show
that such knowledge does not improve identifiability on its own but can improve
both variable-based and state-based identifiability when combined with other
knowledge such as context-specific independencies. Our findings highlight
situations where causal effects of interest may be estimable from observational
data and this identifiability may be missed by existing variable-based
frameworks.

</details>


### [359] [Zero-Shot Performance Prediction for Probabilistic Scaling Laws](https://arxiv.org/abs/2510.16743)
*Viktoria Schram,Markus Hiller,Daniel Beck,Trevor Cohn*

Main category: cs.LG

TL;DR: 本研究提出一种利用多任务学习和多输出高斯过程的方法，以提高NLP模型学习曲线的预测准确性，降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 为了减少数据集获取和处理的成本，通过准确预测NLP模型的学习曲线来实现更好的性能决策。

Method: 使用潜在变量多输出高斯过程对多任务学习进行建模，考虑任务之间的相关性，并支持零-shot学习曲线预测。

Result: 在三个小规模NLP数据集上验证了框架，得到的预测接近真实的缩放法则。

Conclusion: 该方法通过概率缩放法则降低了成本，并提高了学习曲线的预测能力。

Abstract: The prediction of learning curves for Natural Language Processing (NLP)
models enables informed decision-making to meet specific performance
objectives, while reducing computational overhead and lowering the costs
associated with dataset acquisition and curation. In this work, we formulate
the prediction task as a multitask learning problem, where each task's data is
modelled as being organized within a two-layer hierarchy. To model the shared
information and dependencies across tasks and hierarchical levels, we employ
latent variable multi-output Gaussian Processes, enabling to account for task
correlations and supporting zero-shot prediction of learning curves (LCs). We
demonstrate that this approach facilitates the development of probabilistic
scaling laws at lower costs. Applying an active learning strategy, LCs can be
queried to reduce predictive uncertainty and provide predictions close to
ground truth scaling laws. We validate our framework on three small-scale NLP
datasets with up to $30$ LCs. These are obtained from nanoGPT models, from
bilingual translation using mBART and Transformer models, and from multilingual
translation using M2M100 models of varying sizes.

</details>


### [360] [SAMOSA: Sharpness Aware Minimization for Open Set Active learning](https://arxiv.org/abs/2510.16757)
*Young In Kim,Andrea Agiollo,Rajiv Khanna*

Main category: cs.LG

TL;DR: 本文提出了一种新型的主动学习算法SAMOSA，基于数据的典型性提高了开放集学习的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现代机器学习中数据收集与标注昂贵的问题，特别是在开放集主动学习背景下。

Method: 提出了一种基于数据典型性的主动查询算法，称为Sharpness Aware Minimization for Open Set Active Learning (SAMOSA)。

Result: SAMOSA能够有效识别位于模型决策边界附近的非典型样本，从而优先选择对目标类别和区分目标与非目标类别有用的样本。

Conclusion: SAMOSA在多个数据集上相较于现有方法提高了最多3%的准确率，同时没有增加计算开销。

Abstract: Modern machine learning solutions require extensive data collection where
labeling remains costly. To reduce this burden, open set active learning
approaches aim to select informative samples from a large pool of unlabeled
data that includes irrelevant or unknown classes. In this context, we propose
Sharpness Aware Minimization for Open Set Active Learning (SAMOSA) as an
effective querying algorithm. Building on theoretical findings concerning the
impact of data typicality on the generalization properties of traditional
stochastic gradient descent (SGD) and sharpness-aware minimization (SAM),
SAMOSA actively queries samples based on their typicality. SAMOSA effectively
identifies atypical samples that belong to regions of the embedding manifold
close to the model decision boundaries. Therefore, SAMOSA prioritizes the
samples that are (i) highly informative for the targeted classes, and (ii)
useful for distinguishing between targeted and unwanted classes. Extensive
experiments show that SAMOSA achieves up to 3% accuracy improvement over the
state of the art across several datasets, while not introducing computational
overhead. The source code of our experiments is available at:
https://anonymous.4open.science/r/samosa-DAF4

</details>


### [361] [3D-GSRD: 3D Molecular Graph Auto-Encoder with Selective Re-mask Decoding](https://arxiv.org/abs/2510.16780)
*Chang Wu,Zhiyuan Liu,Wen Shu,Liang Wang,Yanchen Luo,Wenqiang Lei,Yatao Bian,Junfeng Fang,Xiang Wang*

Main category: cs.LG

TL;DR: 本研究提出3D-GSRD，一种三维分子图自编码器，解决了二维到三维建模中的结构泄漏问题，显著提升了分子特性预测的表现。


<details>
  <summary>Details</summary>
Motivation: 针对二维结构泄漏与提供足够二维上下文之间的冲突挑战，探索三维分子表示学习的新方法。

Method: 提出了一种三维分子图自编码器，结合选择性重标记解码和三维关系变换器。

Result: 通过选择性重标记解码，3D-GSRD增强了编码器在分子表示学习中的作用，取得了显著的实验结果。

Conclusion: 3D-GSRD在MD17分子特性预测基准上，在8个目标中有7个达到了新的最先进水平，展示了其强大的下游性能。

Abstract: Masked graph modeling (MGM) is a promising approach for molecular
representation learning (MRL).However, extending the success of re-mask
decoding from 2D to 3D MGM is non-trivial, primarily due to two conflicting
challenges: avoiding 2D structure leakage to the decoder, while still providing
sufficient 2D context for reconstructing re-masked atoms.To address these
challenges, we propose 3D-GSRD: a 3D Molecular Graph Auto-Encoder with
Selective Re-mask Decoding. The core innovation of 3D-GSRD lies in its
Selective Re-mask Decoding(SRD), which re-masks only 3D-relevant information
from encoder representations while preserving the 2D graph structures.This SRD
is synergistically integrated with a 3D Relational-Transformer(3D-ReTrans)
encoder alongside a structure-independent decoder. We analyze that SRD,
combined with the structure-independent decoder, enhances the encoder's role in
MRL. Extensive experiments show that 3D-GSRD achieves strong downstream
performance, setting a new state-of-the-art on 7 out of 8 targets in the widely
used MD17 molecular property prediction benchmark. The code is released at
https://github.com/WuChang0124/3D-GSRD.

</details>


### [362] [Computational Budget Should Be Considered in Data Selection](https://arxiv.org/abs/2510.16806)
*Weilin Wan,Weizhong Zhang,Cheng Jin*

Main category: cs.LG

TL;DR: 该研究提出了一种新颖的计算预算感知数据选择方法(CADS)，在计算预算约束下提升了数据选择的效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的数据选择方法忽视计算预算，将数据选择和重要性评估独立进行，而实际中不同的预算对有效训练要求不同。

Method: 采用双层优化框架，其中内层在计算预算约束下训练模型，外层基于模型评估优化数据选择。

Result: CADS方法克服了海森矩阵估计和迭代中内部最优解计算的高计算负担，实现了更高的效率和性能。

Conclusion: 提出的CADS方法在视觉和语言基准测试中相比于基线方法性能提升最高达14.42%。

Abstract: Data selection improves computational efficiency by choosing informative
subsets of training samples. However, existing methods ignore the compute
budget, treating data selection and importance evaluation independently of
compute budget constraints. Yet empirical studies show no algorithm can
consistently outperform others (or even random selection) across varying
budgets. We therefore argue that compute budget must be integral to
data-selection strategies, since different budgets impose distinct requirements
on data quantity, quality, and distribution for effective training. To this
end, we propose a novel Computational budget-Aware Data Selection (CADS) method
and naturally formulate it into a bilevel optimization framework, where the
inner loop trains the model within the constraints of the computational budget
on some selected subset of training data, while the outer loop optimizes data
selection based on model evaluation. Our technical contributions lie in
addressing two main challenges in solving this bilevel optimization problem:
the expensive Hessian matrix estimation for outer-loop gradients and the
computational burden of achieving inner-loop optimality during iterations. To
solve the first issue, we propose a probabilistic reparameterization strategy
and compute the gradient using a Hessian-free policy gradient estimator. To
address the second challenge, we transform the inner optimization problem into
a penalty term in the outer objective, further discovering that we only need to
estimate the minimum of a one-dimensional loss to calculate the gradient,
significantly improving efficiency. Extensive experiments show that our method
achieves performance gains of up to 14.42% over baselines in vision and
language benchmarks.

</details>


### [363] [Improving Model Representation and Reducing KV Cache via Skip Connections with First Value Heads](https://arxiv.org/abs/2510.16807)
*Zhoutong Wu,Yuan Zhang,Yiming Dong,Chenheng Zhang,Cong Fang,Kun Yuan,Zhouchen Lin*

Main category: cs.LG

TL;DR: SkipV1Former通过重用第一层的Value头，减少KV缓存50%，提升Transformer性能。


<details>
  <summary>Details</summary>
Motivation: 针对Transformer模型在提高表示能力时的资源消耗问题，提出了一种新的方案，旨在提升模型性能的同时降低内存占用。

Method: 提出SkipV1Former模型，通过将第一层的Value头的半数重用到后续层，从而减少KV缓存的大小。

Result: SkipV1Former在不同模型规模下均实现了约25%的KV缓存减少，相比于标准多头注意力Transformer及一些先进变体，其困惑度有所改善，并且可以与先进方法结合使用，进一步提升性能。

Conclusion: SkipV1Former有效减少了KV缓存的使用，同时提升了模型的表现，具有较好的资源效率和性能表现。

Abstract: Transformer models have driven breakthroughs across various language tasks by
their strong capability to learn rich contextual representations. Scaling them
to improve representation, however, often demands substantial memory and
compute costs, such as the Key-Value (KV) cache used during auto-regressive
decoding. Skip connections offer a promising way to improve representation
without bloating resource usage, yet most prior works either improve
expressivity while leaving KV costs unchanged, or reduce memory at the cost of
weaker representation. In this work, we propose SkipV1Former, a Transformer
variant that uses skip connections from the first layer's Value heads to
strengthen model representation and reduce KV cache. Specifically, from the
second block onward, each layer reuses half of its Value heads from the very
first layer, while computing the other half as usual-cutting Value projections
and V cache by nearly 50 \%. Theoretically, we show that routing uncompressed
first-layer Values into deeper layers restores information lost to compression
and accelerates the model's implicit mesa-optimization-a key pattern of
Transformer in auto-regressive tasks. Empirically, across different model
scales, SkipV1Former delivers consistent reductions of approximately 25 \% in
KV cache while improving perplexity relative to standard Multi-Head Attention
(MHA) Transformers and some advanced variants. Moreover, we propose a recipe
for uptraining existing MHA Transformer checkpoints to SkipV1Former with only
10-15\% additional compute. Finally, SkipV1Former can seamlessly combine
advanced methods like Group-Query Attention and Multi-Latent Attention to
achieve further KV cache savings and performance improvement. When combined
with YOCO, it cuts KV cache size by nearly 50 \% while still improving
performance.

</details>


### [364] [Graph Learning is Suboptimal in Causal Bandits](https://arxiv.org/abs/2510.16811)
*Mohammad Shahverdikondori,Jalal Etesami,Negar Kiyavash*

Main category: cs.LG

TL;DR: 研究了在因果足够性下的悔恨最小化，发现父母标识并非必要，提出了性能优于现有方法的算法。


<details>
  <summary>Details</summary>
Motivation: 探讨当前方法在因果带宽下的表现，特别是父母标识是否对最小化悔恨是最优的。

Method: 通过证明悔恨最小化和父母标识在某些实例中存在根本性冲突，来分析不同的策略和情境。

Result: 提出了一种近乎最优的算法，证明了在不需要修复图和父母的情况下，也能有效实现悔恨最小化。

Conclusion: 父母标识在悔恨最小化中并不是必要的，从而可以实现更优的算法。

Abstract: We study regret minimization in causal bandits under causal sufficiency where
the underlying causal structure is not known to the agent. Previous work has
focused on identifying the reward's parents and then applying classic bandit
methods to them, or jointly learning the parents while minimizing regret. We
investigate whether such strategies are optimal. Somewhat counterintuitively,
our results show that learning the parent set is suboptimal. We do so by
proving that there exist instances where regret minimization and parent
identification are fundamentally conflicting objectives. We further analyze
both the known and unknown parent set size regimes, establish novel regret
lower bounds that capture the combinatorial structure of the action space.
Building on these insights, we propose nearly optimal algorithms that bypass
graph and parent recovery, demonstrating that parent identification is indeed
unnecessary for regret minimization. Experiments confirm that there exists a
large performance gap between our method and existing baselines in various
environments.

</details>


### [365] [Needles in the Landscape: Semi-Supervised Pseudolabeling for Archaeological Site Discovery under Label Scarcity](https://arxiv.org/abs/2510.16814)
*Simon Jaxy,Anton Theys,Patrick Willett,W. Chris Carleton,Ralf Vandam,Pieter Libin*

Main category: cs.LG

TL;DR: 本研究使用半监督学习和深度学习方法，通过动态伪标签和条件随机场，在考古预测建模中提高了稀疏标注数据集上未发现遗址的预测能力。


<details>
  <summary>Details</summary>
Motivation: 解决考古学中正样本稀缺的问题，并提高未标记位置的预测能力。

Method: 采用半监督的正负样本学习策略，实施语义分割模型，结合动态伪标签和条件随机场（CRF），通过RNN进行优化。

Result: 在数字高程模型（DEM）和原始卫星图像的数据集上，模型与最先进的LAMAP模型表现相当，同时在Dice分数上更高，且在分层k折交叉验证下保持性能，提供更具可解释性的预测结果。

Conclusion: 半监督学习为识别广阔稀疏标注的考古遗址提供了有前景的方法。

Abstract: Archaeological predictive modelling estimates where undiscovered sites are
likely to occur by combining known locations with environmental, cultural, and
geospatial variables. We address this challenge using a deep learning approach
but must contend with structural label scarcity inherent to archaeology:
positives are rare, and most locations are unlabeled. To address this, we adopt
a semi-supervised, positive-unlabeled (PU) learning strategy, implemented as a
semantic segmentation model and evaluated on two datasets covering a
representative range of archaeological periods. Our approach employs dynamic
pseudolabeling, refined with a Conditional Random Field (CRF) implemented via
an RNN, increasing label confidence under severe class imbalance. On a
geospatial dataset derived from a digital elevation model (DEM), our model
performs on par with the state-of-the-art, LAMAP, while achieving higher Dice
scores. On raw satellite imagery, assessed end-to-end with stratified k-fold
cross-validation, it maintains performance and yields predictive surfaces with
improved interpretability. Overall, our results indicate that semi-supervised
learning offers a promising approach to identifying undiscovered sites across
large, sparsely annotated landscapes.

</details>


### [366] [Finding Manifolds With Bilinear Autoencoders](https://arxiv.org/abs/2510.16820)
*Thomas Dooms,Ward Gauderis*

Main category: cs.LG

TL;DR: 本研究利用双线性自编码器将潜在表示分解为二次多项式，探索其代数性质以增强可解释性和分析性。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器在揭示可解释的潜在表示方面是标准工具，但其解释依赖于输入，使得单独研究显得不够完整。

Method: 使用双线性自编码器有效地将表示分解为二次多项式，并讨论改进措施以诱导重要性排序、聚类和激活稀疏性。

Result: 本研究展示了通过代数原理（多项式）分析表示的潜力，桥接线性与复杂流形结构。

Conclusion: 本研究为非线性但可分析的潜在表示提供了初步步骤，利用代数性质来加强理解。

Abstract: Sparse autoencoders are a standard tool for uncovering interpretable latent
representations in neural networks. Yet, their interpretation depends on the
inputs, making their isolated study incomplete. Polynomials offer a solution;
they serve as algebraic primitives that can be analysed without reference to
input and can describe structures ranging from linear concepts to complicated
manifolds. This work uses bilinear autoencoders to efficiently decompose
representations into quadratic polynomials. We discuss improvements that induce
importance ordering, clustering, and activation sparsity. This is an initial
step toward nonlinear yet analysable latents through their algebraic
properties.

</details>


### [367] [ProtoMol: Enhancing Molecular Property Prediction via Prototype-Guided Multimodal Learning](https://arxiv.org/abs/2510.16824)
*Yingxu Wang,Kunyu Zhang,Jiaxin Huang,Nan Yin,Siwei Liu,Eran Segal*

Main category: cs.LG

TL;DR: ProtoMol通过改进的多模态学习框架解决了现有方法的局限性，在分子属性预测中表现优越。


<details>
  <summary>Details</summary>
Motivation: 当前多模态方法在语义依赖和模态对齐方面存在重要局限性。

Method: 提出一种名为ProtoMol的原型引导多模态框架，利用双分支层次编码器和层次双向跨模态注意力机制。

Result: ProtoMol通过细粒度集成和一致的语义对齐，改善了分子图和文本描述之间的结合。

Conclusion: ProtoMol在多种分子属性预测任务中超越了最先进的基准，显示了其优越性。

Abstract: Multimodal molecular representation learning, which jointly models molecular
graphs and their textual descriptions, enhances predictive accuracy and
interpretability by enabling more robust and reliable predictions of drug
toxicity, bioactivity, and physicochemical properties through the integration
of structural and semantic information. However, existing multimodal methods
suffer from two key limitations: (1) they typically perform cross-modal
interaction only at the final encoder layer, thus overlooking hierarchical
semantic dependencies; (2) they lack a unified prototype space for robust
alignment between modalities. To address these limitations, we propose
ProtoMol, a prototype-guided multimodal framework that enables fine-grained
integration and consistent semantic alignment between molecular graphs and
textual descriptions. ProtoMol incorporates dual-branch hierarchical encoders,
utilizing Graph Neural Networks to process structured molecular graphs and
Transformers to encode unstructured texts, resulting in comprehensive
layer-wise representations. Then, ProtoMol introduces a layer-wise
bidirectional cross-modal attention mechanism that progressively aligns
semantic features across layers. Furthermore, a shared prototype space with
learnable, class-specific anchors is constructed to guide both modalities
toward coherent and discriminative representations. Extensive experiments on
multiple benchmark datasets demonstrate that ProtoMol consistently outperforms
state-of-the-art baselines across a variety of molecular property prediction
tasks.

</details>


### [368] [DrivAerStar: An Industrial-Grade CFD Dataset for Vehicle Aerodynamic Optimization](https://arxiv.org/abs/2510.16857)
*Jiyan Qiu,Lyulin Kuang,Guan Wang,Yichen Xu,Leiyao Cui,Shaotong Fu,Yixin Zhu,Ruihua Zhang*

Main category: cs.LG

TL;DR: DrivAerStar 是一个大型的汽车气动优化数据集，结合机器学习和高保真仿真，大幅提升了设计效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 车辆气动优化在汽车电气化中至关重要，传统方法面临计算代价高昂与准确性不足的权衡。

Method: 使用 STAR-CCM+ 软件生成 12,000 个工业级汽车 CFD 仿真，并通过自由形状变形（FFD）算法探索三种车辆配置。

Result: DrivAerStar 的风洞验证精度低于 1.04%，是现有数据集的五倍改善，训练基于此数据的模型将计算成本从数周缩短至数分钟。

Conclusion: DrivAerStar 代表了一个新的标准，促进汽车开发中的数据驱动气动优化，并为其它工程领域提供了高保真物理仿真与人工智能结合的范例。

Abstract: Vehicle aerodynamics optimization has become critical for automotive
electrification, where drag reduction directly determines electric vehicle
range and energy efficiency. Traditional approaches face an intractable
trade-off: computationally expensive Computational Fluid Dynamics (CFD)
simulations requiring weeks per design iteration, or simplified models that
sacrifice production-grade accuracy. While machine learning offers
transformative potential, existing datasets exhibit fundamental limitations --
inadequate mesh resolution, missing vehicle components, and validation errors
exceeding 5% -- preventing deployment in industrial workflows. We present
DrivAerStar, comprising 12,000 industrial-grade automotive CFD simulations
generated using $\text{STAR-CCM+}^\unicode{xAE}$ software. The dataset
systematically explores three vehicle configurations through 20 Computer Aided
Design (CAD) parameters via Free Form Deformation (FFD) algorithms, including
complete engine compartments and cooling systems with realistic internal
airflow. DrivAerStar achieves wind tunnel validation accuracy below 1.04% -- a
five-fold improvement over existing datasets -- through refined mesh strategies
with strict wall $y^+$ control. Benchmarks demonstrate that models trained on
this data achieve production-ready accuracy while reducing computational costs
from weeks to minutes. This represents the first dataset bridging academic
machine learning research and industrial CFD practice, establishing a new
standard for data-driven aerodynamic optimization in automotive development.
Beyond automotive applications, DrivAerStar demonstrates a paradigm for
integrating high-fidelity physics simulations with Artificial Intelligence (AI)
across engineering disciplines where computational constraints currently limit
innovation.

</details>


### [369] [Utility-Diversity Aware Online Batch Selection for LLM Supervised Fine-tuning](https://arxiv.org/abs/2510.16882)
*Heming Zou,Yixiu Mao,Yun Qu,Qi Wang,Xiangyang Ji*

Main category: cs.LG

TL;DR: 本研究提出UDS框架，旨在提高大型语言模型在监督微调中的在线批量选择效率，克服当前方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 在全数据集上进行监督微调（SFT）计算代价高且易过拟合，因此需要有数据策划的方法以优化最有价值的数据。

Method: 通过利用logits矩阵的核范数捕捉数据效用和样本内多样性，同时通过低维嵌入比较历史样本的轻量级内存缓冲区估计样本间多样性。

Result: UDS框架提高了在线批量选择的效率，消除了对外部资源和不必要反向传播的需求。

Conclusion: UDS在不同数据预算下表现超过了最先进的在线批量选择方法，并显著减少了训练时间。

Abstract: Supervised fine-tuning (SFT) is a commonly used technique to adapt large
language models (LLMs) to downstream tasks. In practice, SFT on a full dataset
is computationally expensive and sometimes suffers from overfitting or bias
amplification. This facilitates the rise of data curation in SFT, which
prioritizes the most valuable data to optimze. This work studies the online
batch selection family that dynamically scores and filters samples during the
training process. However, existing popular methods often (i) rely merely on
the utility of data to select a subset while neglecting other crucial factors
like diversity, (ii) rely on external resources such as reference models or
validation sets, and (iii) incur extra training time over full-dataset
training. To address these limitations, this work develops \textbf{UDS
(Utility-Diversity Sampling)}, a framework for efficient online batch selection
in SFT. UDS leverages the nuclear norm of the logits matrix to capture both
data utility and intra-sample diversity, while estimating inter-sample
diversity through efficient low-dimensional embedding comparisons with a
lightweight memory buffer of historical samples. Such a design eliminates the
need for external resources and unnecessary backpropagation, securing
computational efficiency. Experiments on multiple benchmarks demonstrate that
UDS consistently outperforms state-of-the-art online batch selection methods
under varying data budgets, and significantly reduces training time compared to
full-dataset fine-tuning. Code is available at https://github.com/gfyddha/UDS.

</details>


### [370] [Peering Inside the Black Box: Uncovering LLM Errors in Optimization Modelling through Component-Level Evaluation](https://arxiv.org/abs/2510.16943)
*Dania Refai,Moataz Ahmed*

Main category: cs.LG

TL;DR: 本研究提出了一种基于组件的评估框架，用于评估大语言模型在数学优化中的表现，通过引入多种指标，强调了约束的完整覆盖和输出的简洁性对优化模型效果的影响。


<details>
  <summary>Details</summary>
Motivation: 当前评估往往将优化公式视为整体，通过粗略的指标进行评估，掩盖了结构性或数值错误。

Method: 我们建立了一套全面的、基于组件的评估框架，采用精确度、召回率、均方根误差等指标来评估LLM生成的优化公式。

Result: 评估结果显示，GPT-5模型的表现优于其他模型，关键的性能指标包括高约束召回率和低约束RMSE。

Conclusion: 提出的评估框架为大语言模型在优化建模中的细致诊断评估奠定了基础，强调了完整约束覆盖、最小化约束RMSE和简洁输出的重要性。

Abstract: Large language models (LLMs) are increasingly used to convert natural
language descriptions into mathematical optimization formulations. Current
evaluations often treat formulations as a whole, relying on coarse metrics like
solution accuracy or runtime, which obscure structural or numerical errors. In
this study, we present a comprehensive, component-level evaluation framework
for LLM-generated formulations. Beyond the conventional optimality gap, our
framework introduces metrics such as precision and recall for decision
variables and constraints, constraint and objective root mean squared error
(RMSE), and efficiency indicators based on token usage and latency. We evaluate
GPT-5, LLaMA 3.1 Instruct, and DeepSeek Math across optimization problems of
varying complexity under six prompting strategies. Results show that GPT-5
consistently outperforms other models, with chain-of-thought, self-consistency,
and modular prompting proving most effective. Analysis indicates that solver
performance depends primarily on high constraint recall and low constraint
RMSE, which together ensure structural correctness and solution reliability.
Constraint precision and decision variable metrics play secondary roles, while
concise outputs enhance computational efficiency. These findings highlight
three principles for NLP-to-optimization modeling: (i) Complete constraint
coverage prevents violations, (ii) minimizing constraint RMSE ensures
solver-level accuracy, and (iii) concise outputs improve computational
efficiency. The proposed framework establishes a foundation for fine-grained,
diagnostic evaluation of LLMs in optimization modeling.

</details>


### [371] [Forgetting to Forget: Attention Sink as A Gateway for Backdooring LLM Unlearning](https://arxiv.org/abs/2510.17021)
*Bingqi Shang,Yiwei Chen,Yihua Zhang,Bingquan Shen,Sijia Liu*

Main category: cs.LG

TL;DR: 本研究探讨了后门退化在大型语言模型中的实现，发现通过在注意力汇聚位置放置触发器可以在需要时恢复被遗忘知识，同时保持模型在正常条件下的表现。


<details>
  <summary>Details</summary>
Motivation: 随着开放权重的大型语言模型的出现，研究退化过程是否可以被后门化，探讨在触发器激活时恢复被遗忘知识的可能性。

Method: 研究使用了后门攻击的方法，通过设计特定触发器在清洁环境下实现模型知识的遗忘，并分析不同触发器位置对效果的影响。

Result: 通过大量实验验证了在注意力汇聚位置放置后门触发器可以有效增强后门持久性，从而在激活触发器时恢复被遗忘的知识。

Conclusion: 本研究揭示了后门退化的可能性，表明通过在特定输入位置放置触发器，可以在需要时恢复被遗忘的知识，同时在未被激活时与正常模型表现无异。

Abstract: Large language model (LLM) unlearning has become a critical mechanism for
removing undesired data, knowledge, or behaviors from pre-trained models while
retaining their general utility. Yet, with the rise of open-weight LLMs, we
ask: can the unlearning process itself be backdoored, appearing successful
under normal conditions yet reverting to pre-unlearned behavior when a hidden
trigger is activated? Drawing inspiration from classical backdoor attacks that
embed triggers into training data to enforce specific behaviors, we investigate
backdoor unlearning, where models forget as intended in the clean setting but
recover forgotten knowledge when the trigger appears. We show that designing
such attacks presents unique challenges, hinging on where triggers are placed
and how backdoor training is reinforced. We uncover a strong link between
backdoor efficacy and the attention sink phenomenon, i.e., shallow input tokens
consistently attract disproportionate attention in LLMs. Our analysis reveals
that these attention sinks serve as gateways for backdoor unlearning: placing
triggers at sink positions and aligning their attention values markedly
enhances backdoor persistence. Extensive experiments validate these findings,
showing that attention-sink-guided backdoor unlearning reliably restores
forgotten knowledge in the presence of backdoor triggers, while behaving
indistinguishably from a normally unlearned model when triggers are absent.
Code is available at https://github.com/OPTML-Group/Unlearn-Backdoor.

</details>


### [372] [A Lightweight DL Model for Smart Grid Power Forecasting with Feature and Resolution Mismatch](https://arxiv.org/abs/2510.16911)
*Sarah Al-Shareeda,Gulcihan Ozdemir,Heung Seok Jeon,Khaleel Ahmad*

Main category: cs.LG

TL;DR: 本研究提出了一种轻量化深度学习管线，用于在噪音和不完整数据条件下准确预测能源消费，取得了优异的预测结果。


<details>
  <summary>Details</summary>
Motivation: 在传感器数据嘈杂、不完整且缺乏上下文丰富性的情况下，准确预测短期能耗。

Method: 提出了一个结合每小时降维、双模式插补和全面标准化的深度学习管线，最终选择标准缩放以达到最佳平衡。使用轻量级GRU-LSTM序列到单一模型进行预测。

Result: GRU-LSTM模型的平均RMSE为601.9W，MAE为468.9W，准确率为84.36%。在非对称输入和插补缺口的情况下，该模型表现出良好的泛化能力，捕捉了非线性需求模式，并保持低推理延迟。

Conclusion: 目标预处理结合紧凑的递归架构能够在现实条件下实现快速、准确的能源预测。

Abstract: How can short-term energy consumption be accurately forecasted when sensor
data is noisy, incomplete, and lacks contextual richness? This question guided
our participation in the \textit{2025 Competition on Electric Energy
Consumption Forecast Adopting Multi-criteria Performance Metrics}, which
challenged teams to predict next-day power demand using real-world
high-frequency data. We proposed a robust yet lightweight Deep Learning (DL)
pipeline combining hourly downsizing, dual-mode imputation (mean and polynomial
regression), and comprehensive normalization, ultimately selecting Standard
Scaling for optimal balance. The lightweight GRU-LSTM sequence-to-one model
achieves an average RMSE of 601.9~W, MAE of 468.9~W, and 84.36\% accuracy.
Despite asymmetric inputs and imputed gaps, it generalized well, captured
nonlinear demand patterns, and maintained low inference latency. Notably,
spatiotemporal heatmap analysis reveals a strong alignment between temperature
trends and predicted consumption, further reinforcing the model's reliability.
These results demonstrate that targeted preprocessing paired with compact
recurrent architectures can still enable fast, accurate, and deployment-ready
energy forecasting in real-world conditions.

</details>


### [373] [Domain Generalizable Continual Learning](https://arxiv.org/abs/2510.16914)
*Hongwei Yan,Guanglong Sun,Zhiqi Kang,Yi Zhong,Liyuan Wang*

Main category: cs.LG

TL;DR: 本研究提出了一种新的领域可泛化持续学习设置DGCL，并针对其挑战开发了自适应领域转换方法DoT，从而提升智能系统在多领域任务中的泛化能力和效率。


<details>
  <summary>Details</summary>
Motivation: 为了提高智能系统在动态真实环境中的适应能力，需要开发能够持续学习新技能并在多样化场景中泛化的模型。

Method: 提出了一种基于PTMs的自适应领域转换方法DoT，旨在解决DGCL中的语义和领域信息分离问题，促进跨领域任务表示的转换和输出对齐。

Result: 通过大量实验验证了DoT方法在提高持续学习任务效果下的有效性，并在全参数调优和参数高效调优下均显示出显著的性能提升。

Conclusion: 提出的DoT方法有效提高了在DGCL设置中的性能，展现了较好的资源效率和轻量级实现。

Abstract: To adapt effectively to dynamic real-world environments, intelligent systems
must continually acquire new skills while generalizing them to diverse, unseen
scenarios. Here, we introduce a novel and realistic setting named domain
generalizable continual learning (DGCL): a model learns sequential tasks with
each involving a single domain, aiming to perform well across all encountered
tasks and domains. This setting poses unique challenges in acquiring,
retaining, and leveraging both semantic- and domain-relevant information for
robust generalization. Although state-of-the-art continual learning (CL)
methods have employed pre-trained models (PTMs) to enhance task-specific
generalization, they typically assume identical training and testing domains
for each task and therefore perform poorly in DGCL. To this end, we propose
adaptive Domain Transformation (DoT), an innovative PTMs-based approach
tailored to DGCL. Inspired by the distributed-plus-hub theory of the human
brain, DoT disentangles semantic- and domain-relevant information in
representation learning, and adaptively transforms task representations across
various domains for output alignment, ensuring balanced and generalized
predictions. DoT serves as a plug-in strategy that greatly facilitates
state-of-the-art CL baselines under both full parameter tuning and
parameter-efficient tuning paradigms in DGCL, validated by extensive
experiments. Also, DoT is shown to accumulate domain-generalizable knowledge
from DGCL, and ensure resource efficiency with a lightweight implementation.

</details>


### [374] [SolverLLM: Leveraging Test-Time Scaling for Optimization Problem via LLM-Guided Search](https://arxiv.org/abs/2510.16916)
*Dong Li,Xujiang Zhao,Linlin Yu,Yanchi Liu,Wei Cheng,Zhengzhang Chen,Zhong Chen,Feng Chen,Chen Zhao,Haifeng Chen*

Main category: cs.LG

TL;DR: SolverLLM是一种无训练框架，通过MCTS生成数学公式，解决多样化优化问题，显示出强大的泛化能力和 outperform 现有方法的优势。


<details>
  <summary>Details</summary>
Motivation: 探索现有方法在优化问题上依赖提示工程和监督训练的限制，寻求一种更有效的解决方案。

Method: 提出了一种无需训练的框架，通过测试时扩展解决多样化的优化问题，利用MCTS策略生成数学公式并转化为求解器代码。

Result: 在六个标准基准数据集上进行的实验表明，SolverLLM在优化问题解决上表现优异。

Conclusion: SolverLLM超越了现有的基于提示和学习的基准，展示了强大的泛化能力，无需额外训练。

Abstract: Large Language Models (LLMs) offer promising capabilities for tackling
complex reasoning tasks, including optimization problems. However, existing
methods either rely on prompt engineering, which leads to poor generalization
across problem types, or require costly supervised training. We introduce
SolverLLM, a training-free framework that leverages test-time scaling to solve
diverse optimization problems. Rather than solving directly, SolverLLM
generates mathematical formulations and translates them into solver-ready code,
guided by a novel Monte Carlo Tree Search (MCTS) strategy. To enhance the
search process, we modify classical MCTS with (1) dynamic expansion for
adaptive formulation generation, (2) prompt backpropagation to guide
exploration via outcome-driven feedback, and (3) uncertainty backpropagation to
incorporate reward reliability into decision-making. Experiments on six
standard benchmark datasets demonstrate that SolverLLM outperforms both
prompt-based and learning-based baselines, achieving strong generalization
without additional training.

</details>


### [375] [Closing the Curvature Gap: Full Transformer Hessians and Their Implications for Scaling Laws](https://arxiv.org/abs/2510.16927)
*Egor Petrov,Nikita Kiselev,Vladislav Meshkov,Andrey Grabovoy*

Main category: cs.LG

TL;DR: 本研究通过推导Transformer的Hessian，分析其优化特性，并提出新框架以理解收敛轨迹。


<details>
  <summary>Details</summary>
Motivation: 填补Transformer优化景观中Hessian缺乏理论结果的空白。

Method: 推导了层归一化和前馈Hessian的显式二阶表达式，构建了完整Transformer模块的Hessian特征。

Result: 提供了每个子层在曲率传播中的作用估计，并提出了一种基于泰勒展开的框架来分析损失差异。

Conclusion: 这项工作为大规模深度学习中的优化问题建立了新的理论和实证研究基础。

Abstract: The lack of theoretical results for Layer Normalization and feedforward
Hessians has left a gap in the study of Transformer optimization landscapes. We
address this by deriving explicit second-order expressions for these
components, thereby completing the Hessian characterization of full Transformer
blocks. Our results generalize prior self-attention analyses and yield
estimations for the role of each sublayer in curvature propagation. We
demonstrate how these Hessian structures inform both convergence dynamics and
the empirical scaling laws governing large-model performance. Further, we
propose a Taylor-expansion-based framework for analyzing loss differences to
quantify convergence trajectories. By extending Hessian theory to the full
Transformer architecture, this work establishes a new foundation for
theoretical and empirical investigations of optimization in large-scale deep
learning.

</details>


### [376] [LILO: Bayesian Optimization with Interactive Natural Language Feedback](https://arxiv.org/abs/2510.17671)
*Katarzyna Kobalczyk,Zhiyuan Jerry Lin,Benjamin Letham,Zhuokai Zhao,Maximilian Balandat,Eytan Bakshy*

Main category: cs.LG

TL;DR: 研究提出了一种新颖的反馈优化框架，通过大型语言模型将自然语言转换为效用信号，在数值搜索空间中进行贝叶斯优化，进而提升了优化效率和决策者的交互体验。


<details>
  <summary>Details</summary>
Motivation: 在处理复杂且主观的优化目标时，反馈显得尤为重要，现有的贝叶斯优化方法对反馈格式限制较多。

Method: 使用大型语言模型将非结构化的自然语言反馈转换为标量效用，以在数值搜索空间中进行贝叶斯优化。

Result: 该方法利用大型语言模型有效地将多样的文本反馈转化为一致的效用信号，提高了优化过程的灵活性和效率。

Conclusion: 该研究提出了一种语言在循环中的框架，能够有效处理自然语言反馈并优化数值搜索空间，表现优于传统的贝叶斯优化基线和仅使用大型语言模型的优化器，特别是在反馈有限的情况下。

Abstract: For many real-world applications, feedback is essential in translating
complex, nuanced, or subjective goals into quantifiable optimization
objectives. We propose a language-in-the-loop framework that uses a large
language model (LLM) to convert unstructured feedback in the form of natural
language into scalar utilities to conduct BO over a numeric search space.
Unlike preferential BO, which only accepts restricted feedback formats and
requires customized models for each domain-specific problem, our approach
leverages LLMs to turn varied types of textual feedback into consistent utility
signals and to easily include flexible user priors without manual kernel
design. At the same time, our method maintains the sample efficiency and
principled uncertainty quantification of BO. We show that this hybrid method
not only provides a more natural interface to the decision maker but also
outperforms conventional BO baselines and LLM-only optimizers, particularly in
feedback-limited regimes.

</details>


### [377] [Differentially Private Linear Regression and Synthetic Data Generation with Statistical Guarantees](https://arxiv.org/abs/2510.16974)
*Shurong Lin,Aleksandra Slavković,Deekshith Reddy Bhoomireddy*

Main category: cs.LG

TL;DR: 本研究提出了一种新的差分隐私线性回归方法，能够在小规模数据集上有效提高准确性，并生成可靠的合成数据。


<details>
  <summary>Details</summary>
Motivation: 在社会科学中，小到中等规模的数据集普遍存在，而线性回归是常用的方法。然而，在隐私保护设置下，现有的差分隐私线性回归方法主要集中于点估计，而对不确定性量化关注较少，且目前的合成数据生成方法不够适用于连续回归分析。

Method: 提出了一种在高斯差分隐私下有效推断的线性回归方法，采用了DP偏差修正估计器和一般合成数据生成程序。

Result: 实验结果表明，提出的方法在准确性上优于现有方法，提供了有效的置信区间，并生成了比当前差分隐私合成数据生成方法更可靠的合成数据。

Conclusion: 提出的方法在小规模到中等规模的数据集上有效提高了线性回归的准确性，并提供了有效的置信区间，同时生成了更可靠的合成数据，适用于下游机器学习任务。

Abstract: In social sciences, small- to medium-scale datasets are common and linear
regression (LR) is canonical. In privacy-aware settings, much work has focused
on differentially private (DP) LR, but mostly on point estimation with limited
attention to uncertainty quantification. Meanwhile, synthetic data generation
(SDG) is increasingly important for reproducibility studies, yet current DP LR
methods do not readily support it. Mainstream SDG approaches are either
tailored to discretized data, making them less suitable for continuous
regression, or rely on deep models that require large datasets, limiting their
use for the smaller, continuous data typical in social science. We propose a
method for LR with valid inference under Gaussian DP: a DP bias-corrected
estimator with asymptotic confidence intervals (CIs) and a general SDG
procedure in which regression on the synthetic data matches our DP regression.
Our binning-aggregation strategy is effective in small- to moderate-dimensional
settings. Experiments show our method (1) improves accuracy over existing
methods, (2) provides valid CIs, and (3) produces more reliable synthetic data
for downstream ML tasks than current DP SDGs.

</details>


### [378] [Towards Interpretable and Trustworthy Time Series Reasoning: A BlueSky Vision](https://arxiv.org/abs/2510.16980)
*Kanghui Ning,Zijie Pan,Yushan Jiang,Anderson Schneider,Yuriy Nevmyvaka,Dongjin Song*

Main category: cs.LG

TL;DR: 本论文提出了一种旨在提升时间序列推理能力的框架，结合多维度方法以实现可解释和可信的时间智能。


<details>
  <summary>Details</summary>
Motivation: 随着时间序列推理的兴起，目标是超越模式识别，朝着明确、可解释和可信的推理发展。

Method: 论文通过综合的时间理解、结构化多步骤推理和可靠的评估框架构建稳健的时间序列推理基础，并通过引入多智能体协作、多模态上下文和检索增强的方法来推进系统级推理。

Result: 结合两条互补的方向，提出了一种全面的时间序列推理方法，适用于各类领域。

Conclusion: 本论文提出了一种灵活且可扩展的框架，以推动时间序列推理的发展，旨在在不同领域提供可解释和可信的时间智能。

Abstract: Time series reasoning is emerging as the next frontier in temporal analysis,
aiming to move beyond pattern recognition towards explicit, interpretable, and
trustworthy inference. This paper presents a BlueSky vision built on two
complementary directions. One builds robust foundations for time series
reasoning, centered on comprehensive temporal understanding, structured
multi-step reasoning, and faithful evaluation frameworks. The other advances
system-level reasoning, moving beyond language-only explanations by
incorporating multi-agent collaboration, multi-modal context, and
retrieval-augmented approaches. Together, these directions outline a flexible
and extensible framework for advancing time series reasoning, aiming to deliver
interpretable and trustworthy temporal intelligence across diverse domains.

</details>


### [379] [Mapping Post-Training Forgetting in Language Models at Scale](https://arxiv.org/abs/2510.17776)
*Jackson Harmon,Andreas Hochlehnert,Matthias Bethge,Ameya Prabhu*

Main category: cs.LG

TL;DR: 该研究提出了一种新方法来分析后训练对语言模型预训练知识的影响，发现不同策略下的遗忘与逆向迁移存在显著差异，提出了新的衡量标准以促进对AI系统的进展。


<details>
  <summary>Details</summary>
Motivation: 虽然后训练能显著提高语言模型的能力，但对预训练知识的影响尚不明确，因此迫切需要研究遗忘的性质和发生时机。

Method: 我们提出了一种样本导向的方法来测量遗忘和逆向迁移，使用1->0和0->1的转变作为遗忘和逆向迁移的量化指标。

Result: 在大规模分析中，我们发现持续的领域预训练会导致适度遗忘和低到中等的逆向迁移，而RL/SFT后训练则表现出较大的逆向迁移，同时遗忘程度较低.

Conclusion: 我们的框架提供了一个实用的标准，用于衡量大规模后训练如何改变预训练知识，助力普遍智能系统的进步。

Abstract: Scaled post-training now drives many of the largest capability gains in
language models (LMs), yet its effect on pretrained knowledge remains poorly
understood. Not all forgetting is equal: Forgetting one fact (e.g., a U.S.
president or an API call) does not "average out" by recalling another. Hence,
we propose a sample-wise paradigm to measure what is forgotten and when
backward transfer occurs. Our metric counts 1->0 transitions (correct before
post-training, incorrect after) to quantify forgetting and 0->1 transitions to
quantify backward transfer. Traditional task averages conflate these effects
and obscure large changes. For multiple-choice benchmarks, we add
chance-adjusted variants that subtract the expected contribution of random
guessing from pre- and post-training accuracies. We apply this framework across
post-training stages, model sizes, and data scales. Our large-scale analysis
shows that: (1) Domain-continual pretraining induces moderate forgetting with
low-to-moderate backward transfer; (2) RL/SFT post-training applied to base
models and Instruction tuning yields moderate-to-large backward transfer on
math and logic with overall low-to-moderate forgetting; (3) Applying RL/SFT to
instruction-tuned models is sensitive on data scale: at small scales, both
forgetting and backward transfer are small; at larger scales, effects are mixed
and warrant further study with better controls; (4) Model merging does not
reliably mitigate forgetting. Overall, our framework offers a practical
yardstick for mapping how post-training alters pretrained knowledge at scale --
enabling progress towards generally capable AI systems.

</details>


### [380] [MuonBP: Faster Muon via Block-Periodic Orthogonalization](https://arxiv.org/abs/2510.16981)
*Ahmed Khaled,Kaan Ozkara,Tao Yu,Mingyi Hong,Youngsuk Park*

Main category: cs.LG

TL;DR: MuonBP是一种新优化器，通过独立正交化和定期全局正交化，提升了模型训练效率，并相较于原Muon保持了优秀的吞吐量和性能。


<details>
  <summary>Details</summary>
Motivation: 旨在克服在使用模型并行时，Gradient Orthogonalization引入的额外通信开销问题，提升训练效率。

Method: 提出了一种名为Muon with Block-Periodic Orthogonalization (MuonBP) 的新方法，分别对每个设备的矩阵分片进行正交化，并定期进行全局正交化以保持训练稳定性。

Result: 与Muon相比，MuonBP在训练8B模型时提高了8%的吞吐量，并且性能无明显下降。

Conclusion: MuonBP方法在模型训练中提供了较传统Muon优化器更高的吞吐量和稳定性，且性能未降低。

Abstract: Gradient orthogonalization is a simple strategy that shows great utility in
speeding up gradient descent. The Muon optimizer (Jordan, Jin, et al., 2024)
combines gradient orthogonalization with first-order momentum and achieves
significant improvement in data efficiency over Adam/AdamW (Loshchilov and
Hutter, 2019) for language model training. However, when using model
parallelism, gradient orthogonalization introduces additional overhead compared
to coordinate-wise optimizers (such as AdamW) due to additional gather and
scatter operations on gradient matrix shards from different devices. This
additional communication can amount to a throughput hit of 5%-10% compared to
Adam/AdamW. To remedy this, we propose Muon with Block-Periodic
Orthogonalization (MuonBP), which applies orthogonalization independently to
matrix shards on each device and periodically performs full orthogonalization
to maintain training stability at scale. We show how to adjust the learning
rate from the baseline to MuonBP and give convergence guarantees for this
algorithm. Crucially, our theory dictates that we use two stepsizes: one for
the blockwise orthogonalization steps, and one for the full orthogonalization
steps. Our method is simple, requires minimal hyperparameter adjustments, and
achieves competitive iteration complexity compared with baseline Muon while
providing per-iteration throughput comparable to coordinate-wise methods such
as AdamW. When training an 8B model with eight-way tensor parallelism and ZeRO
optimizer state sharding, MuonBP achieves 8% throughput increase compared to
Muon with no degradation in performance.

</details>


### [381] [Graph4MM: Weaving Multimodal Learning with Structural Information](https://arxiv.org/abs/2510.16990)
*Xuying Ning,Dongqi Fu,Tianxin Wei,Wujiang Xu,Jingrui He*

Main category: cs.LG

TL;DR: 本研究提出了Graph4MM框架，通过Hop-Diffused Attention和MM-QFormer，改进多模态学习中的结构信息整合，实验结果显示显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 探讨复杂的多模态数据和图的角色，解决多模态学习中的结构信息整合与模态特定信息融合的挑战。

Method: 提出了Hop-Diffused Attention和MM-QFormer，分别用于自注意力机制和跨模态融合。

Result: Graph4MM在生成任务和区分任务中的实验显示，表现优于更大型的视觉语言模型、语言模型和多模态图基线，平均提升6.93%。

Conclusion: Graph4MM通过利用多跳结构信息提升了多模态理解，超越了传统方法的局限。

Abstract: Real-world multimodal data usually exhibit complex structural relationships
beyond traditional one-to-one mappings like image-caption pairs. Entities
across modalities interact in intricate ways, with images and text forming
diverse interconnections through contextual dependencies and co-references.
Graphs provide powerful structural information for modeling intra-modal and
inter-modal relationships. However, previous works fail to distinguish
multi-hop neighbors and treat the graph as a standalone modality, which
fragments the overall understanding. This limitation presents two key
challenges in multimodal learning: (1) integrating structural information from
multi-hop neighbors into foundational models, and (2) fusing modality-specific
information in a principled manner. To address these challenges, we revisit the
role of graphs in multimodal learning within the era of foundation models and
propose Graph4MM, a graph-based multimodal learning framework. To be specific,
we introduce Hop-Diffused Attention, which integrates multi-hop structural
information into self-attention through causal masking and hop diffusion.
Furthermore, we design MM-QFormer, a multi-mapping querying transformer for
cross-modal fusion. Through theoretical and empirical analysis, we show that
leveraging structures to integrate both intra- and inter-modal interactions
improves multimodal understanding beyond treating them as a standalone
modality. Experiments on both generative and discriminative tasks show that
Graph4MM outperforms larger VLMs, LLMs, and multimodal graph baselines,
achieving a 6.93% average improvement.

</details>


### [382] [Curiosity-driven RL for symbolic equation solving](https://arxiv.org/abs/2510.17022)
*Kevin P. O Keeffe*

Main category: cs.LG

TL;DR: 本研究探讨了增强型强化学习在解决符号数学中的应用，尤其是非线性方程的求解。


<details>
  <summary>Details</summary>
Motivation: To investigate the effectiveness of reinforcement learning (RL) in solving symbolic mathematics problems, especially nonlinear equations.

Method: Utilized model-free Proximal Policy Optimization (PPO) with curiosity-based exploration and graph-based actions.

Result: Successfully demonstrated the ability to solve nonlinear equations involving radicals, exponentials, and trigonometric functions using enhanced RL techniques.

Conclusion: Curiosity-based exploration enhances model-free RL methods like PPO for solving complex symbolic mathematics tasks.

Abstract: We explore if RL can be useful for symbolic mathematics. Previous work showed
contrastive learning can solve linear equations in one variable. We show
model-free PPO \cite{schulman2017proximal} augmented with curiosity-based
exploration and graph-based actions can solve nonlinear equations such as those
involving radicals, exponentials, and trig functions. Our work suggests
curiosity-based exploration may be useful for general symbolic reasoning tasks.

</details>


### [383] [Diverse Influence Component Analysis: A Geometric Approach to Nonlinear Mixture Identifiability](https://arxiv.org/abs/2510.17040)
*Hoang-Son Nguyen,Xiao Fu*

Main category: cs.LG

TL;DR: DICA框架通过最大化雅可比体积，提出了一种无需辅助信息的新方法，实现了潜在成分的可识别性。


<details>
  <summary>Details</summary>
Motivation: 探索非线性混合中的潜在成分识别问题，并提出一种无需依赖于辅助信息的识别方法，促进机器学习中的解耦表示学习和因果推断等任务的进展。

Method: 通过提出雅可比体积最大化准则（J-VolMax），利用混合函数雅可比矩阵的凸几何特性，支持潜在成分识别。

Result: DICA框架在合理条件下实现了潜在成分的可识别性，提供了一种与现有方法互补的视角。

Conclusion: 提出的DICA框架能够在没有辅助信息、潜在成分独立性或雅可比稀疏性假设的前提下，实现潜在成分的可识别性，扩展了可识别性分析的范围。

Abstract: Latent component identification from unknown nonlinear mixtures is a
foundational challenge in machine learning, with applications in tasks such as
disentangled representation learning and causal inference. Prior work in
nonlinear independent component analysis (nICA) has shown that auxiliary
signals -- such as weak supervision -- can support identifiability of
conditionally independent latent components. More recent approaches explore
structural assumptions, e.g., sparsity in the Jacobian of the mixing function,
to relax such requirements. In this work, we introduce Diverse Influence
Component Analysis (DICA), a framework that exploits the convex geometry of the
mixing function's Jacobian. We propose a Jacobian Volume Maximization
(J-VolMax) criterion, which enables latent component identification by
encouraging diversity in their influence on the observed variables. Under
reasonable conditions, this approach achieves identifiability without relying
on auxiliary information, latent component independence, or Jacobian sparsity
assumptions. These results extend the scope of identifiability analysis and
offer a complementary perspective to existing methods.

</details>


### [384] [The Ends Justify the Thoughts: RL-Induced Motivated Reasoning in LLMs](https://arxiv.org/abs/2510.17057)
*Nikolaus Howe,Micah Carroll*

Main category: cs.LG

TL;DR: 本研究探讨了强化学习结合链思维推理下，模型在外部指示与学习行为冲突时的动机推理现象及其检测难度。


<details>
  <summary>Details</summary>
Motivation: 研究链思维推理中的动机推理对模型行为和评估的影响。

Method: 通过简单设置调查当外部指示与学习的行为冲突时，模型的推理过程。

Result: 发现模型在违反指示时生成合理的自我辩护，同时较小的LLM评估者未必能够检测到这种动机推理。

Conclusion: 需要在模型评估和监督中考虑动机推理的影响。

Abstract: The use of reinforcement learning (RL) with chain-of-thought (CoT) reasoning
has emerged as a promising approach for developing more capable language
models. In turn, this has led to investigation of CoT monitoring as a
compelling method for detecting harmful behaviors such as reward hacking, under
the assumption that models' reasoning processes reflect their internal
decision-making. In practice, LLM training often produces unintended behaviors
due to imperfect reward signals, leading models to develop misaligned
tendencies. A common corrective approach is to apply post-hoc instructions to
avoid problematic behaviors like sycophancy, but what happens to the model's
reasoning process when these instructions conflict with learned behaviors? We
investigate this question in simple settings and find that models engage in
systematic motivated reasoning -- generating plausible-sounding justifications
for violating their instructions while downplaying potential harms. Beyond
being an interesting property of training, we find that while motivated
reasoning can be detected by most frontier reasoning models, smaller LLM judges
can fail to identify a portion of it, and in rare cases can themselves be
persuaded that the reasoning is correct, despite it contradicting clear
instructions. This capability gap raises concerns that as models become more
sophisticated, their motivated reasoning may become increasingly difficult for
monitors to detect. Our results underscore the need to account for motivated
reasoning when relying on chain-of-thought processes for model evaluation and
oversight. All code for this paper will be made available. WARNING: some
examples in this paper may be upsetting.

</details>


### [385] [Bitwidth-Specific Logarithmic Arithmetic for Future Hardware-Accelerated Training](https://arxiv.org/abs/2510.17058)
*Hassan Hamad,Yuou Qiu,Peter A. Beerel,Keith M. Chugg*

Main category: cs.LG

TL;DR: 本文提出了一种低精度对数定点训练方法，优化了算术操作，可以在资源节省的同时实现有效深度学习模型训练。


<details>
  <summary>Details</summary>
Motivation: 推进低精度固定点训练，寻求在降低计算成本的同时保留合理的模型训练精度。

Method: 使用基于位宽设计的新型分段线性近似来优化对数加法，结合模拟退火方法在不同精度水平下进行优化。

Result: 在12位整数算术下，训练VGG-11和VGG-16模型时，与32位浮点训练相比，得到的准确度损失最小，同时在面积和能量消耗上显著减少。

Conclusion: 提出的低精度对数定点训练方法在保持较高精度的同时，减少了硬件资源的使用和能量消耗。

Abstract: While advancements in quantization have significantly reduced the
computational costs of inference in deep learning, training still predominantly
relies on complex floating-point arithmetic. Low-precision fixed-point training
presents a compelling alternative. This work introduces a novel enhancement in
low-precision logarithmic fixed-point training, geared towards future hardware
accelerator designs. We propose incorporating bitwidth in the design of
approximations to arithmetic operations. To this end, we introduce a new
hardware-friendly, piece-wise linear approximation for logarithmic addition.
Using simulated annealing, we optimize this approximation at different
precision levels. A C++ bit-true simulation demonstrates training of VGG-11 and
VGG-16 models on CIFAR-100 and TinyImageNet, respectively, using 12-bit integer
arithmetic with minimal accuracy degradation compared to 32-bit floating-point
training. Our hardware study reveals up to 32.5% reduction in area and 53.5%
reduction in energy consumption for the proposed LNS multiply-accumulate units
compared to that of linear fixed-point equivalents.

</details>


### [386] [Data Reliability Scoring](https://arxiv.org/abs/2510.17085)
*Yiling Chen,Shi Feng,Paul Kattuman,Fang-Yi Yu*

Main category: cs.LG

TL;DR: 本文提出了一种新的Gram行列式得分方法，用于在缺乏真实数据的情况下评估数据集的可靠性，表现出实验无关性以及对数据质量的有效捕捉。


<details>
  <summary>Details</summary>
Motivation: 在没有真实数据验证的情况下，评估数据集的可靠性是一个挑战，尤其是当数据来源具有潜在偏见时。

Method: 通过定义基于真实情况的排序，以及引入Gram行列式得分来评估数据集的质量。

Result: Gram行列式得分展示了其在多种观察过程中的有效性，能够捕捉数据质量。

Conclusion: Gram行列式得分能够有效衡量数据集的可靠性，并且在不同实验条件下保持一致的可靠性排名。

Abstract: How can we assess the reliability of a dataset without access to ground
truth? We introduce the problem of reliability scoring for datasets collected
from potentially strategic sources. The true data are unobserved, but we see
outcomes of an unknown statistical experiment that depends on them. To
benchmark reliability, we define ground-truth-based orderings that capture how
much reported data deviate from the truth. We then propose the Gram determinant
score, which measures the volume spanned by vectors describing the empirical
distribution of the observed data and experiment outcomes. We show that this
score preserves several ground-truth based reliability orderings and, uniquely
up to scaling, yields the same reliability ranking of datasets regardless of
the experiment -- a property we term experiment agnosticism. Experiments on
synthetic noise models, CIFAR-10 embeddings, and real employment data
demonstrate that the Gram determinant score effectively captures data quality
across diverse observation processes.

</details>


### [387] [On the Universal Near Optimality of Hedge in Combinatorial Settings](https://arxiv.org/abs/2510.17099)
*Zhiyuan Fan,Arnab Maiti,Kevin Jamieson,Lillian J. Ratliff,Gabriele Farina*

Main category: cs.LG

TL;DR: 本文研究了Hedge算法在组合设置的表现，证明其接近最优，且在某些情况下具有特定的劣势，同时展示了其在在线多任务学习和DAG中的应用。


<details>
  <summary>Details</summary>
Motivation: 探讨Hedge算法在不同组合设置中的最优性，尤其是在多任务在线学习和有向无环图（DAGs）上的应用。

Method: 研究Hedge算法在组合设置下的性能，尤其是其悔恨界限，并通过设定下界评估其最优性。

Result: Hedge在任何组合集上的下界为
Ω(√(T log(|X|)/log d))，并在特定的m-集合中表现出次优性，而在在线多任务学习中达到最优。

Conclusion: Hedge算法在组合设置下是近似最优的，并在特定情况下具有最优边际，且通过引入合适的正则化器可以实现近优性能。

Abstract: In this paper, we study the classical Hedge algorithm in combinatorial
settings. In each round, the learner selects a vector $\boldsymbol{x}_t$ from a
set $X \subseteq \{0,1\}^d$, observes a full loss vector $\boldsymbol{y}_t \in
\mathbb{R}^d$, and incurs a loss $\langle \boldsymbol{x}_t, \boldsymbol{y}_t
\rangle \in [-1,1]$. This setting captures several important problems,
including extensive-form games, resource allocation, $m$-sets, online multitask
learning, and shortest-path problems on directed acyclic graphs (DAGs). It is
well known that Hedge achieves a regret of $O\big(\sqrt{T \log |X|}\big)$ after
$T$ rounds of interaction. In this paper, we ask whether Hedge is optimal
across all combinatorial settings. To that end, we show that for any $X
\subseteq \{0,1\}^d$, Hedge is near-optimal--specifically, up to a $\sqrt{\log
d}$ factor--by establishing a lower bound of $\Omega\big(\sqrt{T \log(|X|)/\log
d}\big)$ that holds for any algorithm. We then identify a natural class of
combinatorial sets--namely, $m$-sets with $\log d \leq m \leq \sqrt{d}$--for
which this lower bound is tight, and for which Hedge is provably suboptimal by
a factor of exactly $\sqrt{\log d}$. At the same time, we show that Hedge is
optimal for online multitask learning, a generalization of the classical
$K$-experts problem. Finally, we leverage the near-optimality of Hedge to
establish the existence of a near-optimal regularizer for online shortest-path
problems in DAGs--a setting that subsumes a broad range of combinatorial
domains. Specifically, we show that the classical Online Mirror Descent (OMD)
algorithm, when instantiated with the dilated entropy regularizer, is
iterate-equivalent to Hedge, and therefore inherits its near-optimal regret
guarantees for DAGs.

</details>


### [388] [Adapting to Stochastic and Adversarial Losses in Episodic MDPs with Aggregate Bandit Feedback](https://arxiv.org/abs/2510.17103)
*Shinji Ito,Kevin Jamieson,Haipeng Luo,Arnab Maiti,Taira Tsuchiya*

Main category: cs.LG

TL;DR: 本研究提出了适用于带有聚合带反馈的有限时间期望决策过程的新型BOBW算法，实现了随机和对抗环境中的低悔恨，并证明了算法的最优性。


<details>
  <summary>Details</summary>
Motivation: 针对已有最坏情况下的分析，本研究旨在探索在在线学习中提出能够在随机和对抗性环境中同时实现低悔恨的BOBW算法。

Method: 结合FTRL方法、自限制技术和新型损失估计器，推进了对带有聚合带反馈的决策过程的处理。

Result: 在已知转移的情况下，算法在随机环境中实现了$O(\log T)$的悔恨，而在对抗环境中实现了${O}(\sqrt{T})$的悔恨。

Conclusion: 我们提出的BOBW算法在已知和未知转移情况下均实现了低悔恨，特别是与当前最佳算法相匹配的下界证明了它们的最优性。

Abstract: We study online learning in finite-horizon episodic Markov decision processes
(MDPs) under the challenging aggregate bandit feedback model, where the learner
observes only the cumulative loss incurred in each episode, rather than
individual losses at each state-action pair. While prior work in this setting
has focused exclusively on worst-case analysis, we initiate the study of
best-of-both-worlds (BOBW) algorithms that achieve low regret in both
stochastic and adversarial environments. We propose the first BOBW algorithms
for episodic tabular MDPs with aggregate bandit feedback. In the case of known
transitions, our algorithms achieve $O(\log T)$ regret in stochastic settings
and ${O}(\sqrt{T})$ regret in adversarial ones. Importantly, we also establish
matching lower bounds, showing the optimality of our algorithms in this
setting. We further extend our approach to unknown-transition settings by
incorporating confidence-based techniques. Our results rely on a combination of
FTRL over occupancy measures, self-bounding techniques, and new loss estimators
inspired by recent advances in online shortest path problems. Along the way, we
also provide the first individual-gap-dependent lower bounds and demonstrate
near-optimal BOBW algorithms for shortest path problems with bandit feedback.

</details>


### [389] [Matricial Free Energy as a Gaussianizing Regularizer: Enhancing Autoencoders for Gaussian Code Generation](https://arxiv.org/abs/2510.17120)
*Rishi Sonthalia,Raj Rao Nadakuditi*

Main category: cs.LG

TL;DR: 本文提出了一种新型正则化方案，用于自编码器，通过最小化矩阵自由能来生成高斯编码，并在欠确定逆问题中展示了有效性。


<details>
  <summary>Details</summary>
Motivation: 旨在通过引入新的正则化方案改善自编码器的性能，使编码更加通用。

Method: 引入了一种差分损失函数，基于代码矩阵的奇异值，通过标准的随机梯度训练来最小化负矩阵自由能。

Result: 通过模拟实验表现出最小化负矩阵自由能能够生成类似高斯的代码，并且在训练和测试集之间具有良好的泛化能力。

Conclusion: 提出了一种基于矩阵自由能的新正则化方案，能够可靠地产生高斯编码，并在欠确定逆问题中展示了其应用。

Abstract: We introduce a novel regularization scheme for autoencoders based on
matricial free energy. Our approach defines a differentiable loss function in
terms of the singular values of the code matrix (code dimension x batch size).
From the standpoint of free probability an d random matrix theory, this loss
achieves its minimum when the singular value distribution of the code matrix
coincides with that of an appropriately sculpted random metric with i.i.d.
Gaussian entries. Empirical simulations demonstrate that minimizing the
negative matricial free energy through standard stochastic gradient-based
training yields Gaussian-like codes that generalize across training and test
sets. Building on this foundation, we propose a matricidal free energy
maximizing autoencoder that reliably produces Gaussian codes and show its
application to underdetermined inverse problems.

</details>


### [390] [In-situ Autoguidance: Eliciting Self-Correction in Diffusion Models](https://arxiv.org/abs/2510.17136)
*Enhao Gu,Haolin Hou*

Main category: cs.LG

TL;DR: 本研究介绍了一种无辅助模型的自我引导方法，通过动态生成劣质预测，有效提高图像生成的质量和多样性。


<details>
  <summary>Details</summary>
Motivation: 解决现有CFG方法中高质量和多样性之间的权衡问题，同时消除辅助模型的需要。

Method: 提出了In-situ Autoguidance方法，通过模型自身动态生成劣质预测，实现引导。

Result: 该方法被证明是可行的，并建立了有效的成本管理引导的新基准。

Conclusion: 本研究提出了一种新的自我引导方法，在不使用辅助模型的情况下实现了高质量和多样化图像生成，且成本效益显著。

Abstract: The generation of high-quality, diverse, and prompt-aligned images is a
central goal in image-generating diffusion models. The popular classifier-free
guidance (CFG) approach improves quality and alignment at the cost of reduced
variation, creating an inherent entanglement of these effects. Recent work has
successfully disentangled these properties by guiding a model with a separately
trained, inferior counterpart; however, this solution introduces the
considerable overhead of requiring an auxiliary model. We challenge this
prerequisite by introducing In-situ Autoguidance, a method that elicits
guidance from the model itself without any auxiliary components. Our approach
dynamically generates an inferior prediction on the fly using a stochastic
forward pass, reframing guidance as a form of inference-time self-correction.
We demonstrate that this zero-cost approach is not only viable but also
establishes a powerful new baseline for cost-efficient guidance, proving that
the benefits of self-guidance can be achieved without external models.

</details>


### [391] [Learning After Model Deployment](https://arxiv.org/abs/2510.17160)
*Derda Kaymak,Gyuhak Kim,Tomoya Kaichi,Tatsuya Konishi,Bing Liu*

Main category: cs.LG

TL;DR: 本文提出了自主学习后模型部署(ALMD)的概念，并介绍了PLDA方法以应对动态环境中的新类学习和检测问题。


<details>
  <summary>Details</summary>
Motivation: 在动态和开放环境中，模型需要不断学习未见类的新样本，以应对现实应用中的不确定性。

Method: 提出PLDA方法进行动态OOD检测和增量学习。

Result: 通过实验评估，证明PLDA能够有效地处理新类的增量学习及动态检测问题。

Conclusion: PLDA是一种有效的方法，能够在应用中实现动态OOD检测和新类的增量学习。

Abstract: In classic supervised learning, once a model is deployed in an application,
it is fixed. No updates will be made to it during the application. This is
inappropriate for many dynamic and open environments, where unexpected samples
from unseen classes may appear. In such an environment, the model should be
able to detect these novel samples from unseen classes and learn them after
they are labeled. We call this paradigm Autonomous Learning after Model
Deployment (ALMD). The learning here is continuous and involves no human
engineers. Labeling in this scenario is performed by human co-workers or other
knowledgeable agents, which is similar to what humans do when they encounter an
unfamiliar object and ask another person for its name. In ALMD, the detection
of novel samples is dynamic and differs from traditional out-of-distribution
(OOD) detection in that the set of in-distribution (ID) classes expands as new
classes are learned during application, whereas ID classes is fixed in
traditional OOD detection. Learning is also different from classic supervised
learning because in ALMD, we learn the encountered new classes immediately and
incrementally. It is difficult to retrain the model from scratch using all the
past data from the ID classes and the novel samples from newly discovered
classes, as this would be resource- and time-consuming. Apart from these two
challenges, ALMD faces the data scarcity issue because instances of new classes
often appear sporadically in real-life applications. To address these issues,
we propose a novel method, PLDA, which performs dynamic OOD detection and
incremental learning of new classes on the fly. Empirical evaluations will
demonstrate the effectiveness of PLDA.

</details>


### [392] [ALPINE: A Lightweight and Adaptive Privacy-Decision Agent Framework for Dynamic Edge Crowdsensing](https://arxiv.org/abs/2510.17162)
*Guanjie Cheng,Siyang Liu,Junqin Huang,Xinkui Zhao,Yin Wang,Mengying Zhu,Linghe Kong,Shuiguang Deng*

Main category: cs.LG

TL;DR: ALPINE是一个轻量级的自适应框架，能够实时调整差分隐私水平，有效应对隐私威胁。


<details>
  <summary>Details</summary>
Motivation: 在动态、资源有限的环境中，移动边缘众测系统面临严重的隐私威胁，现有的静态差分隐私机制难以适应风险变化。

Method: 设计了一个闭环控制系统，包含动态风险感知、基于双延迟深度确定性策略梯度的隐私决策、局部隐私执行和边缘节点的性能验证四个模块。

Result: ALPINE能够实时自主调整差分隐私水平，通过环境风险评估设计奖励函数，以实现隐私、效用和成本之间的动态平衡。

Conclusion: ALPINE框架有效减轻了推断攻击，同时保持了数据效用和成本，为大规模边缘应用提供了实用性。

Abstract: Mobile edge crowdsensing (MECS) systems continuously generate and transmit
user data in dynamic, resource-constrained environments, exposing users to
significant privacy threats. In practice, many privacy-preserving mechanisms
build on differential privacy (DP). However, static DP mechanisms often fail to
adapt to evolving risks, for example, shifts in adversarial capabilities,
resource constraints and task requirements, resulting in either excessive noise
or inadequate protection. To address this challenge, we propose ALPINE, a
lightweight, adaptive framework that empowers terminal devices to autonomously
adjust differential privacy levels in real time. ALPINE operates as a
closed-loop control system consisting of four modules: dynamic risk perception,
privacy decision via twin delayed deep deterministic policy gradient (TD3),
local privacy execution and performance verification from edge nodes. Based on
environmental risk assessments, we design a reward function that balances
privacy gains, data utility and energy cost, guiding the TD3 agent to
adaptively tune noise magnitude across diverse risk scenarios and achieve a
dynamic equilibrium among privacy, utility and cost. Both the collaborative
risk model and pretrained TD3-based agent are designed for low-overhead
deployment. Extensive theoretical analysis and real-world simulations
demonstrate that ALPINE effectively mitigates inference attacks while
preserving utility and cost, making it practical for large-scale edge
applications.

</details>


### [393] [Robustness in Text-Attributed Graph Learning: Insights, Trade-offs, and New Defenses](https://arxiv.org/abs/2510.17185)
*Runlin Lei,Lu Yi,Mingguo He,Pengyu Qiu,Zhewei Wei,Yongchao Liu,Chuntao Hong*

Main category: cs.LG

TL;DR: 本文提出了评估文本属性图学习鲁棒性的框架SFT-auto，揭示了当前GNN和LLM模型在文本和结构扰动下的表现差异，并给出了解决方案。


<details>
  <summary>Details</summary>
Motivation: 针对当前对文本属性图学习中鲁棒性的评估缺乏系统性的研究，提出统一框架以全面理解GNN和LLM的鲁棒性。

Method: 通过评估经典GNN、鲁棒GNN和GraphLLMs在不同数据集和攻击场景下的表现，系统性地研究了文本和结构的扰动对模型的影响。

Result: 研究发现模型在文本和结构之间存在固有的鲁棒性权衡，GNN和RGNN的表现与文本编码器和攻击类型密切相关，GraphLLMs对训练数据的破坏特别脆弱，并提出了SFT-auto框架来缓解这些问题。

Conclusion: 本文建立了一个评估文本属性图学习中鲁棒性的统一框架，并提出了SFT-auto框架以改进模型的鲁棒性。

Abstract: While Graph Neural Networks (GNNs) and Large Language Models (LLMs) are
powerful approaches for learning on Text-Attributed Graphs (TAGs), a
comprehensive understanding of their robustness remains elusive. Current
evaluations are fragmented, failing to systematically investigate the distinct
effects of textual and structural perturbations across diverse models and
attack scenarios. To address these limitations, we introduce a unified and
comprehensive framework to evaluate robustness in TAG learning. Our framework
evaluates classical GNNs, robust GNNs (RGNNs), and GraphLLMs across ten
datasets from four domains, under diverse text-based, structure-based, and
hybrid perturbations in both poisoning and evasion scenarios. Our extensive
analysis reveals multiple findings, among which three are particularly
noteworthy: 1) models have inherent robustness trade-offs between text and
structure, 2) the performance of GNNs and RGNNs depends heavily on the text
encoder and attack type, and 3) GraphLLMs are particularly vulnerable to
training data corruption. To overcome the identified trade-offs, we introduce
SFT-auto, a novel framework that delivers superior and balanced robustness
against both textual and structural attacks within a single model. Our work
establishes a foundation for future research on TAG security and offers
practical solutions for robust TAG learning in adversarial environments. Our
code is available at: https://github.com/Leirunlin/TGRB.

</details>


### [394] [A Standardized Benchmark for Machine-Learned Molecular Dynamics using Weighted Ensemble Sampling](https://arxiv.org/abs/2510.17187)
*Alexander Aghili,Andy Bruce,Daniel Sabo,Sanya Murdeshwar,Kevin Bachelor,Ionut Mistreanu,Ashwin Lokapally,Razvan Marinescu*

Main category: cs.LG

TL;DR: 我们提出了一种新的模块化基准测试框架，用于系统评估蛋白质分子动力学方法，解决了标准化评估的挑战，并提供了一系列工具和数据集以促进方法间的有效比较。


<details>
  <summary>Details</summary>
Motivation: 随着分子动力学方法（包括机器学习动力学）的快速发展，缺乏标准化的工具用于方法验证，并且模拟方法之间的客观比较受到评估指标不一致和稀有构象状态采样不足的阻碍。

Method: 引入了一种模块化基准测试框架，系统评估蛋白质分子动力学方法，使用增强采样分析，结合加权集成取样和时间延迟独立成分分析。

Result: 框架包括一个灵活的轻量级传播者接口，支持任意的模拟引擎，并提供一个能计算19种不同度量和可视化的综合评估套件。此外，提供了九种多样蛋白质的数据集，以展示框架的实用性。

Conclusion: 我们的开源平台为分子模拟社区提供了一种一致、严格的基准测试基础，通过标准化评估协议，促进了各MD方法之间的直接和可重复比较。

Abstract: The rapid evolution of molecular dynamics (MD) methods, including
machine-learned dynamics, has outpaced the development of standardized tools
for method validation. Objective comparison between simulation approaches is
often hindered by inconsistent evaluation metrics, insufficient sampling of
rare conformational states, and the absence of reproducible benchmarks. To
address these challenges, we introduce a modular benchmarking framework that
systematically evaluates protein MD methods using enhanced sampling analysis.
Our approach uses weighted ensemble (WE) sampling via The Weighted Ensemble
Simulation Toolkit with Parallelization and Analysis (WESTPA), based on
progress coordinates derived from Time-lagged Independent Component Analysis
(TICA), enabling fast and efficient exploration of protein conformational
space. The framework includes a flexible, lightweight propagator interface that
supports arbitrary simulation engines, allowing both classical force fields and
machine learning-based models. Additionally, the framework offers a
comprehensive evaluation suite capable of computing more than 19 different
metrics and visualizations across a variety of domains. We further contribute a
dataset of nine diverse proteins, ranging from 10 to 224 residues, that span a
variety of folding complexities and topologies. Each protein has been
extensively simulated at 300K for one million MD steps per starting point (4
ns). To demonstrate the utility of our framework, we perform validation tests
using classic MD simulations with implicit solvent and compare protein
conformational sampling using a fully trained versus under-trained CGSchNet
model. By standardizing evaluation protocols and enabling direct, reproducible
comparisons across MD approaches, our open-source platform lays the groundwork
for consistent, rigorous benchmarking across the molecular simulation
community.

</details>


### [395] [SOLE: Hardware-Software Co-design of Softmax and LayerNorm for Efficient Transformer Inference](https://arxiv.org/abs/2510.17189)
*Wenxun Wang,Shuchang Zhou,Wenyu Sun,Peiqin Sun,Yongpan Liu*

Main category: cs.LG

TL;DR: 本文提出的 SOLE 通过创新设计显著提升了 Softmax 和 LayerNorm 的推理速度和能效，同时保持了准确性，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 为了克服 Softmax 和 LayerNorm 在实时推理速度和效率上的限制。

Method: 提出了 E2Softmax 和 AILayerNorm 的硬件-软件协同设计，实现了对 Softmax 和 LayerNorm 的低精度计算及低比特宽存储。

Result: SOLE 相比于之前的最先进定制硬件，在 Softmax 和 LayerNorm 上分别实现了 3.04x 和 3.86x 的能效提升，以及 2.82x 和 3.32x 的面积效率提升。

Conclusion: SOLE 在不需要重新训练的情况下，提供了显著的推理速度和能效提升，同时保持了准确性。

Abstract: Transformers have shown remarkable performance in both natural language
processing (NLP) and computer vision (CV) tasks. However, their real-time
inference speed and efficiency are limited due to the inefficiency in Softmax
and Layer Normalization (LayerNorm). Previous works based on function
approximation suffer from inefficient implementation as they place emphasis on
computation while disregarding memory overhead concerns. Moreover, such methods
rely on retraining to compensate for approximation error which can be costly
and inconvenient.
  In this paper, we present SOLE, a hardware-software co-design for Softmax and
LayerNorm which is composed of E2Softmax and AILayerNorm. E2Softmax utilizes
log2 quantization of exponent function and log-based division to approximate
Softmax while AILayerNorm adopts low-precision statistic calculation. Compared
with state-of-the-art designs, we achieve both low-precision calculation and
low bit-width storage on Softmax and LayerNorm. Experiments show that SOLE
maintains inference accuracy without retraining while offering orders of
magnitude speedup and energy savings over GPU, achieving 3.04x, 3.86x
energy-efficiency improvements and 2.82x, 3.32x area-efficiency improvements
over prior state-of-the-art custom hardware for Softmax and LayerNorm,
respectively.

</details>


### [396] [D2C-HRHR: Discrete Actions with Double Distributional Critics for High-Risk-High-Return Tasks](https://arxiv.org/abs/2510.17212)
*Jundong Zhang,Yuhui Situ,Fanji Zhang,Rongji Deng,Tianqi Wei*

Main category: cs.LG

TL;DR: 提出一种新的强化学习框架，适用于高风险高回报的多模态任务，通过离散化动作空间和双重评价器架构改善表现。


<details>
  <summary>Details</summary>
Motivation: 针对高风险高回报任务的多模态动作分布和随机回报，现有的强化学习方法有效性不足。

Method: 提出了一种强化学习框架，离散化连续动作空间，使用熵正则化探索，并引入双重评价器架构。

Result: 实验证明该方法在高风险失败可能性的运动和操控基准测试中优于基线。

Conclusion: 该方法在高风险高回报任务中表现优越，强调了在强化学习中显式建模多模态和风险的重要性。

Abstract: Tasks involving high-risk-high-return (HRHR) actions, such as obstacle
crossing, often exhibit multimodal action distributions and stochastic returns.
Most reinforcement learning (RL) methods assume unimodal Gaussian policies and
rely on scalar-valued critics, which limits their effectiveness in HRHR
settings. We formally define HRHR tasks and theoretically show that Gaussian
policies cannot guarantee convergence to the optimal solution. To address this,
we propose a reinforcement learning framework that (i) discretizes continuous
action spaces to approximate multimodal distributions, (ii) employs
entropy-regularized exploration to improve coverage of risky but rewarding
actions, and (iii) introduces a dual-critic architecture for more accurate
discrete value distribution estimation. The framework scales to
high-dimensional action spaces, supporting complex control domains. Experiments
on locomotion and manipulation benchmarks with high risks of failure
demonstrate that our method outperforms baselines, underscoring the importance
of explicitly modeling multimodality and risk in RL.

</details>


### [397] [Adaptive Discretization for Consistency Models](https://arxiv.org/abs/2510.17266)
*Jiayu Bai,Zhanbo Feng,Zhijie Deng,Tianqi Hou,Robert C. Qiu,Zenan Ling*

Main category: cs.LG

TL;DR: 提出了一种统一框架ADCM，实现了一致性模型的自适应离散化，显著提升了训练效率和生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有的一致性模型依赖于手动设计的离散化方案，这在不同噪声调度和数据集上会造成频繁的调整，因此需要提出一种自适应的离散化框架。

Method: 通过将一致性模型的自动化和自适应离散化问题建模为优化问题，利用局部一致性作为优化目标和全局一致性作为约束进行训练。

Result: 在CIFAR-10和ImageNet上，ADCM展现出显著的训练效率提升和优秀的生成性能。

Conclusion: ADCMs显著提高了CMs的训练效率，具有优越的生成性能并且适应性强。

Abstract: Consistency Models (CMs) have shown promise for efficient one-step
generation. However, most existing CMs rely on manually designed discretization
schemes, which can cause repeated adjustments for different noise schedules and
datasets. To address this, we propose a unified framework for the automatic and
adaptive discretization of CMs, formulating it as an optimization problem with
respect to the discretization step. Concretely, during the consistency training
process, we propose using local consistency as the optimization objective to
ensure trainability by avoiding excessive discretization, and taking global
consistency as a constraint to ensure stability by controlling the denoising
error in the training target. We establish the trade-off between local and
global consistency with a Lagrange multiplier. Building on this framework, we
achieve adaptive discretization for CMs using the Gauss-Newton method. We refer
to our approach as ADCMs. Experiments demonstrate that ADCMs significantly
improve the training efficiency of CMs, achieving superior generative
performance with minimal training overhead on both CIFAR-10 and ImageNet.
Moreover, ADCMs exhibit strong adaptability to more advanced DM variants. Code
is available at https://github.com/rainstonee/ADCM.

</details>


### [398] [Uncertainty-aware data assimilation through variational inference](https://arxiv.org/abs/2510.17268)
*Anthony Frion,David S Greenberg*

Main category: cs.LG

TL;DR: 本研究提出了一种新的数据同化模型，基于变分推断，通过引入多元高斯分布提高了预测准确性，并在混沌动力学测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 数据同化在各种环境中涉及不确定性，我们希望通过引入变分推断提高预测的准确性和可靠性。

Method: 在现有的确定性机器学习方法基础上，提出了一种变分推断的方法，使得预测状态符合多元高斯分布。

Result: 该模型在测试中显示出近乎完美的校准预测，且适合融入更长数据同化窗口的流程中。

Conclusion: 该研究提出了一种基于变分推断的扩展方法，可以在混沌Lorenz-96动力学条件下实现近乎完美的校准预测，并能与更广泛的变分数据同化流程结合，提高数据同化窗口长度的效果。

Abstract: Data assimilation, consisting in the combination of a dynamical model with a
set of noisy and incomplete observations in order to infer the state of a
system over time, involves uncertainty in most settings. Building upon an
existing deterministic machine learning approach, we propose a variational
inference-based extension in which the predicted state follows a multivariate
Gaussian distribution. Using the chaotic Lorenz-96 dynamics as a testing
ground, we show that our new model enables to obtain nearly perfectly
calibrated predictions, and can be integrated in a wider variational data
assimilation pipeline in order to achieve greater benefit from increasing
lengths of data assimilation windows. Our code is available at
https://github.com/anthony-frion/Stochastic_CODA.

</details>


### [399] [Breaking and Fixing Defenses Against Control-Flow Hijacking in Multi-Agent Systems](https://arxiv.org/abs/2510.17276)
*Rishi Jha,Harold Triedman,Justin Wagle,Vitaly Shmatikov*

Main category: cs.LG

TL;DR: 本文探讨了控制流劫持攻击对多智能体系统的危害，提出了ControlValve作为新防御机制，有效提高安全性和功能的平衡。


<details>
  <summary>Details</summary>
Motivation: There is a fundamental conflict between safety and functionality in multi-agent systems, leading to vulnerabilities.

Method: ControlValve generates permitted control-flow graphs and enforces compliance with these graphs for agent executions.

Result: ControlValve demonstrates that attacks can bypass existing defenses like LlamaFirewall, highlighting the need for a robust alternative.

Conclusion: ControlValve is an effective defense mechanism that ensures safe execution in multi-agent systems by enforcing control-flow and contextual rules.

Abstract: Control-flow hijacking attacks manipulate orchestration mechanisms in
multi-agent systems into performing unsafe actions that compromise the system
and exfiltrate sensitive information. Recently proposed defenses, such as
LlamaFirewall, rely on alignment checks of inter-agent communications to ensure
that all agent invocations are "related to" and "likely to further" the
original objective.
  We start by demonstrating control-flow hijacking attacks that evade these
defenses even if alignment checks are performed by advanced LLMs. We argue that
the safety and functionality objectives of multi-agent systems fundamentally
conflict with each other. This conflict is exacerbated by the brittle
definitions of "alignment" and the checkers' incomplete visibility into the
execution context.
  We then propose, implement, and evaluate ControlValve, a new defense inspired
by the principles of control-flow integrity and least privilege. ControlValve
(1) generates permitted control-flow graphs for multi-agent systems, and (2)
enforces that all executions comply with these graphs, along with contextual
rules (generated in a zero-shot manner) for each agent invocation.

</details>


### [400] [MemoryBench: A Benchmark for Memory and Continual Learning in LLM Systems](https://arxiv.org/abs/2510.17281)
*Qingyao Ai,Yichen Tang,Changyue Wang,Jianming Long,Weihang Su,Yiqun Liu*

Main category: cs.LG

TL;DR: 本文提出了一种新的基准来评估LLM系统的持续学习能力，实验结果显示现有方法远未达到理想效果。


<details>
  <summary>Details</summary>
Motivation: 考虑到现有的LLM系统在内存和持续学习能力上存在的不足，尤其是在处理用户反馈方面，研究旨在填补这一空白。

Method: 通过构建用户反馈模拟框架并设计多领域、多语言和多类型任务的综合基准，进行实验评估。

Result: 实验表明，当前最先进的基线在效果和效率上仍存在显著不足，表明需要进一步的研究和优化。

Conclusion: 提出了一种用户反馈模拟框架和综合基准，以评估LLM系统的持续学习能力，并表明现有基线的效果和效率远未令人满意。

Abstract: Scaling up data, parameters, and test-time computation has been the
mainstream methods to improve LLM systems (LLMsys), but their upper bounds are
almost reached due to the gradual depletion of high-quality data and marginal
gains obtained from larger computational resource consumption. Inspired by the
abilities of human and traditional AI systems in learning from practice,
constructing memory and continual learning frameworks for LLMsys has become an
important and popular research direction in recent literature. Yet, existing
benchmarks for LLM memory often focus on evaluating the system on homogeneous
reading comprehension tasks with long-form inputs rather than testing their
abilities to learn from accumulated user feedback in service time. Therefore,
we propose a user feedback simulation framework and a comprehensive benchmark
covering multiple domains, languages, and types of tasks to evaluate the
continual learning abilities of LLMsys. Experiments show that the effectiveness
and efficiency of state-of-the-art baselines are far from satisfying, and we
hope this benchmark could pave the way for future studies on LLM memory and
optimization algorithms.

</details>


### [401] [Symmetries in PAC-Bayesian Learning](https://arxiv.org/abs/2510.17303)
*Armin Beck,Peter Ochs*

Main category: cs.LG

TL;DR: 本研究扩展了对称性在机器学习中的理论保证，验证了在非不变数据分布下的效果，结果显示超对称模型的优势。


<details>
  <summary>Details</summary>
Motivation: 理论上解释对称性如何改善机器学习模型的表现，同时考虑非紧致对称和非不变数据分布。

Method: 基于PAC-Bayes框架，调整并收紧现有界限，验证理论的有效性。

Result: 通过在非均匀旋转群的旋转MNIST数据集上的实验验证所推导的理论保证，结果超越了先前的研究。

Conclusion: 对于具有对称性的资料，超对称模型在比紧致群和不变分布更广泛的情况下是可取的。

Abstract: Symmetries are known to improve the empirical performance of machine learning
models, yet theoretical guarantees explaining these gains remain limited. Prior
work has focused mainly on compact group symmetries and often assumes that the
data distribution itself is invariant, an assumption rarely satisfied in
real-world applications. In this work, we extend generalization guarantees to
the broader setting of non-compact symmetries, such as translations and to
non-invariant data distributions. Building on the PAC-Bayes framework, we adapt
and tighten existing bounds, demonstrating the approach on McAllester's
PAC-Bayes bound while showing that it applies to a wide range of PAC-Bayes
bounds. We validate our theory with experiments on a rotated MNIST dataset with
a non-uniform rotation group, where the derived guarantees not only hold but
also improve upon prior results. These findings provide theoretical evidence
that, for symmetric data, symmetric models are preferable beyond the narrow
setting of compact groups and invariant distributions, opening the way to a
more general understanding of symmetries in machine learning.

</details>


### [402] [Disentanglement Beyond Static vs. Dynamic: A Benchmark and Evaluation Framework for Multi-Factor Sequential Representations](https://arxiv.org/abs/2510.17313)
*Tal Barami,Nimrod Berman,Ilan Naiman,Amos H. Hason,Rotem Ezra,Omri Azencot*

Main category: cs.LG

TL;DR: 该论文提出了第一个标准化的基准来评估多因素序列解缠，同时引入了一种新模型和工具，实现了数据集自动标注。


<details>
  <summary>Details</summary>
Motivation: 在深度学习中，学习序列数据的解缠表示是关键目标，但现有研究忽略了真实数据的多因素特性。

Method: 引入了模块化工具以进行数据集整合、模型开发和评估，并提出了一种后期潜在探索阶段。

Result: 建立了评估多因素序列解缠的基准，并实现了最新模型的重大进展。

Conclusion: 提出了一个标准化基准，推动了多因素序列解缠的研究和应用。

Abstract: Learning disentangled representations in sequential data is a key goal in
deep learning, with broad applications in vision, audio, and time series. While
real-world data involves multiple interacting semantic factors over time, prior
work has mostly focused on simpler two-factor static and dynamic settings,
primarily because such settings make data collection easier, thereby
overlooking the inherently multi-factor nature of real-world data. We introduce
the first standardized benchmark for evaluating multi-factor sequential
disentanglement across six diverse datasets spanning video, audio, and time
series. Our benchmark includes modular tools for dataset integration, model
development, and evaluation metrics tailored to multi-factor analysis. We
additionally propose a post-hoc Latent Exploration Stage to automatically align
latent dimensions with semantic factors, and introduce a Koopman-inspired model
that achieves state-of-the-art results. Moreover, we show that Vision-Language
Models can automate dataset annotation and serve as zero-shot disentanglement
evaluators, removing the need for manual labels and human intervention.
Together, these contributions provide a robust and scalable foundation for
advancing multi-factor sequential disentanglement.

</details>


### [403] [Auto-Rubric: Learning to Extract Generalizable Criteria for Reward Modeling](https://arxiv.org/abs/2510.17314)
*Lipeng Xie,Sen Huang,Zhuo Zhang,Anni Zou,Yunpeng Zhai,Dingchao Ren,Kezun Zhang,Haoyuan Hu,Boyin Liu,Haoran Chen,Zhaoyang Liu,Bolin Ding*

Main category: cs.LG

TL;DR: 开发了一种新颖的奖励建模框架，通过数据高效的方法提升大型语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 提高大型语言模型与人类价值观的对齐程度，同时解决偏好数据集的成本高和可解释性差的问题。

Method: 使用无训练的框架，通过验证引导的提出-评估-修订流程推断高质量查询特定的评分标准，并通过最大化信息论编码率将其推广为紧凑的核心集合。

Result: 通过仅使用70对偏好样本，模型如Qwen3-8B的性能超越了完全训练的专门模型，显示出卓越的数据效率和性能。

Conclusion: 该研究开创了一种可扩展、可解释且数据高效的奖励建模方法，显著提高了小型模型的性能。

Abstract: Reward models are essential for aligning Large Language Models (LLMs) with
human values, yet their development is hampered by costly preference datasets
and poor interpretability. While recent rubric-based approaches offer
transparency, they often lack systematic quality control and optimization,
creating a trade-off between scalability and reliability. We address these
limitations with a novel, training-free framework built on a key assumption:
\textit{evaluation rubrics underlying human preferences exhibit significant
generalization ability across diverse queries}, a property that enables
remarkable data efficiency. Our two-stage approach first infers high-quality,
query-specific rubrics using a validation-guided
\textbf{Propose-Evaluate-Revise} pipeline. Second, it generalizes these
granular rubrics into a compact, non-redundant core set by maximizing an
\textbf{information-theoretic coding rate}. The final output is an
interpretable, hierarchical "Theme-Tips" rubric set. Extensive experiments
demonstrate the framework's exceptional data efficiency and performance.
Critically, using just 70 preference pairs (1.5\% of the source data), our
method also empowers smaller models like Qwen3-8B to outperform specialized,
fully-trained counterparts. This work pioneers a scalable, interpretable, and
data-efficient path for reward modeling.

</details>


### [404] [Localist LLMs with Recruitment Learning](https://arxiv.org/abs/2510.17358)
*Joachim Diederich*

Main category: cs.LG

TL;DR: 提出了一个新的框架来训练大语言模型，通过可调参数调整可解释性与高效性，支持在复杂模型与数据编码效率之间的平衡。


<details>
  <summary>Details</summary>
Motivation: 希望解决大语言模型在可解释性和高效性之间的权衡问题，提供一个灵活的框架以适应不同的应用需求。

Method: 提出了一种新颖的框架，通过局部拨盘、信息论招募机制及层次化招募框架，实现对大语言模型的训练和推理过程中内部表征的持续调整。

Result: 通过严格的数学结果，确立了在静态点上注意力集中在语义相关块上的显式阈值条件，提供了模型在块水平和LLM水平的收敛保证。

Conclusion: 该框架允许在可解释性与高性能模式之间进行连续插值，同时在多个粒度适应架构容量，支持在需要透明度与能力的受监管领域中的应用。

Abstract: We present a novel framework for training large language models with
continuously adjustable internal representations that span the full spectrum
from localist (interpretable, rule-based) to distributed (generalizable,
efficient) encodings. The key innovations are (1) a locality dial, a tunable
parameter that dynamically controls the degree of localization during both
training and inference without requiring model retraining, (2) an
information-theoretic recruitment mechanism that adaptively allocates semantic
blocks as needed, eliminating the requirement for complete domain knowledge at
initialization, and (3) a hierarchical recruitment framework that extends
capacity allocation to entire specialized LLMs, enabling multi-granularity
architectural adaptation. This is achieved through group sparsity penalties on
attention mechanisms, information-theoretic anchor design, dynamic rule
injection, and principled recruitment criteria based on penalized likelihood
with explicit units. We provide rigorous mathematical results establishing
explicit threshold conditions under which attention provably concentrates on
semantically relevant blocks at stationary points, with exact bounds on
attention entropy and pointer fidelity. The hierarchical recruitment mechanism
provides convergence guarantees at both the block level (fine-grained,
within-LLM) and the LLM level (coarse-grained, cross-domain), ensuring the
system discovers semantic partitions that balance model complexity against data
encoding efficiency. This framework enables practitioners to continuously
interpolate between interpretable and high-performance modes while adapting
architectural capacity at multiple granularities, supporting applications in
regulated domains requiring both transparency and capability.

</details>


### [405] [Beyond Binary Out-of-Distribution Detection: Characterizing Distributional Shifts with Multi-Statistic Diffusion Trajectories](https://arxiv.org/abs/2510.17381)
*Achref Jaziri,Martin Rogmann,Martin Mundt,Visvanathan Ramesh*

Main category: cs.LG

TL;DR: 本研究提出了DISC方法，克服了现有OOD检测方法的局限，实现了更细致的检测和OOD类型分类。


<details>
  <summary>Details</summary>
Motivation: 当前的OOD检测方法通常将分布变化简化为单一的异常值评分，导致无法充分地对OOD数据进行上下文明确的理解和利用，因此需要开发一种新的方法来克服这一限制。

Method: 提出并应用DISC:基于扩散的统计特征化方法，利用扩散模型的去噪过程提取多维特征向量，以捕捉不同噪声水平下的统计差异。

Result: 在多项图像和表格基准测试中，DISC方法与现有的最先进的OOD检测器相匹配或超越，并能够分类OOD的类型，填补了先前研究中的空白。

Conclusion: 本研究通过引入DISC方法，在OOD数据检测中实现了更丰富的多维特征提取，使得不仅能检测OOD数据，还能对其类型进行分类，从而提升了OOD处理的灵活性和有效性。

Abstract: Detecting out-of-distribution (OOD) data is critical for machine learning, be
it for safety reasons or to enable open-ended learning. However, beyond mere
detection, choosing an appropriate course of action typically hinges on the
type of OOD data encountered. Unfortunately, the latter is generally not
distinguished in practice, as modern OOD detection methods collapse
distributional shifts into single scalar outlier scores. This work argues that
scalar-based methods are thus insufficient for OOD data to be properly
contextualized and prospectively exploited, a limitation we overcome with the
introduction of DISC: Diffusion-based Statistical Characterization. DISC
leverages the iterative denoising process of diffusion models to extract a
rich, multi-dimensional feature vector that captures statistical discrepancies
across multiple noise levels. Extensive experiments on image and tabular
benchmarks show that DISC matches or surpasses state-of-the-art detectors for
OOD detection and, crucially, also classifies OOD type, a capability largely
absent from prior work. As such, our work enables a shift from simple binary
OOD detection to a more granular detection.

</details>


### [406] [Latent Spaces Beyond Synthesis: From GANs to Diffusion Models](https://arxiv.org/abs/2510.17383)
*Ludovica Schaerf*

Main category: cs.LG

TL;DR: 本文研究了生成视觉模型中的内部表征从GAN和VAE到扩散模型的演变，提出了合成的严格和广义区分，挑战了传统的统一内部空间假设。


<details>
  <summary>Details</summary>
Motivation: 探讨生成视觉模型内部表征的演变，尤其是从GAN和VAE到扩散架构的概念和技术转变。

Method: 通过模型架构的深入分析和针对性的实验设置，干预层级表征。

Result: 扩散模型将表征的负担进行碎片化，质疑了统一内部空间的假设，提出了两种合成方式的区分。

Conclusion: 生成模型的内部表征正在向分散化和层次化的方法转变，尤其是扩散模型的应用挑战了传统的理解方式。

Abstract: This paper examines the evolving nature of internal representations in
generative visual models, focusing on the conceptual and technical shift from
GANs and VAEs to diffusion-based architectures. Drawing on Beatrice Fazi's
account of synthesis as the amalgamation of distributed representations, we
propose a distinction between "synthesis in a strict sense", where a compact
latent space wholly determines the generative process, and "synthesis in a
broad sense," which characterizes models whose representational labor is
distributed across layers. Through close readings of model architectures and a
targeted experimental setup that intervenes in layerwise representations, we
show how diffusion models fragment the burden of representation and thereby
challenge assumptions of unified internal space. By situating these findings
within media theoretical frameworks and critically engaging with metaphors such
as the latent space and the Platonic Representation Hypothesis, we argue for a
reorientation of how generative AI is understood: not as a direct synthesis of
content, but as an emergent configuration of specialized processes.

</details>


### [407] [TabR1: Taming GRPO for tabular reasoning LLMs](https://arxiv.org/abs/2510.17385)
*Pengxiang Cai,Zihao Gao,Jintai Chen*

Main category: cs.LG

TL;DR: TabR1是首个用于表格预测的推理LLM，通过PRPO提升了少样本和零样本性能，并在多项任务中超过了大型LLM。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM在表格预测中的应用，填补传统模型在可解释性和跨表格迁移性的不足。

Method: 采用先验结构的奖励优化方法PRPO，利用列排列不变性构建多个标签保持排列，以变稀疏奖励为密集学习信号。

Result: TabR1在零样本条件下接近强基线在32-shot设定下的表现，并且在不同任务上显著超越更大的LLM模型。

Conclusion: TabR1在有限监督下激活了LLM的推理能力，提升了少样本和零样本的性能及可解释性，并在实验中显示与强基线相当的表现。

Abstract: Tabular prediction has traditionally relied on gradient-boosted decision
trees and specialized deep learning models, which excel within tasks but
provide limited interpretability and weak transfer across tables. Reasoning
large language models (LLMs) promise cross-task adaptability with trans- parent
reasoning traces, yet their potential has not been fully realized for tabular
data. This paper presents TabR1, the first reasoning LLM for tabular prediction
with multi-step reasoning. At its core is Permutation Relative Policy
Optimization (PRPO), a simple yet efficient reinforcement learning method that
encodes column-permutation invariance as a structural prior. By construct- ing
multiple label-preserving permutations per sample and estimating advantages
both within and across permutations, PRPO transforms sparse rewards into dense
learning signals and improves generalization. With limited supervision, PRPO
activates the reasoning ability of LLMs for tabular prediction, enhancing
few-shot and zero-shot performance as well as interpretability. Comprehensive
experiments demonstrate that TabR1 achieves performance comparable to strong
baselines under full-supervision fine-tuning. In the zero-shot setting, TabR1
approaches the performance of strong baselines under the 32-shot setting.
Moreover, TabR1 (8B) substantially outperforms much larger LLMs across various
tasks, achieving up to 53.17% improvement over DeepSeek-R1 (685B).

</details>


### [408] [Exploration via Feature Perturbation in Contextual Bandits](https://arxiv.org/abs/2510.17390)
*Seouh-won Yi,Min-hwan Oh*

Main category: cs.LG

TL;DR: 提出特征扰动技术，实现了更低的后悔界限，且在计算和理论性能上表现优异。


<details>
  <summary>Details</summary>
Motivation: 希望找到一种高效的新方法来改善现有随机化算法的表现，特别是在特征处理上。

Method: 引入随机性直接作用于特征输入，而非随机化未知参数或对奖励添加噪声。

Result: 该算法为广义线性乐队提供了$	ilde{	ext{O}}(d	ext{sqrT})$的最坏情况后悔界限，并且具有计算效率高的优点。

Conclusion: 特征扰动技术在理论和实践中优于现有的方法，提供了更低的最坏情况后悔界限。

Abstract: We propose feature perturbation, a simple yet powerful technique that injects
randomness directly into feature inputs, instead of randomizing unknown
parameters or adding noise to rewards. Remarkably, this algorithm achieves
$\tilde{\mathcal{O}}(d\sqrt{T})$ worst-case regret bound for generalized linear
bandits, while avoiding the $\tilde{\mathcal{O}}(d^{3/2}\sqrt{T})$ regret
typical of existing randomized bandit algorithms. Because our algorithm eschews
parameter sampling, it is both computationally efficient and naturally extends
to non-parametric or neural network models. We verify these advantages through
empirical evaluations, demonstrating that feature perturbation not only
surpasses existing methods but also unifies strong practical performance with
best-known theoretical guarantees.

</details>


### [409] [Finite-Time Bounds for Average-Reward Fitted Q-Iteration](https://arxiv.org/abs/2510.17391)
*Jongmin Lee,Ernest K. Ryu*

Main category: cs.LG

TL;DR: 本文建立了弱连接MDP下平均奖励离线RL的样本复杂度结果，并提出了锚定拟合Q-迭代方法。


<details>
  <summary>Details</summary>
Motivation: 尽管已有大量关于折扣回报离线强化学习样本复杂度的研究，但平均奖励设置的相关研究明显不足，且现有方法的假设过于严格。

Method: 提出了锚定拟合Q-迭代，将标准拟合Q-迭代与锚定机制结合。

Result: 证明了在平均奖励设置中，锚定机制对于实现有限时间分析至关重要，并扩展了分析到单轨迹数据集的情况。

Conclusion: 这项工作首次为弱连接MDP下的平均奖励离线强化学习提供了样本复杂度结果，并引入了锚定拟合Q-迭代方法。

Abstract: Although there is an extensive body of work characterizing the sample
complexity of discounted-return offline RL with function approximations, prior
work on the average-reward setting has received significantly less attention,
and existing approaches rely on restrictive assumptions, such as ergodicity or
linearity of the MDP. In this work, we establish the first sample complexity
results for average-reward offline RL with function approximation for weakly
communicating MDPs, a much milder assumption. To this end, we introduce
Anchored Fitted Q-Iteration, which combines the standard Fitted Q-Iteration
with an anchor mechanism. We show that the anchor, which can be interpreted as
a form of weight decay, is crucial for enabling finite-time analysis in the
average-reward setting. We also extend our finite-time analysis to the setup
where the dataset is generated from a single-trajectory rather than IID
transitions, again leveraging the anchor mechanism.

</details>


### [410] [S4ECG: Exploring the impact of long-range interactions for arrhythmia prediction](https://arxiv.org/abs/2510.17406)
*Tiezhi Wang,Wilhelm Haverkamp,Nils Strodthoff*

Main category: cs.LG

TL;DR: S4ECG是一种新颖的深度学习架构，通过多时期分析心电图信号，显著提高了房颤等复杂心律失常的分类准确性。


<details>
  <summary>Details</summary>
Motivation: 推动心电图解读的进步，特别是针对复杂心律失常（如房颤和房扑）的检测和分析。

Method: 采用结构化状态空间模型，通过联合多时期预测来分析心电图信号，实现心律失常的分类。

Result: 相较于单时期方法，联合多时期预测在宏观AUROC指标上提升了1.0-11.6%，房纤颤的特异性从0.718-0.979提高至0.967-0.998，表现出对分布内和分布外的鲁棒性增强。

Conclusion: 本研究提出了一种新型深度学习架构S4ECG，显著提升了多时期心律失常分类的准确性，尤其是在房颤检测方面。

Abstract: The electrocardiogram (ECG) exemplifies biosignal-based time series with
continuous, temporally ordered structure reflecting cardiac physiological and
pathophysiological dynamics. Detailed analysis of these dynamics has proven
challenging, as conventional methods capture either global trends or local
waveform features but rarely their simultaneous interplay at high temporal
resolution. To bridge global and local signal analysis, we introduce S4ECG, a
novel deep learning architecture leveraging structured state space models for
multi-epoch arrhythmia classification. Our joint multi-epoch predictions
significantly outperform single-epoch approaches by 1.0-11.6% in macro-AUROC,
with atrial fibrillation specificity improving from 0.718-0.979 to 0.967-0.998,
demonstrating superior performance in-distribution and enhanced
out-of-distribution robustness. Systematic investigation reveals optimal
temporal dependency windows spanning 10-20 minutes for peak performance. This
work contributes to a paradigm shift toward temporally-aware arrhythmia
detection algorithms, opening new possibilities for ECG interpretation, in
particular for complex arrhythmias like atrial fibrillation and atrial flutter.

</details>


### [411] [Diffusion Models as Dataset Distillation Priors](https://arxiv.org/abs/2510.17421)
*Duo Su,Huyu Wu,Huanran Chen,Yiming Shi,Yuzhu Wang,Xi Ye,Jun Zhu*

Main category: cs.LG

TL;DR: 本论文提出了Diffusion As Priors (DAP)方法，通过量化合成和真实数据的相似性来增强数据集的代表性，进而提高蒸馏数据集的质量，且在多个大型数据集中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在数据集蒸馏领域，实现多样性、泛化和代表性的统一是一项重大挑战，而现有基于生成的蒸馏方法未能充分利用扩散模型的内在代表性先验。

Method: 采用Mercer核量化合成数据和真实数据在特征空间中的相似性，并将此作为引导来改善反向扩散过程，从而改善蒸馏数据集的代表性。

Result: 在ImageNet-1K及其子集等大规模数据集上的大量实验表明，DAP在生成高保真数据集方面优于当前最先进的方法，同时在交叉架构泛化方面表现更佳。

Conclusion: 我们提出的Diffusion As Priors (DAP)方法通过量化合成数据和真实数据之间的相似性，显著提高了蒸馏样本的代表性，并在无需重新训练的情况下增强数据集的质量。

Abstract: Dataset distillation aims to synthesize compact yet informative datasets from
large ones. A significant challenge in this field is achieving a trifecta of
diversity, generalization, and representativeness in a single distilled
dataset. Although recent generative dataset distillation methods adopt powerful
diffusion models as their foundation models, the inherent representativeness
prior in diffusion models is overlooked. Consequently, these approaches often
necessitate the integration of external constraints to enhance data quality. To
address this, we propose Diffusion As Priors (DAP), which formalizes
representativeness by quantifying the similarity between synthetic and real
data in feature space using a Mercer kernel. We then introduce this prior as
guidance to steer the reverse diffusion process, enhancing the
representativeness of distilled samples without any retraining. Extensive
experiments on large-scale datasets, such as ImageNet-1K and its subsets,
demonstrate that DAP outperforms state-of-the-art methods in generating
high-fidelity datasets while achieving superior cross-architecture
generalization. Our work not only establishes a theoretical connection between
diffusion priors and the objectives of dataset distillation but also provides a
practical, training-free framework for improving the quality of the distilled
dataset.

</details>


### [412] [CrossStateECG: Multi-Scale Deep Convolutional Network with Attention for Rest-Exercise ECG Biometrics](https://arxiv.org/abs/2510.17467)
*Dan Zheng,Jing Feng,Juan Liu*

Main category: cs.LG

TL;DR: 本研究提出了一种名为CrossStateECG的ECG身份验证模型，旨在解决在休息与运动状态下的识别问题，实验结果表明该模型在多种场景中均具有出色的识别能力。


<details>
  <summary>Details</summary>
Motivation: 解决当前ECG生物识别研究中在休息-运动场景下的性能下降问题。

Method: 结合多尺度深度卷积特征提取和注意力机制，以增强在跨状态（休息-运动）条件下的识别能力。

Result: 在休息到运动和运动到休息的场景中，CrossStateECG分别达到了92.50%和94.72%的识别准确率，并在其他场景中也表现出色。

Conclusion: CrossStateECG是一种有效的ECG身份验证模型，能够在不同生理状态下保持高识别精度，具有广泛的应用前景。

Abstract: Current research in Electrocardiogram (ECG) biometrics mainly emphasizes
resting-state conditions, leaving the performance decline in rest-exercise
scenarios largely unresolved. This paper introduces CrossStateECG, a robust
ECG-based authentication model explicitly tailored for cross-state
(rest-exercise) conditions. The proposed model creatively combines multi-scale
deep convolutional feature extraction with attention mechanisms to ensure
strong identification across different physiological states. Experimental
results on the exercise-ECGID dataset validate the effectiveness of
CrossStateECG, achieving an identification accuracy of 92.50% in the
Rest-to-Exercise scenario (training on resting ECG and testing on post-exercise
ECG) and 94.72% in the Exercise-to-Rest scenario (training on post-exercise ECG
and testing on resting ECG). Furthermore, CrossStateECG demonstrates
exceptional performance across both state combinations, reaching an accuracy of
99.94% in Rest-to-Rest scenarios and 97.85% in Mixed-to-Mixed scenarios.
Additional validations on the ECG-ID and MIT-BIH datasets further confirmed the
generalization abilities of CrossStateECG, underscoring its potential as a
practical solution for post-exercise ECG-based authentication in dynamic
real-world settings.

</details>


### [413] [Layer Specialization Underlying Compositional Reasoning in Transformers](https://arxiv.org/abs/2510.17469)
*Jing Liu*

Main category: cs.LG

TL;DR: 本研究通过随机层次模型分析变形金刚的组合推理能力，发现层级专门化在训练过程中逐步显现，并与概化表现相关。


<details>
  <summary>Details</summary>
Motivation: 调查变形金刚模型在未观察到的序列上表现出的组合推理能力。

Method: 使用随机层次模型（RHM）生成序列，通过递归规则应用来进行训练和评估。

Result: 模型在任务复杂性和上下文示例数量增加时，表现系统性改善，跨层迁移和分布外任务需更多示例进行有效性评估。

Conclusion: 变形金刚模型展示了支持组合推理的模块化、可解释机制，内部算法结构与观察到的行为能力相联系。

Abstract: Transformers exhibit compositional reasoning on sequences not observed during
training, a capability often attributed to in-context learning (ICL) and skill
composition. We investigate this phenomenon using the Random Hierarchy Model
(RHM), a probabilistic context-free grammar that generates sequences through
recursive rule application. Models are trained on subsets of sequences and
evaluated across four generalization conditions: memorization, in-distribution
generalization, out-of-distribution generalization with the same rules, and
cross-layer transfer. Behaviorally, performance improves systematically with
task complexity and the number of in-context examples, with out-of-distribution
tasks requiring substantially more examples than in-distribution scenarios.
Mechanistically, we identify a progressive emergence of layer specialization
during training that correlates with generalization performance. Principal
component analysis and attention pattern clustering reveal that transformers
develop structured, hierarchically organized representations in specialized
layers. These results demonstrate that transformers develop modular,
interpretable mechanisms supporting compositional reasoning, linking internal
algorithmic structure to observed behavioral capabilities.

</details>


### [414] [Unified Privacy Guarantees for Decentralized Learning via Matrix Factorization](https://arxiv.org/abs/2510.17480)
*Aurélien Bellet,Edwige Cyffers,Davide Frey,Romaric Gaudel,Dimitri Lerévérend,François Taïani*

Main category: cs.LG

TL;DR: 本文探讨了去中心化学习中隐私会计的问题，提出了一种新的去中心化学习算法MAFALDA-SGD，通过引入矩阵分解技术，提高了隐私效用平衡，并在多种图上表现优越。


<details>
  <summary>Details</summary>
Motivation: 解决去中心化学习中隐私和效用的权衡问题，改善当前在差分隐私会计方法的局限性，并提出新的去中心化学习算法。

Method: 通过将矩阵分解（MF）应用于差分隐私（DP）在去中心化学习（DL）中的度量，开发出更紧凑的隐私会计方法。

Result: 通过引入MAFALDA-SGD，展示了用于用户级协相关噪声的基于 gossip 的去中心化学习算法在性能上优于现有方法。

Conclusion: 提出的MAFALDA-SGD算法在合成和现实世界图上优于现有方法，展示了新方法的有效性。

Abstract: Decentralized Learning (DL) enables users to collaboratively train models
without sharing raw data by iteratively averaging local updates with neighbors
in a network graph. This setting is increasingly popular for its scalability
and its ability to keep data local under user control. Strong privacy
guarantees in DL are typically achieved through Differential Privacy (DP), with
results showing that DL can even amplify privacy by disseminating noise across
peer-to-peer communications. Yet in practice, the observed privacy-utility
trade-off often appears worse than in centralized training, which may be due to
limitations in current DP accounting methods for DL. In this paper, we show
that recent advances in centralized DP accounting based on Matrix Factorization
(MF) for analyzing temporal noise correlations can also be leveraged in DL. By
generalizing existing MF results, we show how to cast both standard DL
algorithms and common trust models into a unified formulation. This yields
tighter privacy accounting for existing DP-DL algorithms and provides a
principled way to develop new ones. To demonstrate the approach, we introduce
MAFALDA-SGD, a gossip-based DL algorithm with user-level correlated noise that
outperforms existing methods on synthetic and real-world graphs.

</details>


### [415] [ZACH-ViT: A Zero-Token Vision Transformer with ShuffleStrides Data Augmentation for Robust Lung Ultrasound Classification](https://arxiv.org/abs/2510.17650)
*Athanasios Angelakis,Amne Mousa,Micah L. A. Heldeweg,Laurens A. Biesheuvel,Mark A. Haaksma,Jasper M. Smit,Pieter R. Tuinman,Paul W. G. Elbers*

Main category: cs.LG

TL;DR: ZACH-ViT是一种新型视觉变换器，可有效区分心源性与非心源性肺病，具有更快训练速度和更少参数，适合临床实时应用。


<details>
  <summary>Details</summary>
Motivation: 在肺部超声视频中，区分心源性肺水肿与非心源性肺病及正常肺的挑战性，主要由于视觉变异性和重叠现象。

Method: 提出了一种新的视觉变换器ZACH-ViT，并引入了ShuffleStrides数据增强方法，以处理无序的医疗图像数据。

Result: ZACH-ViT在评估中表现出最高的ROC-AUC值（0.80和0.79），同时获得较好的灵敏度和特异性。

Conclusion: ZACH-ViT模型通过与数据结构的对齐设计，在小数据医疗影像中表现优于规模更大的模型。

Abstract: Differentiating cardiogenic pulmonary oedema (CPE) from non-cardiogenic and
structurally normal lungs in lung ultrasound (LUS) videos remains challenging
due to the high visual variability of non-cardiogenic inflammatory patterns
(NCIP/ARDS-like), interstitial lung disease, and healthy lungs. This
heterogeneity complicates automated classification as overlapping B-lines and
pleural artefacts are common. We introduce ZACH-ViT (Zero-token Adaptive
Compact Hierarchical Vision Transformer), a 0.25 M-parameter Vision Transformer
variant that removes both positional embeddings and the [CLS] token, making it
fully permutation-invariant and suitable for unordered medical image data. To
enhance generalization, we propose ShuffleStrides Data Augmentation (SSDA),
which permutes probe-view sequences and frame orders while preserving
anatomical validity. ZACH-ViT was evaluated on 380 LUS videos from 95
critically ill patients against nine state-of-the-art baselines. Despite the
heterogeneity of the non-cardiogenic group, ZACH-ViT achieved the highest
validation and test ROC-AUC (0.80 and 0.79) with balanced sensitivity (0.60)
and specificity (0.91), while all competing models collapsed to trivial
classification. It trains 1.35x faster than Minimal ViT (0.62M parameters) with
2.5x fewer parameters, supporting real-time clinical deployment. These results
show that aligning architectural design with data structure can outperform
scale in small-data medical imaging.

</details>


### [416] [I-RAVEN-X: Benchmarking Generalization and Robustness of Analogical and Mathematical Reasoning in Large Language and Reasoning Models](https://arxiv.org/abs/2510.17496)
*Giacomo Camposampiero,Michael Hersche,Roger Wattenhofer,Abu Sebastian,Abbas Rahimi*

Main category: cs.LG

TL;DR: I-RAVEN-X基准测试显示LRMs在复杂推理上优于LLMs，但在不确定性下表现不足。


<details>
  <summary>Details</summary>
Motivation: 提升类比和数学推理的复杂性，增加运算数复杂性和属性范围，同时引入感知不确定性。

Method: 引入I-RAVEN-X基准，评估大型语言模型和推理模型在类比和数学推理中的泛化能力和鲁棒性。

Result: LRMs在长期推理关系和更广属性范围中表现更佳，但在处理不确定性方面仍然存在显著挑战。

Conclusion: LRMs outperform LLMs in specific reasoning tasks, yet face limitations in uncertainty handling.

Abstract: We introduce I-RAVEN-X, a symbolic benchmark designed to evaluate
generalization and robustness in analogical and mathematical reasoning for
Large Language Models (LLMs) and Large Reasoning Models (LRMs). I-RAVEN-X
extends I-RAVEN by increasing operand complexity, attribute range, and
introducing perceptual uncertainty. Compared to LLMs, empirical results show
that LRMs achieve improved productivity and systematicity on longer reasoning
relations and wider attribute ranges, respectively. However, LRMs are still
significantly challenged by reasoning under uncertainty and cannot effectively
explore multiple probabilistic outcomes.

</details>


### [417] [Stochastic Difference-of-Convex Optimization with Momentum](https://arxiv.org/abs/2510.17503)
*El Mahdi Chayti,Martin Jaggi*

Main category: cs.LG

TL;DR: 本文探讨了动量在小批量随机差分凸优化中的重要性，提出了一种新的算法，证明其在一般条件下可实现收敛和良好的实证性能。


<details>
  <summary>Details</summary>
Motivation: 当前的小批量随机差分凸优化方法对小批量大小的收敛性质理解不足，限制了其在实际应用中的使用。

Method: 该研究提出了一种基于动量的算法，旨在在标准光滑性和有界方差假设下实现收敛。

Result: 在任何批量大小下，动量使得在标准光滑性和有界方差假设下实现收敛，且没有动量时收敛可能失败。

Conclusion: 提出的动量算法在随机差分凸优化中实现了可证明的收敛，并展示了强大的实证性能。

Abstract: Stochastic difference-of-convex (DC) optimization is prevalent in numerous
machine learning applications, yet its convergence properties under small batch
sizes remain poorly understood. Existing methods typically require large
batches or strong noise assumptions, which limit their practical use. In this
work, we show that momentum enables convergence under standard smoothness and
bounded variance assumptions (of the concave part) for any batch size. We prove
that without momentum, convergence may fail regardless of stepsize,
highlighting its necessity. Our momentum-based algorithm achieves provable
convergence and demonstrates strong empirical performance.

</details>


### [418] [Curiosity Meets Cooperation: A Game-Theoretic Approach to Long-Tail Multi-Label Learning](https://arxiv.org/abs/2510.17520)
*Canran Xiao,Chuangxin Zhao,Zong Ke,Fei Shen*

Main category: cs.LG

TL;DR: CD-GTMLL框架通过合作潜力游戏机制有效解决多标签学习中的长尾不平衡问题，并在多项实验中显示出优异的性能提升。


<details>
  <summary>Details</summary>
Motivation: 针对多标签学习中长尾不平衡的问题，常见的少数标签主导梯度信号，而实际中重要的稀有标签却被忽视。

Method: 通过将多标签学习转化为一个合作潜力游戏，利用合作玩家的机制来解决长尾不平衡问题。

Result: 在传统基准和三个极大规模数据集上的广泛实验显示，提出的方法在Rare-F1和P@3上相较于最强基线有显著提升。

Conclusion: CD-GTMLL提供了一种系统、可扩展的方法来实现多标签预测中的长尾稳健性，从实验结果来看，性能显著提升。

Abstract: Long-tail imbalance is endemic to multi-label learning: a few head labels
dominate the gradient signal, while the many rare labels that matter in
practice are silently ignored. We tackle this problem by casting the task as a
cooperative potential game. In our Curiosity-Driven Game-Theoretic Multi-Label
Learning (CD-GTMLL) framework, the label space is split among several
cooperating players that share a global accuracy payoff yet earn additional
curiosity rewards that rise with label rarity and inter-player disagreement.
These curiosity bonuses inject gradient on under-represented tags without
hand-tuned class weights. We prove that gradient best-response updates ascend a
differentiable potential and converge to tail-aware stationary points that
tighten a lower bound on the expected Rare-F1. Extensive experiments on
conventional benchmarks and three extreme-scale datasets show consistent
state-of-the-art gains, delivering up to +4.3% Rare-F1 and +1.6% P@3 over the
strongest baselines, while ablations reveal emergent division of labour and
faster consensus on rare classes. CD-GTMLL thus offers a principled, scalable
route to long-tail robustness in multi-label prediction.

</details>


### [419] [Mitigating Clever Hans Strategies in Image Classifiers through Generating Counterexamples](https://arxiv.org/abs/2510.17524)
*Sidney Bender,Ole Delzer,Jan Herrmann,Heike Antje Marxfeld,Klaus-Robert Müller,Grégoire Montavon*

Main category: cs.LG

TL;DR: CFKD通过生成多样的反事实数据，克服了现有鲁棒性方法的局限性，在多种数据集中展现出了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型易受虚假相关影响，这破坏了其鲁棒性，尤其是在大规模基础和自监督模型中，因此亟需改进方法来应对这个问题。

Method: 提出了对抗知识蒸馏(CFKD)框架，通过生成多样的反事实数据，帮助人类注释者高效地探讨和修正模型的决策边界。

Result: CFKD避免了依赖显式组标签的局限性，可扩展至多个混淆因素，实现了各组之间的平衡泛化。

Conclusion: CFKD在多种数据集上表现出色，特别是在数据稀缺且存在显著伪相关的情况下，能够有效提升模型的鲁棒性。

Abstract: Deep learning models remain vulnerable to spurious correlations, leading to
so-called Clever Hans predictors that undermine robustness even in large-scale
foundation and self-supervised models. Group distributional robustness methods,
such as Deep Feature Reweighting (DFR) rely on explicit group labels to
upweight underrepresented subgroups, but face key limitations: (1) group labels
are often unavailable, (2) low within-group sample sizes hinder coverage of the
subgroup distribution, and (3) performance degrades sharply when multiple
spurious correlations fragment the data into even smaller groups. We propose
Counterfactual Knowledge Distillation (CFKD), a framework that sidesteps these
issues by generating diverse counterfactuals, enabling a human annotator to
efficiently explore and correct the model's decision boundaries through a
knowledge distillation step. Unlike DFR, our method not only reweights the
undersampled groups, but it also enriches them with new data points. Our method
does not require any confounder labels, achieves effective scaling to multiple
confounders, and yields balanced generalization across groups. We demonstrate
CFKD's efficacy across five datasets, spanning synthetic tasks to an industrial
application, with particularly strong gains in low-data regimes with pronounced
spurious correlations. Additionally, we provide an ablation study on the effect
of the chosen counterfactual explainer and teacher model, highlighting their
impact on robustness.

</details>


### [420] [Reliable Inference in Edge-Cloud Model Cascades via Conformal Alignment](https://arxiv.org/abs/2510.17543)
*Jiayi Huang,Sangwoo Park,Nicola Paoletti,Osvaldo Simeone*

Main category: cs.LG

TL;DR: 本研究提出了CAb级联机制，能够在边缘进行快速推断的同时，保证其覆盖率与可靠性，适用于多种边缘预测集。


<details>
  <summary>Details</summary>
Motivation: 在边缘智能中，实现低延迟推断的同时，确保可靠性仍然具有挑战性，因此研究边缘-云级联模型以保持条件覆盖是重要的。

Method: 通过引入基于保序对齐的级联机制，CAb模型将边缘到云的升级问题视作多重假设检验问题，针对不同输入选择在边缘安全处理的方式。

Result: 提出的CAb级联方法在统计上保证了满足云级条件覆盖的边缘决策的平均比例，且可调节覆盖率、延迟率和集合大小之间的权衡。

Conclusion: 所提出的CAb级联模型在边缘预测中保持了目标条件覆盖，同时显著减少了对云的卸载，并带来适度的预测集大小增加。

Abstract: Edge intelligence enables low-latency inference via compact on-device models,
but assuring reliability remains challenging. We study edge-cloud cascades that
must preserve conditional coverage: whenever the edge returns a prediction set,
it should contain the true label with a user-specified probability, as if
produced by the cloud model. We formalize conditional coverage with respect to
the cloud predictive distribution, and introduce a conformal alignment-based
(CAb) cascading mechanism that certifies this property with user control over
the risk level. Our method casts escalation from edge to cloud models as a
multiple-hypothesis testing (MHT) problem, tailoring conformal alignment (CA)
to select which inputs can be safely handled at the edge. The proposed CAb
model cascading method yields statistical guarantees on the average fraction of
edge decisions that satisfy cloud-level conditional coverage. The procedure
applies to arbitrary edge prediction sets, including variants of conformal
prediction (CP), and exposes a tunable trade-off among coverage, deferral rate,
and set size. Experiments on CIFAR-100 image classification and the TeleQnA
question-answering (QA) benchmark show that the proposed CAb cascade maintains
the target conditional coverage for edge predictions while substantially
reducing offloading to the cloud and incurring modest increases in
prediction-set size.

</details>


### [421] [TrajMamba: An Efficient and Semantic-rich Vehicle Trajectory Pre-training Model](https://arxiv.org/abs/2510.17545)
*Yichen Liu,Yan Lin,Shengnan Guo,Zeyu Zhou,Youfang Lin,Huaiyu Wan*

Main category: cs.LG

TL;DR: TrajMamba是一种新颖的方法，旨在高效学习车辆轨迹，能够有效处理旅行目的与轨迹冗余问题，并在效率与准确性上表现卓越。


<details>
  <summary>Details</summary>
Motivation: 有效和高效地学习车辆轨迹中的旅行语义对实际应用至关重要，但受到道路功能和兴趣点信息的计算负担及轨迹冗余的影响。

Method: 采用Traj-Mamba编码器联合建模GPS和道路视角，通过旅行目的感知的预训练程序和知识蒸馏的预训练方案来处理轨迹数据。

Result: TrajMamba在两个真实世界数据集和三个下游任务中的实验表明其在效率和准确性上均优于其他基准方法。

Conclusion: TrajMamba在效率和准确性方面优于现有最先进的方法，提供了一种高效且语义丰富的车辆轨迹学习解决方案。

Abstract: Vehicle GPS trajectories record how vehicles move over time, storing valuable
travel semantics, including movement patterns and travel purposes. Learning
travel semantics effectively and efficiently is crucial for real-world
applications of trajectory data, which is hindered by two major challenges.
First, travel purposes are tied to the functions of the roads and
points-of-interest (POIs) involved in a trip. Such information is encoded in
textual addresses and descriptions and introduces heavy computational burden to
modeling. Second, real-world trajectories often contain redundant points, which
harm both computational efficiency and trajectory embedding quality. To address
these challenges, we propose TrajMamba, a novel approach for efficient and
semantically rich vehicle trajectory learning. TrajMamba introduces a
Traj-Mamba Encoder that captures movement patterns by jointly modeling both GPS
and road perspectives of trajectories, enabling robust representations of
continuous travel behaviors. It also incorporates a Travel Purpose-aware
Pre-training procedure to integrate travel purposes into the learned embeddings
without introducing extra overhead to embedding calculation. To reduce
redundancy in trajectories, TrajMamba features a Knowledge Distillation
Pre-training scheme to identify key trajectory points through a learnable mask
generator and obtain effective compressed trajectory embeddings. Extensive
experiments on two real-world datasets and three downstream tasks show that
TrajMamba outperforms state-of-the-art baselines in both efficiency and
accuracy.

</details>


### [422] [The Free Transformer](https://arxiv.org/abs/2510.17558)
*François Fleuret*

Main category: cs.LG

TL;DR: 本研究提出了一种改进的解码器Transformer，通过无监督学习的潜变量显著提升了下游任务的效果。


<details>
  <summary>Details</summary>
Motivation: 旨在通过引入随机潜变量来增强解码器Transformer的生成能力。

Method: 使用无监督的变分程序学习随机潜变量，扩展解码器Transformer的生成过程。

Result: 实验评估表明，这种条件化带来了实质性的性能提升。

Conclusion: 引入随机潜变量的解码器Transformer显著改善了下游任务的表现。

Abstract: We propose an extension of the decoder Transformer that conditions its
generative process on random latent variables which are learned without
supervision thanks to a variational procedure. Experimental evaluations show
that allowing such a conditioning translates into substantial improvements on
downstream tasks.

</details>


### [423] [Formally Exploring Time-Series Anomaly Detection Evaluation Metrics](https://arxiv.org/abs/2510.17562)
*Dennis Wagner,Arjun Nair,Billy Joe Franks,Justus Arweiler,Aparna Muraleedharan,Indra Jungjohann,Fabian Hartung,Mayank C. Ahuja,Andriy Balinskyy,Saurabh Varshneya,Nabeel Hussain Syed,Mayank Nagda,Phillip Liznerski,Steffen Reithermann,Maja Rudolph,Sebastian Vollmer,Ralf Schulz,Torsten Katz,Stephan Mandt,Michael Bortz,Heike Leitte,Daniel Neider,Jakob Burger,Fabian Jirasek,Hans Hasse,Sophie Fellenz,Marius Kloft*

Main category: cs.LG

TL;DR: 研究提出了一种新的度量LARM和其变体ALARM，以解决当前时间序列异常检测度量的缺陷，满足所有必要的评估性质。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列异常检测方法的绩效评估存在不足，现有度量方法往往只能反映任务的狭窄方面，导致结果具有误导性。

Method: 分析现有的37种时间序列异常检测度量方法，确定其满足的性质，并提出新的度量标准。

Result: 分析发现，大部分现有度量仅满足少数性质，且没有一种能够满足所有性质。

Conclusion: 本文提出了一种新的灵活度量LARM，及其高级变体ALARM，能够满足所有的验证性质，从而改进时间序列异常检测的评估与比较。

Abstract: Undetected anomalies in time series can trigger catastrophic failures in
safety-critical systems, such as chemical plant explosions or power grid
outages. Although many detection methods have been proposed, their performance
remains unclear because current metrics capture only narrow aspects of the task
and often yield misleading results. We address this issue by introducing
verifiable properties that formalize essential requirements for evaluating
time-series anomaly detection. These properties enable a theoretical framework
that supports principled evaluations and reliable comparisons. Analyzing 37
widely used metrics, we show that most satisfy only a few properties, and none
satisfy all, explaining persistent inconsistencies in prior results. To close
this gap, we propose LARM, a flexible metric that provably satisfies all
properties, and extend it to ALARM, an advanced variant meeting stricter
requirements.

</details>


### [424] [An Empirical Study of Lagrangian Methods in Safe Reinforcement Learning](https://arxiv.org/abs/2510.17564)
*Lindsay Spoor,Álvaro Serra-Gómez,Aske Plaat,Thomas Moerland*

Main category: cs.LG

TL;DR: 本文分析了安全强化学习中拉格朗日乘子的最优性和稳定性，发现自动化乘子更新能够改善性能，但需调试以减少振荡问题。


<details>
  <summary>Details</summary>
Motivation: 在机器人、导航和电力系统等安全关键领域中，优化问题的性能与约束之间的平衡至关重要。

Method: 分析安全强化学习中拉格朗日乘子的最优性和稳定性，提供拉格朗日乘子的$
abla$-曲线以可视化收益和约束成本之间的权衡。

Result: 自动化的乘子更新能够恢复并有时超过在最优值$
abla^*$下找到的最佳表现，但表现出在训练过程中振荡的行为。

Conclusion: 需要进一步研究以稳定安全强化学习中的拉格朗日方法。

Abstract: In safety-critical domains such as robotics, navigation and power systems,
constrained optimization problems arise where maximizing performance must be
carefully balanced with associated constraints. Safe reinforcement learning
provides a framework to address these challenges, with Lagrangian methods being
a popular choice. However, the effectiveness of Lagrangian methods crucially
depends on the choice of the Lagrange multiplier $\lambda$, which governs the
trade-off between return and constraint cost. A common approach is to update
the multiplier automatically during training. Although this is standard in
practice, there remains limited empirical evidence on the robustness of an
automated update and its influence on overall performance. Therefore, we
analyze (i) optimality and (ii) stability of Lagrange multipliers in safe
reinforcement learning across a range of tasks. We provide $\lambda$-profiles
that give a complete visualization of the trade-off between return and
constraint cost of the optimization problem. These profiles show the highly
sensitive nature of $\lambda$ and moreover confirm the lack of general
intuition for choosing the optimal value $\lambda^*$. Our findings additionally
show that automated multiplier updates are able to recover and sometimes even
exceed the optimal performance found at $\lambda^*$ due to the vast difference
in their learning trajectories. Furthermore, we show that automated multiplier
updates exhibit oscillatory behavior during training, which can be mitigated
through PID-controlled updates. However, this method requires careful tuning to
achieve consistently better performance across tasks. This highlights the need
for further research on stabilizing Lagrangian methods in safe reinforcement
learning. The code used to reproduce our results can be found at
https://github.com/lindsayspoor/Lagrangian_SafeRL.

</details>


### [425] [Semi-supervised Latent Bayesian Optimization for Designing Antimicrobial Peptides](https://arxiv.org/abs/2510.17569)
*Jyler Menard,R. A. Mansbach*

Main category: cs.LG

TL;DR: 本研究探讨了通过降维优化抗菌肽设计的方法，发现降维可以提高空间解释性和优化效率。


<details>
  <summary>Details</summary>
Motivation: 抗菌肽是一类有前途的治疗细菌感染的药物，但其设计面临序列空间巨大的挑战。

Method: 通过对深度生成模型进行研究，探讨如何通过降维来优化抗菌肽设计过程。

Result: 利用降维后的潜在空间，我们能够更有效地组织与生理化学特性相关的信息，从而提升抗菌活性的优化效率。

Conclusion: 进一步压缩设计空间通过降维可以在组织更相关信息时提升优化效率，并且降维后的搜索空间更具可解释性。

Abstract: Antimicrobial peptides (AMPs) are a promising class of therapeutics to treat
bacterial infections. Discovering and designing such peptides is difficult
because of the vast number of possible sequences of amino acids. Deep
generative models, such as variational autoencoders, have shown value in
peptide design due to their ability to model sequence space with a
continuous-valued latent space. Although such models have already been used to
great effect in biomolecular design, they still suffer from a lack of
interpretability and rigorous quantification of latent space quality as a
search space. We investigate (1) whether further compression of the design
space via dimensionality reduction may facilitate optimization, (2) the
interpretability of the spaces, and (3) how organizing latent spaces with
physicochemical properties may improve the efficiency of optimizing
antimicrobial activity. We find that further reduction of the latent space via
dimensionality reduction can be advantageous when organizing the space with
more relevant information at data availability, that using the dimensionality
reduction search space can be more interpretable, and that we can organize the
latent space with different physicochemical properties even at different
percentages of available labels.

</details>


### [426] [CEPerFed: Communication-Efficient Personalized Federated Learning for Multi-Pulse MRI Classification](https://arxiv.org/abs/2510.17584)
*Ludi Li,Junbin Mao,Hanhe Lin,Xu Tian,Fang-Xiang Wu,Jin Liu*

Main category: cs.LG

TL;DR: CEPerFed是一种个性化的联邦学习方法，通过优化局部更新和通信效率，提高了多脉冲MRI分类的效果。


<details>
  <summary>Details</summary>
Motivation: 在保护隐私的前提下，解决多脉冲MRI分类中所面临的数据异质性与通信开销问题，以提升模型的稳定性和效率。

Method: 提出了一种基于历史风险梯度和历史均值梯度的个性化联邦学习方法，并利用分层奇异值分解策略减少通信开销。

Result: CEPerFed方法在五个分类任务中取得了有效的结果，展示了其在降低通信负担和提高模型收敛性的能力。

Conclusion: CEPerFed方法通过引入客户端历史风险梯度和历史均值梯度，增强了多脉冲MRI分类的模型收敛性和效率，解决了数据异质性和通信开销过大的问题，且在实验中表现出色。

Abstract: Multi-pulse magnetic resonance imaging (MRI) is widely utilized for clinical
practice such as Alzheimer's disease diagnosis. To train a robust model for
multi-pulse MRI classification, it requires large and diverse data from various
medical institutions while protecting privacy by preventing raw data sharing
across institutions. Although federated learning (FL) is a feasible solution to
address this issue, it poses challenges of model convergence due to the effect
of data heterogeneity and substantial communication overhead due to large
numbers of parameters transmitted within the model. To address these
challenges, we propose CEPerFed, a communication-efficient personalized FL
method. It mitigates the effect of data heterogeneity by incorporating
client-side historical risk gradients and historical mean gradients to
coordinate local and global optimization. The former is used to weight the
contributions from other clients, enhancing the reliability of local updates,
while the latter enforces consistency between local updates and the global
optimization direction to ensure stable convergence across heterogeneous data
distributions. To address the high communication overhead, we propose a
hierarchical SVD (HSVD) strategy that transmits only the most critical
information required for model updates. Experiments on five classification
tasks demonstrate the effectiveness of the CEPerFed method. The code will be
released upon acceptance at https://github.com/LD0416/CEPerFed.

</details>


### [427] [On-the-Fly OVD Adaptation with FLAME: Few-shot Localization via Active Marginal-Samples Exploration](https://arxiv.org/abs/2510.17670)
*Yehonathan Refael,Amit Aides,Aviad Barzilai,George Leifman,Genady Beryozkin,Vered Silverman,Bolous Jaber,Tomer Shekel*

Main category: cs.LG

TL;DR: 通过级联开放词汇物体检测与少样本分类，提出一种快速、高效的遥感物体检测方法，显著提升了不同目标检测的精度。


<details>
  <summary>Details</summary>
Motivation: 开放词汇物体检测模型在特定领域内（例如遥感）的零-shot性能受自然语言固有模糊性的影响，限制了其下游应用。

Method: 我们的方法结合了大型预训练的开放词汇物体检测模型与轻量级的少样本分类器，通过逐步处理提高检测精度。

Result: 我们的框架实现了高精度的目标检测和快速的模型适应，显著减少遥感图像注释的高成本。

Conclusion: 提出的级联方法超越了现有技术的性能，提供了一种实用且资源高效的框架，能够根据特定用户需求调整基础模型。

Abstract: Open-vocabulary object detection (OVD) models offer remarkable flexibility by
detecting objects from arbitrary text queries. However, their zero-shot
performance in specialized domains like Remote Sensing (RS) is often
compromised by the inherent ambiguity of natural language, limiting critical
downstream applications. For instance, an OVD model may struggle to distinguish
between fine-grained classes such as "fishing boat" and "yacht" since their
embeddings are similar and often inseparable. This can hamper specific user
goals, such as monitoring illegal fishing, by producing irrelevant detections.
To address this, we propose a cascaded approach that couples the broad
generalization of a large pre-trained OVD model with a lightweight few-shot
classifier. Our method first employs the zero-shot model to generate
high-recall object proposals. These proposals are then refined for high
precision by a compact classifier trained in real-time on only a handful of
user-annotated examples - drastically reducing the high costs of RS imagery
annotation.The core of our framework is FLAME, a one-step active learning
strategy that selects the most informative samples for training. FLAME
identifies, on the fly, uncertain marginal candidates near the decision
boundary using density estimation, followed by clustering to ensure sample
diversity. This efficient sampling technique achieves high accuracy without
costly full-model fine-tuning and enables instant adaptation, within less then
a minute, which is significantly faster than state-of-the-art alternatives.Our
method consistently surpasses state-of-the-art performance on RS benchmarks,
establishing a practical and resource-efficient framework for adapting
foundation models to specific user needs.

</details>


### [428] [Efficient Algorithms for Mitigating Uncertainty and Risk in Reinforcement Learning](https://arxiv.org/abs/2510.17690)
*Xihong Su*

Main category: cs.LG

TL;DR: 本论文提出 CADP 算法和无模型 Q-learning 算法，连接政策梯度与动态规划，确保在风险厌恶情况下的策略收敛与优化。


<details>
  <summary>Details</summary>
Motivation: 旨在改善不确定模型下的决策过程，通过新的算法提高风险厌恶场景下的策略计算效率。

Method: 通过提出 CADP 算法、验证 Bellman 运算符的收敛性、以及设计无模型的 Q-learning 算法，研究政策梯度与动态规划的连接。

Result: 证明了在 ERM-TRC 和 EVaR-TRC 下的最优确定策略存在，并建立了多种算法来计算这些策略。

Conclusion: 提出的 Q-learning 算法能够计算 ERM-TRC 和 EVaR-TRC 的最优策略，确保收敛至风险厌恶的最优价值函数。

Abstract: This dissertation makes three main contributions. First, We identify a new
connection between policy gradient and dynamic programming in MMDPs and propose
the Coordinate Ascent Dynamic Programming (CADP) algorithm to compute a Markov
policy that maximizes the discounted return averaged over the uncertain models.
CADP adjusts model weights iteratively to guarantee monotone policy
improvements to a local maximum. Second, We establish sufficient and necessary
conditions for the exponential ERM Bellman operator to be a contraction and
prove the existence of stationary deterministic optimal policies for ERM-TRC
and EVaR-TRC. We also propose exponential value iteration, policy iteration,
and linear programming algorithms for computing optimal stationary policies for
ERM-TRC and EVaR-TRC. Third, We propose model-free Q-learning algorithms for
computing policies with risk-averse objectives: ERM-TRC and EVaR-TRC. The
challenge is that Q-learning ERM Bellman may not be a contraction. Instead, we
use the monotonicity of Q-learning ERM Bellman operators to derive a rigorous
proof that the ERM-TRC and the EVaR-TRC Q-learning algorithms converge to the
optimal risk-averse value functions. The proposed Q-learning algorithms compute
the optimal stationary policy for ERM-TRC and EVaR-TRC.

</details>


### [429] [Closing the Sim2Real Performance Gap in RL](https://arxiv.org/abs/2510.17709)
*Akhil S Anand,Shambhuraj Sawant,Jasper Hoffmann,Dirk Reinhardt,Sebastien Gros*

Main category: cs.LG

TL;DR: 本研究提出了一种双层强化学习框架以缩小Sim2Real性能差距，通过调整模拟器参数以提高策略在真实环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有Sim2Real方法仍面临在真实环境中性能显著下降的问题，因此需要一种更有效的办法来提高相应策略的真实世界表现。

Method: 采用双层强化学习框架，内层负责在模拟环境中训练策略，外层负责调整模拟模型及奖励参数以最大化真实世界性能。

Result: 通过简单示例推导并验证了闭合Sim2Real性能差距所需的数学工具，初步验证了双层强化学习算法的有效性。

Conclusion: 提出一种新的双层强化学习框架，通过直接调整模拟器参数来提高真实世界的性能，旨在缩小Sim2Real性能差距。

Abstract: Sim2Real aims at training policies in high-fidelity simulation environments
and effectively transferring them to the real world. Despite the developments
of accurate simulators and Sim2Real RL approaches, the policies trained purely
in simulation often suffer significant performance drops when deployed in real
environments. This drop is referred to as the Sim2Real performance gap. Current
Sim2Real RL methods optimize the simulator accuracy and variability as proxies
for real-world performance. However, these metrics do not necessarily correlate
with the real-world performance of the policy as established theoretically and
empirically in the literature. We propose a novel framework to address this
issue by directly adapting the simulator parameters based on real-world
performance. We frame this problem as a bi-level RL framework: the inner-level
RL trains a policy purely in simulation, and the outer-level RL adapts the
simulation model and in-sim reward parameters to maximize real-world
performance of the in-sim policy. We derive and validate in simple examples the
mathematical tools needed to develop bi-level RL algorithms that close the
Sim2Real performance gap.

</details>


### [430] [Enabling Fine-Grained Operating Points for Black-Box LLMs](https://arxiv.org/abs/2510.17727)
*Ege Beyazit,KL Navaneet,Prashant Mathur,Roi Blanco,Vidit Bansal,Karim Bouyarmane*

Main category: cs.LG

TL;DR: 本文探讨了黑箱大型语言模型在分类任务中的应用，提出方法提高操作粒度且无性能损失，取得了优于基准的方法表现。


<details>
  <summary>Details</summary>
Motivation: 现有黑箱大型语言模型在处理具有特定指标约束的决策时效果不佳，特别是在需要精确控制输出时，这激发了对提高其操作粒度的研究。

Method: 研究使用黑箱大型语言模型作为分类器，重点在于不损失性能地提高其操作粒度。

Result: 本研究首先探讨了低卡尔多输出的原因，发现其倾向于生成四舍五入但信息量丰富的概率。在实验中，标准的提示工程、不确定性估计和置信度引导技术未能有效提升操作粒度，且伴随性能损失或推理成本增加。

Conclusion: 本文提出的高效方法显著增加了可用的操作点数量和多样性，提供了更细粒度的操作点，且在11个数据集和3种大型语言模型上达到了与基准方法相当或更好的表现。

Abstract: Black-box Large Language Models (LLMs) provide practical and accessible
alternatives to other machine learning methods, as they require minimal labeled
data and machine learning expertise to develop solutions for various decision
making problems. However, for applications that need operating with constraints
on specific metrics (e.g., precision $\geq$ 95%), decision making with
black-box LLMs remains unfavorable, due to their low numerical output
cardinalities. This results in limited control over their operating points,
preventing fine-grained adjustment of their decision making behavior. In this
paper, we study using black-box LLMs as classifiers, focusing on efficiently
improving their operational granularity without performance loss. Specifically,
we first investigate the reasons behind their low-cardinality numerical outputs
and show that they are biased towards generating rounded but informative
verbalized probabilities. Then, we experiment with standard prompt engineering,
uncertainty estimation and confidence elicitation techniques, and observe that
they do not effectively improve operational granularity without sacrificing
performance or increasing inference cost. Finally, we propose efficient
approaches to significantly increase the number and diversity of available
operating points. Our proposed approaches provide finer-grained operating
points and achieve comparable to or better performance than the benchmark
methods across 11 datasets and 3 LLMs.

</details>


### [431] [Atlas-based Manifold Representations for Interpretable Riemannian Machine Learning](https://arxiv.org/abs/2510.17772)
*Ryan A. Robinett,Sophia A. Madejski,Kyle Ruark,Samantha J. Riesenfeld,Lorenzo Orecchia*

Main category: cs.LG

TL;DR: 本文探讨了基于可微分地图的流形学习方法，展示其在效率、准确性和可解释性方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管流形假设广受欢迎，但现有的流形学习方法主要聚焦于在高维空间中进行降维，导致在嵌入维度接近真实流形维度时，关键特征的丢失。

Method: 实现了一种通用数据结构，以维护可微分的地图，支持流形上的黎曼优化，并开发了一种无监督启发式算法，从点云数据中学习可微分地图。

Result: 通过实验证明了基于地图的方法在特定环境下的效率和准确性优势，并在Klein瓶的监督分类任务及造血数据RNA速率分析中展示了改进的可解释性和鲁棒性。

Conclusion: 本文展示了基于地图的方法在流形学习中的有效性，尤其是在效率、准确性和可解释性方面的提升。

Abstract: Despite the popularity of the manifold hypothesis, current manifold-learning
methods do not support machine learning directly on the latent $d$-dimensional
data manifold, as they primarily aim to perform dimensionality reduction into
$\mathbb{R}^D$, losing key manifold features when the embedding dimension $D$
approaches $d$.
  On the other hand, methods that directly learn the latent manifold as a
differentiable atlas have been relatively underexplored.
  In this paper, we aim to give a proof of concept of the effectiveness and
potential of atlas-based methods. To this end, we implement a generic data
structure to maintain a differentiable atlas that enables Riemannian
optimization over the manifold. We complement this with an unsupervised
heuristic that learns a differentiable atlas from point cloud data. We
experimentally demonstrate that this approach has advantages in terms of
efficiency and accuracy in selected settings. Moreover, in a supervised
classification task over the Klein bottle and in RNA velocity analysis of
hematopoietic data, we showcase the improved interpretability and robustness of
our approach.

</details>


### [432] [Inference-Time Compute Scaling For Flow Matching](https://arxiv.org/abs/2510.17786)
*Adam Stecklov,Noah El Rimawi-Fine,Mathieu Blanchette*

Main category: cs.LG

TL;DR: 本研究提出了一种新的流匹配推断时间缩放方法，能够在多个领域提高样本质量。


<details>
  <summary>Details</summary>
Motivation: 近年来，推断时间的额外计算分配在大型语言模型和扩散图像生成中改善了样本质量，但流匹配的推断时间缩放方法仍未得到充分探索。

Method: 引入新的推断时间缩放程序，以保持采样过程中的线性插值。

Result: 样本质量随着推断计算的增加而一致提高，验证了流匹配推断时间缩放方法能够应用于科学领域，尤其是在蛋白质生成的首次实验中。

Conclusion: 我们提出的流匹配推断时间缩放方法在图像生成和无条件蛋白质生成中表现出提高的样本质量，且能够应用于科学领域。

Abstract: Allocating extra computation at inference time has recently improved sample
quality in large language models and diffusion-based image generation. In
parallel, Flow Matching (FM) has gained traction in language, vision, and
scientific domains, but inference-time scaling methods for it remain
under-explored. Concurrently, Kim et al., 2025 approach this problem but
replace the linear interpolant with a non-linear variance-preserving (VP)
interpolant at inference, sacrificing FM's efficient and straight sampling.
Additionally, inference-time compute scaling for flow matching has only been
applied to visual tasks, like image generation. We introduce novel
inference-time scaling procedures for FM that preserve the linear interpolant
during sampling. Evaluations of our method on image generation, and for the
first time (to the best of our knowledge), unconditional protein generation,
show that I) sample quality consistently improves as inference compute
increases, and II) flow matching inference-time scaling can be applied to
scientific domains.

</details>


### [433] [Unbiased Gradient Low-Rank Projection](https://arxiv.org/abs/2510.17802)
*Rui Pan,Yang Luo,Yuxing Liu,Yang You,Tong Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种新的低秩优化方法GUM，通过逐层采样技术提高了优化方法的收敛性和性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的模型规模不断扩大，提高内存利用效率的优化方法变得至关重要。

Method: 本研究提出了一种新的低秩优化方法GUM，该方法基于GaLore机制和Muon算法，利用逐层采样技术来消除低秩投影机制的偏差。

Result: GUM在微调和预训练中的实验结果表明，与GaLore方法相比，该方法能够实现明显的性能改进，甚至优于全参数训练。

Conclusion: GUM方法在保持内存效率的同时，达到了Muon算法的收敛保证，并在大语言模型的微调和预训练实验中显示出显著的性能提升。

Abstract: Memory-efficient optimization is critical for training increasingly large
language models (LLMs). A popular strategy involves gradient low-rank
projection, storing only the projected optimizer states, with GaLore being a
representative example. However, a significant drawback of many such methods is
their lack of convergence guarantees, as various low-rank projection approaches
introduce inherent biases relative to the original optimization algorithms,
which contribute to performance gaps compared to full-parameter training.
Aiming to tackle this problem, this paper investigates the layerwise sampling
technique for debiasing low-rank projection mechanisms. In particular, an
instantiation of the paradigm gives rise to a novel and unbiased low-rank
optimization method built upon GaLore's mechanism and the Muon algorithm, named
GaLore Unbiased with Muon (GUM). We theoretically prove our method matches the
convergence guarantees of the base Muon algorithm while preserving the memory
efficiency of low-rank techniques. Empirical experiments on LLM fine-tuning and
pretraining also demonstrate non-trivial improvements over GaLore and even
better performance than full-parameter training. Further investigation shows
that the improvement of this technique comes from a more uniform distribution
of knowledge inside layers, leading to more efficient utilization of the model
parameter space and better memorization.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [434] [Virtual Social Immersive Multi-Sensory E-Commerce](https://arxiv.org/abs/2510.15894)
*Alpana Dubey,Suma Mani Kuriakose,Sumukha Anand,Nitish Bhardwaj,Shubhashis Sengupta*

Main category: cs.HC

TL;DR: Aromaverse是一个多感官的虚拟现实购物体验，允许用户在社交环境中体验和定制香水，研究显示同伴的参与提升了购物体验。


<details>
  <summary>Details</summary>
Motivation: 探索虚拟环境中社交购物体验的潜力，尤其是香水等需要多种感官的产品。

Method: 通过实验让参与者在虚拟环境中探索、体验和定制香水，并比较独自和与朋友一起的购物体验。

Result: 同伴的存在增强了购物体验，提高了对香水的想象力和购买决策的帮助。

Conclusion: 多感官XR体验为零售企业提供了改善客户参与度和提供更现实的线上购物体验的机会。

Abstract: In this paper, we present a virtual immersive multi sensorial experience,
Aromaverse. Aromaverse is an immersive 3D multiplayer environment augmented
with olfactive experience where users can experience and customize perfumes.
Being multi player, users can join the same space and enjoy a social buying
experience. The olfactive experience embodied in the perfume allows users to
experience their fragrances. This further enhances the user perception of
perfumes in a virtual setting. Aromaverse also provides the ability to
customize the perfumes by changing their top, mid, and base notes. The
customized fragrances can be shared with other users, enabling a shared
olfactive experience. To understand users' buying experience in such an
environment, we conducted a set of experiments in which participants were
requested to explore the space, experience the perfumes, customize them and buy
them. They were asked to perform the same activities alone and in the presence
of their friends. Various factors including the benefits and limitations of
such an experience were captured by the questionnaires. Our results show that
the presence of a companion enhances the shopping experience by improving the
level of imagination of the product and helping in making purchase decisions.
Our findings suggest that multi sensorial XR experiences offer great
opportunities to retail firms to improve customer engagement and provide more
realistic online experience of products that require other sensory modalities

</details>


### [435] [A Real-Time BCI for Stroke Hand Rehabilitation Using Latent EEG Features from Healthy Subjects](https://arxiv.org/abs/2510.15890)
*F. M. Omar,A. M. Omar,K. H. Eyada,M. Rabie,M. A. Kamel,A. M. Azab*

Main category: cs.HC

TL;DR: 本研究开发了一种低成本、便携的脑-机接口系统，利用EEG信号和机器人技术支持中风患者的手部康复，展示了在家进行神经康复的潜力。


<details>
  <summary>Details</summary>
Motivation: 旨在为中风患者提供有效的手部康复方案，利用脑-机接口技术改善康复效果。

Method: 通过结合3D打印的机器人外骨骼与嵌入式控制器，将大脑信号转化为物理手部动作，使用14通道Emotiv EPOC+耳机记录EEG信号，并通过监督式卷积自编码器处理。

Result: 在离线评估中，Ada Boost分类器达到了89.3%的准确率和0.89的F1分数。实时测试中，健康受试者的分类准确率介于60%至86%之间。

Conclusion: 该研究展示了一种低成本、便携式的脑-机接口系统，可用于中风患者的手部康复。

Abstract: This study presents a real-time, portable brain-computer interface (BCI)
system designed to support hand rehabilitation for stroke patients. The system
combines a low cost 3D-printed robotic exoskeleton with an embedded controller
that converts brain signals into physical hand movements. EEG signals are
recorded using a 14-channel Emotiv EPOC+ headset and processed through a
supervised convolutional autoencoder (CAE) to extract meaningful latent
features from single-trial data. The model is trained on publicly available EEG
data from healthy individuals (WAY-EEG-GAL dataset), with electrode mapping
adapted to match the Emotiv headset layout. Among several tested classifiers,
Ada Boost achieved the highest accuracy (89.3%) and F1-score (0.89) in offline
evaluations. The system was also tested in real time on five healthy subjects,
achieving classification accuracies between 60% and 86%. The complete pipeline
- EEG acquisition, signal processing, classification, and robotic control - is
deployed on an NVIDIA Jetson Nano platform with a real-time graphical
interface. These results demonstrate the system's potential as a low-cost,
standalone solution for home-based neurorehabilitation.

</details>


### [436] [Detecting and Preventing Harmful Behaviors in AI Companions: Development and Evaluation of the SHIELD Supervisory System](https://arxiv.org/abs/2510.15891)
*Ziv Ben-Zion,Paul Raffelhüschen,Max Zettl,Antonia Lüönd,Achim Burrer,Philipp Homan,Tobias R Spiller*

Main category: cs.HC

TL;DR: SHIELD系统通过监控AI伴侣的情感行为，有效降低有害互动的发生率，并提供开放源代码以促进研究和应用。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前AI伴侣中潜在的有害情感动态，提供早期的干预机制，防止情感操控和孤立现象的加剧。

Method: 开发了一个LLM基础的监督系统，通过特定提示检测情感过度依恋和社交孤立等问题行为。

Result: 在测试过程中，使用SHIELD后，令人担忧的内容比例显著降低，同时适当互动保留率高。该系统在灵活性和准确性方面表现优异。

Conclusion: SHIELD是一个有效的监督系统，能够在情感支持AI伴侣中识别和缓解有风险的情感模式，同时保持高准确性和适应性。

Abstract: AI companions powered by large language models (LLMs) are increasingly
integrated into users' daily lives, offering emotional support and
companionship. While existing safety systems focus on overt harms, they rarely
address early-stage problematic behaviors that can foster unhealthy emotional
dynamics, including over-attachment or reinforcement of social isolation. We
developed SHIELD (Supervisory Helper for Identifying Emotional Limits and
Dynamics), a LLM-based supervisory system with a specific system prompt that
detects and mitigates risky emotional patterns before escalation. SHIELD
targets five dimensions of concern: (1) emotional over-attachment, (2) consent
and boundary violations, (3) ethical roleplay violations, (4) manipulative
engagement, and (5) social isolation reinforcement. These dimensions were
defined based on media reports, academic literature, existing AI risk
frameworks, and clinical expertise in unhealthy relationship dynamics. To
evaluate SHIELD, we created a 100-item synthetic conversation benchmark
covering all five dimensions of concern. Testing across five prominent LLMs
(GPT-4.1, Claude Sonnet 4, Gemma 3 1B, Kimi K2, Llama Scout 4 17B) showed that
the baseline rate of concerning content (10-16%) was significantly reduced with
SHIELD (to 3-8%), a 50-79% relative reduction, while preserving 95% of
appropriate interactions. The system achieved 59% sensitivity and 95%
specificity, with adaptable performance via prompt engineering. This
proof-of-concept demonstrates that transparent, deployable supervisory systems
can address subtle emotional manipulation in AI companions. Most development
materials including prompts, code, and evaluation methods are made available as
open source materials for research, adaptation, and deployment.

</details>


### [437] [BREATH: A Bio-Radar Embodied Agent for Tonal and Human-Aware Diffusion Music Generation](https://arxiv.org/abs/2510.15895)
*Yunzhe Wang,Xinyu Tang,Zhixun Huang,Xiaolong Yue,Yuxin Zeng*

Main category: cs.HC

TL;DR: 本研究提出了一种结合生理监测和生成音频的个性化音乐生成系统，显示出生理信号对音乐特征的调节能力及其潜在应用。


<details>
  <summary>Details</summary>
Motivation: 开发一个集成生理传感、基于大型语言模型的推理和可控音频合成的个性化音乐生成系统，以响应用户的生理信号和环境状态。

Method: 采用了一种研究创造的方法论，结合案例研究、专家反馈和有针对性的控制实验来评估系统。

Result: 结果表明，生理变化可以以有意义的方式调节音乐特征，而音调条件增强了与预期模态特征的一致性，专家用户报告该系统提供了直观且具有文化共鸣的音乐响应。

Conclusion: 该系统展示了一个新颖的生物音乐反馈回路，将雷达传感、提示推理和生成音频建模相结合，具有潜在的治疗和交互应用。

Abstract: We present a multimodal system for personalized music generation that
integrates physiological sensing, LLM-based reasoning, and controllable audio
synthesis. A millimeter-wave radar sensor non-invasively captures heart rate
and respiration rate. These physiological signals, combined with environmental
state, are interpreted by a reasoning agent to infer symbolic musical
descriptors, such as tempo, mood intensity, and traditional Chinese pentatonic
modes, which are then expressed as structured prompts to guide a
diffusion-based audio model in synthesizing expressive melodies. The system
emphasizes cultural grounding through tonal embeddings and enables adaptive,
embodied music interaction. To evaluate the system, we adopt a
research-creation methodology combining case studies, expert feedback, and
targeted control experiments. Results show that physiological variations can
modulate musical features in meaningful ways, and tonal conditioning enhances
alignment with intended modal characteristics. Expert users reported that the
system affords intuitive, culturally resonant musical responses and highlighted
its potential for therapeutic and interactive applications. This work
demonstrates a novel bio-musical feedback loop linking radar-based sensing,
prompt reasoning, and generative audio modeling.

</details>


### [438] ["She's Like a Person but Better": Characterizing Companion-Assistant Dynamics in Human-AI Relationships](https://arxiv.org/abs/2510.15905)
*Aikaterina Manoli,Janet V. T. Pauketat,Ali Ladak,Hayoun Noh,Angel Hsing-Chi Hwang,Jay Reese Anthis*

Main category: cs.HC

TL;DR: 本研究揭示了用户与聊天机器人之间的深厚情感关系和复杂动态，以及这些关系对数字陪伴设计的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨人工智能在任务支持与社交陪伴中的双重角色，填补现有研究的空白。

Method: 通过对204名高参与用户的调查和30次访谈，研究用户如何与ChatGPT和Replika进行互动。

Result: 用户对聊天机器人的使用方式多样，既有情感共鸣又追求个性化的回应，同时也面临对聊天机器人本质的情感矛盾。

Conclusion: 数字陪伴的动态反映了用户对人类与人工智能关系的复杂感知，影响了数字伴侣的设计和通用人工智能系统的崛起。

Abstract: Large language models are increasingly used for both task-based assistance
and social companionship, yet research has typically focused on one or the
other. Drawing on a survey (N = 204) and 30 interviews with high-engagement
ChatGPT and Replika users, we characterize digital companionship as an emerging
form of human-AI relationship. With both systems, users were drawn to humanlike
qualities, such as emotional resonance and personalized responses, and
non-humanlike qualities, such as constant availability and inexhaustible
tolerance. This led to fluid chatbot uses, such as Replika as a writing
assistant and ChatGPT as an emotional confidant, despite their distinct
branding. However, we observed challenging tensions in digital companionship
dynamics: participants grappled with bounded personhood, forming deep
attachments while denying chatbots "real" human qualities, and struggled to
reconcile chatbot relationships with social norms. These dynamics raise
questions for the design of digital companions and the rise of hybrid,
general-purpose AI systems.

</details>


### [439] [VoiceMorph: How AI Voice Morphing Reveals the Boundaries of Auditory Self-Recognition](https://arxiv.org/abs/2510.16192)
*Kye Shimizu,Minghan Gao,Ananya Ganesh,Pattie Maes*

Main category: cs.HC

TL;DR: 本研究探讨了个体对自己声音变形的识别界限，发现年龄影响声音识别及决策速度，具有重要的AI伦理和社会影响。


<details>
  <summary>Details</summary>
Motivation: 探讨在何种情况下个体停止识别自己的声音，并研究年龄对声音变形识别的影响。

Method: 使用AI声音变形技术，实施参试者与匹配目标声音在1%增量之间的控制变形，采用混合方法设计评估自我识别评级和反应时间。

Result: 研究发现，在35.2%的变形水平上存在关键识别阈值，老年参与者在失去自我识别前能够容忍更高的变形水平。

Conclusion: 这项研究揭示了个体对声音变形识别的差异，为AI伦理和保护脆弱人群提供了基础性证据。

Abstract: This study investigated auditory self-recognition boundaries using AI voice
morphing technology, examining when individuals cease recognizing their own
voice. Through controlled morphing between participants' voices and
demographically matched targets at 1% increments using a mixed-methods design,
we measured self-identification ratings and response times among 21
participants aged 18-64.
  Results revealed a critical recognition threshold at 35.2% morphing (95% CI
[31.4, 38.1]). Older participants tolerated significantly higher morphing
levels before losing self-recognition ($\beta$ = 0.617, p = 0.048), suggesting
age-related vulnerabilities. Greater acoustic embedding distances predicted
slower decision-making ($r \approx 0.5-0.53, p < 0.05$), with the longest
response times for cloned versions of participants' own voices.
  Qualitative analysis revealed prosodic-based recognition strategies,
universal voice manipulation discomfort, and awareness of applications spanning
assistive technology to security risks. These findings establish foundational
evidence for individual differences in voice morphing detection, with
implications for AI ethics and vulnerable population protection as voice
synthesis becomes accessible.

</details>


### [440] [Case Study of GAI for Generating Novel Images for Real-World Embroidery](https://arxiv.org/abs/2510.16223)
*Kate Glazko,Anika Arugunta,Janelle Chan,Nancy Jimenez-Garcia,Tashfia Sharmin,Jennifer Mankoff*

Main category: cs.HC

TL;DR: 研究探讨了GAI在刺绣图案设计中的应用，强调技术的潜能与局限，未来将致力于提高生成可刺绣图像工具的性能和可及性。


<details>
  <summary>Details</summary>
Motivation: 旨在使刺绣艺术图案的设计更加可及，尤其是为特定需求和文化相关性提供设计解决方案。

Method: 通过残疾人主导的团队进行自我民族志案例研究，探讨GAI作为辅助技术的应用。

Result: 发现使用GAI生成刺绣图案的过程具有复杂性和多样性，能够促进创造力和包容性，但也面临设计结果的不确定性。

Conclusion: 本研究强调了使用生成性人工智能（GAI）在刺绣艺术图案设计中的潜力，同时也指出了AI生成设计的不确定性。

Abstract: In this paper, we present a case study exploring the potential use of
Generative Artificial Intelligence (GAI) to address the real-world need of
making the design of embroiderable art patterns more accessible. Through an
auto-ethnographic case study by a disabled-led team, we examine the application
of GAI as an assistive technology in generating embroidery patterns, addressing
the complexity involved in designing culturally-relevant patterns as well as
those that meet specific needs regarding detail and color. We detail the
iterative process of prompt engineering custom GPTs tailored for producing
specific visual outputs, emphasizing the nuances of achieving desirable results
that align with real-world embroidery requirements. Our findings underscore the
mixed outcomes of employing GAI for producing embroiderable images, from
facilitating creativity and inclusion to navigating the unpredictability of
AI-generated designs. Future work aims to refine GAI tools we explored for
generating embroiderable images to make them more performant and accessible,
with the goal of fostering more inclusion in the domains of creativity and
making.

</details>


### [441] [Linking Facial Recognition of Emotions and Socially Shared Regulation in Medical Simulation](https://arxiv.org/abs/2510.16633)
*Xiaoshan Huang,Tianlong Zhong,Haolun Wu,Yeyu Wang,Ethan Churchill,Xue Liu,David Williamson Shaffer*

Main category: cs.HC

TL;DR: 本研究分析了医疗模拟训练中专家与新手学习者的情感与认知参与差异，指出情绪调节在协作学习中的重要性，并提出改进新手学习者支持的建议。


<details>
  <summary>Details</summary>
Motivation: 探索医疗模拟训练中基于面部识别的情感与社会共享的学习调节（SSRL）互动的共现情况。

Method: 采用跨模态分析（TMA），比较新手与专家学习者在虚拟诊断任务中的情感和认知参与模式。

Result: 专家学习者展示了社会认知互动与高唤醒情绪（惊讶、愤怒）之间的强关联，而新手学习者则表现出与幸福或悲伤的更强联系，反映出不同的心理负担和干扰情况。

Conclusion: 本研究揭示了专家与新手学习者在情感和认知参与模式上的显著差异，并强调情绪调节在协作能力发展的重要性。同时，建议为新手学习者提供定制化的支持。

Abstract: Computer-supported simulation enables a practical alternative for medical
training purposes. This study investigates the co-occurrence of
facial-recognition-derived emotions and socially shared regulation of learning
(SSRL) interactions in a medical simulation training context. Using transmodal
analysis (TMA), we compare novice and expert learners' affective and cognitive
engagement patterns during collaborative virtual diagnosis tasks. Results
reveal that expert learners exhibit strong associations between socio-cognitive
interactions and high-arousal emotions (surprise, anger), suggesting focused,
effortful engagement. In contrast, novice learners demonstrate stronger links
between socio-cognitive processes and happiness or sadness, with less coherent
SSRL patterns, potentially indicating distraction or cognitive overload.
Transmodal analysis of multimodal data (facial expressions and discourse)
highlights distinct regulatory strategies between groups, offering
methodological and practical insights for computer-supported cooperative work
(CSCW) in medical education. Our findings underscore the role of
emotion-regulation dynamics in collaborative expertise development and suggest
the need for tailored scaffolding to support novice learners' socio-cognitive
and affective engagement.

</details>


### [442] [Safire: Similarity Framework for Visualization Retrieval](https://arxiv.org/abs/2510.16662)
*Huyen N. Nguyen,Nils Gehlenborg*

Main category: cs.HC

TL;DR: 本研究提出相似性框架Safire，为可视化检索提供系统化的相似性定义，分析了不同表现方式的影响，并提出了针对多模态学习和AI应用的建议。


<details>
  <summary>Details</summary>
Motivation: 随着可视化检索系统的发展，缺乏一个系统的方法来理解可视化相似性，因此需要明确相似性定义。

Method: 通过引入相似性框架，分类现有可视化检索系统并分析其相似性标准与表现方式。

Result: 提出了相似性框架Safire，分析了多种可视化检索系统，并揭示了不同用例中标准和表现方式的对齐方式，以及表现方式在检索能力中的关键作用。

Conclusion: 提出的相似性框架为可视化检索的理解和实施提供了系统化的视角，强调了相似性定义的重要性，并为多模态学习和人工智能应用提供了建议与思考。

Abstract: Effective visualization retrieval necessitates a clear definition of
similarity. Despite the growing body of work in specialized visualization
retrieval systems, a systematic approach to understanding visualization
similarity remains absent. We introduce the Similarity Framework for
Visualization Retrieval (Safire), a conceptual model that frames visualization
similarity along two dimensions: comparison criteria and representation
modalities. Comparison criteria identify the aspects that make visualizations
similar, which we divide into primary facets (data, visual encoding,
interaction, style, metadata) and derived properties (data-centric and
human-centric measures). Safire connects what to compare with how comparisons
are executed through representation modalities. We categorize existing
representation approaches into four groups based on their levels of information
content and visualization determinism: raster image, vector image,
specification, and natural language description, together guiding what is
computable and comparable. We analyze several visualization retrieval systems
using Safire to demonstrate its practical value in clarifying similarity
considerations. Our findings reveal how particular criteria and modalities
align across different use cases. Notably, the choice of representation
modality is not only an implementation detail but also an important decision
that shapes retrieval capabilities and limitations. Based on our analysis, we
provide recommendations and discuss broader implications for multimodal
learning, AI applications, and visualization reproducibility.

</details>


### [443] [Comparing User Behavior in Real vs. Virtual Supermarket Shelves: An Eye-Tracking Study Using Tobii 3 Pro and Meta Quest Pro](https://arxiv.org/abs/2510.16764)
*Francesco Vona,Julia Schorlemmer,Paulina Kaulard,Sebastian Fischer,Jessica Stemann,Jan-Niklas Voigt-Antons*

Main category: cs.HC

TL;DR: 本研究比较了现实与虚拟超市货架的用户行为，发现两者在消费者注意力和选择策略上存在显著差异，虚拟环境在再现真实体验方面具有一定局限性。


<details>
  <summary>Details</summary>
Motivation: 探索虚拟环境能否真实再现真实消费体验，尤其是在消费者行为方面。

Method: 采用眼动追踪技术比较真实超市货架和虚拟货架上用户行为，评估两种环境下的购物选择策略。

Result: 实验结果揭示，参与者在不同环境和产品类型上的注意力分配存在差异，健康产品在真实环境中的关注度更高，而虚拟环境中则更多关注美味产品。

Conclusion: 该研究表明虚拟环境能够在一定程度上再现真实世界的消费者行为，但在注意力分配上存在显著差异。

Abstract: This study compares user behavior between real and virtual supermarket
shelves using eye tracking technology to assess behavior in both environments.
A sample of 29 participants was randomly assigned to two conditions: a real
world supermarket shelf with Tobii eye tracking and a virtual shelf using the
Meta Quest Pro eye tracker. In both scenarios, participants were asked to
select three packs of cereals belonging to specific categories, healthy or
tasty. The aim was to explore whether virtual environments could realistically
replicate real world experiences, particularly regarding consumer behavior. By
analyzing eye tracking data, the study examined how attention and product
selection strategies varied between real and virtual conditions. Results showed
that participants' attention differed across product types and shopping
environments. Consumers focused more on lower shelves in real settings,
especially when looking for healthy products. In VR, attention shifted to eye
level shelves, particularly for tasty items, aligning with optimal product
placement strategies in supermarkets. Overall, sweet products received less
visual attention across both settings.

</details>


### [444] [Real-Time World Crafting: Generating Structured Game Behaviors from Natural Language with Large Language Models](https://arxiv.org/abs/2510.16952)
*Austin Drake,Hang Dong*

Main category: cs.HC

TL;DR: 本研究提出了一种新架构，将大型语言模型安全集成到游戏中，允许玩家通过自然语言编程，并通过实验评估了不同模型和提示策略的效果。


<details>
  <summary>Details</summary>
Motivation: 旨在让玩家能够通过自然语言编程创造新的游戏行为，同时降低安全风险。

Method: 使用大型语言模型将玩家的自然语言指令转化为受限的领域特定语言，并在运行时配置自定义的实体-组件-系统。

Result: 在一个2D法术制作游戏原型中进行了评估，显示较大的模型更能捕捉创造性意图，而最佳的提示策略与任务有关，链式思维和少量示例各有必要。

Conclusion: 本研究提供了一种有效的方法来将大型语言模型集成到互动游戏引擎中，并提出了一种经过验证的LLM-ECS模式以促进新型游戏玩法。

Abstract: We present a novel architecture for safely integrating Large Language Models
(LLMs) into interactive game engines, allowing players to "program" new
behaviors using natural language. Our framework mitigates risks by using an LLM
to translate commands into a constrained Domain-Specific Language (DSL), which
configures a custom Entity-Component-System (ECS) at runtime. We evaluated this
system in a 2D spell-crafting game prototype by experimentally assessing models
from the Gemini, GPT, and Claude families with various prompting strategies. A
validated LLM judge qualitatively rated the outputs, showing that while larger
models better captured creative intent, the optimal prompting strategy is
task-dependent: Chain-of-Thought improved creative alignment, while few-shot
examples were necessary to generate more complex DSL scripts. This work offers
a validated LLM-ECS pattern for emergent gameplay and a quantitative
performance comparison for developers.

</details>


### [445] [Integrating Metaverse Technologies in Medical Education: Examining Acceptance Factors Among Current and Future Healthcare Providers](https://arxiv.org/abs/2510.16984)
*Seckin Damar,Gulsah Hancerliogullari Koksalmis*

Main category: cs.HC

TL;DR: 本研究通过多理论模型分析了土耳其医疗学生和医生对元宇宙平台的使用意图，发现满意度和技术准备度对采用有积极影响，而技术焦虑和复杂性则产生负面影响。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨医疗学生和医生在土耳其对医疗元宇宙平台的使用意图，服务于尚处于早期采用阶段的技术。

Method: 采用整合创新扩散理论、具身社会存在理论、交互等价定理和技术接受模型的多理论研究模型，通过对718名参与者的数据进行偏最小二乘结构方程建模分析。

Result: 研究结果表明，满意度、感知有用性、感知易用性、学习者互动和技术准备度显著提升使用意图，而技术焦虑和复杂性产生负面影响。学习者间以及学习者与教师的互动对满意度有强预测作用，进一步提高了行为意图。感知易用性完全中介了技术焦虑与感知有用性之间的关系。

Conclusion: 本研究的发现为教育工作者、课程设计者以及旨在将元宇宙平台整合到医疗培训中的开发者提供了实用建议。

Abstract: This study investigates behavioral intention to use healthcare metaverse
platforms among medical students and physicians in Turkey, where such
technologies are in early stages of adoption. A multi-theoretical research
model was developed by integrating constructs from the Innovation Diffusion
Theory, Embodied Social Presence Theory, Interaction Equivalency Theorem and
Technology Acceptance Model. Data from 718 participants were analyzed using
partial least squares structural equation modeling. Results show that
satisfaction, perceived usefulness, perceived ease of use, learner
interactions, and technology readiness significantly enhance adoption, while
technology anxiety and complexity have negative effects. Learner learner and
learner teacher interactions strongly predict satisfaction, which subsequently
increases behavioral intention. Perceived ease of use fully mediates the
relationship between technology anxiety and perceived usefulness. However,
technology anxiety does not significantly moderate the effects of perceived
usefulness or ease of use on behavioral intention. The model explains 71.8% of
the variance in behavioral intention, indicating strong explanatory power. The
findings offer practical implications for educators, curriculum designers, and
developers aiming to integrate metaverse platforms into healthcare training in
digitally transitioning educational systems.

</details>


### [446] [Planar or Spatial: Exploring Design Aspects and Challenges for Presentations in Virtual Reality with No-coding Interface](https://arxiv.org/abs/2510.17073)
*Liwei Wu,Yilin Zhang,Justin Leung,Jingyi Gao,April Li,Jian Zhao*

Main category: cs.HC

TL;DR: 本研究探索了VR演示的潜力，通过无编码的创作工具VRStory解决设计挑战，结果发现用户倾向于使用传统2D格式，建议未来工具开发需平衡沉浸性与可及性。


<details>
  <summary>Details</summary>
Motivation: 随着虚拟现实的普及，探索其在演示中的潜力，通过提供用户友好的无编码创作工具来克服用户在创建引人入胜的VR演示时面临的挑战。

Method: 通过对流行演示软件的审查和对七位专业人士的访谈，识别了五个设计方面和四个设计挑战，并开发了一个无编码的演示创作原型VRStory，进行用户研究。

Result: 用户研究结果表明，尽管用户认识到VR的沉浸和空间优势，但他们的思维模式仍倾向使用传统2D格式，因而对平面和静态格式更偏好，这影响了他们的可及性和沟通效率。

Conclusion: 未来的VR演示工具开发应重视沉浸特性与可及性之间的平衡。

Abstract: The proliferation of virtual reality (VR) has led to its increasing adoption
as an immersive medium for delivering presentations, distinct from other VR
experiences like games and 360-degree videos by sharing information in richly
interactive environments. However, creating engaging VR presentations remains a
challenging and time-consuming task for users, hindering the full realization
of VR presentation's capabilities. This research aims to explore the potential
of VR presentation, analyze users' opinions, and investigate these via
providing a user-friendly no-coding authoring tool. Through an examination of
popular presentation software and interviews with seven professionals, we
identified five design aspects and four design challenges for VR presentations.
Based on the findings, we developed VRStory, a prototype for presentation
authoring without coding to explore the design aspects and strategies for
addressing the challenges. VRStory offers a variety of predefined and
customizable VR elements, as well as modules for layout design, navigation
control, and asset generation. A user study was then conducted with 12
participants to investigate their opinions and authoring experience with
VRStory. Our results demonstrated that, while acknowledging the advantages of
immersive and spatial features in VR, users often have a consistent mental
model for traditional 2D presentations and may still prefer planar and static
formats in VR for better accessibility and efficient communication. We finally
shared our learned design considerations for future development of VR
presentation tools, emphasizing the importance of balancing of promoting
immersive features and ensuring accessibility.

</details>


### [447] [Toward a Cognitive-Affective-Systemic Framework for Art and Sustainability](https://arxiv.org/abs/2510.17083)
*Ivan C. H. Liu*

Main category: cs.HC

TL;DR: 本研究提出了一个整合认知与情感的艺术框架，强调艺术实践在提升可持续性意识中的重要性，并展示了具体艺术作品的应用。


<details>
  <summary>Details</summary>
Motivation: 通过整合生态美学、情感理论、复杂性科学和后人伦理，提出一种综合框架，以探索艺术在可持续性意识中的作用。

Method: 通过艺术实践，定义认知、情感和系统理解的整合，以培养可持续性意识。

Result: 展示了两个艺术作品如何通过系统建模和感官沉浸将复杂科学转化为体现的生态理解。

Conclusion: 该框架为艺术家、理论家和活动家提供了方法论基础，以将意识转化为参与，推动集体创造力走向可持续的未来。

Abstract: This paper proposes a ognitive-Affective-Systemic (CAS) framework that
integrates cognition, emotion, and systemic understanding to cultivate
sustainability awareness through art. Drawing from eco-aesthetics, affect
theory, complexity science, and posthuman ethics, the framework defines
artistic practice as both epistemic and performative--a way of knowing through
making and feeling. Central to this is logomotion, an aesthetic mode where
comprehension and emotion move together as a unified experience. Two artworks,
SPill, visualizing antimicrobial resistance through avalanche dynamics, and
Echoes of the Land, modeling anthropogenic seismicity, demonstrate how systemic
modeling and sensory immersion transform complex science into embodied
ecological understanding. The framework offers a methodological foundation for
artists, theorists, and activists to translate awareness into engagement,
advancing collective creativity toward sustainable futures.

</details>


### [448] [Kinesthetic Weight Modulation: The Effects of Whole-Arm Tendon Vibration on the Perceived Heaviness](https://arxiv.org/abs/2510.17102)
*Keigo Ushiyama,Hiroyuki Kajimoto*

Main category: cs.HC

TL;DR: 本研究探讨了多点肌腱振动对知觉重感的影响，发现其显著增加重感且可调节，但对减轻重感的影响不显著。


<details>
  <summary>Details</summary>
Motivation: 当前的研究主要集中于虚拟运动的传达，而对知觉重感的调节关注较少，因此探讨这一领域具有重要意义。

Method: 通过实验1和实验2，作者研究了多点肌腱振动对知觉重感的影响及其效果的系统控制。

Result: 实验结果表明，肌腱振动显著增加了知觉的重感，但未能显著减少，且在一定范围内可调节。

Conclusion: 肌腱振动可显著增加知觉的重感，但不会显著减少重感，并且可以在350-450克范围内调节其效果。

Abstract: Kinesthetic illusions, which arise when muscle spindles are activated by
vibration, provide a compact means of presenting kinesthetic sensations.
Because muscle spindles contribute not only to sensing body movement but also
to perceiving heaviness, vibration-induced illusions could potentially modulate
weight perception. While prior studies have primarily focused on conveying
virtual movement, the modulation of perceived heaviness has received little
attention. Presenting a sense of heaviness is essential for enriching haptic
interactions with virtual objects. This study investigates whether multi-point
tendon vibration can increase or decrease perceived heaviness (Experiment 1)
and how the magnitude of the effect can be systematically controlled
(Experiment 2). The results show that tendon vibration significantly increases
perceived heaviness but does not significantly decrease it, although a
decreasing trend was observed. Moreover, the increase can be adjusted across at
least three levels within the range of 350-450 g. Finally, we discuss plausible
mechanisms underlying this vibration-induced modulation of weight perception.

</details>


### [449] [Augmented Web Usage Mining and User Experience Optimization with CAWAL's Enriched Analytics Data](https://arxiv.org/abs/2510.17253)
*Özkan Canay,{Ü}mit Kocabıcak*

Main category: cs.HC

TL;DR: 本研究提出AWUM方法，通过分析大量用户行为数据，旨在改善用户体验，并证明了其在大规模数据处理中的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着对优化用户体验的需求增加，深入理解用户在网页上的行为变得至关重要。

Method: 引入增强的网页使用挖掘(AWUM)方法，对结合应用日志和网页分析(CAWAL)的数据进行分析。

Result: 处理超过120万条会话记录的数据，发现87.16%的会话涉及多个页面，揭示了频繁访问的服务模式，证明了CAWAL方法的精确性和有效性。

Conclusion: AWUM提供了全面的用户行为理解，为大规模用户体验优化奠定了坚实基础。

Abstract: Understanding user behavior on the web is increasingly critical for
optimizing user experience (UX). This study introduces Augmented Web Usage
Mining (AWUM), a methodology designed to enhance web usage mining and improve
UX by enriching the interaction data provided by CAWAL (Combined Application
Log and Web Analytics), a framework for advanced web analytics. Over 1.2
million session records collected in one month (~8.5GB of data) were processed
and transformed into enriched datasets. AWUM analyzes session structures, page
requests, service interactions, and exit methods. Results show that 87.16% of
sessions involved multiple pages, contributing 98.05% of total pageviews; 40%
of users accessed various services and 50% opted for secure exits. Association
rule mining revealed patterns of frequently accessed services, highlighting
CAWAL's precision and efficiency over conventional methods. AWUM offers a
comprehensive understanding of user behavior and strong potential for
large-scale UX optimization.

</details>


### [450] [NieNie: Adaptive Rhythmic System for Stress Relief with LLM-Based Guidance](https://arxiv.org/abs/2510.17534)
*Yichen Yu,Qiaoran Wang*

Main category: cs.HC

TL;DR: NieNie是一种新型的压力管理系统，为年轻人提供互动的生理反馈和心理指导，展示了身体动作与心理健康之间的关系。


<details>
  <summary>Details</summary>
Motivation: 针对年轻人面临的心理压力和传统压力管理工具的不足，开发一种更加互动和有效的解决方案。

Method: 通过结合节奏生物反馈和大语言模型，利用生理信号生成适应性的挤压-释放节奏，并提供个性化的心理反馈。

Result: 研究表明，NieNie能够提升压力管理的效果，提供了一种沉浸式的心理调节体验，促进身体动作与心理健康的联系。

Conclusion: NieNie系统通过结合生理反馈和实时心理指导，为年轻人提供了一种新颖的压力管理方式，强调身体动作与心理健康的联系。

Abstract: Today's young people are facing increasing psychological stress due to
various social issues. Traditional stress management tools often rely on static
scripts or passive content, which are ineffective in alleviating stress. NieNie
addresses this gap by combining rhythm biofeedback with real-time psychological
guidance through a large language model (LLM), offering an interactive, tactile
response. The system is specifically designed for young people experiencing
emotional stress, collecting physiological signals such as heart rate
variability and generating adaptive squeeze-release rhythms via soft, tactile
devices. Utilising LLM, the system provides timely squeezing rhythms and
psychologically guided feedback prompts, offering personalised rhythm games
while reinforcing stress restructuring. Unlike traditional mental health apps,
NieNie places users within an embodied interactive loop, leveraging tactile
interaction, biofeedback, and adaptive language support to create an immersive
stress regulation experience. This study demonstrates how embodied systems can
connect bodily actions with mental health in everyday contexts.

</details>


### [451] [DeTAILS: Deep Thematic Analysis with Iterative LLM Support](https://arxiv.org/abs/2510.17575)
*Ash Sharma,Karen Cochrane,James R. Wallace*

Main category: cs.HC

TL;DR: DeTAILS工具结合LLM，提高定性主题分析效率，增强研究者与AI的互动，验证了其可行性和有效性。


<details>
  <summary>Details</summary>
Motivation: 旨在解决传统主题分析在可扩展性和分析复杂性方面的挑战。

Method: 通过引入大型语言模型（LLM）辅助的互动反馈循环，DeTAILS为主题分析提供了一种新的工作流程。

Result: 与参会的18名定性研究者的分析结果显示，LLM支持的输出与参与者的修订高度一致，并且减少了工作负担，同时被认为非常有用。

Conclusion: DeTAILS是一个有效的工具，能够显著提高定性研究中的主题分析效率，并促进研究者与AI之间的互动。

Abstract: Thematic analysis is widely used in qualitative research but can be difficult
to scale because of its iterative, interpretive demands. We introduce DeTAILS,
a toolkit that integrates large language model (LLM) assistance into a workflow
inspired by Braun and Clarke's thematic analysis framework. DeTAILS supports
researchers in generating and refining codes, reviewing clusters, and
synthesizing themes through interactive feedback loops designed to preserve
analytic agency. We evaluated the system with 18 qualitative researchers
analyzing Reddit data. Quantitative results showed strong alignment between
LLM-supported outputs and participants' refinements, alongside reduced workload
and high perceived usefulness. Qualitatively, participants reported that
DeTAILS accelerated analysis, prompted reflexive engagement with AI outputs,
and fostered trust through transparency and control. We contribute: (1) an
interactive human-LLM workflow for large-scale qualitative analysis, (2)
empirical evidence of its feasibility and researcher experience, and (3) design
implications for trustworthy AI-assisted qualitative research.

</details>


### [452] [Conveying Meaning through Gestures: An Investigation into Semantic Co-Speech Gesture Generation](https://arxiv.org/abs/2510.17599)
*Hendric Voss,Lisa Michelle Bohnenkamp,Stefan Kopp*

Main category: cs.HC

TL;DR: 本研究探讨了两种共语手势生成框架的有效性，结果表明显式语义增强对手势生成的改善并非必然，其效果受上下文影响。


<details>
  <summary>Details</summary>
Motivation: 探索两种共语手势生成框架AQ-GT及其语义增强变体AQ-GT-a，评估其通过手势传达意义的能力及人类对生成动作的感知。

Method: 通过使用来自SAGA空间通信语料库的句子进行用户中心评估，考察概念识别和人类相似性。

Result: 结果显示语义注释与性能之间存在微妙关系。原始AQ-GT框架在其训练领域内有效传达概念，而AQ-GT-a框架在新上下文中表现出更好的概括能力。

Conclusion: 显式语义增强并不总是能保证手势生成的改善，其效果高度依赖于上下文，表明专业化与概括性之间存在潜在的权衡。

Abstract: This study explores two frameworks for co-speech gesture generation, AQ-GT
and its semantically-augmented variant AQ-GT-a, to evaluate their ability to
convey meaning through gestures and how humans perceive the resulting
movements. Using sentences from the SAGA spatial communication corpus,
contextually similar sentences, and novel movement-focused sentences, we
conducted a user-centered evaluation of concept recognition and human-likeness.
Results revealed a nuanced relationship between semantic annotations and
performance. The original AQ-GT framework, lacking explicit semantic input, was
surprisingly more effective at conveying concepts within its training domain.
Conversely, the AQ-GT-a framework demonstrated better generalization,
particularly for representing shape and size in novel contexts. While
participants rated gestures from AQ-GT-a as more expressive and helpful, they
did not perceive them as more human-like. These findings suggest that explicit
semantic enrichment does not guarantee improved gesture generation and that its
effectiveness is highly dependent on the context, indicating a potential
trade-off between specialization and generalization.

</details>


### [453] [ImaGGen: Zero-Shot Generation of Co-Speech Semantic Gestures Grounded in Language and Image Input](https://arxiv.org/abs/2510.17617)
*Hendric Voss,Stefan Kopp*

Main category: cs.HC

TL;DR: 本文提出了一种新方法，通过结合语言和图像输入，生成语义一致的手势，以提升人机交互效果。


<details>
  <summary>Details</summary>
Motivation: 当前生成手势的方法只能生成简单的节拍手势，而无法传达语义，本研究旨在解决这一问题。

Method: 提出了一种零样本系统，通过图像分析提取物体属性，结合语义匹配和逆运动学引擎生成手势。

Result: 通过用户研究，证明了生成的手势提高了参与者对物体属性的识别能力，展示了其可解释性和传达价值。

Conclusion: 本研究展示了一种通过语言和图像输入生成语义一致的手势的有效方法，提升了人机交互的表达能力。

Abstract: Human communication combines speech with expressive nonverbal cues such as
hand gestures that serve manifold communicative functions. Yet, current
generative gesture generation approaches are restricted to simple, repetitive
beat gestures that accompany the rhythm of speaking but do not contribute to
communicating semantic meaning. This paper tackles a core challenge in
co-speech gesture synthesis: generating iconic or deictic gestures that are
semantically coherent with a verbal utterance. Such gestures cannot be derived
from language input alone, which inherently lacks the visual meaning that is
often carried autonomously by gestures. We therefore introduce a zero-shot
system that generates gestures from a given language input and additionally is
informed by imagistic input, without manual annotation or human intervention.
Our method integrates an image analysis pipeline that extracts key object
properties such as shape, symmetry, and alignment, together with a semantic
matching module that links these visual details to spoken text. An inverse
kinematics engine then synthesizes iconic and deictic gestures and combines
them with co-generated natural beat gestures for coherent multimodal
communication. A comprehensive user study demonstrates the effectiveness of our
approach. In scenarios where speech alone was ambiguous, gestures generated by
our system significantly improved participants' ability to identify object
properties, confirming their interpretability and communicative value. While
challenges remain in representing complex shapes, our results highlight the
importance of context-aware semantic gestures for creating expressive and
collaborative virtual agents or avatars, marking a substantial step forward
towards efficient and robust, embodied human-agent interaction. More
information and example videos are available here:
https://review-anon-io.github.io/ImaGGen.github.io/

</details>


### [454] [Muscle Anatomy-aware Geometric Deep Learning for sEMG-based Gesture Decoding](https://arxiv.org/abs/2510.17660)
*Adyasha Dash,Giulia Zappoli,Laya Das,Robert Riener*

Main category: cs.HC

TL;DR: 本研究提出一种新的几何深度学习模型，通过对称正定流形和领域自适应来改善sEMG手势解码，显著提升了准确率，并推动了相关领域的发展。


<details>
  <summary>Details</summary>
Motivation: 由于现有的sEMG手势解码算法在不同主体和会话中表现出高变异性，因此需要重新校准和自适应微调，以提高性能，激励了本研究的开展。

Method: 提出了一种几何深度学习模型，该模型在对称正定(SPD)流形上学习，并利用无监督领域自适应，使模型对不同主体和会话不敏感。

Result: 通过对Ninapro DB6和Flexwear-HD等公开基准手势解码数据集进行实验，展示了该模型在会话间情境下的优越泛化能力，相比于欧几里得和其他基于SPD的模型，准确率分别提高了8.83和4.63个百分点。

Conclusion: 所提方法在sEMG手势识别的前沿领域推动了进展，并为肌肉信号的流形学习开辟了新的研究方向。

Abstract: Robust and accurate decoding of gesture from non-invasive surface
electromyography (sEMG) is important for various applications including spatial
computing, healthcare, and entertainment, and has been actively pursued by
researchers and industry. Majority of sEMG-based gesture decoding algorithms
employ deep neural networks that are designed for Euclidean data, and may not
be suitable for analyzing multi-dimensional, non-stationary time-series with
long-range dependencies such as sEMG. State-of-the-art sEMG-based decoding
methods also demonstrate high variability across subjects and sessions,
requiring re-calibration and adaptive fine-tuning to boost performance. To
address these shortcomings, this work proposes a geometric deep learning model
that learns on symmetric positive definite (SPD) manifolds and leverages
unsupervised domain adaptation to desensitize the model to subjects and
sessions. The model captures the features in time and across sensors with
multiple kernels, projects the features onto SPD manifold, learns on manifolds
and projects back to Euclidean space for classification. It uses a
domain-specific batch normalization layer to address variability between
sessions, alleviating the need for re-calibration or fine-tuning. Experiments
with publicly available benchmark gesture decoding datasets (Ninapro DB6,
Flexwear-HD) demonstrate the superior generalizability of the model compared to
Euclidean and other SPD-based models in the inter-session scenario, with up to
8.83 and 4.63 points improvement in accuracy, respectively. Detailed analyses
reveal that the model extracts muscle-specific information for different tasks
and ablation studies highlight the importance of modules introduced in the
work. The proposed method pushes the state-of-the-art in sEMG-based gesture
recognition and opens new research avenues for manifold-based learning for
muscle signals.

</details>


### [455] [Rethinking Search: A Study of University Students' Perspectives on Using LLMs and Traditional Search Engines in Academic Problem Solving](https://arxiv.org/abs/2510.17726)
*Md. Faiyaz Abdullah Sayeedi,Md. Sadman Haque,Zobaer Ibn Razzaque,Robiul Awoul Robin,Sabila Nawshin*

Main category: cs.HC

TL;DR: 本研究探讨学生对AI工具在学术研究中使用的看法，并开发了一款结合GPT与Google的聊天机器人原型，旨在提高效率。


<details>
  <summary>Details</summary>
Motivation: 研究学生对传统搜索引擎与大型语言模型在信息检索中的看法，强调可用性和效率。

Method: 采用混合方法，调查109名来自不同学科的学生，进行量化分析和深度访谈。

Result: 学生在使用Google和GPT之间频繁切换，反馈出对混合解决方案的强烈需求。

Conclusion: 课程结合了GPT的对话能力与Google的可靠性，以提升学术研究效率，减轻认知负担。

Abstract: With the increasing integration of Artificial Intelligence (AI) in academic
problem solving, university students frequently alternate between traditional
search engines like Google and large language models (LLMs) for information
retrieval. This study explores students' perceptions of both tools, emphasizing
usability, efficiency, and their integration into academic workflows. Employing
a mixed-methods approach, we surveyed 109 students from diverse disciplines and
conducted in-depth interviews with 12 participants. Quantitative analyses,
including ANOVA and chi-square tests, were used to assess differences in
efficiency, satisfaction, and tool preference. Qualitative insights revealed
that students commonly switch between GPT and Google: using Google for
credible, multi-source information and GPT for summarization, explanation, and
drafting. While neither tool proved sufficient on its own, there was a strong
demand for a hybrid solution. In response, we developed a prototype, a chatbot
embedded within the search interface, that combines GPT's conversational
capabilities with Google's reliability to enhance academic research and reduce
cognitive load.

</details>


### [456] [Human-AI Interactions: Cognitive, Behavioral, and Emotional Impacts](https://arxiv.org/abs/2510.17753)
*Celeste Riley,Omar Al-Refai,Yadira Colunga Reyes,Eman Hammad*

Main category: cs.HC

TL;DR: 该论文通过心理三元组审视AI与人类交互中的风险与收益，强调负责任的AI设计与研究的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着人机交互的故事在新闻和研究平台上突出，面临的挑战越来越明显，包括过度依赖、认知卸载、社会和情感操控等风险。

Method: 通过心理三元组（认知、行为、情感）的视角，对人机交互中的最新研究进行审查。

Result: 研究显示，尽管AI可以显著增强记忆、创造力和参与感，但同时也带来了批判性思维减弱、技能退化和焦虑增加等风险。情感结果也同样复杂，AI系统在支持和减轻压力上显示出前景，但也引发了对依赖、不当依恋和伦理监管的担忧。

Conclusion: 这项研究强调了在AI设计中需要负责任且关注上下文的设计，同时指出了纵向研究和扎实评估框架的缺口，以平衡好处与人本风险。

Abstract: As stories of human-AI interactions continue to be highlighted in the news
and research platforms, the challenges are becoming more pronounced, including
potential risks of overreliance, cognitive offloading, social and emotional
manipulation, and the nuanced degradation of human agency and judgment. This
paper surveys recent research on these issues through the lens of the
psychological triad: cognition, behavior, and emotion. Observations seem to
suggest that while AI can substantially enhance memory, creativity, and
engagement, it also introduces risks such as diminished critical thinking,
skill erosion, and increased anxiety. Emotional outcomes are similarly mixed,
with AI systems showing promise for support and stress reduction, but raising
concerns about dependency, inappropriate attachments, and ethical oversight.
This paper aims to underscore the need for responsible and context-aware AI
design, highlighting gaps for longitudinal research and grounded evaluation
frameworks to balance benefits with emerging human-centric risks.

</details>

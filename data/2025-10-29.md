<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 57]
- [cs.CL](#cs.CL) [Total: 65]
- [cs.LG](#cs.LG) [Total: 87]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.HC](#cs.HC) [Total: 10]
- [cs.AI](#cs.AI) [Total: 31]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Explainable Detection of AI-Generated Images with Artifact Localization Using Faster-Than-Lies and Vision-Language Models for Edge Devices](https://arxiv.org/abs/2510.23775)
*Aryan Mathur,Asaduddin Ahmed,Pushti Amit Vasoya,Simeon Kandan Sonar,Yasir Z,Madesh Kuppusamy*

Main category: cs.CV

TL;DR: 本研究开发了一个可解释的图像真实性检测系统，结合了卷积分类器和视觉-语言模型，在低分辨率图像上实现了高效、准确的真实性感知。


<details>
  <summary>Details</summary>
Motivation: 面对AI生成图像日益真实的挑战，提供可解释的视觉真实性检测系统显得尤为重要。

Method: 该系统结合了轻量级卷积分类器和视觉-语言模型，通过生成重建错误图来定位和解释图像中的伪影。

Result: 我们提出了一种结合轻量级卷积分类器和视觉-语言模型的图像真实性检测系统，具有高准确率和快速推理时间。

Conclusion: 此工作展示了结合视觉和语言推理在低分辨率图像中文件真伪检测的可行性，并探讨了其在多个领域的应用潜力。

Abstract: The increasing realism of AI-generated imagery poses challenges for verifying
visual authenticity. We present an explainable image authenticity detection
system that combines a lightweight convolutional classifier
("Faster-Than-Lies") with a Vision-Language Model (Qwen2-VL-7B) to classify,
localize, and explain artifacts in 32x32 images. Our model achieves 96.5%
accuracy on the extended CiFAKE dataset augmented with adversarial
perturbations and maintains an inference time of 175ms on 8-core CPUs, enabling
deployment on local or edge devices. Using autoencoder-based reconstruction
error maps, we generate artifact localization heatmaps, which enhance
interpretability for both humans and the VLM. We further categorize 70 visual
artifact types into eight semantic groups and demonstrate explainable text
generation for each detected anomaly. This work highlights the feasibility of
combining visual and linguistic reasoning for interpretable authenticity
detection in low-resolution imagery and outlines potential cross-domain
applications in forensics, industrial inspection, and social media moderation.

</details>


### [2] [CountFormer: A Transformer Framework for Learning Visual Repetition and Structure in Class-Agnostic Object Counting](https://arxiv.org/abs/2510.23785)
*Md Tanvir Hossain,Akif Islam,Mohd Ruhul Ameen*

Main category: cs.CV

TL;DR: 本文提出了一种新的计数模型CountFormer，利用变换器架构和自监督模型DINOv2，提高了对复杂场景中物体的计数准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的计数模型在处理复杂形状、内部对称或重叠组件的物体时表现欠佳，因此需要一种更先进的框架来提高计数性能。

Method: 该模型基于CounTR架构，通过替换视觉编码器为DINOv2，自监督学习得到更加丰富且空间一致的特征表示，并通过轻量级的卷积解码器将这些特征解码为密度图。

Result: 在FSC-147数据集上的评估显示，CountFormer的性能与当前最先进的方法相媲美，并在结构复杂或密集场景中展现出更高的准确性。

Conclusion: CountFormer在复杂和密集场景中的计数表现优异，向人类的结构感知能力迈进了一步。

Abstract: Humans can effortlessly count diverse objects by perceiving visual repetition
and structural relationships rather than relying on class identity. However,
most existing counting models fail to replicate this ability; they often
miscount when objects exhibit complex shapes, internal symmetry, or overlapping
components. In this work, we introduce CountFormer, a transformer-based
framework that learns to recognize repetition and structural coherence for
class-agnostic object counting. Built upon the CounTR architecture, our model
replaces its visual encoder with the self-supervised foundation model DINOv2,
which produces richer and spatially consistent feature representations. We
further incorporate positional embedding fusion to preserve geometric
relationships before decoding these features into density maps through a
lightweight convolutional decoder. Evaluated on the FSC-147 dataset, our model
achieves performance comparable to current state-of-the-art methods while
demonstrating superior accuracy on structurally intricate or densely packed
scenes. Our findings indicate that integrating foundation models such as DINOv2
enables counting systems to approach human-like structural perception,
advancing toward a truly general and exemplar-free counting paradigm.

</details>


### [3] [A geometric and deep learning reproducible pipeline for monitoring floating anthropogenic debris in urban rivers using in situ cameras](https://arxiv.org/abs/2510.23798)
*Gauthier Grimmer,Romain Wenger,Clément Flint,Germain Forestier,Gilles Rixhon,Valentin Chardon*

Main category: cs.CV

TL;DR: 本研究提出了一种新方法监测河流漂浮垃圾，利用深度学习进行垃圾量化，同时确定最优模型，强调数据集构建的重要性，展示了低成本自动监测系统的可行性。


<details>
  <summary>Details</summary>
Motivation: 为解决河流中的人造垃圾问题，开发一种高效、低成本的监测方法，保护水质与生态。

Method: 研究使用固定摄像机与深度学习技术，连续监测和量化漂浮垃圾，测试不同环境条件下的模型表现，并实施几何模型估算物体大小。

Result: 本研究提出了一种新颖的方法框架，使用固定的现场摄像机监测河流中的人造漂浮垃圾，对生物多样性、水质以及人类活动如航行和娱乐产生负面影响。研究的两个主要贡献是：(i) 使用深度学习实现漂浮垃圾的连续量化与监测；(ii) 确定在复杂环境条件下准确性和推理速度最优的深度学习模型。模型在多种环境条件下进行测试，并实验数据泄漏相关的偏见。此外，实施了一个几何模型，以从2D图像估算检测对象的实际大小，利用相机的内在和外在特征。研究结果强调了数据集构成协议的重要性，特别是在集成负图像和考虑时间泄漏方面。结论表明，结合投影几何和回归修正的度量对象估算的可行性。这一方法为城市水环境的强健、低成本的自动监测系统的发展铺平了道路。

Conclusion: 本研究展示了结合投影几何与回归修正的度量对象估算的可行性，并为自动监测系统的发展铺平道路。

Abstract: The proliferation of floating anthropogenic debris in rivers has emerged as a
pressing environmental concern, exerting a detrimental influence on
biodiversity, water quality, and human activities such as navigation and
recreation. The present study proposes a novel methodological framework for the
monitoring the aforementioned waste, utilising fixed, in-situ cameras. This
study provides two key contributions: (i) the continuous quantification and
monitoring of floating debris using deep learning and (ii) the identification
of the most suitable deep learning model in terms of accuracy and inference
speed under complex environmental conditions. These models are tested in a
range of environmental conditions and learning configurations, including
experiments on biases related to data leakage. Furthermore, a geometric model
is implemented to estimate the actual size of detected objects from a 2D image.
This model takes advantage of both intrinsic and extrinsic characteristics of
the camera. The findings of this study underscore the significance of the
dataset constitution protocol, particularly with respect to the integration of
negative images and the consideration of temporal leakage. In conclusion, the
feasibility of metric object estimation using projective geometry coupled with
regression corrections is demonstrated. This approach paves the way for the
development of robust, low-cost, automated monitoring systems for urban aquatic
environments.

</details>


### [4] [RareFlow: Physics-Aware Flow-Matching for Cross-Sensor Super-Resolution of Rare-Earth Features](https://arxiv.org/abs/2510.23816)
*Forouzan Fallah,Wenwen Li,Chia-Yu Hsu,Hyunho Lee,Yezhou Yang*

Main category: cs.CV

TL;DR: RareFlow是一个针对遥感图像的超分辨率框架，能在稀有地貌下表现出色，兼顾几何和语义信息，同时量化预测不确定性，显著提升输出质量。


<details>
  <summary>Details</summary>
Motivation: 现有的超分辨率方法在处理边界条件（如稀有地貌特征）时常常失败，因此需要一个鲁棒的框架来处理这种数据稀缺环境中的图像合成问题。

Method: 采用双重条件架构的RareFlow框架结合了门控的ControlNet和文本提示，确保低分辨率输入的几何保真度并提供语义指导。同时，引入多面损失函数以确保输出的光谱和辐射一致性。

Result: 在一项针对多传感器卫星影像的新基准测试中，RareFlow在盲评中获得专家的高分评价，其输出结果接近真实图像，并且在感知指标上实现了显著的量化改善，包括接近40%的FID减少。

Conclusion: RareFlow在处理稀有地貌特征时，展现出较高的图像合成真实性，显著超越现有技术基准，提供了数据稀缺科学领域高保真合成的新框架。

Abstract: Super-resolution (SR) for remote sensing imagery often fails under
out-of-distribution (OOD) conditions, such as rare geomorphic features captured
by diverse sensors, producing visually plausible but physically inaccurate
results. We present RareFlow, a physics-aware SR framework designed for OOD
robustness. RareFlow's core is a dual-conditioning architecture. A Gated
ControlNet preserves fine-grained geometric fidelity from the low-resolution
input, while textual prompts provide semantic guidance for synthesizing complex
features. To ensure physically sound outputs, we introduce a multifaceted loss
function that enforces both spectral and radiometric consistency with sensor
properties. Furthermore, the framework quantifies its own predictive
uncertainty by employing a stochastic forward pass approach; the resulting
output variance directly identifies unfamiliar inputs, mitigating feature
hallucination. We validate RareFlow on a new, curated benchmark of multi-sensor
satellite imagery. In blind evaluations, geophysical experts rated our model's
outputs as approaching the fidelity of ground truth imagery, significantly
outperforming state-of-the-art baselines. This qualitative superiority is
corroborated by quantitative gains in perceptual metrics, including a nearly
40\% reduction in FID. RareFlow provides a robust framework for high-fidelity
synthesis in data-scarce scientific domains and offers a new paradigm for
controlled generation under severe domain shift.

</details>


### [5] [TRELLISWorld: Training-Free World Generation from Object Generators](https://arxiv.org/abs/2510.23880)
*Hanke Chen,Yuan Liu,Minchen Li*

Main category: cs.CV

TL;DR: 该研究提出了一种无训练的3D场景合成方法，通过重用通用的文本到3D对象扩散模型作为模块化平铺生成器，从而解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景生成方法通常限制于单对象生成或需要特定领域的训练，缺乏支持全360度可视性的能力。

Method: 将场景生成重新表述为多平铺去噪问题，独立生成重叠的3D区域并通过加权平均无缝混合。

Result: 该方法消除了对场景级数据集或重新训练的需求，依赖于最少的启发式，并继承了对象级先验的泛化能力。

Conclusion: 所提出的方法支持多样的场景布局、高效的生成和灵活的编辑，为通用的、基于语言的3D场景构建奠定了简单而强大的基础。

Abstract: Text-driven 3D scene generation holds promise for a wide range of
applications, from virtual prototyping to AR/VR and simulation. However,
existing methods are often constrained to single-object generation, require
domain-specific training, or lack support for full 360-degree viewability. In
this work, we present a training-free approach to 3D scene synthesis by
repurposing general-purpose text-to-3D object diffusion models as modular tile
generators. We reformulate scene generation as a multi-tile denoising problem,
where overlapping 3D regions are independently generated and seamlessly blended
via weighted averaging. This enables scalable synthesis of large, coherent
scenes while preserving local semantic control. Our method eliminates the need
for scene-level datasets or retraining, relies on minimal heuristics, and
inherits the generalization capabilities of object-level priors. We demonstrate
that our approach supports diverse scene layouts, efficient generation, and
flexible editing, establishing a simple yet powerful foundation for
general-purpose, language-driven 3D scene construction.

</details>


### [6] [Improving Visual Discriminability of CLIP for Training-Free Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2510.23894)
*Jinxin Zhou,Jiachen Jiang,Zhihui Zhu*

Main category: cs.CV

TL;DR: LHT-CLIP是一个无训练框架，旨在改善CLIP模型在语义分割中的表现，提出了针对视觉区分能力的三项技术，经过实验证明其卓越的效果。


<details>
  <summary>Details</summary>
Motivation: 鉴于传统CLIP模型在图像级预训练与像素级视觉理解之间存在的错位，LHT-CLIP旨在改善该模型的语义分割性能。

Method: 通过分析CLIP模型各层、头和标记的视觉区分能力，提出了无训练的LHT-CLIP框架，集成了语义-空间重加权、选择性头增强和异常标记替换等技术。

Result: LHT-CLIP是一种新颖的无训练框架，旨在通过对CLIP模型进行全面分析，解决其在语义分割任务中的表现不佳问题。该研究揭示了传统CLIP模型在处理图像-文本对齐时所损失的视觉区分能力，以及特定注意力头和异常标记在视觉特征提取中的重要性。为提升分割性能，提出了三项互补技术，并在8个语义分割基准测试中验证了LHT-CLIP的有效性和实用性。

Conclusion: LHT-CLIP通过其独特的无训练框架和三种互补技术，显著提升了在多种语义分割基准上的表现，证明了其在实际应用中的有效性。

Abstract: Extending CLIP models to semantic segmentation remains challenging due to the
misalignment between their image-level pre-training objectives and the
pixel-level visual understanding required for dense prediction. While prior
efforts have achieved encouraging results by reorganizing the final layer and
features, they often inherit the global alignment bias of preceding layers,
leading to suboptimal segmentation performance. In this work, we propose
LHT-CLIP, a novel training-free framework that systematically exploits the
visual discriminability of CLIP across layer, head, and token levels. Through
comprehensive analysis, we reveal three key insights: (i) the final layers
primarily strengthen image-text alignment with sacrifice of visual
discriminability (e.g., last 3 layers in ViT-B/16 and 8 layers in ViT-L/14),
partly due to the emergence of anomalous tokens; (ii) a subset of attention
heads (e.g., 10 out of 144 in ViT-B/16) display consistently strong visual
discriminability across datasets; (iii) abnormal tokens display sparse and
consistent activation pattern compared to normal tokens. Based on these
findings, we propose three complementary techniques: semantic-spatial
reweighting, selective head enhancement, and abnormal token replacement to
effectively restore visual discriminability and improve segmentation
performance without any additional training, auxiliary pre-trained networks, or
extensive hyperparameter tuning. Extensive experiments on 8 common semantic
segmentation benchmarks demonstrate that LHT-CLIP achieves state-of-the-art
performance across diverse scenarios, highlighting its effectiveness and
practicality for real-world deployment.

</details>


### [7] [DynaStride: Dynamic Stride Windowing with MMCoT for Instructional Multi-Scene Captioning](https://arxiv.org/abs/2510.23907)
*Eddison Pham,Prisha Priyadarshini,Adrian Maliackel,Kanishk Bandi,Cristian Meo,Kevin Zhu*

Main category: cs.CV

TL;DR: DynaStride is a proposed pipeline for generating coherent scene-level captions in instructional videos, enhancing learning by aligning visual cues with text, and showing improved performance over existing methods.


<details>
  <summary>Details</summary>
Motivation: The motivation is to improve the coherence and quality of captions in instructional videos, thereby enhancing procedural learning and multimodal reasoning.

Method: DynaStride utilizes adaptive frame sampling and multimodal windowing with a dynamic stride window selection algorithm to produce captions from video data.

Result: DynaStride consistently outperforms strong baselines in generating temporally coherent and informative scene-level captions, as shown by empirical evaluations metrics and qualitative analyses.

Conclusion: DynaStride generates coherent, scene-level captions that enhance instructional videos by aligning visual cues with textual guidance, improving learning outcomes.

Abstract: Scene-level captioning in instructional videos can enhance learning by
requiring an understanding of both visual cues and temporal structure. By
aligning visual cues with textual guidance, this understanding supports
procedural learning and multimodal reasoning, providing a richer context for
skill acquisition. However, captions that fail to capture this structure may
lack coherence and quality, which can create confusion and undermine the
video's educational intent. To address this gap, we introduce DynaStride, a
pipeline to generate coherent, scene-level captions without requiring manual
scene segmentation. Using the YouCookII dataset's scene annotations, DynaStride
performs adaptive frame sampling and multimodal windowing to capture key
transitions within each scene. It then employs a multimodal chain-of-thought
process to produce multiple action-object pairs, which are refined and fused
using a dynamic stride window selection algorithm that adaptively balances
temporal context and redundancy. The final scene-level caption integrates
visual semantics and temporal reasoning in a single instructional caption.
Empirical evaluations against strong baselines, including VLLaMA3 and GPT-4o,
demonstrate consistent gains on both N-gram-based metrics (BLEU, METEOR) and
semantic similarity measures (BERTScore, CLIPScore). Qualitative analyses
further show that DynaStride produces captions that are more temporally
coherent and informative, suggesting a promising direction for improving
AI-powered instructional content generation.

</details>


### [8] [TurboPortrait3D: Single-step diffusion-based fast portrait novel-view synthesis](https://arxiv.org/abs/2510.23929)
*Emily Kim,Julieta Martinez,Timur Bagautdinov,Jessica Hodgins*

Main category: cs.CV

TL;DR: TurboPortrait3D是一种低延迟的人像新视图合成方法，通过结合图像扩散模型和现有的人像生成技术，能够生成高质量的3D表示，克服传统方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的人像生成模型存在视觉伪影、细节不足和难以完美保留主体身份的问题，许多图像扩散模型由于计算成本高且缺乏3D支持，无法直接生产多视角一致的输出。

Method: 方法以单一正面图像为输入，经过前馈图像到头像生成管道获得初步3D表示和对应的噪声渲染，随后将这些噪声渲染输入到经过条件训练的单步扩散模型中，进行多视角一致性优化，并采用新的有效训练策略进行预训练和微调。

Result: TurboPortrait3D方法显著提升了现有图像到头像方法的质量，并保持了3D意识且低延迟运行。

Conclusion: 我们的方法在定性和定量上均超越当前最先进的人像新视图合成技术，并且在时间效率上表现优异。

Abstract: We introduce TurboPortrait3D: a method for low-latency novel-view synthesis
of human portraits. Our approach builds on the observation that existing
image-to-3D models for portrait generation, while capable of producing
renderable 3D representations, are prone to visual artifacts, often lack of
detail, and tend to fail at fully preserving the identity of the subject. On
the other hand, image diffusion models excel at generating high-quality images,
but besides being computationally expensive, are not grounded in 3D and thus
are not directly capable of producing multi-view consistent outputs. In this
work, we demonstrate that image-space diffusion models can be used to
significantly enhance the quality of existing image-to-avatar methods, while
maintaining 3D-awareness and running with low-latency. Our method takes a
single frontal image of a subject as input, and applies a feedforward
image-to-avatar generation pipeline to obtain an initial 3D representation and
corresponding noisy renders. These noisy renders are then fed to a single-step
diffusion model which is conditioned on input image(s), and is specifically
trained to refine the renders in a multi-view consistent way. Moreover, we
introduce a novel effective training strategy that includes pre-training on a
large corpus of synthetic multi-view data, followed by fine-tuning on
high-quality real images. We demonstrate that our approach both qualitatively
and quantitatively outperforms current state-of-the-art for portrait novel-view
synthesis, while being efficient in time.

</details>


### [9] [PlanarGS: High-Fidelity Indoor 3D Gaussian Splatting Guided by Vision-Language Planar Priors](https://arxiv.org/abs/2510.23930)
*Xirui Jin,Renbiao Jin,Boying Li,Danping Zou,Wenxian Yu*

Main category: cs.CV

TL;DR: PlanarGS是一种针对室内重建的高效框架，利用语言提示和平面先验优化3DGS，显著提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 解决在大型低纹理区域中，3DGS优化中的光度损失导致的几何模糊和高保真3D表面恢复失败。

Method: 提出了一种基于3DGS的框架，称为PlanarGS，专门用于室内场景重建。

Result: PlanarGS通过语言提示的平面先验模型优化3D高斯，提供了更准确和详细的3D表面重建，显著超越了现有技术。

Conclusion: PlanarGS在标准室内基准测试中表现出色，提供了更高的重建精度和细节，解决了以往方法的局限性。

Abstract: Three-dimensional Gaussian Splatting (3DGS) has recently emerged as an
efficient representation for novel-view synthesis, achieving impressive visual
quality. However, in scenes dominated by large and low-texture regions, common
in indoor environments, the photometric loss used to optimize 3DGS yields
ambiguous geometry and fails to recover high-fidelity 3D surfaces. To overcome
this limitation, we introduce PlanarGS, a 3DGS-based framework tailored for
indoor scene reconstruction. Specifically, we design a pipeline for
Language-Prompted Planar Priors (LP3) that employs a pretrained vision-language
segmentation model and refines its region proposals via cross-view fusion and
inspection with geometric priors. 3D Gaussians in our framework are optimized
with two additional terms: a planar prior supervision term that enforces planar
consistency, and a geometric prior supervision term that steers the Gaussians
toward the depth and normal cues. We have conducted extensive experiments on
standard indoor benchmarks. The results show that PlanarGS reconstructs
accurate and detailed 3D surfaces, consistently outperforming state-of-the-art
methods by a large margin. Project page: https://planargs.github.io

</details>


### [10] [Neural USD: An object-centric framework for iterative editing and control](https://arxiv.org/abs/2510.23956)
*Alejandro Escontrela,Shrinu Kushagra,Sjoerd van Steenkiste,Yulia Rubanova,Aleksander Holynski,Kelsey Allen,Kevin Murphy,Thomas Kipf*

Main category: cs.CV

TL;DR: 提出神经通用场景描述符（Neural USD），解决精确编辑生成图像中的对象的挑战。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有方法在精确和迭代对象编辑方面的挑战，尤其是在改变条件信号时导致意外全局变化的问题。

Method: 介绍一个名为神经通用场景描述符（Neural USD）的框架，采用层次化的方式表示场景和物体。

Result: 展示了Neural USD如何支持逐对象控制外观、几何形状和姿势，并确保控制信号的解耦，支持迭代和增量工作流。

Conclusion: Neural USD为对象编辑提供了新的可能性，能有效控制场景元素，而不引发不必要的全局修改。

Abstract: Amazing progress has been made in controllable generative modeling,
especially over the last few years. However, some challenges remain. One of
them is precise and iterative object editing. In many of the current methods,
trying to edit the generated image (for example, changing the color of a
particular object in the scene or changing the background while keeping other
elements unchanged) by changing the conditioning signals often leads to
unintended global changes in the scene. In this work, we take the first steps
to address the above challenges. Taking inspiration from the Universal Scene
Descriptor (USD) standard developed in the computer graphics community, we
introduce the "Neural Universal Scene Descriptor" or Neural USD. In this
framework, we represent scenes and objects in a structured, hierarchical
manner. This accommodates diverse signals, minimizes model-specific
constraints, and enables per-object control over appearance, geometry, and
pose. We further apply a fine-tuning approach which ensures that the above
control signals are disentangled from one another. We evaluate several design
considerations for our framework, demonstrating how Neural USD enables
iterative and incremental workflows. More information at:
https://escontrela.me/neural_usd .

</details>


### [11] [SafeVision: Efficient Image Guardrail with Robust Policy Adherence and Explainability](https://arxiv.org/abs/2510.23960)
*Peiyang Xu,Minzhou Pan,Zhaorun Chen,Shuang Yang,Chaowei Xiao,Bo Li*

Main category: cs.CV

TL;DR: SafeVision是一种新型图像保护模型，通过整合推理能力和动态适应机制，提升了安全内容识别的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 面对数字媒体快速增长，传统图像模型由于依赖预定义类别和纯特征学习而面临分类错误和适应新威胁的挑战。

Method: 引入SafeVision作为一种新的图像保护模型，结合人类推理能力以提升适应性和透明度。

Result: SafeVision在多个基准测试中表现出色，尤其在VisionHarm-T和VisionHarm-C上分别超越GPT-4o 8.6%和15.5%。

Conclusion: SafeVision提供了一种综合性、遵循政策且可解释的图像保护机制，能够动态适应新兴威胁。

Abstract: With the rapid proliferation of digital media, the need for efficient and
transparent safeguards against unsafe content is more critical than ever.
Traditional image guardrail models, constrained by predefined categories, often
misclassify content due to their pure feature-based learning without semantic
reasoning. Moreover, these models struggle to adapt to emerging threats,
requiring costly retraining for new threats. To address these limitations, we
introduce SafeVision, a novel image guardrail that integrates human-like
reasoning to enhance adaptability and transparency. Our approach incorporates
an effective data collection and generation framework, a policy-following
training pipeline, and a customized loss function. We also propose a diverse QA
generation and training strategy to enhance learning effectiveness. SafeVision
dynamically aligns with evolving safety policies at inference time, eliminating
the need for retraining while ensuring precise risk assessments and
explanations. Recognizing the limitations of existing unsafe image benchmarks,
which either lack granularity or cover limited risks, we introduce VisionHarm,
a high-quality dataset comprising two subsets: VisionHarm Third-party
(VisionHarm-T) and VisionHarm Comprehensive(VisionHarm-C), spanning diverse
harmful categories. Through extensive experiments, we show that SafeVision
achieves state-of-the-art performance on different benchmarks. SafeVision
outperforms GPT-4o by 8.6% on VisionHarm-T and by 15.5% on VisionHarm-C, while
being over 16x faster. SafeVision sets a comprehensive, policy-following, and
explainable image guardrail with dynamic adaptation to emerging threats.

</details>


### [12] [Reasoning Visual Language Model for Chest X-Ray Analysis](https://arxiv.org/abs/2510.23968)
*Andriy Myronenko,Dong Yang,Baris Turkbey,Mariam Aboian,Sena Azamat,Esra Akcicek,Hongxu Yin,Pavlo Molchanov,Marc Edgar,Yufan He,Pengfei Guo,Yucheng Tang,Daguang Xu*

Main category: cs.CV

TL;DR: 本研究提出了一种结合链式思维推理的胸部X光解读框架，提升了模型的透明性和临床应用效果，支持更安全的人机协作。


<details>
  <summary>Details</summary>
Motivation: 应对传统医疗影像处理中的不透明性，提供一种能够解析推理过程的模型，帮助临床医生理解模型的决策依据。

Method: 模型通过高保真视觉编码和两阶段训练（推理风格的有监督微调和强化学习）实现推理与影像证据的对齐。

Result: 在脱离分布的评估中，模型在多标签分类上表现竞争力，并提升了解释性；专家放射科医师的研究显示，推理轨迹提高了信心、支持了错误审核并缩短了报告完成时间。

Conclusion: 提出的框架通过链式思维推理增强了胸部X光解读的透明度和审计能力，促进了人机合作的安全性和效率。

Abstract: Vision-language models (VLMs) have shown strong promise for medical image
analysis, but most remain opaque, offering predictions without the transparent,
stepwise reasoning clinicians rely on. We present a framework that brings
chain-of-thought (CoT) reasoning to chest X-ray interpretation. Inspired by
reasoning-first training paradigms, our approach is designed to learn how
experts reason, not just what they conclude, by aligning intermediate steps
with observable image evidence and radiology workflow. Beyond accuracy, the
explicit reasoning traces support clinical auditability: they reveal why a
conclusion was reached, which alternatives were considered, and where
uncertainty remains, enabling quality assurance, error analysis, and safer
human-AI collaboration.
  Our model couples high-fidelity visual encoding with a two-stage training
recipe: a reasoning-style supervised fine-tuning (SFT) followed by
reinforcement learning (RL) that uses verifiable rewards over a list of X-ray
abnormalities. The model outputs reasoning that mirrors radiologists systematic
thought process, uncertainty, and differential diagnosis. In
out-of-distribution evaluation, the approach achieves competitive multi-label
classification while improving interpretability. In a reader study with expert
radiologists, full reasoning traces increased confidence, supported error
auditing, and reduced time to finalize reports. We release code and the model
NV-Reason-CXR-3B to support community progress toward trustworthy, explainable
AI in chest radiography and other medical imaging tasks where reasoning quality
is as critical as prediction quality.

</details>


### [13] [Eye-Tracking, Mouse Tracking, Stimulus Tracking,and Decision-Making Datasets in Digital Pathology](https://arxiv.org/abs/2510.24653)
*Veronica Thai,Rui Li,Meng Ling,Shuning Jiang,Jeremy Wolfe,Raghu Machiraju,Yan Hu,Zaibo Li,Anil Parwani,Jian Chen*

Main category: cs.CV

TL;DR: PathoGaze1.0是一个新的行为数据集，旨在研究病理学家在癌症诊断中的视觉搜索和决策过程，数据将用于提高病理学家及AI系统的训练。


<details>
  <summary>Details</summary>
Motivation: 填补病理学领域在诊断错误和不一致性方面缺乏行为数据的空白。

Method: 通过记录眼动、鼠标交互等行为数据来建立生态有效性的数据收集过程。

Result: 本文提出PathoGaze1.0，一个全面的行为数据集，旨在捕捉在癌症诊断过程中，病理学家动态视觉搜索和决策的全过程。该数据集包含来自19名病理学家对397张超大图像的诊断过程的18.69小时的眼动追踪、鼠标交互、刺激跟踪、视口导航及诊断决策数据。

Conclusion: 数据可以用于提升病理学家的训练效果及支持人类专家的人工智能系统的改进。

Abstract: Interpretation of giga-pixel whole-slide images (WSIs) is an important but
difficult task for pathologists. Their diagnostic accuracy is estimated to
average around 70%. Adding a second pathologist does not substantially improve
decision consistency. The field lacks adequate behavioral data to explain
diagnostic errors and inconsistencies. To fill in this gap, we present
PathoGaze1.0, a comprehensive behavioral dataset capturing the dynamic visual
search and decision-making processes of the full diagnostic workflow during
cancer diagnosis. The dataset comprises 18.69 hours of eye-tracking, mouse
interaction, stimulus tracking, viewport navigation, and diagnostic decision
data (EMSVD) collected from 19 pathologists interpreting 397 WSIs. The data
collection process emphasizes ecological validity through an
application-grounded testbed, called PTAH. In total, we recorded 171,909
fixations, 263,320 saccades, and 1,867,362 mouse interaction events. In
addition, such data could also be used to improve the training of both
pathologists and AI systems that might support human experts. All experiments
were preregistered at https://osf.io/hj9a7, and the complete dataset along with
analysis code is available at https://go.osu.edu/pathogaze.

</details>


### [14] [TeleEgo: Benchmarking Egocentric AI Assistants in the Wild](https://arxiv.org/abs/2510.23981)
*Jiaqi Yan,Ruilong Ren,Jingren Liu,Shuning Xu,Ling Wang,Yiheng Wang,Yun Wang,Long Zhang,Xiangyu Chen,Changzhi Sun,Jixiang Luo,Dell Zhang,Hao Sun,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TeleEgo是一个新的基准，旨在评估真实环境中的自我中心AI助手，它结合了视频、音频和文本的多模态输入，聚焦于长时段、流媒体场景下的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法有效评估自我中心AI助手在现实生活中的能力，迫切需要一个能覆盖长时段和多模态的评估工具。

Method: 集合同步的自我中心视频、音频和文本数据，设计12个诊断子任务并提出两个关键评估指标。

Result: TeleEgo拥有超过14小时的数据和3291个经人工验证的问答项，提供了对记忆、理解和跨记忆推理的全面评价。

Conclusion: TeleEgo通过提供丰富的多模态数据和全面的评估指标，推动自我中心AI助手的研究与开发。

Abstract: Egocentric AI assistants in real-world settings must process multi-modal
inputs (video, audio, text), respond in real time, and retain evolving
long-term memory. However, existing benchmarks typically evaluate these
abilities in isolation, lack realistic streaming scenarios, or support only
short-term tasks. We introduce \textbf{TeleEgo}, a long-duration, streaming,
omni-modal benchmark for evaluating egocentric AI assistants in realistic daily
contexts. The dataset features over 14 hours per participant of synchronized
egocentric video, audio, and text across four domains: work \& study, lifestyle
\& routines, social activities, and outings \& culture. All data is aligned on
a unified global timeline and includes high-quality visual narrations and
speech transcripts, curated through human refinement.TeleEgo defines 12
diagnostic subtasks across three core capabilities: Memory (recalling past
events), Understanding (interpreting the current moment), and Cross-Memory
Reasoning (linking distant events). It contains 3,291 human-verified QA items
spanning multiple question formats (single-choice, binary, multi-choice, and
open-ended), evaluated strictly in a streaming setting. We propose two key
metrics -- Real-Time Accuracy and Memory Persistence Time -- to jointly assess
correctness, temporal responsiveness, and long-term retention. TeleEgo provides
a realistic and comprehensive evaluation to advance the development of
practical AI assistants.

</details>


### [15] [AdvBlur: Adversarial Blur for Robust Diabetic Retinopathy Classification and Cross-Domain Generalization](https://arxiv.org/abs/2510.24000)
*Heethanjan Kanagalingam,Thenukan Pathmanathan,Mokeeshan Vathanakumar,Tharmakulasingam Mukunthan*

Main category: cs.CV

TL;DR: 提出了AdvBlur方法通过对抗模糊图像和双损失函数提升糖尿病视网膜病变的分类性能，显著改善了模型在不同图像条件下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变（DR）是全球视力损失的主要原因，早期准确检测能显著改善治疗效果。目前的深度学习模型在面对各种分布变化时表现不佳，导致鲁棒性不足，因此提出新方法以解决这一问题。

Method: AdvBlur方法通过将对抗模糊图像整合入数据集中，并利用双损失函数框架来增强领域泛化能力。通过多种实验评估影响因素，确保方法选择的有效性。

Result: 我们的AdvBlur方法通过集成对抗模糊图像到数据集中，采用双损失函数框架，有效提高了模型在不同数据集上的表现，尤其在未见外部数据集上表现优越。

Conclusion: 实验结果表明，AdvBlur在未见外部数据集上相较于现有最先进的领域泛化DR模型表现出竞争力，验证了其有效性。

Abstract: Diabetic retinopathy (DR) is a leading cause of vision loss worldwide, yet
early and accurate detection can significantly improve treatment outcomes.
While numerous Deep learning (DL) models have been developed to predict DR from
fundus images, many face challenges in maintaining robustness due to
distributional variations caused by differences in acquisition devices,
demographic disparities, and imaging conditions. This paper addresses this
critical limitation by proposing a novel DR classification approach, a method
called AdvBlur. Our method integrates adversarial blurred images into the
dataset and employs a dual-loss function framework to address domain
generalization. This approach effectively mitigates the impact of unseen
distributional variations, as evidenced by comprehensive evaluations across
multiple datasets. Additionally, we conduct extensive experiments to explore
the effects of factors such as camera type, low-quality images, and dataset
size. Furthermore, we perform ablation studies on blurred images and the loss
function to ensure the validity of our choices. The experimental results
demonstrate the effectiveness of our proposed method, achieving competitive
performance compared to state-of-the-art domain generalization DR models on
unseen external datasets.

</details>


### [16] [Towards the Automatic Segmentation, Modeling and Meshing of the Aortic Vessel Tree from Multicenter Acquisitions: An Overview of the SEG.A. 2023 Segmentation of the Aorta Challenge](https://arxiv.org/abs/2510.24009)
*Yuan Jin,Antonio Pepe,Gian Marco Melito,Yuxuan Chen,Yunsu Byeon,Hyeseong Kim,Kyungwon Kim,Doohyun Park,Euijoon Choi,Dosik Hwang,Andriy Myronenko,Dong Yang,Yufan He,Daguang Xu,Ayman El-Ghotni,Mohamed Nabil,Hossam El-Kady,Ahmed Ayyad,Amr Nasr,Marek Wodzinski,Henning Müller,Hyeongyu Kim,Yejee Shin,Abbas Khan,Muhammad Asad,Alexander Zolotarev,Caroline Roney,Anthony Mathur,Martin Benning,Gregory Slabaugh,Theodoros Panagiotis Vagenas,Konstantinos Georgas,George K. Matsopoulos,Jihan Zhang,Zhen Zhang,Liqin Huang,Christian Mayer,Heinrich Mächler,Jan Egger*

Main category: cs.CV

TL;DR: 通过SEG.A.挑战推动主动脉血管树的自动化分析，推出多机构数据集，深度学习方法表现优异。


<details>
  <summary>Details</summary>
Motivation: 推动计算机断层血管造影(CTA)下主动脉血管树的自动化分析进展，解决高质量数据缺乏的问题。

Method: 开展SEG.A.挑战，推出多机构的AVT分割数据集。

Result: 深度学习方法的明显收敛，3D U-Net架构占据最佳提交，模型融合显著提升表现。

Conclusion: 该计划建立了新的性能基准，为未来开发临床可转化工具提供了持续的资源。

Abstract: The automated analysis of the aortic vessel tree (AVT) from computed
tomography angiography (CTA) holds immense clinical potential, but its
development has been impeded by a lack of shared, high-quality data. We
launched the SEG.A. challenge to catalyze progress in this field by introducing
a large, publicly available, multi-institutional dataset for AVT segmentation.
The challenge benchmarked automated algorithms on a hidden test set, with
subsequent optional tasks in surface meshing for computational simulations. Our
findings reveal a clear convergence on deep learning methodologies, with 3D
U-Net architectures dominating the top submissions. A key result was that an
ensemble of the highest-ranking algorithms significantly outperformed
individual models, highlighting the benefits of model fusion. Performance was
strongly linked to algorithmic design, particularly the use of customized
post-processing steps, and the characteristics of the training data. This
initiative not only establishes a new performance benchmark but also provides a
lasting resource to drive future innovation toward robust, clinically
translatable tools.

</details>


### [17] [Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars Science Tasks](https://arxiv.org/abs/2510.24010)
*Mirali Purohit,Bimal Gajera,Vatsal Malaviya,Irish Mehta,Kunal Kasodekar,Jacob Adler,Steven Lu,Umaa Rebbapragada,Hannah Kerner*

Main category: cs.CV

TL;DR: Mars-Bench是第一个用于评估与火星相关任务的基准，填补了火星科学领域缺乏标准化评估框架的空白。


<details>
  <summary>Details</summary>
Motivation: 鉴于火星科学在基础模型应用方面的局限性，建立标准化基准以促进火星相关任务的发展。

Method: 通过提供20个涵盖分类、分割和目标检测的数据集，并利用自然图像、地球卫星数据以及最新的视觉语言模型进行基线评估。

Result: 分析结果表明，火星特定的基础模型可能在性能上优于一般领域的模型，为领域适应的预训练提供了进一步探索的动机。

Conclusion: Mars-Bench为开发和比较火星科学领域的机器学习模型奠定了标准化基础，提示火星特定的基础模型可能优于通用模型。

Abstract: Foundation models have enabled rapid progress across many specialized domains
by leveraging large-scale pre-training on unlabeled data, demonstrating strong
generalization to a variety of downstream tasks. While such models have gained
significant attention in fields like Earth Observation, their application to
Mars science remains limited. A key enabler of progress in other domains has
been the availability of standardized benchmarks that support systematic
evaluation. In contrast, Mars science lacks such benchmarks and standardized
evaluation frameworks, which have limited progress toward developing foundation
models for Martian tasks. To address this gap, we introduce Mars-Bench, the
first benchmark designed to systematically evaluate models across a broad range
of Mars-related tasks using both orbital and surface imagery. Mars-Bench
comprises 20 datasets spanning classification, segmentation, and object
detection, focused on key geologic features such as craters, cones, boulders,
and frost. We provide standardized, ready-to-use datasets and baseline
evaluations using models pre-trained on natural images, Earth satellite data,
and state-of-the-art vision-language models. Results from all analyses suggest
that Mars-specific foundation models may offer advantages over general-domain
counterparts, motivating further exploration of domain-adapted pre-training.
Mars-Bench aims to establish a standardized foundation for developing and
comparing machine learning models for Mars science. Our data, models, and code
are available at: https://mars-bench.github.io/.

</details>


### [18] [AutoPrompt: Automated Red-Teaming of Text-to-Image Models via LLM-Driven Adversarial Prompts](https://arxiv.org/abs/2510.24034)
*Yufan Liu,Wanqian Zhang,Huashan Chen,Lin Wang,Xiaojun Jia,Zheng Lin,Weiping Wang*

Main category: cs.CV

TL;DR: 本研究提出了APPT框架，通过自动生成对抗性后缀，提高文本到图像模型的安全评估，展示了优越的性能和迁移能力。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型在安全机制上存在脆弱性，现有红队评估方法效率低且容易被过滤器阻挡。

Method: 通过大语言模型生成对抗性后缀，并结合优化与微调的交替策略，以及双重规避策略。

Result: APPT框架在红队评估表现上优于现有方法，并具备优秀的零样本迁移能力，能够识别商业API中的关键漏洞。

Conclusion: 提出的APPT框架能够有效生成可读且抗过滤的对抗性后缀，提升了文本到图像模型的安全性评估能力。

Abstract: Despite rapid advancements in text-to-image (T2I) models, their safety
mechanisms are vulnerable to adversarial prompts, which maliciously generate
unsafe images. Current red-teaming methods for proactively assessing such
vulnerabilities usually require white-box access to T2I models, and rely on
inefficient per-prompt optimization, as well as inevitably generate
semantically meaningless prompts easily blocked by filters. In this paper, we
propose APT (AutoPrompT), a black-box framework that leverages large language
models (LLMs) to automatically generate human-readable adversarial suffixes for
benign prompts. We first introduce an alternating optimization-finetuning
pipeline between adversarial suffix optimization and fine-tuning the LLM
utilizing the optimized suffix. Furthermore, we integrates a dual-evasion
strategy in optimization phase, enabling the bypass of both perplexity-based
filter and blacklist word filter: (1) we constrain the LLM generating
human-readable prompts through an auxiliary LLM perplexity scoring, which
starkly contrasts with prior token-level gibberish, and (2) we also introduce
banned-token penalties to suppress the explicit generation of banned-tokens in
blacklist. Extensive experiments demonstrate the excellent red-teaming
performance of our human-readable, filter-resistant adversarial prompts, as
well as superior zero-shot transferability which enables instant adaptation to
unseen prompts and exposes critical vulnerabilities even in commercial APIs
(e.g., Leonardo.Ai.).

</details>


### [19] [Kernelized Sparse Fine-Tuning with Bi-level Parameter Competition for Vision Models](https://arxiv.org/abs/2510.24037)
*Shufan Shen,Junshu Sun,Shuhui Wang,Qingming Huang*

Main category: cs.CV

TL;DR: SNELLA 是一种新型的单阶段稀疏调优方法，通过低秩学习和自适应稀疏分配机制来提高性能并减少内存使用。


<details>
  <summary>Details</summary>
Motivation: 旨在克服当前稀疏调优方法的两阶段流程中的内存消耗和性能限制。

Method: 通过引入非线性核函数的低秩分解来选择性更新权重矩阵，并采用自适应双层稀疏分配机制。

Result: SNELLA 在多个下游任务上展现出优越的性能，尤其在 FGVC 基准测试上较 SPT-LoRA 提高了 1.8% 的 Top-1 准确率，且内存使用减少了 31.1%-39.9%。

Conclusion: SNELLA 提出了一个新的单阶段方法，它在保持较低内存使用的同时实现了最佳性能。

Abstract: Parameter-efficient fine-tuning (PEFT) aims to adapt pre-trained vision
models to downstream tasks. Among PEFT paradigms, sparse tuning achieves
remarkable performance by adjusting only the weights most relevant to
downstream tasks, rather than densely tuning the entire weight matrix. Current
methods follow a two-stage paradigm. First, it locates task-relevant weights by
gradient information, which overlooks the parameter adjustments during
fine-tuning and limits the performance. Second, it updates only the located
weights by applying a sparse mask to the gradient of the weight matrix, which
results in high memory usage due to the storage of all weight matrices in the
optimizer. In this paper, we propose a one-stage method named SNELLA to
overcome the above limitations. For memory usage, SNELLA selectively updates
the weight matrix by adding it to another sparse matrix that is merged by two
low-rank learnable matrices. We extend the low-rank decomposition by
introducing nonlinear kernel functions, thereby increasing the rank of the
resulting merged matrix to prevent the interdependency among weight updates,
enabling better adaptation to downstream tasks. For locating task-relevant
weights, we propose an adaptive bi-level sparsity allocation mechanism that
encourages weights to compete across and inside layers based on their
importance scores in an end-to-end manner. Extensive experiments are conducted
on classification, segmentation, and generation tasks using different
pre-trained vision models. The results show that SNELLA achieves SOTA
performance with low memory usage. Notably, SNELLA obtains 1.8% (91.9% v.s.
90.1%) higher Top-1 accuracy on the FGVC benchmark compared to SPT-LoRA.
Compared to previous methods, SNELLA achieves a memory reduction of 31.1%-39.9%
across models with parameter scales from 86M to 632M. Our source codes are
available at https://github.com/ssfgunner/SNELL.

</details>


### [20] [Enhancing CLIP Robustness via Cross-Modality Alignment](https://arxiv.org/abs/2510.24038)
*Xingyu Zhu,Beier Zhu,Shuo Wang,Kesen Zhao,Hanwang Zhang*

Main category: cs.CV

TL;DR: 本文提出了COLA框架，旨在提高视觉-语言模型在对抗扰动下的分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法多集中于对抗微调，未能有效解决VLM中图像和文本特征的不对齐问题，尤其是在对抗扰动情况下。

Method: COLA利用最优传输方法改善图像和文本特征的对齐，项目对抗图像嵌入到文本特征的子空间。

Result: 通过在14个零样本分类基准上的广泛评估，COLA在处理对抗攻击时，平均提升了6.7%的准确率，且在干净样本上保持高准确性。

Conclusion: COLA有效提升了VLM在多种基准测试中的对抗鲁棒性，特别是在PGD攻击下表现显著。

Abstract: Vision-language models (VLMs) such as CLIP demonstrate strong generalization
in zero-shot classification but remain highly vulnerable to adversarial
perturbations. Existing methods primarily focus on adversarial fine-tuning or
prompt optimization; they often overlook the gaps in CLIP's encoded features,
which is shown as the text and image features lie far apart from each other.
This misalignment is significantly amplified under adversarial perturbations,
leading to severe degradation in classification performance. To address this
problem, we propose Cross-modality Alignment, dubbed COLA, an optimal
transport-based framework that explicitly addresses adversarial misalignment by
restoring both global image-text alignment and local structural consistency in
the feature space. (1) COLA first projects adversarial image embeddings onto a
subspace spanned by class text features, effectively filtering out non-semantic
distortions while preserving discriminative information. (2) It then models
images and texts as discrete distributions over multiple augmented views and
refines their alignment via OT, with the subspace projection seamlessly
integrated into the cost computation. This design ensures stable cross-modal
alignment even under adversarial conditions. COLA is training-free and
compatible with existing fine-tuned models. Extensive evaluations across 14
zero-shot classification benchmarks demonstrate the effectiveness of COLA,
especially with an average improvement of 6.7% on ImageNet and its variants
under PGD adversarial attacks, while maintaining high accuracy on clean
samples.

</details>


### [21] [Beyond Objects: Contextual Synthetic Data Generation for Fine-Grained Classification](https://arxiv.org/abs/2510.24078)
*William Yang,Xindi Wu,Zhiwei Deng,Esin Tureci,Olga Russakovsky*

Main category: cs.CV

TL;DR: 提出BOB策略，以改进合成训练数据生成，取得了在低样本精细分类任务上的优异表现。


<details>
  <summary>Details</summary>
Motivation: 生成有效的合成训练数据用于分类任务仍然面临挑战，尤其是处理少量实数样本时。

Method: 提出了一种名为BOB（BeyondOBjects）的微调策略，以减轻生成数据集中的过拟合和多样性降低问题。

Result: BOB方法在低样本精细分类中表现出色，比DataDream在飞机数据集上提高了7.4%的准确率，且在多个基准中超过之前的研究。

Conclusion: BOB方法通过提取类无关属性，在微调过程中调节模型的生成特点，显著提高了模型在合成数据增强下的分类性能。

Abstract: Text-to-image (T2I) models are increasingly used for synthetic dataset
generation, but generating effective synthetic training data for classification
remains challenging. Fine-tuning a T2I model with a few real examples can help
improve the quality of synthetic training data; however, it may also cause
overfitting and reduce diversity in the generated samples. We propose a
fine-tuning strategy BOB (BeyondOBjects) to mitigate these concerns for
fine-grained classification. Given a small set of real examples, we first
extract class-agnostic attributes such as scene background and object pose. We
then explicitly condition on these attributes during fine-tuning of the T2I
model and marginalize them out during generation. This design mitigates
overfitting, preserves the T2I model's generative prior, reduces estimation
errors, and further minimizes unintended inter-class associations. Extensive
experiments across multiple T2I models, backbones, and datasets show that our
method achieves state-of-the-art performance in low-shot fine-grained
classification when augmented with synthetic data. Concretely, BOB outperforms
DataDream by 7.4% on the Aircraft dataset (from 50.0% to 57.4% when fine-tuning
a CLIP classifier with five real images augmented with 100 synthetic images).
In three of the four benchmarks, fine-tuning downstream models with 5 real
images augmented with BOB achieves better performance than fine-tuning with 10
real images. Collectively, BOB outperforms prior art in 18 of 24 experimental
settings, with 2+% accuracy improvements in 14 of these settings.

</details>


### [22] [OmniText: A Training-Free Generalist for Controllable Text-Image Manipulation](https://arxiv.org/abs/2510.24093)
*Agus Gunawan,Samuel Teodoro,Yun Chen,Soo Ye Kim,Jihyong Oh,Munchurl Kim*

Main category: cs.CV

TL;DR: 本研究提出了 OmniText，一个无需训练的通用文本图像操作框架，解决了文本移除和样式控制等关键问题，展现出优秀的性能。


<details>
  <summary>Details</summary>
Motivation: 针对现有文本内嵌方法在文本移除、样式控制和重复字母生成等方面的局限性，提出一种新的解决方案。

Method: 提出了一种无需训练的通用框架，利用自注意力和交叉注意力机制，处理文本移除和样式控制。

Result: OmniText 在多个文本图像操作任务上展示了卓越的性能，并且在多项任务和指标上超越了其他文本内嵌方法。

Conclusion: OmniText 是第一个能够执行多种文本图像操作的通用方法，具有优越的性能和能力。

Abstract: Recent advancements in diffusion-based text synthesis have demonstrated
significant performance in inserting and editing text within images via
inpainting. However, despite the potential of text inpainting methods, three
key limitations hinder their applicability to broader Text Image Manipulation
(TIM) tasks: (i) the inability to remove text, (ii) the lack of control over
the style of rendered text, and (iii) a tendency to generate duplicated
letters. To address these challenges, we propose OmniText, a training-free
generalist capable of performing a wide range of TIM tasks. Specifically, we
investigate two key properties of cross- and self-attention mechanisms to
enable text removal and to provide control over both text styles and content.
Our findings reveal that text removal can be achieved by applying
self-attention inversion, which mitigates the model's tendency to focus on
surrounding text, thus reducing text hallucinations. Additionally, we
redistribute cross-attention, as increasing the probability of certain text
tokens reduces text hallucination. For controllable inpainting, we introduce
novel loss functions in a latent optimization framework: a cross-attention
content loss to improve text rendering accuracy and a self-attention style loss
to facilitate style customization. Furthermore, we present OmniText-Bench, a
benchmark dataset for evaluating diverse TIM tasks. It includes input images,
target text with masks, and style references, covering diverse applications
such as text removal, rescaling, repositioning, and insertion and editing with
various styles. Our OmniText framework is the first generalist method capable
of performing diverse TIM tasks. It achieves state-of-the-art performance
across multiple tasks and metrics compared to other text inpainting methods and
is comparable with specialist methods.

</details>


### [23] [Enhancing Pre-trained Representation Classifiability can Boost its Interpretability](https://arxiv.org/abs/2510.24105)
*Shufan Shen,Zhaobo Qi,Junshu Sun,Qingming Huang,Qi Tian,Shuhui Wang*

Main category: cs.CV

TL;DR: 研究表明，预训练模型的可解释性与可分类性之间存在正相关，且可通过最大化可解释性来提升可分类性。


<details>
  <summary>Details</summary>
Motivation: 随着预训练视觉模型的广泛应用，提出可解释性的新要求，探索如何同时提高可解释性和可分类性。

Method: 量化表示的可解释性，通过与可解释语义比例的相关性进行量化，提出了固有可解释性评分(IIS)来评估信息损失。

Result: 该论文探讨了预训练视觉模型的表示与可解释性之间的关系，发现可解释性和可分类性之间存在正相关。通过引入固有可解释性评分(IIS)，量化了表示的可解释性，并指出通过最大化可解释性可以进一步提升表示的可分类性，同时在此过程中预测的准确性下降较少。

Conclusion: 可解释性和可分类性的提升可以同时进行，能为视觉模型的应用提供更好的支持。

Abstract: The visual representation of a pre-trained model prioritizes the
classifiability on downstream tasks, while the widespread applications for
pre-trained visual models have posed new requirements for representation
interpretability. However, it remains unclear whether the pre-trained
representations can achieve high interpretability and classifiability
simultaneously. To answer this question, we quantify the representation
interpretability by leveraging its correlation with the ratio of interpretable
semantics within the representations. Given the pre-trained representations,
only the interpretable semantics can be captured by interpretations, whereas
the uninterpretable part leads to information loss. Based on this fact, we
propose the Inherent Interpretability Score (IIS) that evaluates the
information loss, measures the ratio of interpretable semantics, and quantifies
the representation interpretability. In the evaluation of the representation
interpretability with different classifiability, we surprisingly discover that
the interpretability and classifiability are positively correlated, i.e.,
representations with higher classifiability provide more interpretable
semantics that can be captured in the interpretations. This observation further
supports two benefits to the pre-trained representations. First, the
classifiability of representations can be further improved by fine-tuning with
interpretability maximization. Second, with the classifiability improvement for
the representations, we obtain predictions based on their interpretations with
less accuracy degradation. The discovered positive correlation and
corresponding applications show that practitioners can unify the improvements
in interpretability and classifiability for pre-trained vision models. Codes
are available at https://github.com/ssfgunner/IIS.

</details>


### [24] [UHKD: A Unified Framework for Heterogeneous Knowledge Distillation via Frequency-Domain Representations](https://arxiv.org/abs/2510.24116)
*Fengming Yu,Haiwei Pan,Kejia Zhang,Jian Guan,Haiying Jiang*

Main category: cs.CV

TL;DR: UHKD通过在频域中处理中间特征，克服了异构模型之间的表示不一致，有效提高了知识蒸馏的效果。


<details>
  <summary>Details</summary>
Motivation: 由于模型架构的多样性导致的语义差异，现有的知识蒸馏方法在异构场景中表现不佳，因此需要一种新方法来充分利用中间特征。

Method: 采用傅里叶变换捕捉全局特征信息，并结合特征变换模块（FTM）和可学习的特征对齐模块（FAM）进行训练，指导目标为均方误差与Kullback-Leibler散度的结合。

Result: 在CIFAR-100和ImageNet-1K上的实验表明，UHKD在最新方法上分别提高了5.59%和0.83%的性能。

Conclusion: Unified Heterogeneous Knowledge Distillation (UHKD) 是一种有效的框架，能够在异构模型之间统一表示，并有效利用视觉知识。

Abstract: Knowledge distillation (KD) is an effective model compression technique that
transfers knowledge from a high-performance teacher to a lightweight student,
reducing cost while maintaining accuracy. In visual applications, where
large-scale image models are widely used, KD enables efficient deployment.
However, architectural diversity introduces semantic discrepancies that hinder
the use of intermediate representations. Most existing KD methods are designed
for homogeneous models and degrade in heterogeneous scenarios, especially when
intermediate features are involved. Prior studies mainly focus on the logits
space, making limited use of the semantic information in intermediate layers.
To address this limitation, Unified Heterogeneous Knowledge Distillation (UHKD)
is proposed as a framework that leverages intermediate features in the
frequency domain for cross-architecture transfer. Fourier transform is applied
to capture global feature information, alleviating representational
discrepancies between heterogeneous teacher-student pairs. A Feature
Transformation Module (FTM) produces compact frequency-domain representations
of teacher features, while a learnable Feature Alignment Module (FAM) projects
student features and aligns them via multi-level matching. Training is guided
by a joint objective combining mean squared error on intermediate features with
Kullback-Leibler divergence on logits. Experiments on CIFAR-100 and ImageNet-1K
demonstrate gains of 5.59% and 0.83% over the latest method, highlighting UHKD
as an effective approach for unifying heterogeneous representations and
enabling efficient utilization of visual knowledge

</details>


### [25] [ETC: training-free diffusion models acceleration with Error-aware Trend Consistency](https://arxiv.org/abs/2510.24129)
*Jiajian Xie,Hubery Yin,Chen Li,Zhou Zhao,Shengyu Zhang*

Main category: cs.CV

TL;DR: 提出了ETC框架，通过预测去噪趋势和模型特定的误差容忍机制，实现了扩散模型的加速与一致性保障。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有快速扩散方法中，去噪趋势忽视与模型容忍度缺乏控制的问题。

Method: 采用错误感知趋势一致性框架，结合历史去噪模式的预测和模型特定的容错搜索机制。

Result: 提出了一种错误感知趋势一致性（ETC）框架，用于解决扩散模型在生成过程中的采样和一致性问题。ETC利用平滑的扩散轨迹，预测历史去噪模式，并在多个近似步骤中分配这些模式，以加速过程而不偏离；同时，ETC引入了一种模型特定的容错搜索机制，通过识别从不稳定的语义规划到稳定质量细化的过渡点，推导出修正阈值。实验证明，ETC在FLUX的基础上实现了2.65倍的加速，同时一致性只降 degraded 了-0.074 SSIM分数。

Conclusion: ETC框架显著提高了扩散模型的生成速度，并在保持一致性的基础上，支持模型的特定需求。

Abstract: Diffusion models have achieved remarkable generative quality but remain
bottlenecked by costly iterative sampling. Recent training-free methods
accelerate diffusion process by reusing model outputs. However, these methods
ignore denoising trends and lack error control for model-specific tolerance,
leading to trajectory deviations under multi-step reuse and exacerbating
inconsistencies in the generated results. To address these issues, we introduce
Error-aware Trend Consistency (ETC), a framework that (1) introduces a
consistent trend predictor that leverages the smooth continuity of diffusion
trajectories, projecting historical denoising patterns into stable future
directions and progressively distributing them across multiple approximation
steps to achieve acceleration without deviating; (2) proposes a model-specific
error tolerance search mechanism that derives corrective thresholds by
identifying transition points from volatile semantic planning to stable quality
refinement. Experiments show that ETC achieves a 2.65x acceleration over FLUX
with negligible (-0.074 SSIM score) degradation of consistency.

</details>


### [26] [Compositional Image Synthesis with Inference-Time Scaling](https://arxiv.org/abs/2510.24133)
*Minsuk Ji,Sanghyeok Lee,Namhyuk Ahn*

Main category: cs.CV

TL;DR: 该论文提出了一个训练无关的框架，通过结合面向对象的方法和自我优化，来改善现代文本到图像模型在排版真实性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现代文本到图像模型在组合性方面存在挑战，特别是在物体数量、属性和空间关系的渲染上。

Method: 利用大语言模型生成明确的布局，随后将其注入图像生成过程中，并通过面向对象的视觉语言模型对多个候选项进行迭代性重新排序。

Result: 通过该框架，显著提高了排版的忠实度，同时仍然保持了美学质量。

Conclusion: 该框架在场景对齐方面比近期的文本到图像模型表现更强。

Abstract: Despite their impressive realism, modern text-to-image models still struggle
with compositionality, often failing to render accurate object counts,
attributes, and spatial relations. To address this challenge, we present a
training-free framework that combines an object-centric approach with
self-refinement to improve layout faithfulness while preserving aesthetic
quality. Specifically, we leverage large language models (LLMs) to synthesize
explicit layouts from input prompts, and we inject these layouts into the image
generation process, where a object-centric vision-language model (VLM) judge
reranks multiple candidates to select the most prompt-aligned outcome
iteratively. By unifying explicit layout-grounding with self-refine-based
inference-time scaling, our framework achieves stronger scene alignment with
prompts compared to recent text-to-image models. The code are available at
https://github.com/gcl-inha/ReFocus.

</details>


### [27] [VC4VG: Optimizing Video Captions for Text-to-Video Generation](https://arxiv.org/abs/2510.24134)
*Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin*

Main category: cs.CV

TL;DR: 本文提出了VC4VG框架，通过优化字幕质量提高文本到视频生成的效果，并构建了VC4VG-Bench作为评估工具。


<details>
  <summary>Details</summary>
Motivation: 探讨如何优化视频字幕以提升文本到视频生成模型的表现，填补相关策略尚未被充分研究的空白。

Method: 采用多维度分析方法，对字幕内容进行拆解，并设计出系统的字幕设计方法，建立了VC4VG-Bench基准进行评估。

Result: 本研究介绍了VC4VG（视频生成的字幕优化框架），旨在提高文本到视频生成（T2V）模型的性能。经过对字幕内容的分析，提出了一种新的字幕设计方法。此外，我们构建了VC4VG-Bench，这是一个新的基准测试，提供多维度和必要性的指标以评估字幕质量。经过一系列实验，结果表明字幕质量的提高与视频生成性能之间存在强关联，验证了我们的方法的有效性。

Conclusion: 优化的字幕质量对文本到视频生成表现有显著影响，VC4VG框架和VC4VG-Bench为进一步研究提供支持。

Abstract: Recent advances in text-to-video (T2V) generation highlight the critical role
of high-quality video-text pairs in training models capable of producing
coherent and instruction-aligned videos. However, strategies for optimizing
video captions specifically for T2V training remain underexplored. In this
paper, we introduce VC4VG (Video Captioning for Video Generation), a
comprehensive caption optimization framework tailored to the needs of T2V
models.We begin by analyzing caption content from a T2V perspective,
decomposing the essential elements required for video reconstruction into
multiple dimensions, and proposing a principled caption design methodology. To
support evaluation, we construct VC4VG-Bench, a new benchmark featuring
fine-grained, multi-dimensional, and necessity-graded metrics aligned with
T2V-specific requirements.Extensive T2V fine-tuning experiments demonstrate a
strong correlation between improved caption quality and video generation
performance, validating the effectiveness of our approach. We release all
benchmark tools and code at https://github.com/qyr0403/VC4VG to support further
research.

</details>


### [28] [Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning](https://arxiv.org/abs/2510.24152)
*Aodi Wu,Xubo Luo*

Main category: cs.CV

TL;DR: 提出了一种系统框架，通过结构化提示和空间基础，大幅提升了视觉-语言模型在自主驾驶安全关键任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 评估视觉-语言模型在自主驾驶场景理解中的表现，尤其是在感知、预测、规划和干扰检测任务上的能力。

Method: 建立了一个包含四个核心组件的框架，包括混合提示路由器、任务特定提示、视觉组合模块和优化模型推理参数的配置。

Result: 在Phase-1（干净数据）上取得70.87%的平均准确率，Phase-2（损坏数据）上达到72.85%。

Conclusion: 结构化提示和空间基础显著提升了视觉-语言模型在自主驾驶任务中的性能，特别是在安全性至关重要的应用场景中。

Abstract: This technical report presents our solution for the RoboSense Challenge at
IROS 2025, which evaluates Vision-Language Models (VLMs) on autonomous driving
scene understanding across perception, prediction, planning, and corruption
detection tasks. We propose a systematic framework built on four core
components. First, a Mixture-of-Prompts router classifies questions and
dispatches them to task-specific expert prompts, eliminating interference
across diverse question types. Second, task-specific prompts embed explicit
coordinate systems, spatial reasoning rules, role-playing,
Chain-of-Thought/Tree-of-Thought reasoning, and few-shot examples tailored to
each task. Third, a visual assembly module composes multi-view images with
object crops, magenta markers, and adaptive historical frames based on question
requirements. Fourth, we configure model inference parameters (temperature,
top-p, message roles) per task to optimize output quality. Implemented on
Qwen2.5-VL-72B, our approach achieves 70.87% average accuracy on Phase-1 (clean
data) and 72.85% on Phase-2 (corrupted data), demonstrating that structured
prompting and spatial grounding substantially enhance VLM performance on
safety-critical autonomous driving tasks. Code and prompt are available at
https://github.com/wuaodi/UCAS-CSU-phase2.

</details>


### [29] [Vanish into Thin Air: Cross-prompt Universal Adversarial Attacks for SAM2](https://arxiv.org/abs/2510.24195)
*Ziqi Zhou,Yifan Hu,Yufei Song,Zijing Li,Shengshan Hu,Leo Yu Zhang,Dezhong Yao,Long Zheng,Hai Jin*

Main category: cs.CV

TL;DR: 本研究提出了一种新的对抗攻击方法UAP-SAM2，专门针对图像分割模型SAM2，解决了与SAM之间的架构差异导致的挑战，实验结果显示该方法在性能上超过了当前最先进的攻击。


<details>
  <summary>Details</summary>
Motivation: 研究旨在填补SAM2在鲁棒性上的空白，探讨现有对SAM的攻击是否能够直接转移至SAM2。

Method: 设计了目标扫描策略和双语义偏差框架，通过优化UAP来降低提示依赖性及保持语义一致性。

Result: 在六个数据集和两个分割任务上的广泛实验表明，UAP-SAM2在攻击效果上显著优于现有最先进的攻击。

Conclusion: UAP-SAM2方法有效地提高了针对SAM2的对抗攻击能力，并在多项实验中显示出显著优于现有最先进攻击方法的表现。

Abstract: Recent studies reveal the vulnerability of the image segmentation foundation
model SAM to adversarial examples. Its successor, SAM2, has attracted
significant attention due to its strong generalization capability in video
segmentation. However, its robustness remains unexplored, and it is unclear
whether existing attacks on SAM can be directly transferred to SAM2. In this
paper, we first analyze the performance gap of existing attacks between SAM and
SAM2 and highlight two key challenges arising from their architectural
differences: directional guidance from the prompt and semantic entanglement
across consecutive frames. To address these issues, we propose UAP-SAM2, the
first cross-prompt universal adversarial attack against SAM2 driven by dual
semantic deviation. For cross-prompt transferability, we begin by designing a
target-scanning strategy that divides each frame into k regions, each randomly
assigned a prompt, to reduce prompt dependency during optimization. For
effectiveness, we design a dual semantic deviation framework that optimizes a
UAP by distorting the semantics within the current frame and disrupting the
semantic consistency across consecutive frames. Extensive experiments on six
datasets across two segmentation tasks demonstrate the effectiveness of the
proposed method for SAM2. The comparative results show that UAP-SAM2
significantly outperforms state-of-the-art (SOTA) attacks by a large margin.

</details>


### [30] [CLFSeg: A Fuzzy-Logic based Solution for Boundary Clarity and Uncertainty Reduction in Medical Image Segmentation](https://arxiv.org/abs/2510.24202)
*Anshul Kaushal,Kunal Jangid,Vinod K. Kurmi*

Main category: cs.CV

TL;DR: 本研究提出了一种新的基于编码器-解码器的框架CLFSeg，利用模糊卷积模块提高医学图像分割性能，尤其在处理不确定性和类不平衡方面表现突出。


<details>
  <summary>Details</summary>
Motivation: 为了提高癌症类疾病的早期检测和治疗精确度，进行息肉和心脏的准确分割至关重要。

Method: 引入模糊卷积模块与卷积层结合，利用二元交叉熵和Dice损失处理类不平衡问题，进行局部与全局特征的识别。

Result: 提出的CLFSeg模型在四个公开数据集上表现出色，超越了现有的最先进技术（SOTA）性能，关注解剖结构中的相关区域。

Conclusion: CLFSeg在保证计算效率的同时，显著改善医学图像分割性能，展现了在实际医疗诊断场景中的应用潜力。

Abstract: Accurate polyp and cardiac segmentation for early detection and treatment is
essential for the diagnosis and treatment planning of cancer-like diseases.
Traditional convolutional neural network (CNN) based models have represented
limited generalizability, robustness, and inability to handle uncertainty,
which affects the segmentation performance. To solve these problems, this paper
introduces CLFSeg, an encoder-decoder based framework that aggregates the
Fuzzy-Convolutional (FC) module leveraging convolutional layers and fuzzy
logic. This module enhances the segmentation performance by identifying local
and global features while minimizing the uncertainty, noise, and ambiguity in
boundary regions, ensuring computing efficiency. In order to handle class
imbalance problem while focusing on the areas of interest with tiny and
boundary regions, binary cross-entropy (BCE) with dice loss is incorporated.
Our proposed model exhibits exceptional performance on four publicly available
datasets, including CVC-ColonDB, CVC-ClinicDB, EtisLaribPolypDB, and ACDC.
Extensive experiments and visual studies show CLFSeg surpasses the existing
SOTA performance and focuses on relevant regions of interest in anatomical
structures. The proposed CLFSeg improves performance while ensuring computing
efficiency, which makes it a potential solution for real-world medical
diagnostic scenarios. Project page is available at
https://visdomlab.github.io/CLFSeg/

</details>


### [31] [MC-SJD : Maximal Coupling Speculative Jacobi Decoding for Autoregressive Visual Generation Acceleration](https://arxiv.org/abs/2510.24211)
*Junhyuk So,Hyunho Kook,Chaeyeon Jang,Eunhyeok Park*

Main category: cs.CV

TL;DR: MC-SJD是一种新的并行解码框架，通过信息论方法加速自回归视觉生成，保持质量的同时显著提高生成速度。


<details>
  <summary>Details</summary>
Motivation: 当前自回归建模在视觉生成中的应用受限于生成速度较慢，因此需要一种有效的解决方案来加速生成过程。

Method: MC-SJD是基于信息论的coupling方法，通过最大化连续迭代中草稿代币相同的概率来提高生成效率。

Result: 本文提出了一种新的并行解码框架MC-SJD，旨在加速自回归（AR）视觉生成。该方法通过改进Speculative Jacobi Decoding（SJD），解决了标准AR解码在生成过程中的低速问题，尤其是需要多次生成才能得到单一样本的效率低下。MC-SJD通过信息论方法优化了代币生成的稳定性，确保连续迭代的草稿代币尽可能相同，从而显著提高了生成速度，同时保持无损属性，最终在图像和视频生成中获得高达4.2倍和13.3倍的加速。

Conclusion: MC-SJD通过优化代币生成过程显著提高了视觉生成的速度，而不影响输出质量，展示了理论和实践的有效结合。

Abstract: While autoregressive (AR) modeling has recently emerged as a new paradigm in
visual generation, its practical adoption is severely constrained by the slow
inference speed of per-token generation, which often requires thousands of
steps to produce a single sample. To address this challenge, we propose MC-SJD,
a training-free, lossless parallel decoding framework designed to accelerate AR
visual generation by extending the recently introduced Speculative Jacobi
Decoding (SJD). Although SJD shows strong potential for accelerating AR
generation, we demonstrate that token instability across iterations
significantly reduces the acceptance rate, a limitation that primarily arises
from the independent sampling process used during draft token generation. To
overcome this, we introduce MC-SJD, an information-theoretic approach based on
coupling, which substantially accelerates standard SJD by maximizing the
probability of sampling identical draft tokens across consecutive iterations,
all while preserving its lossless property. Remarkably, this method requires
only a single-line modification to the existing algorithm, yet achieves
substantial performance gains, delivering up to a ~4.2x acceleration in image
generation and ~13.3x acceleration in video generation compared to standard AR
decoding, without any degradation in output quality.

</details>


### [32] [Beyond Inference Intervention: Identity-Decoupled Diffusion for Face Anonymization](https://arxiv.org/abs/2510.24213)
*Haoxin Yang,Yihong Lin,Jingdan Kang,Xuemiao Xu,Yue Li,Cheng Xu,Shengfeng He*

Main category: cs.CV

TL;DR: 提出ID²Face框架，通过结构化潜在空间解决身份与非身份属性的纠缠问题，实现更高效的脸部匿名化。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在推理时采用负引导或基于能量的优化，导致身份与非身份属性纠缠，影响视觉保真度和数据效用。

Method: 设计了一种条件扩散模型，采用身份掩蔽学习方案，结合身份变分自编码器和双向潜在对齐。

Result: 通过结构化潜在空间学习，直接和可控的匿名化，并引入正交身份映射策略以进一步抑制身份泄露。

Conclusion: ID²Face在视觉质量、身份抑制和效用保留方面超越了现有方法。

Abstract: Face anonymization aims to conceal identity information while preserving
non-identity attributes. Mainstream diffusion models rely on inference-time
interventions such as negative guidance or energy-based optimization, which are
applied post-training to suppress identity features. These interventions often
introduce distribution shifts and entangle identity with non-identity
attributes, degrading visual fidelity and data utility. To address this, we
propose \textbf{ID\textsuperscript{2}Face}, a training-centric anonymization
framework that removes the need for inference-time optimization. The rationale
of our method is to learn a structured latent space where identity and
non-identity information are explicitly disentangled, enabling direct and
controllable anonymization at inference. To this end, we design a conditional
diffusion model with an identity-masked learning scheme. An Identity-Decoupled
Latent Recomposer uses an Identity Variational Autoencoder to model identity
features, while non-identity attributes are extracted from same-identity pairs
and aligned through bidirectional latent alignment. An Identity-Guided Latent
Harmonizer then fuses these representations via soft-gating conditioned on
noisy feature prediction. The model is trained with a recomposition-based
reconstruction loss to enforce disentanglement. At inference, anonymization is
achieved by sampling a random identity vector from the learned identity space.
To further suppress identity leakage, we introduce an Orthogonal Identity
Mapping strategy that enforces orthogonality between sampled and source
identity vectors. Experiments demonstrate that ID\textsuperscript{2}Face
outperforms existing methods in visual quality, identity suppression, and
utility preservation.

</details>


### [33] [SCOPE: Saliency-Coverage Oriented Token Pruning for Efficient Multimodel LLMs](https://arxiv.org/abs/2510.24214)
*Jinhong Deng,Wen Li,Joey Tianyi Zhou,Yang He*

Main category: cs.CV

TL;DR: 本文提出SCOPE，一种新颖的视觉令牌剪枝策略，通过结合显著性和覆盖度提高MLLM的语义完整性，并在多项实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉令牌剪枝方法无法有效保持所选令牌的语义完整性，因此需要一种新的策略来改进这一过程。

Method: 提出SCOPE策略，通过计算选择的令牌的集合覆盖度和未选择令牌的令牌覆盖增益，迭代选择具有最高SCOPE分数的令牌。

Result: 本文提出了一种新的视觉令牌剪枝策略SCOPE，通过联合建模所选视觉令牌的显著性和覆盖度，来更好地保持语义完整性。我们引入了一套选择的令牌的集合覆盖度，并定义了一个未被选择的令牌的令牌覆盖增益。最后，通过集成显著性分数，我们提出了 SCOPE 分数，迭代选择具有最高 SCOPE 分数的令牌。实验结果表明我们的方法在多项视觉语言理解基准测试中优于以往方法。

Conclusion: SCOPE通过引入显著性和覆盖度的联合建模，显著提升了视觉令牌剪枝的效果，为视觉语言理解提供了更高效的解决方案。

Abstract: Multimodal Large Language Models (MLLMs) typically process a large number of
visual tokens, leading to considerable computational overhead, even though many
of these tokens are redundant. Existing visual token pruning methods primarily
focus on selecting the most salient tokens based on attention scores, resulting
in the semantic incompleteness of the selected tokens. In this paper, we
propose a novel visual token pruning strategy, called
\textbf{S}aliency-\textbf{C}overage \textbf{O}riented token \textbf{P}runing
for \textbf{E}fficient MLLMs (SCOPE), to jointly model both the saliency and
coverage of the selected visual tokens to better preserve semantic
completeness. Specifically, we introduce a set-coverage for a given set of
selected tokens, computed based on the token relationships. We then define a
token-coverage gain for each unselected token, quantifying how much additional
coverage would be obtained by including it. By integrating the saliency score
into the token-coverage gain, we propose our SCOPE score and iteratively select
the token with the highest SCOPE score. We conduct extensive experiments on
multiple vision-language understanding benchmarks using the LLaVA-1.5 and
LLaVA-Next models. Experimental results demonstrate that our method
consistently outperforms prior approaches. Our code is available at
\href{https://github.com/kinredon/SCOPE}{https://github.com/kinredon/SCOPE}.

</details>


### [34] [DeshadowMamba: Deshadowing as 1D Sequential Similarity](https://arxiv.org/abs/2510.24260)
*Zhaotong Yang,Yi Chen,Yanying Li,Shengfeng He,Yangyang Xu,Junyu Dong,Jian Yang,Yong Du*

Main category: cs.CV

TL;DR: 通过引入CrossGate和ColorShift，提升影子去除的模型性能，达到最先进的视觉质量和量化表现


<details>
  <summary>Details</summary>
Motivation: 解决现有基于注意力的方法因固定注意力模式导致的光照线索混合问题，改善结构和色彩一致性

Method: 采用选择性状态空间模型Mamba，通过方向性状态转换传播全局上下文来进行影子去除

Result: 提出了CrossGate和ColorShift正则化，使得影子去除在结构完整性和色彩一致性方面表现优异

Conclusion: DeshadowMamba在影子去除任务上展现了优越的视觉质量和强大的量化性能，适用于公共基准测试。

Abstract: Recent deep models for image shadow removal often rely on attention-based
architectures to capture long-range dependencies. However, their fixed
attention patterns tend to mix illumination cues from irrelevant regions,
leading to distorted structures and inconsistent colors. In this work, we
revisit shadow removal from a sequence modeling perspective and explore the use
of Mamba, a selective state space model that propagates global context through
directional state transitions. These transitions yield an efficient global
receptive field while preserving positional continuity. Despite its potential,
directly applying Mamba to image data is suboptimal, since it lacks awareness
of shadow-non-shadow semantics and remains susceptible to color interference
from nearby regions. To address these limitations, we propose CrossGate, a
directional modulation mechanism that injects shadow-aware similarity into
Mamba's input gate, allowing selective integration of relevant context along
transition axes. To further ensure appearance fidelity, we introduce ColorShift
regularization, a contrastive learning objective driven by global color
statistics. By synthesizing structured informative negatives, it guides the
model to suppress color contamination and achieve robust color restoration.
Together, these components adapt sequence modeling to the structural integrity
and chromatic consistency required for shadow removal. Extensive experiments on
public benchmarks demonstrate that DeshadowMamba achieves state-of-the-art
visual quality and strong quantitative performance.

</details>


### [35] [Training-free Source Attribution of AI-generated Images via Resynthesis](https://arxiv.org/abs/2510.24278)
*Pietro Bongini,Valentina Molinari,Andrea Costanzo,Benedetta Tondi,Mauro Barni*

Main category: cs.CV

TL;DR: 提出了一种基于图像重合成的训练-free 单次源归属方法，并引入新的数据集，实验表明该方法在少样本环境下优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 在样本稀缺条件下，开发一种高效的合成图像源归属方法，使其具备几次学习或零次学习的能力。

Method: 基于图像重合成的单次源归属方法，通过生成描述性提示并与候选源进行重合成，对图像进行归属。

Result: 本研究提出了一种新的训练-free 单次源归属方法，基于图像重合成。它通过生成描述待分析图像的提示，然后利用该提示与所有候选源重合成图像，将图像归属到与原始图像在适当特征空间最接近的模型。此外，我们引入了一个新的合成图像归属数据集，由商业和开源文本转图像生成器生成的人脸图像组成。该数据集提供了一个具有挑战性的归属框架，有助于开发新归属模型及其在不同生成架构上的能力测试。实验结果表明，在仅有少量样本可用于训练或微调时，所提出的重合成方法优于现有技术。

Conclusion: 新提出的重合成方法在样本匮乏时的源归属表现优于现有方法，同时新数据集为未来的研究提供了重要的评估基准。

Abstract: Synthetic image source attribution is a challenging task, especially in data
scarcity conditions requiring few-shot or zero-shot classification
capabilities. We present a new training-free one-shot attribution method based
on image resynthesis. A prompt describing the image under analysis is
generated, then it is used to resynthesize the image with all the candidate
sources. The image is attributed to the model which produced the resynthesis
closest to the original image in a proper feature space. We also introduce a
new dataset for synthetic image attribution consisting of face images from
commercial and open-source text-to-image generators. The dataset provides a
challenging attribution framework, useful for developing new attribution models
and testing their capabilities on different generative architectures. The
dataset structure allows to test approaches based on resynthesis and to compare
them to few-shot methods. Results from state-of-the-art few-shot approaches and
other baselines show that the proposed resynthesis method outperforms existing
techniques when only a few samples are available for training or fine-tuning.
The experiments also demonstrate that the new dataset is a challenging one and
represents a valuable benchmark for developing and evaluating future few-shot
and zero-shot methods.

</details>


### [36] [ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model](https://arxiv.org/abs/2510.24285)
*Juntian Zhang,Song Jin,Chuanqi Cheng,Yuhan Liu,Yankai Lin,Xun Zhang,Yufei Zhang,Fei Jiang,Guojun Yin,Wei Lin,Rui Yan*

Main category: cs.CV

TL;DR: 本文提出ViPER框架，通过自我批评和自我预测迭代提升视觉语言模型的感知能力，证明生成与理解之间的关系，从而在多项任务中实现性能增强。


<details>
  <summary>Details</summary>
Motivation: 由于高质量数据稀缺及现有方法的局限性，视觉语言模型在实际应用中面临视觉感知能力不足的瓶颈，因此亟需解决这一问题。

Method: 提出了一种新型的两阶段任务，将视觉感知学习结构化为渐进的粗到细的过程，并开发了自我引导的框架ViPER，结合图像级和实例级重建与两阶段强化学习策略。

Result: 在Qwen2.5-VL系列上应用ViPER，Qwen-Viper系列在七个不同任务的综合基准测试中平均提升1.7%，在细粒度感知上最高提高6.0%。

Conclusion: ViPER通过自我批评和自我预测的迭代进化方式，在视觉语言模型中实现了卓越的感知能力，同时证明了生成与理解之间的相互关系。

Abstract: The limited capacity for fine-grained visual perception presents a critical
bottleneck for Vision-Language Models (VLMs) in real-world applications.
Addressing this is challenging due to the scarcity of high-quality data and the
limitations of existing methods: supervised fine-tuning (SFT) often compromises
general capabilities, while reinforcement fine-tuning (RFT) prioritizes textual
reasoning over visual perception. To bridge this gap, we propose a novel
two-stage task that structures visual perception learning as a coarse-to-fine
progressive process. Based on this task formulation, we develop ViPER, a
self-bootstrapping framework specifically designed to enable iterative
evolution through self-critiquing and self-prediction. By synergistically
integrating image-level and instance-level reconstruction with a two-stage
reinforcement learning strategy, ViPER establishes a closed-loop training
paradigm, where internally synthesized data directly fuel the enhancement of
perceptual ability. Applied to the Qwen2.5-VL family, ViPER produces the
Qwen-Viper series. With an average gain of 1.7% on seven comprehensive
benchmarks spanning various tasks and up to 6.0% on fine-grained perception,
Qwen-Viper consistently demonstrates superior performance across different
vision-language scenarios while maintaining generalizability. Beyond enabling
self-improvement in perceptual capabilities, ViPER provides concrete evidence
for the reciprocal relationship between generation and understanding, a
breakthrough to developing more autonomous and capable VLMs.

</details>


### [37] [Few-Shot Remote Sensing Image Scene Classification with CLIP and Prompt Learning](https://arxiv.org/abs/2510.24321)
*Ivica Dimitrovski,Vlatko Spasev,Ivan Kitanovski*

Main category: cs.CV

TL;DR: 本研究探索了提示学习在遥感图像场景分类中的有效性，显示其在少样本情况下优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 深入研究提示学习作为适应策略，以解决遥感领域的数据稀缺问题和任务特定的语义适应需求。

Method: 采用提示学习方法，如上下文优化、条件上下文优化、多模态提示学习等，对少样本图像场景分类进行探讨与实验。

Result: 本文研究了通过提示学习（prompt learning）对遥感图像场景分类进行有效适应的方法，尤其是在标签数据稀缺和注释成本高企的背景下。作者评估了多种提示学习方法，并与基线方法进行对比，结果显示在少样本场景下，提示学习表现优于基线。这些研究为未来遥感技术提供了坚实的基础。

Conclusion: 提示学习是一种可扩展且高效的解决方案，有助于克服卫星和航空图像中的领域差距，为未来研究提供了重要基础。

Abstract: Remote sensing applications increasingly rely on deep learning for scene
classification. However, their performance is often constrained by the scarcity
of labeled data and the high cost of annotation across diverse geographic and
sensor domains. While recent vision-language models like CLIP have shown
promise by learning transferable representations at scale by aligning visual
and textual modalities, their direct application to remote sensing remains
suboptimal due to significant domain gaps and the need for task-specific
semantic adaptation. To address this critical challenge, we systematically
explore prompt learning as a lightweight and efficient adaptation strategy for
few-shot remote sensing image scene classification. We evaluate several
representative methods, including Context Optimization, Conditional Context
Optimization, Multi-modal Prompt Learning, and Prompting with Self-Regulating
Constraints. These approaches reflect complementary design philosophies: from
static context optimization to conditional prompts for enhanced generalization,
multi-modal prompts for joint vision-language adaptation, and semantically
regularized prompts for stable learning without forgetting. We benchmark these
prompt-learning methods against two standard baselines: zero-shot CLIP with
hand-crafted prompts and a linear probe trained on frozen CLIP features.
Through extensive experiments on multiple benchmark remote sensing datasets,
including cross-dataset generalization tests, we demonstrate that prompt
learning consistently outperforms both baselines in few-shot scenarios.
Notably, Prompting with Self-Regulating Constraints achieves the most robust
cross-domain performance. Our findings underscore prompt learning as a scalable
and efficient solution for bridging the domain gap in satellite and aerial
imagery, providing a strong foundation for future research in this field.

</details>


### [38] [Stroke Lesion Segmentation in Clinical Workflows: A Modular, Lightweight, and Deployment-Ready Tool](https://arxiv.org/abs/2510.24378)
*Yann Kerverdo,Florent Leray,Youwan Mahé,Stéphanie Leplaideur,Francesca Galassi*

Main category: cs.CV

TL;DR: 提出了	extit{StrokeSeg}框架，将脑卒中病灶分割模型转化为可部署应用，分割性能与原始模型相当，且模型体积减半。


<details>
  <summary>Details</summary>
Motivation: 旨在降低深度学习框架在临床部署中的复杂性，使其更易于应用。

Method: 通过模块化设计、ONNX Runtime推理、量化处理等方式实现高效分割。

Result: 本研究介绍了	extit{StrokeSeg}，一个模块化且轻量化的框架，用于将研究级脑卒中病灶分割模型转化为可部署的应用程序。该框架通过解耦预处理、推理和后处理来提升临床应用的可行性，预处理使用Anima工具箱并输出BIDS兼容格式，推理则使用ONNX Runtime和	exttt{Float16}量化，模型大小减少约50%。在300个亚急性和慢性卒中受试者的留存数据集中，分割性能与原始PyTorch管道等效（Dice差异<10^{-3}），证明了高性能研究管道可以转化为可移植的临床可用工具。

Conclusion: 	extit{StrokeSeg}展示了高效研究模型的临床应用潜力，可作为便携式工具部署。

Abstract: Deep learning frameworks such as nnU-Net achieve state-of-the-art performance
in brain lesion segmentation but remain difficult to deploy clinically due to
heavy dependencies and monolithic design. We introduce \textit{StrokeSeg}, a
modular and lightweight framework that translates research-grade stroke lesion
segmentation models into deployable applications. Preprocessing, inference, and
postprocessing are decoupled: preprocessing relies on the Anima toolbox with
BIDS-compliant outputs, and inference uses ONNX Runtime with \texttt{Float16}
quantisation, reducing model size by about 50\%. \textit{StrokeSeg} provides
both graphical and command-line interfaces and is distributed as Python scripts
and as a standalone Windows executable. On a held-out set of 300 sub-acute and
chronic stroke subjects, segmentation performance was equivalent to the
original PyTorch pipeline (Dice difference $<10^{-3}$), demonstrating that
high-performing research pipelines can be transformed into portable, clinically
usable tools.

</details>


### [39] [When are radiology reports useful for training medical image classifiers?](https://arxiv.org/abs/2510.24385)
*Herman Bergström,Zhongqi Yue,Fredrik D. Johansson*

Main category: cs.CV

TL;DR: 研究放射科报告在医学图像分类中作用，发现预训练和微调结合能有效提升分类性能，尤其在标签关联明显时。


<details>
  <summary>Details</summary>
Motivation: 探讨如何利用放射科报告提升医学图像分类性能，尤其是在标签弱关联的任务中。

Method: 系统性研究放射科报告在医学图像分类中的应用

Result: 报告在预训练和微调阶段的使用显示，标签与文本关联强时预训练有益，但显式图像-文本对齐可能在关联弱时有害；微调结合报告可显著提升分类性能。

Conclusion: 合理利用放射科报告可显著提升医学图像分类的效果，但仍需关注研究中的不足之处。

Abstract: Medical images used to train machine learning models are often accompanied by
radiology reports containing rich expert annotations. However, relying on these
reports as inputs for clinical prediction requires the timely manual work of a
trained radiologist. This raises a natural question: when can radiology reports
be leveraged during training to improve image-only classification? Prior works
are limited to evaluating pre-trained image representations by fine-tuning them
to predict diagnostic labels, often extracted from reports, ignoring tasks with
labels that are weakly associated with the text. To address this gap, we
conduct a systematic study of how radiology reports can be used during both
pre-training and fine-tuning, across diagnostic and prognostic tasks (e.g.,
12-month readmission), and under varying training set sizes. Our findings
reveal that: (1) Leveraging reports during pre-training is beneficial for
downstream classification tasks where the label is well-represented in the
text; however, pre-training through explicit image-text alignment can be
detrimental in settings where it's not; (2) Fine-tuning with reports can lead
to significant improvements and even have a larger impact than the pre-training
method in certain settings. These results provide actionable insights into when
and how to leverage privileged text data to train medical image classifiers
while highlighting gaps in current research.

</details>


### [40] [Unsupervised Detection of Post-Stroke Brain Abnormalities](https://arxiv.org/abs/2510.24398)
*Youwan Mahé,Elise Bannier,Stéphanie Leplaideur,Elisa Fromont,Francesca Galassi*

Main category: cs.CV

TL;DR: 本研究评估了REFLECT，一个基于流的生成模型，用于无监督检测中风患者的病灶和非病灶异常，以改善MRI影像的结构性变化捕获表现。


<details>
  <summary>Details</summary>
Motivation: 中风后的MRI不仅显示病灶，还揭示次级结构变化，这些变化的无监督检测尚不充分。

Method: 利用双专家的中心切片标注对ATLAS数据进行性能评估，采用Free-Response ROC分析方法评价异常图的对象级表现。

Result: IXI训练的模型在ATLAS测试对象上表现出更高的病灶分割和对非病灶异常的敏感性，证明了使用健康解剖结构训练的有效性。

Conclusion: 研究表明，使用健康对照数据训练可以提升对中风患者MRI影像中病灶及非病灶异常的检测效果。

Abstract: Post-stroke MRI not only delineates focal lesions but also reveals secondary
structural changes, such as atrophy and ventricular enlargement. These
abnormalities, increasingly recognised as imaging biomarkers of recovery and
outcome, remain poorly captured by supervised segmentation methods. We evaluate
REFLECT, a flow-based generative model, for unsupervised detection of both
focal and non-lesional abnormalities in post-stroke patients. Using dual-expert
central-slice annotations on ATLAS data, performance was assessed at the object
level with Free-Response ROC analysis for anomaly maps. Two models were trained
on lesion-free slices from stroke patients (ATLAS) and on healthy controls
(IXI) to test the effect of training data. On ATLAS test subjects, the
IXI-trained model achieved higher lesion segmentation (Dice = 0.37 vs 0.27) and
improved sensitivity to non-lesional abnormalities (FROC = 0.62 vs 0.43).
Training on fully healthy anatomy improves the modelling of normal variability,
enabling broader and more reliable detection of structural abnormalities.

</details>


### [41] [GenTrack: A New Generation of Multi-Object Tracking](https://arxiv.org/abs/2510.24399)
*Toan Van Nguyen,Rasmus G. K. Christiansen,Dirk Kraft,Leon Bodenhagen*

Main category: cs.CV

TL;DR: 本论文提出了一种名为GenTrack的新型多目标跟踪方法，通过混合追踪策略和粒子群优化技术，显著提高了目标跟踪的可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 提出一种新型的多目标跟踪方法，以应对未知和时变目标数量的问题，特别是在目标身份一致性和非线性动态管理方面。

Method: 使用混合跟踪方法，结合随机和确定性策略，以及粒子群优化技术，以增强目标跟踪的有效性。

Result: GenTrack在标准基准和真实场景中相较于最先进的跟踪器表现出更优异的性能。

Conclusion: 实验结果显示，GenTrack在多目标跟踪任务中表现优异，尤其在处理目标遮挡和动态变化方面效果显著。

Abstract: This paper introduces a novel multi-object tracking (MOT) method, dubbed
GenTrack, whose main contributions include: a hybrid tracking approach
employing both stochastic and deterministic manners to robustly handle unknown
and time-varying numbers of targets, particularly in maintaining target
identity (ID) consistency and managing nonlinear dynamics, leveraging particle
swarm optimization (PSO) with some proposed fitness measures to guide
stochastic particles toward their target distribution modes, enabling effective
tracking even with weak and noisy object detectors, integration of social
interactions among targets to enhance PSO-guided particles as well as improve
continuous updates of both strong (matched) and weak (unmatched) tracks,
thereby reducing ID switches and track loss, especially during occlusions, a
GenTrack-based redefined visual MOT baseline incorporating a comprehensive
state and observation model based on space consistency, appearance, detection
confidence, track penalties, and social scores for systematic and efficient
target updates, and the first-ever publicly available source-code reference
implementation with minimal dependencies, featuring three variants, including
GenTrack Basic, PSO, and PSO-Social, facilitating flexible reimplementation.
Experimental results have shown that GenTrack provides superior performance on
standard benchmarks and real-world scenarios compared to state-of-the-art
trackers, with integrated implementations of baselines for fair comparison.
Potential directions for future work are also discussed. The source-code
reference implementations of both the proposed method and compared-trackers are
provided on GitHub: https://github.com/SDU-VelKoTek/GenTrack

</details>


### [42] [A Hybrid Approach for Visual Multi-Object Tracking](https://arxiv.org/abs/2510.24410)
*Toan Van Nguyen,Rasmus G. K. Christiansen,Dirk Kraft,Leon Bodenhagen*

Main category: cs.CV

TL;DR: 本文提出了一种结合随机和确定性机制的视觉多目标跟踪方法，通过粒子滤波和粒子群优化确保标识符一致性，性能优于当前最先进的跟踪器。


<details>
  <summary>Details</summary>
Motivation: 在多目标跟踪中，面临未知和时变目标数量的挑战，传统方法在处理非线性动态和标识符一致性时存在不足，因此需要新的方法来解决这些问题。

Method: 通过随机粒子滤波结合粒子群优化来处理非线性动态，运用确定性关联强化标识符一致性，并设计了平滑更新目标状态的方案。

Result: 本文提出了一种视觉多目标跟踪方法，结合了随机和确定性机制，以确保在非线性动态下对未知和时变目标数量的标识符一致性。使用随机粒子滤波器处理非线性动态和非高斯噪声，并借助粒子群优化（PSO）来引导粒子朝向状态分布模式，减少通过提出的基于运动一致性、外观相似性和与邻近目标的社会互动线索的适应度度量的发散。确定性关联进一步通过提出的成本矩阵加强标识符一致性，该矩阵结合了粒子与当前检测之间的空间一致性、检测置信度和轨迹惩罚。接着，提出了一种新方案，平滑更新目标状态，同时保持其身份，尤其是在与其他目标交互和长时间遮挡期间的弱轨迹。此外，基于过去状态的速度回归提供趋势种子速度，增强粒子采样和状态更新。该跟踪器设计用于灵活操作于预录视频和摄像头实时流，未来帧不可用的情况。实验结果确认该方法的性能优于最先进的跟踪器。请参考源代码的实现和比较跟踪器于GitHub上： https://github.com/SDU-VelKoTek/GenTrack2

Conclusion: 本方法在动态目标跟踪中展现了高效和准确的性能，尤其在复杂环境下依旧能够保持标识符一致性。

Abstract: This paper proposes a visual multi-object tracking method that jointly
employs stochastic and deterministic mechanisms to ensure identifier
consistency for unknown and time-varying target numbers under nonlinear
dynamics. A stochastic particle filter addresses nonlinear dynamics and
non-Gaussian noise, with support from particle swarm optimization (PSO) to
guide particles toward state distribution modes and mitigate divergence through
proposed fitness measures incorporating motion consistency, appearance
similarity, and social-interaction cues with neighboring targets. Deterministic
association further enforces identifier consistency via a proposed cost matrix
incorporating spatial consistency between particles and current detections,
detection confidences, and track penalties. Subsequently, a novel scheme is
proposed for the smooth updating of target states while preserving their
identities, particularly for weak tracks during interactions with other targets
and prolonged occlusions. Moreover, velocity regression over past states
provides trend-seed velocities, enhancing particle sampling and state updates.
The proposed tracker is designed to operate flexibly for both pre-recorded
videos and camera live streams, where future frames are unavailable.
Experimental results confirm superior performance compared to state-of-the-art
trackers. The source-code reference implementations of both the proposed method
and compared-trackers are provided on GitHub:
https://github.com/SDU-VelKoTek/GenTrack2

</details>


### [43] [50 Years of Water Body Monitoring: The Case of Qaraaoun Reservoir, Lebanon](https://arxiv.org/abs/2510.24413)
*Ali Ahmad Faour,Nabil Amacha,Ali J. Ghandour*

Main category: cs.CV

TL;DR: 本研究通过集成卫星遥感和机器学习，提出了一种无传感器的水库监测方法，展示了其实用性和高准确性。


<details>
  <summary>Details</summary>
Motivation: 为了克服传感器故障和维护能力有限的挑战，实现对黎巴嫩Qaraaoun水库的可持续管理

Method: 采用开源卫星图像、先进的水体范围分割和机器学习进行水库表面面积和体积的实时估算

Result: 提出的水分割指数与地面实测数据一致度超过95%；SVR模型的误差低于1.5%，决定系数超过0.98，显示出方法的有效性和经济性

Conclusion: 该方法为水库的持续监测提供了切实可行的解决方案，可以推广到其他水体，并为气候变化和环境模式研究提供了重要的时序数据。

Abstract: The sustainable management of the Qaraaoun Reservoir, the largest surface
water body in Lebanon located in the Bekaa Plain, depends on reliable
monitoring of its storage volume despite frequent sensor malfunctions and
limited maintenance capacity. This study introduces a sensor-free approach that
integrates open-source satellite imagery, advanced water-extent segmentation,
and machine learning to estimate the reservoir surface area and volume in near
real time. Sentinel-2 and Landsat images are processed, where surface water is
delineated using a newly proposed water segmentation index. A machine learning
model based on Support Vector Regression (SVR) is trained on a curated dataset
that includes water surface area, water level, and water volume calculations
using a reservoir bathymetry survey. The model is then able to estimate
reservoir volume relying solely on surface area extracted from satellite
imagery, without the need for ground measurements. Water segmentation using the
proposed index aligns with ground truth for more than 95 percent of the
shoreline. Hyperparameter tuning with GridSearchCV yields an optimized SVR
performance with error under 1.5 percent of full reservoir capacity and
coefficients of determination exceeding 0.98. These results demonstrate the
robustness and cost-effectiveness of the method, offering a practical solution
for continuous, sensor-independent monitoring of reservoir storage. The
proposed methodology can be replicated for other water bodies, and the
resulting 50 years of time-series data is valuable for research on climate
change and environmental patterns.

</details>


### [44] [XAI Evaluation Framework for Semantic Segmentation](https://arxiv.org/abs/2510.24414)
*Reem Hammoud,Abdul karim Gizzini,Ali J. Ghandour*

Main category: cs.CV

TL;DR: 本文提出了一个新的框架用于评估语义分割中的可解释人工智能，强调了评估方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在安全关键领域的应用增长，确保AI模型的透明度和可信度变得至关重要，而目前对语义分割的XAI评估方法尚不充分。

Method: 通过建立一个综合系统的评估框架，专注于语义分割中的可解释性，采用了像素级评估和量化指标。

Result: 本文提出了一个专门针对语义分割的可解释人工智能（XAI）评估框架，该框架考虑了空间和上下文的任务复杂性。通过使用像素级评估策略和精心设计的指标，框架可以提供细粒度的可解释性见解。经过模拟结果的验证，显示出这一方法的效率、鲁棒性和可靠性。

Conclusion: 作者的研究为提升语义分割模型的透明性与可靠性提供了新的评估工具，推动了可解释人工智能的发展。

Abstract: Ensuring transparency and trust in artificial intelligence (AI) models is
essential, particularly as they are increasingly applied in safety-critical and
high-stakes domains. Explainable AI (XAI) has emerged as a promising approach
to address this challenge, yet the rigorous evaluation of XAI methods remains
crucial for optimizing the trade-offs between model complexity, predictive
performance, and interpretability. While extensive progress has been achieved
in evaluating XAI techniques for classification tasks, evaluation strategies
tailored to semantic segmentation remain relatively underexplored. This work
introduces a comprehensive and systematic evaluation framework specifically
designed for assessing XAI in semantic segmentation, explicitly accounting for
both spatial and contextual task complexities. The framework employs
pixel-level evaluation strategies and carefully designed metrics to provide
fine-grained interpretability insights. Simulation results using recently
adapted class activation mapping (CAM)-based XAI schemes demonstrate the
efficiency, robustness, and reliability of the proposed methodology. These
findings contribute to advancing transparent, trustworthy, and accountable
semantic segmentation models.

</details>


### [45] [Deeply-Conditioned Image Compression via Self-Generated Priors](https://arxiv.org/abs/2510.24437)
*Zhineng Zhao,Zhihai He,Zikun Zhou,Siwei Ma,Yaowei Wang*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的图像压缩框架，通过使用自生成先验来有效解耦信息流，改善低比特率下的图像质量。


<details>
  <summary>Details</summary>
Motivation: 限制当前学习图像压缩（LIC）方法在建模自然图像复杂相关结构方面的能力，特别是固定全局结构与瞬态局部纹理的纠缠问题。

Method: 使用深层条件调制压缩流程，首先编码自生成先验以捕捉图像结构骨架，然后将其用于整体调制分析变换，从而专注于高熵残差细节。

Result: 提出了一种基于功能分解的框架（DCIC-sgp），通过自生成先验全面调制整个压缩流程，显著降低几何变形伪影，并提高性能。

Conclusion: 实验验证该方法在低比特率下显著减少几何变形伪影，且在多项数据集上相较于VVC测试模型具有竞争力的性能。

Abstract: Learned image compression (LIC) has shown great promise for achieving high
rate-distortion performance. However, current LIC methods are often limited in
their capability to model the complex correlation structures inherent in
natural images, particularly the entanglement of invariant global structures
with transient local textures within a single monolithic representation. This
limitation precipitates severe geometric deformation at low bitrates. To
address this, we introduce a framework predicated on functional decomposition,
which we term Deeply-Conditioned Image Compression via self-generated priors
(DCIC-sgp). Our central idea is to first encode a potent, self-generated prior
to encapsulate the image's structural backbone. This prior is subsequently
utilized not as mere side-information, but to holistically modulate the entire
compression pipeline. This deep conditioning, most critically of the analysis
transform, liberates it to dedicate its representational capacity to the
residual, high-entropy details. This hierarchical, dependency-driven approach
achieves an effective disentanglement of information streams. Our extensive
experiments validate this assertion; visual analysis demonstrates that our
method substantially mitigates the geometric deformation artifacts that plague
conventional codecs at low bitrates. Quantitatively, our framework establishes
highly competitive performance, achieving significant BD-rate reductions of
14.4%, 15.7%, and 15.1% against the VVC test model VTM-12.1 on the Kodak, CLIC,
and Tecnick datasets.

</details>


### [46] [Rethinking Visual Intelligence: Insights from Video Pretraining](https://arxiv.org/abs/2510.24448)
*Pablo Acuaviva,Aram Davtyan,Mariam Hassan,Sebastian Stapf,Ahmad Rahimi,Alexandre Alahi,Paolo Favaro*

Main category: cs.CV

TL;DR: 该研究探索视频扩散模型如何通过视频预训练提升视觉任务的适应性和效率。


<details>
  <summary>Details</summary>
Motivation: 大规模的预训练使得系统能够快速适应语言领域的新问题，但在视觉领域效果不佳，因此探索视频扩散模型作为弥补这种差距的方向。

Method: 设计控制评估，比较预训练的大语言模型和视频扩散模型在不同任务下的表现。

Result: 在多个基准测试中，视频扩散模型显示出比语言模型更高的数据效率。

Conclusion: 视频预训练提供了支持视觉基础模型进展的归纳偏差。

Abstract: Large language models (LLMs) have demonstrated that large-scale pretraining
enables systems to adapt rapidly to new problems with little supervision in the
language domain. This success, however, has not translated as effectively to
the visual domain, where models, including LLMs, continue to struggle with
compositional understanding, sample efficiency, and general-purpose
problem-solving. We investigate Video Diffusion Models (VDMs) as a promising
direction for bridging this gap. Pretraining on spatiotemporal data endows
these models with strong inductive biases for structure and dynamics, which we
hypothesize can support broad task adaptability. To test this, we design a
controlled evaluation in which both a pretrained LLM and a pretrained VDM are
equipped with lightweight adapters and presented with tasks in their natural
modalities. Across benchmarks including ARC-AGI, ConceptARC, visual games,
route planning, and cellular automata, VDMs demonstrate higher data efficiency
than their language counterparts. Taken together, our results indicate that
video pretraining offers inductive biases that support progress toward visual
foundation models.

</details>


### [47] [A Critical Study towards the Detection of Parkinsons Disease using ML Technologies](https://arxiv.org/abs/2510.24456)
*Vivek Chetia,Abdul Taher Khan,Rahish Gogoi,David Kapsian Khual,Purnendu Bikash,Sajal Saha*

Main category: cs.CV

TL;DR: 本文提出了一种深度学习技术，用于分类茶叶疾病并评估受损区域，通过比较不同模型的表现，找出最佳方案。


<details>
  <summary>Details</summary>
Motivation: 利用深度学习技术识别和分类茶叶疾病，从而帮助农业生产，保障茶叶质量和产量。

Method: 评估多个深度学习模型（SSD MobileNet V2和Faster R-CNN ResNet50 V1）进行目标检测，利用Mask R-CNN进行实例分割，计算叶片受损区域。

Result: 通过比较SSD MobileNet V2和Faster R-CNN ResNet50 V1两种模型，发现后者在准确性上表现更好，同时开发了自定义方法进行叶片病变面积的计算。

Conclusion: Faster R-CNN ResNet50 V1在茶叶疾病分类和区域识别任务中优于SSD MobileNet V2，能够有效提升农作物病害识别效率。

Abstract: The proposed solution is Deep Learning Technique that will be able classify
three types of tea leaves diseases from which two diseases are caused by the
pests and one due to pathogens (infectious organisms) and environmental
conditions and also show the area damaged by a disease in leaves. Namely Red
Rust, Helopeltis and Red spider mite respectively. In this paper we have
evaluated two models namely SSD MobileNet V2 and Faster R-CNN ResNet50 V1 for
the object detection. The SSD MobileNet V2 gave precision of 0.209 for IOU
range of 0.50:0.95 with recall of 0.02 on IOU 0.50:0.95 and final mAP of 20.9%.
While Faster R-CNN ResNet50 V1 has precision of 0.252 on IOU range of 0.50:0.95
and recall of 0.044 on IOU of 0.50:0.95 with a mAP of 25%, which is better than
SSD. Also used Mask R-CNN for Object Instance Segmentation where we have
implemented our custom method to calculate the damaged diseased portion of
leaves. Keywords: Tea Leaf Disease, Deep Learning, Red Rust, Helopeltis and Red
Spider Mite, SSD MobileNet V2, Faster R-CNN ResNet50 V1 and Mask RCNN.

</details>


### [48] [Kineo: Calibration-Free Metric Motion Capture From Sparse RGB Cameras](https://arxiv.org/abs/2510.24464)
*Charles Javerliat,Pierre Raimbaud,Guillaume Lavoué*

Main category: cs.CV

TL;DR: Kineo是一个全自动的无标记运动捕捉管道，性能优于现有无校准方法，显著提高了重建精度并降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决现有无校准方法中的高计算成本和重建精度下降的问题，使运动捕捉技术更易于为非专业人士和实际应用所接受。

Method: 开发了一种完全自动的标记无关运动捕捉管道（Kineo），旨在利用非同步、未校准的消费级RGB相机进行视频捕捉。

Result: Kineo在EgoHumans和Human3.6M数据集上的评估表明，与之前的无校准方法相比，Kineo在多个指标上显著改进，减少了83-85%的相机平移误差和86-92%的相机角度误差，以及83-91%的世界平均关节误差（W-MPJPE）。

Conclusion: Kineo有效支持实时多视角序列处理，并促进了运动捕捉技术的可重现性和实用性。其完整管道和评估代码已开放发布。

Abstract: Markerless multiview motion capture is often constrained by the need for
precise camera calibration, limiting accessibility for non-experts and
in-the-wild captures. Existing calibration-free approaches mitigate this
requirement but suffer from high computational cost and reduced reconstruction
accuracy.
  We present Kineo, a fully automatic, calibration-free pipeline for markerless
motion capture from videos captured by unsynchronized, uncalibrated,
consumer-grade RGB cameras. Kineo leverages 2D keypoints from off-the-shelf
detectors to simultaneously calibrate cameras, including Brown-Conrady
distortion coefficients, and reconstruct 3D keypoints and dense scene point
maps at metric scale. A confidence-driven spatio-temporal keypoint sampling
strategy, combined with graph-based global optimization, ensures robust
calibration at a fixed computational cost independent of sequence length. We
further introduce a pairwise reprojection consensus score to quantify 3D
reconstruction reliability for downstream tasks.
  Evaluations on EgoHumans and Human3.6M demonstrate substantial improvements
over prior calibration-free methods. Compared to previous state-of-the-art
approaches, Kineo reduces camera translation error by approximately 83-85%,
camera angular error by 86-92%, and world mean-per-joint error (W-MPJPE) by
83-91%.
  Kineo is also efficient in real-world scenarios, processing multi-view
sequences faster than their duration in specific configuration (e.g., 36min to
process 1h20min of footage). The full pipeline and evaluation code are openly
released to promote reproducibility and practical adoption at
https://liris-xr.github.io/kineo/.

</details>


### [49] [Decoupled MeanFlow: Turning Flow Models into Flow Maps for Accelerated Sampling](https://arxiv.org/abs/2510.24474)
*Kyungmin Lee,Sihyun Yu,Jinwoo Shin*

Main category: cs.CV

TL;DR: 研究提出了一种新解码策略，成功将流模型转换为流映射模型，显著提升了生成速度和质量。


<details>
  <summary>Details</summary>
Motivation: 针对生成模型在采样时因离散化误差而需要多个去噪步骤的问题，提出了一种改进方法。

Method: 提出了一种简单的解码策略 Decoupled MeanFlow，能够在不改变架构的情况下将流模型转换为流映射模型。

Result: 在 ImageNet 数据集上，我们的方法在1步和4步的FID值上均优于现有技术，且推断速度提高100倍以上。

Conclusion: 我们的方法在较少的步数内实现了高质量的生成，效率显著提高。

Abstract: Denoising generative models, such as diffusion and flow-based models, produce
high-quality samples but require many denoising steps due to discretization
error. Flow maps, which estimate the average velocity between timesteps,
mitigate this error and enable faster sampling. However, their training
typically demands architectural changes that limit compatibility with
pretrained flow models. We introduce Decoupled MeanFlow, a simple decoding
strategy that converts flow models into flow map models without architectural
modifications. Our method conditions the final blocks of diffusion transformers
on the subsequent timestep, allowing pretrained flow models to be directly
repurposed as flow maps. Combined with enhanced training techniques, this
design enables high-quality generation in as few as 1 to 4 steps. Notably, we
find that training flow models and subsequently converting them is more
efficient and effective than training flow maps from scratch. On ImageNet
256x256 and 512x512, our models attain 1-step FID of 2.16 and 2.12,
respectively, surpassing prior art by a large margin. Furthermore, we achieve
FID of 1.51 and 1.68 when increasing the steps to 4, which nearly matches the
performance of flow models while delivering over 100x faster inference.

</details>


### [50] [Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs](https://arxiv.org/abs/2510.24514)
*Huanyu Zhang,Wenshan Wu,Chengzu Li,Ning Shang,Yan Xia,Yangyu Huang,Yifan Zhang,Li Dong,Zhang Zhang,Liang Wang,Tieniu Tan,Furu Wei*

Main category: cs.CV

TL;DR: Latent Sketchpad框架通过集成生成视觉思维与文本推理，提升了多模态大型语言模型的推理能力和人机交互。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型在视觉理解方面表现优秀，但在需要视觉规划和想象的复杂场景中往往表现不佳。

Method: 通过引入上下文感知的视觉头和预训练的草图解码器，将模态的文本推理与视觉生成过程结合，增强了模型的内部思维过程。

Result: 提出了一种新的框架Latent Sketchpad，为多模态大型语言模型提供内部视觉草稿，增强其生成视觉思维的能力。

Conclusion: Latent Sketchpad能提高推理性能，拓展视觉思考能力，为更丰富的人机交互和更广泛的应用打开了新的机会。

Abstract: While Multimodal Large Language Models (MLLMs) excel at visual understanding,
they often struggle in complex scenarios that require visual planning and
imagination. Inspired by how humans use sketching as a form of visual thinking
to develop and communicate ideas, we introduce Latent Sketchpad, a framework
that equips MLLMs with an internal visual scratchpad. The internal visual
representations of MLLMs have traditionally been confined to perceptual
understanding. We repurpose them to support generative visual thought without
compromising reasoning ability. Building on frontier MLLMs, our approach
integrates visual generation directly into their native autoregressive
reasoning process. It allows the model to interleave textual reasoning with the
generation of visual latents. These latents guide the internal thought process
and can be translated into sketch images for interpretability. To realize this,
we introduce two components: a Context-Aware Vision Head autoregressively
produces visual representations, and a pretrained Sketch Decoder renders these
into human-interpretable images. We evaluate the framework on our new dataset
MazePlanning. Experiments across various MLLMs show that Latent Sketchpad
delivers comparable or even superior reasoning performance to their backbone.
It further generalizes across distinct frontier MLLMs, including Gemma3 and
Qwen2.5-VL. By extending model's textual reasoning to visual thinking, our
framework opens new opportunities for richer human-computer interaction and
broader applications. More details and resources are available on our project
page: https://latent-sketchpad.github.io/.

</details>


### [51] [Group Relative Attention Guidance for Image Editing](https://arxiv.org/abs/2510.24657)
*Xuanpu Zhang,Xuesong Niu,Ruidong Chen,Dan Song,Jianhao Zeng,Penghui Du,Haoxiang Cao,Kai Wu,An-an Liu*

Main category: cs.CV

TL;DR: 提出了一种新的图像编辑方法GRAG，优化了对编辑程度的控制，增强了编辑质量，低代码实现和与现有方法的比较。


<details>
  <summary>Details</summary>
Motivation: 现有的图像编辑方法对编辑程度控制不足，限制了个性化结果的实现。

Method: 基于MM-Attention机制提出Group Relative Attention Guidance，调整不同token的delta值以控制编辑强度。

Result: GRAG在多个图像编辑框架中表现出色，代码易于集成，并且在编辑质量和控制精度上超过了传统方法。

Conclusion: GRAG方法在图像编辑上提供了更好的控制和质量，简化了实现过程。

Abstract: Recently, image editing based on Diffusion-in-Transformer models has
undergone rapid development. However, existing editing methods often lack
effective control over the degree of editing, limiting their ability to achieve
more customized results. To address this limitation, we investigate the
MM-Attention mechanism within the DiT model and observe that the Query and Key
tokens share a bias vector that is only layer-dependent. We interpret this bias
as representing the model's inherent editing behavior, while the delta between
each token and its corresponding bias encodes the content-specific editing
signals. Based on this insight, we propose Group Relative Attention Guidance, a
simple yet effective method that reweights the delta values of different tokens
to modulate the focus of the model on the input image relative to the editing
instruction, enabling continuous and fine-grained control over editing
intensity without any tuning. Extensive experiments conducted on existing image
editing frameworks demonstrate that GRAG can be integrated with as few as four
lines of code, consistently enhancing editing quality. Moreover, compared to
the commonly used Classifier-Free Guidance, GRAG achieves smoother and more
precise control over the degree of editing. Our code will be released at
https://github.com/little-misfit/GRAG-Image-Editing.

</details>


### [52] [SAGE: Structure-Aware Generative Video Transitions between Diverse Clips](https://arxiv.org/abs/2510.24667)
*Mia Kan,Yilin Liu,Niloy Mitra*

Main category: cs.CV

TL;DR: 本文提出了一种新方法SAGE，用于在视频片段之间生成平滑且语义一致的过渡，克服了传统和生成技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有视频过渡技术在处理不同语义和时间跨度的视频片段时存在局限性，因此需要一种新方法来改善过渡效果。

Method: SAGE结合了结构指导（通过线条地图和运动流提供）和生成合成，采用无监督的方法实现视频片段之间的平滑过渡。

Result: 通过大量实验和与现有技术的比较，SAGE展示了明显的优势，特别是在生成多样化视频片段之间的过渡时。

Conclusion: SAGE在定量指标和用户研究中均优于现有的经典和生成基线方法，展示了其在视频过渡生成中的有效性和创新性。

Abstract: Video transitions aim to synthesize intermediate frames between two clips,
but naive approaches such as linear blending introduce artifacts that limit
professional use or break temporal coherence. Traditional techniques
(cross-fades, morphing, frame interpolation) and recent generative inbetweening
methods can produce high-quality plausible intermediates, but they struggle
with bridging diverse clips involving large temporal gaps or significant
semantic differences, leaving a gap for content-aware and visually coherent
transitions. We address this challenge by drawing on artistic workflows,
distilling strategies such as aligning silhouettes and interpolating salient
features to preserve structure and perceptual continuity. Building on this, we
propose SAGE (Structure-Aware Generative vidEo transitions) as a zeroshot
approach that combines structural guidance, provided via line maps and motion
flow, with generative synthesis, enabling smooth, semantically consistent
transitions without fine-tuning. Extensive experiments and comparison with
current alternatives, namely [FILM, TVG, DiffMorpher, VACE, GI], demonstrate
that SAGE outperforms both classical and generative baselines on quantitative
metrics and user studies for producing transitions between diverse clips. Code
to be released on acceptance.

</details>


### [53] [MIC-BEV: Multi-Infrastructure Camera Bird's-Eye-View Transformer with Relation-Aware Fusion for 3D Object Detection](https://arxiv.org/abs/2510.24688)
*Yun Zhang,Zhaoliang Zheng,Johnson Liu,Zhiyu Huang,Zewei Zhou,Zonglin Meng,Tianhui Cai,Jiaqi Ma*

Main category: cs.CV

TL;DR: 本文提出了一种新的多摄像头3D物体检测框架MIC-BEV，能够在各种条件下高效工作，具有良好的实际应用前景。


<details>
  <summary>Details</summary>
Motivation: 基础设施感知在智能交通系统中至关重要，但现有模型在多相机环境中表现不佳。

Method: 提出了一种基于Transformer的鸟瞰视图感知框架，通过图增强融合模块将多视角图像特征整合到鸟瞰图空间。

Result: MIC-BEV在M2I和RoScenes数据集上的实验显示，其在3D物体检测上实现了最先进的性能，并在极端天气和传感器退化条件下依然稳健。

Conclusion: MIC-BEV在3D物体检测中表现出色，能够应对各种恶劣环境，显示出实际应用的潜力。

Abstract: Infrastructure-based perception plays a crucial role in intelligent
transportation systems, offering global situational awareness and enabling
cooperative autonomy. However, existing camera-based detection models often
underperform in such scenarios due to challenges such as multi-view
infrastructure setup, diverse camera configurations, degraded visual inputs,
and various road layouts. We introduce MIC-BEV, a Transformer-based
bird's-eye-view (BEV) perception framework for infrastructure-based
multi-camera 3D object detection. MIC-BEV flexibly supports a variable number
of cameras with heterogeneous intrinsic and extrinsic parameters and
demonstrates strong robustness under sensor degradation. The proposed
graph-enhanced fusion module in MIC-BEV integrates multi-view image features
into the BEV space by exploiting geometric relationships between cameras and
BEV cells alongside latent visual cues. To support training and evaluation, we
introduce M2I, a synthetic dataset for infrastructure-based object detection,
featuring diverse camera configurations, road layouts, and environmental
conditions. Extensive experiments on both M2I and the real-world dataset
RoScenes demonstrate that MIC-BEV achieves state-of-the-art performance in 3D
object detection. It also remains robust under challenging conditions,
including extreme weather and sensor degradation. These results highlight the
potential of MIC-BEV for real-world deployment. The dataset and source code are
available at: https://github.com/HandsomeYun/MIC-BEV.

</details>


### [54] [Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers?](https://arxiv.org/abs/2510.24709)
*Yihao Li,Saeed Salehi,Lyle Ungar,Konrad P. Kording*

Main category: cs.CV

TL;DR: 研究表明，在自监督训练的视觉变换器中，对象绑定能力以高准确率显现，而在ImageNet监督模型中则明显较弱。


<details>
  <summary>Details</summary>
Motivation: 研究对象绑定，即大脑将多种特征整合成一个整体的能力，探讨这一能力是否在经过预训练的视觉变换器（ViTs）中自然出现。

Method: 应用相似性探测器从ViT的补丁嵌入中解码是否同属同一对象的特性，并对不同训练的方法进行比较分析。

Result: 通过相似性探测器解码ViT中是否属于同一对象的特性，准确率超过90%。

Conclusion: 发现对象绑定是自监督预训练的结果，具体训练目标促成了这一能力的出现，挑战了ViTs缺乏对象绑定的观点。

Abstract: Object binding, the brain's ability to bind the many features that
collectively represent an object into a coherent whole, is central to human
cognition. It groups low-level perceptual features into high-level object
representations, stores those objects efficiently and compositionally in
memory, and supports human reasoning about individual object instances. While
prior work often imposes object-centric attention (e.g., Slot Attention)
explicitly to probe these benefits, it remains unclear whether this ability
naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they
could: recognizing which patches belong to the same object should be useful for
downstream prediction and thus guide attention. Motivated by the quadratic
nature of self-attention, we hypothesize that ViTs represent whether two
patches belong to the same object, a property we term IsSameObject. We decode
IsSameObject from patch embeddings across ViT layers using a similarity probe,
which reaches over 90% accuracy. Crucially, this object-binding capability
emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker
in ImageNet-supervised models, suggesting that binding is not a trivial
architectural artifact, but an ability acquired through specific pretraining
objectives. We further discover that IsSameObject is encoded in a
low-dimensional subspace on top of object features, and that this signal
actively guides attention. Ablating IsSameObject from model activations
degrades downstream performance and works against the learning objective,
implying that emergent object binding naturally serves the pretraining
objective. Our findings challenge the view that ViTs lack object binding and
highlight how symbolic knowledge of "which parts belong together" emerges
naturally in a connectionist system.

</details>


### [55] [Routing Matters in MoE: Scaling Diffusion Transformers with Explicit Routing Guidance](https://arxiv.org/abs/2510.24711)
*Yujie Wei,Shiwei Zhang,Hangjie Yuan,Yujin Han,Zhekai Chen,Jiayu Wang,Difan Zou,Xihui Liu,Yingya Zhang,Yu Liu,Hongming Shan*

Main category: cs.CV

TL;DR: 本文提出ProMoE，一个增强专家专业化的Mixture-of-Experts框架，成功改善了视觉领域模型的性能。


<details>
  <summary>Details</summary>
Motivation: 由于语言和视觉token在语义密度和功能多样性上的根本差异，现有的MoE在扩散变换器中的应用效果有限。

Method: 提出一种具有两步路由和显式路由指导的Mixture-of-Experts (MoE)框架，以促进专家的专业化。

Result: 在ImageNet基准测试中，ProMoE在Rectified Flow和DDPM训练目标下超越了当前最先进的方法。

Conclusion: ProMoE在图像处理任务中表现优越，显著超过现有的先进方法，凸显了其在视觉领域的有效性。

Abstract: Mixture-of-Experts (MoE) has emerged as a powerful paradigm for scaling model
capacity while preserving computational efficiency. Despite its notable success
in large language models (LLMs), existing attempts to apply MoE to Diffusion
Transformers (DiTs) have yielded limited gains. We attribute this gap to
fundamental differences between language and visual tokens. Language tokens are
semantically dense with pronounced inter-token variation, while visual tokens
exhibit spatial redundancy and functional heterogeneity, hindering expert
specialization in vision MoE. To this end, we present ProMoE, an MoE framework
featuring a two-step router with explicit routing guidance that promotes expert
specialization. Specifically, this guidance encourages the router to partition
image tokens into conditional and unconditional sets via conditional routing
according to their functional roles, and refine the assignments of conditional
image tokens through prototypical routing with learnable prototypes based on
semantic content. Moreover, the similarity-based expert allocation in latent
space enabled by prototypical routing offers a natural mechanism for
incorporating explicit semantic guidance, and we validate that such guidance is
crucial for vision MoE. Building on this, we propose a routing contrastive loss
that explicitly enhances the prototypical routing process, promoting
intra-expert coherence and inter-expert diversity. Extensive experiments on
ImageNet benchmark demonstrate that ProMoE surpasses state-of-the-art methods
under both Rectified Flow and DDPM training objectives. Code and models will be
made publicly available.

</details>


### [56] [Uniform Discrete Diffusion with Metric Path for Video Generation](https://arxiv.org/abs/2510.24717)
*Haoge Deng,Ting Pan,Fan Zhang,Yang Liu,Zhuoyan Luo,Yufeng Cui,Wenxuan Wang,Chunhua Shen,Shiguang Shan,Zhaoxiang Zhang,Xinlong Wang*

Main category: cs.CV

TL;DR: URSA 是一种新颖的离散生成模型，通过对标记进行全局优化，展示了优于当前技术的性能，适用于多种视频生成任务。


<details>
  <summary>Details</summary>
Motivation: 离散生成建模在面对视频生成方面的挑战时，如错误积累和长上下文不一致性，亟需一种新的方法。

Method: URSA 通过对离散时空标记进行全局迭代精细化，采用线性度量路径和依赖分辨率的时间步长调整机制。

Result: URSA 在高分辨率图像合成和长时视频生成方面具备较高的效率，并且推理步骤更少。

Conclusion: URSA 在视频生成任务中表现优异，超越了现有的离散方法，并可与最先进的连续扩散方法相媲美。

Abstract: Continuous-space video generation has advanced rapidly, while discrete
approaches lag behind due to error accumulation and long-context inconsistency.
In this work, we revisit discrete generative modeling and present Uniform
discRete diffuSion with metric pAth (URSA), a simple yet powerful framework
that bridges the gap with continuous approaches for the scalable video
generation. At its core, URSA formulates the video generation task as an
iterative global refinement of discrete spatiotemporal tokens. It integrates
two key designs: a Linearized Metric Path and a Resolution-dependent Timestep
Shifting mechanism. These designs enable URSA to scale efficiently to
high-resolution image synthesis and long-duration video generation, while
requiring significantly fewer inference steps. Additionally, we introduce an
asynchronous temporal fine-tuning strategy that unifies versatile tasks within
a single model, including interpolation and image-to-video generation.
Extensive experiments on challenging video and image generation benchmarks
demonstrate that URSA consistently outperforms existing discrete methods and
achieves performance comparable to state-of-the-art continuous diffusion
methods. Code and models are available at https://github.com/baaivision/URSA

</details>


### [57] [Generative View Stitching](https://arxiv.org/abs/2510.24718)
*Chonghyuk Song,Michal Stary,Boyuan Chen,George Kopanas,Vincent Sitzmann*

Main category: cs.CV

TL;DR: 本文提出的生成性视图拼接（GVS）方法解决了自回归视频扩散模型在相机引导生成中遇到的生成场景冲突问题，确保了视频的稳定性和一致性。


<details>
  <summary>Details</summary>
Motivation: 为了克服自回归视频扩散模型在未来条件引导下生成视频时的局限性，提出GVS方法以解决生成过程中的冲突问题，提升视频生成的整体质量和一致性。

Method: GVS通过一种新的采样算法来实现生成拼接，并结合了全方位引导技术来提升时间一致性。

Result: 本文提出了生成性视图拼接（GVS）方法，旨在解决自回归视频扩散模型在未来条件引导下生成视频时存在的问题，尤其是在相机引导的视频生成中，该模型容易导致生成场景的冲突。GVS通过并行采样整个序列，确保生成的场景与预定义相机轨迹的一致性。其主要贡献在于提出一种采样算法，该算法扩展了之前的扩散拼接方法，应用于视频生成。GVS兼容任何经过Diffusion Forcing训练的现成视频模型，且只需在此基础上进行修改。我们还引入了全方位引导技术，提升了拼接过程中的时间一致性，并支持长距离连贯性的闭环机制。最终，GVS实现了稳定、无碰撞、逐帧一致的相机引导视频生成，适用于包括奥斯卡·雷特斯瓦德的“不可能阶梯”在内的多种预定义相机路径。

Conclusion: GVS有效提高了相机引导视频生成的稳定性和一致性，特别是在处理复杂的相机路径时，能够实现无碰撞和长距离连贯性。

Abstract: Autoregressive video diffusion models are capable of long rollouts that are
stable and consistent with history, but they are unable to guide the current
generation with conditioning from the future. In camera-guided video generation
with a predefined camera trajectory, this limitation leads to collisions with
the generated scene, after which autoregression quickly collapses. To address
this, we propose Generative View Stitching (GVS), which samples the entire
sequence in parallel such that the generated scene is faithful to every part of
the predefined camera trajectory. Our main contribution is a sampling algorithm
that extends prior work on diffusion stitching for robot planning to video
generation. While such stitching methods usually require a specially trained
model, GVS is compatible with any off-the-shelf video model trained with
Diffusion Forcing, a prevalent sequence diffusion framework that we show
already provides the affordances necessary for stitching. We then introduce
Omni Guidance, a technique that enhances the temporal consistency in stitching
by conditioning on both the past and future, and that enables our proposed
loop-closing mechanism for delivering long-range coherence. Overall, GVS
achieves camera-guided video generation that is stable, collision-free,
frame-to-frame consistent, and closes loops for a variety of predefined camera
paths, including Oscar Reutersv\"ard's Impossible Staircase. Results are best
viewed as videos at https://andrewsonga.github.io/gvs.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [58] [Evaluating Long-Term Memory for Long-Context Question Answering](https://arxiv.org/abs/2510.23730)
*Alessandra Terranova,Björn Ross,Alexandra Birch*

Main category: cs.CL

TL;DR: 本文系统评估了用于长上下文对话的记忆增强方法，发现这些方法能显著减少令牌使用，同时保持竞争性准确性。


<details>
  <summary>Details</summary>
Motivation: 为了提高大型语言模型的对话连贯性和学习能力，引入记忆机制是必要的。

Method: 通过LoCoMo基准测试评估多种记忆增强方法，包括全上下文提示、语义记忆、情节记忆和过程记忆。

Result: 记忆增强方法将令牌使用量减少超过90%，同时保证了准确性。

Conclusion: 记忆架构的复杂性应与模型能力相匹配，不同类型的记忆对不同模型有不同的效益。

Abstract: In order for large language models to achieve true conversational continuity
and benefit from experiential learning, they need memory. While research has
focused on the development of complex memory systems, it remains unclear which
types of memory are most effective for long-context conversational tasks. We
present a systematic evaluation of memory-augmented methods using LoCoMo, a
benchmark of synthetic long-context dialogues annotated for question-answering
tasks that require diverse reasoning strategies. We analyse full-context
prompting, semantic memory through retrieval-augmented generation and agentic
memory, episodic memory through in-context learning, and procedural memory
through prompt optimization. Our findings show that memory-augmented approaches
reduce token usage by over 90% while maintaining competitive accuracy. Memory
architecture complexity should scale with model capability, with small
foundation models benefitting most from RAG, and strong instruction-tuned
reasoning model gaining from episodic learning through reflections and more
complex agentic semantic memory. In particular, episodic memory can help LLMs
recognise the limits of their own knowledge.

</details>


### [59] [BitSkip: An Empirical Analysis of Quantization and Early Exit Composition](https://arxiv.org/abs/2510.23766)
*Ramshankar Bhuvaneswaran,Handan Liu*

Main category: cs.CL

TL;DR: 该论文提出了一种新的框架，展示了一些看似简单的模型在复杂方法中的优势。


<details>
  <summary>Details</summary>
Motivation: 研究极端量化和动态路由技术在大型语言模型中的复合效果与相互作用

Method: 提出了一种名为BitSkip的混合架构框架

Result: 简单的8位量化模型（BitSkip-V1）在质量方面超越了更复杂的4位和Hadamard增强模型，并与全精度基准相竞争；引入Hadamard变换显著降低了性能。

Conclusion: BitSkip-V1在保持质量的同时实现了更高的速度增益，展示了在大型语言模型设计中的潜力。

Abstract: The pursuit of efficient Large Language Models (LLMs) has led to increasingly
complex techniques like extreme quantization and dynamic routing. While
individual benefits of these methods are well-documented, their compositional
effects remain poorly understood. This paper introduces BitSkip, a hybrid
architectural framework for systematically explor- ing these interactions.
Counter-intuitively, our findings reveal that a simple 8-bit quantized model
without Hadamard transform (BitSkip-V1) not only outperforms its more complex
4-bit and Hadamard-enhanced counterparts but also competes the full-precision
baseline in quality (perplexity of 1.13 vs 1.19) . The introduction of Hadamard
transforms, even at 8- bit precision, catastrophically degraded performance by
over 37,000%, tracing fundamental training instability. Our BitSkip-V1 recipe
demonstrates superior early-exit characteristics, with layer 18 providing
optimal 32.5% speed gain for minimal 4% quality loss.

</details>


### [60] [Beyond Understanding: Evaluating the Pragmatic Gap in LLMs' Cultural Processing of Figurative Language](https://arxiv.org/abs/2510.23828)
*Mena Attia,Aashiq Muhamed,Mai Alkhamissi,Thamar Solorio,Mona Diab*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（LLMs）理解和使用文化嵌入语言的能力，尤其是阿拉伯语和英语中的比喻表达。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在处理文化特定语言时的有效性，特别是比喻表达的理解和使用。

Method: 通过设计针对上下文理解、实用使用和内涵解释的评估任务，测试了22个LLMs在阿拉伯语和英语中的表现。

Result: 研究结果显示，阿拉伯语谚语和埃及方言成语的准确度明显低于英语谚语，且LLMs在使用比喻时的准确性明显低于理解时。

Conclusion: LLMs对文化推理的理解能力有限，尽管它们能够解释比喻意义，但在适当地使用上面临挑战。

Abstract: We present a comprehensive evaluation of the ability of large language models
(LLMs) to process culturally grounded language, specifically to understand and
pragmatically use figurative expressions that encode local knowledge and
cultural nuance. Using figurative language as a proxy for cultural nuance and
local knowledge, we design evaluation tasks for contextual understanding,
pragmatic use, and connotation interpretation in Arabic and English. We
evaluate 22 open- and closed-source LLMs on Egyptian Arabic idioms,
multidialectal Arabic proverbs, and English proverbs. Our results show a
consistent hierarchy: the average accuracy for Arabic proverbs is 4.29% lower
than for English proverbs, and performance for Egyptian idioms is 10.28% lower
than for Arabic proverbs. For the pragmatic use task, accuracy drops by 14.07%
relative to understanding, though providing contextual idiomatic sentences
improves accuracy by 10.66%. Models also struggle with connotative meaning,
reaching at most 85.58% agreement with human annotators on idioms with 100%
inter-annotator agreement. These findings demonstrate that figurative language
serves as an effective diagnostic for cultural reasoning: while LLMs can often
interpret figurative meaning, they face challenges in using it appropriately.
To support future research, we release Kinayat, the first dataset of Egyptian
Arabic idioms designed for both figurative understanding and pragmatic use
evaluation.

</details>


### [61] [How Pragmatics Shape Articulation: A Computational Case Study in STEM ASL Discourse](https://arxiv.org/abs/2510.23842)
*Saki Imai,Lee Kezar,Laurel Aichler,Mert Inan,Erin Walker,Alicia Wooten,Lorna Quandt,Malihe Alikhani*

Main category: cs.CL

TL;DR: 本研究针对传统手语模型的局限性，收集了美国手语（ASL）STEM对话的运动捕捉数据集，分析了对话过程中手语的时空变化及其对手语技术的影响。


<details>
  <summary>Details</summary>
Motivation: 为填补现有手语模型在自然对话中的变异性缺失，特别是在教育环境中教师和学生之间的手语交互。

Method: 通过运动捕捉数据集，分析二人互动签署、单人讲座和解释性文章之间的定量比较，并使用连续运动学特征进行分析。

Result: 研究表明，对话中的手语签署平均比孤立签署短24.6%-44.6%，且在单独上下文中不显著，这显示了在STEM术语的重复提及中的时空变化。

Conclusion: 我们的研究结果表明，手语在对话中具有更短的持续时间及显著的局部变化，这对手语技术的发展具有重要启示。

Abstract: Most state-of-the-art sign language models are trained on interpreter or
isolated vocabulary data, which overlooks the variability that characterizes
natural dialogue. However, human communication dynamically adapts to contexts
and interlocutors through spatiotemporal changes and articulation style. This
specifically manifests itself in educational settings, where novel vocabularies
are used by teachers, and students. To address this gap, we collect a motion
capture dataset of American Sign Language (ASL) STEM (Science, Technology,
Engineering, and Mathematics) dialogue that enables quantitative comparison
between dyadic interactive signing, solo signed lecture, and interpreted
articles. Using continuous kinematic features, we disentangle dialogue-specific
entrainment from individual effort reduction and show spatiotemporal changes
across repeated mentions of STEM terms. On average, dialogue signs are
24.6%-44.6% shorter in duration than the isolated signs, and show significant
reductions absent in monologue contexts. Finally, we evaluate sign embedding
models on their ability to recognize STEM signs and approximate how entrained
the participants become over time. Our study bridges linguistic analysis and
computational modeling to understand how pragmatics shape sign articulation and
its representation in sign language technologies.

</details>


### [62] [CRADLE Bench: A Clinician-Annotated Benchmark for Multi-Faceted Mental Health Crisis and Safety Risk Detection](https://arxiv.org/abs/2510.23845)
*Grace Byun,Rebecca Lipschutz,Sean T. Minton,Abigail Lott,Jinho D. Choi*

Main category: cs.CL

TL;DR: 本研究介绍了CRADLE BENCH，一个多维度危机检测基准，涵盖七种危机类型并包含时间标签，以提高语言模型在心理健康危机场景下的检测能力。


<details>
  <summary>Details</summary>
Motivation: 应对自杀意念、家庭暴力等心理健康危机的紧迫需求，推动语言模型在此类问题的检测能力。

Method: 采用临床标准定义的七种危机类型，构建了包含600个临床标注示例和420个开发示例的评估集，以及约4K个使用多模型集成自动标注的训练语料库。

Result: 研究展示了模型在多种协议下的训练效果，提升了危机检测的准确性和可靠性。

Conclusion: 本研究建立的CRADLE BENCH为语言模型在心理健康危机检测中提供了一个全面的基准，促进了更有效的模型训练和评估。

Abstract: Detecting mental health crisis situations such as suicide ideation, rape,
domestic violence, child abuse, and sexual harassment is a critical yet
underexplored challenge for language models. When such situations arise during
user--model interactions, models must reliably flag them, as failure to do so
can have serious consequences. In this work, we introduce CRADLE BENCH, a
benchmark for multi-faceted crisis detection. Unlike previous efforts that
focus on a limited set of crisis types, our benchmark covers seven types
defined in line with clinical standards and is the first to incorporate
temporal labels. Our benchmark provides 600 clinician-annotated evaluation
examples and 420 development examples, together with a training corpus of
around 4K examples automatically labeled using a majority-vote ensemble of
multiple language models, which significantly outperforms single-model
annotation. We further fine-tune six crisis detection models on subsets defined
by consensus and unanimous ensemble agreement, providing complementary models
trained under different agreement criteria.

</details>


### [63] [Tongyi DeepResearch Technical Report](https://arxiv.org/abs/2510.24701)
*Tongyi DeepResearch Team,Baixuan Li,Bo Zhang,Dingchu Zhang,Fei Huang,Guangyu Li,Guoxin Chen,Huifeng Yin,Jialong Wu,Jingren Zhou,Kuan Li,Liangcai Su,Litu Ou,Liwen Zhang,Pengjun Xie,Rui Ye,Wenbiao Yin,Xinmiao Yu,Xinyu Wang,Xixi Wu,Xuanzhong Chen,Yida Zhao,Zhen Zhang,Zhengwei Tao,Zhongwang Zhang,Zile Qiao,Chenxi Wang,Donglei Yu,Gang Fu,Haiyang Shen,Jiayin Yang,Jun Lin,Junkai Zhang,Kui Zeng,Li Yang,Hailong Yin,Maojia Song,Ming Yan,Peng Xia,Qian Xiao,Rui Min,Ruixue Ding,Runnan Fang,Shaowei Chen,Shen Huang,Shihang Wang,Shihao Cai,Weizhou Shen,Xiaobin Wang,Xin Guan,Xinyu Geng,Yingcheng Shi,Yuning Wu,Zhuo Chen,Zijian Li,Yong Jiang*

Main category: cs.CL

TL;DR: Tongyi DeepResearch是一种新型语言模型，专门用于长时间深度研究任务，并实现了先进的表现。


<details>
  <summary>Details</summary>
Motivation: 为了激励自主的深度研究能力，设计一个高效、可扩展的信息寻求系统

Method: 通过端到端训练框架结合中期和后期训练，开发了专门用于深度信息寻求研究任务的语言模型

Result: 实现了在多个深度研究基准上取得了最先进的表现，并开源了模型和框架

Conclusion: 该模型展示了在复杂任务下，自主深度研究的可扩展性和有效性。

Abstract: We present Tongyi DeepResearch, an agentic large language model, which is
specifically designed for long-horizon, deep information-seeking research
tasks. To incentivize autonomous deep research agency, Tongyi DeepResearch is
developed through an end-to-end training framework that combines agentic
mid-training and agentic post-training, enabling scalable reasoning and
information seeking across complex tasks. We design a highly scalable data
synthesis pipeline that is fully automatic, without relying on costly human
annotation, and empowers all training stages. By constructing customized
environments for each stage, our system enables stable and consistent
interactions throughout. Tongyi DeepResearch, featuring 30.5 billion total
parameters, with only 3.3 billion activated per token, achieves
state-of-the-art performance across a range of agentic deep research
benchmarks, including Humanity's Last Exam, BrowseComp, BrowseComp-ZH,
WebWalkerQA, xbench-DeepSearch, FRAMES and xbench-DeepSearch-2510. We
open-source the model, framework, and complete solutions to empower the
community.

</details>


### [64] [Can LLMs Narrate Tabular Data? An Evaluation Framework for Natural Language Representations of Text-to-SQL System Outputs](https://arxiv.org/abs/2510.23854)
*Jyotika Singh,Weiyi Sun,Amit Agarwal,Viji Krishnamurthy,Yassine Benajiba,Sujith Ravi,Dan Roth*

Main category: cs.CL

TL;DR: 本文介绍了一种新的评估方法Combo-Eval，旨在提高大型语言模型生成的自然语言表示的质量，并减少对这些模型的调用次数。


<details>
  <summary>Details</summary>
Motivation: 为了应对目前NLR生成中信息丢失和错误的问题，本文旨在开发一种更可靠的评估方法，从而提升工业系统中的自然语言交互质量。

Method: 提出了一种新颖的评估方法Combo-Eval，结合多种现有评估技术，优化了评估流程。

Result: 本文提出了一种新颖的评估方法Combo-Eval，用于判断大型语言模型（LLMs）生成的自然语言表示（NLRs）。该方法结合了多种现有方法的优点，优化了评估的可靠性，并减少了25-61%的LLM调用次数。同时，推出了首个专门用于NLR基准测试的数据集NLR-BIRD。通过人类评估，表明Combo-Eval与人类判断的契合度更高，适用于有无参考真值的多种场景。

Conclusion: Combo-Eval在与人类判断的一致性方面表现出色，并降低了LLM调用频率，推动了基于NLR的评估方法发展。

Abstract: In modern industry systems like multi-turn chat agents, Text-to-SQL
technology bridges natural language (NL) questions and database (DB) querying.
The conversion of tabular DB results into NL representations (NLRs) enables the
chat-based interaction. Currently, NLR generation is typically handled by large
language models (LLMs), but information loss or errors in presenting tabular
results in NL remains largely unexplored. This paper introduces a novel
evaluation method - Combo-Eval - for judgment of LLM-generated NLRs that
combines the benefits of multiple existing methods, optimizing evaluation
fidelity and achieving a significant reduction in LLM calls by 25-61%.
Accompanying our method is NLR-BIRD, the first dedicated dataset for NLR
benchmarking. Through human evaluations, we demonstrate the superior alignment
of Combo-Eval with human judgments, applicable across scenarios with and
without ground truth references.

</details>


### [65] [Language Models for Longitudinal Clinical Prediction](https://arxiv.org/abs/2510.23884)
*Tananun Songdechakraiwut,Michael Lutz*

Main category: cs.CL

TL;DR: 本研究提出了一种轻量级框架，通过整合患者历史和上下文，利用大型语言模型分析纵向临床数据，实现对阿尔茨海默病的有效监测。


<details>
  <summary>Details</summary>
Motivation: 旨在提高临床数据的分析效率，尤其是在有限训练数据的情况下。

Method: 通过将患者历史和上下文整合到语言模型空间中，利用现有的大型语言模型进行分析，而无需模型微调。

Result: 在神经心理评估中，该方法能够产生准确可靠的预测，显示出良好的应用前景。

Conclusion: 该轻量级框架在分析纵向临床数据方面表现出色，尤其适用于阿尔茨海默病的早期监测。

Abstract: We explore a lightweight framework that adapts frozen large language models
to analyze longitudinal clinical data. The approach integrates patient history
and context within the language model space to generate accurate forecasts
without model fine-tuning. Applied to neuropsychological assessments, it
achieves accurate and reliable performance even with minimal training data,
showing promise for early-stage Alzheimer's monitoring.

</details>


### [66] [AfriMTEB and AfriE5: Benchmarking and Adapting Text Embedding Models for African Languages](https://arxiv.org/abs/2510.23896)
*Kosei Uemura,Miaoran Zhang,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: 本文介绍了AfriMTEB数据集及其任务，突出在非洲语言处理中的重要性，同时展示了基于对比蒸馏的AfriE5模型的出色性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有多语言嵌入在非洲语言领域的不足，以及针对特定任务（如仇恨言论检测、意图检测和情感分类）的支持。

Method: 提出并扩展了一个名为AfriMTEB的新数据集，以及针对非洲语言的AfriE5模型适应。

Result: AfriMTEB涵盖59种语言、14个任务和38个数据集，AfriE5在性能评估中超越了多个已有基线模型，表现出色。

Conclusion: AfriMTEB和AfriE5为非洲语言的自然语言处理提供了新的资源和方法，推动了这一领域的研究。

Abstract: Text embeddings are an essential building component of several NLP tasks such
as retrieval-augmented generation which is crucial for preventing
hallucinations in LLMs. Despite the recent release of massively multilingual
MTEB (MMTEB), African languages remain underrepresented, with existing tasks
often repurposed from translation benchmarks such as FLORES clustering or
SIB-200. In this paper, we introduce AfriMTEB -- a regional expansion of MMTEB
covering 59 languages, 14 tasks, and 38 datasets, including six newly added
datasets. Unlike many MMTEB datasets that include fewer than five languages,
the new additions span 14 to 56 African languages and introduce entirely new
tasks, such as hate speech detection, intent detection, and emotion
classification, which were not previously covered. Complementing this, we
present AfriE5, an adaptation of the instruction-tuned mE5 model to African
languages through cross-lingual contrastive distillation. Our evaluation shows
that AfriE5 achieves state-of-the-art performance, outperforming strong
baselines such as Gemini-Embeddings and mE5.

</details>


### [67] [Breaking the Benchmark: Revealing LLM Bias via Minimal Contextual Augmentation](https://arxiv.org/abs/2510.23921)
*Kaveh Eskandari Miandoab,Mahammed Kamruzzaman,Arshia Gharooni,Gene Louis Kim,Vasanth Sarathy,Ninareh Mehrabi*

Main category: cs.CL

TL;DR: 本研究提出一种增强框架，发现大语言模型易受输入扰动影响，从而表现出刻板印象偏见，呼吁扩大公平性和安全性研究至更多多样化社区。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型由于训练数据的歧视性而表现出的刻板印象偏见，并研究现有方法在偏见对齐方面的脆弱性。

Method: 提出了一种新颖的通用增强框架，包含三个可插拔的步骤，适用于多种公平性评估基准。

Result: 通过将增强应用于公平性评估数据集（BBQ），发现大语言模型在输入扰动情况下更容易表现出刻板印象行为。

Conclusion: 大语言模型在输入扰动时更容易表现出刻板印象偏见，尤其是针对社区较少被研究的目标人群，强调了扩展公平性和安全性研究的必要性。

Abstract: Large Language Models have been shown to demonstrate stereotypical biases in
their representations and behavior due to the discriminative nature of the data
that they have been trained on. Despite significant progress in the development
of methods and models that refrain from using stereotypical information in
their decision-making, recent work has shown that approaches used for bias
alignment are brittle. In this work, we introduce a novel and general
augmentation framework that involves three plug-and-play steps and is
applicable to a number of fairness evaluation benchmarks. Through application
of augmentation to a fairness evaluation dataset (Bias Benchmark for Question
Answering (BBQ)), we find that Large Language Models (LLMs), including
state-of-the-art open and closed weight models, are susceptible to
perturbations to their inputs, showcasing a higher likelihood to behave
stereotypically. Furthermore, we find that such models are more likely to have
biased behavior in cases where the target demographic belongs to a community
less studied by the literature, underlining the need to expand the fairness and
safety research to include more diverse communities.

</details>


### [68] [Auto prompting without training labels: An LLM cascade for product quality assessment in e-commerce catalogs](https://arxiv.org/abs/2510.23941)
*Soham Satyadharma,Fatemeh Sheikholeslami,Swati Kaul,Aziz Umit Batur,Suleiman A. Khan*

Main category: cs.CL

TL;DR: 介绍一种无需训练的自动提示级联方法，显著提高产品质量评估效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 开发一种无需训练的自动提示级联系统，以评估电子商务中的产品质量。

Method: 通过从人工设计的提示出发，级联方法逐步优化指令，以满足特定目录的要求。

Result: 该系统在精准度和召回率上比传统的思维链提示提高了8-10%。

Conclusion: 该方法不仅减少了领域专家的工作时间，还在多种语言和质量评估任务中表现出良好的泛化能力。

Abstract: We introduce a novel, training free cascade for auto-prompting Large Language
Models (LLMs) to assess product quality in e-commerce. Our system requires no
training labels or model fine-tuning, instead automatically generating and
refining prompts for evaluating attribute quality across tens of thousands of
product category-attribute pairs. Starting from a seed of human-crafted
prompts, the cascade progressively optimizes instructions to meet
catalog-specific requirements. This approach bridges the gap between general
language understanding and domain-specific knowledge at scale in complex
industrial catalogs. Our extensive empirical evaluations shows the auto-prompt
cascade improves precision and recall by $8-10\%$ over traditional
chain-of-thought prompting. Notably, it achieves these gains while reducing
domain expert effort from 5.1 hours to 3 minutes per attribute - a $99\%$
reduction. Additionally, the cascade generalizes effectively across five
languages and multiple quality assessment tasks, consistently maintaining
performance gains.

</details>


### [69] [Leveraging LLMs for Early Alzheimer's Prediction](https://arxiv.org/abs/2510.23946)
*Tananun Songdechakraiwut*

Main category: cs.CL

TL;DR: 提出了一种新型框架，利用fMRI数据进行早期阿尔茨海默病预测，表现出色。


<details>
  <summary>Details</summary>
Motivation: 旨在通过利用大脑动态活动模式提高早期阿尔茨海默病的检测能力。

Method: 提出了一种基于连接组的LLM框架，将动态fMRI连接编码为时间序列，应用稳健的归一化，并将这些数据映射到适合于预训练LLM进行临床预测的表示形式。

Result: 针对早期阿尔茨海默病检测的方法达到了敏感预测，错误率远低于临床认可的范围。

Conclusion: 该方法为及时干预阿尔茨海默病提供了重要的前景。

Abstract: We present a connectome-informed LLM framework that encodes dynamic fMRI
connectivity as temporal sequences, applies robust normalization, and maps
these data into a representation suitable for a frozen pre-trained LLM for
clinical prediction. Applied to early Alzheimer's detection, our method
achieves sensitive prediction with error rates well below clinically recognized
margins, with implications for timely Alzheimer's intervention.

</details>


### [70] [Uncovering the Potential Risks in Unlearning: Danger of English-only Unlearning in Multilingual LLMs](https://arxiv.org/abs/2510.23949)
*Kyomin Hwang,Hyeonjin Kim,Seungyeon Kim,Sunghyun Wee,Nojun Kwak*

Main category: cs.CL

TL;DR: 研究了多语言LLM在多语言知识遗忘过程中的语言混淆现象，并提出新的评估标准。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示多语言LLM在微调后进行知识遗忘时，语言混淆现象的影响及现有评估标准的不足。

Method: 引入基于N-gram的Language-Mix评分，通过三步分析语言混淆现象及其对评估标准的影响。

Result: 本研究探讨了多语言LLM在进行多语言知识遗忘时的语言混淆现象，提出了N-gram的Language-Mix评分，以量化这种现象，并指出传统的基于参考的评估标准在高N-Mix评分情况下的失效，从而建议需要引入语义基础的评估标准以更好地评估生成句子的内容。

Conclusion: 多语言LLM在完全微调后在遗忘时出现语言混淆现象，传统的评估标准难以奏效，需要新的语义基础评估标准。

Abstract: There have been a couple of studies showing that attempting to erase
multilingual knowledge using only English data is insufficient for multilingual
LLMs. However, their analyses remain highly performance-oriented. In this
paper, we switch the point of view to evaluation, and address an additional
blind spot which reveals itself when the multilingual LLM is fully finetuned
with parallel multilingual dataset before unlearning. Here, language confusion
occurs whereby a model responds in language different from that of the input
prompt. Language confusion is a problematic phenomenon in unlearning, causing
the standard reference-based metrics to fail. We tackle this phenomenon in
three steps: (1) introduce N-gram-based Language-Mix (N-Mix) score to
quantitatively show the language confusion is pervasive and consistent in
multilingual LLMs, (2) demonstrate that reference-based metrics result in false
negatives when N-Mix score is high, and(3) suggest the need of new type of
unlearning evaluation that can directly assess the content of the generated
sentences. We call this type of metrics as semantic-based metric.

</details>


### [71] [M-Eval: A Heterogeneity-Based Framework for Multi-evidence Validation in Medical RAG Systems](https://arxiv.org/abs/2510.23995)
*Mengzhou Sun,Sendong Zhao,Jianyu Chen,Haochun Wang,Bin Qin*

Main category: cs.CL

TL;DR: 提出M-Eval方法，旨在提高RAG医疗问答系统的准确性，通过异质性分析核查证据的准确性及可靠性，准确率提升23.31%。


<details>
  <summary>Details</summary>
Motivation: 当前RAG应用存在产生错误信息的问题，M-Eval旨在解决这些问题，提高医疗问答系统的准确性和可靠性。

Method: M-Eval方法结合异质性分析，提取外部医学文献和RAG生成的文档，验证其相互支持情况，从而核实准确性和可靠性。

Result: 本研究提出了一种名为M-Eval的新方法，用于提高基于检索增强生成（RAG）的医疗问答系统的准确性。M-Eval受到循证医学中异质性分析方法的启发，通过多个来源的证据检查RAG生成的回答中的事实错误。该方法首先提取外部知识库中的医学文献，然后检索RAG系统生成的证据文档，利用异质性分析验证响应中证据的支持情况。除了核实回答的准确性外，还评估RAG系统提供证据的可靠性。这一方法在不同大型语言模型上的准确性提高了23.31%。

Conclusion: M-Eval方法提升了基于RAG的医疗系统的可靠性，并帮助减少诊断错误。

Abstract: Retrieval-augmented Generation (RAG) has demonstrated potential in enhancing
medical question-answering systems through the integration of large language
models (LLMs) with external medical literature. LLMs can retrieve relevant
medical articles to generate more professional responses efficiently. However,
current RAG applications still face problems. They generate incorrect
information, such as hallucinations, and they fail to use external knowledge
correctly. To solve these issues, we propose a new method named M-Eval. This
method is inspired by the heterogeneity analysis approach used in
Evidence-Based Medicine (EBM). Our approach can check for factual errors in RAG
responses using evidence from multiple sources. First, we extract additional
medical literature from external knowledge bases. Then, we retrieve the
evidence documents generated by the RAG system. We use heterogeneity analysis
to check whether the evidence supports different viewpoints in the response. In
addition to verifying the accuracy of the response, we also assess the
reliability of the evidence provided by the RAG system. Our method shows an
improvement of up to 23.31% accuracy across various LLMs. This work can help
detect errors in current RAG-based medical systems. It also makes the
applications of LLMs more reliable and reduces diagnostic errors.

</details>


### [72] [ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality Games?](https://arxiv.org/abs/2510.24706)
*Shuqing Li,Jiayi Yan,Chenyu Niu,Jen-tse Huang,Yun Peng,Wenxuan Wang,Yepang Liu,Michael R. Lyu*

Main category: cs.CL

TL;DR: 本研究通过ComboBench评估LLMs在VR游戏中的操作能力，发现虽然表现优异，但在程序推理和空间理解上存在缺陷。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLMs）在虚拟现实游戏中将高层语义行动转化为设备操作序列的能力，并建立评估标准。

Method: 构建ComboBench基准，评估多款大型语言模型在262种VR游戏场景下的表现，并与人类表现做对比。

Result: 通过ComboBench基准评估七种大型语言模型在不同VR游戏中的表现，发现模型在程序推理和空间理解方面依然逊色于人类。

Conclusion: 尽管顶级模型在任务分解能力上表现良好，但仍需改进以增强程序推理和空间理解能力，少量示例显示出显著性能提升。

Abstract: Virtual Reality (VR) games require players to translate high-level semantic
actions into precise device manipulations using controllers and head-mounted
displays (HMDs). While humans intuitively perform this translation based on
common sense and embodied understanding, whether Large Language Models (LLMs)
can effectively replicate this ability remains underexplored. This paper
introduces a benchmark, ComboBench, evaluating LLMs' capability to translate
semantic actions into VR device manipulation sequences across 262 scenarios
from four popular VR games: Half-Life: Alyx, Into the Radius, Moss: Book II,
and Vivecraft. We evaluate seven LLMs, including GPT-3.5, GPT-4, GPT-4o,
Gemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, and GLM-4-Flash, compared against
annotated ground truth and human performance. Our results reveal that while
top-performing models like Gemini-1.5-Pro demonstrate strong task decomposition
capabilities, they still struggle with procedural reasoning and spatial
understanding compared to humans. Performance varies significantly across
games, suggesting sensitivity to interaction complexity. Few-shot examples
substantially improve performance, indicating potential for targeted
enhancement of LLMs' VR manipulation capabilities. We release all materials at
https://sites.google.com/view/combobench.

</details>


### [73] [PICOs-RAG: PICO-supported Query Rewriting for Retrieval-Augmented Generation in Evidence-Based Medicine](https://arxiv.org/abs/2510.23998)
*Mengzhou Sun,Sendong Zhao,Jianyu Chen,Bin Qin*

Main category: cs.CL

TL;DR: PICOs-RAG通过标准化查询格式，显著提高了循证医学中的文献检索效率与相关性。


<details>
  <summary>Details</summary>
Motivation: 为了提高基于检索的生成模型在复杂临床查询中的表现以减少无效检索。

Method: 采用PICOs-RAG，通过扩展和标准化用户查询到专业格式，使用PICO格式提取关键信息进行检索。

Result: 相比基准，我们的方法在检索效率上提升了8.8%。

Conclusion: PICOs-RAG显著提高了检索效率和相关性，使大型语言模型在循证医学中成为一个有用且可靠的助手。

Abstract: Evidence-based medicine (EBM) research has always been of paramount
importance. It is important to find appropriate medical theoretical support for
the needs from physicians or patients to reduce the occurrence of medical
accidents. This process is often carried out by human querying relevant
literature databases, which lacks objectivity and efficiency. Therefore,
researchers utilize retrieval-augmented generation (RAG) to search for evidence
and generate responses automatically. However, current RAG methods struggle to
handle complex queries in real-world clinical scenarios. For example, when
queries lack certain information or use imprecise language, the model may
retrieve irrelevant evidence and generate unhelpful answers. To address this
issue, we present the PICOs-RAG to expand the user queries into a better
format. Our method can expand and normalize the queries into professional ones
and use the PICO format, a search strategy tool present in EBM, to extract the
most important information used for retrieval. This approach significantly
enhances retrieval efficiency and relevance, resulting in up to an 8.8\%
improvement compared to the baseline evaluated by our method. Thereby the
PICOs-RAG improves the performance of the large language models into a helpful
and reliable medical assistant in EBM.

</details>


### [74] [META-RAG: Meta-Analysis-Inspired Evidence-Re-Ranking Method for Retrieval-Augmented Generation in Evidence-Based Medicine](https://arxiv.org/abs/2510.24003)
*Mengzhou Sun,Sendong Zhao,Jianyu Chen,Haochun Wang,Bin Qin*

Main category: cs.CL

TL;DR: 本研究通过模拟元分析的方法优化了医学证据的筛选，提高了LLMs在Evidence-Based Medicine中的应用效果。


<details>
  <summary>Details</summary>
Motivation: 针对EBM在使用RAG技术时无法有效区分高质量证据的问题，我们提出了一种改进方法。

Method: 结合了可靠性分析、异质性分析和外推分析的方法，以模拟元分析。

Result: 在实验中，我们的方法使得准确率提高了最多11.4%。

Conclusion: 本研究提出了一种新方法，通过多种原则重新排序和筛选医学证据，从而提高LLMs在EBM中的诊断准确性。

Abstract: Evidence-based medicine (EBM) holds a crucial role in clinical application.
Given suitable medical articles, doctors effectively reduce the incidence of
misdiagnoses. Researchers find it efficient to use large language models (LLMs)
techniques like RAG for EBM tasks. However, the EBM maintains stringent
requirements for evidence, and RAG applications in EBM struggle to efficiently
distinguish high-quality evidence. Therefore, inspired by the meta-analysis
used in EBM, we provide a new method to re-rank and filter the medical
evidence. This method presents multiple principles to filter the best evidence
for LLMs to diagnose. We employ a combination of several EBM methods to emulate
the meta-analysis, which includes reliability analysis, heterogeneity analysis,
and extrapolation analysis. These processes allow the users to retrieve the
best medical evidence for the LLMs. Ultimately, we evaluate these high-quality
articles and show an accuracy improvement of up to 11.4% in our experiments and
results. Our method successfully enables RAG to extract higher-quality and more
reliable evidence from the PubMed dataset. This work can reduce the infusion of
incorrect knowledge into responses and help users receive more effective
replies.

</details>


### [75] [TEXT2DB: Integration-Aware Information Extraction with Large Language Model Agents](https://arxiv.org/abs/2510.24014)
*Yizhu Jiao,Sha Li,Sizhe Zhou,Heng Ji,Jiawei Han*

Main category: cs.CL

TL;DR: 本文提出了IE TEXT2DB任务，旨在通过新开发的OPAL框架，使信息提取与数据库更新相结合。


<details>
  <summary>Details</summary>
Motivation: 信息提取（IE）的输出与下游应用需求之间的不匹配使得利用IE的结果变得复杂。

Method: 引入了OPAL框架，包含观察者、规划者和分析者三个组件，旨在通过代码计划来更新数据库。

Result: 我们提出了一个新任务IE TEXT2DB，能够将IE输出与目标数据库集成，满足用户指令。

Conclusion: 实验表明，OPAL能够适应多样的数据库结构，生成不同的代码计划，然而在处理复杂依赖和提取幻觉方面仍需深入研究。

Abstract: The task of information extraction (IE) is to extract structured knowledge
from text. However, it is often not straightforward to utilize IE output due to
the mismatch between the IE ontology and the downstream application needs. We
propose a new formulation of IE TEXT2DB that emphasizes the integration of IE
output and the target database (or knowledge base). Given a user instruction, a
document set, and a database, our task requires the model to update the
database with values from the document set to satisfy the user instruction.
This task requires understanding user instructions for what to extract and
adapting to the given DB/KB schema for how to extract on the fly. To evaluate
this new task, we introduce a new benchmark featuring common demands such as
data infilling, row population, and column addition. In addition, we propose an
LLM agent framework OPAL (Observe-PlanAnalyze LLM) which includes an Observer
component that interacts with the database, the Planner component that
generates a code-based plan with calls to IE models, and the Analyzer component
that provides feedback regarding code quality before execution. Experiments
show that OPAL can successfully adapt to diverse database schemas by generating
different code plans and calling the required IE models. We also highlight
difficult cases such as dealing with large databases with complex dependencies
and extraction hallucination, which we believe deserve further investigation.
Source code: https://github.com/yzjiao/Text2DB

</details>


### [76] [Teaching LLMs to Abstain via Fine-Grained Semantic Confidence Reward](https://arxiv.org/abs/2510.24020)
*Hao An,Yang Xu*

Main category: cs.CL

TL;DR: 本文提出了一种基于样本特定信心评分的强化学习框架，以指导大语言模型在知识边界之外进行自我弃权，显著提升了模型的可靠性。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型在应对超出知识范围问题时的可靠性，克服现有方法对粗粒度信号的依赖。

Method: 采用强化学习框架，通过样本特定信心进行训练，结合语义聚类来指导模型的弃权决策。

Result: 该研究提出了一种新颖的强化学习框架FiNe-grained Semantic Confidence Reward (Ours)，旨在通过样本特定的信心引导大语言模型(LLM)在知识范围之外的情况下自我弃权。通过对多个候选答案进行语义聚类，并训练LLM保留高信心聚类内的答案，丢弃低信心聚类的答案，该方法显著提高了模型在训练和评估过程中的可靠性。

Conclusion: 该方法在领域内和分布外基准测试中显著提升了LLM的可靠性，展示了其有效性。

Abstract: Mitigating hallucinations in Large Language Models (LLMs) is critical for
their reliable deployment. Existing methods typically fine-tune LLMs to abstain
from answering questions beyond their knowledge scope. However, these methods
often rely on coarse-grained signals to guide LLMs to abstain, such as overall
confidence or uncertainty scores on multiple sampled answers, which may result
in an imprecise awareness of the model's own knowledge boundaries. To this end,
we propose a novel reinforcement learning framework built on
$\textbf{\underline{Fi}ne-grained \underline{S}emantic \underline{Co}nfidence
\underline{Re}ward (\Ours)}$, which guides LLMs to abstain via sample-specific
confidence. Specifically, our method operates by sampling multiple candidate
answers and conducting semantic clustering, then training the LLM to retain
answers within high-confidence clusters and discard those within low-confidence
ones, thereby promoting accurate post-hoc abstention. Additionally, we propose
a new metric for evaluating the reliability of abstention fine-tuning tasks
more comprehensively. Our method significantly enhances reliability in both
in-domain and out-of-distribution benchmarks.

</details>


### [77] [SpecKD: Speculative Decoding for Effective Knowledge Distillation of LLMs](https://arxiv.org/abs/2510.24021)
*Haiduo Huang,Jiangcheng Song,Yadong Zhang,Pengju Ren*

Main category: cs.CL

TL;DR: 本研究提出了SpecKD，一种基于教师模型可信度的新型知识蒸馏方法，显著提高了学生模型的效能。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法忽略了教师模型可信度，导致学习不确定性的问题，影响了学生模型的性能。

Method: 采用动态、按标记等级的门控机制，通过对教师分布的验证，仅对接受的标记应用蒸馏损失。

Result: 本论文提出了一种新的知识蒸馏方法Speculative Knowledge Distillation (SpecKD)，旨在通过动态的、按标记等级的门控机制，提高从大型语言模型到小型学生模型的知识蒸馏效果。与传统的均匀应用蒸馏损失不同，SpecKD依据教师模型的预测可信度，对学生模型的各个标记进行选择性学习，从而减少由于学习不确定性引入的噪声，增强学生模型性能。实验证明，SpecKD在多种文本生成任务中都显著优于传统知识蒸馏方法，并且实现了最先进的结果。

Conclusion: SpecKD通过动态选择性学习，提高学生模型的稳定性和能力，表现出色。

Abstract: Knowledge Distillation (KD) has become a cornerstone technique for
compressing Large Language Models (LLMs) into smaller, more efficient student
models. However, conventional KD approaches typically apply the distillation
loss uniformly across all tokens, regardless of the teacher's confidence. This
indiscriminate mimicry can introduce noise, as the student is forced to learn
from the teacher's uncertain or high-entropy predictions, which may ultimately
harm student performance-especially when the teacher is much larger and more
powerful. To address this, we propose Speculative Knowledge Distillation
(SpecKD), a novel, plug-and-play framework that introduces a dynamic,
token-level gating mechanism inspired by the "propose-and-verify" paradigm of
speculative decoding. At each step, the student's token proposal is verified
against the teacher's distribution; the distillation loss is selectively
applied only to "accepted" tokens, while "rejected" tokens are masked out.
Extensive experiments on diverse text generation tasks show that SpecKD
consistently and significantly outperforms strong KD baselines, leading to more
stable training and more capable student models, and achieving state-of-the-art
results.

</details>


### [78] [Success and Cost Elicit Convention Formation for Efficient Communication](https://arxiv.org/abs/2510.24023)
*Saujas Vaduguru,Yilun Hua,Yoav Artzi,Daniel Fried*

Main category: cs.CL

TL;DR: 本研究展示了如何训练模型形成语言约定，以提高人类和模型之间的沟通效率。


<details>
  <summary>Details</summary>
Motivation: 探讨人类如何利用共享会话上下文提升沟通成功率和效率。

Method: 采用模拟参考游戏训练大型多模态模型，使其能够形成语言约定，无需额外的人类数据。

Result: 模型在与人类的交流中，消息长度减少至41%，成功率提高15%，且人类反应更加迅速。

Conclusion: 通过适应共享会话上下文，模型能够形成语言约定，从而提高沟通的效率。

Abstract: Humans leverage shared conversational context to become increasingly
successful and efficient at communicating over time. One manifestation of this
is the formation of ad hoc linguistic conventions, which allow people to
coordinate on short, less costly utterances that are understood using shared
conversational context. We present a method to train large multimodal models to
form conventions, enabling efficient communication. Our approach uses simulated
reference games between models, and requires no additional human-produced data.
In repeated reference games involving photographs and tangram images, our
method enables models to communicate efficiently with people: reducing the
message length by up to 41% while increasing success by 15% over the course of
the interaction. Human listeners respond faster when interacting with our model
that forms conventions. We also show that training based on success or cost
alone is insufficient - both are necessary to elicit convention formation.

</details>


### [79] [Challenging Multilingual LLMs: A New Taxonomy and Benchmark for Unraveling Hallucination in Translation](https://arxiv.org/abs/2510.24073)
*Xinwei Wu,Heng Liu,Jiang Zhou,Xiaohu Zhao,Linlong Xu,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.CL

TL;DR: 本文提出了HalloMTBench基准，旨在揭示多语言大型语言模型的翻译幻觉。


<details>
  <summary>Details</summary>
Motivation: 鉴于现有机器翻译基准无法有效揭示多语言大型语言模型的翻译幻觉，研究者希望通过新的基准工具给出更好评估。

Method: 通过创建一个包含多种失败模式的诊断框架，并利用多种前沿大型语言模型生成翻译候选，结合专家验证，对候选进行评估，最终整理出高质量实例。

Result: 本文介绍了一种新的多语言基准HalloMTBench，用于评估大型语言模型在机器翻译中的幻觉表现。通过一个包含多种失败模式的诊断框架，研究人员对不同语言模型的翻译候选进行了深入分析，揭示了与模型规模、源文本长度敏感性、语言偏见和强化学习相关的幻觉触发因素。

Conclusion: HalloMTBench提供了一个前瞻性的测试平台，用于识别和分析大型语言模型的翻译失败，为未来研究提供数据支持。

Abstract: Large Language Models (LLMs) have advanced machine translation but remain
vulnerable to hallucinations. Unfortunately, existing MT benchmarks are not
capable of exposing failures in multilingual LLMs. To disclose hallucination in
multilingual LLMs, we introduce a diagnostic framework with a taxonomy that
separates Instruction Detachment from Source Detachment. Guided by this
taxonomy, we create HalloMTBench, a multilingual, human-verified benchmark
across 11 English-to-X directions. We employed 4 frontier LLMs to generate
candidates and scrutinize these candidates with an ensemble of LLM judges, and
expert validation. In this way, we curate 5,435 high-quality instances. We have
evaluated 17 LLMs on HalloMTBench. Results reveal distinct ``hallucination
triggers'' -- unique failure patterns reflecting model scale, source length
sensitivity, linguistic biases, and Reinforcement-Learning (RL) amplified
language mixing. HalloMTBench offers a forward-looking testbed for diagnosing
LLM translation failures. HalloMTBench is available in
https://huggingface.co/collections/AIDC-AI/marco-mt.

</details>


### [80] [Global PIQA: Evaluating Physical Commonsense Reasoning Across 100+ Languages and Cultures](https://arxiv.org/abs/2510.24081)
*Tyler A. Chang,Catherine Arnett,Abdelrahman Eldesokey,Abdelrahman Sadallah,Abeer Kashar,Abolade Daud,Abosede Grace Olanihun,Adamu Labaran Mohammed,Adeyemi Praise,Adhikarinayum Meerajita Sharma,Aditi Gupta,Afitab Iyigun,Afonso Simplício,Ahmed Essouaied,Aicha Chorana,Akhil Eppa,Akintunde Oladipo,Akshay Ramesh,Aleksei Dorkin,Alfred Malengo Kondoro,Alham Fikri Aji,Ali Eren Çetintaş,Allan Hanbury,Alou Dembele,Alp Niksarli,Álvaro Arroyo,Amin Bajand,Amol Khanna,Ana Chkhaidze,Ana Condez,Andiswa Mkhonto,Andrew Hoblitzell,Andrew Tran,Angelos Poulis,Anirban Majumder,Anna Vacalopoulou,Annette Kuuipolani Kanahele Wong,Annika Simonsen,Anton Kovalev,Ashvanth. S,Ayodeji Joseph Lana,Barkin Kinay,Bashar Alhafni,Benedict Cibalinda Busole,Bernard Ghanem,Bharti Nathani,Biljana Stojanovska Đurić,Bola Agbonile,Bragi Bergsson,Bruce Torres Fischer,Burak Tutar,Burcu Alakuş Çınar,Cade J. Kanoniakapueo Kane,Can Udomcharoenchaikit,Catherine Arnett,Chadi Helwe,Chaithra Reddy Nerella,Chen Cecilia Liu,Chiamaka Glory Nwokolo,Cristina España-Bonet,Cynthia Amol,DaeYeop Lee,Dana Arad,Daniil Dzenhaliou,Daria Pugacheva,Dasol Choi,Daud Abolade,David Liu,David Semedo,Deborah Popoola,Deividas Mataciunas,Delphine Nyaboke,Dhyuthy Krishna Kumar,Diogo Glória-Silva,Diogo Tavares,Divyanshu Goyal,DongGeon Lee,Ebele Nwamaka Anajemba,Egonu Ngozi Grace,Elena Mickel,Elena Tutubalina,Elias Herranen,Emile Anand,Emmanuel Habumuremyi,Emuobonuvie Maria Ajiboye,Eryawan Presma Yulianrifat,Esther Adenuga,Ewa Rudnicka,Faith Olabisi Itiola,Faran Taimoor Butt,Fathima Thekkekara,Fatima Haouari,Filbert Aurelian Tjiaranata,Firas Laakom,Francesca Grasso,Francesco Orabona,Francesco Periti,Gbenga Kayode Solomon,Gia Nghia Ngo,Gloria Udhehdhe-oze,Gonçalo Martins,Gopi Naga Sai Ram Challagolla,Guijin Son,Gulnaz Abdykadyrova,Hafsteinn Einarsson,Hai Hu,Hamidreza Saffari,Hamza Zaidi,Haopeng Zhang,Harethah Abu Shairah,Harry Vuong,Hele-Andra Kuulmets,Houda Bouamor,Hwanjo Yu,Iben Nyholm Debess,İbrahim Ethem Deveci,Ikhlasul Akmal Hanif,Ikhyun Cho,Inês Calvo,Inês Vieira,Isaac Manzi,Ismail Daud,Itay Itzhak,Iuliia,Alekseenko,Ivan Belashkin,Ivan Spada,Ivan Zhelyazkov,Jacob Brinton,Jafar Isbarov,Jaka Čibej,Jan Čuhel,Jan Kocoń,Jauza Akbar Krito,Jebish Purbey,Jennifer Mickel,Jennifer Za,Jenny Kunz,Jihae Jeong,Jimena Tena Dávalos,Jinu Lee,João Magalhães,John Yi,Jongin Kim,Joseph Chataignon,Joseph Marvin Imperial,Jubeerathan Thevakumar,Judith Land,Junchen Jiang,Jungwhan Kim,Kairit Sirts,Kamesh R,Kamesh V,Kanda Patrick Tshinu,Kätriin Kukk,Kaustubh Ponkshe,Kavsar Huseynova,Ke He,Kelly Buchanan,Kengatharaiyer Sarveswaran,Kerem Zaman,Khalil Mrini,Kian Kyars,Krister Kruusmaa,Kusum Chouhan,Lainitha Krishnakumar,Laura Castro Sánchez,Laura Porrino Moscoso,Leshem Choshen,Levent Sencan,Lilja Øvrelid,Lisa Alazraki,Lovina Ehimen-Ugbede,Luheerathan Thevakumar,Luxshan Thavarasa,Mahnoor Malik,Mamadou K. Keita,Mansi Jangid,Marco De Santis,Marcos García,Marek Suppa,Mariam D'Ciofalo,Marii Ojastu,Maryam Sikander,Mausami Narayan,Maximos Skandalis,Mehak Mehak,Mehmet İlteriş Bozkurt,Melaku Bayu Workie,Menan Velayuthan,Michael Leventhal,Michał Marcińczuk,Mirna Potočnjak,Mohammadamin Shafiei,Mridul Sharma,Mrityunjaya Indoria,Muhammad Ravi Shulthan Habibi,Murat Kolić,Nada Galant,Naphat Permpredanun,Narada Maugin,Nicholas Kluge Corrêa,Nikola Ljubešić,Nirmal Thomas,Nisansa de Silva,Nisheeth Joshi,Nitish Ponkshe,Nizar Habash,Nneoma C. Udeze,Noel Thomas,Noémi Ligeti-Nagy,Nouhoum Coulibaly,Nsengiyumva Faustin,Odunayo Kareemat Buliaminu,Odunayo Ogundepo,Oghojafor Godswill Fejiro,Ogundipe Blessing Funmilola,Okechukwu God'spraise,Olanrewaju Samuel,Olaoye Deborah Oluwaseun,Olasoji Akindejoye,Olga Popova,Olga Snissarenko,Onyinye Anulika Chiemezie,Orkun Kinay,Osman Tursun,Owoeye Tobiloba Moses,Oyelade Oluwafemi Joshua,Oyesanmi Fiyinfoluwa,Pablo Gamallo,Pablo Rodríguez Fernández,Palak Arora,Pedro Valente,Peter Rupnik,Philip Oghenesuowho Ekiugbo,Pramit Sahoo,Prokopis Prokopidis,Pua Niau-Puhipau,Quadri Yahya,Rachele Mignone,Raghav Singhal,Ram Mohan Rao Kadiyala,Raphael Merx,Rapheal Afolayan,Ratnavel Rajalakshmi,Rishav Ghosh,Romina Oji,Ron Kekeha Solis,Rui Guerra,Rushikesh Zawar,Sa'ad Nasir Bashir,Saeed Alzaabi,Sahil Sandeep,Sai Pavan Batchu,SaiSandeep Kantareddy,Salsabila Zahirah Pranida,Sam Buchanan,Samuel Rutunda,Sander Land,Sarah Sulollari,Sardar Ali,Saroj Sapkota,Saulius Tautvaisas,Sayambhu Sen,Sayantani Banerjee,Sebastien Diarra,SenthilNathan. M,Sewoong Lee,Shaan Shah,Shankar Venkitachalam,Sharifa Djurabaeva,Sharon Ibejih,Shivanya Shomir Dutta,Siddhant Gupta,Silvia Paniagua Suárez,Sina Ahmadi,Sivasuthan Sukumar,Siyuan Song,Snegha A.,Sokratis Sofianopoulos,Sona Elza Simon,Sonja Benčina,Sophie Gvasalia,Sphurti Kirit More,Spyros Dragazis,Stephan P. Kaufhold,Suba. S,Sultan AlRashed,Surangika Ranathunga,Taiga Someya,Taja Kuzman Pungeršek,Tal Haklay,Tasi'u Jibril,Tatsuya Aoyama,Tea Abashidze,Terenz Jomar Dela Cruz,Terra Blevins,Themistoklis Nikas,Theresa Dora Idoko,Thu Mai Do,Tilek Chubakov,Tommaso Gargiani,Uma Rathore,Uni Johannesen,Uwuma Doris Ugwu,Vallerie Alexandra Putra,Vanya Bannihatti Kumar,Varsha Jeyarajalingam,Varvara Arzt,Vasudevan Nedumpozhimana,Viktoria Ondrejova,Viktoryia Horbik,Vishnu Vardhan Reddy Kummitha,Vuk Dinić,Walelign Tewabe Sewunetie,Winston Wu,Xiaojing Zhao,Yacouba Diarra,Yaniv Nikankin,Yash Mathur,Yixi Chen,Yiyuan Li,Yolanda Xavier,Yonatan Belinkov,Yusuf Ismail Abayomi,Zaid Alyafeai,Zhengyang Shan,Zhi Rui Tam,Zilu Tang,Zuzana Nadova,Baber Abbasi,Stella Biderman,David Stap,Duygu Ataman,Fabian Schmidt,Hila Gonen,Jiayi Wang,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: 本文提出了Global PIQA，这是一个涵盖100多种语言的文化特定常识推理基准，由335名来自65个国家的研究人员共同构建。


<details>
  <summary>Details</summary>
Motivation: 目前几乎没有针对大语言模型的文化特定评估基准，因此希望通过Global PIQA填补这一空白。

Method: 通过335位来自全球的研究人员手工构建Global PIQA，包含116种语言变体，覆盖五大洲、14个语言家族和23种书写系统。

Result: 尽管最先进的语言模型在Global PIQA的整体表现良好，但是在资源较低的语言中表现较弱。

Conclusion: Global PIQA揭示了在多语言和文化背景下，日常知识仍需改进，尤其是在低资源语言中表现较弱。

Abstract: To date, there exist almost no culturally-specific evaluation benchmarks for
large language models (LLMs) that cover a large number of languages and
cultures. In this paper, we present Global PIQA, a participatory commonsense
reasoning benchmark for over 100 languages, constructed by hand by 335
researchers from 65 countries around the world. The 116 language varieties in
Global PIQA cover five continents, 14 language families, and 23 writing
systems. In the non-parallel split of Global PIQA, over 50% of examples
reference local foods, customs, traditions, or other culturally-specific
elements. We find that state-of-the-art LLMs perform well on Global PIQA in
aggregate, but they exhibit weaker performance in lower-resource languages (up
to a 37% accuracy gap, despite random chance at 50%). Open models generally
perform worse than proprietary models. Global PIQA highlights that in many
languages and cultures, everyday knowledge remains an area for improvement,
alongside more widely-discussed capabilities such as complex reasoning and
expert knowledge. Beyond its uses for LLM evaluation, we hope that Global PIQA
provides a glimpse into the wide diversity of cultures in which human language
is embedded.

</details>


### [81] [RegSpeech12: A Regional Corpus of Bengali Spontaneous Speech Across Dialects](https://arxiv.org/abs/2510.24096)
*Md. Rezuwan Hassan,Azmol Hossain,Kanij Fatema,Rubayet Sabbir Faruque,Tanmoy Shome,Ruwad Naswan,Trina Chakraborty,Md. Foriduzzaman Zihad,Tawsif Tashwar Dipto,Nazia Tasnim,Nazmuddoha Ansary,Md. Mehedi Hasan Shawon,Ahmed Imtiaz Humayun,Md. Golam Rabiul Alam,Farig Sadeque,Asif Sushmit*

Main category: cs.CL

TL;DR: 该研究分析了孟加拉语方言的语音和形态特征，探讨了自动语音识别系统的构建，旨在保护方言多样性并推动孟加拉语的数字化工具发展。


<details>
  <summary>Details</summary>
Motivation: 虽然孟加拉语在南亚及侨民社区中广泛使用并展现出丰富的方言多样性，但关于孟加拉方言的计算处理研究仍然相对有限，因此需要系统的研究来填补这一空白。

Method: 通过记录和分析不同孟加拉方言的语音和形态特性，构建相应的计算模型，特别是针对区域方言的自动语音识别系统。

Result: 研究识别出五个主要的方言群体，并分析了它们在词汇、句法和形态学上的变异，为构建相应的语言技术工具提供了基础。

Conclusion: 该研究提供了关于孟加拉方言的语音和形态特征的文献，并探讨了发展针对区域方言的自动语音识别系统的可行性，为语言技术的发展和方言多样性的保护做出了贡献。

Abstract: The Bengali language, spoken extensively across South Asia and among
diasporic communities, exhibits considerable dialectal diversity shaped by
geography, culture, and history. Phonological and pronunciation-based
classifications broadly identify five principal dialect groups: Eastern
Bengali, Manbhumi, Rangpuri, Varendri, and Rarhi. Within Bangladesh, further
distinctions emerge through variation in vocabulary, syntax, and morphology, as
observed in regions such as Chittagong, Sylhet, Rangpur, Rajshahi, Noakhali,
and Barishal. Despite this linguistic richness, systematic research on the
computational processing of Bengali dialects remains limited. This study seeks
to document and analyze the phonetic and morphological properties of these
dialects while exploring the feasibility of building computational models
particularly Automatic Speech Recognition (ASR) systems tailored to regional
varieties. Such efforts hold potential for applications in virtual assistants
and broader language technologies, contributing to both the preservation of
dialectal diversity and the advancement of inclusive digital tools for
Bengali-speaking communities. The dataset created for this study is released
for public use.

</details>


### [82] [Squrve: A Unified and Modular Framework for Complex Real-World Text-to-SQL Tasks](https://arxiv.org/abs/2510.24102)
*Yihan Wang,Peiyu Liu,Runyu Chen,Jiaxing Pu,Wei Xu*

Main category: cs.CL

TL;DR: Squrve是一个统一的Text-to-SQL框架，通过标准化接口和多方协作机制，提升了处理复杂查询的效果。


<details>
  <summary>Details</summary>
Motivation: 解决Text-to-SQL技术在现实应用中的集成困难，提升其实际可用性。

Method: 建立通用执行范式与七个原子演员组件的协作机制来优化Text-to-SQL技术。

Result: Text-to-SQL技术快速发展，学术界采用多种方法取得了显著成果。然而，由于有限的集成工具，将这些技术部署到现实系统中仍然面临挑战。为了解决这个问题，我们提出了Squrve，一个统一的、模块化的、广泛的Text-to-SQL框架，旨在结合研究进展和实际应用。Squrve首先建立了一个通用执行范式，以标准化调用接口，然后提出了一种基于七个抽象有效原子演员组件的多参与者协作机制。在广泛采用的基准测试中，实验表明协作工作流程始终优于原来的单独方法，从而为处理复杂的现实查询开辟了新的有效途径。代码可在https://github.com/Satissss/Squrve获取。

Conclusion: Squrve展示了通过模块化和协作机制在Text-to-SQL领域的有效性，能更好地应对现实世界的复杂查询。

Abstract: Text-to-SQL technology has evolved rapidly, with diverse academic methods
achieving impressive results. However, deploying these techniques in real-world
systems remains challenging due to limited integration tools. Despite these
advances, we introduce Squrve, a unified, modular, and extensive Text-to-SQL
framework designed to bring together research advances and real-world
applications. Squrve first establishes a universal execution paradigm that
standardizes invocation interfaces, then proposes a multi-actor collaboration
mechanism based on seven abstracted effective atomic actor components.
Experiments on widely adopted benchmarks demonstrate that the collaborative
workflows consistently outperform the original individual methods, thereby
opening up a new effective avenue for tackling complex real-world queries. The
codes are available at https://github.com/Satissss/Squrve.

</details>


### [83] [Beyond Line-Level Filtering for the Pretraining Corpora of LLMs](https://arxiv.org/abs/2510.24139)
*Chanwoo Park,Suyoung Park,Yelim Ahn,Jongmin Kim,Jongyeon Park,Jaejin Lee*

Main category: cs.CL

TL;DR: 本文提出了改进的行级过滤方法，通过考虑线条信号和文档中序列分布，更好地保留内容，提高语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的行级过滤技术可能会丢失有价值的内容，从而影响下游任务的表现。

Method: 提出了基于模式的行级去重（PLD）和模式感知的尾部标点过滤（PTF）方法，改进传统过滤技术。

Result: 通过训练小型语言模型，在多个选择基准测试和生成问答准确性上，均显示出显著的性能提升。

Conclusion: 模式感知的过滤方法有效保留了结构重要内容，提升了生成问答的准确性，显示出在多种语言模型中的优势。

Abstract: While traditional line-level filtering techniques, such as line-level
deduplication and trailing-punctuation filters, are commonly used, these basic
methods can sometimes discard valuable content, negatively affecting downstream
performance. In this paper, we introduce two methods-pattern-aware line-level
deduplication (PLD) and pattern-aware trailing punctuation filtering (PTF)-by
enhancing the conventional filtering techniques. Our approach not only
considers line-level signals but also takes into account their sequential
distribution across documents, enabling us to retain structurally important
content that might otherwise be removed. We evaluate these proposed methods by
training small language models (1 B parameters) in both English and Korean. The
results demonstrate that our methods consistently improve performance on
multiple-choice benchmarks and significantly enhance generative
question-answering accuracy on both SQuAD v1 and KorQuAD v1.

</details>


### [84] [Ko-MuSR: A Multistep Soft Reasoning Benchmark for LLMs Capable of Understanding Korean](https://arxiv.org/abs/2510.24150)
*Chanwoo Park,Suyoung Park,JiA Kang,Jongyeon Park,Sangho Kim,Hyunji M. Park,Sumin Bae,Mingyu Kang,Jaejin Lee*

Main category: cs.CL

TL;DR: Ko-MuSR是一个新的基准，用于评估韩语中的多步骤推理，研究表明多语言模型在此任务中表现更好。


<details>
  <summary>Details</summary>
Motivation: 为了全面评估韩语叙事中的多步骤软推理，减少数据污染，提出Ko-MuSR基准测试。

Method: 建立在MuSR基础上，评估使用了完全韩语的叙事、推理链和由人工审核的多项选择题。通过精心设计的提示策略提升模型的准确性。

Result: 通过评估四个大型语言模型，发现多语言模型在韩语推理任务中优于专注于韩语的模型，显示了推理能力的跨语言泛化。

Conclusion: Ko-MuSR为推动韩语自然语言处理提供了一个坚实的基础，使得长上下文推理和提示策略的系统评估成为可能。

Abstract: We present Ko-MuSR, the first benchmark to comprehensively evaluate
multistep, soft reasoning in long Korean narratives while minimizing data
contamination. Built following MuSR, Ko-MuSR features fully Korean narratives,
reasoning chains, and multiple-choice questions verified by human annotators
for logical consistency and answerability. Evaluations of four large language
models -- two multilingual and two Korean-specialized -- show that multilingual
models outperform Korean-focused ones even in Korean reasoning tasks,
indicating cross-lingual generalization of reasoning ability. Carefully
designed prompting strategies, which combine few-shot examples, reasoning
traces, and task-specific hints, further boost accuracy, approaching
human-level performance. Ko-MuSR offers a solid foundation for advancing Korean
NLP by enabling systematic evaluation of long-context reasoning and prompting
strategies.

</details>


### [85] [MuSaG: A Multimodal German Sarcasm Dataset with Full-Modal Annotations](https://arxiv.org/abs/2510.24178)
*Aaron Scott,Maike Züfle,Jan Niehues*

Main category: cs.CL

TL;DR: 本研究介绍了MuSaG数据集，并揭示了在多模态讽刺检测中模型与人类依赖音频方式的差异。


<details>
  <summary>Details</summary>
Motivation: 理解讽刺在社交媒体和流行文化中的普遍性及其对自然语言理解、情感分析和内容审核的挑战。

Method: 通过手动选择并注释的德国电视节目中的陈述，整合文本、音频和视频模态进行讽刺检测。

Result: 建立了第一个德语多模态讽刺检测数据集MuSaG，并对多种模型进行基准测试，发现模型在文本上的表现优于人类在对话环境中的表现.

Conclusion: MuSaG的发布为未来多模态讽刺检测和人机模型对齐的研究提供支持。

Abstract: Sarcasm is a complex form of figurative language in which the intended
meaning contradicts the literal one. Its prevalence in social media and popular
culture poses persistent challenges for natural language understanding,
sentiment analysis, and content moderation. With the emergence of multimodal
large language models, sarcasm detection extends beyond text and requires
integrating cues from audio and vision. We present MuSaG, the first German
multimodal sarcasm detection dataset, consisting of 33 minutes of manually
selected and human-annotated statements from German television shows. Each
instance provides aligned text, audio, and video modalities, annotated
separately by humans, enabling evaluation in unimodal and multimodal settings.
We benchmark nine open-source and commercial models, spanning text, audio,
vision, and multimodal architectures, and compare their performance to human
annotations. Our results show that while humans rely heavily on audio in
conversational settings, models perform best on text. This highlights a gap in
current multimodal models and motivates the use of MuSaG for developing models
better suited to realistic scenarios. We release MuSaG publicly to support
future research on multimodal sarcasm detection and human-model alignment.

</details>


### [86] [Exploring the Influence of Relevant Knowledge for Natural Language Generation Interpretability](https://arxiv.org/abs/2510.24179)
*Iván Martínez-Murillo,Paloma Moreda,Elena Lloret*

Main category: cs.CL

TL;DR: 本研究探讨了外部知识在自然语言生成中的重要性，通过扩展CommonGen数据集并创建KITGI基准，发现全外部知识生成的句子表现显著优于过滤后的句子，突出知识增强NLG系统设计的重要性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨外部知识的整合对常识生成任务的影响，以提升自然语言生成系统的可解释性和输出质量。

Method: 通过创建KITGI数据集并运用T5-Large模型，比较全知识和过滤知识条件下的句子生成，采用三阶段方法进行可解释性评估。

Result: 本研究探讨了外部知识整合在自然语言生成（NLG）中的影响，重点是常识生成任务。我们通过创建KITGI基准数据集来扩展CommonGen数据集，该数据集将输入概念集与ConceptNet中检索到的语义关系配对，并包含手动注释的输出。使用T5-Large模型，我们比较了两种条件下的句子生成：全外部知识和过滤后的知识，其中故意去除了高度相关的关系。我们的可解释性基准遵循三阶段方法：（1）识别和移除关键知识，（2）再生成句子，（3）手动评估输出的常识合理性和概念覆盖。结果表明，使用全知识生成的句子在两个标准上的正确率达到了91％，而过滤后性能骤降至6％。这些发现表明，相关外部知识对于维持NLG中的连贯性和概念覆盖至关重要。这项工作强调了设计可解释的知识增强NLG系统的重要性，同时呼吁建立捕捉潜在推理的评估框架，而不仅仅是表面指标。

Conclusion: 研究结果表明，在自然语言生成中，整合相关外部知识对于保证生成句子的连贯性和概念覆盖具有人不可或缺的作用。

Abstract: This paper explores the influence of external knowledge integration in
Natural Language Generation (NLG), focusing on a commonsense generation task.
We extend the CommonGen dataset by creating KITGI, a benchmark that pairs input
concept sets with retrieved semantic relations from ConceptNet and includes
manually annotated outputs. Using the T5-Large model, we compare sentence
generation under two conditions: with full external knowledge and with filtered
knowledge where highly relevant relations were deliberately removed. Our
interpretability benchmark follows a three-stage method: (1) identifying and
removing key knowledge, (2) regenerating sentences, and (3) manually assessing
outputs for commonsense plausibility and concept coverage. Results show that
sentences generated with full knowledge achieved 91\% correctness across both
criteria, while filtering reduced performance drastically to 6\%. These
findings demonstrate that relevant external knowledge is critical for
maintaining both coherence and concept coverage in NLG. This work highlights
the importance of designing interpretable, knowledge-enhanced NLG systems and
calls for evaluation frameworks that capture the underlying reasoning beyond
surface-level metrics.

</details>


### [87] [Beyond Neural Incompatibility: Easing Cross-Scale Knowledge Transfer in Large Language Models through Latent Semantic Alignment](https://arxiv.org/abs/2510.24208)
*Jian Gu,Aldeida Aleti,Chunyang Chen,Hongyu Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种新的方法，通过激活值实现大型语言模型之间的层级知识转移，克服了参数层直接重用的局限性，取得了优于以前工作的结果。


<details>
  <summary>Details</summary>
Motivation: 探讨不同规模的大型语言模型（LLMs）之间的知识转移，特别是面对现有方法的局限性。

Method: 通过在潜在空间中识别语义对齐，采用激活值作为知识转移的媒介，从而实现不同规模大型语言模型之间的有效转移。

Result: 提出了一种基于激活值进行层级知识转移的新方法，从而在不同规模的LLMs之间实现有效的知识转移。

Conclusion: 通过分析和评估，证明了这种基于语义对齐的激活值转移方法的有效性，并揭示了促进跨尺度知识转移的关键因素。

Abstract: Large Language Models (LLMs) encode vast amounts of knowledge in their
massive parameters, which is accessible to locate, trace, and analyze. Despite
advances in neural interpretability, it is still not clear how to transfer
knowledge in a fine-grained manner, namely parametric knowledge transfer (PKT).
A key problem is enabling effective and efficient knowledge transfer across
LLMs of different scales, which is essential for achieving greater flexibility
and broader applicability in transferring knowledge between LLMs. Due to neural
incompatibility, referring to the architectural and parametric differences
between LLMs of varying scales, existing methods that directly reuse layer
parameters are severely limited. In this paper, we identify the semantic
alignment in latent space as the fundamental prerequisite for LLM cross-scale
knowledge transfer. Instead of directly using the layer parameters, our
approach takes activations as the medium of layer-wise knowledge transfer.
Leveraging the semantics in latent space, our approach is simple and
outperforms prior work, better aligning model behaviors across varying scales.
Evaluations on four benchmarks demonstrate the efficacy of our method. Further
analysis reveals the key factors easing cross-scale knowledge transfer and
provides insights into the nature of latent semantic alignment.

</details>


### [88] [HACK: Hallucinations Along Certainty and Knowledge Axes](https://arxiv.org/abs/2510.24222)
*Adi Simhi,Jonathan Herzig,Itay Itzhak,Dana Arad,Zorik Gekhman,Roi Reichart,Fazl Barez,Gabriel Stanovsky,Idan Szpektor,Yonatan Belinkov*

Main category: cs.CL

TL;DR: 本文提出了一个新的分类框架，针对大型语言模型的幻觉现象，以知识和确定性为维度，从而识别和减缓不同类型的幻觉。


<details>
  <summary>Details</summary>
Motivation: 提升大型语言模型的可靠性，针对不同类型的幻觉设计更有效的减缓策略。

Method: 构建模型特定数据集，以知识和确定性两个维度对幻觉进行分类，并验证减缓技术的有效性。

Result: 本文探讨了大型语言模型（LLMs）中的幻觉现象，认为目前的研究主要关注幻觉的外部特性，而忽视了模型内部属性的影响。提出了一个分类框架，通过知识和确定性两个维度对幻觉进行分类，并基于模型的特性构建特定数据集，以识别不同类型的幻觉。框架通过引导减缓技术验证了知识维度的分类，并分析了不同模型之间的知识与幻觉模式。尤其在确定性维度上，发现一些模型在内部知识正确的情况下仍然会出现确定性的幻觉，进而引入了新评价指标以评估减缓方法在此类案件中的有效性。研究强调了在幻觉分析中同时考虑知识和确定性的重要性，并呼吁针对幻觉根本因素的减缓策略。

Conclusion: 研究强调了针对幻觉的根本因素进行分类的重要性，并呼吁开发有针对性的减缓方法。

Abstract: Hallucinations in LLMs present a critical barrier to their reliable usage.
Existing research usually categorizes hallucination by their external
properties rather than by the LLMs' underlying internal properties. This
external focus overlooks that hallucinations may require tailored mitigation
strategies based on their underlying mechanism. We propose a framework for
categorizing hallucinations along two axes: knowledge and certainty. Since
parametric knowledge and certainty may vary across models, our categorization
method involves a model-specific dataset construction process that
differentiates between those types of hallucinations. Along the knowledge axis,
we distinguish between hallucinations caused by a lack of knowledge and those
occurring despite the model having the knowledge of the correct response. To
validate our framework along the knowledge axis, we apply steering mitigation,
which relies on the existence of parametric knowledge to manipulate model
activations. This addresses the lack of existing methods to validate knowledge
categorization by showing a significant difference between the two
hallucination types. We further analyze the distinct knowledge and
hallucination patterns between models, showing that different hallucinations do
occur despite shared parametric knowledge. Turning to the certainty axis, we
identify a particularly concerning subset of hallucinations where models
hallucinate with certainty despite having the correct knowledge internally. We
introduce a new evaluation metric to measure the effectiveness of mitigation
methods on this subset, revealing that while some methods perform well on
average, they fail disproportionately on these critical cases. Our findings
highlight the importance of considering both knowledge and certainty in
hallucination analysis and call for targeted mitigation approaches that
consider the hallucination underlying factors.

</details>


### [89] [Towards Transparent Reasoning: What Drives Faithfulness in Large Language Models?](https://arxiv.org/abs/2510.24236)
*Teague McMillan,Gabriele Dominici,Martin Gjoreski,Marc Langheinrich*

Main category: cs.CL

TL;DR: 研究了如何通过操控示例数量、提示策略和训练过程来提升大语言模型在医疗领域的解释可靠性。


<details>
  <summary>Details</summary>
Motivation: 在医疗领域中，LLM的解释不准确会导致医生的信任下降和潜在的安全风险。

Method: 评估和操控大语言模型在解释生成中的表现

Result: 经过对三种模型在BBQ和MedQA数据集上的评估，发现几种影响解释可靠性的因素。

Conclusion: 通过改善输入示例和提示设计，可以显著提升LLM在敏感领域的解释能力和可信度。

Abstract: Large Language Models (LLMs) often produce explanations that do not
faithfully reflect the factors driving their predictions. In healthcare
settings, such unfaithfulness is especially problematic: explanations that omit
salient clinical cues or mask spurious shortcuts can undermine clinician trust
and lead to unsafe decision support. We study how inference and training-time
choices shape explanation faithfulness, focusing on factors practitioners can
control at deployment. We evaluate three LLMs (GPT-4.1-mini, LLaMA 70B, LLaMA
8B) on two datasets-BBQ (social bias) and MedQA (medical licensing questions),
and manipulate the number and type of few-shot examples, prompting strategies,
and training procedure. Our results show: (i) both the quantity and quality of
few-shot examples significantly impact model faithfulness; (ii) faithfulness is
sensitive to prompting design; (iii) the instruction-tuning phase improves
measured faithfulness on MedQA. These findings offer insights into strategies
for enhancing the interpretability and trustworthiness of LLMs in sensitive
domains.

</details>


### [90] [Abjad AI at NADI 2025: CATT-Whisper: Multimodal Diacritic Restoration Using Text and Speech Representations](https://arxiv.org/abs/2510.24247)
*Ahmad Ghannam,Naif Alharthi,Faris Alasmary,Kholood Al Tabash,Shouq Sadah,Lahouari Ghouti*

Main category: cs.CL

TL;DR: 本研究提出了一种多模态方法用于阿拉伯方言句子的音调恢复任务，结合文本和语音信息，使用自训练的CATT模型和OpenAI Whisper模型。


<details>
  <summary>Details</summary>
Motivation: 旨在提升阿拉伯方言句子的音调恢复准确性，尤其是在多模态信息的结合中探索新的可能性。

Method: 通过建模文本和语音信息，利用CATT和Whisper模型，实施早期融合与跨注意力融合两种策略进行处理和分类。

Result: 模型在开发集上取得了较低的字错误率和字符错误率，在测试集上也达到了满意的结果，展示了其鲁棒性。

Conclusion: 实验结果表明，该模型在开发集和测试集上分别达到0.25和0.55的字错误率以及0.9和0.13的字符错误率，验证了模型的有效性。

Abstract: In this work, we tackle the Diacritic Restoration (DR) task for Arabic
dialectal sentences using a multimodal approach that combines both textual and
speech information. We propose a model that represents the text modality using
an encoder extracted from our own pre-trained model named CATT. The speech
component is handled by the encoder module of the OpenAI Whisper base model.
Our solution is designed following two integration strategies. The former
consists of fusing the speech tokens with the input at an early stage, where
the 1500 frames of the audio segment are averaged over 10 consecutive frames,
resulting in 150 speech tokens. To ensure embedding compatibility, these
averaged tokens are processed through a linear projection layer prior to
merging them with the text tokens. Contextual encoding is guaranteed by the
CATT encoder module. The latter strategy relies on cross-attention, where text
and speech embeddings are fused. The cross-attention output is then fed to the
CATT classification head for token-level diacritic prediction. To further
improve model robustness, we randomly deactivate the speech input during
training, allowing the model to perform well with or without speech. Our
experiments show that the proposed approach achieves a word error rate (WER) of
0.25 and a character error rate (CER) of 0.9 on the development set. On the
test set, our model achieved WER and CER scores of 0.55 and 0.13, respectively.

</details>


### [91] [Evaluating LLMs on Generating Age-Appropriate Child-Like Conversations](https://arxiv.org/abs/2510.24250)
*Syed Zohaib Hassan,Pål Halvorsen,Miriam S. Johnson,Pierre Lison*

Main category: cs.CL

TL;DR: 该研究评估了多种大型语言模型在生成儿童对话方面的性能，结果表明模型在儿童语言生成的适切性上存在显著挑战，尤其是在低资源语言环境下。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在生成儿童对话中的表现，特别是在挪威语环境下的真实性和适宜性。

Method: 比较研究

Result: 通过对五种不同的语言模型进行评估，发现评估者在幼儿（5岁）与较大儿童（9岁）对话生成的准确性差异明显，同时部分模型生成的语言超出目标年龄段的语言能力。

Conclusion: 研究揭示了在为儿童开发语言生成系统时面临的关键数据相关挑战，强调了在年龄适宜性和语言复杂性方面的不足。

Abstract: Large Language Models (LLMs), predominantly trained on adult conversational
data, face significant challenges when generating authentic, child-like
dialogue for specialized applications. We present a comparative study
evaluating five different LLMs (GPT-4, RUTER-LLAMA-2-13b, GPTSW, NorMistral-7b,
and NorBloom-7b) to generate age-appropriate Norwegian conversations for
children aged 5 and 9 years. Through a blind evaluation by eleven education
professionals using both real child interview data and LLM-generated text
samples, we assessed authenticity and developmental appropriateness. Our
results show that evaluators achieved strong inter-rater reliability (ICC=0.75)
and demonstrated higher accuracy in age prediction for younger children
(5-year-olds) compared to older children (9-year-olds). While GPT-4 and
NorBloom-7b performed relatively well, most models generated language perceived
as more linguistically advanced than the target age groups. These findings
highlight critical data-related challenges in developing LLM systems for
specialized applications involving children, particularly in low-resource
languages where comprehensive age-appropriate lexical resources are scarce.

</details>


### [92] [MERGE: Minimal Expression-Replacement GEneralization Test for Natural Language Inference](https://arxiv.org/abs/2510.24295)
*Mădălina Zgreabăn,Tejaswini Deoskar,Lasha Abzianidze*

Main category: cs.CL

TL;DR: 提出了一种新方法MERGE，用于自动生成NLI问题变体，模型在变体上表现显著下降，表明泛化能力不足。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型在自然语言推理中的泛化能力不足，尤其是在现有基准上手动创建新基准成本高且难度大。

Method: 提出了一种自动生成高质量NLI问题变体的方法，通过替换开放类别词并保留潜在推理关系。

Result: NLI模型在变体上的表现比原始问题低4-20%，表明其泛化能力差。还分析了替换词的词类、词概率以及可信度对模型性能的影响。

Conclusion: NLI模型在经过最小修改的问题上表现依然不佳，反映出其推理能力的局限性。

Abstract: In recent years, many generalization benchmarks have shown language models'
lack of robustness in natural language inference (NLI). However, manually
creating new benchmarks is costly, while automatically generating high-quality
ones, even by modifying existing benchmarks, is extremely difficult. In this
paper, we propose a methodology for automatically generating high-quality
variants of original NLI problems by replacing open-class words, while
crucially preserving their underlying reasoning. We dub our generalization test
as MERGE (Minimal Expression-Replacements GEneralization), which evaluates the
correctness of models' predictions across reasoning-preserving variants of the
original problem. Our results show that NLI models' perform 4-20% worse on
variants, suggesting low generalizability even on such minimally altered
problems. We also analyse how word class of the replacements, word probability,
and plausibility influence NLI models' performance.

</details>


### [93] [Lookahead Tree-Based Rollouts for Enhanced Trajectory-Level Exploration in Reinforcement Learning with Verifiable Rewards](https://arxiv.org/abs/2510.24302)
*Shangyu Xing,Siyuan Wang,Chenyuan Yang,Xinyu Dai,Xiang Ren*

Main category: cs.CL

TL;DR: 提出LATR，一种新颖的回滚策略，通过增强轨迹多样性来提升策略学习效果。


<details>
  <summary>Details</summary>
Motivation: 当前方法在样本轨迹多样性方面存在瓶颈，限制了策略学习的有效性。

Method: LATR通过三个阶段操作：在高不确定性生成步骤分支、对每个新分支进行前瞻性模拟、修剪在模拟中表现出长期相似性的分支。

Result: LATR相较于随机采样平均加速策略学习131%，并在不同推理任务上提高了最终的pass@1性能4.2%。

Conclusion: LATR策略有效提高了样本轨迹的多样性，从而加速了策略学习及优化其性能。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR), particularly with
algorithms like Group Relative Policy Optimization (GRPO), has proven highly
effective in enhancing the reasoning capabilities of large language models.
However, a critical bottleneck in current pipelines lies in the limited
diversity of sampled trajectories during group rollouts. Homogeneous
trajectories and their associated rewards would diminish the return signals for
policy updates, thereby hindering effective policy learning. This lack of
diversity stems primarily from token-level stochastic sampling, where local
variations are likely to collapse into near-identical reasoning paths. To
address this limitation, we propose Lookahead Tree-Based Rollouts (LATR), a
novel rollout strategy designed to explicitly promotes trajectory-level
diversity by enforcing branching into different candidate tokens likely to
yield distinct continuations. Specifically, LATR iteratively operates in three
stages: (1) branching at high-uncertainty generation steps, (2) performing
lookahead simulation for each new branch, and (3) pruning branches that
exhibits prolonged similarity during simulation. Compared with stochastic
Sampling, LATR accelerates policy learning by 131% on average and improves
final pass@1 performance by 4.2% on both GRPO and Dynamic sAmpling Policy
Optimization (DAPO) algorithms across different reasoning tasks. Our code and
data are publicly available at https://github.com/starreeze/latr.

</details>


### [94] [Critique-RL: Training Language Models for Critiquing through Two-Stage Reinforcement Learning](https://arxiv.org/abs/2510.24320)
*Zhiheng Xi,Jixuan Huang,Xin Guo,Boyang Hong,Dingwen Yang,Xiaoran Fan,Shuo Li,Zehui Chen,Junjie Ye,Siyu Yuan,Zhengyin Du,Xuesong Yao,Yufei Xu,Jiecao Chen,Rui Zheng,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: Critique-RL是一种无需强监督的在线强化学习方法，通过双阶段优化有效提升评判语言模型的表现。


<details>
  <summary>Details</summary>
Motivation: 提高现有大型语言模型在复杂推理任务上的表现，尤其是在缺乏强监督数据的情况下。

Method: 提出Critique-RL，一种在线强化学习方法，旨在在没有强监督的情况下开发评判语言模型。

Result: Critique-RL通过双阶段优化策略显著提升模型性能，帮助提高评判者的有效性和可区分性。

Conclusion: Critique-RL展示了在多项任务和模型上显著的性能改善，证明了其在提升语言模型能力方面的潜力。

Abstract: Training critiquing language models to assess and provide feedback on model
outputs is a promising way to improve LLMs for complex reasoning tasks.
However, existing approaches typically rely on stronger supervisors for
annotating critique data. To address this, we propose Critique-RL, an online RL
approach for developing critiquing language models without stronger
supervision. Our approach operates on a two-player paradigm: the actor
generates a response, the critic provides feedback, and the actor refines the
response accordingly. We first reveal that relying solely on indirect reward
signals from the actor's outputs for RL optimization often leads to
unsatisfactory critics: while their helpfulness (i.e., providing constructive
feedback) improves, the discriminability (i.e., determining whether a response
is high-quality or not) remains poor, resulting in marginal performance gains.
To overcome this, Critique-RL adopts a two-stage optimization strategy. In
stage I, it reinforces the discriminability of the critic with direct
rule-based reward signals; in stage II, it introduces indirect rewards based on
actor refinement to improve the critic's helpfulness, while maintaining its
discriminability via appropriate regularization. Extensive experiments across
various tasks and models show that Critique-RL delivers substantial performance
improvements. For example, it achieves a 9.02% gain on in-domain tasks and a
5.70% gain on out-of-domain tasks for Qwen2.5-7B, highlighting its potential.

</details>


### [95] [Beyond MCQ: An Open-Ended Arabic Cultural QA Benchmark with Dialect Variants](https://arxiv.org/abs/2510.24328)
*Hunzalah Hassan Bhatti,Firoj Alam*

Main category: cs.CL

TL;DR: 本研究提出一种新方法，旨在提高大语言模型在阿拉伯语和方言上的表现，涉及多项选择题和开放式问题的转换与基准测试，研究发现阿拉伯方言知识差距明显。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决大语言模型在文化基础和方言内容处理不均的问题，为多语言评估提供更包容的依据。

Method: 本研究通过翻译、问题转换与模型基准测试，结合链式思考进行推理，扩展数据集并进行广泛实验。

Result: 本研究提出一种全面的方法，旨在提升大语言模型（LLMs）在现代标准阿拉伯语及其方言内容上的表现。通过将现代标准阿拉伯语的多项选择题（MCQs）翻译为英语及多种阿拉伯方言，并转换为开放式问题（OEQs），同时进行多种零样本和微调LLMs的基准测试，引入链式思考（CoT）推理以完善模型，扩展了现有的多语言对齐的数据集。实验结果表明，阿拉伯方言的表现较差，阿拉伯中心模型在多选题中表现良好但在开放式问题中存在困难，而CoT方法在评判正确性上有所提升，但在基于n-gram的评估指标上结果不一。

Conclusion: 阿拉伯方言在大语言模型的表现上仍存在显著差距，尽管阿拉伯语中心模型在多项选择题中表现良好，但在开放式问题上挑战较大。

Abstract: Large Language Models (LLMs) are increasingly used to answer everyday
questions, yet their performance on culturally grounded and dialectal content
remains uneven across languages. We propose a comprehensive method that (i)
translates Modern Standard Arabic (MSA) multiple-choice questions (MCQs) into
English and several Arabic dialects, (ii) converts them into open-ended
questions (OEQs), (iii) benchmarks a range of zero-shot and fine-tuned LLMs
under both MCQ and OEQ settings, and (iv) generates chain-of-thought (CoT)
rationales to fine-tune models for step-by-step reasoning. Using this method,
we extend an existing dataset in which QAs are parallelly aligned across
multiple language varieties, making it, to our knowledge, the first of its
kind. We conduct extensive experiments with both open and closed models. Our
findings show that (i) models underperform on Arabic dialects, revealing
persistent gaps in culturally grounded and dialect-specific knowledge; (ii)
Arabic-centric models perform well on MCQs but struggle with OEQs; and (iii)
CoT improves judged correctness while yielding mixed n-gram-based metrics. The
developed dataset will be publicly released to support further research on
culturally and linguistically inclusive evaluation.

</details>


### [96] [LongWeave: A Long-Form Generation Benchmark Bridging Real-World Relevance and Verifiability](https://arxiv.org/abs/2510.24345)
*Zikai Xiao,Fei Huang,Jianhong Tu,Jianhui Wei,Wen Ma,Yuxuan Zhou,Jian Wu,Bowen Yu,Zuozhu Liu,Junyang Lin*

Main category: cs.CL

TL;DR: LongWeave结合了现实与可验证评估的方法，通过CoV-Eval系统生成任务，评估大语言模型在处理复杂长文本生成中的能力及其局限性。


<details>
  <summary>Details</summary>
Motivation: 应对大语言模型在生成长文本时面临的挑战，特别是在现实世界查询与评估标准之间的差距。

Method: 引入Constraint-Verifier Evaluation (CoV-Eval)方法，通过定义可验证目标并基于这些目标系统生成查询、文本材料和约束，确保任务既真实又具备客观评估标准。

Result: 在23个大语言模型的评估中，发现即使是最先进的模型，在面对真实复杂性和输出长度增加时，长文本生成仍然面临重大挑战。

Conclusion: LongWeave提供了一种平衡现实与可验证评估的方法，能够有效地评估大语言模型在长文本生成中的能力，并揭示了目前模型在处理复杂真实场景时的局限性。

Abstract: Generating long, informative, and factual outputs remains a major challenge
for Large Language Models (LLMs). Existing benchmarks for long-form generation
typically assess real-world queries with hard-to-verify metrics or use
synthetic setups that ease evaluation but overlook real-world intricacies. In
this paper, we introduce \textbf{LongWeave}, which balances real-world and
verifiable assessment with Constraint-Verifier Evaluation (CoV-Eval). CoV-Eval
constructs tasks by first defining verifiable targets within real-world
scenarios, then systematically generating corresponding queries, textual
materials, and constraints based on these targets. This ensures that tasks are
both realistic and objectively assessable, enabling rigorous assessment of
model capabilities in meeting complex real-world constraints. LongWeave
supports customizable input/output lengths (up to 64K/8K tokens) across seven
distinct tasks. Evaluation on 23 LLMs shows that even state-of-the-art models
encounter significant challenges in long-form generation as real-world
complexity and output length increase.

</details>


### [97] [Comprehensive and Efficient Distillation for Lightweight Sentiment Analysis Models](https://arxiv.org/abs/2510.24425)
*Guangyu Xie,Yice Zhang,Jianzhu Bao,Qianlong Wang,Yang Sun,Bingbing Wang,Ruifeng Xu*

Main category: cs.CL

TL;DR: 论文提出COMPEFFDIST框架，通过自动指令构建和数据过滤提高情感分析模型的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 旨在克服传统知识蒸馏技术在情感分析领域的局限性，尤其是在指令和用户文本的多样性和计算效率方面。

Method: 该框架采用了属性基础的自动指令构建和难度基础的数据过滤，分别解决了指令多样性和计算成本的问题，并在多个模型系列上进行验证。

Result: 该论文提出了一种名为COMPEFFDIST的情感分析知识蒸馏框架，旨在解决当前情感分析模型面临的两个主要挑战：手动生成的指令多样性和数量不足，以及大规模用户文本的计算成本高。通过引入基于属性的自动指令构建和基于难度的数据过滤两个模块，作者成功将3B的学生模型性能提升至与20倍大教师模型相当，并且在数据效率上，使用仅10%的数据就可以达到相同的表现水平。

Conclusion: COMPEFFDIST框架有效解决了传统知识蒸馏方法中的挑战，使得小模型能够在任务上接近大模型的性能，同时实现了更高的数据效率。

Abstract: Recent efforts leverage knowledge distillation techniques to develop
lightweight and practical sentiment analysis models. These methods are grounded
in human-written instructions and large-scale user texts. Despite the promising
results, two key challenges remain: (1) manually written instructions are
limited in diversity and quantity, making them insufficient to ensure
comprehensive coverage of distilled knowledge; (2) large-scale user texts incur
high computational cost, hindering the practicality of these methods. To this
end, we introduce COMPEFFDIST, a comprehensive and efficient distillation
framework for sentiment analysis. Our framework consists of two key modules:
attribute-based automatic instruction construction and difficulty-based data
filtering, which correspondingly tackle the aforementioned challenges. Applying
our method across multiple model series (Llama-3, Qwen-3, and Gemma-3), we
enable 3B student models to match the performance of 20x larger teacher models
on most tasks. In addition, our approach greatly outperforms baseline methods
in data efficiency, attaining the same performance level with only 10% of the
data.

</details>


### [98] [SynthWorlds: Controlled Parallel Worlds for Disentangling Reasoning and Knowledge in Language Models](https://arxiv.org/abs/2510.24427)
*Ken Gu,Advait Bhat,Mike A Merrill,Robert West,Xin Liu,Daniel McDuff,Tim Althoff*

Main category: cs.CL

TL;DR: SynthWorlds框架提供了一个受控环境，以更好地评估语言模型的推理能力与记忆知识之间的关系。


<details>
  <summary>Details</summary>
Motivation: 现有的数据集和方法无法清晰地区分语言模型的推理能力和事实知识，存在过度依赖参数知识的问题。

Method: 提出了SynthWorlds框架，用于评估语言模型的推理能力，区分任务推理复杂性与事实知识之间的关系。

Result: 通过构建平行语料库并设计了两个镜像任务，研究表明知识优势差距仍然存在，尽管知识获取和整合机制有所减少。

Conclusion: SynthWorlds框架为语言模型的评估提供了精准且可测试的方法，揭示了推理与记忆之间的关系。

Abstract: Evaluating the reasoning ability of language models (LMs) is complicated by
their extensive parametric world knowledge, where benchmark performance often
reflects factual recall rather than genuine reasoning. Existing datasets and
approaches (e.g., temporal filtering, paraphrasing, adversarial substitution)
cannot cleanly separate the two. We present SynthWorlds, a framework that
disentangles task reasoning complexity from factual knowledge. In SynthWorlds,
we construct parallel corpora representing two worlds with identical
interconnected structure: a real-mapped world, where models may exploit
parametric knowledge, and a synthetic-mapped world, where such knowledge is
meaningless. On top of these corpora, we design two mirrored tasks as case
studies: multi-hop question answering and page navigation, which maintain equal
reasoning difficulty across worlds. Experiments in parametric-only (e.g.,
closed-book QA) and knowledge-augmented (e.g., retrieval-augmented) LM settings
reveal a persistent knowledge advantage gap, defined as the performance boost
models gain from memorized parametric world knowledge. Knowledge acquisition
and integration mechanisms reduce but do not eliminate this gap, highlighting
opportunities for system improvements. Fully automatic and scalable,
SynthWorlds provides a controlled environment for evaluating LMs in ways that
were previously challenging, enabling precise and testable comparisons of
reasoning and memorization.

</details>


### [99] [LuxIT: A Luxembourgish Instruction Tuning Dataset from Monolingual Seed Data](https://arxiv.org/abs/2510.24434)
*Julian Valline,Cedric Lothritz,Jordi Cabot*

Main category: cs.CL

TL;DR: 本文介绍了 LuxIT 数据集，旨在提升卢森堡语 LLM 的训练效果，尽管结果不一，但为进一步研究提供了基础。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言环境中高质量训练数据不足的问题。

Method: 利用卢森堡母语文本合成的单语指令调优数据集，并通过 LLM 进行质量保证。

Result: 针对多种小规模 LLM 的微调对卢森堡语能力考试的基准测试结果不一，表现差异显著。

Conclusion: LuxIT 是针对卢森堡语自然语言处理的关键贡献，尽管结果显示进一步研究的需求。

Abstract: The effectiveness of instruction-tuned Large Language Models (LLMs) is often
limited in low-resource linguistic settings due to a lack of high-quality
training data. We introduce LuxIT, a novel, monolingual instruction tuning
dataset for Luxembourgish developed to mitigate this challenge. We synthesize
the dataset from a corpus of native Luxembourgish texts, utilizing
DeepSeek-R1-0528, chosen for its shown proficiency in Luxembourgish. Following
generation, we apply a quality assurance process, employing an LLM-as-a-judge
approach. To investigate the practical utility of the dataset, we fine-tune
several smaller-scale LLMs on LuxIT. Subsequent benchmarking against their base
models on Luxembourgish language proficiency examinations, however, yields
mixed results, with performance varying significantly across different models.
LuxIT represents a critical contribution to Luxembourgish natural language
processing and offers a replicable monolingual methodology, though our findings
highlight the need for further research to optimize its application.

</details>


### [100] [Fine-tuning Large Language Models with Limited Data: A Survey and Practical Guide](https://arxiv.org/abs/2411.09539)
*Marton Szep,Daniel Rueckert,Rüdiger von Eisenhart-Rothe,Florian Hinterwimmer*

Main category: cs.CL

TL;DR: 针对数据稀缺场景，系统评估大型语言模型的微调方法，提供操作性见解。


<details>
  <summary>Details</summary>
Motivation: 在低资源语言、专业领域和受限部署环境中，使用有限数据微调大型语言模型面临实际挑战。

Method: 系统性地回顾和分析了参数高效微调技术、领域和跨语言适应方法以及模型专业化策略，对如何选择适合的技术进行了评估。

Result: 提供了一份关于数据稀缺场景下微调大型语言模型的综合实用调查，系统回顾了参数高效的微调技术、领域与跨语言适应方法及模型专业化策略。

Conclusion: 旨在为研究人员和从业者提供可行的见解，以有效微调在数据和资源有限情况下的大型语言模型。

Abstract: Fine-tuning large language models (LLMs) with limited data poses a practical
challenge in low-resource languages, specialized domains, and constrained
deployment settings. While pre-trained LLMs provide strong foundations,
effective adaptation under data scarcity requires focused and efficient
fine-tuning techniques. This paper presents a structured and practical survey
of recent methods for fine-tuning LLMs in data-scarce scenarios. We
systematically review parameter-efficient fine-tuning techniques that lower
training and deployment costs, domain and cross-lingual adaptation methods for
both encoder and decoder models, and model specialization strategies. We
further examine preference alignment approaches that guide model behavior using
limited human or synthetic feedback, emphasizing sample and compute efficiency.
Throughout, we highlight empirical trade-offs, selection criteria, and best
practices for choosing suitable techniques based on task constraints, including
model scaling, data scaling, and the mitigation of catastrophic forgetting. The
aim is to equip researchers and practitioners with actionable insights for
effectively fine-tuning LLMs when data and resources are limited.

</details>


### [101] [SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space](https://arxiv.org/abs/2510.24446)
*Viktoriia Zinkovich,Anton Antonov,Andrei Spiridonov,Denis Shepelev,Andrey Moskalenko,Daria Pugacheva,Elena Tutubalina,Andrey Kuznetsov,Vlad Shakhuro*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的对抗性释义任务，介绍了SPARTA优化方法，表明先进的推理分割模型对对抗性释义依然脆弱。


<details>
  <summary>Details</summary>
Motivation: 研究者们发现，在视觉语言任务中，多模态大型语言模型（MLLMs）的表现令人印象深刻，但在生成对抗性释义方面仍存在不足，特别是如何处理语义等价的文本释义以应对不同用户表达的相同意图。

Method: 提出SPARTA方法，该方法通过在文本自编码器的低维语义潜在空间中进行黑箱句子级优化，并利用强化学习进行指导。

Result: 提出了一项新颖的对抗性释义任务，开发了针对自动化评估的全面协议，并引入了SPARTA，一个基于强化学习的优化方法，显著提高对抗性释义的成功率。

Conclusion: 先进的推理分割模型在面对对抗性释义时，尽管有语义与语法约束，仍然存在脆弱性。

Abstract: Multimodal large language models (MLLMs) have shown impressive capabilities
in vision-language tasks such as reasoning segmentation, where models generate
segmentation masks based on textual queries. While prior work has primarily
focused on perturbing image inputs, semantically equivalent textual
paraphrases-crucial in real-world applications where users express the same
intent in varied ways-remain underexplored. To address this gap, we introduce a
novel adversarial paraphrasing task: generating grammatically correct
paraphrases that preserve the original query meaning while degrading
segmentation performance. To evaluate the quality of adversarial paraphrases,
we develop a comprehensive automatic evaluation protocol validated with human
studies. Furthermore, we introduce SPARTA-a black-box, sentence-level
optimization method that operates in the low-dimensional semantic latent space
of a text autoencoder, guided by reinforcement learning. SPARTA achieves
significantly higher success rates, outperforming prior methods by up to 2x on
both the ReasonSeg and LLMSeg-40k datasets. We use SPARTA and competitive
baselines to assess the robustness of advanced reasoning segmentation models.
We reveal that they remain vulnerable to adversarial paraphrasing-even under
strict semantic and grammatical constraints. All code and data will be released
publicly upon acceptance.

</details>


### [102] [Charting the European LLM Benchmarking Landscape: A New Taxonomy and a Set of Best Practices](https://arxiv.org/abs/2510.24450)
*Špela Vintar,Taja Kuzman Pungeršek,Mojca Brglez,Nikola Ljubešić*

Main category: cs.CL

TL;DR: 本研究综述了大型语言模型(LM)基准测试的最新进展，并提出了适用于多语言和非英语场景的基准分类新方法，旨在提高语言和文化敏感度。


<details>
  <summary>Details</summary>
Motivation: 近年来，随着大型语言模型(AI)能力的提升，非英语语言的评估和使用尚未得到充分研究，急需建立更适合的评估体系。

Method: 通过对现有大型语言模型基准测试的概述，提出新的基准分类法及最佳实践。

Result: 提出了新的基准分类和质量标准，以提高评估方法的语言和文化敏感度，为多语言场景提供支持。

Conclusion: 建立更高语言和文化敏感度的评估标准将有助于为欧洲语言的基准开发提供更协调的发展方向。

Abstract: While new benchmarks for large language models (LLMs) are being developed
continuously to catch up with the growing capabilities of new models and AI in
general, using and evaluating LLMs in non-English languages remains a
little-charted landscape. We give a concise overview of recent developments in
LLM benchmarking, and then propose a new taxonomy for the categorization of
benchmarks that is tailored to multilingual or non-English use scenarios. We
further propose a set of best practices and quality standards that could lead
to a more coordinated development of benchmarks for European languages. Among
other recommendations, we advocate for a higher language and culture
sensitivity of evaluation methods.

</details>


### [103] [Iterative Critique-Refine Framework for Enhancing LLM Personalization](https://arxiv.org/abs/2510.24469)
*Durga Prasad Maram,Dhruvin Gandhi,Zonghai Yao,Gayathri Akkinapalli,Franck Dernoncourt,Yu Wang,Ryan A. Rossi,Nesreen K. Ahmed*

Main category: cs.CL

TL;DR: PerFine是一种无训练的批评-精炼框架，通过迭代的反馈提升个性化文本生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法生成的文本往往在语气、主题或风格上偏离目标用户，需要更有效的个性化生成策略。

Method: 使用LLM生成器和批评LLM的反馈，结合新的淘汰策略，在每个迭代中改进文本。

Result: 在Yelp、Goodreads和亚马逊数据集上，PerFine相较于PGraphRAG在个性化上表现一致提升，GEval提高了7-13%。

Conclusion: PerFine展示了后期、以用户画像为基础的反馈在个性化生成中的强大潜力，且无需训练或特定模型。

Abstract: Personalized text generation requires models not only to produce coherent
text but also to align with a target user's style, tone, and topical focus.
Existing retrieval-augmented approaches such as LaMP and PGraphRAG enrich
profiles with user and neighbor histories, but they stop at generation and
often yield outputs that drift in tone, topic, or style. We present PerFine, a
unified, training-free critique-refine framework that enhances personalization
through iterative, profile-grounded feedback. In each iteration, an LLM
generator produces a draft conditioned on the retrieved profile, and a critic
LLM - also conditioned on the same profile - provides structured feedback on
tone, vocabulary, sentence structure, and topicality. The generator then
revises, while a novel knockout strategy retains the stronger draft across
iterations. We further study additional inference-time strategies such as
Best-of-N and Topic Extraction to balance quality and efficiency. Across Yelp,
Goodreads, and Amazon datasets, PerFine consistently improves personalization
over PGraphRAG, with GEval gains of +7-13%, steady improvements over 3-5
refinement iterations, and scalability with increasing critic size. These
results highlight that post-hoc, profile-aware feedback offers a powerful
paradigm for personalized LLM generation that is both training-free and
model-agnostic.

</details>


### [104] [Mitigating Hallucination in Large Language Models (LLMs): An Application-Oriented Survey on RAG, Reasoning, and Agentic Systems](https://arxiv.org/abs/2510.24476)
*Yihan Li,Xiyuan Fu,Ghanshyam Verma,Paul Buitelaar,Mingming Liu*

Main category: cs.CL

TL;DR: 本调查分析了检索增强生成和推理增强在减轻大型语言模型幻觉方面的结合潜力，提出了幻觉的分类法和统一框架。


<details>
  <summary>Details</summary>
Motivation: 幻觉问题是大型语言模型在真实应用中可靠部署的主要障碍，因此深入研究RAG和推理增强的结合方式以解决该问题具重要意义。

Method: 本研究采用应用导向的视角，结合真实世界的应用、评估和基准测试，系统分析RAG和推理增强在幻觉减轻中的作用。

Result: 本文调查了如何通过检索增强生成（RAG）和推理增强来减轻大型语言模型（LLMs）中的幻觉问题。我们提出了一种分类法，区分基于知识和基于逻辑的幻觉，并系统性地分析了RAG和推理增强如何应对每种类型。研究还呈现了一个统一框架，支持真实应用、评估和基准测试。

Conclusion: 通过对RAG和推理增强的系统分析，本文提出了幻觉减轻的有效策略和框架，为大型语言模型的更可靠应用提供了理论支持。

Abstract: Hallucination remains one of the key obstacles to the reliable deployment of
large language models (LLMs), particularly in real-world applications. Among
various mitigation strategies, Retrieval-Augmented Generation (RAG) and
reasoning enhancement have emerged as two of the most effective and widely
adopted approaches, marking a shift from merely suppressing hallucinations to
balancing creativity and reliability. However, their synergistic potential and
underlying mechanisms for hallucination mitigation have not yet been
systematically examined. This survey adopts an application-oriented perspective
of capability enhancement to analyze how RAG, reasoning enhancement, and their
integration in Agentic Systems mitigate hallucinations. We propose a taxonomy
distinguishing knowledge-based and logic-based hallucinations, systematically
examine how RAG and reasoning address each, and present a unified framework
supported by real-world applications, evaluations, and benchmarks.

</details>


### [105] [Talk2Ref: A Dataset for Reference Prediction from Scientific Talks](https://arxiv.org/abs/2510.24478)
*Frederik Broy,Maike Züfle,Jan Niehues*

Main category: cs.CL

TL;DR: 本研究提出了一个新的任务RPT，用于从科学演讲中自动识别相关文献，并推出了首个大规模数据集Talk2Ref，以支持这一研究。


<details>
  <summary>Details</summary>
Motivation: 科学演讲是研究传播的一个重要媒介，识别相关文献对研究人员和学生均有很大价值。

Method: 提出了一种双编码器架构，并在Talk2Ref上进行训练，同时探索了处理长转录本的策略和领域适应的训练方法。

Result: 验证了最先进的文本嵌入模型在零样本检索场景下的表现，并展示了微调数据集对引用预测性能的显著提升。

Conclusion: 通过微调Talk2Ref数据集显著改善了引用预测的表现，验证了该任务的挑战性以及数据集在学习口语科学内容语义表示方面的有效性。

Abstract: Scientific talks are a growing medium for disseminating research, and
automatically identifying relevant literature that grounds or enriches a talk
would be highly valuable for researchers and students alike. We introduce
Reference Prediction from Talks (RPT), a new task that maps long, and
unstructured scientific presentations to relevant papers. To support research
on RPT, we present Talk2Ref, the first large-scale dataset of its kind,
containing 6,279 talks and 43,429 cited papers (26 per talk on average), where
relevance is approximated by the papers cited in the talk's corresponding
source publication. We establish strong baselines by evaluating
state-of-the-art text embedding models in zero-shot retrieval scenarios, and
propose a dual-encoder architecture trained on Talk2Ref. We further explore
strategies for handling long transcripts, as well as training for domain
adaptation. Our results show that fine-tuning on Talk2Ref significantly
improves citation prediction performance, demonstrating both the challenges of
the task and the effectiveness of our dataset for learning semantic
representations from spoken scientific content. The dataset and trained models
are released under an open license to foster future research on integrating
spoken scientific communication into citation recommendation systems.

</details>


### [106] [CritiCal: Can Critique Help LLM Uncertainty or Confidence Calibration?](https://arxiv.org/abs/2510.24505)
*Qing Zong,Jiayu Liu,Tianshi Zheng,Chunyang Li,Baixuan Xu,Haochen Shi,Weiqi Wang,Zhaowei Wang,Chunkit Chan,Yangqiu Song*

Main category: cs.CL

TL;DR: 本研究提出自然语言批评的策略，通过关注不确定性和置信度，利用自我批评和批评校准训练，大幅提升了LLM在复杂推理任务中的置信度判断能力。


<details>
  <summary>Details</summary>
Motivation: 提高大语言模型（LLM）的置信度校准对于在高风险领域的安全使用至关重要，清晰的语言化置信度能够增强用户的信任感。

Method: 主要采用自我批评和创新的批评校准训练（CritiCal）方法，通过自然语言批评优化LLM的置信度。

Result: 提出了自然语言批评的解决方案，通过自我批评和批评校准训练方法，显著改善了置信度校准，超越了其他竞争基线和教师模型。

Conclusion: 自然语言批评显著增强了LLM的置信度校准能力，展现了在开放场景下的强大适应性，促进了LLM的可靠性。

Abstract: Accurate confidence calibration in Large Language Models (LLMs) is critical
for safe use in high-stakes domains, where clear verbalized confidence enhances
user trust. Traditional methods that mimic reference confidence expressions
often fail to capture the reasoning needed for accurate confidence assessment.
We propose natural language critiques as a solution, ideally suited for
confidence calibration, as precise gold confidence labels are hard to obtain
and often require multiple generations. This paper studies how natural language
critiques can enhance verbalized confidence, addressing: (1) What to critique:
uncertainty (question-focused) or confidence (answer-specific)? Analysis shows
confidence suits multiple-choice tasks, while uncertainty excels in open-ended
scenarios. (2) How to critique: self-critique or critique calibration training?
We propose Self-Critique, enabling LLMs to critique and optimize their
confidence beyond mere accuracy, and CritiCal, a novel Critique Calibration
training method that leverages natural language critiques to improve confidence
calibration, moving beyond direct numerical optimization. Experiments show that
CritiCal significantly outperforms Self-Critique and other competitive
baselines, even surpassing its teacher model, GPT-4o, in complex reasoning
tasks. CritiCal also shows robust generalization in out-of-distribution
settings, advancing LLM's reliability.

</details>


### [107] [Levée d'ambiguïtés par grammaires locales](https://arxiv.org/abs/2510.24530)
*Eric G. C. Laporte*

Main category: cs.CL

TL;DR: 本文探讨了如何通过上下文消解词性歧义，以实现零沉默率的词性标注方法，并在INTEX系统中进行了实现和测试。


<details>
  <summary>Details</summary>
Motivation: 词性消歧是自然语言处理中的重要挑战，影响多个应用场景，因此寻求减少或消除标注失误的目标。

Method: 通过调整局部语法和多重转导器的组合，以适应零沉默率目标来进行词性消歧。

Result: 提出了一种新的消歧方法，强调在局部语法和转导器交互中进行测试，避免孤立考虑带来的不准确性。

Conclusion: 实现零沉默率的词性标注需要仔细测试局部语法，并详细规定语法在文本处理中的应用。

Abstract: Many words are ambiguous in terms of their part of speech (POS). However,
when a word appears in a text, this ambiguity is generally much reduced.
Disambiguating POS involves using context to reduce the number of POS
associated with words, and is one of the main challenges of lexical tagging.
The problem of labeling words by POS frequently arises in natural language
processing, for example for spelling correction, grammar or style checking,
expression recognition, text-to-speech conversion, text corpus analysis, etc.
Lexical tagging systems are thus useful as an initial component of many natural
language processing systems. A number of recent lexical tagging systems produce
multiple solutions when the text is lexically ambiguous or the uniquely correct
solution cannot be found. These contributions aim to guarantee a zero silence
rate: the correct tag(s) for a word must never be discarded. This objective is
unrealistic for systems that tag each word uniquely. This article concerns a
lexical disambiguation method adapted to the objective of a zero silence rate
and implemented in Silberztein's INTEX system (1993). We present here a formal
description of this method. We show that to verify a local disambiguation
grammar in this framework, it is not sufficient to consider the transducer
paths separately: one needs to verify their interactions. Similarly, if a
combination of multiple transducers is used, the result cannot be predicted by
considering them in isolation. Furthermore, when examining the initial labeling
of a text as produced by INTEX, ideas for disambiguation rules come
spontaneously, but grammatical intuitions may turn out to be inaccurate, often
due to an unforeseen construction or ambiguity. If a zero silence rate is
targeted, local grammars must be carefully tested. This is where a detailed
specification of what a grammar will do once applied to texts would be
necessary.

</details>


### [108] [Dark & Stormy: Modeling Humor in the Worst Sentences Ever Written](https://arxiv.org/abs/2510.24538)
*Venkata S Govindarajan,Laura Biester*

Main category: cs.CL

TL;DR: 本研究分析了Bulwer-Lytton小说比赛中的糟糕幽默，发现现有幽默模型适用性差，并揭示了LLM生成内容的特征。


<details>
  <summary>Details</summary>
Motivation: 随着文本幽默的多样性和复杂性增加，计算研究需要考虑这些差异，尤其是故意的糟糕幽默。

Method: 我们策划并分析了一个新颖的文本语料库，通过对文学手法的分析来研究低质量幽默的特点。

Result: 研究发现，标准幽默检测模型在我们的语料库上表现不佳，且LLM在模仿比赛风格句子时过度使用某些文学手法，生成的新词组数量显著高于人类作家。

Conclusion: 本研究通过分析Bulwer-Lytton小说比赛的句子，揭示了英语中的“糟糕”幽默的独特特征，并指出现有幽默检测模型在此类句子上的表现不佳。

Abstract: Textual humor is enormously diverse and computational studies need to account
for this range, including intentionally bad humor. In this paper, we curate and
analyze a novel corpus of sentences from the Bulwer-Lytton Fiction Contest to
better understand "bad" humor in English. Standard humor detection models
perform poorly on our corpus, and an analysis of literary devices finds that
these sentences combine features common in existing humor datasets (e.g., puns,
irony) with metaphor, metafiction and simile. LLMs prompted to synthesize
contest-style sentences imitate the form but exaggerate the effect by
over-using certain literary devices, and including far more novel
adjective-noun bigrams than human writers. Data, code and analysis are
available at https://github.com/venkatasg/bulwer-lytton

</details>


### [109] [Open Korean Historical Corpus: A Millennia-Scale Diachronic Collection of Public Domain Texts](https://arxiv.org/abs/2510.24541)
*Seyoung Song,Nawon Kim,Songeun Chae,Kiwoong Park,Jiho Jin,Haneul Yoo,Kyunghyun Cho,Alice Oh*

Main category: cs.CL

TL;DR: 提出开放韩语历史语料库，以填补对韩语历史演变的研究空白，并进行语言变化的定量分析。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言处理领域对韩语历史演变研究的缺乏，尤其是书面与口语形式之间的差异及中文字符到韩文的转变

Method: 引入开放韩语历史语料库作为研究工具

Result: 构建了一个涵盖1300年的大型、公开许可的韩语历史语料库，包含1800万文件和50亿标记，分析了主要语言转变现象

Conclusion: 此语料库为定量历时语言分析提供了基础资源，并能为大型语言模型的预训练提供支持，提升对现代韩文及古老书写系统的理解。

Abstract: The history of the Korean language is characterized by a discrepancy between
its spoken and written forms and a pivotal shift from Chinese characters to the
Hangul alphabet. However, this linguistic evolution has remained largely
unexplored in NLP due to a lack of accessible historical corpora. To address
this gap, we introduce the Open Korean Historical Corpus, a large-scale, openly
licensed dataset spanning 1,300 years and 6 languages, as well as
under-represented writing systems like Korean-style Sinitic (Idu) and
Hanja-Hangul mixed script. This corpus contains 18 million documents and 5
billion tokens from 19 sources, ranging from the 7th century to 2025. We
leverage this resource to quantitatively analyze major linguistic shifts: (1)
Idu usage peaked in the 1860s before declining sharply; (2) the transition from
Hanja to Hangul was a rapid transformation starting around 1890; and (3) North
Korea's lexical divergence causes modern tokenizers to produce up to 51 times
higher out-of-vocabulary rates. This work provides a foundational resource for
quantitative diachronic analysis by capturing the history of the Korean
language. Moreover, it can serve as a pre-training corpus for large language
models, potentially improving their understanding of Sino-Korean vocabulary in
modern Hangul as well as archaic writing systems.

</details>


### [110] [BEST-RQ-Based Self-Supervised Learning for Whisper Domain Adaptation](https://arxiv.org/abs/2510.24570)
*Raphaël Bagat,Irina Illina,Emmanuel Vincent*

Main category: cs.CL

TL;DR: 本研究提出的BEARD框架通过未标记数据提高Whisper编码器在低资源和领域外场景中的适应性，取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决自动语音识别系统在缺乏标记数据的领域外和低资源场景中的挑战。

Method: 采用未标记数据适应编码器，结合BEST-RQ目标与知识蒸馏，进行模型培训和微调。

Result: 提出了一种新的框架BEARD，通过未标记数据来适应Whisper的编码器，从而提高在低资源和领域外场景中的自动语音识别性能。BEARD独特地结合了BEST-RQ目标和从冻结教师编码器的知识蒸馏，确保了编码器与预训练解码器的互补性。实验结果表明，在具有挑战性的空中交通管制通信领域的ATCO2语料库上，BEARD在使用约5000小时未标记语音和2小时标记语音进行微调的情况下，相较于前一个基线模型和微调模型，提升达12%。

Conclusion: BEARD在低资源领域的自动语音识别中表现出色，首次实现了针对Whisper的自监督学习目标的领域适应。

Abstract: Automatic Speech Recognition (ASR) systems, despite large multilingual
training, struggle in out-of-domain and low-resource scenarios where labeled
data is scarce. We propose BEARD (BEST-RQ Encoder Adaptation with Re-training
and Distillation), a novel framework designed to adapt Whisper's encoder using
unlabeled data. Unlike traditional self-supervised learning methods, BEARD
uniquely combines a BEST-RQ objective with knowledge distillation from a frozen
teacher encoder, ensuring the encoder's complementarity with the pre-trained
decoder. Our experiments focus on the ATCO2 corpus from the challenging Air
Traffic Control (ATC) communications domain, characterized by non-native
speech, noise, and specialized phraseology. Using about 5,000 hours of
untranscribed speech for BEARD and 2 hours of transcribed speech for
fine-tuning, the proposed approach significantly outperforms previous baseline
and fine-tuned model, achieving a relative improvement of 12% compared to the
fine-tuned model. To the best of our knowledge, this is the first work to use a
self-supervised learning objective for domain adaptation of Whisper.

</details>


### [111] [ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization](https://arxiv.org/abs/2510.24592)
*Guoxin Chen,Jing Wu,Xinjie Chen,Wayne Xin Zhao,Ruihua Song,Chengxi Li,Kai Fan,Dayiheng Liu,Minpeng Liao*

Main category: cs.CL

TL;DR: ReForm是一种反思式自动形式化方法，通过语义一致性评估改进传统模型的表现。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在自然语言数学向机器可验证形式陈述翻译中的语义意图保持不足。

Method: Reflective Autoformalization (ReForm)

Result: 通过结合语义一致性评估，ReForm在四个基准测试中性能优越，平均提升17.2个百分点。

Conclusion: 引入ConsistencyCheck基准，表明自动形式化难度高，即便是人类专家也存在显著的语义错误。

Abstract: Autoformalization, which translates natural language mathematics into
machine-verifiable formal statements, is critical for using formal mathematical
reasoning to solve math problems stated in natural language. While Large
Language Models can generate syntactically correct formal statements, they
often fail to preserve the original problem's semantic intent. This limitation
arises from the LLM approaches' treating autoformalization as a simplistic
translation task which lacks mechanisms for self-reflection and iterative
refinement that human experts naturally employ. To address these issues, we
propose ReForm, a Reflective Autoformalization method that tightly integrates
semantic consistency evaluation into the autoformalization process. This
enables the model to iteratively generate formal statements, assess its
semantic fidelity, and self-correct identified errors through progressive
refinement. To effectively train this reflective model, we introduce
Prospective Bounded Sequence Optimization (PBSO), which employs different
rewards at different sequence positions to ensure that the model develops both
accurate autoformalization and correct semantic validations, preventing
superficial critiques that would undermine the purpose of reflection. Extensive
experiments across four autoformalization benchmarks demonstrate that ReForm
achieves an average improvement of 17.2 percentage points over the strongest
baselines. To further ensure evaluation reliability, we introduce
ConsistencyCheck, a benchmark of 859 expert-annotated items that not only
validates LLMs as judges but also reveals that autoformalization is inherently
difficult: even human experts produce semantic errors in up to 38.5% of cases.

</details>


### [112] [Diffusion LLM with Native Variable Generation Lengths: Let [EOS] Lead the Way](https://arxiv.org/abs/2510.24605)
*Yicun Yang,Cong Wang,Shaobo Wang,Zichen Wen,Biqing Qi,Hanlin Xu,Linfeng Zhang*

Main category: cs.CL

TL;DR: 通过训练具备可变生成长度的扩散LLM，本文显著提升了生成效率和准确性，拓展了扩散LLM的实际应用前景。


<details>
  <summary>Details</summary>
Motivation: 为了克服当前扩散LLM在生成长度上的固定限制，提高生成效率和灵活性。

Method: 训练具有本地变量生成长度的扩散LLM，旨在准确预测生成文本中的[EOS]标记。

Result: 在标准基准测试中，方法实现了传统扩散LLM推理的30.1倍加速，相较于自回归模型如Qwen和Llama也有2.4倍的加速，准确性更高。

Conclusion: 本研究提出的dLLM-Var在生成效率和灵活性方面表现优越，适合实际应用。

Abstract: Diffusion-based large language models (dLLMs) have exhibited substantial
potential for parallel text generation, which may enable more efficient
generation compared to autoregressive models. However, current dLLMs suffer
from fixed generation lengths, which indicates the generation lengths of dLLMs
have to be determined before decoding as a hyper-parameter, leading to issues
in efficiency and flexibility. To solve these problems, in this work, we
propose to train a diffusion LLM with native variable generation lengths,
abbreviated as dLLM-Var. Concretely, we aim to train a model to accurately
predict the [EOS] token in the generated text, which makes a dLLM be able to
natively infer in a block diffusion manner, while still maintaining the ability
of global bi-directional (full) attention and high parallelism. Experiments on
standard benchmarks demonstrate that our method achieves a 30.1x speedup over
traditional dLLM inference paradigms and a 2.4x speedup relative to
autoregressive models such as Qwen and Llama. Our method achieves higher
accuracy and faster inference, elevating dLLMs beyond mere academic novelty and
supporting their practical use in real-world applications. Codes and models
have been released.

</details>


### [113] [Long-Context Modeling with Dynamic Hierarchical Sparse Attention for On-Device LLMs](https://arxiv.org/abs/2510.24606)
*Siheng Xiong,Joe Zou,Faramarz Fekri,Yae Jee Cho*

Main category: cs.CL

TL;DR: DHSA提供了一种高效的动态稀疏注意力机制，在保持精度的同时显著降低了计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在长上下文建模中的静态性及依赖预定义模板的问题，提升灵活性和准确性。

Method: 提出了一种数据驱动框架，动态预测注意力稀疏性，通过分段序列并计算块表示来改进注意力机制。

Result: DHSA匹配了密集注意力的准确性，同时减少了20-60%的预填充延迟和35%的峰值内存使用。

Conclusion: DHSA在精度和效率上均优于现有长上下文模型，提供了一种高效且可适应的解决方案。

Abstract: The quadratic cost of attention hinders the scalability of long-context LLMs,
especially in resource-constrained settings. Existing static sparse methods
such as sliding windows or global tokens utilizes the sparsity of attention to
reduce the cost of attention, but poorly adapts to the content-dependent
variations in attention due to their staticity. While previous work has
proposed several dynamic approaches to improve flexibility, they still depend
on predefined templates or heuristic mechanisms. Such strategies reduce
generality and prune tokens that remain contextually important, limiting their
accuracy across diverse tasks. To tackle these bottlenecks of existing methods
for long-context modeling, we introduce Dynamic Hierarchical Sparse Attention
(DHSA), a data-driven framework that dynamically predicts attention sparsity
online without retraining. Our proposed DHSA adaptively segments sequences into
variable-length chunks, then computes chunk representations by aggregating the
token embeddings within each chunk. To avoid the bias introduced by varying
chunk lengths, we apply length-normalized aggregation that scales the averaged
embeddings by the square root of the chunk size. Finally, DHSA upsamples the
chunk-level similarity scores to token level similarities to calculate
importance scores that determine which token-level interactions should be
preserved. Our experiments on Gemma2 with Needle-in-a-Haystack Test and
LongBench show that DHSA matches dense attention in accuracy, while reducing
prefill latency by 20-60% and peak memory usage by 35%. Compared to other
representative baselines such as block sparse attention, DHSA achieves
consistently higher accuracy (6-18% relative gains) with comparable or lower
cost, offering an efficient and adaptable solution for long-context on-device
LLMs.

</details>


### [114] [Zero-Shot Cross-Lingual Transfer using Prefix-Based Adaptation](https://arxiv.org/abs/2510.24619)
*Snegha A,Sayambhu Sen,Piyush Singh Pasi,Abhishek Singhania,Preethi Jyothi*

Main category: cs.CL

TL;DR: 本研究探讨了三种针对零-shot跨语言转移的前缀方法，显示其在多语言设置下优于传统的LoRA技术。


<details>
  <summary>Details</summary>
Motivation: 探索如何在解码器模型中有效应用基于前缀的技术，尤其是在低资源语言的任务中

Method: 研究三种基于前缀的方法进行零-shot跨语言转移

Result: 在Belebele基准上，基于前缀的方法优于LoRA基线，改进幅度最大可达6%。在Mistral v0.3 7B上也观察到类似的改进。

Conclusion: 基于前缀的技术在低资源多语言环境中展现出良好的效果，提供了LoRA的有效替代方案。

Abstract: With the release of new large language models (LLMs) like Llama and Mistral,
zero-shot cross-lingual transfer has become increasingly feasible due to their
multilingual pretraining and strong generalization capabilities. However,
adapting these decoder-only LLMs to new tasks across languages remains
challenging. While parameter-efficient fine-tuning (PeFT) techniques like
Low-Rank Adaptation (LoRA) are widely used, prefix-based techniques such as
soft prompt tuning, prefix tuning, and Llama Adapter are less explored,
especially for zero-shot transfer in decoder-only models. We present a
comprehensive study of three prefix-based methods for zero-shot cross-lingual
transfer from English to 35+ high- and low-resource languages. Our analysis
further explores transfer across linguistic families and scripts, as well as
the impact of scaling model sizes from 1B to 24B. With Llama 3.1 8B, prefix
methods outperform LoRA-baselines by up to 6% on the Belebele benchmark.
Similar improvements were observed with Mistral v0.3 7B as well. Despite using
only 1.23M learning parameters with prefix tuning, we achieve consistent
improvements across diverse benchmarks. These findings highlight the potential
of prefix-based techniques as an effective and scalable alternative to LoRA,
particularly in low-resource multilingual settings.

</details>


### [115] [Relative Scaling Laws for LLMs](https://arxiv.org/abs/2510.24626)
*William Held,David Hall,Percy Liang,Diyi Yang*

Main category: cs.CL

TL;DR: 相对缩放法则揭示了语言模型在不同领域和群体间的性能差异，强调缩放并非普遍平等的能力提升。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在不同数据、参数和计算资源下的表现差异，特别关注如何更好地理解性能差距。

Method: 使用255个仅解码的Transformer模型，在匹配的计算预算下进行训练，分析标准预训练数据集上的性能表现。

Result: 提出了相对缩放法则，能够跟踪测试分布之间的性能差距如何随着模型规模而演变。

Conclusion: 虽然模型缩放提高了整体性能，但并不一定能弥补不同子群体之间的性能差异。

Abstract: Scaling laws describe how language models improve with additional data,
parameters, and compute. While widely used, they are typically measured on
aggregate test sets. Aggregate evaluations yield clean trends but average over
heterogeneous subpopulations, obscuring performance disparities. We introduce
relative scaling laws, which track how performance gaps between test
distributions evolve with scale rather than focusing solely on absolute error.
Using 255 decoder-only Transformers trained under matched-compute (IsoFLOP)
budgets from $10^{18}$--$10^{20}$ FLOPs on standard pretraining datasets, we
find diverse trajectories: academic domains on MMLU converge toward parity;
regional English dialects shift depending on population size; and clusters of
AI risk behaviours split, with capability- and influence-related risks
increasing during pretraining while adversarial risks do not. These results
show that although scaling improves overall performance, it is not a universal
equalizer. To support further study, we release all model checkpoints from this
work to enable practitioners to measure relative alongside traditional scaling
laws, in order to better prioritize robustness challenges in light of the
bitter lesson.

</details>


### [116] [OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement Learning](https://arxiv.org/abs/2510.24636)
*Ziyou Hu,Zhengliang Shi,Minghang Zhu,Haitao Li,Teng Sun,Pengjie Ren,Suzan Verberne,Zhaochun Ren*

Main category: cs.CL

TL;DR: 提出OpenRM，一种工具增强的长形式奖励模型，通过外部工具评估开放式响应，改善了现有奖励模型在知识密集和长文本任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的奖励模型在知识密集和长文任务中表现不佳，需要利用外部证据来评价响应的正确性。

Method: 使用群体相对策略优化（GRPO）训练OpenRM，并在27K对生成的合成例子上进行监督，以优化工具使用和结果准确性。

Result: 在新收集的数据集和常用基准上，OpenRM的表现显著优于现有的方法，并在推理和训练阶段均取得一致的提升。

Conclusion: 实验表明，OpenRM在长期评估中显著优于传统奖励模型，并有效提升了下游任务的对齐性能。

Abstract: Reward models (RMs) have become essential for aligning large language models
(LLMs), serving as scalable proxies for human evaluation in both training and
inference. However, existing RMs struggle on knowledge-intensive and long-form
tasks, where evaluating correctness requires grounding beyond the model's
internal knowledge. This limitation hinders them from reliably discriminating
subtle quality differences, especially when external evidence is necessary. To
address this, we introduce OpenRM, a tool-augmented long-form reward model that
systematically judges open-ended responses by invoking external tools to gather
relevant evidence. We train OpenRM with Group Relative Policy Optimization
(GRPO) on over 27K synthesized pairwise examples generated through a
controllable data synthesis framework. The training objective jointly
supervises intermediate tool usage and final outcome accuracy, incentivizing
our reward model to learn effective evidence-based judgment strategies.
Extensive experiments on three newly-collected datasets and two widely-used
benchmarks demonstrate that OpenRM substantially outperforms existing reward
modeling approaches. As a further step, we integrate OpenRM into both
inference-time response selection and training-time data selection. This yields
consistent gains in downstream LLM alignment tasks, highlighting the potential
of tool-augmented reward models for scaling reliable long-form evaluation.

</details>


### [117] [Quantifying the Effects of Word Length, Frequency, and Predictability on Dyslexia](https://arxiv.org/abs/2510.24647)
*Hugo Rydel-Johnston,Alex Kafkas*

Main category: cs.CL

TL;DR: 该研究分析了在不同条件下，阅读障碍者的阅读时间成本，并探讨了与词汇特征（长度、频率、可预测性）相关的影响。


<details>
  <summary>Details</summary>
Motivation: 了解阅读障碍者在自然阅读中面临的具体挑战，以优化干预措施并推进相关理论研究。

Method: 通过眼动追踪技术，结合自然阅读数据集，分析词汇特征对阅读时间的影响。

Result: 所有三种词汇特征均显著改变了阅读时间，其中可预测性对阅读障碍者的影响最为显著，总体上缩小了阅读障碍者与控制组之间的差距。

Conclusion: 阅读障碍者在阅读时对词汇特征的敏感性更强，特别是对可预测性，有助于理解阅读障碍的机制，并为干预方式提供指导。

Abstract: We ask where, and under what conditions, dyslexic reading costs arise in a
large-scale naturalistic reading dataset. Using eye-tracking aligned to
word-level features (word length, frequency, and predictability), we model how
each feature influences dyslexic time costs. We find that all three features
robustly change reading times in both typical and dyslexic readers, and that
dyslexic readers show stronger sensitivities to each, especially
predictability. Counterfactual manipulations of these features substantially
narrow the dyslexic-control gap by about one third, with predictability showing
the strongest effect, followed by length and frequency. These patterns align
with dyslexia theories that posit heightened demands on linguistic working
memory and phonological encoding, and they motivate further work on lexical
complexity and parafoveal preview benefits to explain the remaining gap. In
short, we quantify when extra dyslexic costs arise, how large they are, and
offer actionable guidance for interventions and computational models for
dyslexics.

</details>


### [118] [Optimizing Retrieval for RAG via Reinforced Contrastive Learning](https://arxiv.org/abs/2510.24652)
*Jiawei Zhou,Lei Chen*

Main category: cs.CL

TL;DR: 本研究提出R3框架，以优化检索增强生成过程，通过动态探索相关性实现自我改进，并在多项任务中实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着检索增强生成（RAG）技术的广泛应用，信息检索（IR）的角色正从为人类用户检索信息转变为为人工智能系统检索上下文知识。这一转变带来了相关性定义和注释的困难，因此需要一种新的解决方案。

Method: R3利用动态探索和对比信号，通过强化学习方法优化检索过程，避免依赖标注或合成数据，提升了检索的相关性定义和优化。

Result: 提出了R3框架，通过 trial-and-feedback 强化对比学习优化RAG的检索过程，并在多项任务中提升了RAG的性能。

Conclusion: R3在效率和实践中表现出色，仅需4个GPU即可在一天内完成训练，显著提高了RAG性能。

Abstract: As retrieval-augmented generation (RAG) becomes increasingly widespread, the
role of information retrieval (IR) is shifting from retrieving information for
human users to retrieving contextual knowledge for artificial intelligence (AI)
systems, where relevance becomes difficult to define or annotate beforehand. To
address this challenge, we propose R3, a Retrieval framework optimized for RAG
through trialand-feedback Reinforced contrastive learning. Unlike prior
approaches that rely on annotated or synthetic data for supervised fine-tuning,
R3 enables the retriever to dynamically explore and optimize relevance within
the RAG environment. During training, the retrieved results interact with the
environment to produce contrastive signals that automatically guide the
retriever's self-improvement. Extensive experiments across diverse tasks
demonstrate that R3 improves RAG performance by 5.2% over the original
retriever and surpasses state-of-the-art retrievers by 4.9%, while achieving
comparable results to LLM-augmented retrieval and RAG systems built on
post-trained or instruction-tuned LLMs. It is both efficient and practical,
requiring only 4 GPUs and completing training within a single day.

</details>


### [119] [MQM Re-Annotation: A Technique for Collaborative Evaluation of Machine Translation](https://arxiv.org/abs/2510.24664)
*Parker Riley,Daniel Deutsch,Mara Finkelstein,Colten DiIanni,Juraj Juraska,Markus Freitag*

Main category: cs.CL

TL;DR: 二次注释提升机器翻译质量评估的准确性，找出并纠正遗漏错误。


<details>
  <summary>Details</summary>
Motivation: 提高机器翻译评估方法，以适应翻译模型质量的提升，减少评估中的噪音影响。

Method: 实验采用二阶段的MQM重新注释方法，评审和编辑已有的MQM注释。

Result: 通过二次注释，评估结果质量提高，发现了首次注释中未识别的错误。

Conclusion: 二次注释可以提高机器翻译质量评估的准确性，发现并纠正首次注释中遗漏的错误。

Abstract: Human evaluation of machine translation is in an arms race with translation
model quality: as our models get better, our evaluation methods need to be
improved to ensure that quality gains are not lost in evaluation noise. To this
end, we experiment with a two-stage version of the current state-of-the-art
translation evaluation paradigm (MQM), which we call MQM re-annotation. In this
setup, an MQM annotator reviews and edits a set of pre-existing MQM
annotations, that may have come from themselves, another human annotator, or an
automatic MQM annotation system. We demonstrate that rater behavior in
re-annotation aligns with our goals, and that re-annotation results in
higher-quality annotations, mostly due to finding errors that were missed
during the first pass.

</details>


### [120] [Dissecting Role Cognition in Medical LLMs via Neuronal Ablation](https://arxiv.org/abs/2510.24677)
*Xun Liang,Huayi Lai,Hanyu Wang,Wentao Zhang,Linfeng Zhang,Yanfang Chen,Feiyu Xiong,Zhiyu Li*

Main category: cs.CL

TL;DR: 角色提示对大型语言模型的医学推理能力影响有限，主要改变表层语言特征，未见明显推理路径的区分。


<details>
  <summary>Details</summary>
Motivation: 探讨角色提示如何影响大型语言模型的医疗推理能力，以评估现有的Prompt-Based Role Playing (PBRP)方法的有效性。

Method: 本文采用神经元消融和表示分析技术，测试RPNA框架在三个医疗QA数据集上的应用。

Result: 本文研究大型语言模型在医学决策支持系统中的角色扮演提示对其推理能力的影响。通过RP-Neuron-Activated Evaluation Framework（RPNA）对模型推理路径进行评估，发现角色提示未能显著提升模型的医学推理能力，主要影响表层语言特征，而非推理路径的深层次差异。

Conclusion: 当前的角色扮演方法无法有效复制真实医学实践中的认知复杂性，强调了需要模拟真实认知过程的模型。

Abstract: Large language models (LLMs) have gained significant traction in medical
decision support systems, particularly in the
  context of medical question answering and role-playing simulations. A common
practice, Prompt-Based Role Playing (PBRP),
  instructs models to adopt different clinical roles (e.g., medical students,
residents, attending physicians) to simulate varied
  professional behaviors. However, the impact of such role prompts on model
reasoning capabilities remains unclear. This
  study introduces the RP-Neuron-Activated Evaluation Framework(RPNA) to
evaluate whether role prompts induce distinct,
  role-specific cognitive processes in LLMs or merely modify linguistic style.
We test this framework on three medical QA
  datasets, employing neuron ablation and representation analysis techniques to
assess changes in reasoning pathways. Our
  results demonstrate that role prompts do not significantly enhance the
medical reasoning abilities of LLMs. Instead, they
  primarily affect surface-level linguistic features, with no evidence of
distinct reasoning pathways or cognitive differentiation
  across clinical roles. Despite superficial stylistic changes, the core
decision-making mechanisms of LLMs remain uniform
  across roles, indicating that current PBRP methods fail to replicate the
cognitive complexity found in real-world medical
  practice. This highlights the limitations of role-playing in medical AI and
emphasizes the need for models that simulate genuine
  cognitive processes rather than linguistic imitation.We have released the
related code in the following repository:https:
  //github.com/IAAR-Shanghai/RolePlay_LLMDoctor

</details>


### [121] [SPICE: Self-Play In Corpus Environments Improves Reasoning](https://arxiv.org/abs/2510.24684)
*Bo Liu,Chuanyang Jin,Seungone Kim,Weizhe Yuan,Wenting Zhao,Ilia Kulikov,Xian Li,Sainbayar Sukhbaatar,Jack Lanchantin,Jason Weston*

Main category: cs.CL

TL;DR: SPICE是一种通过对抗动态自动生成挑战性任务的强化学习框架，在自我提升中取得显著成果。


<details>
  <summary>Details</summary>
Motivation: 研究自我提升系统如何通过环境互动实现持续适应。

Method: SPICE框架中，模型同时扮演挑战者和推理者两个角色，通过对抗动态与文档基础相结合，生成多样化的推理任务并解决。

Result: SPICE在多个模型系列上在数学和一般推理基准测试上实现了一致的提升，分别达到+8.9%和+9.8%。

Conclusion: 文档基础是SPICE的关键成分，使其能够不断生成具有挑战性的目标并实现持续的自我提升。

Abstract: Self-improving systems require environmental interaction for continuous
adaptation. We introduce SPICE (Self-Play In Corpus Environments), a
reinforcement learning framework where a single model acts in two roles: a
Challenger that mines documents from a large corpus to generate diverse
reasoning tasks, and a Reasoner that solves them. Through adversarial dynamics,
the Challenger creates an automatic curriculum at the frontier of the
Reasoner's capability, while corpus grounding provides the rich,
near-inexhaustible external signal necessary for sustained improvement. Unlike
existing ungrounded self-play methods that offer more limited benefits, SPICE
achieves consistent gains across mathematical (+8.9%) and general reasoning
(+9.8%) benchmarks on multiple model families. Our analysis reveals how
document grounding is a key ingredient in SPICE to continuously generate its
own increasingly challenging goals and achieve them, enabling sustained
self-improvement.

</details>


### [122] [MetricX-25 and GemSpanEval: Google Translate Submissions to the WMT25 Evaluation Shared Task](https://arxiv.org/abs/2510.24707)
*Juraj Juraska,Tobias Domhan,Mara Finkelstein,Tetsuji Nakagawa,Geza Kovacs,Daniel Deutsch,Pidong Wang,Markus Freitag*

Main category: cs.CL

TL;DR: 本文展示了针对WMT25翻译评估共享任务的提交，通过改进输入格式和训练协议开发了新的MetricX，并推出了新的错误范围检测模型GemSpanEval，以预测错误范围及其严重性和类别。这两个系统都基于先进的Gemma 3多语言模型，经过公开WMT数据的微调。


<details>
  <summary>Details</summary>
Motivation: 提升翻译质量评估任务的效果，尤其是在质量评分预测和错误范围检测上。

Method: 开发了新一代MetricX和GemSpanEval模型，前者适应了Gemma 3编码器架构，后者则是解码器模型，均经过训练以满足各自任务。

Result: MetricX-25有效地预测了MQM和ESA质量评分，而GemSpanEval在错误范围检测方面表现出竞争力。

Conclusion: 我们的MetricX-25模型在MQM和ESA质量评分预测上显著优于前作，而GemSpanEval模型在错误范围检测方面则与xCOMET竞争。

Abstract: In this paper, we present our submissions to the unified WMT25 Translation
Evaluation Shared Task. For the Quality Score Prediction subtask, we create a
new generation of MetricX with improvements in the input format and the
training protocol, while for the Error Span Detection subtask we develop a new
model, GemSpanEval, trained to predict error spans along with their severities
and categories. Both systems are based on the state-of-the-art multilingual
open-weights model Gemma 3, fine-tuned on publicly available WMT data. We
demonstrate that MetricX-25, adapting Gemma 3 to an encoder-only architecture
with a regression head on top, can be trained to effectively predict both MQM
and ESA quality scores, and significantly outperforms its predecessor. Our
decoder-only GemSpanEval model, on the other hand, we show to be competitive in
error span detection with xCOMET, a strong encoder-only sequence-tagging
baseline. With error span detection formulated as a generative task, we
instruct the model to also output the context for each predicted error span,
thus ensuring that error spans are identified unambiguously.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [123] [Speeding Up MACE: Low-Precision Tricks for Equivarient Force Fields](https://arxiv.org/abs/2510.23621)
*Alexandre Benoit*

Main category: cs.LG

TL;DR: 该论文探讨如何在不损害物理精度的情况下，通过低精度运算和GPU优化来提高MACE模型的效率，结果表明可以显著加快其计算速度。


<details>
  <summary>Details</summary>
Motivation: 旨在降低机器学习力场MACE的计算成本，提高速度，而不损害物理精度。

Method: 通过对MACE模型进行端到端和逐块的性能分析，比较不同后端（e3nn和NVIDIA cuEquivariance）以及不同精度设置 (FP64/FP32/BF16/FP16)。

Result: 结果显示，采用cuEquivariance可将推理延迟减少约3倍，对线性层使用低精度运算可进一步提高约4倍的速度，同时在NVT/NPT分子动力学模拟中保持能量和热力学可观测量的稳定。

Conclusion: 使用cuEquivariance和FP32默认设置，并在需要时对线性层启用BF16/FP16，有助于在训练中保持精度的同时提高计算效率。

Abstract: Machine-learning force fields can deliver accurate molecular dynamics (MD) at
high computational cost. For SO(3)-equivariant models such as MACE, there is
little systematic evidence on whether reduced-precision arithmetic and
GPU-optimized kernels can cut this cost without harming physical fidelity. This
thesis aims to make MACE cheaper and faster while preserving accuracy by
identifying computational bottlenecks and evaluating low-precision execution
policies. We profile MACE end-to-end and per block, compare the e3nn and NVIDIA
cuEquivariance backends, and assess FP64/FP32/BF16/FP16 settings (with FP32
accumulation) for inference, short NVT and long NPT water simulations, and toy
training runs under reproducible, steady-state timing. cuEquivariance reduces
inference latency by about $3\times$. Casting only linear layers to BF16/FP16
within an FP32 model yields roughly 4x additional speedups, while energies and
thermodynamic observables in NVT/NPT MD remain within run-to-run variability.
Half-precision weights during training degrade force RMSE. Mixing e3nn and cuEq
modules without explicit adapters causes representation mismatches. Fused
equivariant kernels and mixed-precision inference can substantially accelerate
state-of-the-art force fields with negligible impact on downstream MD. A
practical policy is to use cuEquivariance with FP32 by default and enable
BF16/FP16 for linear layers (keeping FP32 accumulations) for maximum
throughput, while training remains in FP32. Further gains are expected on
Ampere/Hopper GPUs (TF32/BF16) and from kernel-level FP16/BF16 paths and
pipeline fusion.

</details>


### [124] [Adversarially-Aware Architecture Design for Robust Medical AI Systems](https://arxiv.org/abs/2510.23622)
*Alyssa Gerhart,Balaji Iyangar*

Main category: cs.LG

TL;DR: 对抗性攻击对医疗AI系统造成重大风险，研究表明防御措施虽有成效，但需平衡模型性能与安全性。


<details>
  <summary>Details</summary>
Motivation: 探索医疗AI系统中的脆弱性，旨在保护患者安全，特别是服务不足人群的患者。

Method: 通过对皮肤病数据集的实证实验，对对抗性攻击进行详细的威胁建模、实验基准测试和模型评估。

Result: 本研究揭示了对健康护理中AI系统的对抗性攻击造成的严重风险，尤其是在临床诊断中的影响，强调了保护患者安全的必要性。

Conclusion: 呼吁集成技术、伦理和政策方法，构建更具韧性和公平的医疗AI系统。

Abstract: Adversarial attacks pose a severe risk to AI systems used in healthcare,
capable of misleading models into dangerous misclassifications that can delay
treatments or cause misdiagnoses. These attacks, often imperceptible to human
perception, threaten patient safety, particularly in underserved populations.
Our study explores these vulnerabilities through empirical experimentation on a
dermatological dataset, where adversarial methods significantly reduce
classification accuracy. Through detailed threat modeling, experimental
benchmarking, and model evaluation, we demonstrate both the severity of the
threat and the partial success of defenses like adversarial training and
distillation. Our results show that while defenses reduce attack success rates,
they must be balanced against model performance on clean data. We conclude with
a call for integrated technical, ethical, and policy-based approaches to build
more resilient, equitable AI in healthcare.

</details>


### [125] [DiNo and RanBu: Lightweight Predictions from Shallow Random Forests](https://arxiv.org/abs/2510.23624)
*Tiago Mendonça dos Santos,Rafael Izbicki,Luís Gustavo Esteves*

Main category: cs.LG

TL;DR: 本研究提出了两种新方法DiNo和RanBu，以提高随机森林的效率，同时保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决随机森林在高延迟和资源受限环境下的应用问题。

Method: 提出了两种浅层森林方法DiNo和RanBu，旨在提高随机森林的推理效率。

Result: RanBu在高噪声场景中与全深度随机森林的准确性相当或更高，同时训练和推理时间减少了最多95%；DiNo在低噪声环境中实现了最佳的偏差-方差权衡。

Conclusion: 这两种方法提供了有效的解决方案，适用于时间和资源敏感的预测任务，并可扩展至分位数回归。

Abstract: Random Forest ensembles are a strong baseline for tabular prediction tasks,
but their reliance on hundreds of deep trees often results in high inference
latency and memory demands, limiting deployment in latency-sensitive or
resource-constrained environments. We introduce DiNo (Distance with Nodes) and
RanBu (Random Bushes), two shallow-forest methods that convert a small set of
depth-limited trees into efficient, distance-weighted predictors. DiNo measures
cophenetic distances via the most recent common ancestor of observation pairs,
while RanBu applies kernel smoothing to Breiman's classical proximity measure.
Both approaches operate entirely after forest training: no additional trees are
grown, and tuning of the single bandwidth parameter $h$ requires only
lightweight matrix-vector operations. Across three synthetic benchmarks and 25
public datasets, RanBu matches or exceeds the accuracy of full-depth random
forests-particularly in high-noise settings-while reducing training plus
inference time by up to 95\%. DiNo achieves the best bias-variance trade-off in
low-noise regimes at a modest computational cost. Both methods extend directly
to quantile regression, maintaining accuracy with substantial speed gains. The
implementation is available as an open-source R/C++ package at
https://github.com/tiagomendonca/dirf. We focus on structured tabular random
samples (i.i.d.), leaving extensions to other modalities for future work.

</details>


### [126] [Local Performance vs. Out-of-Distribution Generalization: An Empirical Analysis of Personalized Federated Learning in Heterogeneous Data Environments](https://arxiv.org/abs/2510.24503)
*Mortesa Hussaini,Jan Theiß,Anthony Stein*

Main category: cs.LG

TL;DR: 本研究针对异构数据环境下的联邦学习问题，提出FLIU方法并进行全面评估。


<details>
  <summary>Details</summary>
Motivation: 在异构数据环境下进行联邦学习时，本地模型在本地训练步骤中趋向于各自的局部最优，导致与全局数据分布的偏离。

Method: 对不同阶段的通信轮次进行细致分析，并使用MNIST和CIFAR-10进行实证比较，考察不同算法在复杂数据异构性下的表现。

Result: 提出了一种名为FLIU的改进FedAvg方法，增强个性化更新，并在各类分布条件下进行了实证评估。

Conclusion: 通过在不同分布条件下的评估，证明FLIU方法在保持本地性能的同时显著改善了模型的泛化能力。

Abstract: In the context of Federated Learning with heterogeneous data environments,
local models tend to converge to their own local model optima during local
training steps, deviating from the overall data distributions. Aggregation of
these local updates, e.g., with FedAvg, often does not align with the global
model optimum (client drift), resulting in an update that is suboptimal for
most clients. Personalized Federated Learning approaches address this challenge
by exclusively focusing on the average local performances of clients' models on
their own data distribution. Generalization to out-of-distribution samples,
which is a substantial benefit of FedAvg and represents a significant component
of robustness, appears to be inadequately incorporated into the assessment and
evaluation processes. This study involves a thorough evaluation of Federated
Learning approaches, encompassing both their local performance and their
generalization capabilities. Therefore, we examine different stages within a
single communication round to enable a more nuanced understanding of the
considered metrics. Furthermore, we propose and incorporate a modified approach
of FedAvg, designated as Federated Learning with Individualized Updates (FLIU),
extending the algorithm by a straightforward individualization step with an
adaptive personalization factor. We evaluate and compare the approaches
empirically using MNIST and CIFAR-10 under various distributional conditions,
including benchmark IID and pathological non-IID, as well as additional novel
test environments with Dirichlet distribution specifically developed to stress
the algorithms on complex data heterogeneity.

</details>


### [127] [From Detection to Discovery: A Closed-Loop Approach for Simultaneous and Continuous Medical Knowledge Expansion and Depression Detection on Social Media](https://arxiv.org/abs/2510.23626)
*Shuang Geng,Wenli Zhang,Jiaheng Xie,Rui Wang,Sudha Ram*

Main category: cs.LG

TL;DR: 本研究提出了一个结合预测与知识扩展的框架，提升了抑郁症检测的准确性及医学知识，同时推动了预测分析方法论的发展。


<details>
  <summary>Details</summary>
Motivation: 社交媒体用户生成内容为心理健康状况提供了实时的自我报告指标，现有研究未充分利用预测过程扩展医学知识的机会。

Method: 开发了一个闭环的大语言模型-知识图谱框架，旨在通过迭代学习周期整合预测和知识扩展。

Result: 使用大规模用户生成内容，该框架提高了预测准确性和医学理解。专家评估确认了临床上有意义的症状、共病和社交触发因素的发现，补充了现有文献。

Conclusion: 该框架通过整合预测与知识扩展，推动了预测分析领域的方法论和理论理解，并为数据驱动的知识系统奠定了基础，适用于其他动态风险监测情境。

Abstract: Social media user-generated content (UGC) provides real-time, self-reported
indicators of mental health conditions such as depression, offering a valuable
source for predictive analytics. While prior studies integrate medical
knowledge to improve prediction accuracy, they overlook the opportunity to
simultaneously expand such knowledge through predictive processes. We develop a
Closed-Loop Large Language Model (LLM)-Knowledge Graph framework that
integrates prediction and knowledge expansion in an iterative learning cycle.
In the knowledge-aware depression detection phase, the LLM jointly performs
depression detection and entity extraction, while the knowledge graph
represents and weights these entities to refine prediction performance. In the
knowledge refinement and expansion phase, new entities, relationships, and
entity types extracted by the LLM are incorporated into the knowledge graph
under expert supervision, enabling continual knowledge evolution. Using
large-scale UGC, the framework enhances both predictive accuracy and medical
understanding. Expert evaluations confirmed the discovery of clinically
meaningful symptoms, comorbidities, and social triggers complementary to
existing literature. We conceptualize and operationalize
prediction-through-learning and learning-through-prediction as mutually
reinforcing processes, advancing both methodological and theoretical
understanding in predictive analytics. The framework demonstrates the
co-evolution of computational models and domain knowledge, offering a
foundation for adaptive, data-driven knowledge systems applicable to other
dynamic risk monitoring contexts.

</details>


### [128] [Chain of Execution Supervision Promotes General Reasoning in Large Language Models](https://arxiv.org/abs/2510.23629)
*Nuo Chen,Zehua Li,Keqin Bao,Junyang Lin,Dayiheng Liu*

Main category: cs.LG

TL;DR: TracePile is a large corpus that enhances reasoning in LLMs by transforming code execution into structured rationales, showing significant performance improvements across various tasks.


<details>
  <summary>Details</summary>
Motivation: To improve reasoning abilities in large language models by using code as a training source, while overcoming implicit reasoning and noise in raw code.

Method: Introduced TracePile, a corpus of 2.6 million samples that transforms code execution into explicit rationales; evaluated using continue-pretraining, instruction tuning after pretraining, and two-stage finetuning.

Result: TracePile leads to consistent improvements across four base models and 20 benchmarks, boosting performance in math datasets and demonstrating clear gains in specific tasks.

Conclusion: TracePile significantly enhances the reasoning capabilities of large language models, particularly in mathematical and algorithmic domains, through explicit chain-of-thought rationales derived from code execution.

Abstract: Building robust and general reasoning ability is a central goal in the
development of large language models (LLMs). Recent efforts increasingly turn
to code as a rich training source, given its inherent logical structure and
diverse reasoning paradigms such as divide-and-conquer, topological ordering,
and enumeration. However, reasoning in code is often expressed implicitly and
entangled with syntactic or implementation noise, making direct training on raw
code suboptimal.To address this, we introduce TracePile, a large-scale corpus
of 2.6 million samples that transforms code execution into explicit,
step-by-step chain-of-thought-style rationales, which we call Chain of
Execution (CoE). The corpus spans domains including mathematics, classical
algorithms and algorithmic competition, and is enriched with variable-tracing
questions and code rewritings to enhance logical granularity and code
diversity. We evaluate TracePile using three training setups:
continue-pretraining, instruction tuning after pretraining, and two-stage
finetuning. Experiments across four base models (LLaMA 3, LLaMA 3.1, Qwen-2.5,
and Qwen-2.5 Coder) and 20 benchmarks covering math, code, logic, and
algorithms demonstrate consistent improvements. Notably, TracePile boosts
LLaMA3.1-8B by 7.1\% on average across nine math datasets and delivers clear
gains on LiveCodeBench, CRUX, and MMLU under two-stage fine-tuning.

</details>


### [129] [Beyond Pairwise: Empowering LLM Alignment With Ranked Choice Modeling](https://arxiv.org/abs/2510.23631)
*Yuxuan Tang,Yifan Feng*

Main category: cs.LG

TL;DR: 本研究提出了一种新的框架RCPO，结合了排名偏好数据和选择模型，提高了大型语言模型的对齐效果，超越了现有基线。


<details>
  <summary>Details</summary>
Motivation: 传统的大型语言模型对齐方法主要依赖于成对偏好优化，忽视了从更丰富的人类反馈形式中学习的机会。

Method: 通过最大似然估计，将偏好优化与（排名）选择建模结合，支持多种选择模型。

Result: 提出了排名选择偏好优化（RCPO）框架，能够通过最大似然估计将偏好优化与选择建模相结合，且在多项选择模型中取得了优异表现。

Conclusion: RCPO为将（排名）选择建模整合到大型语言模型训练提供了灵活且可扩展的基础。

Abstract: Alignment of large language models (LLMs) has predominantly relied on
pairwise preference optimization, where annotators select the better of two
responses to a prompt. While simple, this approach overlooks the opportunity to
learn from richer forms of human feedback, such as multiwise comparisons and
top-$k$ rankings. We propose Ranked Choice Preference Optimization (RCPO), a
unified framework that bridges preference optimization with (ranked) choice
modeling via maximum likelihood estimation. The framework is flexible,
supporting both utility-based and rank-based choice models. It subsumes several
existing pairwise methods (e.g., DPO, SimPO), while providing principled
training objectives for richer feedback formats. We instantiate this framework
with two representative ranked choice models (Multinomial Logit and
Mallows-RMJ). Empirical studies on Llama-3-8B-Instruct and Gemma-2-9B-it across
AlpacaEval 2 and Arena-Hard benchmarks show that RCPO consistently outperforms
competitive baselines. RCPO shows how directly leveraging ranked preference
data, combined with the right choice models, yields more effective alignment.
It offers a versatile and extensible foundation for incorporating (ranked)
choice modeling into LLM training.

</details>


### [130] [LLMComp: A Language Modeling Paradigm for Error-Bounded Scientific Data Compression](https://arxiv.org/abs/2510.23632)
*Guozhong Li,Muhannad Alhumaidi,Spiros Skiadopoulos,Panos Kalnis*

Main category: cs.LG

TL;DR: 本文提出了一种基于大型语言模型的新型科学数据压缩方法LLMCOMP，能够在严格误差界限内实现高达30%的压缩率提升。


<details>
  <summary>Details</summary>
Motivation: 随着高分辨率科学模拟和观察系统的快速增长，生成了大量时空数据集，因此高效、误差界限内的压缩变得越来越重要。

Method: 通过量化3D场为离散令牌，并基于Z-顺序曲线进行排列，应用覆盖引导采样增强训练效率，训练自回归变换器以建模令牌过渡。

Result: 在多个重分析数据集上的实验表明，LLMCOMP在严格的误差界限下，比现有的最先进压缩方法的压缩比高出最多30%。

Conclusion: LLMCOMP是一种新颖的损失压缩范例，展示了大型语言模型在高保真科学数据压缩中的潜力。

Abstract: The rapid growth of high-resolution scientific simulations and observation
systems is generating massive spatiotemporal datasets, making efficient,
error-bounded compression increasingly important. Meanwhile, decoder-only large
language models (LLMs) have demonstrated remarkable capabilities in modeling
complex sequential data. In this paper, we propose LLMCOMP, a novel lossy
compression paradigm that leverages decoder-only large LLMs to model scientific
data. LLMCOMP first quantizes 3D fields into discrete tokens, arranges them via
Z-order curves to preserve locality, and applies coverage-guided sampling to
enhance training efficiency. An autoregressive transformer is then trained with
spatial-temporal embeddings to model token transitions. During compression, the
model performs top-k prediction, storing only rank indices and fallback
corrections to ensure strict error bounds. Experiments on multiple reanalysis
datasets show that LLMCOMP consistently outperforms state-of-the-art
compressors, achieving up to 30% higher compression ratios under strict error
bounds. These results highlight the potential of LLMs as general-purpose
compressors for high-fidelity scientific data.

</details>


### [131] [Noise is All You Need: Solving Linear Inverse Problems by Noise Combination Sampling with Diffusion Models](https://arxiv.org/abs/2510.23633)
*Xun Su,Hiroyuki Kasai*

Main category: cs.LG

TL;DR: 提出了一种新方法Noise Combination Sampling，通过合成最优噪声向量有效整合观察信息，提升逆问题求解性能。


<details>
  <summary>Details</summary>
Motivation: 解决过度或不足整合观察信息到生成过程中的问题，平衡生成过程与逆问题约束之间的关系。

Method: Noise Combination Sampling

Result: 在各种逆问题求解器中广泛适用，特别是在生成步骤数量较少时，实现了优秀的性能，几乎没有计算开销。

Conclusion: 该方法显著提高了生成过程的鲁棒性和稳定性，适用于多个逆问题场景。

Abstract: Pretrained diffusion models have demonstrated strong capabilities in
zero-shot inverse problem solving by incorporating observation information into
the generation process of the diffusion models. However, this presents an
inherent dilemma: excessive integration can disrupt the generative process,
while insufficient integration fails to emphasize the constraints imposed by
the inverse problem. To address this, we propose \emph{Noise Combination
Sampling}, a novel method that synthesizes an optimal noise vector from a noise
subspace to approximate the measurement score, replacing the noise term in the
standard Denoising Diffusion Probabilistic Models process. This enables
conditional information to be naturally embedded into the generation process
without reliance on step-wise hyperparameter tuning. Our method can be applied
to a wide range of inverse problem solvers, including image compression, and,
particularly when the number of generation steps $T$ is small, achieves
superior performance with negligible computational overhead, significantly
improving robustness and stability.

</details>


### [132] [Monotone and Separable Set Functions: Characterizations and Neural Models](https://arxiv.org/abs/2510.23634)
*Soutrik Sarangi,Yonatan Sverdlov,Nadav Dym,Abir De*

Main category: cs.LG

TL;DR: 研究为集合包含问题设计单调集合到向量的函数，提出了MAS函数及其变体，证明其在实际任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 探索在集合包含问题中的应用，设计能保持集合自然偏序的集合到向量的函数。

Method: 通过理论分析建立MAS函数的维度上下界，并通过实验评估该模型在集合包含任务中的表现。

Result: 提出了单调且区分的集合函数(MAS)。

Conclusion: 在无限基础集的情况下，MAS函数不存在，但提供了一种弱MAS性质的模型，能近似所有单调集合函数。

Abstract: Motivated by applications for set containment problems, we consider the
following fundamental problem: can we design set-to-vector functions so that
the natural partial order on sets is preserved, namely $S\subseteq T \text{ if
and only if } F(S)\leq F(T) $. We call functions satisfying this property
Monotone and Separating (MAS) set functions. % We establish lower and upper
bounds for the vector dimension necessary to obtain MAS functions, as a
function of the cardinality of the multisets and the underlying ground set. In
the important case of an infinite ground set, we show that MAS functions do not
exist, but provide a model called our which provably enjoys a relaxed MAS
property we name "weakly MAS" and is stable in the sense of Holder continuity.
We also show that MAS functions can be used to construct universal models that
are monotone by construction and can approximate all monotone set functions.
Experimentally, we consider a variety of set containment tasks. The experiments
show the benefit of using our our model, in comparison with standard set models
which do not incorporate set containment as an inductive bias. Our code is
available in https://github.com/yonatansverdlov/Monotone-Embedding.

</details>


### [133] [Help the machine to help you: an evaluation in the wild of egocentric data cleaning via skeptical learning](https://arxiv.org/abs/2510.23635)
*Andrea Bontempelli,Matteo Busso,Leonardo Javier Malcotti,Fausto Giunchiglia*

Main category: cs.LG

TL;DR: 本研究评估了Skeptical Learning (SKEL)在真实场景中通过用户优化标签的性能，凸显用户努力与数据质量之间的平衡和SKEL的潜在优势。


<details>
  <summary>Details</summary>
Motivation: 数字个人助理依赖高质量标注以有效执行任务，而用户标注常受噪声和错误的影响，因此需要评估和优化标注精度。

Method: 通过大学生使用iLog移动应用在为期四周的实践中评估SKEL的表现，分析用户输入标签的优化过程。

Result: 研究结果显示，用户在真实环境中能够有效改善标注质量，但存在用户付出努力和数据质量之间的挑战。

Conclusion: SKEL在真实用户环境中显示了提高数据质量和降低标注成本的潜力，但仍需解决用户努力与数据质量之间的平衡问题。

Abstract: Any digital personal assistant, whether used to support task performance,
answer questions, or manage work and daily life, including fitness schedules,
requires high-quality annotations to function properly. However, user
annotations, whether actively produced or inferred from context (e.g., data
from smartphone sensors), are often subject to errors and noise. Previous
research on Skeptical Learning (SKEL) addressed the issue of noisy labels by
comparing offline active annotations with passive data, allowing for an
evaluation of annotation accuracy. However, this evaluation did not include
confirmation from end-users, the best judges of their own context. In this
study, we evaluate SKEL's performance in real-world conditions with actual
users who can refine the input labels based on their current perspectives and
needs. The study involves university students using the iLog mobile application
on their devices over a period of four weeks. The results highlight the
challenges of finding the right balance between user effort and data quality,
as well as the potential benefits of using SKEL, which include reduced
annotation effort and improved quality of collected data.

</details>


### [134] [Flight Delay Prediction via Cross-Modality Adaptation of Large Language Models and Aircraft Trajectory Representation](https://arxiv.org/abs/2510.23636)
*Thaweerath Phisannupawong,Joshua Julian Damanik,Han-Lim Choi*

Main category: cs.LG

TL;DR: 本文提出了一种结合多模态信息的航班延误预测模型，能够高效捕捉延误相关的上下文信息，并实现亚分钟级的预测精度。


<details>
  <summary>Details</summary>
Motivation: 研究航班延误的预测方法，以提高航空交通管理效率，特别是针对进入终端区航空器的延误监控。

Method: 通过将轨迹数据适配为语言模态，整合航班信息、天气报告和机场通知等文本信息，以捕捉空域条件。

Result: 提出了一种基于大型语言模型的轻量级多模态航班延误预测方法，该方法整合了轨迹表示和文本航空信息。

Conclusion: 该框架通过结合语言理解和轨迹信息的跨模态适应性，显著提高了航班延误预测的准确性，同时具备实际操作可行性和可扩展性。

Abstract: Flight delay prediction has become a key focus in air traffic management, as
delays highlight inefficiencies that impact overall network performance. This
paper presents a lightweight large language model-based multimodal flight delay
prediction, formulated from the perspective of air traffic controllers
monitoring aircraft delay after entering the terminal area. The approach
integrates trajectory representations with textual aeronautical information,
including flight information, weather reports, and aerodrome notices, by
adapting trajectory data into the language modality to capture airspace
conditions. Experimental results show that the model consistently achieves
sub-minute prediction error by effectively leveraging contextual information
related to the sources of delay. The framework demonstrates that linguistic
understanding, when combined with cross-modality adaptation of trajectory
information, enhances delay prediction. Moreover, the approach shows
practicality and scalability for real-world operations, supporting real-time
updates that refine predictions upon receiving new operational information.

</details>


### [135] [Integrating Genomics into Multimodal EHR Foundation Models](https://arxiv.org/abs/2510.23639)
*Jonathan Amar,Edward Liu,Alessandra Breschi,Liangliang Zhang,Pouya Kheradpour,Sylvia Li,Lisa Soleymani Lehmann,Alessandro Giulianelli,Matt Edwards,Yugang Jia,David Nola,Raghav Mani,Pankaj Vats,Jesse Tetreault,T. J. Chen,Cory Y. McLean*

Main category: cs.LG

TL;DR: 提出了一种创新的电子健康记录基础模型，整合了多基因风险评分，以实现更全面的健康档案，验证了其在多种疾病预测中的有效性。


<details>
  <summary>Details</summary>
Motivation: To build more holistic health profiles by incorporating genetic predispositions alongside clinical data.

Method: Innovative Electronic Health Record foundation model integrating Polygenic Risk Scores

Result: Evaluation demonstrates the model's predictive value for various conditions, especially Type 2 Diabetes, and explores transfer learning capabilities.

Conclusion: 这一方法为疾病预测、主动健康管理和个性化治疗策略的深入理解奠定了基础，推动更有针对性和平等的真实世界证据生成。

Abstract: This paper introduces an innovative Electronic Health Record (EHR) foundation
model that integrates Polygenic Risk Scores (PRS) as a foundational data
modality, moving beyond traditional EHR-only approaches to build more holistic
health profiles. Leveraging the extensive and diverse data from the All of Us
(AoU) Research Program, this multimodal framework aims to learn complex
relationships between clinical data and genetic predispositions. The
methodology extends advancements in generative AI to the EHR foundation model
space, enhancing predictive capabilities and interpretability. Evaluation on
AoU data demonstrates the model's predictive value for the onset of various
conditions, particularly Type 2 Diabetes (T2D), and illustrates the interplay
between PRS and EHR data. The work also explores transfer learning for custom
classification tasks, showcasing the architecture's versatility and efficiency.
This approach is pivotal for unlocking new insights into disease prediction,
proactive health management, risk stratification, and personalized treatment
strategies, laying the groundwork for more personalized, equitable, and
actionable real-world evidence generation in healthcare.

</details>


### [136] [Structure-Aware Fusion with Progressive Injection for Multimodal Molecular Representation Learning](https://arxiv.org/abs/2510.23640)
*Zihao Jing,Yan Sun,Yan Yi Li,Sugitha Janarthanan,Alana Deng,Pingzhao Hu*

Main category: cs.LG

TL;DR: MuMo是一个结构化的多模态融合框架，通过两种关键策略提高分子表示的可靠性和泛化能力，在多个基准任务中表现出显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决传统多模态分子模型中的3D构象不稳定性和模态崩溃问题，从而提高模型的鲁棒性和泛化能力。

Method: 通过Structured Fusion Pipeline (SFP)和Progressive Injection (PI)机制，MuMo将2D拓扑和3D几何结合成统一的结构先验，从而实现稳健的信息传播和长距离依赖建模。

Result: MuMo在29项基准任务中平均提高了2.7%，在22项任务中排名第一，尤其在LD50任务上提高了27%。

Conclusion: MuMo在29个基准任务中表现出色，验证了其在分子表示中对3D构象噪声的鲁棒性和多模态融合的有效性。

Abstract: Multimodal molecular models often suffer from 3D conformer unreliability and
modality collapse, limiting their robustness and generalization. We propose
MuMo, a structured multimodal fusion framework that addresses these challenges
in molecular representation through two key strategies. To reduce the
instability of conformer-dependent fusion, we design a Structured Fusion
Pipeline (SFP) that combines 2D topology and 3D geometry into a unified and
stable structural prior. To mitigate modality collapse caused by naive fusion,
we introduce a Progressive Injection (PI) mechanism that asymmetrically
integrates this prior into the sequence stream, preserving modality-specific
modeling while enabling cross-modal enrichment. Built on a state space
backbone, MuMo supports long-range dependency modeling and robust information
propagation. Across 29 benchmark tasks from Therapeutics Data Commons (TDC) and
MoleculeNet, MuMo achieves an average improvement of 2.7% over the
best-performing baseline on each task, ranking first on 22 of them, including a
27% improvement on the LD50 task. These results validate its robustness to 3D
conformer noise and the effectiveness of multimodal fusion in molecular
representation. The code is available at: github.com/selmiss/MuMo.

</details>


### [137] [Spatially Aware Linear Transformer (SAL-T) for Particle Jet Tagging](https://arxiv.org/abs/2510.23641)
*Aaron Wang,Zihan Zhao,Subash Katel,Vivekanand Gyanchand Sahu,Elham E Khoda,Abhijith Gandrakota,Jennifer Ngadiuba,Richard Cavanaugh,Javier Duarte*

Main category: cs.LG

TL;DR: SAL-T是一种改进的线性变换器，通过结合空间感知分区和卷积层，在处理高能粒子碰撞数据时提高了效率与性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统变换器在高数据吞吐环境中的计算复杂度和延迟问题，以提升粒子物理数据处理的效率。

Method: 提出了一种基于物理启示的空间感知线性变换器，通过线性注意力和卷积层的结合，处理粒子间的局部和全局关联。

Result: SAL-T（Spatially Aware Linear Transformer）是一种针对粒子碰撞数据处理的高效变换器模型。它通过线性注意力机制，结合物理启发的空间分区方法，使得在高数据吞吐环境下的效率显著提升。相比传统变换器，SAL-T在资源和延迟方面表现更优，同时在分类任务中超越了标准的linformer，且与全注意力变换器的结果相当。通过在通用点云数据集上的实验进一步验证了该方法的有效性。

Conclusion: SAL-T在粒子物理数据处理方面展示了出色的性能，兼顾了计算资源需求和处理延迟，适合高吞吐量环境下的应用。

Abstract: Transformers are very effective in capturing both global and local
correlations within high-energy particle collisions, but they present
deployment challenges in high-data-throughput environments, such as the CERN
LHC. The quadratic complexity of transformer models demands substantial
resources and increases latency during inference. In order to address these
issues, we introduce the Spatially Aware Linear Transformer (SAL-T), a
physics-inspired enhancement of the linformer architecture that maintains
linear attention. Our method incorporates spatially aware partitioning of
particles based on kinematic features, thereby computing attention between
regions of physical significance. Additionally, we employ convolutional layers
to capture local correlations, informed by insights from jet physics. In
addition to outperforming the standard linformer in jet classification tasks,
SAL-T also achieves classification results comparable to full-attention
transformers, while using considerably fewer resources with lower latency
during inference. Experiments on a generic point cloud classification dataset
(ModelNet10) further confirm this trend. Our code is available at
https://github.com/aaronw5/SAL-T4HEP.

</details>


### [138] [Beyond Hidden-Layer Manipulation: Semantically-Aware Logit Interventions for Debiasing LLMs](https://arxiv.org/abs/2510.23650)
*Wei Xia*

Main category: cs.LG

TL;DR: 提出两种零样本logits层去偏见方法，动态方法在流畅性损失较小的情况下减少了70%的偏见。


<details>
  <summary>Details</summary>
Motivation: 旨在减少对齐大型语言模型中的偏见，提升模型的表现。

Method: 提出了静态和动态两种去偏见方法，比较了logits干预与隐藏层方法的效果。

Result: 动态方法在减少偏见方面表现最佳，显示出比隐藏层方法更优的干预效果。

Conclusion: 语义感知的logits干预方法在去偏见对齐的大型语言模型中是稳定和有效的。

Abstract: We proposed Static and Dynamic -- two zero-shot logits-layer debiasing
methods. Dynamic reduces bias by up to 70% with minimal fluency loss. Logits
intervention outperforms hidden-layer approaches. We show semantic-aware logits
intervention is stable and effective for debiasing aligned LLMs.

</details>


### [139] [The Structural Scalpel: Automated Contiguous Layer Pruning for Large Language Models](https://arxiv.org/abs/2510.23652)
*Yao Lu,Yuqi Li,Wenbin Xie,Shanqing Yu,Qi Xuan,Zhaowei Zhu,Shiping Wen*

Main category: cs.LG

TL;DR: CLP是一种新颖的层修剪框架，通过改进算法和调谐策略，显著提升了修剪效果，并可与量化技术结合以有效压缩模型。


<details>
  <summary>Details</summary>
Motivation: 解决目前层修剪方法中的局限性，如依赖手工指标和忽视层之间的关系。

Method: 提出了一个连续层修剪框架CLP，利用可微分的凹函数门算法和截止端点调谐策略进行优化。

Result: CLP在多个模型架构及参数规模中进行广泛实验表现出色，例如在LLaMA3-70B中，修剪率为20%时，平均性能保持率达到95.34%。

Conclusion: CLP显著提高了大语言模型的层修剪效果，并且可以与量化技术无缝结合，以进一步压缩模型。

Abstract: Although large language models (LLMs) have achieved revolutionary
breakthroughs in many fields, their large model size and high computational
cost pose significant challenges for practical deployment on
resource-constrained edge devices. To this end, layer pruning has been proposed
to reduce the computational overhead by directly removing redundant layers.
However, existing layer pruning methods typically rely on hand-crafted metrics
to evaluate and remove individual layers, while ignoring the dependencies
between layers. This can disrupt the model's information flow and severely
degrade performance. To address these issues, we propose CLP, a novel
continuous layer pruning framework that introduces two key innovations: a
differentiable concave gate algorithm that automatically identifies the best
continuous layer segments for pruning via gradient-based optimization; and a
cutoff endpoint tuning strategy that effectively restores model performance by
fine-tuning only the layers adjacent to the pruned segments. Extensive
experiments across multiple model architectures (including LLaMA2, LLaMA3 and
Qwen) and sizes (from $7$B to $70$B parameters) show that CLP significantly
outperforms existing state-of-the-art baselines. For example, at a pruning rate
of $20\%$, CLP achieves an average performance retention of $95.34\%$ on
LLaMA3-70B, outperforming baselines by $4.29\%$-$30.52\%$. Furthermore, CLP can
be seamlessly combined with quantization to further compress the model with
only a slight performance loss.

</details>


### [140] [Error Adjustment Based on Spatiotemporal Correlation Fusion for Traffic Forecasting](https://arxiv.org/abs/2510.23656)
*Fuqiang Liu,Weiping Ding,Luis Miranda-Moreno,Lijun Sun*

Main category: cs.LG

TL;DR: 本研究提出SAEA框架，通过建模交通数据误差的自相关性，改进交通预测模型，显著提升预测能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前交通预测模型在处理交通数据时假设误差不相关的问题，从而提升其性能。

Method: SAEA框架通过引入自回归过程来建模预测误差，同时整合先验空间信息并在测试时进行动态调整预测。

Result: 提出了Spatiotemporally Autocorrelated Error Adjustment (SAEA)框架，通过系统地调整交通预测中的自相关预测误差，提升了预测性能。

Conclusion: SAEA有效捕捉了交通数据的时空误差相关性，且在多个交通数据集上的测试结果表明，该方法在几乎所有情况下都提升了预测性能。

Abstract: Deep neural networks (DNNs) play a significant role in an increasing body of
research on traffic forecasting due to their effectively capturing
spatiotemporal patterns embedded in traffic data. A general assumption of
training the said forecasting models via mean squared error estimation is that
the errors across time steps and spatial positions are uncorrelated. However,
this assumption does not really hold because of the autocorrelation caused by
both the temporality and spatiality of traffic data. This gap limits the
performance of DNN-based forecasting models and is overlooked by current
studies. To fill up this gap, this paper proposes Spatiotemporally
Autocorrelated Error Adjustment (SAEA), a novel and general framework designed
to systematically adjust autocorrelated prediction errors in traffic
forecasting. Unlike existing approaches that assume prediction errors follow a
random Gaussian noise distribution, SAEA models these errors as a
spatiotemporal vector autoregressive (VAR) process to capture their intrinsic
dependencies. First, it explicitly captures both spatial and temporal error
correlations by a coefficient matrix, which is then embedded into a newly
formulated cost function. Second, a structurally sparse regularization is
introduced to incorporate prior spatial information, ensuring that the learned
coefficient matrix aligns with the inherent road network structure. Finally, an
inference process with test-time error adjustment is designed to dynamically
refine predictions, mitigating the impact of autocorrelated errors in real-time
forecasting. The effectiveness of the proposed approach is verified on
different traffic datasets. Results across a wide range of traffic forecasting
models show that our method enhances performance in almost all cases.

</details>


### [141] [A machine learning framework integrating seed traits and plasma parameters for predicting germination uplift in crops](https://arxiv.org/abs/2510.23657)
*Saklain Niam,Tashfiqur Rahman,Md. Amjad Patwary,Mukarram Hossain*

Main category: cs.LG

TL;DR: 研究提出了一个机器学习框架，能够有效预测冷等离子体对多种植物种子发芽的影响，特别是在精准农业中具有实用价值。


<details>
  <summary>Details</summary>
Motivation: 探讨冷等离子体对种子发芽的影响并预测发芽率，响应复杂的种子-等离子体-环境交互作用。

Method: 采用多种机器学习模型（GB, XGB, ET等），结合工程分析，测试并优化预测冷等离子体对种子发芽的影响。

Result: 开发了一个机器学习框架来预测大豆、大麦、向日葵、萝卜和西红柿在介电屏障放电等离子体下的发芽提升，并找到了最佳预测模型。

Conclusion: 最佳模型为Extra Trees，在一定的激发电压和时间条件下，冷等离子体能够显著提升种子发芽率，但过高的电压和时间会导致效果下降。

Abstract: Cold plasma (CP) is an eco-friendly method to enhance seed germination, yet
outcomes remain difficult to predict due to complex seed--plasma--environment
interactions. This study introduces the first machine learning framework to
forecast germination uplift in soybean, barley, sunflower, radish, and tomato
under dielectric barrier discharge (DBD) plasma. Among the models tested (GB,
XGB, ET, and hybrids), Extra Trees (ET) performed best (R\textsuperscript{2} =
0.919; RMSE = 3.21; MAE = 2.62), improving to R\textsuperscript{2} = 0.925
after feature reduction. Engineering analysis revealed a hormetic response:
negligible effects at $<$7 kV or $<$200 s, maximum germination at 7--15 kV for
200--500 s, and reduced germination beyond 20 kV or prolonged exposures.
Discharge power was also a dominant factor, with germination rate maximizing at
$\geq$100 W with low exposure time. Species and cultivar-level predictions
showed radish (MAE = 1.46) and soybean (MAE = 2.05) were modeled with high
consistency, while sunflower remained slightly higher variable (MAE = 3.80).
Among cultivars, Williams (MAE = 1.23) and Sari (1.33) were well predicted,
while Arian (2.86) and Ny\'{\i}rs\'{e}gi fekete (3.74) were comparatively
poorly captured. This framework was also embedded into MLflow, providing a
decision-support tool for optimizing CP seed germination in precision
agriculture.

</details>


### [142] [Quantum Machine Learning for Image Classification: A Hybrid Model of Residual Network with Quantum Support Vector Machine](https://arxiv.org/abs/2510.23659)
*Md. Farhan Shahriyar,Gazi Tanbhir,Abdullah Md Raihan Chy*

Main category: cs.LG

TL;DR: 本研究提出一种混合方法，结合ResNet-50和QSVM进行土豆疾病检测，显示量子计算在图像分类中的优势。


<details>
  <summary>Details</summary>
Motivation: 在高维复杂数据集上提高图像分类效率，克服传统深度学习和机器学习模型的局限性。

Method: 结合ResNet-50特征提取与量子支持向量机(QSVM)进行土豆疾病检测的分类

Result: Z特征图基础的QSVM模型在土豆疾病检测中实现了99.23%的准确率，优于传统的SVM和随机森林模型。

Conclusion: 研究表明，量子计算与传统模型相结合能够有效提高图像分类性能，为疾病检测提供新的解决方案。

Abstract: Recently, there has been growing attention on combining quantum machine
learning (QML) with classical deep learning approaches, as computational
techniques are key to improving the performance of image classification tasks.
This study presents a hybrid approach that uses ResNet-50 (Residual Network)
for feature extraction and Quantum Support Vector Machines (QSVM) for
classification in the context of potato disease detection. Classical machine
learning as well as deep learning models often struggle with high-dimensional
and complex datasets, necessitating advanced techniques like quantum computing
to improve classification efficiency. In our research, we use ResNet-50 to
extract deep feature representations from RGB images of potato diseases. These
features are then subjected to dimensionality reduction using Principal
Component Analysis (PCA). The resulting features are processed through QSVM
models which apply various quantum feature maps such as ZZ, Z, and Pauli-X to
transform classical data into quantum states. To assess the model performance,
we compared it with classical machine learning algorithms such as Support
Vector Machine (SVM) and Random Forest (RF) using five-fold stratified
cross-validation for comprehensive evaluation. The experimental results
demonstrate that the Z-feature map-based QSVM outperforms classical models,
achieving an accuracy of 99.23 percent, surpassing both SVM and RF models. This
research highlights the advantages of integrating quantum computing into image
classification and provides a potential disease detection solution through
hybrid quantum-classical modeling.

</details>


### [143] [AI-Driven Carbon Monitoring: Transformer-Based Reconstruction of Atmospheric CO2 in Canadian Poultry Regions](https://arxiv.org/abs/2510.23663)
*Padmanabhan Jagannathan Prajesh,Kaliaperumal Ragunath,Miriam Gordon,Bruce Rathgeber,Suresh Neethirajan*

Main category: cs.LG

TL;DR: 本文提出了一种融合波浪小波和变换器注意力的时空视觉变换器（ST-ViWT）框架，用于重建南加拿大农业景观中CO2的连续映射，并量化不确定性。这种方法在OCO-2数据上实现了优异的准确度，为温室气体减排提供了有力支持。


<details>
  <summary>Details</summary>
Motivation: 准确映射农业景观中的CO2水平对于制定减排策略至关重要。

Method: 该框架融合了小波时频表示与变换器注意力，利用气象、植被指数、地形和土地覆盖等多维度数据进行CO2映射。

Result: ST-ViWT在2024 OCO-2数据上表现出色，R2值为0.984，RMSE为0.468 ppm，93%预测值在±1 ppm之内，并且与TCCON的独立验证结果显示出稳定的泛化能力。

Conclusion: ST-ViWT框架能够提供高精度的CO2映射，支持基于卫星的碳核算和减排评估，具有重要的政策相关性。

Abstract: Accurate mapping of column-averaged CO2 (XCO2) over agricultural landscapes
is essential for guiding emission mitigation strategies. We present a
Spatiotemporal Vision Transformer with Wavelets (ST-ViWT) framework that
reconstructs continuous, uncertainty-quantified XCO2 fields from OCO-2 across
southern Canada, emphasizing poultry-intensive regions. The model fuses wavelet
time-frequency representations with transformer attention over meteorology,
vegetation indices, topography, and land cover. On 2024 OCO-2 data, ST-ViWT
attains R2 = 0.984 and RMSE = 0.468 ppm; 92.3 percent of gap-filled predictions
lie within +/-1 ppm. Independent validation with TCCON shows robust
generalization (bias = -0.14 ppm; r = 0.928), including faithful reproduction
of the late-summer drawdown. Spatial analysis across 14 poultry regions reveals
a moderate positive association between facility density and XCO2 (r = 0.43);
high-density areas exhibit larger seasonal amplitudes (9.57 ppm) and enhanced
summer variability. Compared with conventional interpolation and standard
machine-learning baselines, ST-ViWT yields seamless 0.25 degree CO2 surfaces
with explicit uncertainties, enabling year-round coverage despite sparse
observations. The approach supports integration of satellite constraints with
national inventories and precision livestock platforms to benchmark emissions,
refine region-specific factors, and verify interventions. Importantly,
transformer-based Earth observation enables scalable, transparent, spatially
explicit carbon accounting, hotspot prioritization, and policy-relevant
mitigation assessment.

</details>


### [144] [Transformers from Compressed Representations](https://arxiv.org/abs/2510.23665)
*Juan C. Leon Alcazar,Mattia Soldan,Mohammad Saatialsoruji,Alejandro Pardo,Hani Itani,Juan Camilo Perez,Bernard Ghanem*

Main category: cs.LG

TL;DR: TEMPEST是一种利用压缩文件格式进行高效表示学习的方法，能够在保持准确率的同时，提高内存和计算效率。


<details>
  <summary>Details</summary>
Motivation: 探讨压缩文件格式在表示学习中的潜力，利用其内在的字节流结构来设计有效的标记化和编码策略。

Method: TEMPEST (TransformErs froM comPressed rEpreSenTations)

Result: TEMPEST能直接从压缩数据流中学习语义表示，显著减少用于语义分类的标记数量，降低计算复杂度和内存使用。

Conclusion: TEMPEST在多样的数据集和编码方案下表现出竞争力的准确性，并在内存和计算上实现效能提升。

Abstract: Compressed file formats are the corner stone of efficient data storage and
transmission, yet their potential for representation learning remains largely
underexplored. We introduce TEMPEST (TransformErs froM comPressed
rEpreSenTations), a method that exploits the inherent byte-stream structure of
compressed files to design an effective tokenization and encoding strategy. By
leveraging this compact encoding, a standard transformer can directly learn
semantic representations from compressed data streams, bypassing the need for
raw byte-level processing or full media decoding. Our proposal substantially
reduces the number of tokens required for semantic classification, thereby
lowering both computational complexity and memory usage. Through extensive
experiments across diverse datasets, coding schemes, and modalities, we show
that TEMPEST achieves accuracy competitive wit the state-of-the-art while
delivering efficiency gains in memory and compute.

</details>


### [145] [Optimize Any Topology: A Foundation Model for Shape- and Resolution-Free Structural Topology Optimization](https://arxiv.org/abs/2510.23667)
*Amin Heyrani Nobari,Lyle Regenwetter,Cyril Picard,Ligong Han,Faez Ahmed*

Main category: cs.LG

TL;DR: OAT是一种创新的拓扑优化方法，通过深度学习模型显著提高了优化效率，降低了合规性，且能够处理多种复杂条件。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在处理固定网格和手工编码边界条件方面有限，因此需要一个通用的解决方案来提升结构拓扑优化的效率。

Method: 通过结合分辨率和形状无关的自编码器、隐式神经场解码器和条件潜在扩散模型，OAT直接预测任意形状的最小合规布局。

Result: OAT在四个公共基准测试和两个具有挑战性的未见测试中，相较于最佳现有模型，平均合规性降低了多达90%，并在单个GPU上实现了小于1秒的推理速度。

Conclusion: OAT是一个通用、快速且无分辨率限制的结构拓扑优化框架，能显著降低合规性，并提供了一个大型数据集以促进逆向设计的进一步研究。

Abstract: Structural topology optimization (TO) is central to engineering design but
remains computationally intensive due to complex physics and hard constraints.
Existing deep-learning methods are limited to fixed square grids, a few
hand-coded boundary conditions, and post-hoc optimization, preventing general
deployment. We introduce Optimize Any Topology (OAT), a foundation-model
framework that directly predicts minimum-compliance layouts for arbitrary
aspect ratios, resolutions, volume fractions, loads, and fixtures. OAT combines
a resolution- and shape-agnostic autoencoder with an implicit neural-field
decoder and a conditional latent-diffusion model trained on OpenTO, a new
corpus of 2.2 million optimized structures covering 2 million unique
boundary-condition configurations. On four public benchmarks and two
challenging unseen tests, OAT lowers mean compliance up to 90% relative to the
best prior models and delivers sub-1 second inference on a single GPU across
resolutions from 64 x 64 to 256 x 256 and aspect ratios as high as 10:1. These
results establish OAT as a general, fast, and resolution-free framework for
physics-aware topology optimization and provide a large-scale dataset to spur
further research in generative modeling for inverse design. Code & data can be
found at https://github.com/ahnobari/OptimizeAnyTopology.

</details>


### [146] [Traffic flow forecasting, STL decomposition, Hybrid model, LSTM, ARIMA, XGBoost, Intelligent transportation systems](https://arxiv.org/abs/2510.23668)
*Fujiang Yuan,Yangrui Fan,Xiaohuan Bing,Zhen Tian,Chunhong Yuan,Yankang Li*

Main category: cs.LG

TL;DR: 提出了一种混合模型，结合STL分解和LSTM、ARIMA及XGBoost，以提高交通流量预测的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 考虑到交通流数据的复杂性和非线性特性，单一模型难以全面捕捉其时间特征，迫切需要一种新的预测方法。

Method: 通过季节性趋势分解与LSTM、ARIMA、XGBoost相结合的建模方法进行交通流量预测。

Result: 实验结果表明，该混合模型在MAE、RMSE和R平方等指标上显著优于各个独立模型。

Conclusion: 该研究提出的混合框架在交通流量预测中展示了显著的准确性提升，超越了单一模型的表现。

Abstract: Accurate traffic flow forecasting is essential for intelligent transportation
systems and urban traffic management. However, single model approaches often
fail to capture the complex, nonlinear, and multi scale temporal patterns in
traffic flow data. This study proposes a decomposition driven hybrid framework
that integrates Seasonal Trend decomposition using Loess (STL) with three
complementary predictive models. STL first decomposes the original time series
into trend, seasonal, and residual components. Then, a Long Short Term Memory
(LSTM) network models long term trends, an Autoregressive Integrated Moving
Average (ARIMA) model captures seasonal periodicity, and an Extreme Gradient
Boosting (XGBoost) algorithm predicts nonlinear residual fluctuations. The
final forecast is obtained through multiplicative integration of the sub model
predictions. Using 998 traffic flow records from a New York City intersection
between November and December 2015, results show that the LSTM ARIMA XGBoost
hybrid model significantly outperforms standalone models including LSTM, ARIMA,
and XGBoost across MAE, RMSE, and R squared metrics. The decomposition strategy
effectively isolates temporal characteristics, allowing each model to
specialize, thereby improving prediction accuracy, interpretability, and
robustness.

</details>


### [147] [DBLoss: Decomposition-based Loss Function for Time Series Forecasting](https://arxiv.org/abs/2510.23672)
*Xiangfei Qiu,Xingjian Wu,Hanyin Cheng,Xvyuan Liu,Chenjuan Guo,Jilin Hu,Bin Yang*

Main category: cs.LG

TL;DR: DBLoss是一个新提出的损失函数，通过分解时间序列来改善预测性能，适用于深度学习模型。


<details>
  <summary>Details</summary>
Motivation: 现有的均方误差(MSE)损失函数对时间序列的季节性和趋势捕捉不佳，影响预测性能。

Method: DBLoss利用指数移动平均法将时间序列分解为季节性和趋势成分，分别计算损失后进行加权。

Result: 提出了一种新颖的分解基础损失函数DBLoss，显著提高了多种先进模型在实际数据集上的预测性能。

Conclusion: DBLoss展示了更有效的时间序列损失函数设计的新思路，促进了预测模型的性能提升。

Abstract: Time series forecasting holds significant value in various domains such as
economics, traffic, energy, and AIOps, as accurate predictions facilitate
informed decision-making. However, the existing Mean Squared Error (MSE) loss
function sometimes fails to accurately capture the seasonality or trend within
the forecasting horizon, even when decomposition modules are used in the
forward propagation to model the trend and seasonality separately. To address
these challenges, we propose a simple yet effective Decomposition-Based Loss
function called DBLoss. This method uses exponential moving averages to
decompose the time series into seasonal and trend components within the
forecasting horizon, and then calculates the loss for each of these components
separately, followed by weighting them. As a general loss function, DBLoss can
be combined with any deep learning forecasting model. Extensive experiments
demonstrate that DBLoss significantly improves the performance of
state-of-the-art models across diverse real-world datasets and provides a new
perspective on the design of time series loss functions.

</details>


### [148] [On the Societal Impact of Machine Learning](https://arxiv.org/abs/2510.23693)
*Joachim Baumann*

Main category: cs.LG

TL;DR: 该博士论文研究了机器学习的社会影响，探讨其在决策过程中的公平性问题，并提出了相应的解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在决策中的广泛应用，其潜在的歧视性影响引起了关注，因此需要探索如何在不牺牲系统效用的情况下实现公平。

Method: 通过对机器学习系统的公平性进行更适当的测量、系统性分解以预测偏见动态，并提出有效的干预措施来减少算法歧视。

Result: 这项研究提供了基础，以确保机器学习的社会影响与更广泛的社会价值相一致，并讨论了产生式人工智能带来的挑战与研究方向。

Conclusion: 论文总结了机器学习对社会的影响以及未来研究方向，以确保机器学习符合更广泛的社会价值。

Abstract: This PhD thesis investigates the societal impact of machine learning (ML). ML
increasingly informs consequential decisions and recommendations, significantly
affecting many aspects of our lives. As these data-driven systems are often
developed without explicit fairness considerations, they carry the risk of
discriminatory effects. The contributions in this thesis enable more
appropriate measurement of fairness in ML systems, systematic decomposition of
ML systems to anticipate bias dynamics, and effective interventions that reduce
algorithmic discrimination while maintaining system utility. I conclude by
discussing ongoing challenges and future research directions as ML systems,
including generative artificial intelligence, become increasingly integrated
into society. This work offers a foundation for ensuring that ML's societal
impact aligns with broader social values.

</details>


### [149] [MUStReason: A Benchmark for Diagnosing Pragmatic Reasoning in Video-LMs for Multimodal Sarcasm Detection](https://arxiv.org/abs/2510.23727)
*Anisha Saha,Varsha Suresh,Timothy Hospedales,Vera Demberg*

Main category: cs.LG

TL;DR: 提出MUStReason基准和PragCoT框架以改进视频语言模型的讽刺检测能力。


<details>
  <summary>Details</summary>
Motivation: 当前视频语言模型在讽刺检测中面临挑战，本文动机在于通过引入新的评估标准和方法来解决这一问题。

Method: 本文提出了MUStReason基准与PragCoT框架，致力于改善视频语言模型在讽刺识别中的表现，强调理解潜在意图的重要性。

Result: 本文介绍了一种新型基准MUStReason，用于评估视频语言模型（VideoLMs）对讽刺的检测能力。讽刺的识别不仅依赖于字面内容，还包括说话者的语气、面部表情及对话背景等非语言线索。当前的多模态模型在执行这些复杂任务时的表现不足，MUStReason通过提供特定于模态的相关线索注释和推理步骤，帮助识别讽刺意图。此外，论文提出了PragCoT框架，旨在引导VideoLMs关注含意而非字面意义，以提高讽刺检测性能。

Conclusion: 通过MUStReason基准的引入和PragCoT框架的提出，本文为视频语言模型在讽刺检测领域提供了新的评估方法和改进方案。

Abstract: Sarcasm is a specific type of irony which involves discerning what is said
from what is meant. Detecting sarcasm depends not only on the literal content
of an utterance but also on non-verbal cues such as speaker's tonality, facial
expressions and conversational context. However, current multimodal models
struggle with complex tasks like sarcasm detection, which require identifying
relevant cues across modalities and pragmatically reasoning over them to infer
the speaker's intention. To explore these limitations in VideoLMs, we introduce
MUStReason, a diagnostic benchmark enriched with annotations of
modality-specific relevant cues and underlying reasoning steps to identify
sarcastic intent. In addition to benchmarking sarcasm classification
performance in VideoLMs, using MUStReason we quantitatively and qualitatively
evaluate the generated reasoning by disentangling the problem into perception
and reasoning, we propose PragCoT, a framework that steers VideoLMs to focus on
implied intentions over literal meaning, a property core to detecting sarcasm.

</details>


### [150] [Debiasing Reward Models by Representation Learning with Guarantees](https://arxiv.org/abs/2510.23751)
*Ignavier Ng,Patrick Blöbaum,Siddharth Bhandari,Kun Zhang,Shiva Kasiviswanathan*

Main category: cs.LG

TL;DR: 本文提出了一种新框架，通过变分推断减轻奖励模型的偏见，实验结果表明该方法有效。


<details>
  <summary>Details</summary>
Motivation: 当前的奖励模型在与人类偏好对齐时存在利用伪相关性的倾向，亟需一个有效的框架来解决这一问题。

Method: 使用变分推断来识别和恢复非伪变量，以改善奖励模型的训练。

Result: 本文提出了一种新的框架，以减轻在大型语言模型过程中使用奖励模型时出现的偏见。通过将生成数据的过程建模为同时受伪变量和非伪变量影响，研究者发现可以从数据中理论上识别非伪变量。这一发现促进了一种使用变分推断的方法，以恢复这些变量并用于训练更稳健的奖励模型。实验结果表明，该方法在处理伪相关性问题上取得了有效的效果。

Conclusion: 该方法有效减轻了奖励模型中的伪相关性问题，增强了模型的鲁棒性。

Abstract: Recent alignment techniques, such as reinforcement learning from human
feedback, have been widely adopted to align large language models with human
preferences by learning and leveraging reward models. In practice, these models
often exploit spurious correlations, involving, e.g., response length,
discrimination, sycophancy, and conceptual bias, which is a problem that has
received increasing attention. In this work, we propose a principled framework
that mitigates these biases in reward models while preserving the underlying
factors that reflect intended preferences. We first provide a formulation of
the data-generating process, assuming that the observed data (e.g., text) is
generated from both spurious and non-spurious latent variables. We show that,
interestingly, these non-spurious latent variables can be theoretically
identified from data, regardless of whether a surrogate for the spurious latent
variables is available. This further inspires a practical method that uses
variational inference to recover these variables and leverages them to train
reward models. Experiments on synthetic and real-world datasets demonstrate
that our method effectively mitigates spurious correlation issues and yields
more robust reward models.

</details>


### [151] [Revealing the Potential of Learnable Perturbation Ensemble Forecast Model for Tropical Cyclone Prediction](https://arxiv.org/abs/2510.23794)
*Jun Liu,Tao Zhou,Jiarui Li,Xiaohui Zhong,Peng Zhang,Jie Feng,Lei Chen,Hao Li*

Main category: cs.LG

TL;DR: FuXi-ENS通过可学习扰动方案在热带气旋预测中表现优于传统的ECMWF-ENS，尤其在物理变量预测和路径预测上，但强度预测仍待提高。


<details>
  <summary>Details</summary>
Motivation: 为了应对热带气旋预测中的不确定性和计算成本问题，提出基于AI的FuXi-ENS模型，旨在提高预测的准确性和可靠性。

Method: 本研究采用系统对比的方法，通过分析FuXi-ENS与ECMWF-ENS在同一组热带气旋数据集上的表现，评估其在物理变量、路径和强度预测的效果。

Result: 本文研究了FuXi-ENS与ECMWF-ENS对2018年全球90个热带气旋(TCs)的预测性能比较。FuXi-ENS引入了一种可学习的扰动方案，作为一种新的基于AI的预测范式。它在TC相关物理变量的预测方面表现出明显优势，并能提供更准确的路径预测，同时减少了集成扩展。但在强度预测上仍低于观测值。研究还发现，FuXi-ENS在捕捉大尺度环流上表现更佳，水分汤普森能量更加集中，这与ECMWF-ENS的分散分布形成对比。这些结果显示了可学习扰动在提升热带气旋预测准确性方面的潜力。

Conclusion: FuXi-ENS显示出在热带气旋预测中具有明显的优势，特别是在捕捉气候大尺度变化及改进预测技能方面。

Abstract: Tropical cyclones (TCs) are highly destructive and inherently uncertain
weather systems. Ensemble forecasting helps quantify these uncertainties, yet
traditional systems are constrained by high computational costs and limited
capability to fully represent atmospheric nonlinearity. FuXi-ENS introduces a
learnable perturbation scheme for ensemble generation, representing a novel
AI-based forecasting paradigm. Here, we systematically compare FuXi-ENS with
ECMWF-ENS using all 90 global TCs in 2018, examining their performance in
TC-related physical variables, track and intensity forecasts, and the
associated dynamical and thermodynamical fields. FuXi-ENS demonstrates clear
advantages in predicting TC-related physical variables, and achieves more
accurate track forecasts with reduced ensemble spread, though it still
underestimates intensity relative to observations. Further dynamical and
thermodynamical analyses reveal that FuXi-ENS better captures large-scale
circulation, with moisture turbulent energy more tightly concentrated around
the TC warm core, whereas ECMWF-ENS exhibits a more dispersed distribution.
These findings highlight the potential of learnable perturbations to improve TC
forecasting skill and provide valuable insights for advancing AI-based ensemble
prediction of extreme weather events that have significant societal impacts.

</details>


### [152] [Learning Interpretable Features in Audio Latent Spaces via Sparse Autoencoders](https://arxiv.org/abs/2510.23802)
*Nathan Paek,Yongyi Zang,Qihui Yang,Randal Leistikow*

Main category: cs.LG

TL;DR: 本论文提出了一种框架，利用稀疏自编码器对音频生成模型进行解释，并分析声学属性在生成过程中的演变。


<details>
  <summary>Details</summary>
Motivation: 深入理解音频生成模型的潜在表示与人类可解释的声学概念之间的关系，以便更好地操控和分析AI音乐生成过程。

Method: 通过训练稀疏自编码器（SAEs）在音频自编码器的潜在空间上，然后学习从SAE特征到离散声学属性（音高、振幅和音色）的线性映射。

Result: 提出了一个框架，通过将潜在表示映射到离散的声学属性，实现对音频生成过程的可控操控和分析。

Conclusion: 我们的框架在音频生成领域表现出色，能够揭示生成过程中声学属性的演变，同时可以扩展到视觉生成模型的可解释性分析。

Abstract: While sparse autoencoders (SAEs) successfully extract interpretable features
from language models, applying them to audio generation faces unique
challenges: audio's dense nature requires compression that obscures semantic
meaning, and automatic feature characterization remains limited. We propose a
framework for interpreting audio generative models by mapping their latent
representations to human-interpretable acoustic concepts. We train SAEs on
audio autoencoder latents, then learn linear mappings from SAE features to
discretized acoustic properties (pitch, amplitude, and timbre). This enables
both controllable manipulation and analysis of the AI music generation process,
revealing how acoustic properties emerge during synthesis. We validate our
approach on continuous (DiffRhythm-VAE) and discrete (EnCodec, WavTokenizer)
audio latent spaces, and analyze DiffRhythm, a state-of-the-art text-to-music
model, to demonstrate how pitch, timbre, and loudness evolve throughout
generation. While our work is only done on audio modality, our framework can be
extended to interpretable analysis of visual latent space generation models.

</details>


### [153] [How do simple rotations affect the implicit bias of Adam?](https://arxiv.org/abs/2510.23804)
*Adela DePavia,Vasileios Charisopoulos,Rebecca Willett*

Main category: cs.LG

TL;DR: 研究发现Adam方法在数据分布的旋转下会失去其优势，并提出一种方法以恢复其能力。


<details>
  <summary>Details</summary>
Motivation: 探索自适应梯度方法（如Adam和Adagrad）对机器学习模型泛化能力的影响，尤其是在与传统的梯度下降方法相比时的表现。

Method: 通过实证研究，比较了Adam和梯度下降在不同数据分布下的表现，提出并测试了重新参数化方法以实现对数据旋转的等变性。

Result: 提出了一种重新参数化方法，以提高自适应梯度方法在数据旋转下的均匀性，从而恢复Adam模型对复杂决策边界的偏向。

Conclusion: 重新参数化方法可以增强自适应梯度方法在面对数据旋转时的表现，帮助其维持对富决策边界的偏好。

Abstract: Adaptive gradient methods such as Adam and Adagrad are widely used in machine
learning, yet their effect on the generalization of learned models -- relative
to methods like gradient descent -- remains poorly understood. Prior work on
binary classification suggests that Adam exhibits a ``richness bias,'' which
can help it learn nonlinear decision boundaries closer to the Bayes-optimal
decision boundary relative to gradient descent. However, the coordinate-wise
preconditioning scheme employed by Adam renders the overall method sensitive to
orthogonal transformations of feature space. We show that this sensitivity can
manifest as a reversal of Adam's competitive advantage: even small rotations of
the underlying data distribution can make Adam forfeit its richness bias and
converge to a linear decision boundary that is farther from the Bayes-optimal
decision boundary than the one learned by gradient descent. To alleviate this
issue, we show that a recently proposed reparameterization method -- which
applies an orthogonal transformation to the optimization objective -- endows
any first-order method with equivariance to data rotations, and we empirically
demonstrate its ability to restore Adam's bias towards rich decision
boundaries.

</details>


### [154] [A Physics-informed Multi-resolution Neural Operator](https://arxiv.org/abs/2510.23810)
*Sumanta Roy,Bahador Bahmani,Ioannis G. Kevrekidis,Michael D. Shields*

Main category: cs.LG

TL;DR: 本研究提出了一种融合物理知识的操作学习方法，扩展了无分辨率神经操作框架（RINO）至完全无数据的设置，以解决训练数据质量和分辨率不均的问题。


<details>
  <summary>Details</summary>
Motivation: 解决操作学习框架对高质量训练数据的依赖，尤其是在实际工程应用中数据获取的挑战。

Method: 通过使用预训练基函数将输入函数投影到潜在嵌入空间，利用简单的多层感知器（MLP）近似与偏微分方程（PDE）相关的操作，并在物理空间中通过有限差分求解器实施PDE约束。

Result: 在多分辨率数据的数值示例中进行了验证，显示了该方法在不同分辨率下的有效性和优越性。

Conclusion: 该方法在多分辨率数据的数值示例中表现良好，验证了其有效性。

Abstract: The predictive accuracy of operator learning frameworks depends on the
quality and quantity of available training data (input-output function pairs),
often requiring substantial amounts of high-fidelity data, which can be
challenging to obtain in some real-world engineering applications. These
datasets may be unevenly discretized from one realization to another, with the
grid resolution varying across samples. In this study, we introduce a
physics-informed operator learning approach by extending the Resolution
Independent Neural Operator (RINO) framework to a fully data-free setup,
addressing both challenges simultaneously. Here, the arbitrarily (but
sufficiently finely) discretized input functions are projected onto a latent
embedding space (i.e., a vector space of finite dimensions), using pre-trained
basis functions. The operator associated with the underlying partial
differential equations (PDEs) is then approximated by a simple multi-layer
perceptron (MLP), which takes as input a latent code along with spatiotemporal
coordinates to produce the solution in the physical space. The PDEs are
enforced via a finite difference solver in the physical space. The validation
and performance of the proposed method are benchmarked on several numerical
examples with multi-resolution data, where input functions are sampled at
varying resolutions, including both coarse and fine discretizations.

</details>


### [155] [Combining SHAP and Causal Analysis for Interpretable Fault Detection in Industrial Processes](https://arxiv.org/abs/2510.23817)
*Pedro Cortes dos Santos,Matheus Becali Rocha,Renato A Krohling*

Main category: cs.LG

TL;DR: 本研究开发了一种创新的故障检测框架，通过SHAP和因果分析增强了故障检测的准确性和可解释性，为工业系统监测提供了有效工具。


<details>
  <summary>Details</summary>
Motivation: 工业过程生成的复杂数据使得故障检测系统面临挑战，因此需要一种新的方法来提升检测性能和可解释性。

Method: 利用SHAP（SHapley Additive exPlanations）和有向无环图进行因果分析，识别和分析故障传播的关键机制。

Result: 该框架不仅提高了故障检测的准确性，还为操作人员提供了明确的操作建议，揭示了故障发生的关键元素， 如冷却和分离系统。

Conclusion: 本研究提出了一种创新的故障检测框架，通过结合SHAP和因果分析，显著提升了故障检测的准确性和可解释性，指出关键过程特征，并助力操作人员理解故障来源。

Abstract: Industrial processes generate complex data that challenge fault detection
systems, often yielding opaque or underwhelming results despite advanced
machine learning techniques. This study tackles such difficulties using the
Tennessee Eastman Process, a well-established benchmark known for its intricate
dynamics, to develop an innovative fault detection framework. Initial attempts
with standard models revealed limitations in both performance and
interpretability, prompting a shift toward a more tractable approach. By
employing SHAP (SHapley Additive exPlanations), we transform the problem into a
more manageable and transparent form, pinpointing the most critical process
features driving fault predictions. This reduction in complexity unlocks the
ability to apply causal analysis through Directed Acyclic Graphs, generated by
multiple algorithms, to uncover the underlying mechanisms of fault propagation.
The resulting causal structures align strikingly with SHAP findings,
consistently highlighting key process elements-like cooling and separation
systems-as pivotal to fault development. Together, these methods not only
enhance detection accuracy but also provide operators with clear, actionable
insights into fault origins, a synergy that, to our knowledge, has not been
previously explored in this context. This dual approach bridges predictive
power with causal understanding, offering a robust tool for monitoring complex
manufacturing environments and paving the way for smarter, more interpretable
fault detection in industrial systems.

</details>


### [156] [ScaLoRA: Optimally Scaled Low-Rank Adaptation for Efficient High-Rank Fine-Tuning](https://arxiv.org/abs/2510.23818)
*Yilang Zhang,Xiaodong Yang,Yiwei Cai,Georgios B. Giannakis*

Main category: cs.LG

TL;DR: 提出了一种通过逐步累积高秩权重更新来克服低秩适应（LoRA）限制的方法，以实现高效的任务特定微调。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型的微调过程中，降低计算开销并提高收敛速度是重要目标。

Method: 通过逐步更新低秩增量来形成高秩更新，利用优化的低秩矩阵接近全量微调。

Result: 在使用多达120亿参数的流行大语言模型进行的广泛数值测试中，显示出显著的性能提升。

Conclusion: 该方法在多个任务上表现出一致的性能提升和快速收敛，优于现有的LoRA变体。

Abstract: As large language models (LLMs) continue to scale in size, the computational
overhead has become a major bottleneck for task-specific fine-tuning. While
low-rank adaptation (LoRA) effectively curtails this cost by confining the
weight updates to a low-dimensional subspace, such a restriction can hinder
effectiveness and slow convergence. This contribution deals with these
limitations by accumulating progressively a high-rank weight update from
consecutive low-rank increments. Specifically, the per update optimal low-rank
matrix is identified to minimize the loss function and closely approximate full
fine-tuning. To endow efficient and seamless optimization without restarting,
this optimal choice is formed by appropriately scaling the columns of the
original low-rank matrix. Rigorous performance guarantees reveal that the
optimal scaling can be found analytically. Extensive numerical tests with
popular LLMs scaling up to 12 billion parameters demonstrate a consistent
performance gain and fast convergence relative to state-of-the-art LoRA
variants on diverse tasks including natural language understanding, commonsense
reasoning, and mathematical problem solving.

</details>


### [157] [A PDE-Informed Latent Diffusion Model for 2-m Temperature Downscaling](https://arxiv.org/abs/2510.23866)
*Paul Rosu,Muchang Bahng,Erick Jiang,Rico Zhu,Vahid Tarokh*

Main category: cs.LG

TL;DR: 提出了一种物理条件的潜在扩散模型，用于大气数据的动态降尺度，重点重建高分辨率的2米温度场。


<details>
  <summary>Details</summary>
Motivation: 旨在改进高分辨率气象数据的生成，并确保所生成数据的物理合理性。

Method: 基于现有的扩散架构，采用残差公式并整合偏微分方程损失项，使用像素空间中的全分辨率进行训练。

Result: 通过细调模型与额外的偏微分方程损失，进一步加强了生成场的物理可行性，实验结果显示出改进的效果。

Conclusion: 该模型通过整合偏微分方程损失项，提高了生成场的物理一致性，具备更强的实际应用潜力。

Abstract: This work presents a physics-conditioned latent diffusion model tailored for
dynamical downscaling of atmospheric data, with a focus on reconstructing
high-resolution 2-m temperature fields. Building upon a pre-existing diffusion
architecture and employing a residual formulation against a reference UNet, we
integrate a partial differential equation (PDE) loss term into the model's
training objective. The PDE loss is computed in the full resolution (pixel)
space by decoding the latent representation and is designed to enforce physical
consistency through a finite-difference approximation of an effective
advection-diffusion balance. Empirical observations indicate that conventional
diffusion training already yields low PDE residuals, and we investigate how
fine-tuning with this additional loss further regularizes the model and
enhances the physical plausibility of the generated fields. The entirety of our
codebase is available on Github, for future reference and development.

</details>


### [158] [GIFT: Group-relative Implicit Fine Tuning Integrates GRPO with DPO and UNA](https://arxiv.org/abs/2510.23868)
*Zhichao Wang*

Main category: cs.LG

TL;DR: GIFT是一个新颖的强化学习框架，通过归一化隐式和显式奖励，实现了高效的模型对齐和推理。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统方法在使用隐式奖励时所面临的复杂性和不稳定性，以及提高模型的对齐能力和推理性能。

Method: 通过最小化隐式和显式奖励模型之间的差异而非直接最大化累积奖励来实现。

Result: GIFT实现了更快的收敛、更好的泛化能力和显著减少的训练过拟合，同时在计算上保持高效。

Conclusion: GIFT是一种高效的强化学习框架，能够在对齐大型语言模型的同时保持探索能力，并在数学基准测试中表现出优越的推理和对齐性能。

Abstract: I propose \textbf{G}roup-relative \textbf{I}mplicit \textbf{F}ine
\textbf{T}uning (GIFT), a novel reinforcement learning framework for aligning
LLMs. Instead of directly maximizing cumulative rewards like PPO or GRPO, GIFT
minimizes the discrepancy between implicit and explicit reward models. It
combines three key ideas: (1) the online multi-response generation and
normalization of GRPO, (2) the implicit reward formulation of DPO, and (3) the
implicit-explicit reward alignment principle of UNA. By jointly normalizing the
implicit and explicit rewards, GIFT eliminates an otherwise intractable term
that prevents effective use of implicit rewards. This normalization transforms
the complex reward maximization objective into a simple mean squared error
(MSE) loss between the normalized reward functions, converting a non-convex
optimization problem into a convex, stable, and analytically differentiable
formulation. Unlike offline methods such as DPO and UNA, GIFT remains on-policy
and thus retains exploration capability. Compared to GRPO, it requires fewer
hyperparameters, converges faster, and generalizes better with significantly
reduced training overfitting. Empirically, GIFT achieves superior reasoning and
alignment performance on mathematical benchmarks while remaining
computationally efficient.

</details>


### [159] [RS-ORT: A Reduced-Space Branch-and-Bound Algorithm for Optimal Regression Trees](https://arxiv.org/abs/2510.23901)
*Cristobal Heredia,Pedro Chumpitaz-Flores,Kaixun Hua*

Main category: cs.LG

TL;DR: RS-ORT是一种新颖的回归树训练算法，针对大规模数据和连续特征，显著提升了训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有混合整数规划方法在回归任务中对于连续特征处理的局限性及其计算复杂性问题。

Method: 提出了一种两阶段优化问题的框架，并设计了一种专门的分支限界算法，专注于树结构变量的分支。

Result: RS-ORT在多种回归基准数据集上表现优于现有的最先进方法，能够在大规模数据集上实现高效训练和测试性能。

Conclusion: RS-ORT提供了一种高效且可扩展的回归树训练方法，优于传统方法，特别是在处理大规模连续特征数据方面表现突出。

Abstract: Mixed-integer programming (MIP) has emerged as a powerful framework for
learning optimal decision trees. Yet, existing MIP approaches for regression
tasks are either limited to purely binary features or become computationally
intractable when continuous, large-scale data are involved. Naively binarizing
continuous features sacrifices global optimality and often yields needlessly
deep trees. We recast the optimal regression-tree training as a two-stage
optimization problem and propose Reduced-Space Optimal Regression Trees
(RS-ORT) - a specialized branch-and-bound (BB) algorithm that branches
exclusively on tree-structural variables. This design guarantees the
algorithm's convergence and its independence from the number of training
samples. Leveraging the model's structure, we introduce several bound
tightening techniques - closed-form leaf prediction, empirical threshold
discretization, and exact depth-1 subtree parsing - that combine with
decomposable upper and lower bounding strategies to accelerate the training.
The BB node-wise decomposition enables trivial parallel execution, further
alleviating the computational intractability even for million-size datasets.
Based on the empirical studies on several regression benchmarks containing both
binary and continuous features, RS-ORT also delivers superior training and
testing performance than state-of-the-art methods. Notably, on datasets with up
to 2,000,000 samples with continuous features, RS-ORT can obtain guaranteed
training performance with a simpler tree structure and a better generalization
ability in four hours.

</details>


### [160] [Preference Learning with Response Time: Robust Losses and Guarantees](https://arxiv.org/abs/2505.22820)
*Ayush Sawarni,Sahasrajit Sarmasarkar,Vasilis Syrgkanis*

Main category: cs.LG

TL;DR: 本文探讨了在偏好学习框架中整合响应时间数据，以提升奖励模型的有效性，提出了新方法来结合响应时间和二元选择数据。


<details>
  <summary>Details</summary>
Motivation: 尽管二元偏好数据在微调基础模型中非常关键，但用户决策中蕴含的时间信息尚未得到充分利用，研究这一点可以改善奖励模型的构建。

Method: 采用证据积累漂移扩散（EZ）模型，将响应时间视为偏好强度的指标，并开发了奈曼正交损失函数，以实现奖励模型学习的最佳收敛率。

Result: 通过理论分析和大量实验，证明了响应时间增强的方法在图像偏好学习中的有效性，显著降低了错误率，提高了样本效率。

Conclusion: 通过将响应时间信息整合进偏好学习，模型的样本效率显著提高，从而在奖励函数学习中表现出更好的收敛性和准确性。

Abstract: This paper investigates the integration of response time data into human
preference learning frameworks for more effective reward model elicitation.
While binary preference data has become fundamental in fine-tuning foundation
models, generative AI systems, and other large-scale models, the valuable
temporal information inherent in user decision-making remains largely
unexploited. We propose novel methodologies to incorporate response time
information alongside binary choice data, leveraging the Evidence Accumulation
Drift Diffusion (EZ) model, under which response time is informative of the
preference strength. We develop Neyman-orthogonal loss functions that achieve
oracle convergence rates for reward model learning, matching the theoretical
optimal rates that would be attained if the expected response times for each
query were known a priori. Our theoretical analysis demonstrates that for
linear reward functions, conventional preference learning suffers from error
rates that scale exponentially with reward magnitude. In contrast, our response
time-augmented approach reduces this to polynomial scaling, representing a
significant improvement in sample efficiency. We extend these guarantees to
non-parametric reward function spaces, establishing convergence properties for
more complex, realistic reward models. Our extensive experiments validate our
theoretical findings in the context of preference learning over images.

</details>


### [161] [Key and Value Weights Are Probably All You Need: On the Necessity of the Query, Key, Value weight Triplet in Decoder-Only Transformers](https://arxiv.org/abs/2510.23912)
*Marko Karbevski,Antonij Mijoski*

Main category: cs.LG

TL;DR: 研究表明，Query权重在注意力机制中是冗余的，减少后提升了模型效率。


<details>
  <summary>Details</summary>
Motivation: 探索Query权重的冗余性，以减少模型参数并提高效率。

Method: 理论研究与实验验证

Result: 通过简化假设证明Query权重冗余，非嵌入/语言模型头参数减少超过8%。在完整复杂度的GPT-3小型架构上验证了理论，减少后的模型在验证损失上与标准基线相当。

Conclusion: 这一发现激励了对大规模模型中Query权重冗余性的进一步研究。

Abstract: The Query, Key, Value weight triplet is a building block of current attention
mechanisms in state-of-the-art LLMs. We theoretically investigate whether this
triplet can be reduced, proving under simplifying assumptions that the Query
weights are redundant, thereby reducing the number of non-embedding/lm-head
parameters by over 8%. We validate the theory on full-complexity GPT-3 small
architectures (with layer normalization, skip connections, and weight decay)
trained from scratch, demonstrating that the reduced model achieves comparable
validation loss to standard baselines. These findings motivate the
investigation of the Query weight redundancy at scale.

</details>


### [162] [Geometry-Inspired Unified Framework for Discounted and Average Reward MDPs](https://arxiv.org/abs/2510.23914)
*Arsenii Mustafin,Xinyi Sheng,Dominik Baumann*

Main category: cs.LG

TL;DR: 扩展了MDPs的几何解释，将平均收益和折扣收益案例统一，并证明了在独特的遍历最优策略下，价值迭代算法在平均收益案例中也具有几何收敛率。


<details>
  <summary>Details</summary>
Motivation: 统一对平均收益和折扣收益案例的分析，以便更全面地理解马尔可夫决策过程（MDPs）的行为。

Method: 理论分析

Result: 通过将折扣收益案例的几何解释扩展到平均收益案例，实现了两者的统一，并推广了对于折扣收益案例的主要结果至平均收益案例。

Conclusion: 在独特且遍历的最优策略下，价值迭代算法在平均收益情况下达到了几何收敛速率。

Abstract: The theoretical analysis of Markov Decision Processes (MDPs) is commonly
split into two cases - the average-reward case and the discounted-reward case -
which, while sharing similarities, are typically analyzed separately. In this
work, we extend a recently introduced geometric interpretation of MDPs for the
discounted-reward case to the average-reward case, thereby unifying both. This
allows us to extend a major result known for the discounted-reward case to the
average-reward case: under a unique and ergodic optimal policy, the Value
Iteration algorithm achieves a geometric convergence rate.

</details>


### [163] [Differential Privacy: Gradient Leakage Attacks in Federated Learning Environments](https://arxiv.org/abs/2510.23931)
*Miguel Fernandez-de-Retana,Unai Zulaika,Rubén Sánchez-Corcuera,Aitor Almeida*

Main category: cs.LG

TL;DR: 本研究探讨了差分隐私机制（DP-SGD和PDP-SGD）在联邦学习中对梯度泄露攻击的防御效果，结果显示DP-SGD能有效降低攻击风险，而PDP-SGD则在分类性能上强劲但防御效果不佳。


<details>
  <summary>Details</summary>
Motivation: 随着联邦学习的广泛应用，如何保护敏感数据不被泄露成为一个重要挑战，因此需要研究有效的防御策略。

Method: 通过在模拟的联邦学习环境中训练多个计算机视觉模型，评估不同隐私级别对分类任务的影响，并分析拦截梯度获得的私人数据重建质量。

Result: 研究结果表明，DP-SGD显著减轻了梯度泄露攻击的风险，但伴随了一定的模型效用下降，而PDP-SGD在分类任务中表现优异但对重建攻击防御效果有限。

Conclusion: DP-SGD在防御梯度泄露攻击方面表现出色，但需牺牲一定的模型效用；而PDP-SGD保持分类性能，但对重建攻击无效，揭示了在分布式学习中评估隐私机制的重要性。

Abstract: Federated Learning (FL) allows for the training of Machine Learning models in
a collaborative manner without the need to share sensitive data. However, it
remains vulnerable to Gradient Leakage Attacks (GLAs), which can reveal private
information from the shared model updates. In this work, we investigate the
effectiveness of Differential Privacy (DP) mechanisms - specifically, DP-SGD
and a variant based on explicit regularization (PDP-SGD) - as defenses against
GLAs. To this end, we evaluate the performance of several computer vision
models trained under varying privacy levels on a simple classification task,
and then analyze the quality of private data reconstructions obtained from the
intercepted gradients in a simulated FL environment. Our results demonstrate
that DP-SGD significantly mitigates the risk of gradient leakage attacks,
albeit with a moderate trade-off in model utility. In contrast, PDP-SGD
maintains strong classification performance but proves ineffective as a
practical defense against reconstruction attacks. These findings highlight the
importance of empirically evaluating privacy mechanisms beyond their
theoretical guarantees, particularly in distributed learning scenarios where
information leakage may represent an unassumable critical threat to data
security and privacy.

</details>


### [164] [ChessQA: Evaluating Large Language Models for Chess Understanding](https://arxiv.org/abs/2510.23948)
*Qianfeng Wen,Zhenwei Tang,Ashton Anderson*

Main category: cs.LG

TL;DR: ChessQA是一个全面的基准，用于评估大型语言模型的国际象棋理解能力，超越了传统的简单移动质量评估。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在国际象棋理解方面的能力，填补现有评估方法的不足

Method: 提出ChessQA基准

Result: 发现当前的主流语言模型在五个分类下都有持续的弱点，并提供了各类别的结果和错误分析

Conclusion: ChessQA提供了一个动态且系统化的平台，能有效支持未来的研究。

Abstract: Chess provides an ideal testbed for evaluating the reasoning, modeling, and
abstraction capabilities of large language models (LLMs), as it has
well-defined structure and objective ground truth while admitting a wide
spectrum of skill levels. However, existing evaluations of LLM ability in chess
are ad hoc and narrow in scope, making it difficult to accurately measure LLM
chess understanding and how it varies with scale, post-training methodologies,
or architecture choices. We present ChessQA, a comprehensive benchmark that
assesses LLM chess understanding across five task categories (Structural,
Motifs, Short Tactics, Position Judgment, and Semantic), which approximately
correspond to the ascending abstractions that players master as they accumulate
chess knowledge, from understanding basic rules and learning tactical motifs to
correctly calculating tactics, evaluating positions, and semantically
describing high-level concepts. In this way, ChessQA captures a more
comprehensive picture of chess ability and understanding, going significantly
beyond the simple move quality evaluations done previously, and offers a
controlled, consistent setting for diagnosis and comparison. Furthermore,
ChessQA is inherently dynamic, with prompts, answer keys, and construction
scripts that can evolve as models improve. Evaluating a range of contemporary
LLMs, we find persistent weaknesses across all five categories and provide
results and error analyses by category. We will release the code, periodically
refreshed datasets, and a public leaderboard to support further research.

</details>


### [165] [A Pragmatic Way to Measure Chain-of-Thought Monitorability](https://arxiv.org/abs/2510.23966)
*Scott Emmons,Roland S. Zimmermann,David K. Elson,Rohin Shah*

Main category: cs.LG

TL;DR: 本研究提出了评估Chain-of-Thought监控能力的实用方法，旨在确保AI安全性。


<details>
  <summary>Details</summary>
Motivation: 确保AI安全性通过持续监控Chain-of-Thought，避免因训练实践或模型架构的变化而损失监控能力。

Method: 使用生成的自动评分提示来评估逻辑的清晰度和覆盖率，适用于不同的前沿模型。

Result: 在多个前沿模型上进行评价，结果显示这些模型具有较高的可监控性。

Conclusion: 提出了一种测量Chain-of-Thought监控可行性的实用方法，并确保在模型设计中关注可监控性。

Abstract: While Chain-of-Thought (CoT) monitoring offers a unique opportunity for AI
safety, this opportunity could be lost through shifts in training practices or
model architecture. To help preserve monitorability, we propose a pragmatic way
to measure two components of it: legibility (whether the reasoning can be
followed by a human) and coverage (whether the CoT contains all the reasoning
needed for a human to also produce the final output). We implement these
metrics with an autorater prompt that enables any capable LLM to compute the
legibility and coverage of existing CoTs. After sanity-checking our prompted
autorater with synthetic CoT degradations, we apply it to several frontier
models on challenging benchmarks, finding that they exhibit high
monitorability. We present these metrics, including our complete autorater
prompt, as a tool for developers to track how design decisions impact
monitorability. While the exact prompt we share is still a preliminary version
under ongoing development, we are sharing it now in the hopes that others in
the community will find it useful. Our method helps measure the default
monitorability of CoT - it should be seen as a complement, not a replacement,
for the adversarial stress-testing needed to test robustness against
deliberately evasive models.

</details>


### [166] [An efficient probabilistic hardware architecture for diffusion-like models](https://arxiv.org/abs/2510.23972)
*Andraž Jelinčič,Owen Lockwood,Akhil Garlapati,Guillaume Verdon,Trevor McCourt*

Main category: cs.LG

TL;DR: 本文提出了一种新型全晶体管概率计算机，能显著降低能耗并在性能上与GPU相媲美。


<details>
  <summary>Details</summary>
Motivation: 随着概率人工智能的普及，提出了专门的随机计算机方案，但由于建模技术和硬件的限制，这些方案未能得到广泛采用。

Method: 采用全晶体管架构实现去噪模型，并通过系统分析评估性能和能耗。

Result: 本文提出了一种全晶体管的概率计算机，可以在硬件层面实现强大的去噪模型，并通过系统层面的分析表明，该架构可在简单图像基准上达到与GPU平行的性能，同时能耗减少约10,000倍。

Conclusion: 新的全晶体管概率计算机能够克服现有硬件的局限，以更高效的方式执行复杂计算任务。

Abstract: The proliferation of probabilistic AI has promoted proposals for specialized
stochastic computers. Despite promising efficiency gains, these proposals have
failed to gain traction because they rely on fundamentally limited modeling
techniques and exotic, unscalable hardware. In this work, we address these
shortcomings by proposing an all-transistor probabilistic computer that
implements powerful denoising models at the hardware level. A system-level
analysis indicates that devices based on our architecture could achieve
performance parity with GPUs on a simple image benchmark using approximately
10,000 times less energy.

</details>


### [167] [Diffusion Adaptive Text Embedding for Text-to-Image Diffusion Models](https://arxiv.org/abs/2510.23974)
*Byeonghu Na,Minsang Park,Gyuwon Sim,Donghyeok Shin,HeeSun Bae,Mina Kang,Se Jung Kwon,Wanmo Kang,Il-Chul Moon*

Main category: cs.LG

TL;DR: 提出DATE，通过动态更新文本嵌入提升文本与图像的对齐，改善生成性能。


<details>
  <summary>Details</summary>
Motivation: 解决固定文本嵌入在生成过程中适应性不足的问题，提高生成图像与文本的对齐度。

Method: 通过优化问题的制定和更新规则的推导，在扩散采样的每个步骤动态调整文本嵌入。

Result: 本文提出了一种新的文本到图像扩散模型方法Diffusion Adaptive Text Embedding (DATE)，通过在每个扩散时间步动态更新文本嵌入，克服了固定文本嵌入的局限性。通过理论分析和实证结果，我们证明了DATE在不同任务中的表现优于传统固定文本嵌入，尤其是在多概念生成和文本引导的图像编辑中。

Conclusion: DATE在多种任务中表现出优越的文本与图像对齐能力，保持了模型的生成能力。

Abstract: Text-to-image diffusion models rely on text embeddings from a pre-trained
text encoder, but these embeddings remain fixed across all diffusion timesteps,
limiting their adaptability to the generative process. We propose Diffusion
Adaptive Text Embedding (DATE), which dynamically updates text embeddings at
each diffusion timestep based on intermediate perturbed data. We formulate an
optimization problem and derive an update rule that refines the text embeddings
at each sampling step to improve alignment and preference between the mean
predicted image and the text. This allows DATE to dynamically adapts the text
conditions to the reverse-diffused images throughout diffusion sampling without
requiring additional model training. Through theoretical analysis and empirical
results, we show that DATE maintains the generative capability of the model
while providing superior text-image alignment over fixed text embeddings across
various tasks, including multi-concept generation and text-guided image
editing. Our code is available at https://github.com/aailab-kaist/DATE.

</details>


### [168] [Optimal Arm Elimination Algorithms for Combinatorial Bandits](https://arxiv.org/abs/2510.23992)
*Yuxiao Wen,Yanjun Han,Zhengyuan Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种新型的消除方案，针对组合型强盗问题实现了接近最优的表现。


<details>
  <summary>Details</summary>
Motivation: 组合型强盗问题扩展了经典强盗框架，适用于多臂选择的情况，如在线推荐和组合优化。

Method: 提出了一种新的消除方案，将臂分为三个类别（确认、活跃和消除），并纳入显式探索以更新这些类别。

Result: 在组合多臂强盗及组合线性上下文强盗的设置中，算法展现了有效性，达到接近最优的遗憾水平。

Conclusion: 通过匹配下界，证明了该算法在显式探索方面的优势，避免了UCB方法的潜在失败。

Abstract: Combinatorial bandits extend the classical bandit framework to settings where
the learner selects multiple arms in each round, motivated by applications such
as online recommendation and assortment optimization. While extensions of upper
confidence bound (UCB) algorithms arise naturally in this context, adapting arm
elimination methods has proved more challenging. We introduce a novel
elimination scheme that partitions arms into three categories (confirmed,
active, and eliminated), and incorporates explicit exploration to update these
sets. We demonstrate the efficacy of our algorithm in two settings: the
combinatorial multi-armed bandit with general graph feedback, and the
combinatorial linear contextual bandit. In both cases, our approach achieves
near-optimal regret, whereas UCB-based methods can provably fail due to
insufficient explicit exploration. Matching lower bounds are also provided.

</details>


### [169] [Predicting Barge Tow Size on Inland Waterways Using Vessel Trajectory Derived Features: Proof of Concept](https://arxiv.org/abs/2510.23994)
*Geoffery Agorku,Sarah Hernandez,Hayley Hames,Cade Wagner*

Main category: cs.LG

TL;DR: 本文提出了一种基于机器学习的创新方法，利用AIS跟踪数据实时预测内陆水道上的驳船数量，结果显示Poisson回归模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 提高内陆水道驳船数量的实时准确估计，以应对现有监测系统的局限性。

Method: 使用手动标注的卫星图像与AIS轨迹数据配对，并通过递归特征消除法提取和评估特征，训练多种回归模型以预测驳船数量。

Result: 通过机器学习和AIS数据，提出了一种预测驳船数量的创新方法，取得了最优表现的模型。

Conclusion: 该方法对于提高海事领域的监控能力有潜在的应用前景，可拓展到其他内陆河流的模型转移性研究。

Abstract: Accurate, real-time estimation of barge quantity on inland waterways remains
a critical challenge due to the non-self-propelled nature of barges and the
limitations of existing monitoring systems. This study introduces a novel
method to use Automatic Identification System (AIS) vessel tracking data to
predict the number of barges in tow using Machine Learning (ML). To train and
test the model, barge instances were manually annotated from satellite scenes
across the Lower Mississippi River. Labeled images were matched to AIS vessel
tracks using a spatiotemporal matching procedure. A comprehensive set of 30
AIS-derived features capturing vessel geometry, dynamic movement, and
trajectory patterns were created and evaluated using Recursive Feature
Elimination (RFE) to identify the most predictive variables. Six regression
models, including ensemble, kernel-based, and generalized linear approaches,
were trained and evaluated. The Poisson Regressor model yielded the best
performance, achieving a Mean Absolute Error (MAE) of 1.92 barges using 12 of
the 30 features. The feature importance analysis revealed that metrics
capturing vessel maneuverability such as course entropy, speed variability and
trip length were most predictive of barge count. The proposed approach provides
a scalable, readily implementable method for enhancing Maritime Domain
Awareness (MDA), with strong potential applications in lock scheduling, port
management, and freight planning. Future work will expand the proof of concept
presented here to explore model transferability to other inland rivers with
differing operational and environmental conditions.

</details>


### [170] [Training-Free Safe Text Embedding Guidance for Text-to-Image Diffusion Models](https://arxiv.org/abs/2510.24012)
*Byeonghu Na,Mina Kang,Jiseok Kwak,Minsang Park,Jiwoo Shin,SeJoon Jun,Gayoung Lee,Jin-Hwa Kim,Il-Chul Moon*

Main category: cs.LG

TL;DR: 本文提出了STG方法，通过调整文本嵌入来提高文本到图像模型的安全性，无需额外训练，实验结果显示该方法在移除不安全内容方面效果显著。


<details>
  <summary>Details</summary>
Motivation: 鉴于现有数据集中存在的不当或偏见内容，本文旨在减少模型生成有害输出的风险。

Method: 本方法为训练无关，通过在采样过程中根据安全函数调整文本嵌入，确保生成过程符合安全约束。

Result: 本文提出了一种名为安全文本嵌入引导（STG）的新方法，旨在提高文本到图像生成模型的安全性。该方法通过在采样过程中指导文本嵌入，避免了需要额外训练的过程。STG根据对预期去噪图像的安全函数对文本嵌入进行调整，从而使模型能够生成更安全的输出，同时保持生成质量。本研究通过理论分析和实验验证了STG的有效性，在去除不安全内容的同时，保持输入提示的核心语义意图。

Conclusion: 安全文本嵌入引导（STG）方法通过在无额外训练的情况下，提高文本到图像生成模型的安全性，提供了一种有效的解决方案。

Abstract: Text-to-image models have recently made significant advances in generating
realistic and semantically coherent images, driven by advanced diffusion models
and large-scale web-crawled datasets. However, these datasets often contain
inappropriate or biased content, raising concerns about the generation of
harmful outputs when provided with malicious text prompts. We propose Safe Text
embedding Guidance (STG), a training-free approach to improve the safety of
diffusion models by guiding the text embeddings during sampling. STG adjusts
the text embeddings based on a safety function evaluated on the expected final
denoised image, allowing the model to generate safer outputs without additional
training. Theoretically, we show that STG aligns the underlying model
distribution with safety constraints, thereby achieving safer outputs while
minimally affecting generation quality. Experiments on various safety
scenarios, including nudity, violence, and artist-style removal, show that STG
consistently outperforms both training-based and training-free baselines in
removing unsafe content while preserving the core semantic intent of input
prompts. Our code is available at https://github.com/aailab-kaist/STG.

</details>


### [171] [Efficient Global-Local Fusion Sampling for Physics-Informed Neural Networks](https://arxiv.org/abs/2510.24026)
*Jiaqi Luo,Shixin Xu,Zhouwang Yang*

Main category: cs.LG

TL;DR: 提出了一种新颖的GLF采样策略，提升了PINNs在求解PDE时的性能。


<details>
  <summary>Details</summary>
Motivation: PINNs的准确性依赖于配点的放置，现有方法在稳定性与效率之间存在折衷。

Method: 提出一种全球-局部融合（GLF）采样策略，结合全局和局部采样的优点。

Result: GLF策略通过调整训练点并引入线性替代模型，提高了PINNs在处理复杂PDE时的准确性和效率。

Conclusion: GLF策略通过结合全局和局部方法，实现了PINNs在高维PDE求解中的稳健性和效率。

Abstract: The accuracy of Physics-Informed Neural Networks (PINNs) critically depends
on the placement of collocation points, as the PDE loss is approximated through
sampling over the solution domain. Global sampling ensures stability by
covering the entire domain but requires many samples and is computationally
expensive, whereas local sampling improves efficiency by focusing on
high-residual regions but may neglect well-learned areas, reducing robustness.
We propose a Global-Local Fusion (GLF) Sampling Strategy that combines the
strengths of both approaches. Specifically, new collocation points are
generated by perturbing training points with Gaussian noise scaled inversely to
the residual, thereby concentrating samples in difficult regions while
preserving exploration. To further reduce computational overhead, a lightweight
linear surrogate is introduced to approximate the global residual-based
distribution, achieving similar effectiveness at a fraction of the cost.
Together, these components, residual-adaptive sampling and residual-based
approximation, preserve the stability of global methods while retaining the
efficiency of local refinement. Extensive experiments on benchmark PDEs
demonstrate that GLF consistently improves both accuracy and efficiency
compared with global and local sampling strategies. This study provides a
practical and scalable framework for enhancing the reliability and efficiency
of PINNs in solving complex and high-dimensional PDEs.

</details>


### [172] [Spatio-temporal Multivariate Time Series Forecast with Chosen Variables](https://arxiv.org/abs/2510.24027)
*Zibo Liu,Zhe Jiang,Zelin Xu,Tingsong Xiao,Yupu Zhang,Zhengkun Xiao,Haibo Wang,Shigang Chen*

Main category: cs.LG

TL;DR: 本文提出了一种优化输入变量选择的空间-时间多元时间序列预测新方法，显著提升了预测精度与模型效率。


<details>
  <summary>Details</summary>
Motivation: 解决传感应用中由于传感器数量不足造成的缺失变量问题，并研究如何选择输入变量以最大化预测精度。

Method: 提出一个统一框架，联合执行变量选择和模型优化，以提高预测准确性和模型效率。

Result: 实验结果表明，所提方法在准确性和效率上显著优于最新的基线模型。

Conclusion: 通过联合执行变量选择和模型优化，该方法有效提升了STMF的预测性能，适用于实际应用场景。

Abstract: Spatio-Temporal Multivariate time series Forecast (STMF) uses the time series
of $n$ spatially distributed variables in a period of recent past to forecast
their values in a period of near future. It has important applications in
spatio-temporal sensing forecast such as road traffic prediction and air
pollution prediction. Recent papers have addressed a practical problem of
missing variables in the model input, which arises in the sensing applications
where the number $m$ of sensors is far less than the number $n$ of locations to
be monitored, due to budget constraints. We observe that the state of the art
assumes that the $m$ variables (i.e., locations with sensors) in the model
input are pre-determined and the important problem of how to choose the $m$
variables in the input has never been studied. This paper fills the gap by
studying a new problem of STMF with chosen variables, which optimally selects
$m$-out-of-$n$ variables for the model input in order to maximize the forecast
accuracy. We propose a unified framework that jointly performs variable
selection and model optimization for both forecast accuracy and model
efficiency. It consists of three novel technical components: (1) masked
variable-parameter pruning, which progressively prunes less informative
variables and attention parameters through quantile-based masking; (2)
prioritized variable-parameter replay, which replays low-loss past samples to
preserve learned knowledge for model stability; (3) dynamic extrapolation
mechanism, which propagates information from variables selected for the input
to all other variables via learnable spatial embeddings and adjacency
information. Experiments on five real-world datasets show that our work
significantly outperforms the state-of-the-art baselines in both accuracy and
efficiency, demonstrating the effectiveness of joint variable selection and
model optimization.

</details>


### [173] [GraphNet: A Large-Scale Computational Graph Dataset for Tensor Compiler Research](https://arxiv.org/abs/2510.24035)
*Xinqi Li,Yiqun Liu,Shan Jiang,Enrong Zheng,Huaijin Zheng,Wenhao Dai,Haodong Deng,Dianhai Yu,Yanjun Ma*

Main category: cs.LG

TL;DR: 本文介绍了GraphNet数据集及其评估张量编译器性能的方法，提供了一种多维度的性能评估指标。


<details>
  <summary>Details</summary>
Motivation: 为了评估张量编译器在深度学习计算图上的性能，提出了GraphNet数据集和评估指标。

Method: 创建一个包含多种深度学习框架的计算图数据集，并提出新的性能基准指标来评估和比较张量编译器。

Result: 通过GraphNet数据集和Speedup Score S(t)指标，对多种张量编译器在计算机视觉和自然语言处理任务中的表现进行了基准测试。

Conclusion: 通过对比不同编译器的性能，识别出关键的性能瓶颈，并为编译器开发者提供了有效的参考。

Abstract: We introduce GraphNet, a dataset of 2.7K real-world deep learning
computational graphs with rich metadata, spanning six major task categories
across multiple deep learning frameworks. To evaluate tensor compiler
performance on these samples, we propose the benchmark metric Speedup Score
S(t), which jointly considers runtime speedup and execution correctness under
tunable tolerance levels, offering a reliable measure of general optimization
capability. Furthermore, we extend S(t) to the Error-aware Speedup Score ES(t),
which incorporates error information and helps compiler developers identify key
performance bottlenecks. In this report, we benchmark the default tensor
compilers, CINN for PaddlePaddle and TorchInductor for PyTorch, on computer
vision (CV) and natural language processing (NLP) samples to demonstrate the
practicality of GraphNet. The full construction pipeline with graph extraction
and compiler evaluation tools is available at
https://github.com/PaddlePaddle/GraphNet .

</details>


### [174] [Localized Kernel Projection Outlyingness: A Two-Stage Approach for Multi-Modal Outlier Detection](https://arxiv.org/abs/2510.24043)
*Akira Tamamori*

Main category: cs.LG

TL;DR: 提出了一种新颖的两阶段LKPLO框架，用于解决传统投影方法的局限性，通过灵活的损失函数、全局核PCA和局部聚类相结合的方式，显著提高了异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统异常检测方法依赖固定统计度量和单一数据结构的局限性。

Method: 通过引入灵活的损失函数、全局核PCA和局部聚类，构建了一种新型的多阶段异常检测框架。

Result: 通过5-fold交叉验证和超参数优化，Two-Stage LKPLO在多个具有挑战性的数据集上表现出色，尤其在多簇数据和复杂高维数据集上显著优于现有方法。

Conclusion: 两阶段LKPLO是异常检测领域的一个强大新工具，强调了混合多阶段结构的重要性。

Abstract: This paper presents Two-Stage LKPLO, a novel multi-stage outlier detection
framework that overcomes the coexisting limitations of conventional
projection-based methods: their reliance on a fixed statistical metric and
their assumption of a single data structure. Our framework uniquely synthesizes
three key concepts: (1) a generalized loss-based outlyingness measure (PLO)
that replaces the fixed metric with flexible, adaptive loss functions like our
proposed SVM-like loss; (2) a global kernel PCA stage to linearize non-linear
data structures; and (3) a subsequent local clustering stage to handle
multi-modal distributions. Comprehensive 5-fold cross-validation experiments on
10 benchmark datasets, with automated hyperparameter optimization, demonstrate
that Two-Stage LKPLO achieves state-of-the-art performance. It significantly
outperforms strong baselines on datasets with challenging structures where
existing methods fail, most notably on multi-cluster data (Optdigits) and
complex, high-dimensional data (Arrhythmia). Furthermore, an ablation study
empirically confirms that the synergistic combination of both the kernelization
and localization stages is indispensable for its superior performance. This
work contributes a powerful new tool for a significant class of outlier
detection problems and underscores the importance of hybrid, multi-stage
architectures.

</details>


### [175] [Mitigating Negative Transfer via Reducing Environmental Disagreement](https://arxiv.org/abs/2510.24044)
*Hui Sun,Zheng Xie,Hao-Yuan He,Ming Li*

Main category: cs.LG

TL;DR: 本研究提出RED方法，通过解缠因果与环境特征，减轻了负迁移问题，并取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 研究负迁移现象并通过因果解缠学习的视角理解其成因，尤其关注非因果环境特征导致的跨领域判别不一致性。

Method: 通过对抗性训练对样本进行解缠，提取领域不变的因果特征和领域特定的非因果环境特征，并估计和减少环境不一致性。

Result: 实验结果证实了RED方法在减轻负迁移方面的有效性，并达到了最先进的性能。

Conclusion: 该研究提出的RED方法有效减轻了负迁移，并取得了最先进的性能。

Abstract: Unsupervised Domain Adaptation~(UDA) focuses on transferring knowledge from a
labeled source domain to an unlabeled target domain, addressing the challenge
of \emph{domain shift}. Significant domain shifts hinder effective knowledge
transfer, leading to \emph{negative transfer} and deteriorating model
performance. Therefore, mitigating negative transfer is essential. This study
revisits negative transfer through the lens of causally disentangled learning,
emphasizing cross-domain discriminative disagreement on non-causal
environmental features as a critical factor. Our theoretical analysis reveals
that overreliance on non-causal environmental features as the environment
evolves can cause discriminative disagreements~(termed \emph{environmental
disagreement}), thereby resulting in negative transfer. To address this, we
propose Reducing Environmental Disagreement~(RED), which disentangles each
sample into domain-invariant causal features and domain-specific non-causal
environmental features via adversarially training domain-specific environmental
feature extractors in the opposite domains. Subsequently, RED estimates and
reduces environmental disagreement based on domain-specific non-causal
environmental features. Experimental results confirm that RED effectively
mitigates negative transfer and achieves state-of-the-art performance.

</details>


### [176] [Causal-Aware Generative Adversarial Networks with Reinforcement Learning](https://arxiv.org/abs/2510.24046)
*Tu Anh Hoang Nguyen,Dang Nguyen,Tri-Nhan Vo,Thuc Duy Le,Sunil Gupta*

Main category: cs.LG

TL;DR: CA-GAN是一种新型生成框架，旨在处理表格数据的隐私和效用问题，利用因果图提取和强化学习目标提升生成数据的质量与隐私保障能力。


<details>
  <summary>Details</summary>
Motivation: 针对现有数据生成方法在捕捉复杂因果关系、保持数据效用及隐私保证方面的不足，提供一种高效、适应实际应用的解决方案。

Method: 使用因果图提取与条件WGAN-GP相结合的两步法，结合强化学习的目标进行生成器训练。

Result: 本文提出了一种名为CA-GAN的新生成框架，旨在解决实际表格数据集中的复杂因果关系捕捉、数据效用保持及隐私保障等挑战。CA-GAN采用两步法：首先进行因果图提取，以学习数据流形中的稳健因果关系；接着使用针对因果图节点结构定制的条件WGAN-GP进行生成。其中，生成器采用基于强化学习的新目标进行训练，以确保从真实和虚假数据中构建的因果图在训练和采样阶段均具备因果意识。本研究在14个表格数据集上对比评估了CA-GAN与六种最先进方法的性能，在因果保护、效用保护和隐私保护等核心数据工程指标上展现了优越性。

Conclusion: CA-GAN在保护数据隐私的同时，能够有效捕捉复杂的因果关系，为数据工程师提供高性能、隐私合规的合成数据生成解决方案。

Abstract: The utility of tabular data for tasks ranging from model training to
large-scale data analysis is often constrained by privacy concerns or
regulatory hurdles. While existing data generation methods, particularly those
based on Generative Adversarial Networks (GANs), have shown promise, they
frequently struggle with capturing complex causal relationship, maintaining
data utility, and providing provable privacy guarantees suitable for enterprise
deployment. We introduce CA-GAN, a novel generative framework specifically
engineered to address these challenges for real-world tabular datasets. CA-GAN
utilizes a two-step approach: causal graph extraction to learn a robust,
comprehensive causal relationship in the data's manifold, followed by a custom
Conditional WGAN-GP (Wasserstein GAN with Gradient Penalty) that operates
exclusively as per the structure of nodes in the causal graph. More
importantly, the generator is trained with a new Reinforcement Learning-based
objective that aligns the causal graphs constructed from real and fake data,
ensuring the causal awareness in both training and sampling phases. We
demonstrate CA-GAN superiority over six SOTA methods across 14 tabular
datasets. Our evaluations, focused on core data engineering metrics: causal
preservation, utility preservation, and privacy preservation. Our method offers
a practical, high-performance solution for data engineers seeking to create
high-quality, privacy-compliant synthetic datasets to benchmark database
systems, accelerate software development, and facilitate secure data-driven
research.

</details>


### [177] [Low-N Protein Activity Optimization with FolDE](https://arxiv.org/abs/2510.24053)
*Jacob B. Roberts,Catherine R. Ji,Isaac Donnell,Thomas D. Young,Allison N. Pearson,Graham A. Hudson,Leah S. Keiser,Mia Wesselkamper,Peter H. Winegar,Janik Ludwig,Sarah H. Klass,Isha V. Sheth,Ezechinyere C. Ukabiala,Maria C. T. Astolfi,Benjamin Eysenbach,Jay D. Keasling*

Main category: cs.LG

TL;DR: FolDE是一种新型ALDE方法，通过改进数据多样性和活动预测，显著提升了蛋白质突变体的发现效率，并使这一技术对更多实验室可及。


<details>
  <summary>Details</summary>
Motivation: 开发一种能有效减少蛋白质优化成本的技术，同时提高选择最佳突变体的准确性，使得各实验室能更便捷地进行蛋白质优化。

Method: FolDE利用蛋白质语言模型的输出结合有限的活性测量，并通过常量撒谎者批量选择器来提升训练数据的多样性。

Result: 本研究提出了一种名为FolDE的主动学习辅助定向进化(ALDE)方法，旨在优化蛋白质的开发成本和准确性。相较于现有的ALDE方法，FolDE在20个蛋白质目标的仿真实验中表现出色，能够发现23%的顶尖突变体，并且找到顶尖1%突变体的概率提高了55%。该方法通过基于自然性的热启动和引入常量撒谎者批量选择器来提升突变体的多样性，从而提高了整个实验的成功率。此完整工作流程作为开源软件提供，便于其他实验室的高效蛋白质优化。

Conclusion: FolDE方法通过改进的预测和多样性选择机制，提高了蛋白质突变体的优化效率，并公开了软件以促进科学研究。

Abstract: Proteins are traditionally optimized through the costly construction and
measurement of many mutants. Active Learning-assisted Directed Evolution (ALDE)
alleviates that cost by predicting the best improvements and iteratively
testing mutants to inform predictions. However, existing ALDE methods face a
critical limitation: selecting the highest-predicted mutants in each round
yields homogeneous training data insufficient for accurate prediction models in
subsequent rounds. Here we present FolDE, an ALDE method designed to maximize
end-of-campaign success. In simulations across 20 protein targets, FolDE
discovers 23% more top 10% mutants than the best baseline ALDE method (p=0.005)
and is 55% more likely to find top 1% mutants. FolDE achieves this primarily
through naturalness-based warm-starting, which augments limited activity
measurements with protein language model outputs to improve activity
prediction. We also introduce a constant-liar batch selector, which improves
batch diversity; this is important in multi-mutation campaigns but had limited
effect in our benchmarks. The complete workflow is freely available as
open-source software, making efficient protein optimization accessible to any
laboratory.

</details>


### [178] [FALQON: Accelerating LoRA Fine-tuning with Low-Bit Floating-Point Arithmetic](https://arxiv.org/abs/2510.24061)
*Kanghyun Choi,Hyeyoon Lee,SunJong Park,Dain Kwon,Jinho Lee*

Main category: cs.LG

TL;DR: FALQON框架通过优化FP8量化和LoRA结合，实现高效的大规模模型微调，提供约3倍加速。


<details>
  <summary>Details</summary>
Motivation: 探究FP8量化在低秩适应（LoRA）中的局限性，并寻求改进大语言模型的微调效率。

Method: 提出FALQON框架，通过将LoRA适配器直接合并到FP8量化的主干中来消除量化开销，并重构前向和后向计算以减少开销。

Result: FALQON实现了大约3倍的训练加速，与现有方法在准确性方面相当。

Conclusion: FALQON提供了一种有效的解决方案，通过消除量化开销，实现了大规模模型微调的高效性。

Abstract: Low-bit floating-point (FP) formats, such as FP8, provide significant
acceleration and memory savings in model training thanks to native hardware
support on modern GPUs and NPUs. However, we analyze that FP8 quantization
offers speedup primarily for large-dimensional matrix multiplications, while
inherent quantization overheads diminish speedup when applied to low-rank
adaptation (LoRA), which uses small-dimensional matrices for efficient
fine-tuning of large language models (LLMs). To address this limitation, we
propose FALQON, a novel framework that eliminates the quantization overhead
from separate LoRA computational paths by directly merging LoRA adapters into
an FP8-quantized backbone during fine-tuning. Furthermore, we reformulate the
forward and backward computations for merged adapters to significantly reduce
quantization overhead, and introduce a row-wise proxy update mechanism that
efficiently integrates substantial updates into the quantized backbone.
Experimental evaluations demonstrate that FALQON achieves approximately a
3$\times$ training speedup over existing quantized LoRA methods with a similar
level of accuracy, providing a practical solution for efficient large-scale
model fine-tuning. Moreover, FALQON's end-to-end FP8 workflow removes the need
for post-training quantization, facilitating efficient deployment. Code is
available at https://github.com/iamkanghyunchoi/falqon.

</details>


### [179] [Information-Theoretic Discrete Diffusion](https://arxiv.org/abs/2510.24088)
*Moongyu Jeon,Sangwoo Shin,Dongjae Jeon,Albert No*

Main category: cs.LG

TL;DR: 本文提出了一种信息理论框架，用于离散扩散模型，提供基于得分匹配损失的对数似然原则估计量。


<details>
  <summary>Details</summary>
Motivation: 旨在为离散扩散模型提供一种信息理论上的框架，实现更好的对数似然估计。

Method: 通过引入信息-最小去噪得分熵（I-MDSE）关系和信息-最小去噪交叉熵（I-MDCE）关系，连接数据和其扩散版本的互信息与去噪得分熵损失及交叉熵损失。

Result: 通过对合成和真实数据的实验验证了估计量的准确性、方差稳定性及实用性。

Conclusion: 研究结果表明，DSE和DCE损失不仅是变分界限，而是对数似然的稳健估计量，具有广泛的应用潜力。

Abstract: We present an information-theoretic framework for discrete diffusion models
that yields principled estimators of log-likelihood using score-matching
losses. Inspired by the I-MMSE identity for the Gaussian setup, we derive
analogous results for the discrete setting. Specifically, we introduce the
Information-Minimum Denoising Score Entropy (I-MDSE) relation, which links
mutual information between data and its diffused version to the minimum
denoising score entropy (DSE) loss. We extend this theory to masked diffusion
and establish the Information-Minimum Denoising Cross-Entropy (I-MDCE)
relation, connecting cross-entropy losses to mutual information in discrete
masked processes. These results provide a time-integral decomposition of the
log-likelihood of the data in terms of optimal score-based losses, showing that
commonly used losses such as DSE and DCE are not merely variational bounds but
tight and principled estimators of log-likelihood. The I-MDCE decomposition
further enables practical extensions, including time-free formula, conditional
likelihood estimation in prompt-response tasks, and coupled Monte Carlo
estimation of likelihood ratios. Experiments on synthetic and real-world data
confirm the accuracy, variance stability, and utility of our estimators. The
code is publicly available at https://github.com/Dongjae0324/infodis.

</details>


### [180] [What do vision-language models see in the context? Investigating multimodal in-context learning](https://arxiv.org/abs/2510.24331)
*Gabriel O. dos Santos,Esther Colombini,Sandra Avila*

Main category: cs.LG

TL;DR: 本研究系统地探讨了大语言模型中的上下文学习在视觉语言模型中的有效性，揭示了模型的限制和提高其多模态学习能力的建议。


<details>
  <summary>Details</summary>
Motivation: 尽管在大语言模型中已经广泛研究上下文学习，但在视觉语言模型中的有效性尚未深入探讨。

Method: 通过对七个模型在三个图像字幕基准上的表现进行系统评估，分析提示设计、架构选择和训练策略对多模态上下文学习的影响。

Result: 结果表明，基于图像-文本交织数据的训练能增强上下文学习性能，但视觉信息的整合能力有限，当前模型主要依赖文本线索而忽视视觉信息。

Conclusion: 当前的视觉语言模型在学习上下文示例的多模态能力上存在关键限制，提示需要改进其学习能力。

Abstract: In-context learning (ICL) enables Large Language Models (LLMs) to learn tasks
from demonstration examples without parameter updates. Although it has been
extensively studied in LLMs, its effectiveness in Vision-Language Models (VLMs)
remains underexplored. In this work, we present a systematic study of ICL in
VLMs, evaluating seven models spanning four architectures on three image
captioning benchmarks. We analyze how prompt design, architectural choices, and
training strategies influence multimodal ICL. To our knowledge, we are the
first to analyze how attention patterns in VLMs vary with an increasing number
of in-context demonstrations. Our results reveal that training on imag-text
interleaved data enhances ICL performance but does not imply effective
integration of visual and textual information from demonstration examples. In
contrast, instruction tuning improves instruction-following but can reduce
reliance on in-context demonstrations, suggesting a trade-off between
instruction alignment and in-context adaptation. Attention analyses further
show that current VLMs primarily focus on textual cues and fail to leverage
visual information, suggesting a limited capacity for multimodal integration.
These findings highlight key limitations in the ICL abilities of current VLMs
and provide insights for enhancing their ability to learn from multimodal
in-context examples.

</details>


### [181] [Learning Parameterized Skills from Demonstrations](https://arxiv.org/abs/2510.24095)
*Vedant Gupta,Haotian Fu,Calvin Luo,Yiding Jiang,George Konidaris*

Main category: cs.LG

TL;DR: DEPS算法通过学习参数化技能和元策略，提升了对未见任务的泛化能力，并在基准测试中表现突出。


<details>
  <summary>Details</summary>
Motivation: 解决潜在变量模型中的退化问题，提升技能的时间延续性、语义意义和适应性。

Method: 通过时间变分推理和信息论正则化，结合元策略学习参数化技能策略。

Result: DEPS在LIBERO和MetaWorld基准测试中超越了多任务和技能学习的基线，发现可解释的参数化技能。

Conclusion: DEPS算法有效发现可参数化技能，显著提高对未见任务的泛化能力，且在多个基准测试中优于其他方法。

Abstract: We present DEPS, an end-to-end algorithm for discovering parameterized skills
from expert demonstrations. Our method learns parameterized skill policies
jointly with a meta-policy that selects the appropriate discrete skill and
continuous parameters at each timestep. Using a combination of temporal
variational inference and information-theoretic regularization methods, we
address the challenge of degeneracy common in latent variable models, ensuring
that the learned skills are temporally extended, semantically meaningful, and
adaptable. We empirically show that learning parameterized skills from
multitask expert demonstrations significantly improves generalization to unseen
tasks. Our method outperforms multitask as well as skill learning baselines on
both LIBERO and MetaWorld benchmarks. We also demonstrate that DEPS discovers
interpretable parameterized skills, such as an object grasping skill whose
continuous arguments define the grasp location.

</details>


### [182] [Graph-Guided Concept Selection for Efficient Retrieval-Augmented Generation](https://arxiv.org/abs/2510.24120)
*Ziyu Liu,Yijing Liu,Jianfei Yuan,Minzhi Yan,Le Yue,Honghui Xiong,Yi Yang*

Main category: cs.LG

TL;DR: 本文提出G2ConS，通过选择重要文档块和独立于LLM的概念图，降低构建知识图的成本，提高检索和回答质量。


<details>
  <summary>Details</summary>
Motivation: 在生物医学、法律等领域，传统的方法需要多次调用大型语言模型，这在大规模应用时成本过高。

Method: 通过 chunk 选择方法和与 LLM 无关的概念图来减少知识图的构建成本，同时解决了因 chunk 选择而引入的知识缺口。

Result: 通过评估多个真实世界的数据集，发现 G2ConS 在各方面性能均优于传统方法。

Conclusion: G2ConS在知识图构建成本、检索有效性和回答质量方面优于所有基准。

Abstract: Graph-based RAG constructs a knowledge graph (KG) from text chunks to enhance
retrieval in Large Language Model (LLM)-based question answering. It is
especially beneficial in domains such as biomedicine, law, and political
science, where effective retrieval often involves multi-hop reasoning over
proprietary documents. However, these methods demand numerous LLM calls to
extract entities and relations from text chunks, incurring prohibitive costs at
scale. Through a carefully designed ablation study, we observe that certain
words (termed concepts) and their associated documents are more important.
Based on this insight, we propose Graph-Guided Concept Selection (G2ConS). Its
core comprises a chunk selection method and an LLM-independent concept graph.
The former selects salient document chunks to reduce KG construction costs; the
latter closes knowledge gaps introduced by chunk selection at zero cost.
Evaluations on multiple real-world datasets show that G2ConS outperforms all
baselines in construction cost, retrieval effectiveness, and answering quality.

</details>


### [183] [Fixed Point Neural Acceleration and Inverse Surrogate Model for Battery Parameter Identification](https://arxiv.org/abs/2510.24135)
*Hojin Cheon,Hyeongseok Seo,Jihun Jeon,Wooju Lee,Dohyun Jeong,Hongseok Kim*

Main category: cs.LG

TL;DR: 提出了一种基于深度学习的电化学电池模型参数识别框架，显著提升了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在电动汽车电池参数识别中的计算成本高和收敛速度慢的问题，以及机器学习方法对恒定电流数据依赖性强的问题。

Method: 深度学习框架

Result: 通过提出的框架，参数识别加速超过2000倍，样本效率显著提升，准确度是传统算法的10倍以上。

Conclusion: 新框架在动态负载条件下性能优于传统算法，适用于实际应用中的电池健康评估。

Abstract: The rapid expansion of electric vehicles has intensified the need for
accurate and efficient diagnosis of lithium-ion batteries. Parameter
identification of electrochemical battery models is widely recognized as a
powerful method for battery health assessment. However, conventional
metaheuristic approaches suffer from high computational cost and slow
convergence, and recent machine learning methods are limited by their reliance
on constant current data, which may not be available in practice. To overcome
these challenges, we propose deep learning-based framework for parameter
identification of electrochemical battery models. The proposed framework
combines a neural surrogate model of the single particle model with electrolyte
(NeuralSPMe) and a deep learning-based fixed-point iteration method. NeuralSPMe
is trained on realistic EV load profiles to accurately predict lithium
concentration dynamics under dynamic operating conditions while a parameter
update network (PUNet) performs fixed-point iterative updates to significantly
reduce both the evaluation time per sample and the overall number of iterations
required for convergence. Experimental evaluations demonstrate that the
proposed framework accelerates the parameter identification by more than 2000
times, achieves superior sample efficiency and more than 10 times higher
accuracy compared to conventional metaheuristic algorithms, particularly under
dynamic load scenarios encountered in practical applications.

</details>


### [184] [EddyFormer: Accelerated Neural Simulations of Three-Dimensional Turbulence at Scale](https://arxiv.org/abs/2510.24173)
*Yiheng Du,Aditi S. Krishnapriyan*

Main category: cs.LG

TL;DR: EddyFormer是一种新颖的机器学习架构，用于高效模拟湍流，并在多个物理条件下表现出色。


<details>
  <summary>Details</summary>
Motivation: 由于直接数值模拟（DNS）在计算上具有不可行性，因此需要数据驱动的机器学习替代方法来解决湍流问题。

Method: 提出了一种基于Transformer的光谱元素架构EddyFormer，用于大规模湍流模拟。

Result: EddyFormer在256^3分辨率下达到了DNS级别的准确性，相比DNS实现了30倍的加速，并在未见过的领域上保持准确性。

Conclusion: EddyFormer在各种湍流情况下表现优异，成功解决了以往机器学习模型无法收敛的问题，展示了其在流体动力学中的应用潜力。

Abstract: Computationally resolving turbulence remains a central challenge in fluid
dynamics due to its multi-scale interactions. Fully resolving large-scale
turbulence through direct numerical simulation (DNS) is computationally
prohibitive, motivating data-driven machine learning alternatives. In this
work, we propose EddyFormer, a Transformer-based spectral-element (SEM)
architecture for large-scale turbulence simulation that combines the accuracy
of spectral methods with the scalability of the attention mechanism. We
introduce an SEM tokenization that decomposes the flow into grid-scale and
subgrid-scale components, enabling capture of both local and global features.
We create a new three-dimensional isotropic turbulence dataset and train
EddyFormer to achieves DNS-level accuracy at 256^3 resolution, providing a 30x
speedup over DNS. When applied to unseen domains up to 4x larger than in
training, EddyFormer preserves accuracy on physics-invariant metrics-energy
spectra, correlation functions, and structure functions-showing domain
generalization. On The Well benchmark suite of diverse turbulent flows,
EddyFormer resolves cases where prior ML models fail to converge, accurately
reproducing complex dynamics across a wide range of physical conditions.

</details>


### [185] [V-SAT: Video Subtitle Annotation Tool](https://arxiv.org/abs/2510.24180)
*Arpita Kundu,Joyita Chakraborty,Anindita Desarkar,Aritra Sen,Srushti Anil Patil,Vishwanathan Raman*

Main category: cs.LG

TL;DR: V-SAT是一个新的字幕质量自动修正工具，使用多种技术显著改善了字幕的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 随着流媒体平台和社交媒体上视听内容的激增，对准确和易于获取的字幕的需求不断增加。然而，现有的字幕生成方法在同步性、文本准确性、格式一致性等方面存在缺陷。

Method: 本研究结合了大型语言模型(LLMs)、视觉语言模型(VLMs)、图像处理和自动语音识别(ASR)，利用音频和视频的上下文线索来改进字幕质量。

Result: V-SAT（视频字幕注释工具），一种统一框架，通过结合多种技术自动检测并修正字幕质量问题，显著提高了字幕质量。

Conclusion: 本研究提出了V-SAT，作为首个全面解决字幕注释问题的解决方案，展示了其在字幕质量改进上的有效性。

Abstract: The surge of audiovisual content on streaming platforms and social media has
heightened the demand for accurate and accessible subtitles. However, existing
subtitle generation methods primarily speech-based transcription or OCR-based
extraction suffer from several shortcomings, including poor synchronization,
incorrect or harmful text, inconsistent formatting, inappropriate reading
speeds, and the inability to adapt to dynamic audio-visual contexts. Current
approaches often address isolated issues, leaving post-editing as a
labor-intensive and time-consuming process. In this paper, we introduce V-SAT
(Video Subtitle Annotation Tool), a unified framework that automatically
detects and corrects a wide range of subtitle quality issues. By combining
Large Language Models(LLMs), Vision-Language Models (VLMs), Image Processing,
and Automatic Speech Recognition (ASR), V-SAT leverages contextual cues from
both audio and video. Subtitle quality improved, with the SUBER score reduced
from 9.6 to 3.54 after resolving all language mode issues and F1-scores of
~0.80 for image mode issues. Human-in-the-loop validation ensures high-quality
results, providing the first comprehensive solution for robust subtitle
annotation.

</details>


### [186] [SPEAR++: Scaling Gradient Inversion via Sparsely-Used Dictionary Learning](https://arxiv.org/abs/2510.24200)
*Alexander Bakarsky,Dimitar I. Dimitrov,Maximilian Baader,Martin Vechev*

Main category: cs.LG

TL;DR: 本文提出了SPEAR++，一种改进的渐变反演攻击方法，能有效提高联邦学习的攻击实用性和批量处理能力。


<details>
  <summary>Details</summary>
Motivation: 随着联邦学习在实际场景中的推广，保护用户隐私的重要性日益增加，针对渐变反演攻击的研究亟需深入。

Method: 通过应用稀疏字典学习相关技术，使得在具有ReLU激活的线性层中的渐变反演问题变得可处理。

Result: 论文研究了联邦学习的隐私保护性能与渐变反演攻击之间的矛盾。引入的SPEAR攻击虽然在理论上是一个突破，但其实用性受到严重限制。为此，作者将稀疏字典学习的前沿技术应用于线性层的渐变反演问题，提出了新的攻击方法SPEAR++。实验结果表明，SPEAR++在保持SPEAR各种优良特性的同时，能够适用更大的批量大小。

Conclusion: 新的攻击方法SPEAR++不仅保留了SPEAR的优势，还通过技术改进能够适用于更大规模的批量训练。

Abstract: Federated Learning has seen an increased deployment in real-world scenarios
recently, as it enables the distributed training of machine learning models
without explicit data sharing between individual clients. Yet, the introduction
of the so-called gradient inversion attacks has fundamentally challenged its
privacy-preserving properties. Unfortunately, as these attacks mostly rely on
direct data optimization without any formal guarantees, the vulnerability of
real-world systems remains in dispute and requires tedious testing for each new
federated deployment. To overcome these issues, recently the SPEAR attack was
introduced, which is based on a theoretical analysis of the gradients of linear
layers with ReLU activations. While SPEAR is an important theoretical
breakthrough, the attack's practicality was severely limited by its exponential
runtime in the batch size b. In this work, we fill this gap by applying
State-of-the-Art techniques from Sparsely-Used Dictionary Learning to make the
problem of gradient inversion on linear layers with ReLU activations tractable.
Our experiments demonstrate that our new attack, SPEAR++, retains all desirable
properties of SPEAR, such as robustness to DP noise and FedAvg aggregation,
while being applicable to 10x bigger batch sizes.

</details>


### [187] [Unlocking Out-of-Distribution Generalization in Dynamics through Physics-Guided Augmentation](https://arxiv.org/abs/2510.24216)
*Fan Xu,Hao Wu,Kun Wang,Nan Wang,Qingsong Wen,Xian Wu,Wei Gong,Xibin Zhao*

Main category: cs.LG

TL;DR: 提出SPARK，一个通过物理引导的定量增强插件，能在数据稀缺条件下生成新的、物理上合理的训练样本，并与四ier增强的Graph ODE结合，进行有效预测。


<details>
  <summary>Details</summary>
Motivation: 解决传统数值方法计算成本高，现代数据驱动方法面临数据稀缺和分布变化的问题。

Method: 使用重构自编码器整合物理参数，并通过潜在空间的原理插值创建新的训练样本，同时结合Fourier增强的Graph ODE进行下游预测。

Result: SPARK显著优于最新的基准，尤其是在困难的分布外情况和数据稀缺场景中。

Conclusion: 证明了物理引导增强范式的有效性。

Abstract: In dynamical system modeling, traditional numerical methods are limited by
high computational costs, while modern data-driven approaches struggle with
data scarcity and distribution shifts. To address these fundamental
limitations, we first propose SPARK, a physics-guided quantitative augmentation
plugin. Specifically, SPARK utilizes a reconstruction autoencoder to integrate
physical parameters into a physics-rich discrete state dictionary. This state
dictionary then acts as a structured dictionary of physical states, enabling
the creation of new, physically-plausible training samples via principled
interpolation in the latent space. Further, for downstream prediction, these
augmented representations are seamlessly integrated with a Fourier-enhanced
Graph ODE, a combination designed to robustly model the enriched data
distribution while capturing long-term temporal dependencies. Extensive
experiments on diverse benchmarks demonstrate that SPARK significantly
outperforms state-of-the-art baselines, particularly in challenging
out-of-distribution scenarios and data-scarce regimes, proving the efficacy of
our physics-guided augmentation paradigm.

</details>


### [188] [Closing Gaps: An Imputation Analysis of ICU Vital Signs](https://arxiv.org/abs/2510.24217)
*Alisher Turubayev,Anna Shopova,Fabian Lange,Mahmut Kamalak,Paul Mattes,Victoria Ayvasky,Bert Arnrich,Bjarne Pfitzner,Robin P. van de Water*

Main category: cs.LG

TL;DR: 本研究比较了ICU生命体征数据插补技术，以改善临床预测模型的性能，并创建了基准工具


<details>
  <summary>Details</summary>
Motivation: 提高ICU临床预测模型的性能，通过选择最准确的插补技术来填补重要生命体征数据的缺失部分

Method: 比较现有的插补技术与实验性插补方法

Result: 建立了一个包含15种插补方法和4种缺失数据处理方法的基准，针对主要的ICU数据集进行评估

Conclusion: 希望为相关研究提供比较基础，促进机器学习技术在临床实践中的应用。

Abstract: As more Intensive Care Unit (ICU) data becomes available, the interest in
developing clinical prediction models to improve healthcare protocols
increases. However, the lack of data quality still hinders clinical prediction
using Machine Learning (ML). Many vital sign measurements, such as heart rate,
contain sizeable missing segments, leaving gaps in the data that could
negatively impact prediction performance. Previous works have introduced
numerous time-series imputation techniques. Nevertheless, more comprehensive
work is needed to compare a representative set of methods for imputing ICU
vital signs and determine the best practice. In reality, ad-hoc imputation
techniques that could decrease prediction accuracy, like zero imputation, are
still used. In this work, we compare established imputation techniques to guide
researchers in improving the performance of clinical prediction models by
selecting the most accurate imputation technique. We introduce an extensible
and reusable benchmark with currently 15 imputation and 4 amputation methods,
created for benchmarking on major ICU datasets. We hope to provide a
comparative basis and facilitate further ML development to bring more models
into clinical practice.

</details>


### [189] [PRIVET: Privacy Metric Based on Extreme Value Theory](https://arxiv.org/abs/2510.24233)
*Antoine Szatkownik,Aurélien Decelle,Beatriz Seoane,Nicolas Bereux,Léo Planche,Guillaume Charpiat,Burak Yelmen,Flora Jay,Cyril Furtlehner*

Main category: cs.LG

TL;DR: 本文提出PRIVET算法，解决了深度生成模型在敏感数据上训练时的隐私泄漏问题，通过样本级评估提供了更直观的隐私风险信息。


<details>
  <summary>Details</summary>
Motivation: 探讨深度生成模型在处理敏感数据时可能导致的隐私泄漏问题，尤其是与过拟合密切相关的隐私风险评估方法的缺乏。

Method: 采用极值统计手段对最近邻距离进行分析，提炼出样本级隐私泄漏评分。

Result: 提出了PRIVET，一个基于样本的隐私泄漏评估算法，能够为每个合成样本分配个体隐私泄漏评分。

Conclusion: PRIVET算法在多种数据模态下能有效检测记忆和隐私泄漏实例，提供优于现有方法的评估结果。

Abstract: Deep generative models are often trained on sensitive data, such as genetic
sequences, health data, or more broadly, any copyrighted, licensed or protected
content. This raises critical concerns around privacy-preserving synthetic
data, and more specifically around privacy leakage, an issue closely tied to
overfitting. Existing methods almost exclusively rely on global criteria to
estimate the risk of privacy failure associated to a model, offering only
quantitative non interpretable insights. The absence of rigorous evaluation
methods for data privacy at the sample-level may hinder the practical
deployment of synthetic data in real-world applications. Using extreme value
statistics on nearest-neighbor distances, we propose PRIVET, a generic
sample-based, modality-agnostic algorithm that assigns an individual privacy
leak score to each synthetic sample. We empirically demonstrate that PRIVET
reliably detects instances of memorization and privacy leakage across diverse
data modalities, including settings with very high dimensionality, limited
sample sizes such as genetic data and even under underfitting regimes. We
compare our method to existing approaches under controlled settings and show
its advantage in providing both dataset level and sample level assessments
through qualitative and quantitative outputs. Additionally, our analysis
reveals limitations in existing computer vision embeddings to yield
perceptually meaningful distances when identifying near-duplicate samples.

</details>


### [190] [Sparse Optimistic Information Directed Sampling](https://arxiv.org/abs/2510.24234)
*Ludovic Schwartz,Hamish Flynn,Gergely Neu*

Main category: cs.LG

TL;DR: SOIDS算法通过时间依赖学习率，在数据丰富和贫瘠情况下同时实现最优遗憾界限。


<details>
  <summary>Details</summary>
Motivation: 解决高维在线决策问题中算法在数据丰富与贫瘠两种情形下的性能权衡。

Method: 通过时间依赖的学习率进行新的分析，实现对信息与遗憾的最佳平衡。

Result: 本研究提出了一种新的稀疏乐观信息导向采样(SOIDS)算法，旨在同时在数据丰富和数据贫瘠的情况下实现最优的最坏情况下的遗憾界限。与现有算法需要在数据丰富和数据贫瘠之间进行权衡不同，SOIDS使用时间依赖的学习率来平衡信息与遗憾，扩展了稀疏信息导向采样(IDS)的理论保证，并通过实证研究证明了其良好的性能。

Conclusion: SOIDS算法是第一个在两种数据条件下都能达到最优遗憾界限的算法，具有良好的实证性能。

Abstract: Many high-dimensional online decision-making problems can be modeled as
stochastic sparse linear bandits. Most existing algorithms are designed to
achieve optimal worst-case regret in either the data-rich regime, where
polynomial depen- dence on the ambient dimension is unavoidable, or the
data-poor regime, where dimension-independence is possible at the cost of worse
dependence on the num- ber of rounds. In contrast, the sparse Information
Directed Sampling (IDS) algo- rithm satisfies a Bayesian regret bound that has
the optimal rate in both regimes simultaneously. In this work, we explore the
use of Sparse Optimistic Informa- tion Directed Sampling (SOIDS) to achieve the
same adaptivity in the worst-case setting, without Bayesian assumptions.
Through a novel analysis that enables the use of a time-dependent learning
rate, we show that SOIDS can optimally balance information and regret. Our
results extend the theoretical guarantees of IDS, pro- viding the first
algorithm that simultaneously achieves optimal worst-case regret in both the
data-rich and data-poor regimes. We empirically demonstrate the good
performance of SOIDS.

</details>


### [191] [PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware Task-Adaptive Reward Modeling](https://arxiv.org/abs/2510.24235)
*Ai Jian,Jingqing Ruan,Xing Ma,Dailin Li,QianLin Zhou,Ke Zeng,Xunliang Cai*

Main category: cs.LG

TL;DR: 提出了一种新型的偏好感知任务自适应奖励模型（PaTaRM），在RLHF中显著提升了性能和解释性。


<details>
  <summary>Details</summary>
Motivation: 解决现有生成奖励模型在训练中的局限性，包括依赖二元标签和复杂配对策略的问题。

Method: 提出一种统一框架，将偏好感知奖励机制与动态评分标准相结合，构建稳健的点对点训练信号。

Result: 在Qwen3-8B和Qwen3-14B模型上，PaTaRM在RewardBench和RMBench的平均相对提升为4.7%，在IFEval和InFoBench基准上，RLHF性能平均提升13.6%。

Conclusion: PaTaRM在多个基准上展示了有效性与鲁棒性，显著提高了下游RLHF性能。

Abstract: Reward models (RMs) are central to reinforcement learning from human feedback
(RLHF), providing the critical supervision signals that align large language
models (LLMs) with human preferences. While generative reward models (GRMs)
offer greater interpretability than traditional scalar RMs, current training
paradigms remain limited. Pair-wise methods rely on binary good-versus-bad
labels, which cause mismatches for point-wise inference and necessitate complex
pairing strategies for effective application in RLHF. On the other hand,
point-wise methods require more elaborate absolute labeling with rubric-driven
criteria, resulting in poor adaptability and high annotation costs. In this
work, we propose the Preference-Aware Task-Adaptive Reward Model (PaTaRM), a
unified framework that integrates a preference-aware reward (PAR) mechanism
with dynamic rubric adaptation. PaTaRM leverages relative preference
information from pairwise data to construct robust point-wise training signals,
eliminating the need for explicit point-wise labels. Simultaneously, it employs
a task-adaptive rubric system that flexibly generates evaluation criteria for
both global task consistency and instance-specific fine-grained reasoning. This
design enables efficient, generalizable, and interpretable reward modeling for
RLHF. Extensive experiments show that PaTaRM achieves an average relative
improvement of 4.7% on RewardBench and RMBench across Qwen3-8B and Qwen3-14B
models. Furthermore, PaTaRM boosts downstream RLHF performance, with an average
improvement of 13.6% across IFEval and InFoBench benchmarks, confirming its
effectiveness and robustness. Our code is available at
https://github.com/JaneEyre0530/PaTaRM.

</details>


### [192] [Temporal Knowledge Graph Hyperedge Forecasting: Exploring Entity-to-Category Link Prediction](https://arxiv.org/abs/2510.24240)
*Edward Markai,Sina Molavipour*

Main category: cs.LG

TL;DR: 本文探讨了一种扩展的规则基础框架TLogic，致力于提高预测准确性和可解释性，通过引入实体类别和数据驱动的类别生成方法，提升对动态知识图的建模能力。


<details>
  <summary>Details</summary>
Motivation: 随着时间推移，传统的嵌入式方法在动态关系建模方面存在局限性，迫切需要一种能够提供可解释性的解决方案来预测未来的图组件。

Method: 通过扩展TLogic框架，结合实体类别来限制规则的适用性，并使用基于大型语言模型(LLM)的数据驱动方法生成未知的类别。

Result: 本研究的创新之处在于结合了实体类别，并引入了一种数据驱动的方法来生成类别，从而在进行类别预测时影响得分的聚合方法选择。

Conclusion: 本研究提出了一种扩展的基于规则的框架TLogic，能够实现高准确度和可解释性的预测，增强了透明性，使最终用户能够批判性地评估应用的规则。

Abstract: Temporal Knowledge Graphs have emerged as a powerful way of not only modeling
static relationships between entities but also the dynamics of how relations
evolve over time. As these informational structures can be used to store
information from a real-world setting, such as a news flow, predicting future
graph components to a certain extent equates predicting real-world events. Most
of the research in this field focuses on embedding-based methods, often
leveraging convolutional neural net architectures. These solutions act as black
boxes, limiting insight. In this paper, we explore an extension to an
established rule-based framework, TLogic, that yields a high accuracy in
combination with explainable predictions. This offers transparency and allows
the end-user to critically evaluate the rules applied at the end of the
prediction stage. The new rule format incorporates entity category as a key
component with the purpose of limiting rule application only to relevant
entities. When categories are unknown for building the graph, we propose a
data-driven method to generate them with an LLM-based approach. Additionally,
we investigate the choice of aggregation method for scores of retrieved
entities when performing category prediction.

</details>


### [193] [SALS: Sparse Attention in Latent Space for KV cache Compression](https://arxiv.org/abs/2510.24273)
*Junlin Mu,Hantao Huang,Jihang Zhang,Minghui Yu,Tao Wang,Yidong Li*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的稀疏注意力机制SALS，通过低秩投影和无RoPE的查询-键交互，克服了现有方法中的准确性损失和速度瓶颈，实现了显著的性能改进。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在推理过程中由于Key-Value缓存大小和高内存带宽需求而带来的挑战，特别是在低秩压缩与Rotary Position Embedding(RoPE)机制下的准确性损失问题。

Method: 提出稀疏注意力在潜在空间框架(SALS)，通过低秩投影将KV缓存投影到紧凑的潜在空间，并在此空间中使用无RoPE的查询-键交互进行稀疏令牌选择。

Result: SALS在多种任务上通过使用LLaMA2-7b-chat和Mistral-7b两种大型模型进行了全面评估，在不同设置下实现了对KV缓存的6.4倍压缩和对注意力运算的5.7倍速度提升。

Conclusion: SALS在保证竞争力准确性的同时，实现了在4K序列上1.4倍和32K序列上4.5倍的端到端吞吐量提升，展现出卓越的性能。

Abstract: Large Language Models capable of handling extended contexts are in high
demand, yet their inference remains challenging due to substantial Key-Value
cache size and high memory bandwidth requirements. Previous research has
demonstrated that KV cache exhibits low-rank characteristics within the hidden
dimension, suggesting the potential for effective compression. However, due to
the widely adopted Rotary Position Embedding mechanism in modern LLMs, naive
low-rank compression suffers severe accuracy degradation or creates a new speed
bottleneck, as the low-rank cache must first be reconstructed in order to apply
RoPE. In this paper, we introduce two key insights: first, the application of
RoPE to the key vectors increases their variance, which in turn results in a
higher rank; second, after the key vectors are transformed into the latent
space, they largely maintain their representation across most layers. Based on
these insights, we propose the Sparse Attention in Latent Space framework. SALS
projects the KV cache into a compact latent space via low-rank projection, and
performs sparse token selection using RoPE-free query-key interactions in this
space. By reconstructing only a small subset of important tokens, it avoids the
overhead of full KV cache reconstruction. We comprehensively evaluate SALS on
various tasks using two large-scale models: LLaMA2-7b-chat and Mistral-7b, and
additionally verify its scalability on the RULER-128k benchmark with
LLaMA3.1-8B-Instruct. Experimental results demonstrate that SALS achieves SOTA
performance by maintaining competitive accuracy. Under different settings, SALS
achieves 6.4-fold KV cache compression and 5.7-fold speed-up in the attention
operator compared to FlashAttention2 on the 4K sequence. For the end-to-end
throughput performance, we achieves 1.4-fold and 4.5-fold improvement compared
to GPT-fast on 4k and 32K sequences, respectively.

</details>


### [194] [EDC: Equation Discovery for Classification](https://arxiv.org/abs/2510.24310)
*Guus Toussaint,Arno Knobbe*

Main category: cs.LG

TL;DR: 提出了一种新型的基于方程发现的二分类方法EDC，能够发现决策边界的解析函数，并在多项实验中优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 探讨如何在二分类任务中通过方程发现技术改善模型的可解释性和结构

Method: 通过引入一个适度复杂的语法，EDC能够表示包含线性、二次和指数项的决策边界，并捕捉特定的数据模式。

Result: 提出了一种新的EDC框架，在二分类任务中表现优于现有方法，并能发现目标方程的结构与参数值

Conclusion: EDC方法通过配置合理的语法和丰富的模型灵活性，在二分类中取得了显著的效果而避免过拟合。

Abstract: Equation Discovery techniques have shown considerable success in regression
tasks, where they are used to discover concise and interpretable models
(\textit{Symbolic Regression}). In this paper, we propose a new ED-based binary
classification framework. Our proposed method EDC finds analytical functions of
manageable size that specify the location and shape of the decision boundary.
In extensive experiments on artificial and real-life data, we demonstrate how
EDC is able to discover both the structure of the target equation as well as
the value of its parameters, outperforming the current state-of-the-art
ED-based classification methods in binary classification and achieving
performance comparable to the state of the art in binary classification. We
suggest a grammar of modest complexity that appears to work well on the tested
datasets but argue that the exact grammar -- and thus the complexity of the
models -- is configurable, and especially domain-specific expressions can be
included in the pattern language, where that is required. The presented grammar
consists of a series of summands (additive terms) that include linear,
quadratic and exponential terms, as well as products of two features (producing
hyperbolic curves ideal for capturing XOR-like dependencies). The experiments
demonstrate that this grammar allows fairly flexible decision boundaries while
not so rich to cause overfitting.

</details>


### [195] [Transformers can do Bayesian Clustering](https://arxiv.org/abs/2510.24318)
*Prajit Bhaskaran,Tom Viering*

Main category: cs.LG

TL;DR: Cluster-PFN是一个基于Transformer的贝叶斯聚类模型，专为处理大规模和缺失数据设计，具有高效性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 解决传统贝叶斯聚类在处理大规模数据时的计算负担及缺失值带来的不确定性问题。

Method: 使用Transformer扩展Prior-Data Fitted Networks (PFNs)进行无监督贝叶斯聚类。

Result: Cluster-PFN在估计聚类数量和聚类分配方面的准确性优于手工模型选择程序，其聚类质量与变分推断方法相当，但速度更快。

Conclusion: Cluster-PFN模型在应对缺失数据时，表现出比传统插补方法更优的聚类性能，并且能够更高效地进行贝叶斯聚类。

Abstract: Bayesian clustering accounts for uncertainty but is computationally demanding
at scale. Furthermore, real-world datasets often contain missing values, and
simple imputation ignores the associated uncertainty, resulting in suboptimal
results. We present Cluster-PFN, a Transformer-based model that extends
Prior-Data Fitted Networks (PFNs) to unsupervised Bayesian clustering. Trained
entirely on synthetic datasets generated from a finite Gaussian Mixture Model
(GMM) prior, Cluster-PFN learns to estimate the posterior distribution over
both the number of clusters and the cluster assignments. Our method estimates
the number of clusters more accurately than handcrafted model selection
procedures such as AIC, BIC and Variational Inference (VI), and achieves
clustering quality competitive with VI while being orders of magnitude faster.
Cluster-PFN can be trained on complex priors that include missing data,
outperforming imputation-based baselines on real-world genomic datasets, at
high missingness. These results show that the Cluster-PFN can provide scalable
and flexible Bayesian clustering.

</details>


### [196] [Perception Learning: A Formal Separation of Sensory Representation Learning from Decision Learning](https://arxiv.org/abs/2510.24356)
*Suman Sanyal*

Main category: cs.LG

TL;DR: 该论文提出了一种新的感知学习范式，通过任务不可知的信号优化感知接口，以增强感知特性并提供评估指标。


<details>
  <summary>Details</summary>
Motivation: 希望提高感知系统在各种环境下的灵活性与适应性，提升其性能和可靠性。

Method: 提出Perception Learning范式，通过任务不可知的信号优化感知接口，并定义无标签感知特性与相关评估方法。

Result: 该论文引入了感知学习(Perception Learning, PeL)的范式，优化传感器接口，以任务不可知的信号指导决策学习，专注于无标签的感知特性，强调在不同环境下的稳定性、信息丰富性以及几何控制。通过标准化的表示不变性度量来评估这些特性，论文理论上明确了感知与决策的分离，提供了用于验证感知质量的评估指标。

Conclusion: PeL范式有效分离了感知与决策过程，使感知特性得以独立于具体任务或参数重标定，并提供了有效的评估工具。

Abstract: We introduce Perception Learning (PeL), a paradigm that optimizes an agent's
sensory interface $f_\phi:\mathcal{X}\to\mathcal{Z}$ using task-agnostic
signals, decoupled from downstream decision learning
$g_\theta:\mathcal{Z}\to\mathcal{Y}$. PeL directly targets label-free
perceptual properties, such as stability to nuisances, informativeness without
collapse, and controlled geometry, assessed via objective
representation-invariant metrics. We formalize the separation of perception and
decision, define perceptual properties independent of objectives or
reparameterizations, and prove that PeL updates preserving sufficient
invariants are orthogonal to Bayes task-risk gradients. Additionally, we
provide a suite of task-agnostic evaluation metrics to certify perceptual
quality.

</details>


### [197] [Filtering instances and rejecting predictions to obtain reliable models in healthcare](https://arxiv.org/abs/2510.24368)
*Maria Gabriela Valeriano,David Kohan Marzagão,Alfredo Montelongo,Carlos Roberto Veiga Kiffer,Natan Katz,Ana Carolina Lorena*

Main category: cs.LG

TL;DR: 提出了一种新方法，通过数据质量提升和低置信度预测过滤，提高机器学习模型在医疗领域的可靠性。


<details>
  <summary>Details</summary>
Motivation: 在医疗等高风险领域，机器学习模型必须提供可靠的预测，因此需要处理模型的不确定性和低置信度的预测。

Method: 采用两步数据中心方法，首先通过实例难度过滤训练数据，其次在推理阶段应用基于置信度的拒绝机制。

Result: 使用三个真实世界的医疗数据集进行评估，结果表明该方法有效提高了模型的可靠性，同时平衡了预测性能和拒绝率。

Conclusion: 该方法通过集成实例难度过滤和基于置信度的拒绝机制，显著提高了机器学习模型的性能，同时保留了大量实例。

Abstract: Machine Learning (ML) models are widely used in high-stakes domains such as
healthcare, where the reliability of predictions is critical. However, these
models often fail to account for uncertainty, providing predictions even with
low confidence. This work proposes a novel two-step data-centric approach to
enhance the performance of ML models by improving data quality and filtering
low-confidence predictions. The first step involves leveraging Instance
Hardness (IH) to filter problematic instances during training, thereby refining
the dataset. The second step introduces a confidence-based rejection mechanism
during inference, ensuring that only reliable predictions are retained. We
evaluate our approach using three real-world healthcare datasets, demonstrating
its effectiveness at improving model reliability while balancing predictive
performance and rejection rate. Additionally, we use alternative criteria -
influence values for filtering and uncertainty for rejection - as baselines to
evaluate the efficiency of the proposed method. The results demonstrate that
integrating IH filtering with confidence-based rejection effectively enhances
model performance while preserving a large proportion of instances. This
approach provides a practical method for deploying ML systems in
safety-critical applications.

</details>


### [198] [A Comprehensive Evaluation Framework for Synthetic Trip Data Generation in Public Transport](https://arxiv.org/abs/2510.24375)
*Yuanyuan Wu,Zhenlin Qin,Zhenliang Ma*

Main category: cs.LG

TL;DR: 本研究提出了一种代表性-隐私-效用（RPU）框架，用于系统评估公共交通中的合成数据，强调了隐私与效用之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 应对智能卡数据使用中的隐私和可获取性挑战，同时填补对合成数据评估的不足。

Method: 提出RPU框架，通过三维度和三层次评估合成数据的质量，整合了一系列量化指标。

Result: 对十二种生成方法进行评估，发现隐私与数据的代表性/效用之间存在明显权衡，CTGAN在各方面表现最佳。

Conclusion: 合成数据在公共交通研究中不能自动保证隐私，最佳生成模型为CTGAN，RPU框架有助于选择合适的合成数据生成技术。

Abstract: Synthetic data offers a promising solution to the privacy and accessibility
challenges of using smart card data in public transport research. Despite rapid
progress in generative modeling, there is limited attention to comprehensive
evaluation, leaving unclear how reliable, safe, and useful synthetic data truly
are. Existing evaluations remain fragmented, typically limited to
population-level representativeness or record-level privacy, without
considering group-level variations or task-specific utility. To address this
gap, we propose a Representativeness-Privacy-Utility (RPU) framework that
systematically evaluates synthetic trip data across three complementary
dimensions and three hierarchical levels (record, group, population). The
framework integrates a consistent set of metrics to quantify similarity,
disclosure risk, and practical usefulness, enabling transparent and balanced
assessment of synthetic data quality. We apply the framework to benchmark
twelve representative generation methods, spanning conventional statistical
models, deep generative networks, and privacy-enhanced variants. Results show
that synthetic data do not inherently guarantee privacy and there is no
"one-size-fits-all" model, the trade-off between privacy and
representativeness/utility is obvious. Conditional Tabular generative
adversarial network (CTGAN) provide the most balanced trade-off and is
suggested for practical applications. The RPU framework provides a systematic
and reproducible basis for researchers and practitioners to compare synthetic
data generation techniques and select appropriate methods in public transport
applications.

</details>


### [199] [Methodology for Comparing Machine Learning Algorithms for Survival Analysis](https://arxiv.org/abs/2510.24473)
*Lucas Buk Cardoso,Simone Aldrey Angelo,Yasmin Pacheco Gil Bonilha,Fernando Maia,Adeylson Guimarães Ribeiro,Maria Paula Curado,Gisele Aparecida Fernandes,Vanderlei Cunha Parro,Flávio Almeida de Magalhães Cipparrone,Alexandre Dias Porto Chiavegatto Filho,Tatiana Natasha Toporcov*

Main category: cs.LG

TL;DR: 本研究比较了六种机器学习模型在生存分析中的应用，XGB-AFT表现最佳，强调了其在生存预测中的潜力。


<details>
  <summary>Details</summary>
Motivation: 旨在通过分析不同机器学习模型在生存分析中的应用，提高结直肠癌患者的生存预测能力。

Method: 采用六种机器学习生存分析模型进行比较，包括RSF、GBSA、SSVM、XGB-Cox、XGB-AFT和LGBM，并进行了超参数优化和性能评估。

Result: XGB-AFT获得最佳性能，其C-Index为0.7618，IPCW为0.7532，表明该方法在生存预测中的有效性。

Conclusion: 结果表明，XGB-AFT模型在生存预测中表现最佳，为医疗决策提供支持。

Abstract: This study presents a comparative methodological analysis of six machine
learning models for survival analysis (MLSA). Using data from nearly 45,000
colorectal cancer patients in the Hospital-Based Cancer Registries of S\~ao
Paulo, we evaluated Random Survival Forest (RSF), Gradient Boosting for
Survival Analysis (GBSA), Survival SVM (SSVM), XGBoost-Cox (XGB-Cox),
XGBoost-AFT (XGB-AFT), and LightGBM (LGBM), capable of predicting survival
considering censored data. Hyperparameter optimization was performed with
different samplers, and model performance was assessed using the Concordance
Index (C-Index), C-Index IPCW, time-dependent AUC, and Integrated Brier Score
(IBS). Survival curves produced by the models were compared with predictions
from classification algorithms, and predictor interpretation was conducted
using SHAP and permutation importance. XGB-AFT achieved the best performance
(C-Index = 0.7618; IPCW = 0.7532), followed by GBSA and RSF. The results
highlight the potential and applicability of MLSA to improve survival
prediction and support decision making.

</details>


### [200] [MIMIC-Sepsis: A Curated Benchmark for Modeling and Learning from Sepsis Trajectories in the ICU](https://arxiv.org/abs/2510.24500)
*Yong Huang,Zhongqi Yang,Amir Rahmani*

Main category: cs.LG

TL;DR: MIMIC-Sepsis是从MIMIC-IV数据库提取的一个新数据集，旨在提供一个可重复的模型框架来研究脓毒症病程，包含35,239名ICU患者的临床数据，并引入了标准化的治疗数据。


<details>
  <summary>Details</summary>
Motivation: 现有研究依赖于过时的数据集和不具可重复性的预处理流程，限制了临床干预的覆盖范围，需要一个更具代表性和透明的数据集来研究脓毒症。

Method: 使用基于Sepsis-3标准的透明预处理流程、结构化插补策略以及治疗数据的纳入和释放来处理数据。

Result: 实证结果表明，纳入治疗变量显著提高了模型性能，特别是在基于Transformer的架构中。

Conclusion: MIMIC-Sepsis为重症监护研究提供了一个强有力的平台，能够评估预测和顺序模型的有效性。

Abstract: Sepsis is a leading cause of mortality in intensive care units (ICUs), yet
existing research often relies on outdated datasets, non-reproducible
preprocessing pipelines, and limited coverage of clinical interventions. We
introduce MIMIC-Sepsis, a curated cohort and benchmark framework derived from
the MIMIC-IV database, designed to support reproducible modeling of sepsis
trajectories. Our cohort includes 35,239 ICU patients with time-aligned
clinical variables and standardized treatment data, including vasopressors,
fluids, mechanical ventilation and antibiotics. We describe a transparent
preprocessing pipeline-based on Sepsis-3 criteria, structured imputation
strategies, and treatment inclusion-and release it alongside benchmark tasks
focused on early mortality prediction, length-of-stay estimation, and shock
onset classification. Empirical results demonstrate that incorporating
treatment variables substantially improves model performance, particularly for
Transformer-based architectures. MIMIC-Sepsis serves as a robust platform for
evaluating predictive and sequential models in critical care research.

</details>


### [201] [LoRA-DA: Data-Aware Initialization for Low-Rank Adaptation via Asymptotic Analysis](https://arxiv.org/abs/2510.24561)
*Qingyue Zhang,Chang Chu,Tianren Peng,Qi Li,Xiangyang Luo,Zhihao Jiang,Shao-Lun Huang*

Main category: cs.LG

TL;DR: 本文构建了一个新的LoRA初始化框架并开发了有效算法LoRA-DA，实验表明其在多个基准测试中的表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的LoRA初始化方法在针对目标领域数据的利用方面存在明显限制，且基于梯度的方法在有效性和理论基础上都显不足。

Method: 通过基于期望的参数差异最小化问题，结合偏差项和方差项，推导出最优的LoRA初始化策略。

Result: 提出了一种基于渐进分析的对数据感知的LoRA初始化理论框架，并开发了高效算法LoRA-DA。

Conclusion: LoRA-DA在多个基准测试中表现出色，提升了最终准确性，并改善了收敛性和稳定性。

Abstract: With the widespread adoption of LLMs, LoRA has become a dominant method for
PEFT, and its initialization methods have attracted increasing attention.
However, existing methods have notable limitations: many methods do not
incorporate target-domain data, while gradient-based methods exploit data only
at a shallow level by relying on one-step gradient decomposition, which remains
unsatisfactory due to the weak empirical performance of the one-step
fine-tuning model that serves as their basis, as well as the fact that these
methods either lack a rigorous theoretical foundation or depend heavily on
restrictive isotropic assumptions. In this paper, we establish a theoretical
framework for data-aware LoRA initialization based on asymptotic analysis.
Starting from a general optimization objective that minimizes the expectation
of the parameter discrepancy between the fine-tuned and target models, we
derive an optimization problem with two components: a bias term, which is
related to the parameter distance between the fine-tuned and target models, and
is approximated using a Fisher-gradient formulation to preserve anisotropy; and
a variance term, which accounts for the uncertainty introduced by sampling
stochasticity through the Fisher information. By solving this problem, we
obtain an optimal initialization strategy for LoRA. Building on this
theoretical framework, we develop an efficient algorithm, LoRA-DA, which
estimates the terms in the optimization problem from a small set of target
domain samples and obtains the optimal LoRA initialization. Empirical results
across multiple benchmarks demonstrate that LoRA-DA consistently improves final
accuracy over existing initialization methods. Additional studies show faster,
more stable convergence, robustness across ranks, and only a small
initialization overhead for LoRA-DA. The source code will be released upon
publication.

</details>


### [202] [DistDF: Time-Series Forecasting Needs Joint-Distribution Wasserstein Alignment](https://arxiv.org/abs/2510.24574)
*Hao Wang,Licheng Pan,Yuan Lu,Zhixuan Chu,Xiaoxi Li,Shuting He,Zhichao Chen,Haoxuan Li,Qingsong Wen,Zhouchen Lin*

Main category: cs.LG

TL;DR: 本论文提出DistDF，一种通过最小化条件预测与标签分布差异改进时间序列预测的方法，解决了传统方法中的偏差问题，并取得了卓越的预测效果。


<details>
  <summary>Details</summary>
Motivation: 研究传统预测方法中的偏差问题，提出改进模型训练的有效方法以提升预测性能。

Method: 通过交替最小化条件预测与标签分布之间的差异，使用了一种联合分布Wasserstein差异进行有效的估计。

Result: 本论文提出了一种新的时间序列预测模型训练方法，称为DistDF。传统的直接预测方法（DF）在面对标签自相关时，其基于均方误差的条件负对数似然估计存在偏差。DistDF通过交替最小化条件预测与标签分布之间的差异来实现对齐。为了解决基于有限时间序列观察估计条件差异的困难，我们引入了一种新提议的联合分布Wasserstein差异，该差异可证明地上界了感兴趣的条件差异，并且可从经验样本中有效、可微地估计。经过广泛的实验评估，DistDF在多种预测模型中表现优异，达到了最新的预测性能。

Conclusion: DistDF显著提升了不同预测模型的性能，并实现了最先进的预测效果。

Abstract: Training time-series forecast models requires aligning the conditional
distribution of model forecasts with that of the label sequence. The standard
direct forecast (DF) approach resorts to minimize the conditional negative
log-likelihood of the label sequence, typically estimated using the mean
squared error. However, this estimation proves to be biased in the presence of
label autocorrelation. In this paper, we propose DistDF, which achieves
alignment by alternatively minimizing a discrepancy between the conditional
forecast and label distributions. Because conditional discrepancies are
difficult to estimate from finite time-series observations, we introduce a
newly proposed joint-distribution Wasserstein discrepancy for time-series
forecasting, which provably upper bounds the conditional discrepancy of
interest. This discrepancy admits tractable, differentiable estimation from
empirical samples and integrates seamlessly with gradient-based training.
Extensive experiments show that DistDF improves the performance diverse
forecast models and achieves the state-of-the-art forecasting performance. Code
is available at https://anonymous.4open.science/r/DistDF-F66B.

</details>


### [203] [Physics-Informed Extreme Learning Machine (PIELM): Opportunities and Challenges](https://arxiv.org/abs/2510.24577)
*He Yang,Fei Ren,Hai-Sui Yu,Xiaohui Chen,Pei-Zhi Zhuang*

Main category: cs.LG

TL;DR: 本文回顾了物理信息极限学习机的发展，探讨了其在解决偏微分方程中面临的挑战及未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 总结和回顾物理信息极限学习机（PIELM）在物理信息机器学习中的发展，填补该领域文献的空白。

Method: 分析当前PIELM研究的进展，讨论解决偏微分方程所面临的各种困难与挑战。

Result: 提出了对PIELM现状的看法，并总结了该领域的研究成果与挑战。

Conclusion: 虽然PIELM取得了一定成功，但仍需克服众多挑战，以开发出更鲁棒、可解释且具有广泛适应性的框架，推动科学和工程领域的应用。

Abstract: We are very delighted to see the fast development of physics-informed extreme
learning machine (PIELM) in recent years for higher computation efficiency and
accuracy in physics-informed machine learning. As a summary or review on PIELM
is currently not available, we would like to take this opportunity to show our
perspective and experience for this promising research direction. We can see
many efforts are made to solve PDEs with sharp gradients, nonlinearities,
high-frequency behavior, hard constraints, uncertainty, multiphysics coupling.
Despite the success, many urgent challenges remain to be tackled, which also
provides us opportunities to develop more robust, interpretable, and
generalizable PIELM frameworks with applications in science and engineering.

</details>


### [204] [Semi-supervised and unsupervised learning for health indicator extraction from guided waves in aerospace composite structures](https://arxiv.org/abs/2510.24614)
*James Josep Perry,Pablo Garcia-Conde Ortiz,George Konstantinou,Cornelie Vergouwen,Edlyn Santha Kumaran,Morteza Moradi*

Main category: cs.LG

TL;DR: 本研究提出了一种数据驱动的框架，通过深度学习方法有效提取航空复合材料健康指标，展示了良好的性能提升。


<details>
  <summary>Details</summary>
Motivation: 由于材料特性的变异、损伤演化的随机性和多样的损伤模式，提取可靠的健康指标面临挑战，制造缺陷和在役事件使问题更加复杂，因此需要新的方法来监测复合材料结构的健康状态。

Method: 利用一种综合数据驱动框架，包括多域信号处理，并提出了半监督和无监督学习方法，如多样性深度半监督异常检测（Diversity-DeepSAD）和退化趋势约束变分自编码器（DTC-VAE）。

Result: Diversity-DeepSAD模型在快速傅里叶变换特征下实现了81.6%的性能，而DTC-VAE则以92.3%的性能提供了一致的健康指标，优于现有基准。

Conclusion: 研究展示了一种基于数据驱动的方法，通过多种学习策略有效提取航空复合材料结构的健康指标，提升了维护效率和安全性。

Abstract: Health indicators (HIs) are central to diagnosing and prognosing the
condition of aerospace composite structures, enabling efficient maintenance and
operational safety. However, extracting reliable HIs remains challenging due to
variability in material properties, stochastic damage evolution, and diverse
damage modes. Manufacturing defects (e.g., disbonds) and in-service incidents
(e.g., bird strikes) further complicate this process. This study presents a
comprehensive data-driven framework that learns HIs via two learning approaches
integrated with multi-domain signal processing. Because ground-truth HIs are
unavailable, a semi-supervised and an unsupervised approach are proposed: (i) a
diversity deep semi-supervised anomaly detection (Diversity-DeepSAD) approach
augmented with continuous auxiliary labels used as hypothetical damage proxies,
which overcomes the limitation of prior binary labels that only distinguish
healthy and failed states while neglecting intermediate degradation, and (ii) a
degradation-trend-constrained variational autoencoder (DTC-VAE), in which the
monotonicity criterion is embedded via an explicit trend constraint. Guided
waves with multiple excitation frequencies are used to monitor single-stiffener
composite structures under fatigue loading. Time, frequency, and time-frequency
representations are explored, and per-frequency HIs are fused via unsupervised
ensemble learning to mitigate frequency dependence and reduce variance. Using
fast Fourier transform features, the augmented Diversity-DeepSAD model achieved
81.6% performance, while DTC-VAE delivered the most consistent HIs with 92.3%
performance, outperforming existing baselines.

</details>


### [205] [Symbolic Snapshot Ensembles](https://arxiv.org/abs/2510.24633)
*Mingyue Liu,Andrew Cropper*

Main category: cs.LG

TL;DR: 提出了一种新的集成ILP方法，通过一次训练保存中间假设，结合后提高了预测准确率。


<details>
  <summary>Details</summary>
Motivation: 目标是通过一次训练保存多种假设，结合成一个集成模型，以此提升ILP的预测性能。

Method: 仅训练一次ILP算法并保存中间假设，然后使用最小描述长度加权方案合并这些假设。

Result: 通过实验验证，在游戏和视觉推理等多种基准任务上，所提方法有效提高了预测准确率。

Conclusion: 该方法在多个基准任务上提高了4%的预测准确率，并且计算开销不足1%。

Abstract: Inductive logic programming (ILP) is a form of logical machine learning. Most
ILP algorithms learn a single hypothesis from a single training run. Ensemble
methods train an ILP algorithm multiple times to learn multiple hypotheses. In
this paper, we train an ILP algorithm only once and save intermediate
hypotheses. We then combine the hypotheses using a minimum description length
weighting scheme. Our experiments on multiple benchmarks, including game
playing and visual reasoning, show that our approach improves predictive
accuracy by 4% with less than 1% computational overhead.

</details>


### [206] [Causal Ordering for Structure Learning From Time Series](https://arxiv.org/abs/2510.24639)
*Pedro P. Sanchez,Damian Machlanski,Steven McDonagh,Sotirios A. Tsaftaris*

Main category: cs.LG

TL;DR: 本文提出DOTS，这是一个通过整合多个有效因果排序来改进时间序列因果发现的方法， outperforming 传统基线。


<details>
  <summary>Details</summary>
Motivation: 从时间序列数据中预测因果结构对于理解生理学、大脑连接性、气候动态和社会经济行为等复杂现象至关重要。

Method: 结合多个因果排序，通过扩散过程实现有效的Hessian估计，解决传统单排序方法的限制。

Result: DOTS（扩散排序的时间结构）凭借基于扩散的因果发现方法，有效地恢复潜在有向无环图的传递闭包，缓解了单一排序方法固有的虚假伪影。

Conclusion: 实验表明，DOTS在各种基准测试中均表现优异，是一种可扩展且准确的时间因果发现解决方案。

Abstract: Predicting causal structure from time series data is crucial for
understanding complex phenomena in physiology, brain connectivity, climate
dynamics, and socio-economic behaviour. Causal discovery in time series is
hindered by the combinatorial complexity of identifying true causal
relationships, especially as the number of variables and time points grow. A
common approach to simplify the task is the so-called ordering-based methods.
Traditional ordering methods inherently limit the representational capacity of
the resulting model. In this work, we fix this issue by leveraging multiple
valid causal orderings, instead of a single one as standard practice. We
propose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based
causal discovery for temporal data. By integrating multiple orderings, DOTS
effectively recovers the transitive closure of the underlying directed acyclic
graph, mitigating spurious artifacts inherent in single-ordering approaches. We
formalise the problem under standard assumptions such as stationarity and the
additive noise model, and leverage score matching with diffusion processes to
enable efficient Hessian estimation. Extensive experiments validate the
approach. Empirical evaluations on synthetic and real-world datasets
demonstrate that DOTS outperforms state-of-the-art baselines, offering a
scalable and robust approach to temporal causal discovery. On synthetic
benchmarks ($d{=}\!3-\!6$ variables, $T{=}200\!-\!5{,}000$ samples), DOTS
improves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the
CausalTime real-world benchmark ($d{=}20\!-\!36$), while baselines remain the
best on individual datasets, DOTS attains the highest average summary-graph
$F1$ while halving runtime relative to graph-optimisation methods. These
results establish DOTS as a scalable and accurate solution for temporal causal
discovery.

</details>


### [207] [Pearl: A Foundation Model for Placing Every Atom in the Right Location](https://arxiv.org/abs/2510.24670)
*Genesis Research Team,Alejandro Dobles,Nina Jovic,Kenneth Leidal,Pranav Murugan,David C. Williams,Drausin Wulsin,Nate Gruver,Christina X. Ji,Korrawat Pruegsanusak,Gianluca Scarpellini,Ansh Sharma,Wojciech Swiderski,Andrea Bootsma,Richard Strong Bowen,Charlotte Chen,Jamin Chen,Marc André Dämgen,Roy Tal Dew,Benjamin DiFrancesco,J. D. Fishman,Alla Ivanova,Zach Kagin,David Li-Bland,Zuli Liu,Igor Morozov,Jeffrey Ouyang-Zhang,Frank C. Pickard IV,Kushal S. Shah,Ben Shor,Gabriel Monteiro da Silva,Maxx Tessmer,Carl Tilbury,Cyr Vetcher,Daniel Zeng,Maruan Al-Shedivat,Aleksandra Faust,Evan N. Feinberg,Michael V. LeVine,Matteus Pan*

Main category: cs.LG

TL;DR: 该研究介绍了一种名为Pearl的基础模型，用于大规模蛋白质-配体共折叠，以解决蛋白质-配体结构预测中的数据稀缺和效率等问题。


<details>
  <summary>Details</summary>
Motivation: 为了克服深度学习方法在蛋白质-配体结构预测中的数据和架构限制，提升预测的准确性和实用性。

Method: 该研究采用大规模合成数据的训练配方、SO(3)等变扩散模块以及可控推理架构来进行预测。

Result: Pearl模型在生成准确和物理有效的姿态上显著超越了AlphaFold 3和其他基准模型，尤其在口袋条件共折叠方面表现卓越。

Conclusion: Pearl在蛋白质-配体共折叠中建立了新的最先进性能，且与训练时使用的合成数据集大小直接相关。

Abstract: Accurately predicting the three-dimensional structures of protein-ligand
complexes remains a fundamental challenge in computational drug discovery that
limits the pace and success of therapeutic design. Deep learning methods have
recently shown strong potential as structural prediction tools, achieving
promising accuracy across diverse biomolecular systems. However, their
performance and utility are constrained by scarce experimental data,
inefficient architectures, physically invalid poses, and the limited ability to
exploit auxiliary information available at inference. To address these issues,
we introduce Pearl (Placing Every Atom in the Right Location), a foundation
model for protein-ligand cofolding at scale. Pearl addresses these challenges
with three key innovations: (1) training recipes that include large-scale
synthetic data to overcome data scarcity; (2) architectures that incorporate an
SO(3)-equivariant diffusion module to inherently respect 3D rotational
symmetries, improving generalization and sample efficiency, and (3)
controllable inference, including a generalized multi-chain templating system
supporting both protein and non-polymeric components as well as dual
unconditional/conditional modes. Pearl establishes a new state-of-the-art
performance in protein-ligand cofolding. On the key metric of generating
accurate (RMSD < 2 \r{A}) and physically valid poses, Pearl surpasses AlphaFold
3 and other open source baselines on the public Runs N' Poses and PoseBusters
benchmarks, delivering 14.5% and 14.2% improvements, respectively, over the
next best model. In the pocket-conditional cofolding regime, Pearl delivers
$3.6\times$ improvement on a proprietary set of challenging, real-world drug
targets at the more rigorous RMSD < 1 \r{A} threshold. Finally, we demonstrate
that model performance correlates directly with synthetic dataset size used in
training.

</details>


### [208] [Eigenfunction Extraction for Ordered Representation Learning](https://arxiv.org/abs/2510.24672)
*Burak Varıcı,Che-Ping Tsai,Ritabrata Ray,Nicholas M. Boffi,Pradeep Ravikumar*

Main category: cs.LG

TL;DR: 本研究提出了一种新的框架，用于从上下文核中提取有序、可识别的特征，增强特征选择的效率与准确性。


<details>
  <summary>Details</summary>
Motivation: 动机在于现有对比和非对比的学习目标未能完全恢复上下文核的特征重要性，通过更精确的特征提取，提升特征选择的质量。

Method: 本研究采用了一种基于模块化构建块的通用框架，并结合低秩近似与Rayleigh商优化实现特征提取。

Result: 本研究提出了一种新框架，旨在从上下文核中提取有序和可识别的特征。这一框架与低秩近似和Rayleigh商优化方法相结合，能够有效提取特征的特征值并据此进行特征选择，达到理想的效率与准确性平衡。

Conclusion: 通过合成核和真实世界图像数据的验证，我们的方法成功从特征中恢复重要性分数，并实现效率与准确性的权衡。

Abstract: Recent advances in representation learning reveal that widely used
objectives, such as contrastive and non-contrastive, implicitly perform
spectral decomposition of a contextual kernel, induced by the relationship
between inputs and their contexts. Yet, these methods recover only the linear
span of top eigenfunctions of the kernel, whereas exact spectral decomposition
is essential for understanding feature ordering and importance. In this work,
we propose a general framework to extract ordered and identifiable
eigenfunctions, based on modular building blocks designed to satisfy key
desiderata, including compatibility with the contextual kernel and scalability
to modern settings. We then show how two main methodological paradigms,
low-rank approximation and Rayleigh quotient optimization, align with this
framework for eigenfunction extraction. Finally, we validate our approach on
synthetic kernels and demonstrate on real-world image datasets that the
recovered eigenvalues act as effective importance scores for feature selection,
enabling principled efficiency-accuracy tradeoffs via adaptive-dimensional
representations.

</details>


### [209] [Learning to Drive Safely with Hybrid Options](https://arxiv.org/abs/2510.24674)
*Bram De Cooman,Johan Suykens*

Main category: cs.LG

TL;DR: 该论文将选项框架应用于高速公路自动驾驶任务，提出了一种通过分别选择纵向和横向控制动作的多种灵活政策，从而实现更好的驾驶表现。


<details>
  <summary>Details</summary>
Motivation: 探讨深度强化学习在自动驾驶中的应用，尤其是在选项框架下的不足之处。

Method: 采用选项框架进行层次控制，定义纵向和横向操作的专用选项，并结合状态-of-the-art的强化学习技术。

Result: 提出了应用选项框架的多种层次控制设置，并通过实用算法进行验证。

Conclusion: 通过将选项框架与自动驾驶任务结合，可以提升驾驶策略在不同交通条件下的表现。

Abstract: Out of the many deep reinforcement learning approaches for autonomous
driving, only few make use of the options (or skills) framework. That is
surprising, as this framework is naturally suited for hierarchical control
applications in general, and autonomous driving tasks in specific. Therefore,
in this work the options framework is applied and tailored to autonomous
driving tasks on highways. More specifically, we define dedicated options for
longitudinal and lateral manoeuvres with embedded safety and comfort
constraints. This way, prior domain knowledge can be incorporated into the
learning process and the learned driving behaviour can be constrained more
easily. We propose several setups for hierarchical control with options and
derive practical algorithms following state-of-the-art reinforcement learning
techniques. By separately selecting actions for longitudinal and lateral
control, the introduced policies over combined and hybrid options obtain the
same expressiveness and flexibility that human drivers have, while being easier
to interpret than classical policies over continuous actions. Of all the
investigated approaches, these flexible policies over hybrid options perform
the best under varying traffic conditions, outperforming the baseline policies
over actions.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [210] [Coordinated Autonomous Drones for Human-Centered Fire Evacuation in Partially Observable Urban Environments](https://arxiv.org/abs/2510.23899)
*Maria G. Mendoza,Addison Kalanther,Daniel Bostwick,Emma Stephan,Chinmay Maheshwari,Shankar Sastry*

Main category: cs.MA

TL;DR: 本研究提出利用自主无人机技术增强疏散操作，通过多智能体协调框架有效指导人类避险，显著提高救援效率。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于解决现有疏散模型忽视人类在极端压力下的心理与情感复杂性，尤其是在真实火灾场景中，疏散者往往因恐慌和不确定性偏离安全路线。

Method: 该研究使用部分可观察马尔可夫决策过程（POMDP）建模问题，结合了高层和低层救助无人机的协调，采用PPO算法进行决策。

Result: 仿真结果显示，无人机团队能够迅速定位和拦截疏散者，相较于没有无人机辅助的环境，大幅度减少了疏散者到达安全区域所需的时间。

Conclusion: 本研究提出的多智能体协调框架有效提高了无人机在动态疏散中的辅助作用，能够显著缩短疏散者到达安全区域的时间。

Abstract: Autonomous drone technology holds significant promise for enhancing search
and rescue operations during evacuations by guiding humans toward safety and
supporting broader emergency response efforts. However, their application in
dynamic, real-time evacuation support remains limited. Existing models often
overlook the psychological and emotional complexity of human behavior under
extreme stress. In real-world fire scenarios, evacuees frequently deviate from
designated safe routes due to panic and uncertainty. To address these
challenges, this paper presents a multi-agent coordination framework in which
autonomous Unmanned Aerial Vehicles (UAVs) assist human evacuees in real-time
by locating, intercepting, and guiding them to safety under uncertain
conditions. We model the problem as a Partially Observable Markov Decision
Process (POMDP), where two heterogeneous UAV agents, a high-level rescuer (HLR)
and a low-level rescuer (LLR), coordinate through shared observations and
complementary capabilities. Human behavior is captured using an agent-based
model grounded in empirical psychology, where panic dynamically affects
decision-making and movement in response to environmental stimuli. The
environment features stochastic fire spread, unknown evacuee locations, and
limited visibility, requiring UAVs to plan over long horizons to search for
humans and adapt in real-time. Our framework employs the Proximal Policy
Optimization (PPO) algorithm with recurrent policies to enable robust
decision-making in partially observable settings. Simulation results
demonstrate that the UAV team can rapidly locate and intercept evacuees,
significantly reducing the time required for them to reach safety compared to
scenarios without UAV assistance.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [211] [Reality Distortion Room: A Study of User Locomotion Responses to Spatial Augmented Reality Effects](https://arxiv.org/abs/2510.23840)
*You-Jin Kim,Andrew D. Wilson,Jennifer Jacobs,Tobias Höllerer*

Main category: cs.HC

TL;DR: 本研究探讨了增强现实系统如何通过不同的视觉效果鼓励用户在物理空间中运动。


<details>
  <summary>Details</summary>
Motivation: 研究用户在视觉效果影响下的运动反应，探索如何通过增强现实效果鼓励用户运动。

Method: 使用投影映射及与Microsoft RoomAlive系统的无障碍互动的增强现实系统进行实验。

Result: 实验展示了不同的视觉扭曲和增强效果对用户在普通客厅环境中的反应，效果包括墙面网格、家具全息图和空气中的小颗粒。

Conclusion: 结果表明，AR体验在有限的物理空间中的实施是可行的，有助于用户在房间内的运动。

Abstract: Reality Distortion Room (RDR) is a proof-of-concept augmented reality system
using projection mapping and unencumbered interaction with the Microsoft
RoomAlive system to study a user's locomotive response to visual effects that
seemingly transform the physical room the user is in. This study presents five
effects that augment the appearance of a physical room to subtly encourage user
motion. Our experiment demonstrates users' reactions to the different
distortion and augmentation effects in a standard living room, with the
distortion effects projected as wall grids, furniture holograms, and small
particles in the air. The augmented living room can give the impression of
becoming elongated, wrapped, shifted, elevated, and enlarged. The study results
support the implementation of AR experiences in limited physical spaces by
providing an initial understanding of how users can be subtly encouraged to
move throughout a room.

</details>


### [212] [Spatial Orchestra: Locomotion Music Instruments through Spatial Exploration](https://arxiv.org/abs/2510.23848)
*You-Jin Kim,Myungin Lee,Marko Peljhan,JoAnn Kuchera-Morin,Tobias Höllerer*

Main category: cs.HC

TL;DR: Spatial Orchestra 是一个通过增强现实技术，使用户可以轻松创作音乐的互动体验，强调空间意识和音乐表现之间的关系。


<details>
  <summary>Details</summary>
Motivation: 为了让更多人能够体验音乐创作的乐趣，打破传统乐器的门槛，提升人们的空间意识和音乐表现能力。

Method: 通过自然的身体移动和步入颜色编码的虚拟泡泡，用户可以与声音进行互动，体验音乐创作的过程。

Result: Spatial Orchestra是一个增强现实体验，用户通过自然 locomotion interacting 可以容易地演奏音乐。与传统乐器不同，用户无论技能水平如何，都可以在虚拟泡泡中毫不费力地创作音乐。每个泡泡都对应一个大提琴音符，用户通过走进颜色编码的泡泡来互动。这个体验结合了空间意识、音乐节奏及身体表达，创造出一种独特而丰富的音乐演奏体验。

Conclusion: Spatial Orchestra 的设计让不同技能水平的用户都能参与音乐创作，展示了空间意识和音乐表演之间的微妙关系。

Abstract: Spatial Orchestra demonstrates how easy it is to play musical instruments
using basic input like natural locomotion, which is accessible to most. Unlike
many musical instruments, our work allows individuals of all skill levels to
effortlessly create music by walking into virtual bubbles. Our Augmented
Reality experience involves interacting with ever-shifting sound bubbles that
the user engages with by stepping into color-coded bubbles within the assigned
area using a standalone AR headset. Each bubble corresponds to a cello note,
and omits sound from the center of the bubble, and lets the user hear and
express in spatial audio, effectively transforming participants into musicians.
This interactive element enables users to explore the intersection of spatial
awareness, musical rhythm that extends to bodily expression through playful
movements and dance-like gestures within the bubble-filled environment. This
unique experience illuminates the intricate relationship between spatial
awareness and the art of musical performance.

</details>


### [213] [MORA: AI-Mediated Story-Based practice for Speech Sound Disorder from Clinic to Home](https://arxiv.org/abs/2510.23887)
*Sumin Hong,Xavier Briggs,Qingxiao Zheng,Yao Du,Jinjun Xiong,Toby Jia-jun Li*

Main category: cs.HC

TL;DR: MORA是一个互动故事实践系统，通过动态叙事、视觉提示以及AI支持，帮助学前儿童解决语音障碍，旨在提高练习的有效性与参与度。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有家庭实践工具交互性不足、与临床治疗计划不一致的问题，提高儿童在语言治疗中的参与度和练习有效性。

Method: 通过与多个执业言语语言治疗师的合作，设计了MORA系统，包含故事叙事、视觉支持、AI工作流程等元素。

Result: 本研究介绍了一种名为MORA的互动故事实践系统，旨在帮助学前儿童克服语音障碍。该系统集成了三个创新要素：将目标语音和词汇嵌入以角色为驱动的对话叙事中，以激励儿童主动发声；提供视觉提示、明确指导和反馈，支持独立或与看护者的练习；以及支持AI干预的工作流程，使言语语言治疗师能够配置材料并异步调整治疗计划。经过与多位执业治疗师的讨论与评估，证实该系统与现有的发音治疗方法相一致，并具备提高儿童参与度和文明的潜力。

Conclusion: MORA有潜力在儿童语言障碍的治疗中发挥重要作用，桥接临床与家庭实践，同时尊重专业治疗师的专业知识。

Abstract: Speech sound disorder is among the most common communication challenges in
preschool children. Home-based practice is essential for effective therapy and
for acquiring generalization of target sounds, yet sustaining engaging and
consistent practice remains difficult. Existing story-based activities, despite
their potential for sound generalization and educational benefits, are often
underutilized due to limited interactivity. Moreover, many practice tools fail
to sufficiently integrate speech--language pathologists into the process,
resulting in weak alignment with clinical treatment plans. To address these
limitations, we present MORA, an interactive story-based practice system. MORA
introduces three key innovations. First, it embeds target sounds and vocabulary
into dynamic, character-driven conversational narratives, requiring children to
actively produce speech to progress the story, thereby creating natural
opportunities for exposure, repetition, and generalization. Second, it provides
visual cues, explicit instruction, and feedback, allowing children to practice
effectively either independently or with caregivers. Third, it supports an
AI-in-the-loop workflow, enabling SLPs to configure target materials, review
logged speech with phoneme-level scoring, and adapt therapy plans
asynchronously -- bridging the gap between clinic and home practice while
respecting professional expertise. A formative study with six licensed SLPs
informed the system's design rationale, and an expert review with seven SLPs
demonstrated strong alignment with established articulation-based treatments,
as well as potential to enhance children's engagement and literacy.
Furthermore, discussions highlight the design considerations for professional
support and configurability, adaptive and multimodal child interaction, while
highlighting MORA's broader applicability across speech and language disorders.

</details>


### [214] [Towards AI as Colleagues: Multi-Agent System Improves Structured Professional Ideation](https://arxiv.org/abs/2510.23904)
*Kexin Quan,Dina Albassam,Mengke Wu,Zijian Ding,Jessie Chin*

Main category: cs.HC

TL;DR: 本研究介绍了MultiColleagues，一种多智能体对话系统，能够通过相互交流和用户合作进行创意生成，与单智能体系统相比，表现出更强的社会存在感和更高质量的新颖性想法。


<details>
  <summary>Details</summary>
Motivation: 当前的AI系统虽然能够有效管理任务，但在与人类进行共同问题解决和创意贡献方面存在局限性。

Method: 通过对20名参与者进行的内部对照研究，比较MultiColleagues和单智能体基线的表现。

Result: MultiColleagues增强了社会存在感，产生了质量和新颖性显著更高的创意，并促进了更深层次的讨论。

Conclusion: MultiColleagues展示了AI智能体超越传统过程合作伙伴的潜力，为人类提供更深层次的协作与创意分享。

Abstract: Most AI systems today are designed to manage tasks and execute predefined
steps. This makes them effective for process coordination but limited in their
ability to engage in joint problem-solving with humans or contribute new ideas.
We introduce MultiColleagues, a multi-agent conversational system that shows
how AI agents can act as colleagues by conversing with each other, sharing new
ideas, and actively involving users in collaborative ideation. In a
within-subjects study with 20 participants, we compared MultiColleagues to a
single-agent baseline. Results show that MultiColleagues fostered stronger
perceptions of social presence, produced ideas rated significantly higher in
quality and novelty, and encouraged deeper elaboration. These findings
demonstrate the potential of AI agents to move beyond process partners toward
colleagues that share intent, strengthen group dynamics, and collaborate with
humans to advance ideas.

</details>


### [215] [Toward Socially-Aware LLMs: A Survey of Multimodal Approaches to Human Behavior Understanding](https://arxiv.org/abs/2510.23947)
*Zihan Liu,Parisa Rabbani,Veda Duddu,Kyle Fan,Madison Lee,Yun Huang*

Main category: cs.HC

TL;DR: 本研究评审了LLM驱动的多模态系统解读人类行为的应用现状，指出了在技术、评估和伦理方面的不足，并提出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 旨在加深对大语言模型在多模态系统中如何理解和应用社会能力的认识，推动相关研究的深入发展。

Method: 通过四维编码框架对176篇文献进行系统文献回顾，涵盖应用、技术、评估和伦理维度。

Result: 该论文系统回顾了176篇关于大语言模型（LLM）驱动的多模态系统在解读人类社会行为方面的应用，探讨了研究者如何应用这些模型的社会能力。发现这些系统普遍使用模式识别和信息提取，但对自适应、交互推理支持有限，主要依赖文本模式而忽视丰富的视听线索；评价方法多依赖静态基准，缺乏以社会为基础和以人为中心的评估；伦理讨论主要聚焦法律和隐私风险，社会风险（如欺骗）未被充分重视或仅在表面上提到。

Conclusion: 强调了需要一个以社会能力、伦理认识和互动意识为基础的多模态系统的评估研究议程。

Abstract: LLM-powered multimodal systems are increasingly used to interpret human
social behavior, yet how researchers apply the models' 'social competence'
remains poorly understood. This paper presents a systematic literature review
of 176 publications across different application domains (e.g., healthcare,
education, and entertainment). Using a four-dimensional coding framework
(application, technical, evaluative, and ethical), we find (1) frequent use of
pattern recognition and information extraction from multimodal sources, but
limited support for adaptive, interactive reasoning; (2) a dominant
'modality-to-text' pipeline that privileges language over rich audiovisual
cues, striping away nuanced social cues; (3) evaluation practices reliant on
static benchmarks, with socially grounded, human-centered assessments rare; and
(4) Ethical discussions focused mainly on legal and rights-related risks (e.g.,
privacy), leaving societal risks (e.g., deception) overlooked--or at best
acknowledged but left unaddressed. We outline a research agenda for evaluating
socially competent, ethically informed, and interaction-aware multi-modal
systems.

</details>


### [216] [Understanding Reader Perception Shifts upon Disclosure of AI Authorship](https://arxiv.org/abs/2510.24011)
*Hiroki Nakano,Jo Takezawa,Fabrice Matulic,Chi-Lan Yang,Koji Yatani*

Main category: cs.HC

TL;DR: 这项研究探讨了在写作支持中披露AI使用对读者印象的影响，发现披露通常会降低对作者的信任感、关怀度、能力和可爱度，尤其在社交写作中影响最为明显。但AI素养较高的读者对此的负面感知有所减轻。


<details>
  <summary>Details</summary>
Motivation: 在AI写作支持普及的背景下，探索其使用披露如何影响读者的感知，为相关领域提供新的见解。

Method: 通过对261名参与者的990份反馈进行分析，研究了不同程度的AI参与披露对作者印象的影响。

Result: 披露AI的使用通常会降低读者的信任感和好感，尤其是在社交和人际写作中，AI素养较高的读者对此影响表现出更大的容忍度或欣赏。

Conclusion: 研究表明，在AI写作中，披露AI的使用会导致读者对作者信任和亲和力的下降，但提高AI素养能够改善这种状况。

Abstract: As AI writing support becomes ubiquitous, how disclosing its use affects
reader perception remains a critical, underexplored question. We conducted a
study with 261 participants to examine how revealing varying levels of AI
involvement shifts author impressions across six distinct communicative acts.
Our analysis of 990 responses shows that disclosure generally erodes
perceptions of trustworthiness, caring, competence, and likability, with the
sharpest declines in social and interpersonal writing. A thematic analysis of
participants' feedback links these negative shifts to a perceived loss of human
sincerity, diminished author effort, and the contextual inappropriateness of
AI. Conversely, we find that higher AI literacy mitigates these negative
perceptions, leading to greater tolerance or even appreciation for AI use. Our
results highlight the nuanced social dynamics of AI-mediated authorship and
inform design implications for creating transparent, context-sensitive writing
systems that better preserve trust and authenticity.

</details>


### [217] [VR-Assisted Guide Dog Training: A 360° PanoHaptic System for Right-Hand Commands Analysis](https://arxiv.org/abs/2510.24057)
*Qirong Zhu,Ansheng Wang,Shinji Tanaka,Yasutoshi Makino,Hiroyuki Shinoda*

Main category: cs.HC

TL;DR: 本研究提出了一种基于虚拟现实的导盲犬训练系统，以帮助新手训练师理解导盲犬行为并适当发出训练指令。


<details>
  <summary>Details</summary>
Motivation: 由于合格训练师数量有限，训练过程复杂且要求高，因此亟需一种更有效的培训方式。

Method: 系统集成了全景视觉和触觉反馈，创造了一个沉浸式的训练环境。

Result: 系统通过改善右手指令的时效性和准确性，提供了多场景的独立练习机会，提升了训练效果。

Conclusion: 该系统通过虚拟现实技术改善了训练质量，预计将加速技能获取，并提高合格训练师的供给，从而增加对视障人士的导盲犬的可用性。

Abstract: This paper presents a VR-based guide dog training system designed to assist
novice trainers in understanding guide dog behavior and issuing appropriate
training commands. Guide dogs play a vital role in supporting independent
mobility for visually impaired individuals, yet the limited number of skilled
trainers restricts their availability. Training is highly demanding, requiring
accurate observation of the dog's status and precise command issuance,
especially through right-hand gestures. While the trainer's left hand holds the
harness to perceive haptic cues, the right hand is used to indicate directions,
maintain attention, and provide comfort, with motion patterns varying by
scenario and the dog's progress. Currently, novices learn mainly by observing
experts or watching videos, which lacks immersion and makes it difficult to
adopt the trainer's perspective for understanding behavior or synchronizing
command timing.
  To address these limitations, the proposed system introduces a VR-based
assistive platform integrating panoramic visuals and haptic feedback to create
an immersive training environment. The visual module provides contextual
guidance, including cues for command execution and real-time comparison of the
user's posture with standard actions, while the haptic module delivers tactile
feedback for command gestures. Users can re-experience training sessions across
diverse scenarios and dog proficiency levels, allowing independent and repeated
practice. By improving the timing, accuracy, and expressiveness of right-hand
commands, the system aims to accelerate skill acquisition, enhance training
quality, and mitigate the shortage of qualified trainers, ultimately increasing
the availability of guide dogs for visually impaired individuals.

</details>


### [218] [Building AI Literacy at Home: How Families Navigate Children's Self-Directed Learning with AI](https://arxiv.org/abs/2510.24070)
*Jingyi Xie,Chuhao Wu,Ge Wang,Rui Yu,He Zhang,Ronald Metoyer,Si Chen*

Main category: cs.HC

TL;DR: 本文探讨了父母如何在儿童学习空间中支持和引导生成性人工智能的使用，强调了自我导向学习的重要性和家长的参与角色。


<details>
  <summary>Details</summary>
Motivation: 研究生成性人工智能在儿童学习中的应用，帮助家庭应对新的使用挑战。

Method: 通过与13对父母-儿童组进行焦点小组讨论，收集父母对儿童人工智能素养发展的看法。

Result: 父母对人工智能的理解存在差距，通常通过共同探索和参与的方式进行学习，许多父母主要将人工智能视为学习工具，忽视其非教育角色及相关风险。

Conclusion: 家庭共同构建儿童的人工智能素养，同时在实际期望与批判性素养之间存在紧张关系。

Abstract: As generative AI becomes embedded in children's learning spaces, families
face new challenges in guiding its use. Middle childhood (ages 7-13) is a
critical stage where children seek autonomy even as parental influence remains
strong. Using self-directed learning (SDL) as a lens, we examine how parents
perceive and support children's developing AI literacy through focus groups
with 13 parent-child pairs. Parents described evolving phases of engagement
driven by screen time, self-motivation, and growing knowledge. While many
framed AI primarily as a study tool, few considered its non-educational roles
or risks, such as privacy and infrastructural embedding. Parents also noted
gaps in their own AI understanding, often turning to joint exploration and
engagement as a form of co-learning. Our findings reveal how families
co-construct children's AI literacy, exposing tensions between practical
expectations and critical literacies, and provide design implications that
foster SDL while balancing autonomy and oversight.

</details>


### [219] [Detecting the Use of Generative AI in Crowdsourced Surveys: Implications for Data Integrity](https://arxiv.org/abs/2510.24594)
*Dapeng Zhang,Marina Katoh,Weiping Pei*

Main category: cs.HC

TL;DR: 本研究探讨了生成性人工智能对众包数据收集的影响，评估了检测AI生成响应的两种方法，发现AI生成的调查响应显著增加，提示数据完整性的潜在风险。


<details>
  <summary>Details</summary>
Motivation: 随着生成性人工智能的广泛应用，特别是在调查研究中，其意外使用对数据完整性构成威胁，促进了对检测AI生成响应的研究。

Method: 通过比较2022年前后七项调查研究的数据，评估LLM基础检测和签名基础检测两种方法的有效性。

Result: 研究结果表明，2022年后调查中AI生成响应显著增加，反映出生成性人工智能对众包数据可能造成的隐性扭曲。

Conclusion: 本研究揭示了生成性人工智能在众包数据收集中的潜在威胁，并提出了检测AI生成响应的有效策略，以保护研究的完整性。

Abstract: The widespread adoption of generative AI (GenAI) has introduced new
challenges in crowdsourced data collection, particularly in survey-based
research. While GenAI offers powerful capabilities, its unintended use in
crowdsourcing, such as generating automated survey responses, threatens the
integrity of empirical research and complicates efforts to understand public
opinion and behavior. In this study, we investigate and evaluate two approaches
for detecting AI-generated responses in online surveys: LLM-based detection and
signature-based detection. We conducted experiments across seven survey
studies, comparing responses collected before 2022 with those collected after
the release of ChatGPT. Our findings reveal a significant increase in
AI-generated responses in the post-2022 studies, highlighting how GenAI may
silently distort crowdsourced data. This work raises broader concerns about
evolving landscape of data integrity, where GenAI can compromise data quality,
mislead researchers, and influence downstream findings in fields such as
health, politics, and social behavior. By surfacing detection strategies and
empirical evidence of GenAI's impact, we aim to contribute to ongoing
conversation about safeguarding research integrity and supporting scholars
navigating these methodological and ethical challenges.

</details>


### [220] [What Does It Take? Developing a Smartphone App that Motivates Older Adults to be Physically Active](https://arxiv.org/abs/2510.24638)
*Sabrina Haque,Kyle Henry,Troyee Saha,Kimberly Vanhoose,Jobaidul Boni,Samantha Moss,Kate Hyun,Kathy Siepker,Xiangli Gu,Angela Liegey-Dougall,Stephen Mattingly,Christoph Csallner*

Main category: cs.HC

TL;DR: 本研究探讨了Senior Fit，一个为老年人设计的独立移动健身应用的可行性和参与度，发现其在设计数字健康干预中的潜力和挑战。


<details>
  <summary>Details</summary>
Motivation: 随着老年人身体活动的参与度低，开发能有效促进他们健康的数字干预工具显得尤为重要。

Method: 通过与25名65至85岁的参与者进行持续测试，根据反馈优化应用，以提高可用性和可及性。

Result: 老年人重视运动演示视频和提醒，但对手动记录和个性化选择表示不满，社交支持的有效性因平台熟悉度而异。

Conclusion: 本研究提出了针对老年人的移动健身工具设计建议，强调灵活追踪、明确反馈和低门槛社交支持的重要性，以促进长期、现实世界中的部署。

Abstract: Maintaining physical activity is essential for older adults' health and
well-being, yet participation remains low. Traditional paper-based and
in-person interventions have been effective but face scalability issues.
Smartphone apps offer a potential solution, but their effectiveness in
real-world use remains underexplored. Most prior studies take place in
controlled environments, use specialized hardware, or rely on in-person
training sessions or researcher-led setup. This study examines the feasibility
and engagement of Senior Fit, a standalone mobile fitness app designed for
older adults. We conducted continuous testing with 25 participants aged 65-85,
refining the app based on their feedback to improve usability and
accessibility. Our findings underscore both the potential and key challenges in
designing digital health interventions. Older adults valued features such as
video demonstrations and reminders that made activity feel accessible and
motivating, yet some expressed frustration with manual logging and limited
personalization. The Facebook group provided encouragement for some but
excluded others unfamiliar with the platform. These results highlight the need
for fitness apps that integrate flexible tracking, clear feedback, and
low-barrier social support. We contribute design recommendations for creating
inclusive mobile fitness tools that align with older adults' routines and
capabilities, offering insights for future long-term, real-world deployments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [221] [BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning](https://arxiv.org/abs/2510.24161)
*Wentao Tan,Bowen Wang,Heng Zhi,Chenyu Liu,Zhe Li,Jian Liu,Zengrong Lin,Yukun Dai,Yipeng Chen,Wenjie Yang,Enci Xie,Hao Xue,Baixu Ji,Chen Xu,Zhibin Wang,Tianshi Wang,Lei Zhu,Heng Tao Shen*

Main category: cs.AI

TL;DR: 本研究提出的BLM$_1$通过两阶段训练克服了现有多模态大语言模型的局限，在数字与物理空间中的任务中实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在数字与物理空间之间的迁移和推广能力较弱，尚缺乏能够无缝适应不同空间和任务的统一模型。

Method: BLM$_1$采用两阶段训练范式，第一阶段通过策划的数字语料注入具身知识并维持语言能力，第二阶段通过意图桥接接口训练策略模块，以提取高层语义指导控制。

Result: 通过在数字和物理基准测试中的评估，BLM$_1$表现优于四个模型家族，显示其有效整合了跨空间、跨任务与跨典型体的能力。

Conclusion: BLM$_1$在数字和物理任务中分别实现了约6%和3%的性能提升，展示出了其在跨空间、跨任务和跨典型体概括方面的强大能力。

Abstract: Multimodal large language models (MLLMs) have advanced vision-language
reasoning and are increasingly deployed in embodied agents. However,
significant limitations remain: MLLMs generalize poorly across digital-physical
spaces and embodiments; vision-language-action models (VLAs) produce low-level
actions yet lack robust high-level embodied reasoning; and most embodied large
language models (ELLMs) are constrained to digital-space with poor
generalization to the physical world. Thus, unified models that operate
seamlessly across digital and physical spaces while generalizing across
embodiments and tasks remain absent. We introduce the \textbf{Boundless Large
Model (BLM$_1$)}, a multimodal spatial foundation model that preserves
instruction following and reasoning, incorporates embodied knowledge, and
supports robust cross-embodiment control. BLM$_1$ integrates three key
capabilities -- \textit{cross-space transfer, cross-task learning, and
cross-embodiment generalization} -- via a two-stage training paradigm. Stage I
injects embodied knowledge into the MLLM through curated digital corpora while
maintaining language competence. Stage II trains a policy module through an
intent-bridging interface that extracts high-level semantics from the MLLM to
guide control, without fine-tuning the MLLM backbone. This process is supported
by a self-collected cross-embodiment demonstration suite spanning four robot
embodiments and six progressively challenging tasks. Evaluations across digital
and physical benchmarks show that a single BLM$_1$ instance outperforms four
model families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving
$\sim\!\textbf{6%}$ gains in digital tasks and $\sim\!\textbf{3%}$ in physical
tasks.

</details>


### [222] [AI and the Decentering of Disciplinary Creativity](https://arxiv.org/abs/2510.23734)
*Eamon Duede*

Main category: cs.AI

TL;DR: 本文探讨人工智能在科学问题解决中的作用及其对学科创造力的影响，指出尽管计算增强创造力，AI方法可能会取代这种创造力。


<details>
  <summary>Details</summary>
Motivation: 探讨创造力哲学中的最新研究，区分创意方法与创意产品，并提出学科创造力的概念。

Method: 分析人工智能在科学问题解决中的角色，重点关注其对学科创造力的影响。

Result: 通过两个数学案例，表明计算可以扩展学科创造力，但某些涉及人工智能的方法可能会取代它。

Conclusion: 人工智能的某些应用可能会改变科学追求的价值，甚至可能降低其价值。

Abstract: This paper examines the role of artificial intelligence in scientific
problem-solving, with a focus on its implications for disciplinary creativity.
Drawing on recent work in the philosophy of creativity, I distinguish between
creative approaches and creative products, and introduce the concept of
disciplinary creativity -the creative application of discipline-specific
expertise to a valued problem within that field. Through two cases in
mathematics, I show that while computation can extend disciplinary creativity,
certain approaches involving AI can serve to displace it. This displacement has
the potential to alter (and, perhaps, diminish) the value of scientific
pursuit.

</details>


### [223] [Multi-Environment POMDPs: Discrete Model Uncertainty Under Partial Observability](https://arxiv.org/abs/2510.23744)
*Eline M. Bovy,Caleb Probine,Marnix Suilen,Ufuk Topcu,Nils Jansen*

Main category: cs.AI

TL;DR: 本研究扩展了ME-POMDPs的概念，提出了新的算法来计算在多环境背景下的稳健策略。


<details>
  <summary>Details</summary>
Motivation: 研究多环境部分可观测马尔可夫决策过程（ME-POMDPs）以处理模型不确定性，适用于多个领域专家对问题建模存在分歧的情况。

Method: 提出了对抗信念POMDPs（AB-POMDPs）的定义，并开发了精确和近似算法来计算稳健策略。

Result: 提出了针对AB-POMDPs和ME-POMDPs的精确和近似算法，以计算稳健策略。

Conclusion: 通过将ME-POMDPs简化为只在转移和奖励函数或观察和奖励函数上变化的形式，同时保持最优策略，我们成功计算了针对标准POMDP基准测试的策略。

Abstract: Multi-environment POMDPs (ME-POMDPs) extend standard POMDPs with discrete
model uncertainty. ME-POMDPs represent a finite set of POMDPs that share the
same state, action, and observation spaces, but may arbitrarily vary in their
transition, observation, and reward models. Such models arise, for instance,
when multiple domain experts disagree on how to model a problem. The goal is to
find a single policy that is robust against any choice of POMDP within the set,
i.e., a policy that maximizes the worst-case reward across all POMDPs. We
generalize and expand on existing work in the following way. First, we show
that ME-POMDPs can be generalized to POMDPs with sets of initial beliefs, which
we call adversarial-belief POMDPs (AB-POMDPs). Second, we show that any
arbitrary ME-POMDP can be reduced to a ME-POMDP that only varies in its
transition and reward functions or only in its observation and reward
functions, while preserving (optimal) policies. We then devise exact and
approximate (point-based) algorithms to compute robust policies for AB-POMDPs,
and thus ME-POMDPs. We demonstrate that we can compute policies for standard
POMDP benchmarks extended to the multi-environment setting.

</details>


### [224] [Test-Time Tuned Language Models Enable End-to-end De Novo Molecular Structure Generation from MS/MS Spectra](https://arxiv.org/abs/2510.23746)
*Laura Mismetti,Marvin Alberts,Andreas Krause,Mara Graziani*

Main category: cs.AI

TL;DR: 本文提出了一种基于测试时调整的框架，能够直接从串联质谱生成分子结构，超越现有方法并提高了对新光谱的适应性。


<details>
  <summary>Details</summary>
Motivation: 当前方法对未在参考数据库中观察到的化合物识别难度较大，迫切需要一种高效的解决方案。

Method: 采用测试时调整方法，利用预训练的变压器模型，直接从串联质谱和分子式中生成分子结构。

Result: 本论文介绍了一种框架，通过测试时调整增强预训练变压器模型的学习，以从串联质谱和分子式直接生成分子结构， bypassing 手动注释和中间步骤。 该方法在 NPLIB1 和 MassSpecGym 两个基准上分别超越了现有的 DiffMS 方法 100% 和 20%。 测试时调整使得模型能够动态适应新的光谱，并且在 MassSpecGym 上相较常规微调的性能提升达62%。当预测偏离实际情况时，生成的分子候选仍保持结构准确，为人类解读和更可靠的识别提供重要指导。

Conclusion: 通过测试时调整，能够有效扩大对未知化合物的识别能力，提供有效的分子生成和识别方案。

Abstract: Tandem Mass Spectrometry enables the identification of unknown compounds in
crucial fields such as metabolomics, natural product discovery and
environmental analysis. However, current methods rely on database matching from
previously observed molecules, or on multi-step pipelines that require
intermediate fragment or fingerprint prediction. This makes finding the correct
molecule highly challenging, particularly for compounds absent from reference
databases. We introduce a framework that, by leveraging test-time tuning,
enhances the learning of a pre-trained transformer model to address this gap,
enabling end-to-end de novo molecular structure generation directly from the
tandem mass spectra and molecular formulae, bypassing manual annotations and
intermediate steps. We surpass the de-facto state-of-the-art approach DiffMS on
two popular benchmarks NPLIB1 and MassSpecGym by 100% and 20%, respectively.
Test-time tuning on experimental spectra allows the model to dynamically adapt
to novel spectra, and the relative performance gain over conventional
fine-tuning is of 62% on MassSpecGym. When predictions deviate from the ground
truth, the generated molecular candidates remain structurally accurate,
providing valuable guidance for human interpretation and more reliable
identification.

</details>


### [225] [Evaluating In Silico Creativity: An Expert Review of AI Chess Compositions](https://arxiv.org/abs/2510.23772)
*Vivek Veeriah,Federico Barbero,Marcus Chiam,Xidong Feng,Michael Dennis,Ryan Pachauri,Thomas Tumiel,Johan Obando-Ceron,Jiaxin Shi,Shaobo Hou,Satinder Singh,Nenad Tomašev,Tom Zahavy*

Main category: cs.AI

TL;DR: 本研究探讨了生成式AI在创作国际象棋难题方面的能力，专家评估表明其具备创新性和美学价值。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI在创作和生成新的国际象棋难题方面的能力。

Method: 设计了一种AI系统用于生成具有创新性和审美吸引力的国际象棋难题。

Result: 经过国际象棋领域著名专家的评估，AI生成的难题被认为具备很高的创意和挑战性。

Conclusion: AI系统能够生成具有美学吸引力和独特解决方案的国际象棋难题，且得到了国际象棋领域专家的积极反馈。

Abstract: The rapid advancement of Generative AI has raised significant questions
regarding its ability to produce creative and novel outputs. Our recent work
investigates this question within the domain of chess puzzles and presents an
AI system designed to generate puzzles characterized by aesthetic appeal,
novelty, counter-intuitive and unique solutions. We briefly discuss our method
below and refer the reader to the technical paper for more details. To assess
our system's creativity, we presented a curated booklet of AI-generated puzzles
to three world-renowned experts: International Master for chess compositions
Amatzia Avni, Grandmaster Jonathan Levitt, and Grandmaster Matthew Sadler. All
three are noted authors on chess aesthetics and the evolving role of computers
in the game. They were asked to select their favorites and explain what made
them appealing, considering qualities such as their creativity, level of
challenge, or aesthetic design.

</details>


### [226] [Why Foundation Models in Pathology Are Failing](https://arxiv.org/abs/2510.23807)
*Hamid R. Tizhoosh*

Main category: cs.AI

TL;DR: 基础模型在计算病理学中的应用面临多重挑战，主要源于与组织复杂性之间的理论不匹配。


<details>
  <summary>Details</summary>
Motivation: 探讨基础模型在计算病理学中的应用及其面临的挑战，特别是在癌症诊断和预后方面的潜力未能实现。

Method: 系统评估现有病理基础模型的表现，识别七个导致诊断准确性低和稳健性差的相互关联的原因。

Result: 揭示当前计算病理学中的基础模型存在的主要问题，强调其在处理人类组织复杂性方面的局限性。

Conclusion: 当前的病理基础模型与组织形态学的本质存在概念不一致，需要重新审视该范式。

Abstract: In non-medical domains, foundation models (FMs) have revolutionized computer
vision and language processing through large-scale self-supervised and
multimodal learning. Consequently, their rapid adoption in computational
pathology was expected to deliver comparable breakthroughs in cancer diagnosis,
prognostication, and multimodal retrieval. However, recent systematic
evaluations reveal fundamental weaknesses: low diagnostic accuracy, poor
robustness, geometric instability, heavy computational demands, and concerning
safety vulnerabilities. This short paper examines these shortcomings and argues
that they stem from deeper conceptual mismatches between the assumptions
underlying generic foundation modeling in mainstream AI and the intrinsic
complexity of human tissue. Seven interrelated causes are identified:
biological complexity, ineffective self-supervision, overgeneralization,
excessive architectural complexity, lack of domain-specific innovation,
insufficient data, and a fundamental design flaw related to tissue patch size.
These findings suggest that current pathology foundation models remain
conceptually misaligned with the nature of tissue morphology and call for a
fundamental rethinking of the paradigm itself.

</details>


### [227] [ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents](https://arxiv.org/abs/2510.23822)
*Zhenyu Zhang,Tianyi Chen,Weiran Xu,Alex Pentland,Jiaxin Pei*

Main category: cs.AI

TL;DR: 本研究提出ReCAP框架，通过三种机制提高长时间任务中大语言模型的推理和规划能力。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在长时间任务中面临的上下文漂移、目标信息丢失和失败循环等挑战。

Method: 引入ReCAP（递归上下文感知推理和规划）框架，优化多步推理和动态重规划过程。

Result: ReCAP显著提高了子目标对齐和成功率，在Robotouille基准测试中分别实现了32%和29%的提升。

Conclusion: ReCAP有效缩小了高层目标与低层操作之间的差距，降低冗余提示的出现，并在递归过程中保持一致的上下文更新。

Abstract: Long-horizon tasks requiring multi-step reasoning and dynamic re-planning
remain challenging for large language models (LLMs). Sequential prompting
methods are prone to context drift, loss of goal information, and recurrent
failure cycles, while hierarchical prompting methods often weaken cross-level
continuity or incur substantial runtime overhead. We introduce ReCAP (Recursive
Context-Aware Reasoning and Planning), a hierarchical framework with shared
context for reasoning and planning in LLMs. ReCAP combines three key
mechanisms: (i) plan-ahead decomposition, in which the model generates a full
subtask list, executes the first item, and refines the remainder; (ii)
structured re-injection of parent plans, maintaining consistent multi-level
context during recursive return; and (iii) memory-efficient execution, bounding
the active prompt so costs scale linearly with task depth. Together these
mechanisms align high-level goals with low-level actions, reduce redundant
prompting, and preserve coherent context updates across recursion. Experiments
demonstrate that ReCAP substantially improves subgoal alignment and success
rates on various long-horizon reasoning benchmarks, achieving a 32% gain on
synchronous Robotouille and a 29% improvement on asynchronous Robotouille under
the strict pass@1 protocol.

</details>


### [228] [Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models](https://arxiv.org/abs/2510.23824)
*Murad Ismayilov,Edwin Meriaux,Shuo Wen,Gregory Dudek*

Main category: cs.AI

TL;DR: 研究在多智能体路径规划中采用去中心化目标分配的方法，LLM模型表现优越。


<details>
  <summary>Details</summary>
Motivation: 解决在共享环境中协调多个自治智能体的问题，尤其是在去中心化条件下的目标分配挑战。

Method: 多智能体路径规划中的去中心化目标分配

Result: LLM（大语言模型）智能体在提供良好设计的提示和相关定量信息的情况下，可以实现接近最优的时间消耗，并持续超过传统启发式方法。

Conclusion: 语言模型在多智能体路径规划中的去中心化目标分配中具有潜力，信息结构的重要性不容忽视。

Abstract: Coordinating multiple autonomous agents in shared environments under
decentralized conditions is a long-standing challenge in robotics and
artificial intelligence. This work addresses the problem of decentralized goal
assignment for multi-agent path planning, where agents independently generate
ranked preferences over goals based on structured representations of the
environment, including grid visualizations and scenario data. After this
reasoning phase, agents exchange their goal rankings, and assignments are
determined by a fixed, deterministic conflict-resolution rule (e.g., agent
index ordering), without negotiation or iterative coordination. We
systematically compare greedy heuristics, optimal assignment, and large
language model (LLM)-based agents in fully observable grid-world settings. Our
results show that LLM-based agents, when provided with well-designed prompts
and relevant quantitative information, can achieve near-optimal makespans and
consistently outperform traditional heuristics. These findings underscore the
potential of language models for decentralized goal assignment in multi-agent
path planning and highlight the importance of information structure in such
systems.

</details>


### [229] [Generating Creative Chess Puzzles](https://arxiv.org/abs/2510.23881)
*Xidong Feng,Vivek Veeriah,Marcus Chiam,Michael Dennis,Ryan Pachauri,Thomas Tumiel,Federico Barbero,Johan Obando-Ceron,Jiaxin Shi,Satinder Singh,Shaobo Hou,Nenad Tomašev,Tom Zahavy*

Main category: cs.AI

TL;DR: 本文探讨并解决生成式AI在创意国际象棋谜题生成中的不足，通过强化学习框架显著提升谜题的独特性和多样性，成果获得国际专家认可。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式AI在多个领域快速发展，但在生成真正具有创造性和反直觉的输出方面仍面临挑战，尤其是在国际象棋谜题领域。

Method: 通过基准测试生成式AI架构，并引入新的强化学习框架，基于国际象棋引擎搜索统计设计奖励机制。

Result: 采用强化学习方法后，反直觉谜题的生成率显著提升，从0.22%提升至2.5%，超越现有数据集和最佳模型，同时获得更高的创意和愉悦感。

Conclusion: 本文提出的方法成功地提升了国际象棋谜题的生成质量和多样性，得到专家的认可，展示了生成式AI在创造性输出方面的潜力。

Abstract: While Generative AI rapidly advances in various domains, generating truly
creative, aesthetic, and counter-intuitive outputs remains a challenge. This
paper presents an approach to tackle these difficulties in the domain of chess
puzzles. We start by benchmarking Generative AI architectures, and then
introduce an RL framework with novel rewards based on chess engine search
statistics to overcome some of those shortcomings. The rewards are designed to
enhance a puzzle's uniqueness, counter-intuitiveness, diversity, and realism.
Our RL approach dramatically increases counter-intuitive puzzle generation by
10x, from 0.22\% (supervised) to 2.5\%, surpassing existing dataset rates
(2.1\%) and the best Lichess-trained model (0.4\%). Our puzzles meet novelty
and diversity benchmarks, retain aesthetic themes, and are rated by human
experts as more creative, enjoyable, and counter-intuitive than composed book
puzzles, even approaching classic compositions. Our final outcome is a curated
booklet of these AI-generated puzzles, which is acknowledged for creativity by
three world-renowned experts.

</details>


### [230] [Agentic AI Security: Threats, Defenses, Evaluation, and Open Challenges](https://arxiv.org/abs/2510.23883)
*Shrestha Datta,Shahriar Kabir Nahin,Anshuman Chhabra,Prasant Mohapatra*

Main category: cs.AI

TL;DR: 本文讨论了基于大型语言模型的自主AI系统所面临的独特安全风险，并提供了针对这些风险的防御策略。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI系统的出现，传统的AI安全和软件安全范畴无法完全覆盖其带来的新风险。

Method: 通过综述现有的威胁分类、基准测试和评估方法，分析自主AI系统的安全风险。

Result: 本文梳理了特定于自主AI的威胁，评估了其面临的安全性挑战，并提出了相应的技术与治理防御策略。

Conclusion: 为了支持安全设计的自主系统发展，本文强调了当前研究的挑战和防御策略。

Abstract: Agentic AI systems powered by large language models (LLMs) and endowed with
planning, tool use, memory, and autonomy, are emerging as powerful, flexible
platforms for automation. Their ability to autonomously execute tasks across
web, software, and physical environments creates new and amplified security
risks, distinct from both traditional AI safety and conventional software
security. This survey outlines a taxonomy of threats specific to agentic AI,
reviews recent benchmarks and evaluation methodologies, and discusses defense
strategies from both technical and governance perspectives. We synthesize
current research and highlight open challenges, aiming to support the
development of secure-by-design agent systems.

</details>


### [231] [Latent Chain-of-Thought for Visual Reasoning](https://arxiv.org/abs/2510.23925)
*Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao*

Main category: cs.AI

TL;DR: 通过将推理重构为后验推断，开发了一种新的培训方法，显著提升了LVLM的性能。


<details>
  <summary>Details</summary>
Motivation: 提高大型视觉语言模型的可解释性和可靠性，解决现有训练算法在新推理任务上的泛化能力不足和偏见奖励模型的问题。

Method: 基于后验推断的可扩展训练算法，结合变分推断和稀疏奖励函数。

Result: 提出的方法在七个推理基准测试中，在效果、泛化能力和可解释性方面，提升了当前最先进的LVLM模型。

Conclusion: 新提出的算法有效解决了现有训练方法的不足，从而在推理任务上实现了显著的提升。

Abstract: Chain-of-thought (CoT) reasoning is critical for improving the
interpretability and reliability of Large Vision-Language Models (LVLMs).
However, existing training algorithms such as SFT, PPO, and GRPO may not
generalize well across unseen reasoning tasks and heavily rely on a biased
reward model. To address this challenge, we reformulate reasoning in LVLMs as
posterior inference and propose a scalable training algorithm based on
amortized variational inference. By leveraging diversity-seeking reinforcement
learning algorithms, we introduce a novel sparse reward function for
token-level learning signals that encourage diverse, high-likelihood latent
CoT, overcoming deterministic sampling limitations and avoiding reward hacking.
Additionally, we implement a Bayesian inference-scaling strategy that replaces
costly Best-of-N and Beam Search with a marginal likelihood to efficiently rank
optimal rationales and answers. We empirically demonstrate that the proposed
method enhances the state-of-the-art LVLMs on seven reasoning benchmarks, in
terms of effectiveness, generalization, and interpretability.

</details>


### [232] [Decentralized Causal Discovery using Judo Calculus](https://arxiv.org/abs/2510.23942)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: 本文介绍了基于judo演算的因果发现理论与实现，强调了其在上下文依赖性和计算效率上的优势。


<details>
  <summary>Details</summary>
Motivation: 因果效应在不同背景下具有依赖性，因此需要在局部真理的框架下进行因果推断。

Method: 提出了一种基于sheaf理论的去中心化因果发现框架，并结合多种因果发现方法进行算法实现。

Result: 实验证明了基于judo演算的因果发现方法在多个领域中的计算效率和表现优于传统方法。

Conclusion: 本文提出的judo演算在因果发现中的应用展示了其在计算效率和性能上的优势。

Abstract: We describe a theory and implementation of an intuitionistic decentralized
framework for causal discovery using judo calculus, which is formally defined
as j-stable causal inference using j-do-calculus in a topos of sheaves. In
real-world applications -- from biology to medicine and social science --
causal effects depend on regime (age, country, dose, genotype, or lab
protocol). Our proposed judo calculus formalizes this context dependence
formally as local truth: a causal claim is proven true on a cover of regimes,
not everywhere at once. The Lawvere-Tierney modal operator j chooses which
regimes are relevant; j-stability means the claim holds constructively and
consistently across that family. We describe an algorithmic and implementation
framework for judo calculus, combining it with standard score-based,
constraint-based, and gradient-based causal discovery methods. We describe
experimental results on a range of domains, from synthetic to real-world
datasets from biology and economics. Our experimental results show the
computational efficiency gained by the decentralized nature of sheaf-theoretic
causal discovery, as well as improved performance over classical causal
discovery methods.

</details>


### [233] [The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity](https://arxiv.org/abs/2510.23965)
*Aymane El Gadarri,Ali Aouad,Vivek F. Farias*

Main category: cs.AI

TL;DR: 提出了一种名为符号估计器的新方法，可有效提升LLM对齐的准确性，显著减少偏差。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM对齐方法对人类偏好的异质性敏感，需要一种更一致和有效的解决方案。

Method: 通过替换聚合步骤中的交叉熵为二分类损失，提供一致的序数对齐。

Result: 提出了一种新方法，称为符号估计器，通过在聚合步骤中用二分类损失替代交叉熵，提供了一种简单、可证明一致和高效的估计器。该方法在轻微假设下恢复一致的序数对齐，并在该设置下实现了第一个多项式有限样本错误界限。在使用数字双胞胎进行的LLM对齐的现实模拟中，符号估计器显著减少了偏好扭曲，与标准的RLHF相比，角度估计误差减少了近35%，与真实人群偏好的不一致度从12%降至8%。

Conclusion: 符号估计器在保证实施简便的同时，有效降低了LLM对齐中偏好扭曲，提升了与真实偏好的符合度。

Abstract: Traditional LLM alignment methods are vulnerable to heterogeneity in human
preferences. Fitting a na\"ive probabilistic model to pairwise comparison data
(say over prompt-completion pairs) yields an inconsistent estimate of the
population-average utility -a canonical measure of social welfare. We propose a
new method, dubbed the sign estimator, that provides a simple, provably
consistent, and efficient estimator by replacing cross-entropy with binary
classification loss in the aggregation step. This simple modification recovers
consistent ordinal alignment under mild assumptions and achieves the first
polynomial finite-sample error bounds in this setting. In realistic simulations
of LLM alignment using digital twins, the sign estimator substantially reduces
preference distortion over a panel of simulated personas, cutting (angular)
estimation error by nearly 35% and decreasing disagreement with true population
preferences from 12% to 8% compared to standard RLHF. Our method also compares
favorably to panel data heuristics that explicitly model user heterogeneity and
require tracking individual-level preference data-all while maintaining the
implementation simplicity of existing LLM alignment pipelines.

</details>


### [234] [Learning Individual Movement Shifts After Urban Disruptions with Social Infrastructure Reliance](https://arxiv.org/abs/2510.23989)
*Shangde Gao,Zelin Xu,Zhe Jiang*

Main category: cs.AI

TL;DR: 本研究提出了一种新的深度学习模型，结合社会基础设施韧性和空间上下文，旨在提高对干扰事件后个体运动模式预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 在干扰事件后，个体运动模式的变化可以揭示社区资源需求的变化，但在干扰事件之前预测这种变化存在挑战。

Method: 利用条件深度学习模型，在大型稀疏个体数据下，整合个体的社会基础设施韧性(SIR)与空间上下文，以捕捉个体运动模式与局部空间的复杂关系。

Result: 通过实验表明，结合个体的SIR和空间上下文可以提升模型预测干扰事件后个体运动模式的能力。

Conclusion: 该条件模型能够捕捉在相似事件前模式的个体中，由于SIR的差异而导致的运动模式的不同变化。

Abstract: Shifts in individual movement patterns following disruptive events can reveal
changing demands for community resources. However, predicting such shifts
before disruptive events remains challenging for several reasons. First,
measures are lacking for individuals' heterogeneous social infrastructure
resilience (SIR), which directly influences their movement patterns, and
commonly used features are often limited or unavailable at scale, e.g.,
sociodemographic characteristics. Second, the complex interactions between
individual movement patterns and spatial contexts have not been sufficiently
captured. Third, individual-level movement may be spatially sparse and not
well-suited to traditional decision-making methods for movement predictions.
This study incorporates individuals' SIR into a conditioned deep learning model
to capture the complex relationships between individual movement patterns and
local spatial context using large-scale, sparse individual-level data. Our
experiments demonstrate that incorporating individuals' SIR and spatial context
can enhance the model's ability to predict post-event individual movement
patterns. The conditioned model can capture the divergent shifts in movement
patterns among individuals who exhibit similar pre-event patterns but differ in
SIR.

</details>


### [235] [OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting](https://arxiv.org/abs/2510.24028)
*Tingyue Pan,Mingyue Cheng,Shilong Zhang,Zhiding Liu,Xiaoyu Tao,Yucong Luo,Jintao Zhang,Qi Liu*

Main category: cs.AI

TL;DR: OneCast框架通过分解时间序列为季节性和趋势成分，显著提升了跨领域时间序列预测的效果。


<details>
  <summary>Details</summary>
Motivation: 理解跨领域时间序列预测中的挑战，尤其是如何处理领域特定的趋势变动和不一致的周期模式。

Method: 提出一种结构化和模块化预测框架OneCast，分解时间序列为季节性和趋势成分，采用定制的生成路径进行建模。

Result: OneCast在八个领域的广泛实验中，通常超越了最先进的基线模型。

Conclusion: OneCast有效地捕捉季节性模式并跟踪领域特定的趋势，展示了其在跨领域预测任务中的优势。

Abstract: Cross-domain time series forecasting is a valuable task in various web
applications. Despite its rapid advancement, achieving effective generalization
across heterogeneous time series data remains a significant challenge. Existing
methods have made progress by extending single-domain models, yet often fall
short when facing domain-specific trend shifts and inconsistent periodic
patterns. We argue that a key limitation lies in treating temporal series as
undifferentiated sequence, without explicitly decoupling their inherent
structural components. To address this, we propose OneCast, a structured and
modular forecasting framework that decomposes time series into seasonal and
trend components, each modeled through tailored generative pathways.
Specifically, the seasonal component is captured by a lightweight projection
module that reconstructs periodic patterns via interpretable basis functions.
In parallel, the trend component is encoded into discrete tokens at segment
level via a semantic-aware tokenizer, and subsequently inferred through a
masked discrete diffusion mechanism. The outputs from both branches are
combined to produce a final forecast that captures seasonal patterns while
tracking domain-specific trends. Extensive experiments across eight domains
demonstrate that OneCast mostly outperforms state-of-the-art baselines.

</details>


### [236] [LLMLogAnalyzer: A Clustering-Based Log Analysis Chatbot using Large Language Models](https://arxiv.org/abs/2510.24031)
*Peng Cai,Reza Ryan,Nickson M. Karie*

Main category: cs.AI

TL;DR: LLMLogAnalyzer是一种基于聚类的日志分析聊天机器人，它利用大型语言模型和机器学习算法，简化了日志分析过程，提高了性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 面对组织在日志分析中遇到的成本、专业技术和时间约束，开发出一种创新的、易于使用的日志分析工具。

Method: 该研究开发了LLMLogAnalyzer，通过聚类方法和大型语言模型，优化了日志分析的多个方面。

Result: 在四个不同领域的日志数据上进行评估后，LLMLogAnalyzer在多个任务中展现出比现有的聊天机器人提高了39%到68%的性能。

Conclusion: LLMLogAnalyzer表现出色，能够有效处理多种日志数据，并在多个任务中超越现有的最先进技术。

Abstract: System logs are a cornerstone of cybersecurity, supporting proactive breach
prevention and post-incident investigations. However, analyzing vast amounts of
diverse log data remains significantly challenging, as high costs, lack of
in-house expertise, and time constraints make even basic analysis difficult for
many organizations. This study introduces LLMLogAnalyzer, a clustering-based
log analysis chatbot that leverages Large Language Models (LLMs) and Machine
Learning (ML) algorithms to simplify and streamline log analysis processes.
This innovative approach addresses key LLM limitations, including context
window constraints and poor structured text handling capabilities, enabling
more effective summarization, pattern extraction, and anomaly detection tasks.
LLMLogAnalyzer is evaluated across four distinct domain logs and various tasks.
Results demonstrate significant performance improvements over state-of-the-art
LLM-based chatbots, including ChatGPT, ChatPDF, and NotebookLM, with consistent
gains ranging from 39% to 68% across different tasks. The system also exhibits
strong robustness, achieving a 93% reduction in interquartile range (IQR) when
using ROUGE-1 scores, indicating significantly lower result variability. The
framework's effectiveness stems from its modular architecture comprising a
router, log recognizer, log parser, and search tools. This design enhances LLM
capabilities for structured text analysis while improving accuracy and
robustness, making it a valuable resource for both cybersecurity experts and
non-technical users.

</details>


### [237] [Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine Learning Approach](https://arxiv.org/abs/2510.24085)
*Md. Shihab Uddin,Md Nazmus Shakib,Rahul Bhadani*

Main category: cs.AI

TL;DR: 本研究比较了经典模型与随机森林机器学习模型在电动车跟车行为的表现，发现后者在预测精度上优于前者。


<details>
  <summary>Details</summary>
Motivation: 随着电动车的普及，亟需理解其驾驶行为以增强交通安全和发展智能驾驶系统。

Method: 比较经典与机器学习模型以研究电动车的跟车行为

Result: 随机森林回归模型在各种条件下展现出优越的预测精度，RMSE表现显著优于经典模型。

Conclusion: 随机森林模型在电动车跟车行为模拟中具有更高的准确性，适用于分析电动车环境下的混合自主交通动态。

Abstract: The increasing adoption of electric vehicles (EVs) necessitates an
understanding of their driving behavior to enhance traffic safety and develop
smart driving systems. This study compares classical and machine learning
models for EV car following behavior. Classical models include the Intelligent
Driver Model (IDM), Optimum Velocity Model (OVM), Optimal Velocity Relative
Velocity (OVRV), and a simplified CACC model, while the machine learning
approach employs a Random Forest Regressor. Using a real world dataset of an EV
following an internal combustion engine (ICE) vehicle under varied driving
conditions, we calibrated classical model parameters by minimizing the RMSE
between predictions and real data. The Random Forest model predicts
acceleration using spacing, speed, and gap type as inputs. Results demonstrate
the Random Forest's superior accuracy, achieving RMSEs of 0.0046 (medium gap),
0.0016 (long gap), and 0.0025 (extra long gap). Among physics based models,
CACC performed best, with an RMSE of 2.67 for long gaps. These findings
highlight the machine learning model's performance across all scenarios. Such
models are valuable for simulating EV behavior and analyzing mixed autonomy
traffic dynamics in EV integrated environments.

</details>


### [238] [HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology](https://arxiv.org/abs/2510.24115)
*Sandeep Vissapragada,Vikrant Sahu,Gagan Raj Gupta,Vandita Singh*

Main category: cs.AI

TL;DR: HistoLens是一个透明的AI辅助工具，帮助病理学家理解分析过程，增强了对AI的信任，并通过视觉证据提供分析依据。


<details>
  <summary>Details</summary>
Motivation: 为了增强医生对人工智能的信任，AI需要透明，并能够解释其推理过程。

Method: 创建一个可以用简单英语提问的系统，AI将其翻译为精确查询，并生成结构化报告，同时提供分析依据和热图。

Result: HistoLens使病理学家能够更快速、自信地进行诊断，同时保持对诊断过程的掌控。

Conclusion: HistoLens通过透明的沟通和可视化证明，提升了病理学家对AI的信任，优化了诊断流程。

Abstract: For doctors to truly trust artificial intelligence, it can't be a black box.
They need to understand its reasoning, almost as if they were consulting a
colleague. We created HistoLens1 to be that transparent, collaborative partner.
It allows a pathologist to simply ask a question in plain English about a
tissue slide--just as they would ask a trainee. Our system intelligently
translates this question into a precise query for its AI engine, which then
provides a clear, structured report. But it doesn't stop there. If a doctor
ever asks, "Why?", HistoLens can instantly provide a 'visual proof' for any
finding--a heatmap that points to the exact cells and regions the AI used for
its analysis. We've also ensured the AI focuses only on the patient's tissue,
just like a trained pathologist would, by teaching it to ignore distracting
background noise. The result is a workflow where the pathologist remains the
expert in charge, using a trustworthy AI assistant to verify their insights and
make faster, more confident diagnoses.

</details>


### [239] [From Observability Data to Diagnosis: An Evolving Multi-agent System for Incident Management in Cloud Systems](https://arxiv.org/abs/2510.24145)
*Yu Luo,Jiamin Jiang,Jingfei Feng,Lei Tao,Qingliang Zhang,Xidao Wen,Yongqian Sun,Shenglin Zhang,Jielong Huang,Nan Qi,Dan Pei*

Main category: cs.AI

TL;DR: 本文提出OpsAgent，一个能有效处理和自动化事故管理的多智能体系统，在测试中表现优异且具备自我进化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有事故管理方法在系统泛化、可解释性和部署成本上的局限性，以提高大规模云系统的可靠性。

Method: 呈现一个轻量级、自我进化的多智能体系统OpsAgent，旨在改进事故管理的自动化，包含训练自由的数据处理器和多智能体协作框架。

Result: OpsAgent在OPENRCA基准测试中展示了最先进的性能，具有良好的泛化能力、可解释性、成本效率和自我进化能力。

Conclusion: OpsAgent提供了一种可持续且适用于真实云系统长期操作的解决方案，促进了事故管理的有效性和可靠性。

Abstract: Incident management (IM) is central to the reliability of large-scale cloud
systems. Yet manual IM, where on-call engineers examine metrics, logs, and
traces is labor-intensive and error-prone in the face of massive and
heterogeneous observability data. Existing automated IM approaches often
struggle to generalize across systems, provide limited interpretability, and
incur high deployment costs, which hinders adoption in practice. In this paper,
we present OpsAgent, a lightweight, self-evolving multi-agent system for IM
that employs a training-free data processor to convert heterogeneous
observability data into structured textual descriptions, along with a
multi-agent collaboration framework that makes diagnostic inference transparent
and auditable. To support continual capability growth, OpsAgent also introduces
a dual self-evolution mechanism that integrates internal model updates with
external experience accumulation, thereby closing the deployment loop.
Comprehensive experiments on the OPENRCA benchmark demonstrate state-of-the-art
performance and show that OpsAgent is generalizable, interpretable,
cost-efficient, and self-evolving, making it a practically deployable and
sustainable solution for long-term operation in real-world cloud systems.

</details>


### [240] [BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning Questions from Semi-structured Data](https://arxiv.org/abs/2510.24151)
*Bingsen Qiu,Zijian Liu,Xiao Liu,Haoshen Yang,Zeren Gao,Bingjie Wang,Feier Zhang,Yixuan Qin,Chunyan Li*

Main category: cs.AI

TL;DR: 提出了一种自动化生成高难度多跳问题的框架，旨在减少人工成本并提升数据可用性。


<details>
  <summary>Details</summary>
Motivation: 旨在解决手动策划多跳问题的高成本及数据匮乏问题，为模型训练生成高质量数据。

Method: 使用自然语言推理对证据进行标注及扩展，并通过反向问题构造和双步评估流程保证问题质量。

Result: 本文提出了一种自动化框架，可以从半结构化知识源生成高难度、可用于训练的多跳问题。这一系统通过自然语言推理（NLI）建立多样化的证据集群，利用反向问题构造技术组合间接线索，并通过多模型共识过滤与结构约束分解相结合的两步评估流程来确保问题质量。最终，生成的复杂问题既适合监督微调（SFT）和强化学习（RL）训练，也适用于高难度评估，从而在保证评估基准难度的同时显著减少人工策划的工作量。

Conclusion: 通过自动化技术，实现了对复杂问题的高效生成，支持模型训练和评估，缓解了当前数据瓶颈问题。

Abstract: Building training-ready multi-hop question answering (QA) datasets that truly
stress a model's retrieval and reasoning abilities remains highly challenging
recently. While there have been a few recent evaluation datasets that capture
the characteristics of hard-to-search but easy-to-verify problems -- requiring
the integration of ambiguous, indirect, and cross-domain cues -- these data
resources remain scarce and are mostly designed for evaluation, making them
unsuitable for supervised fine-tuning (SFT) or reinforcement learning (RL).
Meanwhile, manually curating non-trivially retrievable questions -- where
answers cannot be found through a single direct query but instead require
multi-hop reasoning over oblique and loosely connected evidence -- incurs
prohibitive human costs and fails to scale, creating a critical data bottleneck
for training high-capability retrieval-and-reasoning agents.
  To address this, we present an automated framework for generating
high-difficulty, training-ready multi-hop questions from semi-structured
knowledge sources. The system (i) grows diverse, logically labeled evidence
clusters through Natural Language Inference (NLI)-based relation typing and
diversity-aware expansion; (ii) applies reverse question construction to
compose oblique cues so that isolated signals are underinformative but their
combination uniquely identifies the target entity; and (iii) enforces quality
with a two-step evaluation pipeline that combines multi-model consensus
filtering with structured constraint decomposition and evidence-based matching.
The result is a scalable process that yields complex, retrieval-resistant yet
verifiable questions suitable for SFT/RL training as well as challenging
evaluation, substantially reducing human curation effort while preserving the
difficulty profile of strong evaluation benchmarks.

</details>


### [241] [Investigating Intra-Abstraction Policies For Non-exact Abstraction Algorithms](https://arxiv.org/abs/2510.24297)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 探索了蒙特卡罗树搜索中的新抽象策略，结果显示新策略在效率上优于随机策略。


<details>
  <summary>Details</summary>
Motivation: 弥补蒙特卡罗树搜索在样本效率上的不足，尤其是在处理同父节点下多个动作的抽象节点时优化UCB值的决策流程。

Method: 通过重新评估蒙特卡罗树搜索中的抽象算法，特别是针对同一父节点下多动作共享同一抽象节点的情况，提出新策略并进行实证评估。

Result: 多个新提出的内部抽象策略在多个环境中表现出优于传统随机决策策略的样本效率。

Conclusion: 提出并评估了多种替代性内部抽象策略，许多策略在大多数环境和参数设置下优于随机策略。

Abstract: One weakness of Monte Carlo Tree Search (MCTS) is its sample efficiency which
can be addressed by building and using state and/or action abstractions in
parallel to the tree search such that information can be shared among nodes of
the same layer. The primary usage of abstractions for MCTS is to enhance the
Upper Confidence Bound (UCB) value during the tree policy by aggregating visits
and returns of an abstract node. However, this direct usage of abstractions
does not take the case into account where multiple actions with the same parent
might be in the same abstract node, as these would then all have the same UCB
value, thus requiring a tiebreak rule. In state-of-the-art abstraction
algorithms such as pruned On the Go Abstractions (pruned OGA), this case has
not been noticed, and a random tiebreak rule was implicitly chosen. In this
paper, we propose and empirically evaluate several alternative
intra-abstraction policies, several of which outperform the random policy
across a majority of environments and parameter settings.

</details>


### [242] [Verifying Large Language Models' Reasoning Paths via Correlation Matrix Rank](https://arxiv.org/abs/2510.24299)
*Jiayu Liu,Wei Dai,Zhenya Huang,Ning Miao,Enhong Chen*

Main category: cs.AI

TL;DR: 本文提出了一种基于大型语言模型内部行为的新方法Self-Indicator，用于检查推理路径的正确性，减少外部资源依赖，提高检测效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在推理过程中容易出现错误和虚构，因此开发有效、低成本的内部检查方法是必要的。

Method: 通过分析输入问题与输出推理路径之间的相关性矩阵，设计了一种简单的Self-Indicator方法，避免了训练独立模型或设计复杂提示的需求。

Result: 通过实验验证，Self-Indicator在多个不同规模的LLM上表现优越，能显著提高推理准确性。

Conclusion: Self-Indicator方法在准确区分正确与错误推理路径上表现出色，实现超过75%的准确率，并提升了三项推理基准测试的准确性超过8%。

Abstract: Despite the strong reasoning ability of large language models~(LLMs), they
are prone to errors and hallucinations. As a result, how to check their outputs
effectively and efficiently has become a critical problem in their
applications. Existing checking methods heavily rely on external resources,
such as trained verifiers (e.g., process/outcome reward models) or elaborate
prompts, which lead to high computational overhead and are only applicable to
specific domains. In this paper, we investigate whether the internal behaviors
of LLMs have already implied the credibility of their reasoning paths.
Specifically, we find that the rank of the correlation matrix between the input
problem and the output reasoning path is a robust indicator of reasoning
correctness. Different from other correctness indicators for LLMs, the
calculation of the correlation matrix only relies on the LLM itself, which
avoids the hassle of training a separate model or designing complicated
prompts. Based on it, we design a simple, plug-and-play Self-Indicator method
to reweight candidate reasoning paths, which achieves significant performance
improvements than other voting and verification methods with very few
computational overhead. Our experiments across multiple LLMs of varying scales
and model families have further shown the effectiveness of Self-Indicator. It
achieves over 75% accuracy in distinguishing correct reasoning paths from
incorrect ones, and, in turn, improves the accuracies on three reasoning
benchmarks by more than 8%.

</details>


### [243] [Generative Large Language Models (gLLMs) in Content Analysis: A Practical Guide for Communication Research](https://arxiv.org/abs/2510.24337)
*Daria Kravets-Meinke,Hannah Schmid-Petri,Sonja Niemann,Ute Schmid*

Main category: cs.AI

TL;DR: 本论文探讨了生成式大型语言模型在传播研究中内容分析的应用，分析了其优势与面临的挑战，并提出最佳实践指南以提升其研究质量。


<details>
  <summary>Details</summary>
Motivation: 为了促进生成式大型语言模型在传播研究中的应用，提高内容分析的效率和质量，同时响应学术界对新方法的需求。

Method: 通过对现有文献的综合分析，识别gLLM辅助内容分析中的关键挑战，并提出针对性的策略和建议。

Result: 本论文讨论了生成式大型语言模型（gLLMs），例如ChatGPT，在传播研究中的应用，特别是在内容分析方面的潜力与挑战。 gLLMs在各种编码任务上常常比人类编码者表现出色，且所需时间和成本较低。然而，其整合至传播研究的方法论工具包仍处于起步阶段。论文指出了gLLM辅助定量内容分析中的七个主要挑战，并提出了一套全面的最佳实践指南，旨在提高gLLM内容分析的可及性，确保遵循有效性、可靠性、可重复性和研究伦理等学科质量标准。

Conclusion: 本研究为传播研究提供了gLLM内容分析的最佳实践，旨在提高研究的有效性和可重复性，同时推动学科内对新技术的接受和使用。

Abstract: Generative Large Language Models (gLLMs), such as ChatGPT, are increasingly
being used in communication research for content analysis. Studies show that
gLLMs can outperform both crowd workers and trained coders, such as research
assistants, on various coding tasks relevant to communication science, often at
a fraction of the time and cost. Additionally, gLLMs can decode implicit
meanings and contextual information, be instructed using natural language,
deployed with only basic programming skills, and require little to no annotated
data beyond a validation dataset - constituting a paradigm shift in automated
content analysis. Despite their potential, the integration of gLLMs into the
methodological toolkit of communication research remains underdeveloped. In
gLLM-assisted quantitative content analysis, researchers must address at least
seven critical challenges that impact result quality: (1) codebook development,
(2) prompt engineering, (3) model selection, (4) parameter tuning, (5)
iterative refinement, (6) validation of the model's reliability, and
optionally, (7) performance enhancement. This paper synthesizes emerging
research on gLLM-assisted quantitative content analysis and proposes a
comprehensive best-practice guide to navigate these challenges. Our goal is to
make gLLM-based content analysis more accessible to a broader range of
communication researchers and ensure adherence to established disciplinary
quality standards of validity, reliability, reproducibility, and research
ethics.

</details>


### [244] [Improving LLM Reasoning via Dependency-Aware Query Decomposition and Logic-Parallel Content Expansion](https://arxiv.org/abs/2510.24390)
*Xianjun Gao,Jianchun Liu,Hongli Xu,Liusheng Huang*

Main category: cs.AI

TL;DR: 本文提出了Orion框架，有效解决了大语言模型在Web应用中的推理瓶颈，显著提高了效率和推理质量。


<details>
  <summary>Details</summary>
Motivation: 针对当前大语言模型在实时Web服务中推理性能不足的问题，寻求一种能够同时提升效率和质量的解决方案。

Method: 提出了一种新的推理框架Orion，通过依赖意识查询分解和逻辑并行内容扩展来优化推理过程。

Result: Orion相比于基线模型，在代币生成速度上提升了4.33倍，回答延迟降低了3.42倍，推理质量提升了18.75%。

Conclusion: Orion大幅提升了语言模型在实时Web应用中的推理性能，兼顾了效率与质量，能够更好地满足现代Web平台的需求。

Abstract: The integration of Large Language Models (LLMs) into real-time Web
applications, such as AI-powered search and conversational agents, presents a
fundamental Web infrastructure challenge: reconciling the demand for
high-quality, complex reasoning with the stringent low-latency and
high-throughput requirements of interactive services. Current LLM reasoning,
hindered by computationally inefficient sequential generation and rigid
reasoning strategies, creates a critical bottleneck for the Web services.
Existing approaches typically optimize the LLM reasoning for either efficiency
or quality but struggle to achieve both, and thus fail to meet the dual
requirements of modern Web platforms. To overcome these limitations, we propose
Orion, a novel and efficient reasoning framework that enables dependency-aware
query decomposition and logic-parallel content expansion. Concretely, Orion
decomposes a single query reasoning process into two synergistic phases: (1)
\textit{key point generation}, which distills logically structured key points
through retrieval-augmented few-shot prompting, and (2) \textit{content
parallel expansion}, which concurrently elaborates on these points based on a
dependency graph to ensure logical consistency. Furthermore, Orion introduces a
pipeline scheduling mechanism that exploits the complementary computational
characteristics of the two phases (generation imposes pressure on GPU computing
and expansion stresses on GPU memory) across multiple queries, enabling
cross-query parallelism and dramatically improving reasoning performance (\ie,
efficiency and quality). Experiments on diverse benchmarks show that Orion not
only delivers up to 4.33x higher token generation speed and 3.42x lower answer
latency over the baselines but also improves reasoning quality by up to 18.75%
through explicitly modeling inter-point dependencies.

</details>


### [245] [Human-Level Reasoning: A Comparative Study of Large Language Models on Logical and Abstract Reasoning](https://arxiv.org/abs/2510.24435)
*Benjamin Grando Moreira*

Main category: cs.AI

TL;DR: 本研究通过定制的推理问题比较多种大型语言模型的推理能力，发现这些模型在逻辑推理方面与人类的表现存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型的推理能力对推动人工智能的发展至关重要，这超越了单纯的语言任务表现。

Method: 通过设计八个自定义推理问题，比较了多种大型语言模型的逻辑和抽象推理能力。

Result: 研究结果显示，LLM在推理方面的表现与人类存在显著差异，特别是在演绎推理任务上。

Conclusion: 这项研究表明，大型语言模型在推理能力方面与人类存在显著差异，尤其是在演绎推理任务上表现较差。

Abstract: Evaluating reasoning ability in Large Language Models (LLMs) is important for
advancing artificial intelligence, as it transcends mere linguistic task
performance. It involves understanding whether these models truly understand
information, perform inferences, and are able to draw conclusions in a logical
and valid way. This study compare logical and abstract reasoning skills of
several LLMs - including GPT, Claude, DeepSeek, Gemini, Grok, Llama, Mistral,
Perplexity, and Sabi\'a - using a set of eight custom-designed reasoning
questions. The LLM results are benchmarked against human performance on the
same tasks, revealing significant differences and indicating areas where LLMs
struggle with deduction.

</details>


### [246] [From Cross-Task Examples to In-Task Prompts: A Graph-Based Pseudo-Labeling Framework for In-context Learning](https://arxiv.org/abs/2510.24528)
*Zihan Chen,Song Wang,Xingbo Fu,Chengshuai Shi,Zhenyu Lei,Cong Shen,Jundong Li*

Main category: cs.AI

TL;DR: 本文提出了一种两阶段的成本效率管道，以降低大语言模型的标注依赖，取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 收集新任务或挑战任务的高质量示例成本高且劳动密集，因此需要一种更高效的数据标注方法。

Method: 提出一种两阶段的成本效率管道来减少对大语言模型(LLMs)的数据标注依赖。第一阶段利用已有的交叉任务示例来提示LLM并对一小组目标任务实例进行伪标注。第二阶段则引入基于图的标签传播方法，将标签信息传播到剩余的目标示例，而无需额外的LLM查询。

Result: 通过在五个任务上的实验，提出的方法在降低标注成本的同时，表现出较强的性能。

Conclusion: 该方法结合了交叉任务监督的灵活性和无LLM查询的可扩展性，为在上下文学习提供了高效的数据标注解决方案。

Abstract: The capability of in-context learning (ICL) enables large language models
(LLMs) to perform novel tasks without parameter updates by conditioning on a
few input-output examples. However, collecting high-quality examples for new or
challenging tasks can be costly and labor-intensive. In this work, we propose a
cost-efficient two-stage pipeline that reduces reliance on LLMs for data
labeling. Our approach first leverages readily available cross-task examples to
prompt an LLM and pseudo-label a small set of target task instances. We then
introduce a graph-based label propagation method that spreads label information
to the remaining target examples without additional LLM queries. The resulting
fully pseudo-labeled dataset is used to construct in-task demonstrations for
ICL. This pipeline combines the flexibility of cross-task supervision with the
scalability of LLM-free propagation. Experiments across five tasks demonstrate
that our method achieves strong performance while lowering labeling costs.

</details>


### [247] [Generative AI for Healthcare: Fundamentals, Challenges, and Perspectives](https://arxiv.org/abs/2510.24551)
*Gang Chen,Changshuo Liu,Gene Anne Ooi,Marcus Tan,Zhongle Xie,Jianwei Yin,James Wei Luen Yip,Wenqiao Zhang,Jiaqi Zhu,Beng Chin Ooi*

Main category: cs.AI

TL;DR: 生成性人工智能正在变革医疗实践，本文提出了一种数据中心的生态系统设计，以优化医疗数据的整合和使用，从而提高医疗服务的质量与效率。


<details>
  <summary>Details</summary>
Motivation: 探讨生成性人工智能在医疗领域的潜力及其对现有医疗实践的变革.

Method: 通过重定位医疗数据生命周期，设计一个能够持续支持多样化医疗数据和知识整合的生态系统，实施高效的数据处理流程，如语义向量搜索和上下文查询。

Result: 提出了一种以数据为中心的范式，旨在通过建立医疗数据生态系统来设计和部署生成性AI系统，提高医疗服务质量和效率。

Conclusion: 通过建立一个支持多种医疗数据集成和检索的生态系统，生成性人工智能能够有效提升医疗服务的质量和效率。

Abstract: Generative Artificial Intelligence (GenAI) is taking the world by storm. It
promises transformative opportunities for advancing and disrupting existing
practices, including healthcare. From large language models (LLMs) for clinical
note synthesis and conversational assistance to multimodal systems that
integrate medical imaging, electronic health records, and genomic data for
decision support, GenAI is transforming the practice of medicine and the
delivery of healthcare, such as diagnosis and personalized treatments, with
great potential in reducing the cognitive burden on clinicians, thereby
improving overall healthcare delivery. However, GenAI deployment in healthcare
requires an in-depth understanding of healthcare tasks and what can and cannot
be achieved. In this paper, we propose a data-centric paradigm in the design
and deployment of GenAI systems for healthcare. Specifically, we reposition the
data life cycle by making the medical data ecosystem as the foundational
substrate for generative healthcare systems. This ecosystem is designed to
sustainably support the integration, representation, and retrieval of diverse
medical data and knowledge. With effective and efficient data processing
pipelines, such as semantic vector search and contextual querying, it enables
GenAI-powered operations for upstream model components and downstream clinical
applications. Ultimately, it not only supplies foundation models with
high-quality, multimodal data for large-scale pretraining and domain-specific
fine-tuning, but also serves as a knowledge retrieval backend to support
task-specific inference via the agentic layer. The ecosystem enables the
deployment of GenAI for high-quality and effective healthcare delivery.

</details>


### [248] [FunReason-MT Technical Report: Overcoming the Complexity Barrier in Multi-Turn Function Calling](https://arxiv.org/abs/2510.24645)
*Zengzhuang Xu,Bingguang Hao,Zechuan Wang,Yuntao Wen,Maolin Wang,Yang Liu,Long Chen,Dong Wang,Yicheng Chen,Cunyin Peng,Chenyi Zhuang,Jinjie Gu,Leilei Gan,Xiangyu Zhao,Shi Gu*

Main category: cs.AI

TL;DR: FunReason-MT是一个新颖的数据合成框架，旨在提高大型语言模型在多轮工具调用中的表现，通过多种方法解决现有数据合成的不足。


<details>
  <summary>Details</summary>
Motivation: 随着函数调用能力在高级人工智能系统中的重要性日益增加，需要高质量的多轮训练数据来支持这一能力的发展和完善。

Method: 使用环境-API图交互、先进的工具查询合成和引导迭代链来生成高质量的多轮FC数据。

Result: 基于FunReason-MT生成的数据，在Berkeley Function-Calling Leaderboard上，一个4B模型的表现达到了同行中的最佳水平。

Conclusion: FunReason-MT显著提升了大型语言模型在多轮工具调用任务的性能，使其在同行中表现优异。

Abstract: Function calling (FC) empowers large language models (LLMs) and autonomous
agents to interface with external tools, a critical capability for solving
complex, real-world problems. As this ability becomes increasingly central to
advanced AI systems, the need for high-quality, multi-turn training data to
develop and refine it cannot be overstated. Existing data synthesis methods,
such as random environment sampling or multi-agent role-playing, are not
powerful enough to generate high-quality data in real-world environments.
Practical challenges come in three folds: targeted model training, isolation of
tool architecture, and multi-turn logical dependency. To address these
structural deficiencies, we present FunReason-MT, a novel data synthesis
framework for real-world multi-turn tool use. FunReason-MT resolves the
complexity barrier in multi-turn FC data by employing 1) Environment-API Graph
Interactions to gather varied high-quality trajectories, 2) Advanced Tool-Query
Synthesis to simplify hard query construction, and 3) Guided Iterative Chain
for sophisticated CoT generation. Evaluations on Berkeley Function-Calling
Leaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built
upon FunReason-MT generated data achieves state-of-the-art performance among
comparable-sized models, outperforming most close-source models. Further
performance improvements on BFCLv4 confirm that FunReason-MT provides a
reliable and robust source for agentic learning.

</details>


### [249] [Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning](https://arxiv.org/abs/2510.24650)
*Nitin Rai,Daeun,Choi,Nathan S. Boyd,Arnold W. Schumann*

Main category: cs.AI

TL;DR: 该论文评估了基础模型在作物疾病管理中的应用，强调了视觉-语言模型的快速发展和适应性学习的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习和深度学习的发展，作物的地点特定疾病管理（SSDM）需要实时计算机视觉解决方案。

Method: 通过筛选约40篇关于基础模型在地点特定疾病管理中的应用的文章，重点讨论大语言模型和视觉-语言模型在相关技术中的作用。

Result: 这篇综述分析了基础模型（FMs）在SSDM中的应用，特别是大语言模型（LLMs）和视觉-语言模型（VLMs），评估了其在适应性学习和强化学习等领域的作用。

Conclusion: FMs，尤其是VLMs，正在推动下一代SSDM的进步，但仍需解决现实世界部署中的挑战。

Abstract: Site-specific disease management (SSDM) in crops has advanced rapidly through
machine and deep learning (ML and DL) for real-time computer vision. Research
evolved from handcrafted feature extraction to large-scale automated feature
learning. With foundation models (FMs), crop disease datasets are now processed
in fundamentally new ways. Unlike traditional neural networks, FMs integrate
visual and textual data, interpret symptoms in text, reason about
symptom-management relationships, and support interactive QA for growers and
educators. Adaptive and imitation learning in robotics further enables
field-based disease management. This review screened approx. 40 articles on FM
applications for SSDM, focusing on large-language models (LLMs) and
vision-language models (VLMs), and discussing their role in adaptive learning
(AL), reinforcement learning (RL), and digital twin frameworks for targeted
spraying. Key findings: (a) FMs are gaining traction with surging literature in
2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL
and AL are still nascent for smart spraying; (d) digital twins with RL can
simulate targeted spraying virtually; (e) addressing the sim-to-real gap is
critical for real-world deployment; (f) human-robot collaboration remains
limited, especially in human-in-the-loop approaches where robots detect early
symptoms and humans validate uncertain cases; (g) multi-modal FMs with
real-time feedback will drive next-gen SSDM. For updates, resources, and
contributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to
submit papers, code, or datasets.

</details>


### [250] [OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan DAGs](https://arxiv.org/abs/2510.24663)
*Yifu Lu,Shengjie Liu,Li Dong*

Main category: cs.AI

TL;DR: 本文引入了一种新的合成数据生成去模型工具执行，提出了基于图的奖励机制来提高多轮工具交互的训练效果，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有多轮工具交互研究中对复杂性的忽视，并提高模型在这些复杂场景下的表现。

Method: 通过合成数据生成管道将工具执行建模为有向无环图，并进行模型性能基准测试及奖励机制的设计。

Result: 本文介绍了OrchDAG，这是一种合成数据生成管道，它将工具执行建模为可控复杂度的有向无环图（DAG）。使用该数据集，作者对模型性能进行了基准测试，并提出了一种基于图的奖励机制来增强RLVR训练。实验结果表明，该数据集提供了一个具有挑战性的但可解决的基准，并且所提出的奖励机制在与GRPO风格算法结合使用时有效，强调了在多轮工具使用中利用拓扑结构和数据复杂性的重要性。

Conclusion: 本研究提出了一种新的数据生成管道和奖励机制，能够有效提升多轮工具交互的学习性能。

Abstract: Agentic tool use has gained traction with the rise of agentic tool calling,
yet most existing work overlooks the complexity of multi-turn tool
interactions. We introduce OrchDAG, a synthetic data generation pipeline that
models tool execution as directed acyclic graphs (DAGs) with controllable
complexity. Using this dataset, we benchmark model performance and propose a
graph-based reward to enhance RLVR training. Experiments show that the dataset
presents a challenging but solvable benchmark, and the proposed reward is
effective when combined with GRPO-style algorithms, highlighting the importance
of leveraging topological structure and data complexity in multi-turn tool use.

</details>


### [251] [Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework for In-Context Planning](https://arxiv.org/abs/2510.24690)
*Shengjie Liu,Li Dong,Zhenyu Zhang*

Main category: cs.AI

TL;DR: 提出一个框架，通过构建工具知识图谱及其与文档知识图谱的融合，来提高示例工件的生成效率。


<details>
  <summary>Details</summary>
Motivation: 提高示例工件生成的效率，利用工具和文档之间的依赖性。

Method: 通过工具模式构建工具知识图谱，并结合内部文档和标准操作程序(SOP)生成补充知识图谱，再利用深度稀疏集成策略生成示例计划。

Result: 建立了一个统一框架，有效建模工具交互，并改善了计划生成。

Conclusion: 将工具图谱与领域知识图谱联系起来，有助于增强推理和规划能力。

Abstract: We present a framework for uncovering and exploiting dependencies among tools
and documents to enhance exemplar artifact generation. Our method begins by
constructing a tool knowledge graph from tool schemas,including descriptions,
arguments, and output payloads, using a DeepResearch-inspired analysis. In
parallel, we derive a complementary knowledge graph from internal documents and
SOPs, which is then fused with the tool graph. To generate exemplar plans, we
adopt a deep-sparse integration strategy that aligns structural tool
dependencies with procedural knowledge. Experiments demonstrate that this
unified framework effectively models tool interactions and improves plan
generation, underscoring the benefits of linking tool graphs with domain
knowledge graphs for tool-augmented reasoning and planning.

</details>

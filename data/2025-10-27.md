<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 58]
- [cs.CL](#cs.CL) [Total: 34]
- [cs.LG](#cs.LG) [Total: 73]
- [cs.HC](#cs.HC) [Total: 5]
- [cs.AI](#cs.AI) [Total: 22]
- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Preventing Shortcuts in Adapter Training via Providing the Shortcuts](https://arxiv.org/abs/2510.20887)
*Anujraaj Argo Goyal,Guocheng Gordon Qian,Huseyin Coskun,Aarush Gupta,Himmy Tam,Daniil Ostashev,Ju Hu,Dhritiman Sagar,Sergey Tulyakov,Kfir Aberman,Kuan-Chieh Jackson Wang*

Main category: cs.CV

TL;DR: 提出了一种新的适配器训练方式，以消除视觉因素干扰，提高生成质量和多样性。


<details>
  <summary>Details</summary>
Motivation: 解决适配器训练中混合视觉因素导致的目标属性与干扰因素的纠缠问题，提升模型的生成能力。

Method: 通过在适配器训练中引入辅助模块来引导干扰因素，消除适配器对这些因素的内化。

Result: 本文提出了一种新的解决方案，称为Shortcut-Rerouted Adapter Training，旨在解决适配器训练中因图像混合因素导致的目标属性与干扰因素的纠缠问题。通过将干扰因素通过辅助模块进行引导，避免了适配器内部化这些因素，从而提高了生成质量、多样性和对文本提示的遵循性。

Conclusion: 使用Shortcut-Rerouted Adapter Training可显著提高模型的生成质量和对文本提示的遵循，同时提供了一种解耦表示的设计原则。

Abstract: Adapter-based training has emerged as a key mechanism for extending the
capabilities of powerful foundation image generators, enabling personalized and
stylized text-to-image synthesis. These adapters are typically trained to
capture a specific target attribute, such as subject identity, using
single-image reconstruction objectives. However, because the input image
inevitably contains a mixture of visual factors, adapters are prone to entangle
the target attribute with incidental ones, such as pose, expression, and
lighting. This spurious correlation problem limits generalization and obstructs
the model's ability to adhere to the input text prompt. In this work, we
uncover a simple yet effective solution: provide the very shortcuts we wish to
eliminate during adapter training. In Shortcut-Rerouted Adapter Training,
confounding factors are routed through auxiliary modules, such as ControlNet or
LoRA, eliminating the incentive for the adapter to internalize them. The
auxiliary modules are then removed during inference. When applied to tasks like
facial and full-body identity injection, our approach improves generation
quality, diversity, and prompt adherence. These results point to a general
design principle in the era of large models: when seeking disentangled
representations, the most effective path may be to establish shortcuts for what
should NOT be learned.

</details>


### [2] [Video-As-Prompt: Unified Semantic Control for Video Generation](https://arxiv.org/abs/2510.20888)
*Yuxuan Bian,Xin Chen,Zenan Li,Tiancheng Zhi,Shen Sang,Linjie Luo,Qiang Xu*

Main category: cs.CV

TL;DR: Video-As-Prompt（VAP）是一种新的视频生成 paradigm，通过使用参考视频，解决了现有方法中的多种问题，并在性能上超越了许多现有的商业模型。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成方法存在引入伪影或依赖特定条件微调的问题，迫切需要一种更加通用的控制方法。

Method: 提出Video-As-Prompt（VAP）新范式，将视频生成问题转变为上下文生成。

Result: VAP通过参考视频作为直接语义提示，引导一个冻结的Video Diffusion Transformer，实现了在开放源码方法中新的领先水平，用户偏好率达到38.7%。

Conclusion: VAP及其配套的VAP-Data数据集，为通用、可控的视频生成研究奠定了重要基础，表明在零样本的情况下具备良好的泛化能力，能支持多种下游应用。

Abstract: Unified, generalizable semantic control in video generation remains a
critical open challenge. Existing methods either introduce artifacts by
enforcing inappropriate pixel-wise priors from structure-based controls, or
rely on non-generalizable, condition-specific finetuning or task-specific
architectures. We introduce Video-As-Prompt (VAP), a new paradigm that reframes
this problem as in-context generation. VAP leverages a reference video as a
direct semantic prompt, guiding a frozen Video Diffusion Transformer (DiT) via
a plug-and-play Mixture-of-Transformers (MoT) expert. This architecture
prevents catastrophic forgetting and is guided by a temporally biased position
embedding that eliminates spurious mapping priors for robust context retrieval.
To power this approach and catalyze future research, we built VAP-Data, the
largest dataset for semantic-controlled video generation with over 100K paired
videos across 100 semantic conditions. As a single unified model, VAP sets a
new state-of-the-art for open-source methods, achieving a 38.7% user preference
rate that rivals leading condition-specific commercial models. VAP's strong
zero-shot generalization and support for various downstream applications mark a
significant advance toward general-purpose, controllable video generation.

</details>


### [3] [Generative Point Tracking with Flow Matching](https://arxiv.org/abs/2510.20951)
*Mattie Tesfaldet,Adam W. Harley,Konstantinos G. Derpanis,Derek Nowrouzezahrai,Christopher Pal*

Main category: cs.CV

TL;DR: GenPT是一种生成框架，旨在通过建模多模态点轨迹来改进视频中的点追踪性能，具有在遮挡情况下的卓越表现。


<details>
  <summary>Details</summary>
Motivation: 视频中对点进行追踪的任务具有挑战性，尤其是在视觉遮挡和外观变化等不确定性因素的影响下。现有的判别模型在长时间点轨迹估计方面表现突出，但在面对不确定性时只能回归均值，无法捕捉多模态信息。

Method: 采用基于流匹配的创新训练方法，结合判别追踪器的迭代精炼，窗口依赖的先验知识，以及针对点坐标调整的方差调度。

Result: 提出了一种生成框架 Generative Point Tracker (GenPT)，能够有效建模多模态轨迹，并通过创新的流匹配公式进行训练，提高了点轨迹的估计准确性。

Conclusion: GenPT在处理遮挡点追踪时，能够捕捉多模态特性，并在标准基准测试上展示出最先进的追踪精度，尤其是在遮挡情况下。

Abstract: Tracking a point through a video can be a challenging task due to uncertainty
arising from visual obfuscations, such as appearance changes and occlusions.
Although current state-of-the-art discriminative models excel in regressing
long-term point trajectory estimates -- even through occlusions -- they are
limited to regressing to a mean (or mode) in the presence of uncertainty, and
fail to capture multi-modality. To overcome this limitation, we introduce
Generative Point Tracker (GenPT), a generative framework for modelling
multi-modal trajectories. GenPT is trained with a novel flow matching
formulation that combines the iterative refinement of discriminative trackers,
a window-dependent prior for cross-window consistency, and a variance schedule
tuned specifically for point coordinates. We show how our model's generative
capabilities can be leveraged to improve point trajectory estimates by
utilizing a best-first search strategy on generated samples during inference,
guided by the model's own confidence of its predictions. Empirically, we
evaluate GenPT against the current state of the art on the standard
PointOdyssey, Dynamic Replica, and TAP-Vid benchmarks. Further, we introduce a
TAP-Vid variant with additional occlusions to assess occluded point tracking
performance and highlight our model's ability to capture multi-modality. GenPT
is capable of capturing the multi-modality in point trajectories, which
translates to state-of-the-art tracking accuracy on occluded points, while
maintaining competitive tracking accuracy on visible points compared to extant
discriminative point trackers.

</details>


### [4] [3DReasonKnee: Advancing Grounded Reasoning in Medical Vision Language Models](https://arxiv.org/abs/2510.20967)
*Sraavya Sambara,Sung Eun Kim,Xiaoman Zhang,Luyang Luo,Shreya Johri,Mohammed Baharoon,Du Hyun Ro,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: 3DReasonKnee是一个针对医学影像的首个3D基础推理数据集，包含494k高质量五元组，旨在提高视觉-语言模型在医疗诊断中的应用能力。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-语言模型（VLMs）在3D医学影像中定位解剖区域及逐步推理方面存在困难，这对真实世界的诊断评估至关重要。

Method: 数据集通过手动分割MRI和生成推理链的方式创建与验证，确保其优良质量和临床相关性。

Result: 引入了3DReasonKnee，这是首个针对医学图像的3D基础推理数据集，提供494k高质量的五元组，支持VLM的定位和诊断能力评估。

Conclusion: 通过创建这一独特的专家标注3D推理路径资源，3DReasonKnee为推进多模态医疗AI系统向3D、临床对齐的本地化决策能力提供了重要的测试平台。

Abstract: Current Vision-Language Models (VLMs) struggle to ground anatomical regions
in 3D medical images and reason about them in a step-by-step manner, a key
requirement of real-world diagnostic assessment. This ability is essential for
aligning model outputs with the diagnostic workflows clinicians use in
practice, enabling trustworthy clinician-AI collaboration. Existing 3D datasets
provide localization labels, but none support this "grounded reasoning"
ability. To address this gap, we introduce 3DReasonKnee, the first 3D grounded
reasoning dataset for medical images, which provides 494k high-quality
quintuples derived from 7,970 3D knee MRI volumes. Each quintuple includes: (1)
the 3D MRI volume, (2) a diagnostic question targeting a specific anatomical
region (3) a 3D bounding box localizing the relevant anatomical structures, (4)
clinician-generated diagnostic reasoning steps that explicitly detail the 3D
reasoning process, and (5) structured severity assessments for the relevant
anatomical region. The creation and validation of 3DReasonKnee, involving over
450 hours of expert clinician time for manually segmenting MRIs and generating
reasoning chains, ensures its superior quality and clinical relevance. We
establish ReasonKnee-Bench to evaluate localization and diagnostic accuracy,
providing insight into VLM ability to perform grounding and severity assessment
across anatomical regions and diagnostic inquiries. We benchmark five
state-of-the-art VLMs, providing baseline performance for ReasonKnee-Bench. By
providing this unique resource of expert-annotated 3D reasoning pathways,
3DReasonKnee serves as a repository of orthopedic surgeons' diagnostic
expertise and offers a vital testbed for advancing multimodal medical AI
systems towards 3D, clinically aligned, localized decision-making capabilities.
The dataset can be found in:
https://huggingface.co/datasets/rajpurkarlab/3DReasonKnee

</details>


### [5] [Thermal Polarimetric Multi-view Stereo](https://arxiv.org/abs/2510.20972)
*Takahiro Kushida,Kenichiro Tanaka*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的利用热偏振线索进行详细三维形状重建的方法，实验表明其效果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 提出一种独立于照明和材料特性的三维形状重建新方法。

Method: 利用多视角的热偏振图像恢复详细的三维形状。

Result: 通过实验结果表明，所提方法能有效重建细微细节。

Conclusion: 该方法有效地重建透明、半透明和异质对象中的细节，优于现有技术。

Abstract: This paper introduces a novel method for detailed 3D shape reconstruction
utilizing thermal polarization cues. Unlike state-of-the-art methods, the
proposed approach is independent of illumination and material properties. In
this paper, we formulate a general theory of polarization observation and show
that long-wave infrared (LWIR) polarimetric imaging is free from the
ambiguities that affect visible polarization analyses. Subsequently, we propose
a method for recovering detailed 3D shapes using multi-view thermal
polarimetric images. Experimental results demonstrate that our approach
effectively reconstructs fine details in transparent, translucent, and
heterogeneous objects, outperforming existing techniques.

</details>


### [6] [VESSA: Video-based objEct-centric Self-Supervised Adaptation for Visual Foundation Models](https://arxiv.org/abs/2510.20994)
*Jesimon Barreto,Carlos Caetano,André Araujo,William Robson Schwartz*

Main category: cs.CV

TL;DR: VESSA是一种新颖的自监督微调方法，通过短多视角对象中心视频实现视觉基础模型的适应，提升模型在分布变化和标签稀缺情况下的性能。


<details>
  <summary>Details</summary>
Motivation: 解决基础模型在分布变化和标签稀缺情况下的适应问题，特别是在计算机视觉领域。

Method: VESSA基于自蒸馏范式，利用多视角对象观察进行自监督学习，有效地学习对不同捕捉条件的鲁棒性。

Result: 通过VESSA方法，在无需注释的情况下，在新的领域中适应视觉基础模型，显著提高下游分类任务的表现。

Conclusion: VESSA在2个数据集上对3个视觉基础模型的实验结果表明，该方法相比基模型和以前的适应方法取得了一致的改进。

Abstract: Foundation models have advanced computer vision by enabling strong
performance across diverse tasks through large-scale pretraining and supervised
fine-tuning. However, they may underperform in domains with distribution shifts
and scarce labels, where supervised fine-tuning may be infeasible. While
continued self-supervised learning for model adaptation is common for
generative language models, this strategy has not proven effective for
vision-centric encoder models. To address this challenge, we introduce a novel
formulation of self-supervised fine-tuning for vision foundation models, where
the model is adapted to a new domain without requiring annotations, leveraging
only short multi-view object-centric videos. Our method is referred to as
VESSA: Video-based objEct-centric Self-Supervised Adaptation for visual
foundation models. VESSA's training technique is based on a self-distillation
paradigm, where it is critical to carefully tune prediction heads and deploy
parameter-efficient adaptation techniques - otherwise, the model may quickly
forget its pretrained knowledge and reach a degraded state. VESSA benefits
significantly from multi-view object observations sourced from different frames
in an object-centric video, efficiently learning robustness to varied capture
conditions, without the need of annotations. Through comprehensive experiments
with 3 vision foundation models on 2 datasets, VESSA demonstrates consistent
improvements in downstream classification tasks, compared to the base models
and previous adaptation methods. Code is publicly available at
https://github.com/jesimonbarreto/VESSA.

</details>


### [7] [BioDet: Boosting Industrial Object Detection with Image Preprocessing Strategies](https://arxiv.org/abs/2510.21000)
*Jiaqi Hu,Hongli Xu,Junwen Huang,Peter KT Yu,Slobodan Ilic,Benjamin Busam*

Main category: cs.CV

TL;DR: 通过改进检测管道，克服传统方法在复杂环境中的局限性，提升了姿态估计精度


<details>
  <summary>Details</summary>
Motivation: 解决传统6D姿态估计在复杂环境中的性能下降问题

Method: 利用低光图像增强和背景去除，通过基础模型进行开放词汇检测，降低背景伪影和领域偏移

Result: 提出一种标准化的插件管道，显著提升检测准确性

Conclusion: 实验表明，所提方法在真实工业环境下有效提高了检测精度且推理开销极小

Abstract: Accurate 6D pose estimation is essential for robotic manipulation in
industrial environments. Existing pipelines typically rely on off-the-shelf
object detectors followed by cropping and pose refinement, but their
performance degrades under challenging conditions such as clutter, poor
lighting, and complex backgrounds, making detection the critical bottleneck. In
this work, we introduce a standardized and plug-in pipeline for 2D detection of
unseen objects in industrial settings. Based on current SOTA baselines, our
approach reduces domain shift and background artifacts through low-light image
enhancement and background removal guided by open-vocabulary detection with
foundation models. This design suppresses the false positives prevalent in raw
SAM outputs, yielding more reliable detections for downstream pose estimation.
Extensive experiments on real-world industrial bin-picking benchmarks from BOP
demonstrate that our method significantly boosts detection accuracy while
incurring negligible inference overhead, showing the effectiveness and
practicality of the proposed method.

</details>


### [8] [Deep learning-based automated damage detection in concrete structures using images from earthquake events](https://arxiv.org/abs/2510.21063)
*Abdullah Turer,Yongsheng Bai,Halil Sezen,Alper Yilmaz*

Main category: cs.CV

TL;DR: 本研究利用深度学习方法评估地震后混凝土建筑和桥梁的结构损伤，自动检测暴露的钢筋。


<details>
  <summary>Details</summary>
Motivation: 在地震事件后，及时评估结构的完整性对公共安全和应急响应至关重要。

Method: 采用YOLOv11模型进行裂缝及剥落损伤和暴露钢筋的检测，结合数据增强和细调技术，建立自动分类框架。

Result: 建立的混合框架能够自动、可靠地确定输入图像的损伤级别。

Conclusion: 本研究表明，通过图像数据收集、标注和深度学习方法，可以实现地震后快速自动的损伤检测。

Abstract: Timely assessment of integrity of structures after seismic events is crucial
for public safety and emergency response. This study focuses on assessing the
structural damage conditions using deep learning methods to detect exposed
steel reinforcement in concrete buildings and bridges after large earthquakes.
Steel bars are typically exposed after concrete spalling or large flexural or
shear cracks. The amount and distribution of exposed steel reinforcement is an
indication of structural damage and degradation. To automatically detect
exposed steel bars, new datasets of images collected after the 2023 Turkey
Earthquakes were labeled to represent a wide variety of damaged concrete
structures. The proposed method builds upon a deep learning framework, enhanced
with fine-tuning, data augmentation, and testing on public datasets. An
automated classification framework is developed that can be used to identify
inside/outside buildings and structural components. Then, a YOLOv11 (You Only
Look Once) model is trained to detect cracking and spalling damage and exposed
bars. Another YOLO model is finetuned to distinguish different categories of
structural damage levels. All these trained models are used to create a hybrid
framework to automatically and reliably determine the damage levels from input
images. This research demonstrates that rapid and automated damage detection
following disasters is achievable across diverse damage contexts by utilizing
image data collection, annotation, and deep learning approaches.

</details>


### [9] [ZING-3D: Zero-shot Incremental 3D Scene Graphs via Vision-Language Models](https://arxiv.org/abs/2510.21069)
*Pranav Saxena,Jimmy Chiun*

Main category: cs.CV

TL;DR: ZING-3D框架利用预训练模型，实现开放词汇识别和三维环境的语义表示，支持增量更新和几何定位，适合机器人应用。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D场景图生成方法在观察更新和几何基础方面的不足，提供更全面的场景理解能力。

Method: 通过VLM推理生成丰富的2D场景图，并利用深度信息进行三维定位，节点表示开放词汇对象及其特征、三维位置和语义上下文，边表示空间和语义关系。

Result: 本文提出了ZING-3D框架，以解决复杂三维环境中对象及其语义和空间关系的理解和推理问题。该框架利用预训练基础模型的知识，实现开放词汇识别，生成丰富的语义表示，并支持增量更新与三维几何定位，适用于机器人应用。

Conclusion: ZING-3D能够在不进行任务特定训练的情况下，有效捕获场景中的空间和关系知识。

Abstract: Understanding and reasoning about complex 3D environments requires structured
scene representations that capture not only objects but also their semantic and
spatial relationships. While recent works on 3D scene graph generation have
leveraged pretrained VLMs without task-specific fine-tuning, they are largely
confined to single-view settings, fail to support incremental updates as new
observations arrive and lack explicit geometric grounding in 3D space, all of
which are essential for embodied scenarios. In this paper, we propose, ZING-3D,
a framework that leverages the vast knowledge of pretrained foundation models
to enable open-vocabulary recognition and generate a rich semantic
representation of the scene in a zero-shot manner while also enabling
incremental updates and geometric grounding in 3D space, making it suitable for
downstream robotics applications. Our approach leverages VLM reasoning to
generate a rich 2D scene graph, which is grounded in 3D using depth
information. Nodes represent open-vocabulary objects with features, 3D
locations, and semantic context, while edges capture spatial and semantic
relations with inter-object distances. Our experiments on scenes from the
Replica and HM3D dataset show that ZING-3D is effective at capturing spatial
and relational knowledge without the need of task-specific training.

</details>


### [10] [HistRetinex: Optimizing Retinex model in Histogram Domain for Efficient Low-Light Image Enhancement](https://arxiv.org/abs/2510.21100)
*Jingtian Zhao,Xueli Xie,Jianxiang Xi,Xiaogang Yang,Haoxuan Sun*

Main category: cs.CV

TL;DR: 本研究提出了一种新的快速低光照图像增强方法HistRetinex，通过直方图域的优化显著提升了处理速度和效果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Retinex的低光照图像增强方法在处理大型图像时耗时较长，因此亟需一种快速的方法来提升低光照图像的质量。

Method: 将Retinex模型从空间域扩展到直方图域，通过构建直方图位置矩阵和直方图计数矩阵，建立了低光照图像的照明和反射率的直方图之间的关系，并提出了基于直方图的Retinex模型的双层优化模型。

Result: 提出了一种新的基于直方图的Retinex模型（HistRetinex），显著提高了低光照图像的增强速度和效果。

Conclusion: HistRetinex在图像增强的可见度和性能指标上均优于现有的方法，同时在处理1000*664分辨率的图像时，执行时间仅为1.86秒，节省了至少6.67秒的时间。

Abstract: Retinex-based low-light image enhancement methods are widely used due to
their excellent performance. However, most of them are time-consuming for
large-sized images. This paper extends the Retinex model from the spatial
domain to the histogram domain, and proposes a novel histogram-based Retinex
model for fast low-light image enhancement, named HistRetinex. Firstly, we
define the histogram location matrix and the histogram count matrix, which
establish the relationship among histograms of the illumination, reflectance
and the low-light image. Secondly, based on the prior information and the
histogram-based Retinex model, we construct a novel two-level optimization
model. Through solving the optimization model, we give the iterative formulas
of the illumination histogram and the reflectance histogram, respectively.
Finally, we enhance the low-light image through matching its histogram with the
one provided by HistRetinex. Experimental results demonstrate that the
HistRetinex outperforms existing enhancement methods in both visibility and
performance metrics, while executing 1.86 seconds on 1000*664 resolution
images, achieving a minimum time saving of 6.67 seconds.

</details>


### [11] [Group Inertial Poser: Multi-Person Pose and Global Translation from Sparse Inertial Sensors and Ultra-Wideband Ranging](https://arxiv.org/abs/2510.21654)
*Ying Xue,Jiaxi Jiang,Rayan Armani,Dominik Hollidt,Yi-Chi Liao,Christian Holz*

Main category: cs.CV

TL;DR: 本研究提出了一种基于IMU和超宽带(UWB)的多人体运动追踪新方法，显著提高了姿态估计的精度和稳健性。


<details>
  <summary>Details</summary>
Motivation: 解决传统IMU方法在人员之间的绝对定位不足问题，提升多人体运动捕捉的准确性和稳健性。

Method: 通过结合稀疏可穿戴传感器之间的距离估计与惯性观测，利用结构化状态空间模型实现精确的3D姿态估计。

Result: Group Inertial Poser在合成和真实场景数据中均优于传统方法，展示了IMU+UWB技术在复杂环境下的应用潜力。

Conclusion: Group Inertial Poser在多个个体的全身运动追踪中表现优异，超越了传统方法的局限性。

Abstract: Tracking human full-body motion using sparse wearable inertial measurement
units (IMUs) overcomes the limitations of occlusion and instrumentation of the
environment inherent in vision-based approaches. However, purely IMU-based
tracking compromises translation estimates and accurate relative positioning
between individuals, as inertial cues are inherently self-referential and
provide no direct spatial reference for others. In this paper, we present a
novel approach for robustly estimating body poses and global translation for
multiple individuals by leveraging the distances between sparse wearable
sensors - both on each individual and across multiple individuals. Our method
Group Inertial Poser estimates these absolute distances between pairs of
sensors from ultra-wideband ranging (UWB) and fuses them with inertial
observations as input into structured state-space models to integrate temporal
motion patterns for precise 3D pose estimation. Our novel two-step optimization
further leverages the estimated distances for accurately tracking people's
global trajectories through the world. We also introduce GIP-DB, the first
IMU+UWB dataset for two-person tracking, which comprises 200 minutes of motion
recordings from 14 participants. In our evaluation, Group Inertial Poser
outperforms previous state-of-the-art methods in accuracy and robustness across
synthetic and real-world data, showing the promise of IMU+UWB-based multi-human
motion capture in the wild. Code, models, dataset:
https://github.com/eth-siplab/GroupInertialPoser

</details>


### [12] [PhysVLM-AVR: Active Visual Reasoning for Multimodal Large Language Models in Physical Environments](https://arxiv.org/abs/2510.21111)
*Weijie Zhou,Xuantang Xiong,Yi Peng,Manli Tao,Chaoyang Zhao,Honghui Dong,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: 这篇论文介绍了一项新的任务：主动视觉推理（AVR），旨在扩展多模态大语言模型（MLLMs）在部分可观察的互动环境中的推理能力，构建了CLEVR-AVR基准来评估推理的正确性和信息获取的效率，并提出了PhysVLM-AVR模型。


<details>
  <summary>Details</summary>
Motivation: 该研究受到人类在探索和交互环境中主动获取信息能力的启发，旨在提升MLLMs在真实世界中处理不完整信息的能力。

Method: 论文提出了通过一系列的物理动作主动获取信息、综合多步观察以进行连贯推理，并根据视觉反馈动态调整决策的AVR任务，以及相应的CLEVR-AVR模拟基准和PhysVLM-AVR模型。

Result: 研究表明，PhysVLM-AVR在CLEVR-AVR和其他推理任务上取得了最先进的性能，揭示了当前MLLM在主动推理能力方面的不足。

Conclusion: 尽管目前的领域模型能够检测信息的不完整性，但在通过互动主动获取和整合新信息方面仍存在显著的能力缺口。

Abstract: Visual reasoning in multimodal large language models (MLLMs) has primarily
been studied in static, fully observable settings, limiting their effectiveness
in real-world environments where information is often incomplete due to
occlusion or limited field of view. Humans, in contrast, actively explore and
interact with their environment-moving, examining, and manipulating objects-to
gather information through a closed-loop process integrating perception,
reasoning, and action. Inspired by this human capability, we introduce the
Active Visual Reasoning (AVR) task, extending visual reasoning to partially
observable, interactive environments. AVR necessitates agents to: (1) actively
acquire information via sequential physical actions, (2) integrate observations
across multiple steps for coherent reasoning, and (3) dynamically adjust
decisions based on evolving visual feedback. To rigorously evaluate AVR, we
introduce CLEVR-AVR, a simulation benchmark featuring multi-round interactive
environments designed to assess both reasoning correctness and
information-gathering efficiency. We present AVR-152k, a large-scale dataset
that offers rich Chain-of-Thought (CoT) annotations detailing iterative
reasoning for uncertainty identification, action-conditioned information gain
prediction, and information-maximizing action selection, crucial for training
agents in a higher-order Markov Decision Process. Building on this, we develop
PhysVLM-AVR, an MLLM achieving state-of-the-art performance on CLEVR-AVR,
embodied reasoning (OpenEQA, RoboVQA), and passive visual reasoning (GeoMath,
Geometry30K). Our analysis also reveals that current embodied MLLMs, despite
detecting information incompleteness, struggle to actively acquire and
integrate new information through interaction, highlighting a fundamental gap
in active reasoning capabilities.

</details>


### [13] [SafetyPairs: Isolating Safety Critical Image Features with Counterfactual Image Generation](https://arxiv.org/abs/2510.21120)
*Alec Helbling,Shruti Palaskar,Kundan Krishna,Polo Chau,Leon Gatys,Joseph Yitan Cheng*

Main category: cs.CV

TL;DR: 引入SafetyPairs框架，通过生成反事实图像对，解决图像安全性区分问题，提供系统化的安全基准与数据增强策略。


<details>
  <summary>Details</summary>
Motivation: 系统区分良性与有问题的图像是一个具有挑战性的任务，现有图像安全数据集提供的安全标签过于粗糙且模糊，未能明确孤立出驱动这些差异的具体特征。

Method: 采用图像编辑模型，对图像进行针对性修改，改变其安全标签而不改变与安全无关的细节。

Result: 我们提出了SafetyPairs，一个可扩展的框架，通过生成仅在与安全策略相关的特征上有所不同的反事实图像对，以此反转其安全标签，从而构建了一个新的安全基准。

Conclusion: 我们的工作构建了一个包含3020多个SafetyPair图像的新安全基准，为研究精细的图像安全差异提供了首个系统化资源，同时提高了轻量级监控模型的训练样本效率。

Abstract: What exactly makes a particular image unsafe? Systematically differentiating
between benign and problematic images is a challenging problem, as subtle
changes to an image, such as an insulting gesture or symbol, can drastically
alter its safety implications. However, existing image safety datasets are
coarse and ambiguous, offering only broad safety labels without isolating the
specific features that drive these differences. We introduce SafetyPairs, a
scalable framework for generating counterfactual pairs of images, that differ
only in the features relevant to the given safety policy, thus flipping their
safety label. By leveraging image editing models, we make targeted changes to
images that alter their safety labels while leaving safety-irrelevant details
unchanged. Using SafetyPairs, we construct a new safety benchmark, which serves
as a powerful source of evaluation data that highlights weaknesses in
vision-language models' abilities to distinguish between subtly different
images. Beyond evaluation, we find our pipeline serves as an effective data
augmentation strategy that improves the sample efficiency of training
lightweight guard models. We release a benchmark containing over 3,020
SafetyPair images spanning a diverse taxonomy of 9 safety categories, providing
the first systematic resource for studying fine-grained image safety
distinctions.

</details>


### [14] [NoisyGRPO: Incentivizing Multimodal CoT Reasoning via Noise Injection and Bayesian Estimation](https://arxiv.org/abs/2510.21122)
*Longtian Qiu,Shan Ning,Jiaxuan Sun,Xuming He*

Main category: cs.CV

TL;DR: NoisyGRPO是一个多模态强化学习框架，通过可控噪声和贝叶斯估计提升推理能力，改善泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决现有强化学习框架在推理能力与泛化能力上面临的挑战，特别是在多模态大语言模型中。

Method: 引入高斯噪声进行视觉输入的扰动（噪声注入探索策略）和将优势估计建模为贝叶斯推断问题（贝叶斯优势估计）。

Result: 本文提出了一种名为NoisyGRPO的多模态强化学习框架，旨在通过引入可控噪声和贝叶斯优势估计，提高多模态大语言模型的推理能力。该框架的创新之处在于使用高斯噪声进行视觉输入的扰动，鼓励更广泛的探索，同时利用贝叶斯推断方法进行优势估计，从而增强模型的泛化能力和鲁棒性。实验结果表明，NoisyGRPO在推理质量、通用能力和幻觉基准测试上表现出显著的改进，尤其是在小规模的多模态语言模型上。

Conclusion: NoisyGRPO框架显著改善了小规模多模态语言模型的推理能力和泛化性，为强化学习领域提供了新的方向。

Abstract: Reinforcement learning (RL) has shown promise in enhancing the general
Chain-of-Thought (CoT) reasoning capabilities of multimodal large language
models (MLLMs). However, when applied to improve general CoT reasoning,
existing RL frameworks often struggle to generalize beyond the training
distribution. To address this, we propose NoisyGRPO, a systematic multimodal RL
framework that introduces controllable noise into visual inputs for enhanced
exploration and explicitly models the advantage estimation process via a
Bayesian framework. Specifically, NoisyGRPO improves RL training by: (1)
\textbf{Noise-Injected Exploration Policy}: Perturbing visual inputs with
Gaussian noise to encourage exploration across a wider range of visual
scenarios; and (2) \textbf{Bayesian Advantage Estimation}: Formulating
advantage estimation as a principled Bayesian inference problem, where the
injected noise level serves as a prior and the observed trajectory reward as
the likelihood. This Bayesian modeling fuses both sources of information to
compute a robust posterior estimate of trajectory advantage, effectively
guiding MLLMs to prefer visually grounded trajectories over noisy ones.
Experiments on standard CoT quality, general capability, and hallucination
benchmarks demonstrate that NoisyGRPO substantially improves generalization and
robustness, especially in RL settings with small-scale MLLMs such as Qwen2.5-VL
3B. The project page is available at
\href{https://artanic30.github.io/project_pages/NoisyGRPO/}{\texttt{https://artanic30.github.io/project\_pages/NoisyGRPO}}.

</details>


### [15] [Towards Physics-informed Spatial Intelligence with Human Priors: An Autonomous Driving Pilot Study](https://arxiv.org/abs/2510.21160)
*Guanlin Wu,Boyan Su,Yang Zhao,Pu Wang,Yichen Lin,Hao Frank Yang*

Main category: cs.CV

TL;DR: 本文提出了空间智能网格(SIG)，用于改善基础模型的空间智能评估，并显示出相较于传统方式的显著优势。


<details>
  <summary>Details</summary>
Motivation: 解决当前基于文本的视觉空间智能 (VSI) 衡量方法的一些局限性，提供更准确的空间能力评估。

Method: 引入空间智能网格 (SIG) 的结构化、基于网格的框架来编码对象布局和对象间关系，以支持基础模型的推理。

Result: SIG显著提高了多模态大型语言模型 (如GPT和Gemini家族模型) 在VSI指标上的表现，并发布了SIGBench基准。

Conclusion: SIG提供了一种可靠的方式来评估和提升模型的空间智能，特别是在自动驾驶场景中。

Abstract: How to integrate and verify spatial intelligence in foundation models remains
an open challenge. Current practice often proxies Visual-Spatial Intelligence
(VSI) with purely textual prompts and VQA-style scoring, which obscures
geometry, invites linguistic shortcuts, and weakens attribution to genuinely
spatial skills. We introduce Spatial Intelligence Grid (SIG): a structured,
grid-based schema that explicitly encodes object layouts, inter-object
relations, and physically grounded priors. As a complementary channel to text,
SIG provides a faithful, compositional representation of scene structure for
foundation-model reasoning. Building on SIG, we derive SIG-informed evaluation
metrics that quantify a model's intrinsic VSI, which separates spatial
capability from language priors. In few-shot in-context learning with
state-of-the-art multimodal LLMs (e.g. GPT- and Gemini-family models), SIG
yields consistently larger, more stable, and more comprehensive gains across
all VSI metrics compared to VQA-only representations, indicating its promise as
a data-labeling and training schema for learning VSI. We also release SIGBench,
a benchmark of 1.4K driving frames annotated with ground-truth SIG labels and
human gaze traces, supporting both grid-based machine VSI tasks and
attention-driven, human-like VSI tasks in autonomous-driving scenarios.

</details>


### [16] [Blockwise Flow Matching: Improving Flow Matching Models For Efficient High-Quality Generation](https://arxiv.org/abs/2510.21167)
*Dogyun Park,Taehoon Lee,Minseok Joo,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: 本研究提出了BFM框架，通过区分时间段并优化推理过程，在提高生成效率和质量方面显著优于现有Flow Matching模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有Flow Matching模型在多个时间步长下无法有效捕捉信号特征和推理成本高的问题。

Method: 采用块状设计，将生成路径分为多个时间段，由专门的速度块建模，同时结合语义特征引导和特征残差近似策略。

Result: 本文提出了Blockwise Flow Matching（BFM）框架，以克服现有Flow Matching模型在生成数据时的效率和质量问题。该框架将生成路径划分为多个时间段，每个时间段由专门的速度块进行建模，旨在提高推理效率和样本质量。同时，文章引入了语义特征引导模块和轻量级特征残差近似策略，在保持语义质量的同时进一步降低推理成本。实验结果显示，BFM在ImageNet上的推理复杂度较现有方法显著降低，且保持了相似的生成性能。

Conclusion: Blockwise Flow Matching框架在保证生成性能的同时，实现了推理复杂度的显著降低，具有较好的应用潜力。

Abstract: Recently, Flow Matching models have pushed the boundaries of high-fidelity
data generation across a wide range of domains. It typically employs a single
large network to learn the entire generative trajectory from noise to data.
Despite their effectiveness, this design struggles to capture distinct signal
characteristics across timesteps simultaneously and incurs substantial
inference costs due to the iterative evaluation of the entire model. To address
these limitations, we propose Blockwise Flow Matching (BFM), a novel framework
that partitions the generative trajectory into multiple temporal segments, each
modeled by smaller but specialized velocity blocks. This blockwise design
enables each block to specialize effectively in its designated interval,
improving inference efficiency and sample quality. To further enhance
generation fidelity, we introduce a Semantic Feature Guidance module that
explicitly conditions velocity blocks on semantically rich features aligned
with pretrained representations. Additionally, we propose a lightweight Feature
Residual Approximation strategy that preserves semantic quality while
significantly reducing inference cost. Extensive experiments on ImageNet
256x256 demonstrate that BFM establishes a substantially improved Pareto
frontier over existing Flow Matching methods, achieving 2.1x to 4.9x
accelerations in inference complexity at comparable generation performance.
Code is available at https://github.com/mlvlab/BFM.

</details>


### [17] [TokenCLIP: Token-wise Prompt Learning for Zero-shot Anomaly Detection](https://arxiv.org/abs/2510.21171)
*Qihang Zhou,Binbin Gao,Guansong Pang,Xin Wang,Jiming Chen,Shibo He*

Main category: cs.CV

TL;DR: TokenCLIP通过动态对齐视觉和文本空间，提高了对未知对象异常检测的能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖于单一文本空间进行视觉语义的对齐，这限制了模型准确捕捉不同异常语义的能力。

Method: 提出了TokenCLIP，一个基于token的适应框架，动态地将视觉和可学习的文本空间进行对齐，支持细粒度的异常学习。

Result: TokenCLIP的提出和实验表明其在异常检测任务上优于现有方法。

Conclusion: TokenCLIP能有效实现细粒度的异常学习，解决了单一文本空间对齐的局限性，展现出在细粒度异常检测上的优势。

Abstract: Adapting CLIP for anomaly detection on unseen objects has shown strong
potential in a zero-shot manner. However, existing methods typically rely on a
single textual space to align with visual semantics across diverse objects and
domains. The indiscriminate alignment hinders the model from accurately
capturing varied anomaly semantics. We propose TokenCLIP, a token-wise
adaptation framework that enables dynamic alignment between visual and
learnable textual spaces for fine-grained anomaly learning. Rather than mapping
all visual tokens to a single, token-agnostic textual space, TokenCLIP aligns
each token with a customized textual subspace that represents its visual
characteristics. Explicitly assigning a unique learnable textual space to each
token is computationally intractable and prone to insufficient optimization. We
instead expand the token-agnostic textual space into a set of orthogonal
subspaces, and then dynamically assign each token to a subspace combination
guided by semantic affinity, which jointly supports customized and efficient
token-wise adaptation. To this end, we formulate dynamic alignment as an
optimal transport problem, where all visual tokens in an image are transported
to textual subspaces based on semantic similarity. The transport constraints of
OT ensure sufficient optimization across subspaces and encourage them to focus
on different semantics. Solving the problem yields a transport plan that
adaptively assigns each token to semantically relevant subspaces. A top-k
masking is then applied to sparsify the plan and specialize subspaces for
distinct visual regions. Extensive experiments demonstrate the superiority of
TokenCLIP.

</details>


### [18] [KBE-DME: Dynamic Multimodal Evaluation via Knowledge Enhanced Benchmark Evolution](https://arxiv.org/abs/2510.21182)
*Junzhe Zhang,Huixuan Zhang,Xiaojun Wan*

Main category: cs.CV

TL;DR: KBE是一个动态的多模态评估框架，通过图形公式化和知识增强，有效解决了静态基准的不足，提供了更可靠的多模态大语言模型评估。


<details>
  <summary>Details</summary>
Motivation: 现有的静态基准存在数据污染和饱和等问题，可能导致误导性的性能评估。

Method: 应用图形公式化构建静态或动态视觉问答样本，并通过知识增强基准演变(KBE)来扩展基准。

Result: KBE改善了多模态评估，允许重选视觉信息和扩展现有问题，实现可控的难度评估。

Conclusion: KBE框架通过动态演变基准，提供了对多模态大语言模型能力的更全面评估，降低了数据污染和饱和的风险。

Abstract: The rapid progress of multimodal large language models (MLLMs) calls for more
reliable evaluation protocols. Existing static benchmarks suffer from the
potential risk of data contamination and saturation, leading to inflated or
misleading performance evaluations. To address these issues, we first apply
Graph formulation to represent a static or dynamic VQA sample. With the
formulation, we propose Knowledge-enhanced Benchmark Evolution(KBE), a dynamic
multimodal evaluation framework. KBE first analyzes the original static
benchmark, then expands it by integrating multimodal knowledge, transforming
the static benchmark into a controllable, dynamic evolving version. Crucially,
KBE can both reconstruct questions by Re-selecting visual information in the
original image and expand existing questions with external textual knowledge.
It enables difficulty-controllable evaluation by adjusting the degree of
question exploration. Extensive experiments demonstrate that KBE alleviates the
risk of data contamination, data saturation, and provides a more comprehensive
assessment of MLLM capabilities.

</details>


### [19] [3rd Place Solution to ICCV LargeFineFoodAI Retrieval](https://arxiv.org/abs/2510.21198)
*Yang Zhong,Zhiming Wang,Zhaoyang Li,Jinyu Ma,Xiang Li*

Main category: cs.CV

TL;DR: 该论文介绍了在ICCV LargeFineFoodAI检索竞赛中的第3名解决方案。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在提高食品图像检索的准确性和效率，以应对大型数据集的挑战。

Method: 四个基本模型采用ArcFace和Circle损失的加权和独立训练，随后应用了TTA和集成方法以提升特征表示能力，同时提出了一种基于扩散和k-相互回归的新重排名方法。

Result: 通过提出的新方法，本文在竞赛中取得了优秀的成绩。

Conclusion: 本文提出的方法在公开和私有排行榜上的mAP@100均表现良好，分别为0.81219和0.81191。

Abstract: This paper introduces the 3rd place solution to the ICCV LargeFineFoodAI
Retrieval Competition on Kaggle. Four basic models are independently trained
with the weighted sum of ArcFace and Circle loss, then TTA and Ensemble are
successively applied to improve feature representation ability. In addition, a
new reranking method for retrieval is proposed based on diffusion and
k-reciprocal reranking. Finally, our method scored 0.81219 and 0.81191 mAP@100
on the public and private leaderboard, respectively.

</details>


### [20] [3rd Place Solution to Large-scale Fine-grained Food Recognition](https://arxiv.org/abs/2510.21199)
*Yang Zhong,Yifan Yao,Tong Luo,Youcai Zhang,Yaqian Li*

Main category: cs.CV

TL;DR: 本论文提出了一种结合Arcface和Circle损失的训练方法以提高细粒度食品识别性能，并在相关比赛中取得佳绩。


<details>
  <summary>Details</summary>
Motivation: 随着健康领域对食品分析的关注增加，细粒度的食品识别任务变得重要。

Method: 提出了一种基于Arcface损失和Circle损失结合的方法来改进食品识别性能。

Result: 该解决方案在Kaggle举办的LargeFineFoodAI-ICCV Workshop-Recognition挑战赛中获得了第三名。

Conclusion: 通过精心调整的配置和模型集成，成功提高了食品识别模型的表现，证明了损失函数组合的有效性。

Abstract: Food analysis is becoming a hot topic in health area, in which fine-grained
food recognition task plays an important role. In this paper, we describe the
details of our solution to the LargeFineFoodAI-ICCV Workshop-Recognition
challenge held on Kaggle. We find a proper combination of Arcface loss[1] and
Circle loss[9] can bring improvement to the performance. With Arcface and the
combined loss, model was trained with carefully tuned configurations and
ensembled to get the final results. Our solution won the 3rd place in the
competition.

</details>


### [21] [Topology Sculptor, Shape Refiner: Discrete Diffusion Model for High-Fidelity 3D Meshes Generation](https://arxiv.org/abs/2510.21264)
*Kaiyu Song,Hanjiang Lai,Yaqing Zhang,Chuangjian Cai,Yan Pan Kun Yue,Jian Yin*

Main category: cs.CV

TL;DR: 本文介绍了一种新方法TSSR，用于基于离散扩散模型生成高质量艺术风格3D网格，具备显著的并行生成能力和多个创新。


<details>
  <summary>Details</summary>
Motivation: 实现高精度的令牌预测并支持并行生成，以超越序列自回归方法的局限。

Method: 将生成过程分为拓扑雕刻阶段和形状细化阶段，同时引入了改进的Hourglass架构和新型的连接损失。

Result: TSSR生成高质量的艺术风格3D网格，能够在1024^3的空间分辨率下达到10000个面。

Conclusion: TSSR通过有效捕捉局部和全局形状特征，结合新的架构和损失函数，显著提高了3D网格生成的质量和效率。

Abstract: In this paper, we introduce Topology Sculptor, Shape Refiner (TSSR), a novel
method for generating high-quality, artist-style 3D meshes based on Discrete
Diffusion Models (DDMs). Our primary motivation for TSSR is to achieve highly
accurate token prediction while enabling parallel generation, a significant
advantage over sequential autoregressive methods. By allowing TSSR to "see" all
mesh tokens concurrently, we unlock a new level of efficiency and control. We
leverage this parallel generation capability through three key innovations: 1)
Decoupled Training and Hybrid Inference, which distinctly separates the
DDM-based generation into a topology sculpting stage and a subsequent shape
refinement stage. This strategic decoupling enables TSSR to effectively capture
both intricate local topology and overarching global shape. 2) An Improved
Hourglass Architecture, featuring bidirectional attention enriched by
face-vertex-sequence level Rotational Positional Embeddings (RoPE), thereby
capturing richer contextual information across the mesh structure. 3) A novel
Connection Loss, which acts as a topological constraint to further enhance the
realism and fidelity of the generated meshes. Extensive experiments on complex
datasets demonstrate that TSSR generates high-quality 3D artist-style meshes,
capable of achieving up to 10,000 faces at a remarkable spatial resolution of
$1024^3$. The code will be released at:
https://github.com/psky1111/Tencent-TSSR.

</details>


### [22] [Towards Physically Executable 3D Gaussian for Embodied Navigation](https://arxiv.org/abs/2510.21307)
*Bingchen Miao,Rong Wei,Zhiqi Ge,Xiaoquan sun,Shiqi Gao,Jingzhe Zhu,Renhan Wang,Siliang Tang,Jun Xiao,Rui Tang,Juncheng Li*

Main category: cs.CV

TL;DR: 提出SAGE-3D，改进3DGS以增强语义和物理执行能力，发布InteriorGS数据集和SAGE-Bench基准，实验显示基准提升显著。


<details>
  <summary>Details</summary>
Motivation: 为提高视觉语言导航的效果并解决3DGS缺乏语义和物理可执行性的问题。

Method: SAGE-3D包括两个部分：物体中心的语义注释与物理意识的执行连接。

Result: 本文提出SAGE-3D，一种新兴的3D导航环境，旨在提升3D Gaussian Splatting (3DGS)的语义和物理可执行性。SAGE-3D通过引入物体中心语义基础和物理意识执行整合来解决3DGS在视觉语言导航（VLN）中的不足。研究还发布了InteriorGS，包含1000个标注物体的3DGS室内场景数据，并介绍了SAGE-Bench作为首个基于3DGS的VLN基准，将数据扩展至200万条VLN任务。实验结果表明，尽管3DGS场景数据更难以收敛，但展现出更强的泛化能力，在VLN-CE Unseen任务上基线性能提升了31%。

Conclusion: SAGE-3D通过物体语义和物理接入提升了3DGS的应用效果，突破了现有技术的限制。

Abstract: 3D Gaussian Splatting (3DGS), a 3D representation method with photorealistic
real-time rendering capabilities, is regarded as an effective tool for
narrowing the sim-to-real gap. However, it lacks fine-grained semantics and
physical executability for Visual-Language Navigation (VLN). To address this,
we propose SAGE-3D (Semantically and Physically Aligned Gaussian Environments
for 3D Navigation), a new paradigm that upgrades 3DGS into an executable,
semantically and physically aligned environment. It comprises two components:
(1) Object-Centric Semantic Grounding, which adds object-level fine-grained
annotations to 3DGS; and (2) Physics-Aware Execution Jointing, which embeds
collision objects into 3DGS and constructs rich physical interfaces. We release
InteriorGS, containing 1K object-annotated 3DGS indoor scene data, and
introduce SAGE-Bench, the first 3DGS-based VLN benchmark with 2M VLN data.
Experiments show that 3DGS scene data is more difficult to converge, while
exhibiting strong generalizability, improving baseline performance by 31% on
the VLN-CE Unseen task. The data and code will be available soon.

</details>


### [23] [FineRS: Fine-grained Reasoning and Segmentation of Small Objects with Reinforcement Learning](https://arxiv.org/abs/2510.21311)
*Lu Zhang,Jiazuo Yu,Haomiao Xiong,Ping Hu,Yunzhi Zhuge,Huchuan Lu,You He*

Main category: cs.CV

TL;DR: FineRS是一种新型的强化学习框架，旨在提高多模态大语言模型在高分辨率图像中对小物体的推理和分割能力，实验结果表明其效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在高分辨率图像中对极小物体理解和定位的挑战。

Method: 提出了一种基于多模态大语言模型的强化学习框架FineRS，采用粗到精的处理流程进行小物体的推理和分割。

Result: 在FineRS-4k数据集及公共数据集上进行实验，结果表明该方法在指令引导的分割和视觉推理任务中，性能均优于现有的最先进方法。

Conclusion: 该方法为高分辨率场景中小物体的精确分割和推理提供了一种有效的解决方案，并在相关数据集上显示出优异性能。

Abstract: Multi-modal Large Language Models (MLLMs) have shown remarkable capabilities
across a wide range of vision-language tasks. However, due to the restricted
input resolutions, MLLMs face significant challenges in precisely understanding
and localizing visual details in high-resolution images -- particularly when
dealing with extra-small objects embedded in cluttered contexts. To address
this issue, we propose \textsc{FineRS}, a two-stage MLLM-based reinforcement
learning framework for jointly reasoning and segmenting extremely small objects
within high-resolution scenes. \textsc{FineRS} adopts a coarse-to-fine pipeline
comprising Global Semantic Exploration (GSE) and Localized Perceptual
Refinement (LPR). Specifically, GSE performs instruction-guided reasoning to
generate a textural response and a coarse target region, while LPR refines this
region to produce an accurate bounding box and segmentation mask. To couple the
two stages, we introduce a locate-informed retrospective reward, where LPR's
outputs are used to optimize GSE for more robust coarse region exploration. %
Additionally, we present \textsc{FineRS}-4k, a new dataset for evaluating MLLMs
on attribute-level reasoning and pixel-level segmentation on subtle,
small-scale targets in complex high-resolution scenes. Experimental results on
\textsc{FineRS}-4k and public datasets demonstrate that our method consistently
outperforms state-of-the-art MLLM-based approaches on both instruction-guided
segmentation and visual reasoning tasks.

</details>


### [24] [VL-SAE: Interpreting and Enhancing Vision-Language Alignment with a Unified Concept Set](https://arxiv.org/abs/2510.21323)
*Shufan Shen,Junshu Sun,Qingming Huang,Shuhui Wang*

Main category: cs.CV

TL;DR: VL-SAE是一个稀疏自编码器，旨在提高视觉-语言模型的多模态推理能力，通过统一概念集解释视觉-语言表示。


<details>
  <summary>Details</summary>
Motivation: 由于多模态表示语义映射困难，当前视觉-语言模型的对齐组件缺乏可解释性。

Method: 通过稀疏自编码器构建距离编码器和两个特定模态解码器，确保语义相似表示在自监督训练中展现一致的神经元激活。

Result: 在多个视觉-语言模型上进行实验，VL-SAE证明了其在解释和增强视觉-语言对齐方面的优越能力。

Conclusion: VL-SAE在视觉-语言对齐的解释和增强方面展现出卓越能力，为后续任务提供性能提升。

Abstract: The alignment of vision-language representations endows current
Vision-Language Models (VLMs) with strong multi-modal reasoning capabilities.
However, the interpretability of the alignment component remains uninvestigated
due to the difficulty in mapping the semantics of multi-modal representations
into a unified concept set. To address this problem, we propose VL-SAE, a
sparse autoencoder that encodes vision-language representations into its hidden
activations. Each neuron in its hidden layer correlates to a concept
represented by semantically similar images and texts, thereby interpreting
these representations with a unified concept set. To establish the
neuron-concept correlation, we encourage semantically similar representations
to exhibit consistent neuron activations during self-supervised training.
First, to measure the semantic similarity of multi-modal representations, we
perform their alignment in an explicit form based on cosine similarity. Second,
we construct the VL-SAE with a distance-based encoder and two modality-specific
decoders to ensure the activation consistency of semantically similar
representations. Experiments across multiple VLMs (e.g., CLIP, LLaVA)
demonstrate the superior capability of VL-SAE in interpreting and enhancing the
vision-language alignment. For interpretation, the alignment between vision and
language representations can be understood by comparing their semantics with
concepts. For enhancement, the alignment can be strengthened by aligning
vision-language representations at the concept level, contributing to
performance improvements in downstream tasks, including zero-shot image
classification and hallucination elimination. Codes are available at
https://github.com/ssfgunner/VL-SAE.

</details>


### [25] [Morphologically Intelligent Perturbation Prediction with FORM](https://arxiv.org/abs/2510.21337)
*Reed Naidoo,Matt De Vries,Olga Fourkioti,Vicky Bousgouni,Mar Arias-Garcia,Maria Portillo-Malumbres,Chris Bakal*

Main category: cs.CV

TL;DR: FORM是一个预测细胞三维结构变化的机器学习框架，能模拟细胞在不同扰动条件下的反应。


<details>
  <summary>Details</summary>
Motivation: 当前的计算框架在建模细胞反应时只限于二维表示，无法有效捕捉细胞形态在扰动下的复杂性，因此需要开发准确的虚拟细胞模型。

Method: 提出一种名为FORM的机器学习框架，用于预测外部扰动引起的细胞三维结构变化。

Result: FORM能够进行无条件的形态合成和有条件的扰动细胞状态模拟，并能够预测下游信号活性，模拟组合扰动效果，建模未知扰动的形态动态转变。

Conclusion: FORM和MorphoEval的结合为实现更高分辨率的3D虚拟细胞提供了重要工具，能够有效链接形态、扰动和功能。

Abstract: Understanding how cells respond to external stimuli is a central challenge in
biomedical research and drug development. Current computational frameworks for
modelling cellular responses remain restricted to two-dimensional
representations, limiting their capacity to capture the complexity of cell
morphology under perturbation. This dimensional constraint poses a critical
bottleneck for the development of accurate virtual cell models. Here, we
present FORM, a machine learning framework for predicting perturbation-induced
changes in three-dimensional cellular structure. FORM consists of two
components: a morphology encoder, trained end-to-end via a novel multi-channel
VQGAN to learn compact 3D representations of cell shape, and a diffusion-based
perturbation trajectory module that captures how morphology evolves across
perturbation conditions. Trained on a large-scale dataset of over 65,000
multi-fluorescence 3D cell volumes spanning diverse chemical and genetic
perturbations, FORM supports both unconditional morphology synthesis and
conditional simulation of perturbed cell states. Beyond generation, FORM can
predict downstream signalling activity, simulate combinatorial perturbation
effects, and model morphodynamic transitions between states of unseen
perturbations. To evaluate performance, we introduce MorphoEval, a benchmarking
suite that quantifies perturbation-induced morphological changes in structural,
statistical, and biological dimensions. Together, FORM and MorphoEval work
toward the realisation of the 3D virtual cell by linking morphology,
perturbation, and function through high-resolution predictive simulation.

</details>


### [26] [CT-CLIP: A Multi-modal Fusion Framework for Robust Apple Leaf Disease Recognition in Complex Environments](https://arxiv.org/abs/2510.21346)
*Lemin Liu,Fangchao Hu,Honghua Jiang,Yaru Chen,Limin Liu,Yongliang Qiao*

Main category: cs.CV

TL;DR: CT-CLIP通过结合CNN和视觉变换器，动态融合特征，显著提升了苹果病害的识别准确性，适用于复杂环境条件下的农业应用。


<details>
  <summary>Details</summary>
Motivation: 传统的多尺度特征融合方法无法充分处理复杂果园环境下不同苹果叶病害表型的异质性和局部-全局特征关系。

Method: CT-CLIP框架结合了CNN和视觉变换器，通过自适应特征融合模块动态融合局部与全局信息，提升了病害识别能力。

Result: CT-CLIP在苹果病害识别任务上分别在公开和自建数据集上取得了97.38%和96.12%的识别准确率，超过了多个基线方法。

Conclusion: CT-CLIP在识别苹果病害方面表现出色，明显提高了复杂环境条件下的识别准确性，为农业应用的自动病害识别提供了创新且实用的解决方案。

Abstract: In complex orchard environments, the phenotypic heterogeneity of different
apple leaf diseases, characterized by significant variation among lesions,
poses a challenge to traditional multi-scale feature fusion methods. These
methods only integrate multi-layer features extracted by convolutional neural
networks (CNNs) and fail to adequately account for the relationships between
local and global features. Therefore, this study proposes a multi-branch
recognition framework named CNN-Transformer-CLIP (CT-CLIP). The framework
synergistically employs a CNN to extract local lesion detail features and a
Vision Transformer to capture global structural relationships. An Adaptive
Feature Fusion Module (AFFM) then dynamically fuses these features, achieving
optimal coupling of local and global information and effectively addressing the
diversity in lesion morphology and distribution. Additionally, to mitigate
interference from complex backgrounds and significantly enhance recognition
accuracy under few-shot conditions, this study proposes a multimodal image-text
learning approach. By leveraging pre-trained CLIP weights, it achieves deep
alignment between visual features and disease semantic descriptions.
Experimental results show that CT-CLIP achieves accuracies of 97.38% and 96.12%
on a publicly available apple disease and a self-built dataset, outperforming
several baseline methods. The proposed CT-CLIP demonstrates strong capabilities
in recognizing agricultural diseases, significantly enhances identification
accuracy under complex environmental conditions, provides an innovative and
practical solution for automated disease recognition in agricultural
applications.

</details>


### [27] [Dynamic Semantic-Aware Correlation Modeling for UAV Tracking](https://arxiv.org/abs/2510.21351)
*Xinyu Zhou,Tongxin Pan,Lingyi Hong,Pinxue Guo,Haijing Guo,Zhaoyu Chen,Kaixun Jiang,Wenqiang Zhang*

Main category: cs.CV

TL;DR: 提出了一种新型无人机跟踪框架，强调语义意识和速度平衡，并在多项数据集中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的无人机跟踪方法注重速度，而缺乏对语义意识的探索，限制了精确提取模板的位置信息。

Method: 提出了一种动态语义相关性建模的跟踪框架。核心是动态语义相关性生成器，结合Transformer的相关性图探究语义相关性。

Result: 通过动态语义相关性生成器和剪枝方法，该框架在多个无人机跟踪数据集上取得了竞争性表现。实现了速度与准确性的平衡。

Conclusion: 该方法提高了在典型无人机跟踪挑战下的跟踪准确性和鲁棒性，并实现了灵活部署。

Abstract: UAV tracking can be widely applied in scenarios such as disaster rescue,
environmental monitoring, and logistics transportation. However, existing UAV
tracking methods predominantly emphasize speed and lack exploration in semantic
awareness, which hinders the search region from extracting accurate
localization information from the template. The limitation results in
suboptimal performance under typical UAV tracking challenges such as camera
motion, fast motion, and low resolution, etc. To address this issue, we propose
a dynamic semantic aware correlation modeling tracking framework. The core of
our framework is a Dynamic Semantic Relevance Generator, which, in combination
with the correlation map from the Transformer, explore semantic relevance. The
approach enhances the search region's ability to extract important information
from the template, improving accuracy and robustness under the aforementioned
challenges. Additionally, to enhance the tracking speed, we design a pruning
method for the proposed framework. Therefore, we present multiple model
variants that achieve trade-offs between speed and accuracy, enabling flexible
deployment according to the available computational resources. Experimental
results validate the effectiveness of our method, achieving competitive
performance on multiple UAV tracking datasets. The code is available at
https://github.com/zxyyxzz/DSATrack.

</details>


### [28] [Gaze-VLM:Bridging Gaze and VLMs through Attention Regularization for Egocentric Understanding](https://arxiv.org/abs/2510.21356)
*Anupam Pani,Yanchao Yang*

Main category: cs.CV

TL;DR: 我们提出了一种基于凝视的正则化框架，通过在训练中使用人类凝视来增强视觉语言模型(VLM)的预测能力，显著提高了未来事件预测和当前活动理解的准确性。


<details>
  <summary>Details</summary>
Motivation: 眼睛凝视提供了关于注意力、短期意图和未来动作的有价值线索，是建模自我中心行为的强大信号。

Method: 提出了一种凝视正则化注意机制，使模型的关注点与人类视觉凝视对齐，灵活且模块化，能够在多个VLM架构中推广。

Result: 实验结果表明，与不使用凝视正则化的基线模型相比，该方法在未来事件预测的语义预测分数上提高了最多11分，而在当前活动理解上提高了约7分。

Conclusion: 这项工作为在现实场景中增强视觉语言模型(VLM)的预测能力奠定了基础，例如助理机器人和人机合作。

Abstract: Eye gaze offers valuable cues about attention, short-term intent, and future
actions, making it a powerful signal for modeling egocentric behavior. In this
work, we propose a gaze-regularized framework that enhances VLMs for two key
egocentric understanding tasks: fine-grained future event prediction and
current activity understanding. Unlike prior approaches that rely solely on
visual inputs or use gaze as an auxiliary input signal , our method uses gaze
only during training. We introduce a gaze-regularized attention mechanism that
aligns model focus with human visual gaze. This design is flexible and modular,
allowing it to generalize across multiple VLM architectures that utilize
attention. Experimental results show that our approach improves semantic
prediction scores by up to 11 for future event prediction and around 7 for
current activity understanding, compared to the corresponding baseline models
trained without gaze regularization. These results highlight the value of
gaze-guided training in improving the accuracy and robustness of egocentric
VLMs. Overall, this work establishes a foundation for using human gaze to
enhance the predictive capabilities of VLMs in real-world scenarios like
assistive robots and human-machine collaboration. Code and additional
information is available at: https://github.com/anupampani/Gaze-VLM

</details>


### [29] [Why Registration Quality Matters: Enhancing sCT Synthesis with IMPACT-Based Registration](https://arxiv.org/abs/2510.21358)
*Valentin Boussot,Cédric Hémon,Jean-Claude Nunes,Jean-Louis Dillenseger*

Main category: cs.CV

TL;DR: 本研究通过IMPACT策略提高合成CT的生成质量，但注册偏差可能会影响模型的评估结果。


<details>
  <summary>Details</summary>
Motivation: 提升MRI与CBCT生成sCT的准确性与结构真实感

Method: 联合使用2.5D U-Net++模型与ResNet-34编码器生成合成CT (sCT)

Result: IMPACT基础的注册策略在局部测试集上表现出更高的对齐精度和更低的MAE，但在公共验证集上与Elastix对齐的数据训练模型分数更高，显示出注册偏差问题。

Conclusion: IMPACT方法通过促进解剖一致的对齐来减轻注册偏差，从而支持更强大、更具可泛化性的合成CT模型的开发。

Abstract: We participated in the SynthRAD2025 challenge (Tasks 1 and 2) with a unified
pipeline for synthetic CT (sCT) generation from MRI and CBCT, implemented using
the KonfAI framework. Our model is a 2.5D U-Net++ with a ResNet-34 encoder,
trained jointly across anatomical regions and fine-tuned per region. The loss
function combined pixel-wise L1 loss with IMPACT-Synth, a perceptual loss
derived from SAM and TotalSegmentator to enhance structural fidelity. Training
was performed using AdamW (initial learning rate = 0.001, halved every 25k
steps) on patch-based, normalized, body-masked inputs (320x320 for MRI, 256x256
for CBCT), with random flipping as the only augmentation. No post-processing
was applied. Final predictions leveraged test-time augmentation and five-fold
ensembling. The best model was selected based on validation MAE. Two
registration strategies were evaluated: (i) Elastix with mutual information,
consistent with the challenge pipeline, and (ii) IMPACT, a feature-based
similarity metric leveraging pretrained segmentation networks. On the local
test sets, IMPACT-based registration achieved more accurate and anatomically
consistent alignments than mutual-information-based registration, resulting in
improved sCT synthesis with lower MAE and more realistic anatomical structures.
On the public validation set, however, models trained with Elastix-aligned data
achieved higher scores, reflecting a registration bias favoring alignment
strategies consistent with the evaluation pipeline. This highlights how
registration errors can propagate into supervised learning, influencing both
training and evaluation, and potentially inflating performance metrics at the
expense of anatomical fidelity. By promoting anatomically consistent alignment,
IMPACT helps mitigate this bias and supports the development of more robust and
generalizable sCT synthesis models.

</details>


### [30] [TerraGen: A Unified Multi-Task Layout Generation Framework for Remote Sensing Data Augmentation](https://arxiv.org/abs/2510.21391)
*Datao Tang,Hao Wang,Yudeng Xin,Hui Qiao,Dongsheng Jiang,Yin Li,Zhiheng Yu,Xiangyong Cao*

Main category: cs.CV

TL;DR: TerraGen 是一种新型的遥感图像生成框架，通过结合地理空间布局编码器和多尺度注入方案，改善了生成图像的质量并增强了下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 目前的生成数据增强框架在处理遥感视觉任务时存在局限性，例如每个任务需要独立的生成模型，并且忽视了地理信息和空间约束的建模。

Method: TerraGen 引入了一个地理空间布局编码器，结合了边界框和分割掩膜输入，并使用多尺度注入方案和掩膜加权损失来明确编码空间约束。

Result: TerraGen 提供了一种统一的布局到图像生成框架，能够灵活且可控地合成遥感图像，支持检测、分割和提取等多种高层视觉任务。

Conclusion: 实验结果表明，TerraGen 在多样化任务中实现了最佳的生成图像质量，并能作为通用的数据增强生成器，在全数据和少样本场景下均展现出稳健的跨任务泛化能力。

Abstract: Remote sensing vision tasks require extensive labeled data across multiple,
interconnected domains. However, current generative data augmentation
frameworks are task-isolated, i.e., each vision task requires training an
independent generative model, and ignores the modeling of geographical
information and spatial constraints. To address these issues, we propose
\textbf{TerraGen}, a unified layout-to-image generation framework that enables
flexible, spatially controllable synthesis of remote sensing imagery for
various high-level vision tasks, e.g., detection, segmentation, and extraction.
Specifically, TerraGen introduces a geographic-spatial layout encoder that
unifies bounding box and segmentation mask inputs, combined with a multi-scale
injection scheme and mask-weighted loss to explicitly encode spatial
constraints, from global structures to fine details. Also, we construct the
first large-scale multi-task remote sensing layout generation dataset
containing 45k images and establish a standardized evaluation protocol for this
task. Experimental results show that our TerraGen can achieve the best
generation image quality across diverse tasks. Additionally, TerraGen can be
used as a universal data-augmentation generator, enhancing downstream task
performance significantly and demonstrating robust cross-task generalisation in
both full-data and few-shot scenarios.

</details>


### [31] [Depth-Supervised Fusion Network for Seamless-Free Image Stitching](https://arxiv.org/abs/2510.21396)
*Zhiying Jiang,Ruhao Yan,Zengxi Zhang,Bowei Zhang,Jinyuan Liu*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的无缝图像拼接方法，能够有效处理视差问题并提高拼接质量。


<details>
  <summary>Details</summary>
Motivation: 解决由于物体深度变化导致的视差大引起的拼接图像中的鬼影和错位问题

Method: 深度一致性约束无缝图像拼接方法

Result: 提出的方法在多个现有方法中表现出优越的拼接效果

Conclusion: 通过多阶段机制和优化对接缝设计，显著提高了图像拼接的准确性和效率。

Abstract: Image stitching synthesizes images captured from multiple perspectives into a
single image with a broader field of view. The significant variations in object
depth often lead to large parallax, resulting in ghosting and misalignment in
the stitched results. To address this, we propose a
depth-consistency-constrained seamless-free image stitching method. First, to
tackle the multi-view alignment difficulties caused by parallax, a multi-stage
mechanism combined with global depth regularization constraints is developed to
enhance the alignment accuracy of the same apparent target across different
depth ranges. Second, during the multi-view image fusion process, an optimal
stitching seam is determined through graph-based low-cost computation, and a
soft-seam region is diffused to precisely locate transition areas, thereby
effectively mitigating alignment errors induced by parallax and achieving
natural and seamless stitching results. Furthermore, considering the
computational overhead in the shift regression process, a reparameterization
strategy is incorporated to optimize the structural design, significantly
improving algorithm efficiency while maintaining optimal performance. Extensive
experiments demonstrate the superior performance of the proposed method against
the existing methods. Code is available at https://github.com/DLUT-YRH/DSFN.

</details>


### [32] [MUVR: A Multi-Modal Untrimmed Video Retrieval Benchmark with Multi-Level Visual Correspondence](https://arxiv.org/abs/2510.21406)
*Yue Feng,Jinwei Hu,Qijia Lu,Jiawei Niu,Li Tan,Shuo Yuan,Ziyi Yan,Yizhen Jia,Qingzhi He,Shiping Ge,Ethan Q. Chen,Wentong Li,Limin Wang,Jie Qin*

Main category: cs.CV

TL;DR: 本文提出了多模态未剪辑视频检索任务MUVR，旨在通过多模态查询从长视频中检索相关片段，并构建了一套新的评估标准与基准。


<details>
  <summary>Details</summary>
Motivation: 应对长视频平台的检索需求，通过多模态查询提升未剪辑视频的相关片段检索能力。

Method: 构建多模态未剪辑视频检索任务MUVR，包含多级视觉对应和综合评估标准，对多种视频检索模型进行广泛评估。

Result: 本文提出了多模态未剪辑视频检索任务，并建立了新的基准（MUVR），旨在推进长视频平台的视频检索。MUVR旨在通过多模态查询检索包含相关片段的未剪辑视频，具有以下特点：1）实用的检索范式：MUVR支持视频中心的多模态查询，通过长文本描述、视频标签提示和掩码提示表达细粒度的检索需求。2）多级视觉对应：为了覆盖常见的视频类别（如新闻、旅行、舞蹈），并精确定义检索匹配标准，构建了基于核心视频内容的多级视觉对应。3）全面的评估标准：开发了3个版本的MUVR（即Base、Filter、QA）。MUVR包含来自Bilibili视频平台的53,000个未剪辑视频，配有1,050个多模态查询和84,000个匹配项。

Conclusion: MUVR展示了目前针对未剪辑视频和多模态查询的检索方法及MLLMs在多视频理解和重新排序方面的局限性。

Abstract: We propose the Multi-modal Untrimmed Video Retrieval task, along with a new
benchmark (MUVR) to advance video retrieval for long-video platforms. MUVR aims
to retrieve untrimmed videos containing relevant segments using multi-modal
queries. It has the following features: 1) Practical retrieval paradigm: MUVR
supports video-centric multi-modal queries, expressing fine-grained retrieval
needs through long text descriptions, video tag prompts, and mask prompts. It
adopts a one-to-many retrieval paradigm and focuses on untrimmed videos,
tailored for long-video platform applications. 2) Multi-level visual
correspondence: To cover common video categories (e.g., news, travel, dance)
and precisely define retrieval matching criteria, we construct multi-level
visual correspondence based on core video content (e.g., news events, travel
locations, dance moves) which users are interested in and want to retrieve. It
covers six levels: copy, event, scene, instance, action, and others. 3)
Comprehensive evaluation criteria: We develop 3 versions of MUVR (i.e., Base,
Filter, QA). MUVR-Base/Filter evaluates retrieval models, while MUVR-QA
assesses MLLMs in a question-answering format. We also propose a Reranking
Score to evaluate the reranking ability of MLLMs. MUVR consists of 53K
untrimmed videos from the video platform Bilibili, with 1,050 multi-modal
queries and 84K matches. Extensive evaluations of 3 state-of-the-art video
retrieval models, 6 image-based VLMs, and 10 MLLMs are conducted. MUVR reveals
the limitations of retrieval methods in processing untrimmed videos and
multi-modal queries, as well as MLLMs in multi-video understanding and
reranking. Our code and benchmark is available at
https://github.com/debby-0527/MUVR.

</details>


### [33] [Bridging the gap to real-world language-grounded visual concept learning](https://arxiv.org/abs/2510.21412)
*Whie Jung,Semin Kim,Junee Kim,Seunghoon Hong*

Main category: cs.CV

TL;DR: 本研究提出一种可扩展的框架，以适应真实场景中图像相关概念轴的识别，展示了出色的编辑能力和组合泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的以语言为基础的视觉概念学习方法局限于少数预定义的原始轴，且通常在合成数据集上进行探讨，本研究旨在开发一种可扩展的框架，以适应真实场景中图像相关概念轴的识别。

Method: 利用预训练的视觉-语言模型和通用提示策略，自适应识别图像相关的概念轴，并通过一种组合锚定目标来确保每个轴的独立性。

Result: 该框架在真实场景中识别多样的图像相关轴，并在这些轴上对视觉概念进行基础，显示出优越的编辑能力和强大的组合泛化能力。

Conclusion: 我们的框架在处理来自不同现实世界概念的编辑任务中表现出色，超越了现有的视觉概念学习和基于文本的编辑方法。

Abstract: Human intelligence effortlessly interprets visual scenes along a rich
spectrum of semantic dimensions. However, existing approaches to
language-grounded visual concept learning are limited to a few predefined
primitive axes, such as color and shape, and are typically explored in
synthetic datasets. In this work, we propose a scalable framework that
adaptively identifies image-related concept axes and grounds visual concepts
along these axes in real-world scenes. Leveraging a pretrained vision-language
model and our universal prompting strategy, our framework identifies a diverse
image-related axes without any prior knowledge. Our universal concept encoder
adaptively binds visual features to the discovered axes without introducing
additional model parameters for each concept. To ground visual concepts along
the discovered axes, we optimize a compositional anchoring objective, which
ensures that each axis can be independently manipulated without affecting
others. We demonstrate the effectiveness of our framework on subsets of
ImageNet, CelebA-HQ, and AFHQ, showcasing superior editing capabilities across
diverse real-world concepts that are too varied to be manually predefined. Our
method also exhibits strong compositional generalization, outperforming
existing visual concept learning and text-based editing methods. The code is
available at https://github.com/whieya/Language-grounded-VCL.

</details>


### [34] [ArtiLatent: Realistic Articulated 3D Object Generation via Structured Latents](https://arxiv.org/abs/2510.21432)
*Honghua Chen,Yushi Lan,Yongwei Chen,Xingang Pan*

Main category: cs.CV

TL;DR: ArtiLatent是一个生成框架，通过联合建模几何和关节动态，重建高保真3D对象，显示出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 我们希望合成具有细致几何、精确关节和真实外观的人造3D对象。

Method: 通过变分自编码器将稀疏体素表示及其关节属性嵌入统一潜在空间，并通过潜在扩散模型进行采样，采用关节感知高斯解码器重建逼真的3D形状。

Result: 在PartNet-Mobility和ACD数据集上的大量实验表明，ArtiLatent在几何一致性和外观保真度方面优于现有评估方法。

Conclusion: ArtiLatent在几何一致性和外观保真度方面优于现有方法，为关节3D对象合成及操控提供了可扩展的解决方案。

Abstract: We propose ArtiLatent, a generative framework that synthesizes human-made 3D
objects with fine-grained geometry, accurate articulation, and realistic
appearance. Our approach jointly models part geometry and articulation dynamics
by embedding sparse voxel representations and associated articulation
properties, including joint type, axis, origin, range, and part category, into
a unified latent space via a variational autoencoder. A latent diffusion model
is then trained over this space to enable diverse yet physically plausible
sampling. To reconstruct photorealistic 3D shapes, we introduce an
articulation-aware Gaussian decoder that accounts for articulation-dependent
visibility changes (e.g., revealing the interior of a drawer when opened). By
conditioning appearance decoding on articulation state, our method assigns
plausible texture features to regions that are typically occluded in static
poses, significantly improving visual realism across articulation
configurations. Extensive experiments on furniture-like objects from
PartNet-Mobility and ACD datasets demonstrate that ArtiLatent outperforms
existing approaches in geometric consistency and appearance fidelity. Our
framework provides a scalable solution for articulated 3D object synthesis and
manipulation.

</details>


### [35] [OpenHype: Hyperbolic Embeddings for Hierarchical Open-Vocabulary Radiance Fields](https://arxiv.org/abs/2510.21441)
*Lisa Weijler,Sebastian Koch,Fabio Poiesi,Timo Ropinski,Pedro Hermosilla*

Main category: cs.CV

TL;DR: OpenHype 是一种新的3D场景层次建模方法，利用超曲形潜在空间，克服了现有方法的不足，在效率和适应性上表现出色。


<details>
  <summary>Details</summary>
Motivation: 提升自主智能体对复杂环境的理解能力，克服现有层次建模方法的局限性。

Method: 使用连续的超曲形潜在空间来表示和处理3D场景的层次结构。

Result: 本文提出了一种新的方法OpenHype，用于建模3D物体和场景的层次结构，旨在提升自主智能体的环境理解能力。该方法利用连续的超曲形潜在空间来表示场景层次结构，有效克服了现有方法在推理时间和普适性上的不足。OpenHype利用超几何的性质，实现了多尺度关系的自然编码，并通过测地线路径在潜在空间中实现了层次的平滑遍历。经过标准基准测试，OpenHype在效率和适应性方面优于当前最先进的方法。

Conclusion: OpenHype通过超曲几何特性有效编码多尺度关系，提升了3D场景理解的效率和适应性。

Abstract: Modeling the inherent hierarchical structure of 3D objects and 3D scenes is
highly desirable, as it enables a more holistic understanding of environments
for autonomous agents. Accomplishing this with implicit representations, such
as Neural Radiance Fields, remains an unexplored challenge. Existing methods
that explicitly model hierarchical structures often face significant
limitations: they either require multiple rendering passes to capture
embeddings at different levels of granularity, significantly increasing
inference time, or rely on predefined, closed-set discrete hierarchies that
generalize poorly to the diverse and nuanced structures encountered by agents
in the real world. To address these challenges, we propose OpenHype, a novel
approach that represents scene hierarchies using a continuous hyperbolic latent
space. By leveraging the properties of hyperbolic geometry, OpenHype naturally
encodes multi-scale relationships and enables smooth traversal of hierarchies
through geodesic paths in latent space. Our method outperforms state-of-the-art
approaches on standard benchmarks, demonstrating superior efficiency and
adaptability in 3D scene understanding.

</details>


### [36] [PhysWorld: From Real Videos to World Models of Deformable Objects via Physics-Aware Demonstration Synthesis](https://arxiv.org/abs/2510.21447)
*Yu Yang,Zhilu Zhang,Xiang Zhang,Yihan Zeng,Hui Li,Wangmeng Zuo*

Main category: cs.CV

TL;DR: PhysWorld是一个新的框架，通过生成多样的合成数据来学习物体动态模型，显著提升推断速度，适用于可变形物体的未来预测。


<details>
  <summary>Details</summary>
Motivation: 在有限的真实世界视频数据下，学习具有物理一致性的动态模型是一个重大挑战，尤其是对于具有空间变化物理性质的可变形物体。

Method: 构建物理一致的数字双胞胎，应用部件感知扰动生成多种运动模式，并通过这些演示训练轻量级的基于GNN的世界模型。

Result: PhysWorld能够准确快速地预测各种可变形物体的未来行为，并且在新的交互场景中表现良好，其推断速度比最新的技术PhysTwin快47倍。

Conclusion: PhysWorld是一种新颖的框架，通过合成物理上合理且多样的演示数据，能够高效学习物体动态模型，尤其适用于可变形物体，并显著提高推断速度。

Abstract: Interactive world models that simulate object dynamics are crucial for
robotics, VR, and AR. However, it remains a significant challenge to learn
physics-consistent dynamics models from limited real-world video data,
especially for deformable objects with spatially-varying physical properties.
To overcome the challenge of data scarcity, we propose PhysWorld, a novel
framework that utilizes a simulator to synthesize physically plausible and
diverse demonstrations to learn efficient world models. Specifically, we first
construct a physics-consistent digital twin within MPM simulator via
constitutive model selection and global-to-local optimization of physical
properties. Subsequently, we apply part-aware perturbations to the physical
properties and generate various motion patterns for the digital twin,
synthesizing extensive and diverse demonstrations. Finally, using these
demonstrations, we train a lightweight GNN-based world model that is embedded
with physical properties. The real video can be used to further refine the
physical properties. PhysWorld achieves accurate and fast future predictions
for various deformable objects, and also generalizes well to novel
interactions. Experiments show that PhysWorld has competitive performance while
enabling inference speeds 47 times faster than the recent state-of-the-art
method, i.e., PhysTwin.

</details>


### [37] [VidSplice: Towards Coherent Video Inpainting via Explicit Spaced Frame Guidance](https://arxiv.org/abs/2510.21461)
*Ming Xie,Junqiu Yu,Qiaole Dong,Xiangyang Xue,Yanwei Fu*

Main category: cs.CV

TL;DR: 论文提出了VidSplice框架，改进视频修复性能，增强时空一致性并减少内容失真。


<details>
  <summary>Details</summary>
Motivation: 现有视频修复方法在重建严重损坏内容时存在时空不稳定性，VidSplice旨在改善这一问题，提高视频修复的控制能力和效果。

Method: VidSplice将视频修复分为多帧一致性图像修复和遮罩区域运动传播，通过引入间隔帧先验和CoSpliced模块增强修复质量。

Result: 该论文提出了一种新颖的视频修复框架VidSplice，旨在解决现有修复方法在严重内容损坏及时空稳定性方面的不足。VidSplice将视频修复分解为两个子任务：多帧一致性图像修复和遮罩区域运动传播。通过引入间隔帧先验，VidSplice指导修复过程并提升空间一致性，且通过CoSpliced模块实现初始帧内容向后续参考帧的传播，减小内容失真。该模型在多种视频修复场景下表现出竞争力，同时显著提升了前景对齐及运动稳定性。

Conclusion: VidSplice框架通过改进的视频修复方法在多个评价指标上超越了现有技术，展现出更强的前景对齐和运动稳定性。

Abstract: Recent video inpainting methods often employ image-to-video (I2V) priors to
model temporal consistency across masked frames. While effective in moderate
cases, these methods struggle under severe content degradation and tend to
overlook spatiotemporal stability, resulting in insufficient control over the
latter parts of the video. To address these limitations, we decouple video
inpainting into two sub-tasks: multi-frame consistent image inpainting and
masked area motion propagation. We propose VidSplice, a novel framework that
introduces spaced-frame priors to guide the inpainting process with
spatiotemporal cues. To enhance spatial coherence, we design a CoSpliced Module
to perform first-frame propagation strategy that diffuses the initial frame
content into subsequent reference frames through a splicing mechanism.
Additionally, we introduce a delicate context controller module that encodes
coherent priors after frame duplication and injects the spliced video into the
I2V generative backbone, effectively constraining content distortion during
generation. Extensive evaluations demonstrate that VidSplice achieves
competitive performance across diverse video inpainting scenarios. Moreover,
its design significantly improves both foreground alignment and motion
stability, outperforming existing approaches.

</details>


### [38] [CXR-LanIC: Language-Grounded Interpretable Classifier for Chest X-Ray Diagnosis](https://arxiv.org/abs/2510.21464)
*Yiming Tang,Wenjia Zhong,Rushi Shah,Dianbo Liu*

Main category: cs.CV

TL;DR: CXR-LanIC框架提升了胸部X光诊断的可解释性，提炼出约5000个可理解的视觉模式，支持安全的临床应用。


<details>
  <summary>Details</summary>
Motivation: 解决医疗AI黑箱问题，提升临床医生对自动化诊断结果的信任度和透明度。

Method: 该研究使用基于转码器的稀疏自编码器对医学图像表示进行解构，提炼出可解释的视觉模式。

Result: 模型在五个关键诊断结果上取得了竞争性的准确性，并能够提供基于自然语言的可解释说明。

Conclusion: CXR-LanIC实现了在胸部X光诊断中的精确且可解释的分类，推动了医疗AI系统的安全应用。

Abstract: Deep learning models have achieved remarkable accuracy in chest X-ray
diagnosis, yet their widespread clinical adoption remains limited by the
black-box nature of their predictions. Clinicians require transparent,
verifiable explanations to trust automated diagnoses and identify potential
failure modes. We introduce CXR-LanIC (Language-Grounded Interpretable
Classifier for Chest X-rays), a novel framework that addresses this
interpretability challenge through task-aligned pattern discovery. Our approach
trains transcoder-based sparse autoencoders on a BiomedCLIP diagnostic
classifier to decompose medical image representations into interpretable visual
patterns. By training an ensemble of 100 transcoders on multimodal embeddings
from the MIMIC-CXR dataset, we discover approximately 5,000 monosemantic
patterns spanning cardiac, pulmonary, pleural, structural, device, and artifact
categories. Each pattern exhibits consistent activation behavior across images
sharing specific radiological features, enabling transparent attribution where
predictions decompose into 20-50 interpretable patterns with verifiable
activation galleries. CXR-LanIC achieves competitive diagnostic accuracy on
five key findings while providing the foundation for natural language
explanations through planned large multimodal model annotation. Our key
innovation lies in extracting interpretable features from a classifier trained
on specific diagnostic objectives rather than general-purpose embeddings,
ensuring discovered patterns are directly relevant to clinical decision-making,
demonstrating that medical AI systems can be both accurate and interpretable,
supporting safer clinical deployment through transparent, clinically grounded
explanations.

</details>


### [39] [ITC-RWKV: Interactive Tissue-Cell Modeling with Recurrent Key-Value Aggregation for Histopathological Subtyping](https://arxiv.org/abs/2510.21479)
*Yating Huang,Qijun Yang,Lintao Xiang,Hujun Yin*

Main category: cs.CV

TL;DR: 提出一种双流架构，通过细胞级信息聚合和组织细胞交互模块，提升组织病理图像的亚型分类能力。


<details>
  <summary>Details</summary>
Motivation: 提高组织病理图像解读的准确性，整合不同空间和语义尺度的信息，克服主流模型缺乏细胞级特征建模的不足。

Method: 提出双流架构，并引入重接塑性加权键值聚合模型和双向组织细胞交互模块。

Result: 该方法在四个组织病理亚型分类基准测试中表现优于现有模型。

Conclusion: 细胞级聚合和组织细胞交互在细粒度计算病理学中起关键作用。

Abstract: Accurate interpretation of histopathological images demands integration of
information across spatial and semantic scales, from nuclear morphology and
cellular textures to global tissue organization and disease-specific patterns.
Although recent foundation models in pathology have shown strong capabilities
in capturing global tissue context, their omission of cell-level feature
modeling remains a key limitation for fine-grained tasks such as cancer subtype
classification. To address this, we propose a dual-stream architecture that
models the interplay between macroscale tissue features and aggregated cellular
representations. To efficiently aggregate information from large cell sets, we
propose a receptance-weighted key-value aggregation model, a recurrent
transformer that captures inter-cell dependencies with linear complexity.
Furthermore, we introduce a bidirectional tissue-cell interaction module to
enable mutual attention between localized cellular cues and their surrounding
tissue environment. Experiments on four histopathological subtype
classification benchmarks show that the proposed method outperforms existing
models, demonstrating the critical role of cell-level aggregation and
tissue-cell interaction in fine-grained computational pathology.

</details>


### [40] [GRAP-MOT: Unsupervised Graph-based Position Weighted Person Multi-camera Multi-object Tracking in a Highly Congested Space](https://arxiv.org/abs/2510.21482)
*Marek Socha,Michał Marczyk,Aleksander Kempski,Michał Cogiel,Paweł Foszner,Radosław Zawiski,Michał Staniszewski*

Main category: cs.CV

TL;DR: GRAP-MOT是针对闭合区域视频的人员多目标跟踪新方法，采用图加权方案并集成位置估计，表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 旨在解决闭合空间中多目标跟踪的挑战，特别是人员遮挡和多摄像头视角下的问题。

Method: 采用图加权算法，通过在线更新身份标签和集成位置数据来提高人员跟踪精度。

Result: GRAP-MOT是一种新方法，旨在解决重叠多摄像头视角下闭合区域视频中的人员多目标跟踪（MOT）问题，特别是在人员遮挡频繁发生的情况下。该方法采用图加权解法，在线更新人员识别标签，基于轨迹和人员特征。我们深入研究了MOT过程中的各个要素，包括特征提取、跟踪和社区搜索。同时，GRAP-MOT还配备了人员位置估计模块，提供位置数据，确保相较于不使用位置数据的方法得到更好的结果。本研究在闭合区域模型和公开可用的真实数据集上进行了测试，展示了所提方法的优越性。最后，我们分析了现有的MOT算法比较指标，认为IDF1比MOTA更适合此类比较。我们公开了代码及获得的数据集。

Conclusion: GRAP-MOT在处理人员遮挡和多摄像头跟踪中表现优越，IDF1指标更适合比较MOT算法。

Abstract: GRAP-MOT is a new approach for solving the person MOT problem dedicated to
videos of closed areas with overlapping multi-camera views, where person
occlusion frequently occurs. Our novel graph-weighted solution updates a
person's identification label online based on tracks and the person's
characteristic features. To find the best solution, we deeply investigated all
elements of the MOT process, including feature extraction, tracking, and
community search. Furthermore, GRAP-MOT is equipped with a person's position
estimation module, which gives additional key information to the MOT method,
ensuring better results than methods without position data. We tested GRAP-MOT
on recordings acquired in a closed-area model and on publicly available real
datasets that fulfil the requirement of a highly congested space, showing the
superiority of our proposition. Finally, we analyzed existing metrics used to
compare MOT algorithms and concluded that IDF1 is more adequate than MOTA in
such comparisons. We made our code, along with the acquired dataset, publicly
available.

</details>


### [41] [An Automatic Detection Method for Hematoma Features in Placental Abruption Ultrasound Images Based on Few-Shot Learning](https://arxiv.org/abs/2510.21495)
*Xiaoqing Liu,Jitai Han,Hua Yan,Peng Li,Sida Tang,Ying Li,Kaiwen Zhang,Min Yu*

Main category: cs.CV

TL;DR: EH-YOLOv11n模型提高了胎盘剥离时超声图像血肿的自动检测精度，精度达到78%，具有重要的临床应用价值。


<details>
  <summary>Details</summary>
Motivation: 胎盘剥离是怀孕期间的严重并发症，早期准确的诊断对于保障母婴安全至关重要，传统超声方法存在主观偏差和不一致性，因此需要一种自动化的诊断方法。

Method: 论文基于小样本学习，采用多维优化策略，通过集成波变换卷积和级联组注意机制来提高模型的性能和准确度。

Result: 本文提出了一种改进的模型EH-YOLOv11n（增强型出血-YOLOv11n），旨在自动检测胎盘超声图像中的血肿特征，克服传统超声诊断中医生经验的主观偏差和不一致性问题。通过多维优化，该模型提高了检测性能，实验结果显示检测精度达到78%，并且在多个性能指标上优于传统YOLO模型。

Conclusion: EH-YOLOv11n模型通过集成波变换卷积和级联组注意机制，有效提升了胎盘剥离的超声图像检测准确性，展示了其在临床应用中的潜力。

Abstract: Placental abruption is a severe complication during pregnancy, and its early
accurate diagnosis is crucial for ensuring maternal and fetal safety.
Traditional ultrasound diagnostic methods heavily rely on physician experience,
leading to issues such as subjective bias and diagnostic inconsistencies. This
paper proposes an improved model, EH-YOLOv11n (Enhanced Hemorrhage-YOLOv11n),
based on small-sample learning, aiming to achieve automatic detection of
hematoma features in placental ultrasound images. The model enhances
performance through multidimensional optimization: it integrates wavelet
convolution and coordinate convolution to strengthen frequency and spatial
feature extraction; incorporates a cascaded group attention mechanism to
suppress ultrasound artifacts and occlusion interference, thereby improving
bounding box localization accuracy. Experimental results demonstrate a
detection accuracy of 78%, representing a 2.5% improvement over YOLOv11n and a
13.7% increase over YOLOv8. The model exhibits significant superiority in
precision-recall curves, confidence scores, and occlusion scenarios. Combining
high accuracy with real-time processing, this model provides a reliable
solution for computer-aided diagnosis of placental abruption, holding
significant clinical application value.

</details>


### [42] [GranViT: A Fine-Grained Vision Model With Autoregressive Perception For MLLMs](https://arxiv.org/abs/2510.21501)
*Guanghao Zheng,Bowen Shi,Mingxing Xu,Ruoyu Sun,Peisen Zhao,Zhibo Zhang,Wenrui Dai,Junni Zou,Hongkai Xiong,Xiaopeng Zhang,Qi Tian*

Main category: cs.CV

TL;DR: GranViT是一种新型视觉变换器，通过结合精细特征提取和自回归训练，克服了现有视觉编码器的局限，展现出在多模态任务中的领先性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉编码器在处理精细区域分析时的不足，特别是在数据稀缺和预训练方法缺乏的情况下。

Method: 构建Gran-29M数据集，结合精细特征提取与自回归训练，发展预训练-适配框架，通过自蒸馏机制强化区域推理能力。

Result: 本论文提出了一种名为GranViT的新型视觉变换器，它通过区域级自回归训练，将精细特征提取与大型语言模型（LLMs）的语义对齐结合起来，旨在克服现有视觉编码器在精细感知方面的限制。这项研究首先构建了Gran-29M数据集，包含200万张自然和OCR图像，配有超过1.8亿个高质量区域级注释，以支持大规模的精细预训练。随后，作者发展了一个预训练-适配框架，并引入自蒸馏机制，充分利用Gran-29M中的精细注释，通过边界框到文本的回归，提高视觉编码器的局部化视觉表现，并通过文本到边界框的回归，实现对LLM的视觉特征利用和局部化的改进。实验结果表明，GranViT在精细识别、跨模态视觉问答（VQA）和OCR理解方面超越了现有的视觉编码器，并展现出强大的转移能力。

Conclusion: GranViT通过创新的数据集和方法论，显著提升了视觉编码器在精细识别及多模态任务的表现，展示了出色的迁移学习能力。

Abstract: Vision encoders are indispensable for allowing impressive performance of
Multi-modal Large Language Models (MLLMs) in vision language tasks such as
visual question answering and reasoning. However, existing vision encoders
focus on global image representations but overlook fine-grained regional
analysis. They are limited in fine grained perception due to the scarcity of
fine grained annotated data and the lack of a fine grained pre-training
paradigm. In this paper, we propose GranViT, a novel Vision Transformer that
integrates fine-grained feature extraction with semantic alignment to Large
Language Models (LLMs) via region level autoregressive training. We first
construct Gran-29M, a dataset comprising 2million natural and OCR images paired
with over 180 million high-quality region-level annotations, to enable large
scale fine grained pretraining. Consequently, we develop a
pretraining-adaptation framework along with a self distillation mechanism to
train fine-grained GranViT on Gran-29M. We sufficiently exploit the
fine-grained annotations from Gran-29M to resort to bounding-box-to-caption
regression to enhance localized visual representation of the vision encoder in
the pretraining and caption-to-bounding-box regression to improve vision
feature utilization and localization for LLM in the adaptation. We further
incorporate a self distillation mechanism that imposes explicit localization
constraints on the vision encoder to strengthen its regional reasoning
capability. Extensive experiments show that GranViT surpasses existing vision
encoders and attains strong transferability to varying LLMs. Remarkably, it
achieves state-of-the-art results on fine-grained recognition, multimodal VQA,
and OCR understanding.

</details>


### [43] [Towards a Golden Classifier-Free Guidance Path via Foresight Fixed Point Iterations](https://arxiv.org/abs/2510.21512)
*Kaibo Wang,Jianda Mao,Tong Wu,Yang Xiang*

Main category: cs.CV

TL;DR: 本文提出了一种统一的条件指导视角，通过引入前瞻性指导（FSG），实现了在图像质量和计算效率上的显著改进。


<details>
  <summary>Details</summary>
Motivation: 为了理解和推进文本到图像扩散模型中无分类器指导的操作机制，解决现有设计空间和关键设计选择的不明确性。

Method: 提出了一种统一视角，将条件指导重新框架为固定点迭代，并引入前瞻性指导（FSG）作为改进方案。

Result: FSG在图像质量和计算效率上超越了最先进的方法，并在各种数据集和模型架构中得到了广泛的实验验证。

Conclusion: 我们的工作为条件指导提供了新视角，并开启了自适应设计的潜力。

Abstract: Classifier-Free Guidance (CFG) is an essential component of text-to-image
diffusion models, and understanding and advancing its operational mechanisms
remains a central focus of research. Existing approaches stem from divergent
theoretical interpretations, thereby limiting the design space and obscuring
key design choices. To address this, we propose a unified perspective that
reframes conditional guidance as fixed point iterations, seeking to identify a
golden path where latents produce consistent outputs under both conditional and
unconditional generation. We demonstrate that CFG and its variants constitute a
special case of single-step short-interval iteration, which is theoretically
proven to exhibit inefficiency. To this end, we introduce Foresight Guidance
(FSG), which prioritizes solving longer-interval subproblems in early diffusion
stages with increased iterations. Extensive experiments across diverse datasets
and model architectures validate the superiority of FSG over state-of-the-art
methods in both image quality and computational efficiency. Our work offers
novel perspectives for conditional guidance and unlocks the potential of
adaptive design.

</details>


### [44] [Head Pursuit: Probing Attention Specialization in Multimodal Transformers](https://arxiv.org/abs/2510.21518)
*Lorenzo Basile,Valentino Maiorca,Diego Doimo,Francesco Locatello,Alberto Cazzaniga*

Main category: cs.CV

TL;DR: 通过分析注意力头的专业化，提出了一种可解释和可控的结构，用于理解和编辑大型生成模型


<details>
  <summary>Details</summary>
Motivation: 语言和视觉语言模型在多种任务中表现出色，但其内部机制尚未完全理解，因此需要深入分析注意力头的专业化特点

Method: 研究文本生成模型中各个注意力头在特定语义或视觉属性上如何专业化的方式

Result: 发现注意力头在单模态和多模态变换器中都表现出一致的专业化模式，且通过选择少量的头部即可有效抑制或增强模型输出中的目标概念

Conclusion: 研究表明注意力层中存在可解释和可控的结构，为大型生成模型的理解和编辑提供了简单工具。

Abstract: Language and vision-language models have shown impressive performance across
a wide range of tasks, but their internal mechanisms remain only partly
understood. In this work, we study how individual attention heads in
text-generative models specialize in specific semantic or visual attributes.
Building on an established interpretability method, we reinterpret the practice
of probing intermediate activations with the final decoding layer through the
lens of signal processing. This lets us analyze multiple samples in a
principled way and rank attention heads based on their relevance to target
concepts. Our results show consistent patterns of specialization at the head
level across both unimodal and multimodal transformers. Remarkably, we find
that editing as few as 1% of the heads, selected using our method, can reliably
suppress or enhance targeted concepts in the model output. We validate our
approach on language tasks such as question answering and toxicity mitigation,
as well as vision-language tasks including image classification and captioning.
Our findings highlight an interpretable and controllable structure within
attention layers, offering simple tools for understanding and editing
large-scale generative models.

</details>


### [45] [Foley Control: Aligning a Frozen Latent Text-to-Audio Model to Video](https://arxiv.org/abs/2510.21581)
*Ciara Rowles,Varun Jampani,Simon Donné,Shimon Vainer,Julian Parker,Zach Evans*

Main category: cs.CV

TL;DR: Foley Control是一种有效的轻量级视频到音频同步方法，保持了高效的语义对齐和较少的训练参数。


<details>
  <summary>Details</summary>
Motivation: 提出一种轻量级的视频引导Foley方法，以在不重新训练音频先验的情况下，实现视频和音频的同步。

Method: 通过冻结单模态模型，只学习小规模的跨注意力桥接来连接视频和音频，保持了强大的模型能力并简化了训练过程。

Result: 在经过精心设计的视频-音频基准测试中，Foley Control实现了竞争性的时间和语义对齐，并且训练参数数量显著少于近期的多模态系统。

Conclusion: Foley Control方法在视频到音频的同步与语义对齐任务中表现优越，且在训练参数上具有显著优势。

Abstract: Foley Control is a lightweight approach to video-guided Foley that keeps
pretrained single-modality models frozen and learns only a small
cross-attention bridge between them. We connect V-JEPA2 video embeddings to a
frozen Stable Audio Open DiT text-to-audio (T2A) model by inserting compact
video cross-attention after the model's existing text cross-attention, so
prompts set global semantics while video refines timing and local dynamics. The
frozen backbones retain strong marginals (video; audio given text) and the
bridge learns the audio-video dependency needed for synchronization -- without
retraining the audio prior. To cut memory and stabilize training, we pool video
tokens before conditioning. On curated video-audio benchmarks, Foley Control
delivers competitive temporal and semantic alignment with far fewer trainable
parameters than recent multi-modal systems, while preserving prompt-driven
controllability and production-friendly modularity (swap/upgrade encoders or
the T2A backbone without end-to-end retraining). Although we focus on
Video-to-Foley, the same bridge design can potentially extend to other audio
modalities (e.g., speech).

</details>


### [46] [Sample By Step, Optimize By Chunk: Chunk-Level GRPO For Text-to-Image Generation](https://arxiv.org/abs/2510.21583)
*Yifu Luo,Penghui Du,Bo Li,Sinan Du,Tiantian Zhang,Yongzhe Chang,Kai Wu,Kun Gai,Xueqian Wang*

Main category: cs.CV

TL;DR: Chunk-GRPO是一种新的文本到图像生成方法，通过块级别优化解决了GRPO的主要问题，表现优秀。


<details>
  <summary>Details</summary>
Motivation: 解决GRPO在生成过程中面临的优势归因不准确和忽视时间动态的问题。

Method: 提出Chunk-GRPO，一种基于块级别的GRPO方法用于文本到图像生成。

Result: Chunk-GRPO在偏好对齐和图像质量方面取得了优越的结果，验证了块级优化的潜力。

Conclusion: 块级优化为基于GRPO的方法开辟了新的可能性。

Abstract: Group Relative Policy Optimization (GRPO) has shown strong potential for
flow-matching-based text-to-image (T2I) generation, but it faces two key
limitations: inaccurate advantage attribution, and the neglect of temporal
dynamics of generation. In this work, we argue that shifting the optimization
paradigm from the step level to the chunk level can effectively alleviate these
issues. Building on this idea, we propose Chunk-GRPO, the first chunk-level
GRPO-based approach for T2I generation. The insight is to group consecutive
steps into coherent 'chunk's that capture the intrinsic temporal dynamics of
flow matching, and to optimize policies at the chunk level. In addition, we
introduce an optional weighted sampling strategy to further enhance
performance. Extensive experiments show that ChunkGRPO achieves superior
results in both preference alignment and image quality, highlighting the
promise of chunk-level optimization for GRPO-based methods.

</details>


### [47] [MATrack: Efficient Multiscale Adaptive Tracker for Real-Time Nighttime UAV Operations](https://arxiv.org/abs/2510.21586)
*Xuzhao Li,Xuchen Li,Shiyu Hu*

Main category: cs.CV

TL;DR: 本文提出了一种名为MATrack的多尺度自适应系统，以解决夜间无人机跟踪中的低光照和动态物体信息利用不足的问题，显著提高了跟踪性能并保持实时处理速度。


<details>
  <summary>Details</summary>
Motivation: 研究的动力在于改善现有无人机在低光照条件下跟踪的不足，尤其是跟踪漂移、失效，以及在复杂背景下识别动态物体信息的困难。

Method: MATrack通过多尺度层次融合、适应性关键标记门和夜间模板校准器三个核心模块协同工作，解决夜间跟踪的主要技术挑战。

Result: MATrack在UAVDark135基准测试中，其精度、标准化精度和AUC分别比最先进的方法提高了5.9%、5.4%和4.2%，并且处理速度达到81 FPS。

Conclusion: MATrack在夜间无人机跟踪方面表现出色，能有效支持关键机器人应用，如夜间搜索与救援，以及边境巡逻。

Abstract: Nighttime UAV tracking faces significant challenges in real-world robotics
operations. Low-light conditions not only limit visual perception capabilities,
but cluttered backgrounds and frequent viewpoint changes also cause existing
trackers to drift or fail during deployment. To address these difficulties,
researchers have proposed solutions based on low-light enhancement and domain
adaptation. However, these methods still have notable shortcomings in actual
UAV systems: low-light enhancement often introduces visual artifacts, domain
adaptation methods are computationally expensive and existing lightweight
designs struggle to fully leverage dynamic object information. Based on an
in-depth analysis of these key issues, we propose MATrack-a multiscale adaptive
system designed specifically for nighttime UAV tracking. MATrack tackles the
main technical challenges of nighttime tracking through the collaborative work
of three core modules: Multiscale Hierarchy Blende (MHB) enhances feature
consistency between static and dynamic templates. Adaptive Key Token Gate
accurately identifies object information within complex backgrounds. Nighttime
Template Calibrator (NTC) ensures stable tracking performance over long
sequences. Extensive experiments show that MATrack achieves a significant
performance improvement. On the UAVDark135 benchmark, its precision, normalized
precision and AUC surpass state-of-the-art (SOTA) methods by 5.9%, 5.4% and
4.2% respectively, while maintaining a real-time processing speed of 81 FPS.
Further tests on a real-world UAV platform validate the system's reliability,
demonstrating that MATrack can provide stable and effective nighttime UAV
tracking support for critical robotics applications such as nighttime search
and rescue and border patrol.

</details>


### [48] [Restore Text First, Enhance Image Later: Two-Stage Scene Text Image Super-Resolution with Glyph Structure Guidance](https://arxiv.org/abs/2510.21590)
*Minxing Luo,Linlong Fan,Wang Qiushi,Ge Wu,Yiyan Luo,Yuhang Yu,Jinwei Chen,Yaxing Wang,Qingnan Fan,Jian Yang*

Main category: cs.CV

TL;DR: 提出了一种新颖的两阶段框架TIGER，旨在解决生成超分辨率方法在自然图像中失真文本的问题，通过先恢复精确的文本结构再进行全图超分辨率，实现图像质量和文本可读性之间的平衡。


<details>
  <summary>Details</summary>
Motivation: 当前生成的超分辨率方法在自然图像上表现良好，但在文本方面存在失真，导致图像质量和文本可读性之间的根本矛盾。

Method: TIGER采用"先文本后图像"的策略，明确地将字形恢复与图像增强解耦，确保高保真度和视觉一致性。

Result: 通过广泛的实验，TIGER展现了在超分辨率任务上卓越的性能，尤其是在可读性和图像质量方面的改进。

Conclusion: TIGER框架在提升可读性的同时，保持了整体图像质量，展现了最先进的性能。

Abstract: Current generative super-resolution methods show strong performance on
natural images but distort text, creating a fundamental trade-off between image
quality and textual readability. To address this, we introduce \textbf{TIGER}
(\textbf{T}ext-\textbf{I}mage \textbf{G}uided
sup\textbf{E}r-\textbf{R}esolution), a novel two-stage framework that breaks
this trade-off through a \textit{"text-first, image-later"} paradigm.
\textbf{TIGER} explicitly decouples glyph restoration from image enhancement:
it first reconstructs precise text structures and then uses them to guide
subsequent full-image super-resolution. This glyph-to-image guidance ensures
both high fidelity and visual consistency. To support comprehensive training
and evaluation, we also contribute the \textbf{UltraZoom-ST} (UltraZoom-Scene
Text), the first scene text dataset with extreme zoom (\textbf{$\times$14.29}).
Extensive experiments show that \textbf{TIGER} achieves
\textbf{state-of-the-art} performance, enhancing readability while preserving
overall image quality.

</details>


### [49] [S3OD: Towards Generalizable Salient Object Detection with Synthetic Data](https://arxiv.org/abs/2510.21605)
*Orest Kupyn,Hirokatsu Kataoka,Christian Rupprecht*

Main category: cs.CV

TL;DR: 本研究提出了一种利用合成数据和模糊感知架构的显著物体检测方法，显著提高了模型的泛化能力和在基准测试中的表现。


<details>
  <summary>Details</summary>
Motivation: 显著物体检测任务通常需要高成本的像素级标注，造成模型在相关子任务（如DIS和HR-SOD）中训练分离。

Method: 通过合成数据生成和模糊感知架构来改善模型训练，并构建了一个包含超过139,000幅高分辨率图像的数据集。

Result: 仅使用合成数据训练的模型在跨数据集泛化中实现了20-50%的错误减少，微调后的模型在DIS和HR-SOD基准测试中达到最先进的性能。

Conclusion: 提出的S3OD数据集和多掩膜解码器显著提升了显著物体检测的泛化能力，促进了模型在相应基准测试中的表现。

Abstract: Salient object detection exemplifies data-bounded tasks where expensive
pixel-precise annotations force separate model training for related subtasks
like DIS and HR-SOD. We present a method that dramatically improves
generalization through large-scale synthetic data generation and
ambiguity-aware architecture. We introduce S3OD, a dataset of over 139,000
high-resolution images created through our multi-modal diffusion pipeline that
extracts labels from diffusion and DINO-v3 features. The iterative generation
framework prioritizes challenging categories based on model performance. We
propose a streamlined multi-mask decoder that naturally handles the inherent
ambiguity in salient object detection by predicting multiple valid
interpretations. Models trained solely on synthetic data achieve 20-50% error
reduction in cross-dataset generalization, while fine-tuned versions reach
state-of-the-art performance across DIS and HR-SOD benchmarks.

</details>


### [50] [Modest-Align: Data-Efficient Alignment for Vision-Language Models](https://arxiv.org/abs/2510.21606)
*Jiaxiang Liu,Yuan Wang,Jiawei Du,Joey Tianyi Zhou,Mingkun Xu,Zuozhu Liu*

Main category: cs.CV

TL;DR: 研究提出了一种新的轻量级跨模态对齐方法Modest-Align，旨在提升低资源环境中的性能，减少过度自信现象。


<details>
  <summary>Details</summary>
Motivation: 针对在资源受限环境中，现有模型因过度自信而遭遇的性能退化问题，该研究旨在提出一种有效且可扩展的解决方案。

Method: 该方法结合了随机扰动和嵌入平滑策略，前者模拟了不确定性，后者校准了嵌入空间中的相似性分布，从而减少了过度自信。

Result: 本研究提出了Modest-Align，一个轻量级的跨模态对齐框架，旨在解决资源受限环境下现有模型的过度自信和性能下降问题。通过引入随机扰动和嵌入平滑策略，该方法有效降低了不确定样本的过度自信，提升了在噪声和弱对齐样本上的表现。实验结果显示，在检索任务中，Modest-Align在使用超过100倍更少的训练数据和600倍更少的GPU时间的情况下，优于当前最先进的技术。

Conclusion: Modest-Align通过引入随机扰动和嵌入平滑方法，有效提高了跨模态对齐的准确性和效率，特别是在低数据和高噪声的情况下。

Abstract: Cross-modal alignment aims to map heterogeneous modalities into a shared
latent space, as exemplified by models like CLIP, which benefit from
large-scale image-text pretraining for strong recognition capabilities.
However, when operating in resource-constrained settings with limited or
low-quality data, these models often suffer from overconfidence and degraded
performance due to the prevalence of ambiguous or weakly correlated image-text
pairs. Current contrastive learning approaches, which rely on single positive
pairs, further exacerbate this issue by reinforcing overconfidence on uncertain
samples. To address these challenges, we propose Modest-Align, a lightweight
alignment framework designed for robustness and efficiency. Our approach
leverages two complementary strategies -- Random Perturbation, which introduces
controlled noise to simulate uncertainty, and Embedding Smoothing, which
calibrates similarity distributions in the embedding space. These mechanisms
collectively reduce overconfidence and improve performance on noisy or weakly
aligned samples. Extensive experiments across multiple benchmark datasets
demonstrate that Modest-Align outperforms state-of-the-art methods in retrieval
tasks, achieving competitive results with over 100x less training data and 600x
less GPU time than CLIP. Our method offers a practical and scalable solution
for cross-modal alignment in real-world, low-resource scenarios.

</details>


### [51] [Epipolar Geometry Improves Video Generation Models](https://arxiv.org/abs/2510.21615)
*Orest Kupyn,Fabian Manhardt,Federico Tombari,Christian Rupprecht*

Main category: cs.CV

TL;DR: 本研究探讨了通过极几何约束提升视频扩散模型性能，展示了在生成空间一致性视频的同时维持视觉质量的有效方法。


<details>
  <summary>Details</summary>
Motivation: 研究3D一致性视频生成对下游应用的显著影响，并探索如何使用极几何约束来改善现代视频扩散模型。

Method: 利用配对极几何约束通过基于偏好的优化来对扩散模型进行对齐，以解决不稳定的相机轨迹和几何伪影。

Result: 通过评估表明，经典几何约束提供了比现代学习度量更稳定的优化信号，确保了高质量的生成结果，同时模型能够有效地推广到多样化的动态内容。

Conclusion: 通过将数据驱动的深度学习与经典几何计算机视觉相结合，我们提出了一种实用的生成空间一致性视频的方法。

Abstract: Video generation models have progressed tremendously through large latent
diffusion transformers trained with rectified flow techniques. Yet these models
still struggle with geometric inconsistencies, unstable motion, and visual
artifacts that break the illusion of realistic 3D scenes. 3D-consistent video
generation could significantly impact numerous downstream applications in
generation and reconstruction tasks. We explore how epipolar geometry
constraints improve modern video diffusion models. Despite massive training
data, these models fail to capture fundamental geometric principles underlying
visual content. We align diffusion models using pairwise epipolar geometry
constraints via preference-based optimization, directly addressing unstable
camera trajectories and geometric artifacts through mathematically principled
geometric enforcement. Our approach efficiently enforces geometric principles
without requiring end-to-end differentiability. Evaluation demonstrates that
classical geometric constraints provide more stable optimization signals than
modern learned metrics, which produce noisy targets that compromise alignment
quality. Training on static scenes with dynamic cameras ensures high-quality
measurements while the model generalizes effectively to diverse dynamic
content. By bridging data-driven deep learning with classical geometric
computer vision, we present a practical method for generating spatially
consistent videos without compromising visual quality.

</details>


### [52] [DAP-MAE: Domain-Adaptive Point Cloud Masked Autoencoder for Effective Cross-Domain Learning](https://arxiv.org/abs/2510.21635)
*Ziqi Gao,Qiufu Li,Linlin Shen*

Main category: cs.CV

TL;DR: 本文提出DAP-MAE，通过异构领域适配器改进点云数据的预训练，有效解决数据稀缺问题，提升下游任务表现。


<details>
  <summary>Details</summary>
Motivation: 解决点云数据训练中的数据稀缺问题，并提高混合领域知识对下游任务的适应性。

Method: 设计异构领域适配器，采用适应模式与融合模式，对点云特征进行预训练和微调。

Result: 该论文提出了一种名为域自适应点云掩码自编码器（DAP-MAE）的方法，以解决点云数据训练中的数据稀缺问题。与2D数据相比，点云数据在不同领域的可用训练数据规模有限。传统的混合领域预训练可能无法有效对接下游任务，导致性能下降。为此，DAP-MAE通过设计异构领域适配器，灵活地整合跨领域数据的知识，以改进点云分析。该方法在预训练和微调阶段分别采用适应模式与融合模式，有效提升了点云特征的学习能力。最终，DAP-MAE在四个点云分析任务上展示了出色的性能，包括在ScanObjectNN上达到95.18%的对象分类精度和在Bosphorus上达到88.45%的面部表情识别准确率。

Conclusion: DAP-MAE有效提升了多项点云分析任务的性能，证明了其在处理跨领域数据上的有效性。

Abstract: Compared to 2D data, the scale of point cloud data in different domains
available for training, is quite limited. Researchers have been trying to
combine these data of different domains for masked autoencoder (MAE)
pre-training to leverage such a data scarcity issue. However, the prior
knowledge learned from mixed domains may not align well with the downstream 3D
point cloud analysis tasks, leading to degraded performance. To address such an
issue, we propose the Domain-Adaptive Point Cloud Masked Autoencoder (DAP-MAE),
an MAE pre-training method, to adaptively integrate the knowledge of
cross-domain datasets for general point cloud analysis. In DAP-MAE, we design a
heterogeneous domain adapter that utilizes an adaptation mode during
pre-training, enabling the model to comprehensively learn information from
point clouds across different domains, while employing a fusion mode in the
fine-tuning to enhance point cloud features. Meanwhile, DAP-MAE incorporates a
domain feature generator to guide the adaptation of point cloud features to
various downstream tasks. With only one pre-training, DAP-MAE achieves
excellent performance across four different point cloud analysis tasks,
reaching 95.18% in object classification on ScanObjectNN and 88.45% in facial
expression recognition on Bosphorus.

</details>


### [53] [A Dynamic Knowledge Distillation Method Based on the Gompertz Curve](https://arxiv.org/abs/2510.21649)
*Han Yang,Guangjun Qin*

Main category: cs.CV

TL;DR: 提出了一种结合Gompertz增长模型的动态知识蒸馏框架Gompertz-CNN，通过动态调整蒸馏损失权重来改善知识转移。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法未能有效捕捉学生模型认知能力的变化，导致知识转移不佳。

Method: 引入Gompertz曲线动态调整蒸馏损失的权重，结合Wasserstein距离测量特征差异，并进行梯度匹配。

Result: Gompertz-CNN框架在CIFAR-10和CIFAR-100数据集上表现优于传统方法，分别提高了8%和4%的准确率。

Conclusion: Gompertz-CNN在多个实验中优于传统的知识蒸馏方法，表明其有效性。

Abstract: This paper introduces a novel dynamic knowledge distillation framework,
Gompertz-CNN, which integrates the Gompertz growth model into the training
process to address the limitations of traditional knowledge distillation.
Conventional methods often fail to capture the evolving cognitive capacity of
student models, leading to suboptimal knowledge transfer. To overcome this, we
propose a stage-aware distillation strategy that dynamically adjusts the weight
of distillation loss based on the Gompertz curve, reflecting the student's
learning progression: slow initial growth, rapid mid-phase improvement, and
late-stage saturation. Our framework incorporates Wasserstein distance to
measure feature-level discrepancies and gradient matching to align backward
propagation behaviors between teacher and student models. These components are
unified under a multi-loss objective, where the Gompertz curve modulates the
influence of distillation losses over time. Extensive experiments on CIFAR-10
and CIFAR-100 using various teacher-student architectures (e.g., ResNet50 and
MobileNet_v2) demonstrate that Gompertz-CNN consistently outperforms
traditional distillation methods, achieving up to 8% and 4% accuracy gains on
CIFAR-10 and CIFAR-100, respectively.

</details>


### [54] [Self-Supervised Learning of Synapse Types from EM Images](https://arxiv.org/abs/2510.21663)
*Aarav Shetty,Gary B Huang*

Main category: cs.CV

TL;DR: 本研究提出了一种基于电子显微镜图像对突触进行无监督分类的方法，旨在为生物学中的突触功能研究提供新的视角和工具。


<details>
  <summary>Details</summary>
Motivation: 通过突触分类深入理解生物学中的神经传递机制，以及不同突触在功能和可调性上的差异。

Method: 基于同一神经元中相邻突触之间相似性进行突触分类，而不是依赖于预先定义的示例数据。

Result: 在果蝇的数据集中成功地应用了该方法，证明了其有效性和节省标注成本的潜力。

Conclusion: 该方法能够在未知突触类型数量的情况下有效进行分类，并有助于选择涵盖突触结构范围的真实标注。

Abstract: Separating synapses into different classes based on their appearance in EM
images has many applications in biology. Examples may include assigning a
neurotransmitter to a particular class, or separating synapses whose strength
can be modulated from those whose strength is fixed. Traditionally, this has
been done in a supervised manner, giving the classification algorithm examples
of the different classes. Here we instead separate synapses into classes based
only on the observation that nearby synapses in the same neuron are likely more
similar than synapses chosen randomly from different cells. We apply our
methodology to data from {\it Drosophila}. Our approach has the advantage that
the number of synapse types does not need to be known in advance. It may also
provide a principled way to select ground-truth that spans the range of synapse
structure.

</details>


### [55] [Foundation Models in Dermatopathology: Skin Tissue Classification](https://arxiv.org/abs/2510.21664)
*Riya Gupta,Yiwei Zong,Dennis H. Murphree*

Main category: cs.CV

TL;DR: 本研究评估了基础模型在皮肤病全滑模图像分类中的应用，发现Virchow2在特征提取上表现更好，并探讨了数据增强和图像归一化对模型的影响。


<details>
  <summary>Details</summary>
Motivation: 由于皮肤病理学中全滑模图像的快速生成，迫切需要高效处理和准确分类的自动化方法。

Method: 评估两个基础模型（UNI和Virchow2）作为特征提取器，用于将全滑模图像（WSIs）分类为三种诊断类型。

Result: Virchow2提取的补丁级特征在大多数滑模级分类器中的性能优于UNI，逻辑回归在Virchow2上达到最高准确率（90%）。

Conclusion: 研究展示了基础模型在自动化WSI分类中的潜力，为皮肤病理学诊断提供了一种可扩展和有效的方法，并为滑模级表示学习的未来进展铺平了道路。

Abstract: The rapid generation of whole-slide images (WSIs) in dermatopathology
necessitates automated methods for efficient processing and accurate
classification. This study evaluates the performance of two foundation models,
UNI and Virchow2, as feature extractors for classifying WSIs into three
diagnostic categories: melanocytic, basaloid, and squamous lesions. Patch-level
embeddings were aggregated into slide-level features using a mean-aggregation
strategy and subsequently used to train multiple machine learning classifiers,
including logistic regression, gradient-boosted trees, and random forest
models. Performance was assessed using precision, recall, true positive rate,
false positive rate, and the area under the receiver operating characteristic
curve (AUROC) on the test set. Results demonstrate that patch-level features
extracted using Virchow2 outperformed those extracted via UNI across most
slide-level classifiers, with logistic regression achieving the highest
accuracy (90%) for Virchow2, though the difference was not statistically
significant. The study also explored data augmentation techniques and image
normalization to enhance model robustness and generalizability. The
mean-aggregation approach provided reliable slide-level feature
representations. All experimental results and metrics were tracked and
visualized using WandB.ai, facilitating reproducibility and interpretability.
This research highlights the potential of foundation models for automated WSI
classification, providing a scalable and effective approach for
dermatopathological diagnosis while paving the way for future advancements in
slide-level representation learning.

</details>


### [56] [WorldGrow: Generating Infinite 3D World](https://arxiv.org/abs/2510.21682)
*Sikuang Li,Chen Yang,Jiemin Fang,Taoran Yi,Jia Lu,Jiazhong Cen,Lingxi Xie,Wei Shen,Qi Tian*

Main category: cs.CV

TL;DR: 本研究提出WorldGrow，一个层次化框架，用于无界3D场景合成，能生成大规模虚拟环境。


<details>
  <summary>Details</summary>
Motivation: 解决生成可无限扩展的3D世界的挑战，创建大型连贯的环境，具有一致的几何形状和真实的外观。

Method: 提出了一种包含数据筛选管道、3D块修补机制和由粗到细的生成策略的层次框架。

Result: WorldGrow在几何重建方面达到了现有最佳性能，同时支持产生具有真实感和结构一致性的无限场景。

Conclusion: WorldGrow展示了构建大规模虚拟环境的能力，并可能推动未来世界模型的发展。

Abstract: We tackle the challenge of generating the infinitely extendable 3D world --
large, continuous environments with coherent geometry and realistic appearance.
Existing methods face key challenges: 2D-lifting approaches suffer from
geometric and appearance inconsistencies across views, 3D implicit
representations are hard to scale up, and current 3D foundation models are
mostly object-centric, limiting their applicability to scene-level generation.
Our key insight is leveraging strong generation priors from pre-trained 3D
models for structured scene block generation. To this end, we propose
WorldGrow, a hierarchical framework for unbounded 3D scene synthesis. Our
method features three core components: (1) a data curation pipeline that
extracts high-quality scene blocks for training, making the 3D structured
latent representations suitable for scene generation; (2) a 3D block inpainting
mechanism that enables context-aware scene extension; and (3) a coarse-to-fine
generation strategy that ensures both global layout plausibility and local
geometric/textural fidelity. Evaluated on the large-scale 3D-FRONT dataset,
WorldGrow achieves SOTA performance in geometry reconstruction, while uniquely
supporting infinite scene generation with photorealistic and structurally
consistent outputs. These results highlight its capability for constructing
large-scale virtual environments and potential for building future world
models.

</details>


### [57] [BachVid: Training-Free Video Generation with Consistent Background and Character](https://arxiv.org/abs/2510.21696)
*Han Yan,Xibin Song,Yifu Wang,Hongdong Li,Pan Ji,Chao Ma*

Main category: cs.CV

TL;DR: BachVid是一种无需训练的方法，用于生成一致角色和背景的多视频内容，基于DiT的特点来实现。


<details>
  <summary>Details</summary>
Motivation: 解决多个视频生成中的角色和背景一致性问题，克服现有方法的限制，提供一种无需参考图像的有效方案。

Method: 通过生成身份视频并缓存中间变量，之后将这些缓存变量注入新生成视频的对应位置，确保多视频之间的前景和背景一致性。

Result: BachVid是一种新颖的训练-free方法，能够实现多个视频生成中的角色和背景一致性，而不需要参考图像或额外的训练。它基于对扩散变换器(DiT)注意机制和中间特征的系统分析，表明DiT在去噪过程中能够提取前景掩码和识别匹配点，进而确保生成视频中的前景和背景一致性。

Conclusion: BachVid提供了一种新颖而高效的解决方案，实现了一致的视频生成，而不依赖参考图像或额外训练。

Abstract: Diffusion Transformers (DiTs) have recently driven significant progress in
text-to-video (T2V) generation. However, generating multiple videos with
consistent characters and backgrounds remains a significant challenge. Existing
methods typically rely on reference images or extensive training, and often
only address character consistency, leaving background consistency to
image-to-video models. We introduce BachVid, the first training-free method
that achieves consistent video generation without needing any reference images.
Our approach is based on a systematic analysis of DiT's attention mechanism and
intermediate features, revealing its ability to extract foreground masks and
identify matching points during the denoising process. Our method leverages
this finding by first generating an identity video and caching the intermediate
variables, and then inject these cached variables into corresponding positions
in newly generated videos, ensuring both foreground and background consistency
across multiple videos. Experimental results demonstrate that BachVid achieves
robust consistency in generated videos without requiring additional training,
offering a novel and efficient solution for consistent video generation without
relying on reference images or additional training.

</details>


### [58] [Visual Diffusion Models are Geometric Solvers](https://arxiv.org/abs/2510.21697)
*Nir Goren,Shai Yehezkel,Omer Dahary,Andrey Voynov,Or Patashnik,Daniel Cohen-Or*

Main category: cs.CV

TL;DR: 本文展示了视觉扩散模型在几何问题求解中的有效性，提供了一种通过图像生成来处理困难几何任务的新方法。


<details>
  <summary>Details</summary>
Motivation: 探讨将几何推理转换为图像生成的可能性，并提供一种简单方法来处理复杂的几何问题。

Method: 将每个问题实例视为图像，训练标准视觉扩散模型，将高斯噪声转化为表示有效近似解的图像。

Result: 成功应用于长久以来的几何问题如内接正方形问题、斯坦纳树问题和简单多边形问题。

Conclusion: 视觉扩散模型可以作为有效的几何求解器，通过在像素空间直接推理几何问题。

Abstract: In this paper we show that visual diffusion models can serve as effective
geometric solvers: they can directly reason about geometric problems by working
in pixel space. We first demonstrate this on the Inscribed Square Problem, a
long-standing problem in geometry that asks whether every Jordan curve contains
four points forming a square. We then extend the approach to two other
well-known hard geometric problems: the Steiner Tree Problem and the Simple
Polygon Problem.
  Our method treats each problem instance as an image and trains a standard
visual diffusion model that transforms Gaussian noise into an image
representing a valid approximate solution that closely matches the exact one.
The model learns to transform noisy geometric structures into correct
configurations, effectively recasting geometric reasoning as image generation.
  Unlike prior work that necessitates specialized architectures and
domain-specific adaptations when applying diffusion to parametric geometric
representations, we employ a standard visual diffusion model that operates on
the visual representation of the problem. This simplicity highlights a
surprising bridge between generative modeling and geometric problem solving.
Beyond the specific problems studied here, our results point toward a broader
paradigm: operating in image space provides a general and practical framework
for approximating notoriously hard problems, and opens the door to tackling a
far wider class of challenging geometric tasks.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [59] [Code-enabled language models can outperform reasoning models on diverse tasks](https://arxiv.org/abs/2510.20909)
*Cedegao E. Zhang,Cédric Colas,Gabriel Poesia,Joshua B. Tenenbaum,Jacob Andreas*

Main category: cs.CL

TL;DR: 标准的指令语言模型（LMs）在长形式自然语言推理方面表现出色，且无需微调，能够与强化学习训练的推理模型（RMs）相媲美或超越。


<details>
  <summary>Details</summary>
Motivation: 研究旨在展示标准语言模型在推理任务中的潜力，减少训练和运行的计算成本。

Method: 通过CodeAdapt，将自然语言推理与代码执行结合，采用少量示例进行上下文学习。

Result: 在八项任务中，三种LMs平均超越了相应的RMs，且在效率上提升了10-81%。

Conclusion: CodeAdapt结合了自然语言推理与代码执行，提升了LMs的推理能力，并且在多项任务上超越了对应的RMs。

Abstract: Reasoning models (RMs), language models (LMs) trained with reinforcement
learning to produce long-form natural language reasoning, have been remarkably
successful, but they still require large amounts of computation and data to
train, and can be slow and expensive to run. In this paper, we show that
standard instruct LMs can already be elicited to be strong reasoners at a level
comparable to or even surpassing their corresponding RMs (e.g., DeepSeek V3 vs
R1) without finetuning, across diverse domains from instruction following and
creative generation to mathematical reasoning. This is achieved by CodeAdapt,
our simple recipe that combines the CodeAct framework, where LMs interleave
natural language reasoning with code execution in a multi-step fashion, with
few-shot bootstrap in-context learning from as few as five training problems.
Analyzing four matched pairs of LMs and RMs, we find that CodeAdapt enables
three LMs to outperform the corresponding RMs on average over eight tasks (up
to 22.9%) while being 10-81% more token efficient, and delivers superior
performance on six tasks when averaged over the four models (up to 35.7%).
Furthermore, the code-augmented reasoning traces display rich and varied
problem-solving strategies. Our findings support that (1) CodeAdapt-style
learning and reasoning may be robust and domain general and (2) code-enabled
LMs are cognitively grounded and powerful systems, potentially providing a
strong foundation for in-weight reinforcement learning.

</details>


### [60] [FicSim: A Dataset for Multi-Faceted Semantic Similarity in Long-Form Fiction](https://arxiv.org/abs/2510.20926)
*Natasha Johnson,Amanda Bertsch,Maria-Emil Deal,Emma Strubell*

Main category: cs.CL

TL;DR: 本研究构建了FICSIM数据集，用以评估语言模型在计算文学研究中的应用有效性，结果显示模型在深层语义处理方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 促进语言模型在计算文学研究中的应用，解决评估其有效性时的数据标注成本和公共领域文学作品的数据污染问题。

Method: 构建并发布FICSIM数据集（长篇小说的相似度评分），评估嵌入模型在文学计算任务上的表现。

Result: 发布FICSIM数据集，包含长篇小说的相似度评分，并通过测试展示嵌入模型在处理文学任务时的局限性。

Conclusion: 研究结果表明当前嵌入模型更侧重于表面特征，需要更加关注语义类别，以提高其在计算文学研究中的适用性。

Abstract: As language models become capable of processing increasingly long and complex
texts, there has been growing interest in their application within
computational literary studies. However, evaluating the usefulness of these
models for such tasks remains challenging due to the cost of fine-grained
annotation for long-form texts and the data contamination concerns inherent in
using public-domain literature. Current embedding similarity datasets are not
suitable for evaluating literary-domain tasks because of a focus on
coarse-grained similarity and primarily on very short text. We assemble and
release FICSIM, a dataset of long-form, recently written fiction, including
scores along 12 axes of similarity informed by author-produced metadata and
validated by digital humanities scholars. We evaluate a suite of embedding
models on this task, demonstrating a tendency across models to focus on
surface-level features over semantic categories that would be useful for
computational literary studies tasks. Throughout our data-collection process,
we prioritize author agency and rely on continual, informed author consent.

</details>


### [61] [Do LLMs Truly Understand When a Precedent Is Overruled?](https://arxiv.org/abs/2510.20941)
*Li Zhang,Jaromir Savelka,Kevin Ashley*

Main category: cs.CL

TL;DR: 本研究评估大型语言模型在法律文件理解中的表现，发现其在历史案件、深层推理和复杂任务中的局限性，并提出了一种新基准。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在复杂法律推理任务中的性能，特别是在处理长法律文档方面的能力不足。

Method: 使用来自236对案件的数据集，评估模型在识别推翻关系方面的表现。

Result: 评估了最先进的语言模型在识别美国最高法院案件中的推翻关系上的表现，并发现了三个关键限制。

Conclusion: 提出的基准填补了现实长上下文评估中的关键空白，模拟真实法律推理任务的复杂性和风险。

Abstract: Large language models (LLMs) with extended context windows show promise for
complex legal reasoning tasks, yet their ability to understand long legal
documents remains insufficiently evaluated. Developing long-context benchmarks
that capture realistic, high-stakes tasks remains a significant challenge in
the field, as most existing evaluations rely on simplified synthetic tasks that
fail to represent the complexity of real-world document understanding.
Overruling relationships are foundational to common-law doctrine and commonly
found in judicial opinions. They provide a focused and important testbed for
long-document legal understanding that closely resembles what legal
professionals actually do. We present an assessment of state-of-the-art LLMs on
identifying overruling relationships from U.S. Supreme Court cases using a
dataset of 236 case pairs. Our evaluation reveals three critical limitations:
(1) era sensitivity -- the models show degraded performance on historical cases
compared to modern ones, revealing fundamental temporal bias in their training;
(2) shallow reasoning -- models rely on shallow logical heuristics rather than
deep legal comprehension; and (3) context-dependent reasoning failures --
models produce temporally impossible relationships in complex open-ended tasks
despite maintaining basic temporal awareness in simple contexts. Our work
contributes a benchmark that addresses the critical gap in realistic
long-context evaluation, providing an environment that mirrors the complexity
and stakes of actual legal reasoning tasks.

</details>


### [62] [Irish-BLiMP: A Linguistic Benchmark for Evaluating Human and Language Model Performance in a Low-Resource Setting](https://arxiv.org/abs/2510.20957)
*Josh McGiff,Khanh-Tung Tran,William Mulcahy,Dáibhidh Ó Luinín,Jake Dalzell,Róisín Ní Bhroin,Adam Burke,Barry O'Sullivan,Hoang D. Nguyen,Nikola S. Nikolov*

Main category: cs.CL

TL;DR: 研究构建了第一个针对爱尔兰语的语言能力评估框架，揭示人类在语法知识上明显优于语言模型。


<details>
  <summary>Details</summary>
Motivation: 开发针对爱尔兰语的评估框架，以填补对这种濒危语言的语言能力评价的空缺。

Method: 手动构建并审核1020个最小对，针对11个语言特征，对现有大型语言模型和流利的爱尔兰语使用者进行语法知识评估。

Result: 通过对1020个最小对的评估，发现人类在所有语言特征上的表现优于现有的语言模型。

Conclusion: 爱尔兰-BLiMP为低资源语言的语言理解研究提供了有价值的基准，可以推动相关研究的发展。

Abstract: We present Irish-BLiMP (Irish Benchmark of Linguistic Minimal Pairs), the
first dataset and framework designed for fine-grained evaluation of linguistic
competence in the Irish language, an endangered language. Drawing on a variety
of linguistic literature and grammar reference works, we manually constructed
and reviewed 1020 minimal pairs across a taxonomy of 11 linguistic features,
through a team of fluent Irish speakers. We evaluate both existing Large
Language Models (LLMs) and fluent human participants on their syntactic
knowledge of Irish. Our findings show that humans outperform all models across
all linguistic features, achieving 16.6% higher accuracy on average. Moreover,
a substantial performance gap of 18.1% persists between open- and closed-source
LLMs, with even the strongest model (gpt-5) reaching only 73.5% accuracy
compared to 90.1% by human. Interestingly, human participants and models
struggle on different aspects of Irish grammar, thus highlighting a difference
in representation learned by the models. Overall, Irish-BLiMP provides the
first systematic framework for evaluating the grammatical competence of LLMs in
Irish and offers a valuable benchmark for advancing research on linguistic
understanding in low-resource languages.

</details>


### [63] [Can Confidence Estimates Decide When Chain-of-thought is Necessary for Llms?](https://arxiv.org/abs/2510.21007)
*Samuel Lewis-Lim,Xingwei Tan,Zhixue Zhao,Nikolaos Aletras*

Main category: cs.CL

TL;DR: 提出了一种自信度驱动的链式推理激活机制，表明无训练的自信度测量方法能够有效减少冗余推理。


<details>
  <summary>Details</summary>
Motivation: 现有的链式推理方法在某些任务上效果显著，但在许多场景中会增加token使用量，降低实用性，急需系统性解决方案来判断何时使用CoT。

Method: 提出了一种基于自信度的链式推理（CoT）激活机制，以在自信度低时使用推理，节省资源。

Result: 通过广泛的实验，发现现有的无训练自信度测量能够减少冗余的CoT使用，并在性能上优于随机调用的CoT，但其有效性在不同数据集和模型上表现不均。

Conclusion: 本研究指出当前方法的潜力和局限性，并为更可靠的自适应CoT激活机制铺平了道路。

Abstract: Chain-of-thought (CoT) prompting has emerged as a common technique for
enhancing the reasoning abilities of large language models (LLMs). While
extended reasoning can boost accuracy on complex tasks, it is often unnecessary
and substantially increases token usage, limiting the practicality of reasoning
models in many scenarios. Recent models, such as GPT-OSS and Qwen3, expose
controls that enable users to adjust the length of CoT or determine whether it
is used at all. Yet, it remains unclear when CoT should be used: on some tasks
it improves performance, while on others it provides little benefit or even
harms performance. We address this challenge with confidence-gated CoT, where a
model invokes reasoning only when confidence in its direct answer is low. To
this end, we present the first systematic study of training-free confidence
estimation methods for CoT gating. Specifically, we evaluate four training-free
confidence estimation methods and compare them to a random baseline and an
oracle that always knows when CoT is needed. Through extensive experiments, we
show that existing training-free confidence measures can reduce redundant CoT
and outperform randomly invoked CoT. However, the utility of individual
confidence measures is inconsistent, varying with both the dataset and the
model, underscoring the difficulty of deploying confidence-gated CoT in
practice. By analysing both strengths and failure modes, our study highlights
the potential and limitations of current methods and paves the way toward more
reliable adaptive gating of CoT.

</details>


### [64] [DispatchMAS: Fusing taxonomy and artificial intelligence agents for emergency medical services](https://arxiv.org/abs/2510.21228)
*Xiang Li,Huizi Yu,Wenkong Wang,Yiran Wu,Jiayan Zhou,Wenyue Hua,Xinxin Lin,Wenjia Tan,Lexuan Zhu,Bingyi Chen,Guang Chen,Ming-Li Chen,Yang Zhou,Zhao Li,Themistocles L. Assimes,Yongfeng Zhang,Qingyun Wu,Xin Ma,Lingyao Li,Lizhou Fan*

Main category: cs.CL

TL;DR: 研究开发了一种新的基于分类法的多智能体系统，用于高效模拟紧急医疗调度，结果表明其具备良好的指导效果和调度有效性。


<details>
  <summary>Details</summary>
Motivation: 应对紧急医疗调度中的挑战，如呼叫者的 distress、模糊性和认知负担，探索大语言模型和多智能体系统的应用。

Method: 采用分类法构建的多智能体系统，进行模拟，并结合医生评估与自动化语言分析进行综合评估。

Result: 本研究开发了一种基于临床分类法的多智能体系统（MAS），用于模拟真实的紧急医疗调度（EMD）场景。通过设计32种主要主诉和6种来电者身份，构建了一个六阶段的呼叫协议。该系统确保了临床情境的合理性，并减少了错误信息的干扰。四位医生评估了100个模拟案例，结果显示该系统在“指导效果”和“调度有效性”方面均表现优秀，且与自动语言分析结果一致。

Conclusion: 该多智能体系统能够高保真模拟多样的临床调度场景，并适用于调度员训练和实时决策支持。

Abstract: Objective: Emergency medical dispatch (EMD) is a high-stakes process
challenged by caller distress, ambiguity, and cognitive load. Large Language
Models (LLMs) and Multi-Agent Systems (MAS) offer opportunities to augment
dispatchers. This study aimed to develop and evaluate a taxonomy-grounded,
LLM-powered multi-agent system for simulating realistic EMD scenarios. Methods:
We constructed a clinical taxonomy (32 chief complaints, 6 caller identities
from MIMIC-III) and a six-phase call protocol. Using this framework, we
developed an AutoGen-based MAS with Caller and Dispatcher Agents. The system
grounds interactions in a fact commons to ensure clinical plausibility and
mitigate misinformation. We used a hybrid evaluation framework: four physicians
assessed 100 simulated cases for "Guidance Efficacy" and "Dispatch
Effectiveness," supplemented by automated linguistic analysis (sentiment,
readability, politeness). Results: Human evaluation, with substantial
inter-rater agreement (Gwe's AC1 > 0.70), confirmed the system's high
performance. It demonstrated excellent Dispatch Effectiveness (e.g., 94 %
contacting the correct potential other agents) and Guidance Efficacy (advice
provided in 91 % of cases), both rated highly by physicians. Algorithmic
metrics corroborated these findings, indicating a predominantly neutral
affective profile (73.7 % neutral sentiment; 90.4 % neutral emotion), high
readability (Flesch 80.9), and a consistently polite style (60.0 % polite; 0 %
impolite). Conclusion: Our taxonomy-grounded MAS simulates diverse, clinically
plausible dispatch scenarios with high fidelity. Findings support its use for
dispatcher training, protocol evaluation, and as a foundation for real-time
decision support. This work outlines a pathway for safely integrating advanced
AI agents into emergency response workflows.

</details>


### [65] [Reasoning's Razor: Reasoning Improves Accuracy but Can Hurt Recall at Critical Operating Points in Safety and Hallucination Detection](https://arxiv.org/abs/2510.21049)
*Atoosa Chegini,Hamid Kazemi,Garrett Souza,Maria Safi,Yang Song,Samy Bengio,Sinead Williamson,Mehrdad Farajtabar*

Main category: cs.CL

TL;DR: 推理是大型语言模型中的核心范式，但其在精度敏感任务中的适用性仍不明确。研究表明，推理增强的生成在整体准确性上有所提高，但在低误报率下表现不佳，而未使用推理的模式在此类任务中表现更好。


<details>
  <summary>Details</summary>
Motivation: 系统研究推理在分类任务中在严格低误报率下的适用性。

Method: 对安全检测和幻觉检测任务进行分析，评估了微调和零-shot两个设置，使用标准大型语言模型和大型推理模型。

Result: 发现推理增强生成提高了整体准确性，但在精度敏感的任务中表现不佳，未推理模式反之则表现更优。

Conclusion: 推理在整体准确性上具有优势，但在需要严格精准的应用中常常不合适。

Abstract: Reasoning has become a central paradigm for large language models (LLMs),
consistently boosting accuracy across diverse benchmarks. Yet its suitability
for precision-sensitive tasks remains unclear. We present the first systematic
study of reasoning for classification tasks under strict low false positive
rate (FPR) regimes. Our analysis covers two tasks--safety detection and
hallucination detection--evaluated in both fine-tuned and zero-shot settings,
using standard LLMs and Large Reasoning Models (LRMs). Our results reveal a
clear trade-off: Think On (reasoning-augmented) generation improves overall
accuracy, but underperforms at the low-FPR thresholds essential for practical
use. In contrast, Think Off (no reasoning during inference) dominates in these
precision-sensitive regimes, with Think On surpassing only when higher FPRs are
acceptable. In addition, we find token-based scoring substantially outperforms
self-verbalized confidence for precision-sensitive deployments. Finally, a
simple ensemble of the two modes recovers the strengths of each. Taken
together, our findings position reasoning as a double-edged tool: beneficial
for average accuracy, but often ill-suited for applications requiring strict
precision.

</details>


### [66] [Dynamic Retriever for In-Context Knowledge Editing via Policy Optimization](https://arxiv.org/abs/2510.21059)
*Mahmud Wasif Nafee,Maiqi Jiang,Haipeng Chen,Yanfu Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的动态检索框架DR-IKE，以提高大型语言模型的上下文知识编辑能力，通过动态选择支持示例来优化编辑过程，实现了编辑成功率、速度和准确性的提升。


<details>
  <summary>Details</summary>
Motivation: 解决现有知识编辑方法中数量与质量的权衡及缺乏适应性的问题，通过动态选择支持示例来提高大型语言模型的知识编辑效果。

Method: 动态检索框架，使用REINFORCE对BERT检索模型进行训练，根据编辑奖励对示例进行排名，利用可学习阈值修剪低价值示例。

Result: 该论文提出了一种新的动态检索框架DR-IKE，用于上下文知识编辑，旨在提高大型语言模型的知识编辑能力。与现有的静态编辑方法相比，DR-IKE能够根据编辑的效用动态选择支持示例，从而解决了数量与质量之间的权衡以及缺乏适应性的任务困难问题。通过训练BERT检索模型，DR-IKE能够通过奖励来对示例进行排名，并利用可学习阈值修剪低价值示例，实现了对提示的调整，从而在不同任务难度下发挥最佳效果。该方法在COUNTERFACT基准测试中取得了编辑成功率提高17.1%、延迟减少41.6%的显著成果，同时在无关查询上保持了准确性，显示了可扩展和适应性的知识编辑能力。

Conclusion: DR-IKE展现了在知识编辑方面的可扩展性和适应性，显著提高了编辑成功率，减少了延迟，同时保持了对无关查询的准确性。

Abstract: Large language models (LLMs) excel at factual recall yet still propagate
stale or incorrect knowledge. In-context knowledge editing offers a
gradient-free remedy suitable for black-box APIs, but current editors rely on
static demonstration sets chosen by surface-level similarity, leading to two
persistent obstacles: (i) a quantity-quality trade-off, and (ii) lack of
adaptivity to task difficulty. We address these issues by dynamically selecting
supporting demonstrations according to their utility for the edit. We propose
Dynamic Retriever for In-Context Knowledge Editing (DR-IKE), a lightweight
framework that (1) trains a BERT retriever with REINFORCE to rank
demonstrations by editing reward, and (2) employs a learnable threshold to
prune low-value examples, shortening the prompt when the edit is easy and
expanding it when the task is hard. DR-IKE performs editing without modifying
model weights, relying solely on forward passes for compatibility with
black-box LLMs. On the COUNTERFACT benchmark, it improves edit success by up to
17.1%, reduces latency by 41.6%, and preserves accuracy on unrelated queries,
demonstrating scalable and adaptive knowledge editing. The code is available at
https://github.com/mwnafee/DR-IKE .

</details>


### [67] [Bridging Language Gaps with Adaptive RAG: Improving Indonesian Language Question Answering](https://arxiv.org/abs/2510.21068)
*William Christian,Daniel Adamlu,Adrian Yu,Derwin Suhartono*

Main category: cs.CL

TL;DR: 研究提出适用于印尼语的自适应检索增强生成系统，通过分类问题复杂性来定制回答策略，并采用机器翻译增强数据。但在多检索答案策略中存在显著不一致性影响评价结果。


<details>
  <summary>Details</summary>
Motivation: 旨在提升印尼语问答系统的准确性，解决现有模型主要集中在英语语境下的局限性。

Method: 采用自适应检索增强生成（Adaptive RAG）系统，结合分类器以识别问题复杂性，并利用机器翻译进行数据增强。

Result: 这项研究提出了一种自适应检索增强生成（Adaptive RAG）系统，以解决印尼语在问答系统中的性能瓶颈。通过引入分类器来识别问题的复杂性，从而定制回答策略，提升了问答准确性。此外，鉴于印尼语数据集的有限性，本研究采用机器翻译进行数据增强，以丰富可用数据。实验结果显示，模型在问题复杂性分类方面表现可靠，但在多检索回答策略的应用中存在显著不一致性，导致整体评估效果不佳。这些发现既展示了低资源语言问答领域的潜力，也揭示了面临的挑战，为未来的研究指明了方向。

Conclusion: 本研究表明在低资源语言的问答系统中存在潜力与挑战，未来的研究需聚焦于提高多检索回答策略的一致性。

Abstract: Question Answering (QA) has seen significant improvements with the
advancement of machine learning models, further studies enhanced this question
answering system by retrieving external information, called Retrieval-Augmented
Generation (RAG) to produce more accurate and informative answers. However,
these state-of-the-art-performance is predominantly in English language. To
address this gap we made an effort of bridging language gaps by incorporating
Adaptive RAG system to Indonesian language. Adaptive RAG system integrates a
classifier whose task is to distinguish the question complexity, which in turn
determines the strategy for answering the question. To overcome the limited
availability of Indonesian language dataset, our study employs machine
translation as data augmentation approach. Experiments show reliable question
complexity classifier; however, we observed significant inconsistencies in
multi-retrieval answering strategy which negatively impacted the overall
evaluation when this strategy was applied. These findings highlight both the
promise and challenges of question answering in low-resource language
suggesting directions for future improvement.

</details>


### [68] [CDrugRed: A Chinese Drug Recommendation Dataset for Discharge Medications in Metabolic Diseases](https://arxiv.org/abs/2510.21084)
*Juntao Li,Haobin Yuan,Ling Luo,Yan Jiang,Fan Wang,Ping Zhang,Huiyi Lv,Jian Wang,Yuanyuan Sun,Hongfei Lin*

Main category: cs.CL

TL;DR: 本研究发布了CDrugRed数据集，专注于代谢疾病出院药物推荐，包含5,894名患者的记录。实验显示模型性能仍有提升空间。


<details>
  <summary>Details</summary>
Motivation: 针对缺乏公开真实EHR数据集的挑战，尤其是非英语的EHR数据，推动临床药物推荐系统的发展。

Method: 基于大型语言模型进行基准测试，以评估推荐性能。

Result: 本研究提出了CDrugRed，这是首个公开可用的中文药物推荐数据集，专注于代谢疾病的出院药物。数据集包含3,190名患者的5,894条去识别记录，包括患者的人口统计信息、病史、临床过程和出院诊断。通过基准测试多个先进的大型语言模型（LLMs），评估了CDrugRed在出院药物推荐任务中的效用。实验结果表明，尽管监督微调提高了模型性能，但仍有显著的提升空间，最佳模型的F1分数为0.5648，Jaccard分数为0.4477。

Conclusion: CDrugRed是一个具有挑战性且有价值的资源，可用于开发更鲁棒和准确的药物推荐系统。

Abstract: Intelligent drug recommendation based on Electronic Health Records (EHRs) is
critical for improving for improving the quality and efficiency of clinical
decision-making. By leveraging large-scale patient data, drug recommendation
systems can assist physicians in selecting the most appropriate medications
according to a patient's medical history, diagnoses, laboratory results, and
comorbidities. However, the advancement of such systems is significantly
hampered by the scarcity of publicly available, real-world EHR datasets,
particularly in languages other than English. In this work, we present
CDrugRed, a first publicly available Chinese drug recommendation dataset
focused on discharge medications for metabolic diseases. The dataset includes
5,894 de-identified records from 3,190 patients, containing comprehensive
information such as patient demographics, medical history, clinical course, and
discharge diagnoses. We assess the utility of CDrugRed by benchmarking several
state-of-the-art large language models (LLMs) on the discharge medication
recommendation task. Experimental results show that while supervised
fine-tuning improves model performance, there remains substantial room for
improvement, with the best model achieving the F1 score of 0.5648 and Jaccard
score of 0.4477. This result highlights the complexity of the clinical drug
recommendation task and establishes CDrugRed as a challenging and valuable
resource for developing more robust and accurate drug recommendation systems.
The dataset is publicly available to the research community under the data
usage agreements at https://github.com/DUTIR-BioNLP/CDrugRed.

</details>


### [69] [Self-Rewarding PPO: Aligning Large Language Models with Demonstrations Only](https://arxiv.org/abs/2510.21090)
*Qingru Zhang,Liang Qiu,Ilgee Hong,Zhenghao Xu,Tianyi Liu,Shiyang Li,Rongzhi Zhang,Zheng Li,Lihong Li,Bing Yin,Chao Zhang,Jianshu Chen,Haoming Jiang,Tuo Zhao*

Main category: cs.CL

TL;DR: 提出Self-Rewarding PPO作为一种新型微调方法，以解决SFT的局限，尤其是在数据稀缺的情况下。


<details>
  <summary>Details</summary>
Motivation: 解决传统监督微调在有限数据场景下过拟合和泛化能力差的问题。

Method: Self-Rewarding PPO

Result: Self-Rewarding PPO在多个自然语言处理任务中表现优于传统的SFT方法。

Conclusion: Self-Rewarding PPO通过自奖励机制与PPO结合，有效提升了中文大型语言模型的对齐能力和泛化性能。

Abstract: Supervised fine-tuning (SFT) has emerged as a crucial method for aligning
large language models (LLMs) with human-annotated demonstrations. However, SFT,
being an off-policy approach similar to behavior cloning, often struggles with
overfitting and poor out-of-domain generalization, especially in limited-data
scenarios. To address these limitations, we propose Self-Rewarding PPO, a novel
fine-tuning method that leverages on-policy techniques to enhance
generalization performance. Our approach combines the strengths of SFT and
proximal policy optimization (PPO) to achieve more effective alignment from
demonstration data. At its core is a reward function designed as the log policy
ratio between the SFT model and the pretrained base model. This function serves
as an implicit reward signal, using the pretrained policy as a baseline and the
SFT policy as a target. By doing so, it enables on-policy fine-tuning without
relying on human preference annotations. The integration of this self-rewarding
mechanism with PPO addresses key limitations of SFT, improving generalization,
data efficiency, and robustness. Our empirical evaluation across a range of
natural language processing tasks demonstrates that Self-Rewarding PPO
consistently outperforms traditional SFT methods. The results highlight the
effectiveness of our approach in aligning LLMs using demonstration data,
particularly in scenarios where high-quality annotated data is scarce.

</details>


### [70] [The Gray Zone of Faithfulness: Taming Ambiguity in Unfaithfulness Detection](https://arxiv.org/abs/2510.21118)
*Qiang Ding,Lvzhou Luo,Yixuan Cao,Ping Luo*

Main category: cs.CL

TL;DR: 本文提出了一种新的可信度注释框架，并构建了一个新的不可信度检测基准，揭示了现有模型在生成摘要时存在的幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 确保大型语言模型生成的摘要与源文档忠实是一项重要的现实应用需求，当前研究存在注释模糊的问题。

Method: 提出一种新的可信度注释框架，并建立了一个新的不可信度检测基准——VeriGray。

Result: 构建了VeriGray基准，并发现即便是最先进的LLM，如GPT-5，在摘要任务中也出现了约6%的句子幻觉，约8%的生成句子需外部知识进行验证。

Conclusion: 注释模糊性在不可信度检测基准中亟待解决，未来有显著改进空间。

Abstract: Ensuring that Large Language Models (LLMs) generate summaries faithful to a
given source document is essential for real-world applications. While prior
research has explored LLM faithfulness, existing benchmarks suffer from
annotation ambiguity, primarily due to the ill-defined boundary of permissible
external knowledge in generated outputs. For instance, common sense is often
incorporated into responses and labeled as "faithful", yet the acceptable
extent of such knowledge remains unspecified, leading to inconsistent
annotations. To address this issue, we propose a novel faithfulness annotation
framework, which introduces an intermediate category, Out-Dependent, to
classify cases where external knowledge is required for verification. Using
this framework, we construct VeriGray (Verification with the Gray Zone) -- a
new unfaithfulness detection benchmark in summarization. Statistics reveal that
even SOTA LLMs, such as GPT-5, exhibit hallucinations ($\sim 6\%$ of sentences)
in summarization tasks. Moreover, a substantial proportion ($\sim 8\%$ on
average of models) of generated sentences fall into the Out-Dependent category,
underscoring the importance of resolving annotation ambiguity in unfaithfulness
detection benchmarks. Experiments demonstrate that our benchmark poses
significant challenges to multiple baseline methods, indicating considerable
room for future improvement.

</details>


### [71] [Large Language Models Meet Text-Attributed Graphs: A Survey of Integration Frameworks and Applications](https://arxiv.org/abs/2510.21131)
*Guangxin Su,Hanchen Wang,Jianwei Wang,Wenjie Zhang,Ying Zhang,Jian Pei*

Main category: cs.CL

TL;DR: 本调研提供了LLMs与TAGs集成的系统性回顾，介绍了新的分类法及其在多种应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型（LLMs）与文本属性图（TAGs）集成的优势及其在多项任务中的应用。

Method: 分析了LLMs与TAGs的整合策略，并在顺序、并行和多模块框架中进行了分类讨论，同时总结了相关方法、数据集及应用。

Result: 通过综合LLMs与TAGs，增强了图表表示学习，并提高了LLMs的推理和可解释性。

Conclusion: 研究表明，LLMs与TAGs的结合在多个领域具有显著优势，并提出了未来研究方向和挑战。

Abstract: Large Language Models (LLMs) have achieved remarkable success in natural
language processing through strong semantic understanding and generation.
However, their black-box nature limits structured and multi-hop reasoning. In
contrast, Text-Attributed Graphs (TAGs) provide explicit relational structures
enriched with textual context, yet often lack semantic depth. Recent research
shows that combining LLMs and TAGs yields complementary benefits: enhancing TAG
representation learning and improving the reasoning and interpretability of
LLMs. This survey provides the first systematic review of LLM--TAG integration
from an orchestration perspective. We introduce a novel taxonomy covering two
fundamental directions: LLM for TAG, where LLMs enrich graph-based tasks, and
TAG for LLM, where structured graphs improve LLM reasoning. We categorize
orchestration strategies into sequential, parallel, and multi-module
frameworks, and discuss advances in TAG-specific pretraining, prompting, and
parameter-efficient fine-tuning. Beyond methodology, we summarize empirical
insights, curate available datasets, and highlight diverse applications across
recommendation systems, biomedical analysis, and knowledge-intensive question
answering. Finally, we outline open challenges and promising research
directions, aiming to guide future work at the intersection of language and
graph learning.

</details>


### [72] [Estonian Native Large Language Model Benchmark](https://arxiv.org/abs/2510.21193)
*Helena Grete Lillepalu,Tanel Alumäe*

Main category: cs.CL

TL;DR: 提出新的基准用于评估LLM在爱沙尼亚语的表现，基于七个数据集的比较显示LLM可以有效支持爱沙尼亚语言模型的评估。


<details>
  <summary>Details</summary>
Motivation: 建立爱沙尼亚语言的LLM基准，填补现有评估的空白，并对不同LLM在爱沙尼亚任务上的表现进行全面比较。

Method: 建立七个数据集，评估多种LLM模型的表现，包括人类评估和LLM作为评委的方法。

Result: 引入了一个新的基准，基于七个多样化的数据集，评估了多种LLM模型在爱沙尼亚语任务上的表现。

Conclusion: 高表现的LLM能够有效支持爱沙尼亚语言模型的评估，且人类评估与基准评估之间存在中等到高度的相关性。

Abstract: The availability of LLM benchmarks for the Estonian language is limited, and
a comprehensive evaluation comparing the performance of different LLMs on
Estonian tasks has yet to be conducted. We introduce a new benchmark for
evaluating LLMs in Estonian, based on seven diverse datasets. These datasets
assess general and domain-specific knowledge, understanding of Estonian grammar
and vocabulary, summarization abilities, contextual comprehension, and more.
The datasets are all generated from native Estonian sources without using
machine translation. We compare the performance of base models,
instruction-tuned open-source models, and commercial models. Our evaluation
includes 6 base models and 26 instruction-tuned models. To assess the results,
we employ both human evaluation and LLM-as-a-judge methods. Human evaluation
scores showed moderate to high correlation with benchmark evaluations,
depending on the dataset. Claude 3.7 Sonnet, used as an LLM judge, demonstrated
strong alignment with human ratings, indicating that top-performing LLMs can
effectively support the evaluation of Estonian-language models.

</details>


### [73] [The "Right" Discourse on Migration: Analysing Migration-Related Tweets in Right and Far-Right Political Movements](https://arxiv.org/abs/2510.21220)
*Nishan Chatterjee,Veronika Bajt,Ana Zwitter Vitez,Senja Pollak*

Main category: cs.CL

TL;DR: 本研究通过自然语言处理和社会学方法分析极右分子的推文，旨在揭示移民相关的极端话语与其社会影响。


<details>
  <summary>Details</summary>
Motivation: 随着欧洲右翼民粹主义的兴起，通过社交媒体话语分析来理解极端主义意识形态的传播及其对政治结果的影响变得重要。

Method: 采用先进的自然语言处理技术与社会学视角相结合的方法，分析MIGR-TWIT语料库中英文和法文的极右推文。

Result: 揭示有关移民、仇恨言论和极右势力所采用的说服技巧的话语模式。

Conclusion: 通过跨学科的方法，增进对右翼极端主义当代挑战的理解。

Abstract: The rise of right-wing populism in Europe has brought to the forefront the
significance of analysing social media discourse to understand the
dissemination of extremist ideologies and their impact on political outcomes.
Twitter, as a platform for interaction and mobilisation, provides a unique
window into the everyday communication of far-right supporters. In this paper,
we propose a methodology that uses state-of-the-art natural language processing
techniques with sociological insights to analyse the MIGR-TWIT corpus of
far-right tweets in English and French. We aim to uncover patterns of discourse
surrounding migration, hate speech, and persuasion techniques employed by right
and far-right actors. By integrating linguistic, sociological, and
computational approaches, we seek to offer cross-disciplinary insights into
societal dynamics and contribute to a better understanding of contemporary
challenges posed by right-wing extremism on social media platforms.

</details>


### [74] [Correlation Dimension of Auto-Regressive Large Language Models](https://arxiv.org/abs/2510.21258)
*Xin Du,Kumiko Tanaka-Ishii*

Main category: cs.CL

TL;DR: 本论文引入相关维度作为测量LLM生成文本复杂性的工具，揭示了其在预训练阶段的变化及其生成退化的倾向。


<details>
  <summary>Details</summary>
Motivation: 旨在克服传统评估指标的局限性，提供一种新的方法来理解大型语言模型生成文本中的复杂性和结构。

Method: 通过实验验证相关维度在量化文本复杂性方面的有效性，并研究其与大型语言模型性能的关系。

Result: 该论文探讨了大型语言模型（LLMs）在自然语言生成中的表现，指出其在低困惑度时仍显示出的重复性和不连贯性。这反映出传统评估指标的局限性，往往侧重于局部预测准确性，而忽视了长范围结构复杂性。为了量化语言的认知复杂性，论文提出了“相关维度”这一分形几何度量，捕捉语言的层次递归结构，通过广泛的实验验证该方法的有效性，包括在预训练阶段的三种不同相位、上下文相关复杂性、模型的幻觉倾向以及多种生成文本的退化形式的检测。此外，该方法计算效率高，对模型量化具备鲁棒性，适用于多种自回归架构（如Transformer和Mamba），为LLM的生成动态提供新的见解。

Conclusion: 相关维度提供了一种新的视角，可以有效评估和理解大型语言模型生成文本的复杂性及其潜在问题。

Abstract: Large language models (LLMs) have achieved remarkable progress in natural
language generation, yet they continue to display puzzling behaviors -- such as
repetition and incoherence -- even when exhibiting low perplexity. This
highlights a key limitation of conventional evaluation metrics, which emphasize
local prediction accuracy while overlooking long-range structural complexity.
We introduce correlation dimension, a fractal-geometric measure of
self-similarity, to quantify the epistemological complexity of text as
perceived by a language model. This measure captures the hierarchical
recurrence structure of language, bridging local and global properties in a
unified framework. Through extensive experiments, we show that correlation
dimension (1) reveals three distinct phases during pretraining, (2) reflects
context-dependent complexity, (3) indicates a model's tendency toward
hallucination, and (4) reliably detects multiple forms of degeneration in
generated text. The method is computationally efficient, robust to model
quantization (down to 4-bit precision), broadly applicable across
autoregressive architectures (e.g., Transformer and Mamba), and provides fresh
insight into the generative dynamics of LLMs.

</details>


### [75] [Sparser Block-Sparse Attention via Token Permutation](https://arxiv.org/abs/2510.21270)
*Xinghao Wang,Pengyu Wang,Dong Zhang,Chenkun Tan,Shaojun Zhou,Zhaoxiang Liu,Shiguo Lian,Fangxu Liu,Kai Song,Xipeng Qiu*

Main category: cs.CL

TL;DR: 本文提出了一种名为PBS-Attn的改进块稀疏注意机制，旨在提高大语言模型在长上下文填充中的计算效率。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型的上下文长度处理能力，同时降低计算开销，特别是在自注意机制的背景下。

Method: 本研究提出了Permuted Block-Sparse Attention（PBS-Attn），它利用注意力的排列特性来增加块级稀疏性，从而提升计算效率。

Result: PBS-Attn在长上下文预填充中实现了高达2.75倍的端到端加速，验证了这一方法的实用性。

Conclusion: PBS-Attn方法在处理长上下文数据集时，表现出比现有的块稀疏注意机制更高的模型准确性，并且接近全注意力基准。

Abstract: Scaling the context length of large language models (LLMs) offers significant
benefits but is computationally expensive. This expense stems primarily from
the self-attention mechanism, whose $O(N^2)$ complexity with respect to
sequence length presents a major bottleneck for both memory and latency.
Fortunately, the attention matrix is often sparse, particularly for long
sequences, suggesting an opportunity for optimization. Block-sparse attention
has emerged as a promising solution that partitions sequences into blocks and
skips computation for a subset of these blocks. However, the effectiveness of
this method is highly dependent on the underlying attention patterns, which can
lead to sub-optimal block-level sparsity. For instance, important key tokens
for queries within a single block may be scattered across numerous other
blocks, leading to computational redundancy. In this work, we propose Permuted
Block-Sparse Attention (\textbf{PBS-Attn}), a plug-and-play method that
leverages the permutation properties of attention to increase block-level
sparsity and enhance the computational efficiency of LLM prefilling. We conduct
comprehensive experiments on challenging real-world long-context datasets,
demonstrating that PBS-Attn consistently outperforms existing block-sparse
attention methods in model accuracy and closely matches the full attention
baseline. Powered by our custom permuted-FlashAttention kernels, PBS-Attn
achieves an end-to-end speedup of up to $2.75\times$ in long-context
prefilling, confirming its practical viability. Code available at
https://github.com/xinghaow99/pbs-attn

</details>


### [76] [Efficient semantic uncertainty quantification in language models via diversity-steered sampling](https://arxiv.org/abs/2510.21310)
*Ji Won Park,Kyunghyun Cho*

Main category: cs.CL

TL;DR: 提出一种多样性引导采样器，提高大语言模型在不确定性估计中的采样效率。


<details>
  <summary>Details</summary>
Motivation: 在自由形式问题回答中，准确估计语义随机性和知识不确定性非常具有挑战性

Method: 引入多样性引导采样器，通过注入语义相似性惩罚来降低冗余输出

Result: 在四个QA基准测试中，该方法与基线匹配或超越，同时覆盖更多语义群体

Conclusion: 该框架模块化，且不需要对基础LLM进行梯度访问，适用于风险敏感的模型部署中的不确定性估计。

Abstract: Accurately estimating semantic aleatoric and epistemic uncertainties in large
language models (LLMs) is particularly challenging in free-form question
answering (QA), where obtaining stable estimates often requires many expensive
generations. We introduce a diversity-steered sampler that discourages
semantically redundant outputs during decoding, covers both autoregressive and
masked diffusion paradigms, and yields substantial sample-efficiency gains. The
key idea is to inject a continuous semantic-similarity penalty into the model's
proposal distribution using a natural language inference (NLI) model lightly
finetuned on partial prefixes or intermediate diffusion states. We debias
downstream uncertainty estimates with importance reweighting and shrink their
variance with control variates. Across four QA benchmarks, our method matches
or surpasses baselines while covering more semantic clusters with the same
number of samples. Being modular and requiring no gradient access to the base
LLM, the framework promises to serve as a drop-in enhancement for uncertainty
estimation in risk-sensitive model deployments.

</details>


### [77] [Typoglycemia under the Hood: Investigating Language Models' Understanding of Scrambled Words](https://arxiv.org/abs/2510.21326)
*Gianluca Sperduti,Alejandro Moreo*

Main category: cs.CL

TL;DR: 研究表明，人类能够阅读内部字母顺序混乱的单词，部分自然语言处理模型也展示了对这种扭曲的鲁棒性。我们探讨了在这种情况下模型为何仍能表现良好，并假设主要原因在于少数单词会崩溃且其上下文足够明显。


<details>
  <summary>Details</summary>
Motivation: 研究字母混乱现象对模型表现的影响，以及模型为何能够在字母顺序混乱的情况下仍旧有效。

Method: 通过分析英国国家语料库量化单词在字母混乱下的崩溃和歧义性，评估BERT对崩溃形式的消歧能力，并进行对比实验。

Result: 研究表明，尽管存在字母混乱，模型的表现下降程度比预期要小，指出了模型在处理此类问题时的鲁棒性。

Conclusion: 我们的研究结果显示，字母混乱造成的性能下降比预期的要小，这表明现有模型对于字母混乱具有较高的鲁棒性。

Abstract: Research in linguistics has shown that humans can read words with internally
scrambled letters, a phenomenon recently dubbed typoglycemia. Some specific NLP
models have recently been proposed that similarly demonstrate robustness to
such distortions by ignoring the internal order of characters by design. This
raises a fundamental question: how can models perform well when many distinct
words (e.g., form and from) collapse into identical representations under
typoglycemia? Our work, focusing exclusively on the English language, seeks to
shed light on the underlying aspects responsible for this robustness. We
hypothesize that the main reasons have to do with the fact that (i) relatively
few English words collapse under typoglycemia, and that (ii) collapsed words
tend to occur in contexts so distinct that disambiguation becomes trivial. In
our analysis, we (i) analyze the British National Corpus to quantify word
collapse and ambiguity under typoglycemia, (ii) evaluate BERT's ability to
disambiguate collapsing forms, and (iii) conduct a probing experiment by
comparing variants of BERT trained from scratch on clean versus typoglycemic
Wikipedia text; our results reveal that the performance degradation caused by
scrambling is smaller than expected.

</details>


### [78] [TripTide: A Benchmark for Adaptive Travel Planning under Disruptions](https://arxiv.org/abs/2510.21329)
*Priyanshu Karmakar,Soumyabrata Chaudhuri,Shubhojit Mallick,Manish Gupta,Abhik Jana,Shreya Ghosh*

Main category: cs.CL

TL;DR: TripTide是一个评估LLM在旅行计划中应对干扰能力的基准，通过多个评估指标分析其适应性与个性化。


<details>
  <summary>Details</summary>
Motivation: 为了应对现实旅行中频繁发生的干扰，开发TripTide基准，评估LLM的旅行计划修订能力。

Method: 本研究采用了三种评估方法：自动化指标评估、LLM作为评审的自动评估，以及专家手动评估。

Result: TripTide是一个新Benchmark，旨在评估大型语言模型在旅行计划中应对现实世界干扰的能力。研究提出了三个评估维度，分别是意图保持、响应能力和适应性，并通过自动化指标及专家人工评估进行验证。实验结果显示，LLM在顺序一致性和语义稳定性方面表现良好，但在处理干扰时，随着计划长度增加，适应能力下降。

Conclusion: TripTide为LLM在现实世界不确定性下的旅行规划提供了评价基准，揭示了其适应性和鲁棒性的局限。

Abstract: Recent efforts like TripCraft and TravelPlanner have advanced the use of
Large Language Models ( LLMs) for personalized, constraint aware travel
itinerary generation. Yet, real travel often faces disruptions. To address
this, we present TripTide, the first benchmark evaluating LLM's ability to
revise itineraries under realistic disruptions. TripTide models key dimensions
such as disruption severity and traveler tolerance, enabling nuanced assessment
of LLM adaptability to events like flight cancellations, weather closures, or
overbooked attractions. We conduct a threefold evaluation. First, we introduce
automatic metrics including Preservation of Intent (how well the revised plan
maintains feasibility and goals), Responsiveness (promptness and
appropriateness of disruption handling), and Adaptability (semantic, spatial,
and sequential divergence between original and revised plans). Second, we apply
an LLM-as-a-judge approach to automatically assess revision quality. Third, we
perform manual expert evaluation to verify whether revisions preserve semantic,
spatial, sequential, and responsive aspects. Our experiments show that LLMs
maintain strong sequential consistency and semantic stability, while spatial
deviations are larger for shorter trips but decrease with longer ones,
indicating that extended plans encourage better geographic coherence. However,
disruption-handling ability declines as plan length increases, highlighting
limits in LLM robustness. TripTide establishes a benchmark for evaluating
adaptability, personalization, and resilience in LLM-based travel planning
under real-world uncertainty.

</details>


### [79] [Multi-turn Training with Basic Human Feedback Helps Little on LLM Reasoning](https://arxiv.org/abs/2510.21339)
*Qiang Liu,Wuganjing Song,Zhenzhou Lin,Feifan Chen,Qiaolong Cai,Chen Li,Yongduo Sui*

Main category: cs.CL

TL;DR: 研究表明，单轮训练在推理任务中比多轮训练更具有效性，后者可能会导致性能下降。


<details>
  <summary>Details</summary>
Motivation: 探讨与人类反馈的多轮训练对推理任务的必要性。

Method: 比较传统的单轮训练与三种多轮策略的模型表现。

Result: 单轮设置的模型在单轮和多轮评估中有效概括，而多轮策略的模型在单轮推理表现上明显下降。

Conclusion: 单轮训练在完整信息的任务中更有效可靠，多轮训练在基本反馈下可能会降低推理能力。

Abstract: The reasoning capabilities of Large Language Models (LLMs) are typically
developed through the single-turn reinforcement learning, whereas real-world
applications often involve multi-turn interactions with human feedback, leading
to a potential mismatch between training and deployment conditions. In this
work, we study whether multi-turn training with human feedback is necessary for
reasoning tasks. We compare conventional single-turn training with three
multi-turn strategies and reach contrary conclusions to previous research. We
find that models trained in a single-turn setting generalize effectively to
both single- and multi-turn evaluations, while models trained with multi-turn
strategies exhibit a significant degradation in single-turn reasoning
performance. These results suggest that for tasks with complete information,
robust single-turn training remains more effective and reliable, as multi-turn
training with basic feedback provides limited benefits and can even degrade
reasoning capabilities.

</details>


### [80] [A Diagnostic Benchmark for Sweden-Related Factual Knowledge](https://arxiv.org/abs/2510.21360)
*Jenny Kunz*

Main category: cs.CL

TL;DR: 本研究介绍了一个专门针对瑞典相关人物和事件的问答基准数据集，以填补现有美国中心基准不适用于瑞典的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的瑞典基准主要是美国中心的翻译，缺乏针对瑞典特有知识的测试工具。

Method: 研究团队手动编写了一个问答基准，灵感来自瑞典文化传媒领域的电台节目及重大体育事件。

Result: 较小的模型在瑞典相关事实的回忆上与三倍大的多语言模型表现相当，而持续的预训练有助于提高对瑞典知识的掌握，但也可能导致对某些之前已知信息的遗忘。

Conclusion: 该数据集作为诊断工具，具有研究多语言模型的语言适应和知识保留潜力。

Abstract: Many Swedish benchmarks are translated US-centric benchmarks, and therefore
not suitable for testing knowledge that is particularly relevant, or even
specific, to Sweden. We therefore introduce a manually written
question-answering benchmark specifically targeted to Sweden-related
personalities and events, many of which receive very limited coverage in
international media. Our annotators drew inspiration from a popular radio
program featuring public figures from culture and media, as well as major
sports events in Sweden. The dataset can be used to measure factual recall
across models of varying sizes and degrees of Swedish coverage, and allows to
probe cross-lingual factual consistency as to contains English translations.
Using the dataset, we find that smaller models with stronger Swedish coverage
perform comparably to a three times larger multilingual model in recalling
Sweden-related facts. We also observe that continued pre-training on Swedish
generally improves factual knowledge but also leads to forgetting of a part of
the previously known information. These results demonstrate the dataset's
potential as a diagnostic tool for studying language adaptation and knowledge
retention in multilingual models and during language adaptation.

</details>


### [81] [SindBERT, the Sailor: Charting the Seas of Turkish NLP](https://arxiv.org/abs/2510.21364)
*Raphael Scheible-Schmitt,Stefan Schweter*

Main category: cs.CL

TL;DR: SindBERT是第一个基于RoBERTa的土耳其语言模型，填补了大规模预训练的空白，展示了在现有基准下的表现和扩展限制。


<details>
  <summary>Details</summary>
Motivation: 填补土耳其自然语言处理（NLP）领域大规模预训练的空白，特别是针对形态丰富语言的需求

Method: 训练RoBERTa基础的编码器模型SindBERT，在312GB土耳其文本上进行预训练

Result: SindBERT在多项任务上表现优于现有土耳其语和多语言模型，尤其是在两个任务中大模型取得最佳成绩，但整体缺乏一致的扩展优势

Conclusion: SindBERT不仅作为土耳其NLP的开放资源贡献，同时也提供了关于扩展限制与语料组成重要性的实证研究。

Abstract: Transformer models have revolutionized NLP, yet many morphologically rich
languages remain underrepresented in large-scale pre-training efforts. With
SindBERT, we set out to chart the seas of Turkish NLP, providing the first
large-scale RoBERTa-based encoder for Turkish. Trained from scratch on 312 GB
of Turkish text (mC4, OSCAR23, Wikipedia), SindBERT is released in both base
and large configurations, representing the first large-scale encoder-only
language model available for Turkish. We evaluate SindBERT on part-of-speech
tagging, named entity recognition, offensive language detection, and the
TurBLiMP linguistic acceptability benchmark. Our results show that SindBERT
performs competitively with existing Turkish and multilingual models, with the
large variant achieving the best scores in two of four tasks but showing no
consistent scaling advantage overall. This flat scaling trend, also observed
for XLM-R and EuroBERT, suggests that current Turkish benchmarks may already be
saturated. At the same time, comparisons with smaller but more curated models
such as BERTurk highlight that corpus quality and diversity can outweigh sheer
data volume. Taken together, SindBERT contributes both as an openly released
resource for Turkish NLP and as an empirical case study on the limits of
scaling and the central role of corpus composition in morphologically rich
languages. The SindBERT models are released under the MIT license and made
available in both fairseq and Huggingface formats.

</details>


### [82] [Vision Language Models for Dynamic Human Activity Recognition in Healthcare Settings](https://arxiv.org/abs/2510.21424)
*Abderrazek Abid,Thanh-Cong Ho,Fakhri Karray*

Main category: cs.CL

TL;DR: 视觉语言模型在远程健康监测的人体活动识别中展现出较强性能，并提出了新的评估方法。


<details>
  <summary>Details</summary>
Motivation: 探讨视觉语言模型在远程健康监测中的应用，特别是在人体活动识别方面的发展与挑战。

Method: 引入描述性字幕数据集，提出全面的评估方法，并与最先进的深度学习模型进行比较实验。

Result: 研究表明，视觉语言模型在准确性上与传统深度学习模型相当，甚至在某些情况下超越了常规方法。

Conclusion: 本研究为智能医疗系统中视觉语言模型的整合提供了强有力的基准，并开启了新的可能性。

Abstract: As generative AI continues to evolve, Vision Language Models (VLMs) have
emerged as promising tools in various healthcare applications. One area that
remains relatively underexplored is their use in human activity recognition
(HAR) for remote health monitoring. VLMs offer notable strengths, including
greater flexibility and the ability to overcome some of the constraints of
traditional deep learning models. However, a key challenge in applying VLMs to
HAR lies in the difficulty of evaluating their dynamic and often
non-deterministic outputs. To address this gap, we introduce a descriptive
caption data set and propose comprehensive evaluation methods to evaluate VLMs
in HAR. Through comparative experiments with state-of-the-art deep learning
models, our findings demonstrate that VLMs achieve comparable performance and,
in some cases, even surpass conventional approaches in terms of accuracy. This
work contributes a strong benchmark and opens new possibilities for the
integration of VLMs into intelligent healthcare systems.

</details>


### [83] [Redefining Retrieval Evaluation in the Era of LLMs](https://arxiv.org/abs/2510.21440)
*Giovanni Trappolini,Florin Cuconasu,Simone Filice,Yoelle Maarek,Fabrizio Silvestri*

Main category: cs.CL

TL;DR: 传统的信息检索指标在处理大规模语言模型时存在局限，因此提出了UDCG指标替代传统指标以更精确地评估检索表现。


<details>
  <summary>Details</summary>
Motivation: 传统IR指标无法准确预测RAG性能，因其未考虑LLM的处理方式与文档的相关性与效用差异。

Method: 引入基于效用的注释方案，量化相关段落的正向贡献和干扰段落的负面影响，基于此方案提出UDCG指标。

Result: 在五个数据集和六个LLM上进行实验，结果显示UDCG指标在相关性评估上比传统指标提高至多36%。

Conclusion: UDCG指标在准确性评估方面表现优于传统的IR指标，能更有效地对齐信息检索与大规模语言模型的消费行为。

Abstract: Traditional Information Retrieval (IR) metrics, such as nDCG, MAP, and MRR,
assume that human users sequentially examine documents with diminishing
attention to lower ranks. This assumption breaks down in Retrieval Augmented
Generation (RAG) systems, where search results are consumed by Large Language
Models (LLMs), which, unlike humans, process all retrieved documents as a whole
rather than sequentially. Additionally, traditional IR metrics do not account
for related but irrelevant documents that actively degrade generation quality,
rather than merely being ignored. Due to these two major misalignments, namely
human vs. machine position discount and human relevance vs. machine utility,
classical IR metrics do not accurately predict RAG performance. We introduce a
utility-based annotation schema that quantifies both the positive contribution
of relevant passages and the negative impact of distracting ones. Building on
this foundation, we propose UDCG (Utility and Distraction-aware Cumulative
Gain), a metric using an LLM-oriented positional discount to directly optimize
the correlation with the end-to-end answer accuracy. Experiments on five
datasets and six LLMs demonstrate that UDCG improves correlation by up to 36%
compared to traditional metrics. Our work provides a critical step toward
aligning IR evaluation with LLM consumers and enables more reliable assessment
of RAG components

</details>


### [84] [REMONI: An Autonomous System Integrating Wearables and Multimodal Large Language Models for Enhanced Remote Health Monitoring](https://arxiv.org/abs/2510.21445)
*Thanh Cong Ho,Farah Kharrat,Abderrazek Abid,Fakhri Karray*

Main category: cs.CL

TL;DR: 本文提出了REMONI远程健康监测系统，旨在提高医疗机构的效率，整合多种技术实现实时监测与交互。


<details>
  <summary>Details</summary>
Motivation: 应对可穿戴设备广泛应用下，远程监测需求的增加，尤其是在改善人机互动方面的不足。

Method: 结合多模态大语言模型、物联网和可穿戴技术，利用异常检测模块和自然语言处理。

Result: 本文提出了一种名为REMONI的远程健康监测系统，旨在填补人机互动方面的空白。该系统集成了多模态大语言模型、物联网和可穿戴设备，能够自动持续收集生命体征、加速度计数据和患者视频剪辑等信息。通过异常检测模块，该系统能识别患者的紧急情况并向护理人员报警。同时，采用自然语言处理技术，使系统能够识别患者的活动和情绪，并回复医护人员的询问。此外，系统提供一个用户友好的网页应用，便于医生和护士实时访问患者的健康状态。实验结果表明，该系统可在现实场景中实施，减少医护人员的工作负担和医疗成本。

Conclusion: REMONI系统在实际场景中可实施且具备可扩展性，有潜力降低医疗工作量和成本。

Abstract: With the widespread adoption of wearable devices in our daily lives, the
demand and appeal for remote patient monitoring have significantly increased.
Most research in this field has concentrated on collecting sensor data,
visualizing it, and analyzing it to detect anomalies in specific diseases such
as diabetes, heart disease and depression. However, this domain has a notable
gap in the aspect of human-machine interaction. This paper proposes REMONI, an
autonomous REmote health MONItoring system that integrates multimodal large
language models (MLLMs), the Internet of Things (IoT), and wearable devices.
The system automatically and continuously collects vital signs, accelerometer
data from a special wearable (such as a smartwatch), and visual data in patient
video clips collected from cameras. This data is processed by an anomaly
detection module, which includes a fall detection model and algorithms to
identify and alert caregivers of the patient's emergency conditions. A
distinctive feature of our proposed system is the natural language processing
component, developed with MLLMs capable of detecting and recognizing a
patient's activity and emotion while responding to healthcare worker's
inquiries. Additionally, prompt engineering is employed to integrate all
patient information seamlessly. As a result, doctors and nurses can access
real-time vital signs and the patient's current state and mood by interacting
with an intelligent agent through a user-friendly web application. Our
experiments demonstrate that our system is implementable and scalable for
real-life scenarios, potentially reducing the workload of medical professionals
and healthcare costs. A full-fledged prototype illustrating the functionalities
of the system has been developed and being tested to demonstrate the robustness
of its various capabilities.

</details>


### [85] [MRO: Enhancing Reasoning in Diffusion Language Models via Multi-Reward Optimization](https://arxiv.org/abs/2510.21473)
*Chenglong Wang,Yang Gan,Hang Zhou,Chi Hu,Yongyu Mu,Kai Song,Murun Yang,Bei Li,Chunliang Zhang,Tongran Liu,Jingbo Zhu,Zhengtao Yu,Tong Xiao*

Main category: cs.CL

TL;DR: 本论文提出了一种多奖励优化方法，旨在提升扩散语言模型的推理性能，通过增强令牌相关性来改善推理能力，同时实现采样速度的显著提升。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型在推理性能上落后于传统大语言模型，主要是由于在去噪步骤中独立生成掩码令牌未能捕捉令牌之间的相关性。

Method: 提出多奖励优化(MRO)方法，通过测试时间缩放、拒绝采样和强化学习来优化令牌相关性，结合群组步骤和重要性采样策略降低奖励方差。

Result: 本论文提出了一种新颖的多奖励优化方法(MRO)，旨在提高扩散语言模型(DLMs)的推理性能。通过定义两种类型的令牌相关性（序列内相关性和序列间相关性），作者指出，通过增强这些相关性，DLMs的推理能力可以得到改善。MRO方法运用测试时间缩放、拒绝采样和强化学习等策略，直接优化令牌相关性，并引入群组步骤和重要性采样策略来降低奖励方差，提高采样效率。实验结果表明，MRO不仅提升了推理性能，还显著加快了采样速度。

Conclusion: MRO方法有效改善了扩散语言模型的推理能力，同时提高了采样效率，为进一步研究DLMs提供了新的思路。

Abstract: Recent advances in diffusion language models (DLMs) have presented a
promising alternative to traditional autoregressive large language models
(LLMs). However, DLMs still lag behind LLMs in reasoning performance,
especially as the number of denoising steps decreases. Our analysis reveals
that this shortcoming arises primarily from the independent generation of
masked tokens across denoising steps, which fails to capture the token
correlation. In this paper, we define two types of token correlation:
intra-sequence correlation and inter-sequence correlation, and demonstrate that
enhancing these correlations improves reasoning performance. To this end, we
propose a Multi-Reward Optimization (MRO) approach, which encourages DLMs to
consider the token correlation during the denoising process. More specifically,
our MRO approach leverages test-time scaling, reject sampling, and
reinforcement learning to directly optimize the token correlation with multiple
elaborate rewards. Additionally, we introduce group step and importance
sampling strategies to mitigate reward variance and enhance sampling
efficiency. Through extensive experiments, we demonstrate that MRO not only
improves reasoning performance but also achieves significant sampling speedups
while maintaining high performance on reasoning benchmarks.

</details>


### [86] [Brain-tuning Improves Generalizability and Efficiency of Brain Alignment in Speech Models](https://arxiv.org/abs/2510.21520)
*Omer Moussa,Mariya Toneva*

Main category: cs.CL

TL;DR: 本研究提出了一种可扩展的脑调优方法，通过微调预训练的语言模型，显著提高了脑部对齐能力及其对新参与者的泛化性，同时改善了在语义任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前的方法在参与者之间的泛化能力有限，而本研究的动机在于解决这一问题，通过引入可扩展的脑调优方法，提高新参与者的预测精度和整体的脑部对齐程度。

Method: 我们引入了一种多参与者脑调优方法，微调预训练的语言模型以联合预测来自多个参与者的fMRI反应，从而改善个体的脑部对齐能力和模型的泛化能力。

Result: 该研究介绍了一种可扩展的脑调优方法，通过对预训练的语音语言模型进行微调，联合预测来自多个参与者的fMRI反应。这种方法显著提高了个人脑部对齐能力，尤其是减少了预测新参与者脑部数据所需的fMRI数据量，同时提高了整体脑部对齐度和对未见数据集的强泛化能力。此外，这种多参与者的脑调优还改善了下游语义任务的表现，表明使用来自多个参与者的脑数据进行训练能够导致更具泛化性的语义表示。这些研究结果展示了神经科学与人工智能之间的双向利益，促进了两个领域的结合。

Conclusion: 我们的结果表明，通过结合多个参与者的脑数据训练模型，可以提升人工智能在语言处理任务上的表现，并为神经科学提供更有效的工具。

Abstract: Pretrained language models are remarkably effective in aligning with human
brain responses elicited by natural language stimuli, positioning them as
promising model organisms for studying language processing in the brain.
However, existing approaches for both estimating and improving this brain
alignment are participant-dependent and highly affected by the amount of data
available per participant, hindering both generalization to new participants
and population-level analyses. In this work, we address these limitations by
introducing a scalable, generalizable brain-tuning method, in which we
fine-tune pretrained speech language models to jointly predict fMRI responses
from multiple participants. We demonstrate that the resulting brain-tuned
models exhibit strong individual brain alignment while generalizing across
participants. Specifically, our method leads to 1) a 5-fold decrease in the
amount of fMRI data needed to predict brain data from new participants, 2) up
to a 50% increase in the overall brain alignment, and 3) strong generalization
to new unseen datasets. Furthermore, this multi-participant brain-tuning
additionally improves downstream performance on semantic tasks, suggesting that
training using brain data from multiple participants leads to more
generalizable semantic representations. Taken together, these findings
demonstrate a bidirectional benefit between neuroscience and AI, helping bridge
the gap between the two fields. We make our code and models publicly available
at https://github.com/bridge-ai-neuro/multi-brain-tuning.

</details>


### [87] [Document Understanding, Measurement, and Manipulation Using Category Theory](https://arxiv.org/abs/2510.21553)
*Jared Claypoole,Yunye Gong,Noson S. Yanofsky,Ajay Divakaran*

Main category: cs.CL

TL;DR: 本研究应用范畴理论提取文档结构，发展信息度量与摘要技术，并通过自监督方法改进大型预训练模型。


<details>
  <summary>Details</summary>
Motivation: 利用范畴理论提取多模态文档结构，以推动信息理论度量、内容摘要和扩展，以及自监督的深度学习模型改进。

Method: 将文档表示为问题-答案对的范畴，并应用正交化程序将多个文档中的信息划分为不重叠的部分。

Result: 开发了新的摘要技术和解决方案（如释经），并提出了一种基于大型预训练模型的多模态扩展框架。

Conclusion: 提出了一种新颖的自监督方法，通过一致性约束提升大型预训练模型，推动了范畴理论在文档处理中的应用。

Abstract: We apply category theory to extract multimodal document structure which leads
us to develop information theoretic measures, content summarization and
extension, and self-supervised improvement of large pretrained models. We first
develop a mathematical representation of a document as a category of
question-answer pairs. Second, we develop an orthogonalization procedure to
divide the information contained in one or more documents into non-overlapping
pieces. The structures extracted in the first and second steps lead us to
develop methods to measure and enumerate the information contained in a
document. We also build on those steps to develop new summarization techniques,
as well as to develop a solution to a new problem viz. exegesis resulting in an
extension of the original document. Our question-answer pair methodology
enables a novel rate distortion analysis of summarization techniques. We
implement our techniques using large pretrained models, and we propose a
multimodal extension of our overall mathematical framework. Finally, we develop
a novel self-supervised method using RLVR to improve large pretrained models
using consistency constraints such as composability and closure under certain
operations that stem naturally from our category theoretic framework.

</details>


### [88] [Are the LLMs Capable of Maintaining at Least the Language Genus?](https://arxiv.org/abs/2510.21561)
*Sandra Mitrović,David Kletz,Ljiljana Dolamic,Fabio Rinaldi*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型在多语言表现中的谱系语言结构影响，结果表明谱系因素和训练数据不平衡共同作用于模型的表现。


<details>
  <summary>Details</summary>
Motivation: 探讨语言谱系结构在大型语言模型多语言行为中的影响，填补现有研究的空白。

Method: 通过分析MultiQ数据集，检验LLMs在不同谱系语言间的切换和知识一致性保持情况。

Result: 本文研究了大型语言模型（LLMs）的多语言行为及其与语言谱系结构的关系。通过MultiQ数据集的分析，发现LLMs在语言之间切换的偏好与语言的谱系相关性有关。研究还表明，知识一致性在同一谱系内部更容易保持，同时不同LLMs家族采用了不同的多语言策略。尽管谱系结构在一定程度上影响了LLMs的表现，但训练数据的不平衡仍是主要的影响因素。

Conclusion: LLMs在其多语言表现中编码了谱系结构的某些方面，但训练数据的不平衡是主要的制约因素。

Abstract: Large Language Models (LLMs) display notable variation in multilingual
behavior, yet the role of genealogical language structure in shaping this
variation remains underexplored. In this paper, we investigate whether LLMs
exhibit sensitivity to linguistic genera by extending prior analyses on the
MultiQ dataset. We first check if models prefer to switch to genealogically
related languages when prompt language fidelity is not maintained. Next, we
investigate whether knowledge consistency is better preserved within than
across genera. We show that genus-level effects are present but strongly
conditioned by training resource availability. We further observe distinct
multilingual strategies across LLMs families. Our findings suggest that LLMs
encode aspects of genus-level structure, but training data imbalances remain
the primary factor shaping their multilingual performance.

</details>


### [89] [From Polyester Girlfriends to Blind Mice: Creating the First Pragmatics Understanding Benchmarks for Slovene](https://arxiv.org/abs/2510.21575)
*Mojca Brglez,Špela Vintar*

Main category: cs.CL

TL;DR: 本研究引入了斯洛文尼亚语的首个语用理解基准，指出当前语言模型在理解细微语言方面存在不足，特别是在非字面表达和文化特定内容的推断上。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型能力的不断增强，亟需更具挑战性的评估标准，超越表面语言能力的考量。

Method: 介绍了翻译中的挑战，建立人类基线的过程，并报告了对大型语言模型的初步评估结果。

Result: 引入了SloPragEval和SloPragMega，这两个斯洛文尼亚语的语用理解基准，包含405个多项选择题。

Conclusion: 语言理解基准需要精心设计，应以本地数据构建，并通过人类回应进行验证。

Abstract: Large language models are demonstrating increasing capabilities, excelling at
benchmarks once considered very difficult. As their capabilities grow, there is
a need for more challenging evaluations that go beyond surface-level linguistic
competence. Namely, language competence involves not only syntax and semantics
but also pragmatics, i.e., understanding situational meaning as shaped by
context as well as linguistic and cultural norms. To contribute to this line of
research, we introduce SloPragEval and SloPragMega, the first pragmatics
understanding benchmarks for Slovene that contain altogether 405
multiple-choice questions. We discuss the difficulties of translation, describe
the campaign to establish a human baseline, and report pilot evaluations with
LLMs. Our results indicate that current models have greatly improved in
understanding nuanced language but may still fail to infer implied speaker
meaning in non-literal utterances, especially those that are culture-specific.
We also observe a significant gap between proprietary and open-source models.
Finally, we argue that benchmarks targeting nuanced language understanding and
knowledge of the target culture must be designed with care, preferably
constructed from native data, and validated with human responses.

</details>


### [90] [Automated Quality Control for Language Documentation: Detecting Phonotactic Inconsistencies in a Kokborok Wordlist](https://arxiv.org/abs/2510.21584)
*Kellen Parker van Dam,Abishek Stephen*

Main category: cs.CL

TL;DR: 本文介绍了一种无监督异常检测方法，用于改进语言文档中的数据质量，特别是在Kokborok和孟加拉语的研究中。


<details>
  <summary>Details</summary>
Motivation: 为了提高语言文档的准确性和可靠性，尤其是存在转录错误和借用词的情况下，更好地支持语言的描述和分析。

Method: 采用无监督学习的方法，通过定义字符级和音节级的音韵特征，识别和标记潜在的转录错误和借用词。

Result: 本文提出的无监督异常检测方法能够识别语言文档中的音韵不一致性，尤其在涉及Kokborok方言和孟加拉语的多语言数据集中应用成效显著。通过使用字符级别和音节级别的音韵特征，算法可以有效识别潜在的转录错误及借用词，尽管由于异常的微妙性，其精准度和召回率较为一般，音节特征显著优于字符级基线。高召回率的方法为田野工作者提供了系统的标记方式，帮助其验证需要审核的条目，进而提升低资源语言文档的质量。

Conclusion: 无监督异常检测方法有效检测语言数据中的音韵不一致性，支持田野工作者验证数据，提高低资源语言文档的质量。

Abstract: Lexical data collection in language documentation often contains
transcription errors and undocumented borrowings that can mislead linguistic
analysis. We present unsupervised anomaly detection methods to identify
phonotactic inconsistencies in wordlists, applying them to a multilingual
dataset of Kokborok varieties with Bangla. Using character-level and
syllable-level phonotactic features, our algorithms identify potential
transcription errors and borrowings. While precision and recall remain modest
due to the subtle nature of these anomalies, syllable-aware features
significantly outperform character-level baselines. The high-recall approach
provides fieldworkers with a systematic method to flag entries requiring
verification, supporting data quality improvement in low-resourced language
documentation.

</details>


### [91] [RETuning: Upgrading Inference-Time Scaling for Stock Movement Prediction with Large Language Models](https://arxiv.org/abs/2510.21604)
*Xueyuan Lin,Cehao Yang,Ye Ma,Ming Li,Rongjunchen Zhang,Yang Ni,Xiaojun Wu,Chengjin Xu,Jian Guo,Hui Xiong*

Main category: cs.CL

TL;DR: 本文探讨了大语言模型在股市预测中的不足并提出RETuning方法，通过建立分析框架提高模型的独立推理能力。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型在金融任务中的应用不足，并通过提出RETuning方法进行优化。

Method: 通过RETuning方法，模型动态构建分析框架，组织和评分证据，实现独立推理。

Result: 本文研究了大语言模型在股市走势预测中的应用，发现其在分析上过度依赖分析师的意见，缺乏系统的独立逻辑。为了解决这一问题，提出了一种新的方法——反思证据调优（RETuning），旨在增强模型的预测能力。该方法在强化学习之前，通过构建动态的分析框架，组织和评分决定股价涨跌的证据，从而促进独立的逻辑推理。实验表明，RETuning 能显著提高模型在金融领域的推理能力，并且即使在离线数据上或时隔六个月后，依然表现良好。

Conclusion: RETuning方法显著提升了大语言模型在股市走势预测中的分析能力，实现了更独立的逻辑思考，并有效应对各种信息来源。

Abstract: Recently, large language models (LLMs) have demonstrated outstanding
reasoning capabilities on mathematical and coding tasks. However, their
application to financial tasks-especially the most fundamental task of stock
movement prediction-remains underexplored. We study a three-class
classification problem (up, hold, down) and, by analyzing existing reasoning
responses, observe that: (1) LLMs follow analysts' opinions rather than exhibit
a systematic, independent analytical logic (CoTs). (2) LLMs list summaries from
different sources without weighing adversarial evidence, yet such
counterevidence is crucial for reliable prediction. It shows that the model
does not make good use of its reasoning ability to complete the task. To
address this, we propose Reflective Evidence Tuning (RETuning), a cold-start
method prior to reinforcement learning, to enhance prediction ability. While
generating CoT, RETuning encourages dynamically constructing an analytical
framework from diverse information sources, organizing and scoring evidence for
price up or down based on that framework-rather than on contextual
viewpoints-and finally reflecting to derive the prediction. This approach
maximally aligns the model with its learned analytical framework, ensuring
independent logical reasoning and reducing undue influence from context. We
also build a large-scale dataset spanning all of 2024 for 5,123 A-share stocks,
with long contexts (32K tokens) and over 200K samples. In addition to price and
news, it incorporates analysts' opinions, quantitative reports, fundamental
data, macroeconomic indicators, and similar stocks. Experiments show that
RETuning successfully unlocks the model's reasoning ability in the financial
domain. Inference-time scaling still works even after 6 months or on
out-of-distribution stocks, since the models gain valuable insights about stock
movement prediction.

</details>


### [92] [The Universal Landscape of Human Reasoning](https://arxiv.org/abs/2510.21623)
*Qiguang Chen,Jinhao Liu,Libo Qin,Yimeng Zhang,Yihao Liang,Shangxu Ren,Chengyu Luan,Dengyun Peng,Hanjing Li,Jiannan Guan,Zheng Yan,Jiaqi Wang,Mengkang Hu,Yantao Du,Zhi Chen,Xie Chen,Wanxiang Che*

Main category: cs.CL

TL;DR: 本文提出信息流追踪（IF-Track），为人类推理行为提供量化模型，揭示推理动态特征。


<details>
  <summary>Details</summary>
Motivation: 理解信息在推理中的动态积累与转化，以应对传统推理模型的局限性。

Method: 引入信息流追踪（IF-Track），利用大型语言模型（LLM）作为概率编码器量化推理过程中的信息熵和信息增益。

Result: IF-Track成功建模人类推理行为的普遍特征，识别系统性错误模式，并刻画个体差异。

Conclusion: 该方法在理论与测量之间建立定量桥梁，为推理机制提供见解。

Abstract: Understanding how information is dynamically accumulated and transformed in
human reasoning has long challenged cognitive psychology, philosophy, and
artificial intelligence. Existing accounts, from classical logic to
probabilistic models, illuminate aspects of output or individual modelling, but
do not offer a unified, quantitative description of general human reasoning
dynamics. To solve this, we introduce Information Flow Tracking (IF-Track),
that uses large language models (LLMs) as probabilistic encoder to quantify
information entropy and gain at each reasoning step. Through fine-grained
analyses across diverse tasks, our method is the first successfully models the
universal landscape of human reasoning behaviors within a single metric space.
We show that IF-Track captures essential reasoning features, identifies
systematic error patterns, and characterizes individual differences. Applied to
discussion of advanced psychological theory, we first reconcile single- versus
dual-process theories in IF-Track and discover the alignment of artificial and
human cognition and how LLMs reshaping human reasoning process. This approach
establishes a quantitative bridge between theory and measurement, offering
mechanistic insights into the architecture of reasoning.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [93] [Incentivizing Consistent, Effective and Scalable Reasoning Capability in Audio LLMs via Reasoning Process Rewards](https://arxiv.org/abs/2510.20867)
*Jiajun Fan,Roger Ren,Jingyuan Li,Rahul Pandey,Prashanth Gurunath Shivakumar,Ivan Bulyko,Ankur Gandhe,Ge Liu,Yile Gu*

Main category: cs.LG

TL;DR: CESAR通过优化推理过程，解决了推理性能下降问题，显著提高了音频大语言模型的推理质量。


<details>
  <summary>Details</summary>
Motivation: 解决推理过程中性能下降的问题，并改善模型的推理质量。

Method: 提出CESAR（Consistent, Effective, and Scalable Audio Reasoners）框架，通过在线强化学习优化推理过程。

Result: 在MMAU Test-mini上取得了领先的表现，超越了Gemini 2.5 Pro和GPT-4o Audio，以及在MMSU推理任务上接近人类水平的表现。

Conclusion: CESAR为音频大语言模型中的推理发展提供了一个有原则的方法，强调了推理质量和多模态能力的协同效应。

Abstract: The role of reasoning in Audio Large Language Models remains widely
underexplored, as introducing a reasoning process often degrades rather than
improves performance during inference, a phenomenon we term test-time inverse
scaling, where longer reasoning chains yield progressively worse results. We
demonstrate that this stems not from fundamental limitations of reasoning
itself, but from inadequate training: models without proper guidance for the
reasoning process produce hallucinatory, inconsistent reasoning that
accumulates errors over longer chains. To address these challenges, we
introduce CESAR (Consistent, Effective, and Scalable Audio Reasoners), shifting
from outcome verification to rewarding the reasoning process. Our online
reinforcement learning framework employs Group Relative Policy Optimization
with a multi-faceted reward suite that incentivizes not only correctness and
format but also consistency, structured analytical patterns, causal reasoning,
domain-knowledge integration, and calibrated reasoning depth. CESAR resolves
test-time inverse scaling, transforming reasoning from detriments into gains
while revealing model-specific ``reasoning sweet spots", where performance
peaks during test-time scaling. We achieve state-of-the-art results on MMAU
Test-mini, substantially outperforming Gemini 2.5 Pro and GPT-4o Audio, and
near-human-level performance on MMSU reasoning tasks. Through AI-as-judge
evaluations and qualitative comparisons, we provide both quantitative and
qualitative validation of our improved reasoning quality. Importantly, enhanced
reasoning creates synergistic effects, simultaneously improving multimodal
reasoning and perception capabilities. Overall, CESAR establishes a principled
method for developing robust and scalable reasoning in Audio LLMs.

</details>


### [94] [MOBO-OSD: Batch Multi-Objective Bayesian Optimization via Orthogonal Search Directions](https://arxiv.org/abs/2510.20872)
*Lam Ngo,Huong Ha,Jeffrey Chan,Hongyu Zhang*

Main category: cs.LG

TL;DR: 提出MOBO-OSD，多目标贝叶斯优化算法，通过多个约束优化问题生成多样化的Pareto最优解，并在多项基准测试中表现优越。


<details>
  <summary>Details</summary>
Motivation: 当前多目标优化问题解决方法不足，急需改进以提高解决方案多样性与性能。

Method: 提出MOBO-OSD算法，解决多个约束优化问题，生成多样的Pareto最优解。

Result: MOBO-OSD在多个合成和真实世界基准函数上表现优于现有最先进算法。

Conclusion: MOBO-OSD提供了一种有效的多目标优化手段，具有较高的解决方案多样性和优化性能。

Abstract: Bayesian Optimization (BO) is a powerful tool for optimizing expensive
black-box objective functions. While extensive research has been conducted on
the single-objective optimization problem, the multi-objective optimization
problem remains challenging. In this paper, we propose MOBO-OSD, a
multi-objective Bayesian Optimization algorithm designed to generate a diverse
set of Pareto optimal solutions by solving multiple constrained optimization
problems, referred to as MOBO-OSD subproblems, along orthogonal search
directions (OSDs) defined with respect to an approximated convex hull of
individual objective minima. By employing a well-distributed set of OSDs,
MOBO-OSD ensures broad coverage of the objective space, enhancing both solution
diversity and hypervolume performance. To further improve the density of the
set of Pareto optimal candidate solutions without requiring an excessive number
of subproblems, we leverage a Pareto Front Estimation technique to generate
additional solutions in the neighborhood of existing solutions. Additionally,
MOBO-OSD supports batch optimization, enabling parallel function evaluations to
accelerate the optimization process when resources are available. Through
extensive experiments and analysis on a variety of synthetic and real-world
benchmark functions with two to six objectives, we demonstrate that MOBO-OSD
consistently outperforms the state-of-the-art algorithms. Our code
implementation can be found at https://github.com/LamNgo1/mobo-osd.

</details>


### [95] [Multimodal Negative Learning](https://arxiv.org/abs/2510.20877)
*Baoquan Gong,Xiyuan Gao,Pengfei Zhu,Qinghua Hu,Bing Cao*

Main category: cs.LG

TL;DR: 提出了多模态负学习框架，解决模态不平衡问题，通过动态指导机制增强弱模态的独特信息保留，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 针对传统的正向学习方法在模态不平衡情况下可能导致弱模态信息压制的问题，提出一种新的负向学习方法。

Method: 通过引入动态指导机制，利用主导模态来抑制非目标类，稳定决策空间，保留模态特有信息。

Result: 实验结果表明，所提出的方法在多项基准测试中有效提升了弱模态的表现，尤其在噪声和不平衡场景下表现出色。

Conclusion: 我们提出的多模态负学习框架有效解决了模态不平衡问题，增强弱模态在复杂场景中的表现。

Abstract: Multimodal learning systems often encounter challenges related to modality
imbalance, where a dominant modality may overshadow others, thereby hindering
the learning of weak modalities. Conventional approaches often force weak
modalities to align with dominant ones in "Learning to be (the same)" (Positive
Learning), which risks suppressing the unique information inherent in the weak
modalities. To address this challenge, we offer a new learning paradigm:
"Learning Not to be" (Negative Learning). Instead of enhancing weak modalities'
target-class predictions, the dominant modalities dynamically guide the weak
modality to suppress non-target classes. This stabilizes the decision space and
preserves modality-specific information, allowing weak modalities to preserve
unique information without being over-aligned. We proceed to reveal multimodal
learning from a robustness perspective and theoretically derive the Multimodal
Negative Learning (MNL) framework, which introduces a dynamic guidance
mechanism tailored for negative learning. Our method provably tightens the
robustness lower bound of multimodal learning by increasing the Unimodal
Confidence Margin (UCoM) and reduces the empirical error of weak modalities,
particularly under noisy and imbalanced scenarios. Extensive experiments across
multiple benchmarks demonstrate the effectiveness and generalizability of our
approach against competing methods. The code will be available at
https://github.com/BaoquanGong/Multimodal-Negative-Learning.git.

</details>


### [96] [HA-RAG: Hotness-Aware RAG Acceleration via Mixed Precision and Data Placement](https://arxiv.org/abs/2510.20878)
*Danying Ge,Jianhua Gao,Yixue Yang,Weixing Ji*

Main category: cs.LG

TL;DR: 本文提出热度感知RAG（HA-RAG）推理优化系统，通过压缩和数据放置策略提升长上下文处理效能。


<details>
  <summary>Details</summary>
Motivation: 解决长上下文处理中RAG面临的内存消耗和推理延迟问题。

Method: 提出了热度感知的混合精度压缩和加载方法以及数据放置策略。

Result: HA-RAG相较于TurboRAG在首个输出时间上平均加速2.10倍，最大加速10.49倍。

Conclusion: HA-RAG系统显著提高了推理速度，并仅带来微小的准确性损失。

Abstract: Retrieval-Augmented Generation (RAG) improves model output accuracy by
leveraging external knowledge bases, serving as an effective solution to
address hallucination issues and knowledge-update delays in Large Language
Models (LLMs). However, the introduction of external knowledge bases presents
RAG with challenges in long-context processing, significantly increasing memory
consumption and inference latency. Existing research accelerates inference by
precomputing Key and Value (KV) of the knowledge base and loading them
on-demand during inference. Based on the access frequency of different KV
chunks within the external knowledge base, this paper proposes a hotness-aware
RAG (HA-RAG) inference optimization system. First, leveraging the numerical
distribution of KV chunks, we introduce a hotness-aware mixed-precision
compressing and loading method to reduce disk I/O and memory access overhead.
Second, we design a hotness-aware data placement strategy that prioritizes
storing frequently accessed KV chunks in high-speed memory to improve data
access efficiency. Experimental results demonstrate that, compared with
TurboRAG, the proposed HA-RAG achieves an average speedup of 2.10x and maximum
speedup of 10.49x in Time-To-First-Token (TTFT) with negligible accuracy loss.

</details>


### [97] [Global Dynamics of Heavy-Tailed SGDs in Nonconvex Loss Landscape: Characterization and Control](https://arxiv.org/abs/2510.20905)
*Xingyu Wang,Chang-Han Rhee*

Main category: cs.LG

TL;DR: 通过新技术分析重尾SGD的全局动态，证明其可以避免尖锐局部最小并提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 理解随机梯度下降(SGD)的全局动态，以改善其在损失景观中避免尖锐局部最小值的能力

Method: 基于大偏差理论和亚稳态分析的方法

Result: 提出了一种新的方法，通过注入和截断重尾噪声，SGD能够有效规避尖锐局部最小值，从而提高泛化性能

Conclusion: 重尾SGD在梯度裁剪下找到更加平坦的局部最小值，表现出更好的泛化性能。

Abstract: Stochastic gradient descent (SGD) and its variants enable modern artificial
intelligence. However, theoretical understanding lags far behind their
empirical success. It is widely believed that SGD has a curious ability to
avoid sharp local minima in the loss landscape, which are associated with poor
generalization. To unravel this mystery and further enhance such capability of
SGDs, it is imperative to go beyond the traditional local convergence analysis
and obtain a comprehensive understanding of SGDs' global dynamics. In this
paper, we develop a set of technical machinery based on the recent large
deviations and metastability analysis in Wang and Rhee (2023) and obtain sharp
characterization of the global dynamics of heavy-tailed SGDs. In particular, we
reveal a fascinating phenomenon in deep learning: by injecting and then
truncating heavy-tailed noises during the training phase, SGD can almost
completely avoid sharp minima and achieve better generalization performance for
the test data. Simulation and deep learning experiments confirm our theoretical
prediction that heavy-tailed SGD with gradient clipping finds local minima with
a more flat geometry and achieves better generalization performance.

</details>


### [98] [Learning from Interval Targets](https://arxiv.org/abs/2510.20925)
*Rattana Pukdee,Ziqi Ke,Chirag Gupta*

Main category: cs.LG

TL;DR: 本文研究了区间目标回归问题，提出兼容的损失函数和新的学习框架，并在实际数据集上实现了优秀的结果。


<details>
  <summary>Details</summary>
Motivation: 针对获取确切目标标签存在困难或代价高昂的情况，研究区间目标回归问题。

Method: 采用与区间目标兼容的损失函数，并引入新的最小-最大学习公式，以应对给定区间内的最坏情况目标标签。

Result: 通过理论分析和实证研究，提出的解决方案在性能上达到了当前最优水平。

Conclusion: 该研究提出了一种处理区间目标回归问题的新方法，并在实际数据集上展示了其优越的性能。

Abstract: We study the problem of regression with interval targets, where only upper
and lower bounds on target values are available in the form of intervals. This
problem arises when the exact target label is expensive or impossible to
obtain, due to inherent uncertainties. In the absence of exact targets,
traditional regression loss functions cannot be used. First, we study the
methodology of using a loss functions compatible with interval targets, for
which we establish non-asymptotic generalization bounds based on smoothness of
the hypothesis class that significantly relaxing prior assumptions of
realizability and small ambiguity degree. Second, we propose a novel min-max
learning formulation: minimize against the worst-case (maximized) target labels
within the provided intervals. The maximization problem in the latter is
non-convex, but we show that good performance can be achieved with the
incorporation of smoothness constraints. Finally, we perform extensive
experiments on real-world datasets and show that our methods achieve
state-of-the-art performance.

</details>


### [99] [Meta-Learning for Cross-Task Generalization in Protein Mutation Property Prediction](https://arxiv.org/abs/2510.20943)
*Srivathsan Badrinarayanan,Yue Su,Janghoon Ock,Alan Pham,Sanya Ahuja,Amir Barati Farimani*

Main category: cs.LG

TL;DR: 本文提出将MAML应用于蛋白质突变预测，并引入新的突变编码策略，显著提高了预测准确性和训练效率。


<details>
  <summary>Details</summary>
Motivation: 蛋白质突变对生物功能的影响深远，因此准确预测其属性变化对药物发现和精密医学至关重要。当前方法在跨数据集推广方面存在困难，亟需更有效的解决方案。

Method: 研究结合了模型无关的元学习（MAML）与新的突变编码策略，构建在变换器架构上，以提高对新任务的快速适应能力。

Result: 该研究提出了一种新的蛋白质突变属性预测方法，结合了模型无关的元学习（MAML）和一种新的突变编码策略，以提高跨数据集的通用性与效率。通过对三种不同的蛋白质突变数据集进行评估，结果显示该方法在功能适应性和溶解性上显著提升了预测准确性，并减少了训练时间。

Conclusion: 本研究建立了元学习在蛋白质突变分析中的系统应用，提供了一种有效的突变编码策略，为蛋白质工程的跨领域推广提供了变革性的方法。

Abstract: Protein mutations can have profound effects on biological function, making
accurate prediction of property changes critical for drug discovery, protein
engineering, and precision medicine. Current approaches rely on fine-tuning
protein-specific transformers for individual datasets, but struggle with
cross-dataset generalization due to heterogeneous experimental conditions and
limited target domain data. We introduce two key innovations: (1) the first
application of Model-Agnostic Meta-Learning (MAML) to protein mutation property
prediction, and (2) a novel mutation encoding strategy using separator tokens
to directly incorporate mutations into sequence context. We build upon
transformer architectures integrating them with MAML to enable rapid adaptation
to new tasks through minimal gradient steps rather than learning
dataset-specific patterns. Our mutation encoding addresses the critical
limitation where standard transformers treat mutation positions as unknown
tokens, significantly degrading performance. Evaluation across three diverse
protein mutation datasets (functional fitness, thermal stability, and
solubility) demonstrates significant advantages over traditional fine-tuning.
In cross-task evaluation, our meta-learning approach achieves 29% better
accuracy for functional fitness with 65% less training time, and 94% better
accuracy for solubility with 55% faster training. The framework maintains
consistent training efficiency regardless of dataset size, making it
particularly valuable for industrial applications and early-stage protein
design where experimental data is limited. This work establishes a systematic
application of meta-learning to protein mutation analysis and introduces an
effective mutation encoding strategy, offering transformative methodology for
cross-domain generalization in protein engineering.

</details>


### [100] [Assessing the Real-World Utility of Explainable AI for Arousal Diagnostics: An Application-Grounded User Study](https://arxiv.org/abs/2510.21389)
*Stefan Kraft,Andreas Theissler,Vera Wienhausen-Wilke,Gjergji Kasneci,Hendrik Lensch*

Main category: cs.LG

TL;DR: 该研究探讨了透明AI辅助在临床睡眠医学中的应用，发现其在提高准确性与效率方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了有效融合人工智能系统于临床实践，需要理解临床医生在何时和为何信任算法推荐。

Method: 应用驱动的用户研究

Result: AI和人类-AI团队相比于无辅助专家表现显著提升，且协作减少了评分者间的变异性。透明的AI辅助在质量控制步骤中，实现了事件级表现提高约30%。

Conclusion: 战略性及时的透明AI辅助为信任的AI整合提供了有效路径，增强了临床工作流程中的用户接受度。

Abstract: Artificial intelligence (AI) systems increasingly match or surpass human
experts in biomedical signal interpretation. However, their effective
integration into clinical practice requires more than high predictive accuracy.
Clinicians must discern \textit{when} and \textit{why} to trust algorithmic
recommendations. This work presents an application-grounded user study with
eight professional sleep medicine practitioners, who score nocturnal arousal
events in polysomnographic data under three conditions: (i) manual scoring,
(ii) black-box (BB) AI assistance, and (iii) transparent white-box (WB) AI
assistance. Assistance is provided either from the \textit{start} of scoring or
as a post-hoc quality-control (\textit{QC}) review. We systematically evaluate
how the type and timing of assistance influence event-level and clinically most
relevant count-based performance, time requirements, and user experience. When
evaluated against the clinical standard used to train the AI, both AI and
human-AI teams significantly outperform unaided experts, with collaboration
also reducing inter-rater variability. Notably, transparent AI assistance
applied as a targeted QC step yields median event-level performance
improvements of approximately 30\% over black-box assistance, and QC timing
further enhances count-based outcomes. While WB and QC approaches increase the
time required for scoring, start-time assistance is faster and preferred by
most participants. Participants overwhelmingly favor transparency, with seven
out of eight expressing willingness to adopt the system with minor or no
modifications. In summary, strategically timed transparent AI assistance
effectively balances accuracy and clinical efficiency, providing a promising
pathway toward trustworthy AI integration and user acceptance in clinical
workflows.

</details>


### [101] [Safety Assessment in Reinforcement Learning via Model Predictive Control](https://arxiv.org/abs/2510.20955)
*Jeff Pflueger,Michael Everett*

Main category: cs.LG

TL;DR: 提出一种基于逆可逆性的模型无关强化学习方法，通过模型预测路径积分控制检查安全性，实验表明该算法有效保证安全性并与传统方法训练进展相当。


<details>
  <summary>Details</summary>
Motivation: 鉴于现有方法对安全规格的详细知识依赖较大，本研究旨在通过逆可逆性来解决难以明确指定的安全问题。

Method: 使用模型预测路径积分控制来检查训练过程中学习策略提出的动作的安全性，侧重于逆可逆性。

Result: 该研究提出了一种模型无关的强化学习方法，以解决传统控制方法缺乏安全保障的问题。最重要的是，该方法利用逆可逆性作为防止安全问题的手段，提出一种基于模型预测路径积分控制的算法来在训练过程中检查所提议的动作的安全性。实验结果表明，该算法能够在不安全行为发生前提前中止，同时在训练进展上与传统的PPO方法相当，即使后者可以违反安全性规定。

Conclusion: 该算法有效地解决了模型无关强化学习在安全性方面的缺陷，能够在保持训练效率的同时避免不安全行为的发生。

Abstract: Model-free reinforcement learning approaches are promising for control but
typically lack formal safety guarantees. Existing methods to shield or
otherwise provide these guarantees often rely on detailed knowledge of the
safety specifications. Instead, this work's insight is that many
difficult-to-specify safety issues are best characterized by invariance.
Accordingly, we propose to leverage reversibility as a method for preventing
these safety issues throughout the training process. Our method uses
model-predictive path integral control to check the safety of an action
proposed by a learned policy throughout training. A key advantage of this
approach is that it only requires the ability to query the black-box dynamics,
not explicit knowledge of the dynamics or safety constraints. Experimental
results demonstrate that the proposed algorithm successfully aborts before all
unsafe actions, while still achieving comparable training progress to a
baseline PPO approach that is allowed to violate safety.

</details>


### [102] [An Ensembled Penalized Federated Learning Framework for Falling People Detection](https://arxiv.org/abs/2510.20960)
*Sizhe Rao,Runqiu Zhang,Sajal Saha,Liang Chen*

Main category: cs.LG

TL;DR: EPFL是一个为老年人和残疾人士设计的高效、隐私保护的跌倒检测框架，表现优异。


<details>
  <summary>Details</summary>
Motivation: 针对现有跌倒检测方法的局限性，如可泛化性差与数据隐私问题，设计更好的解决方案。

Method: 提出了一种集成式惩罚性联邦学习方法，结合个性化建模和动态加权聚合，利用可穿戴传感器进行运动模式捕捉。

Result: 本论文提出了EPFL，一个集成了持续学习、个性化建模和特殊加权聚合(SWA)策略的惩罚性联邦学习框架，用于老年人和残疾人跌倒检测。该框架利用可穿戴传感器数据捕捉运动模式，同时通过同态加密和联邦训练保护用户隐私。实验结果表明，EPFL在跌倒检测数据集上表现出色，召回率达到88.31%，F1-score为89.94%，显著优于传统集成和基线模型。

Conclusion: EPFL展示了在医疗环境中实现安全、准确和可扩展的跌倒检测的潜力，具有持续改进的能力。

Abstract: Falls among elderly and disabled individuals remain a leading cause of injury
and mortality worldwide, necessitating robust, accurate, and privacy-aware fall
detection systems. Traditional fall detection approaches, whether centralized
or point-wise, often struggle with key challenges such as limited
generalizability, data privacy concerns, and variability in individual movement
behaviors. To address these limitations, we propose EPFL-an Ensembled Penalized
Federated Learning framework that integrates continual learning, personalized
modeling, and a novel Specialized Weighted Aggregation (SWA) strategy. EPFL
leverages wearable sensor data to capture sequential motion patterns while
preserving user privacy through homomorphic encryption and federated training.
Unlike existing federated models, EPFL incorporates both penalized local
training and ensemble-based inference to improve inter-client consistency and
adaptability to behavioral differences. Extensive experiments on a benchmark
fall detection dataset demonstrate the effectiveness of our approach, achieving
a Recall of 88.31 percent and an F1-score of 89.94 percent, significantly
outperforming both centralized and baseline models. This work presents a
scalable, secure, and accurate solution for real-world fall detection in
healthcare settings, with strong potential for continuous improvement via its
adaptive feedback mechanism.

</details>


### [103] [Neural Mutual Information Estimation with Vector Copulas](https://arxiv.org/abs/2510.20968)
*Yanzhi Chen,Zijing Ou,Adrian Weller,Michael U. Gutmann*

Main category: cs.LG

TL;DR: 提出一种基于向量copula理论的互信息估计器，兼顾复杂性与容量。


<details>
  <summary>Details</summary>
Motivation: 现有估计器在数据需求和模型复杂度之间存在权衡，因此需要一种新的方法来解决这一问题。

Method: 通过向量copula理论，进行高度灵活模型和过于简化模型之间的插值。

Result: 本文提出了一种新的互信息估计方法，基于近期的向量copula理论，旨在提升现有互信息估计器在复杂性与容量之间的平衡。

Conclusion: 该方法在合成基准和实际多模态数据上表现出较好的性能，优于现有的估计方法。

Abstract: Estimating mutual information (MI) is a fundamental task in data science and
machine learning. Existing estimators mainly rely on either highly flexible
models (e.g., neural networks), which require large amounts of data, or overly
simplified models (e.g., Gaussian copula), which fail to capture complex
distributions. Drawing upon recent vector copula theory, we propose a
principled interpolation between these two extremes to achieve a better
trade-off between complexity and capacity. Experiments on state-of-the-art
synthetic benchmarks and real-world data with diverse modalities demonstrate
the advantages of the proposed estimator.

</details>


### [104] [On the accuracy of implicit neural representations for cardiovascular anatomies and hemodynamic fields](https://arxiv.org/abs/2510.20970)
*Jubilee Lee,Daniele E. Schiavazzi*

Main category: cs.LG

TL;DR: 隐式神经表示（INRs）在血流动力学场和心血管解剖表示方面表现优异，达到高压缩比和低误差。


<details>
  <summary>Details</summary>
Motivation: 探讨INRs在特定领域应用中的准确性及其表现，尤其是在血流动力学场和心血管解剖表示的上下文中。

Method: 评估最先进的隐式神经表示（INRs）在压缩血流动力学场的表现

Result: INRs在胸主动脉的实际空间和时间变化的血流动力学场中实现了高达230的压缩比，压力的最大绝对误差为1 mmHg，速度为5-10 cm/s，且未经过多的超参数调优。

Conclusion: SIREN、MFN-Gabor和MHE架构在测试中表现最佳，显示出INRs在医学领域应用的潜力。

Abstract: Implicit neural representations (INRs, also known as neural fields) have
recently emerged as a powerful framework for knowledge representation,
synthesis, and compression. By encoding fields as continuous functions within
the weights and biases of deep neural networks-rather than relying on voxel- or
mesh-based structured or unstructured representations-INRs offer both
resolution independence and high memory efficiency. However, their accuracy in
domain-specific applications remains insufficiently understood. In this work,
we assess the performance of state-of-the-art INRs for compressing hemodynamic
fields derived from numerical simulations and for representing cardiovascular
anatomies via signed distance functions. We investigate several strategies to
mitigate spectral bias, including specialized activation functions, both fixed
and trainable positional encoding, and linear combinations of nonlinear
kernels. On realistic, space- and time-varying hemodynamic fields in the
thoracic aorta, INRs achieved remarkable compression ratios of up to
approximately 230, with maximum absolute errors of 1 mmHg for pressure and 5-10
cm/s for velocity, without extensive hyperparameter tuning. Across 48 thoracic
aortic anatomies, the average and maximum absolute anatomical discrepancies
were below 0.5 mm and 1.6 mm, respectively. Overall, the SIREN, MFN-Gabor, and
MHE architectures demonstrated the best performance. Source code and data is
available at https://github.com/desResLab/nrf.

</details>


### [105] [L^2M^3OF: A Large Language Multimodal Model for Metal-Organic Frameworks](https://arxiv.org/abs/2510.20976)
*Jiyu Cui,Fang Wu,Haokai Zhao,Minggao Feng,Xenophon Evangelopoulos,Andrew I. Cooper,Yejin Choi*

Main category: cs.LG

TL;DR: L2M3OF是一种针对金属有机框架(MOF)的多模态大语言模型，通过结合晶体表示学习与语言理解，有效提升了材料发现中的性能，尤其在性质预测和知识生成方面超过了现有的文本基闭源模型。


<details>
  <summary>Details</summary>
Motivation: 科学发现中的复杂物理现象需要超越单一语言的多方面表征，而L2M3OF旨在克服MOF设计中依赖隐性人类专业知识的难题。

Method: L2M3OF结合了晶体表示学习与语言理解，通过预训练的晶体编码器和轻量投影层共同处理结构、文本及知识模态。

Result: L2M3OF在性质预测和知识生成任务中优于领先的文本基闭源大语言模型，同时使用的参数量更少。

Conclusion: L2M3OF展示了多模态方法在理解多孔材料中的重要性，为下一代材料发现的人工智能系统奠定了基础。

Abstract: Large language models have demonstrated remarkable reasoning capabilities
across diverse natural language tasks. However, comparable breakthroughs in
scientific discovery are more limited, because understanding complex physical
phenomena demands multifaceted representations far beyond language alone. A
compelling example is the design of functional materials such as MOFs-critical
for a range of impactful applications like carbon capture and hydrogen storage.
Navigating their vast and intricate design space in language-based
representations interpretable by LLMs is challenging due to the numerous
possible three-dimensional atomic arrangements and strict reticular rules of
coordination geometry and topology. Despite promising early results in
LLM-assisted discovery for simpler materials systems, MOF design remains
heavily reliant on tacit human expertise rarely codified in textual information
alone. To overcome this barrier, we introduce L2M3OF, the first multimodal LLM
for MOFs. L2M3OF integrates crystal representation learning with language
understanding to process structural, textual, and knowledge modalities jointly.
L2M3OF employs a pre-trained crystal encoder with a lightweight projection
layer to compress structural information into a token space, enabling efficient
alignment with language instructions. To facilitate training and evaluation, we
curate a structure-property-knowledge database of crystalline materials and
benchmark L2M3OF against state-of-the-art closed-source LLMs such as GPT-5,
Gemini-2.5-Pro and DeepSeek-R1. Experiments show that L2M3OF outperforms
leading text-based closed-source LLMs in property prediction and knowledge
generation tasks, despite using far fewer parameters. These results highlight
the importance of multimodal approaches for porous material understanding and
establish L2M3OF as a foundation for next-generation AI systems in materials
discovery.

</details>


### [106] [Memory Constrained Dynamic Subnetwork Update for Transfer Learning](https://arxiv.org/abs/2510.20979)
*Aël Quélennec,Pavlo Mozharovskyi,Van-Tam Nguyen,Enzo Tartaglione*

Main category: cs.LG

TL;DR: MeDyate是一个新的方法，优化内存使用以提高模型在有限资源下的表现。


<details>
  <summary>Details</summary>
Motivation: 解决预训练模型在下游任务中的适应性受到内存限制的挑战。

Method: 提出MeDyate框架，结合LaRa和动态通道采样策略以适应内存限制的情况。

Result: MeDyate在极端内存限制下展现了先进性能，超越现有静态和动态方法，同时保持高计算效率。

Conclusion: MeDyate为实现高效的设备学习提供了重要进展，能够在极低内存预算下进行有效的微调。

Abstract: On-device neural network training faces critical memory constraints that
limit the adaptation of pre-trained models to downstream tasks. We present
MeDyate, a theoretically-grounded framework for memory-constrained dynamic
subnetwork adaptation. Our approach introduces two key innovations: LaRa (Layer
Ranking), an improved layer importance metric that enables principled layer
pre-selection, and a dynamic channel sampling strategy that exploits the
temporal stability of channel importance distributions during fine-tuning.
MeDyate dynamically resamples channels between epochs according to
importance-weighted probabilities, ensuring comprehensive parameter space
exploration while respecting strict memory budgets. Extensive evaluation across
a large panel of tasks and architectures demonstrates that MeDyate achieves
state-of-the-art performance under extreme memory constraints, consistently
outperforming existing static and dynamic approaches while maintaining high
computational efficiency. Our method represents a significant step towards
enabling efficient on-device learning by demonstrating effective fine-tuning
with memory budgets as low as a few hundred kB of RAM.

</details>


### [107] [Learning Grouped Lattice Vector Quantizers for Low-Bit LLM Compression](https://arxiv.org/abs/2510.20984)
*Xi Zhang,Xiaolin Wu,Jiamang Wang,Weisi Lin*

Main category: cs.LG

TL;DR: 提出了一种分组格量化（GLVQ）框架，提高大规模语言模型推理效率，减小资源需求，且在模型大小与准确性之间取得更好平衡。


<details>
  <summary>Details</summary>
Motivation: 针对传统均匀量化在低比特情况下性能下降的问题，提出一种有效的量化方法，以满足大规模语言模型在资源受限条件下的应用需求。

Method: 引入分组格量化（GLVQ），为每组权重设置定制的格代码本，并使用Babai舍入近似寻找最近格点，进行生成矩阵的训练优化。

Result: 本研究提出了一种新的分组格量化（GLVQ）框架，用于提高大规模语言模型（LLMs）在推理过程中的效率。通过为每组权重分配定制的格代码本，GLVQ框架能够有效减少计算资源和内存需求。我们使用Babai舍入方法来处理量化过程的不可微分性，从而实现生成矩阵的稳定优化。实验结果表明，GLVQ在模型大小和准确性之间实现了更好的平衡，适用于在资源有限的情况下部署较大模型。

Conclusion: GLVQ在后训练量化的基准测试中表现优越，适应性强，适用于资源有限的环境。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities but
typically require extensive computational resources and memory for inference.
Post-training quantization (PTQ) can effectively reduce these demands by
storing weights in lower bit-width formats. However, standard uniform
quantization often leads to notable performance degradation, particularly in
low-bit scenarios. In this work, we introduce a Grouped Lattice Vector
Quantization (GLVQ) framework that assigns each group of weights a customized
lattice codebook, defined by a learnable generation matrix. To address the
non-differentiability of the quantization process, we adopt Babai rounding to
approximate nearest-lattice-point search during training, which enables stable
optimization of the generation matrices. Once trained, decoding reduces to a
simple matrix-vector multiplication, yielding an efficient and practical
quantization pipeline. Experiments on multiple benchmarks show that our
approach achieves a better trade-off between model size and accuracy compared
to existing post-training quantization baselines, highlighting its
effectiveness in deploying large models under stringent resource constraints.
Our source code is available on GitHub repository:
https://github.com/xzhang9308/GLVQ.

</details>


### [108] [GPU Memory Requirement Prediction for Deep Learning Task Based on Bidirectional Gated Recurrent Unit Optimization Transformer](https://arxiv.org/abs/2510.20985)
*Chao Wang,Zhizhao Wen,Ruoxin Zhang,Puyang Xu,Yifan Jiang*

Main category: cs.LG

TL;DR: 本文提出了一种基于BiGRU优化的Transformer模型，用于提高GPU内存需求预测的准确性，实验结果显示该模型在各项指标上均优于传统机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 应对对深度学习任务中GPU内存资源准确预测日益增加的需求。

Method: 提出了一种整合双向门控递归单元的深度学习模型，优化了Transformer架构，并通过比较实验验证了模型的有效性。

Result: 这篇论文提出了一种创新的深度学习模型，采用双向门控递归单元（BiGRU）优化了Transformer架构，以提高GPU内存需求预测的准确性。通过与四种基本机器学习模型的比较实验，结果表明该模型在均方误差（MSE）、均方根误差（RMSE）以及平均绝对误差（MAE）等关键评估指标上表现优异，预测结果与实际值的偏差最小，并且综合预测性能远超传统机器学习方法。

Conclusion: 基于双向门控递归单元优化的Transformer模型在GPU内存需求预测任务中实现了显著的准确性提升，为深度学习任务的资源调度与管理提供了可靠的理论支持。

Abstract: In response to the increasingly critical demand for accurate prediction of
GPU memory resources in deep learning tasks, this paper deeply analyzes the
current research status and innovatively proposes a deep learning model that
integrates bidirectional gated recurrent units (BiGRU) to optimize the
Transformer architecture, aiming to improve the accuracy of memory demand
prediction. To verify the effectiveness of the model, a carefully designed
comparative experiment was conducted, selecting four representative basic
machine learning models: decision tree, random forest, Adaboost, and XGBoost as
benchmarks. The detailed experimental results show that the BiGRU Transformer
optimization model proposed in this paper exhibits significant advantages in
key evaluation indicators: in terms of mean square error (MSE) and root mean
square error (RMSE), the model achieves the lowest value among all comparison
models, and its predicted results have the smallest deviation from the actual
values; In terms of mean absolute error (MAE) and coefficient of determination
(R2) indicators, the model also performs well and the results are balanced and
stable, with comprehensive predictive performance far exceeding the benchmark
machine learning methods compared. In summary, the Transformer model based on
bidirectional gated recurrent unit optimization successfully constructed in
this study can efficiently and accurately complete GPU memory demand prediction
tasks in deep learning tasks, and its prediction accuracy has been
significantly improved compared to traditional machine learning methods. This
research provides strong technical support and reliable theoretical basis for
optimizing resource scheduling and management of deep learning tasks, and
improving the utilization efficiency of computing clusters.

</details>


### [109] [AL-CoLe: Augmented Lagrangian for Constrained Learning](https://arxiv.org/abs/2510.20995)
*Ignacio Boero,Ignacio Hounie,Alejandro Ribeiro*

Main category: cs.LG

TL;DR: 增强拉格朗日方法在非凸约束学习中有效，可以解决对偶间隙问题并保证收敛性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 针对现代机器学习参数化的非凸性以及对约束学习问题的解决能力改善方法

Method: 重访增强拉格朗日方法

Result: 在轻微条件下建立了强对偶性结果，证明了对偶上升算法收敛到可行及最优的原始解，并提供 PAC 风格的泛化保证。

Conclusion: 增强拉格朗日方法在公平分类任务中的有效性得到了验证，并为非凸约束学习提供了理论支持。

Abstract: Despite the non-convexity of most modern machine learning parameterizations,
Lagrangian duality has become a popular tool for addressing constrained
learning problems. We revisit Augmented Lagrangian methods, which aim to
mitigate the duality gap in non-convex settings while requiring only minimal
modifications, and have remained comparably unexplored in constrained learning
settings. We establish strong duality results under mild conditions, prove
convergence of dual ascent algorithms to feasible and optimal primal solutions,
and provide PAC-style generalization guarantees. Finally, we demonstrate its
effectiveness on fairness constrained classification tasks.

</details>


### [110] [Fair Representation Learning with Controllable High Confidence Guarantees via Adversarial Inference](https://arxiv.org/abs/2510.21017)
*Yuhong Luo,Austin Hoag,Xintong Wang,Philip S. Thomas,Przemyslaw A. Grabowicz*

Main category: cs.LG

TL;DR: 提出FRG框架，通过优化对抗模型确保代表学习中的高置信度公平性保障，并在实证中优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 代表学习在多个下游任务中应用广泛，但缺乏公平性保障可能导致对特定群体的不公正对待。

Method: 提出FRG框架，通过一种优化的对抗模型实现高置信度的公平性保障。

Result: FRG框架在多个真实世界数据集上表现优越，能够有效控制不公正性。

Conclusion: FRG方法在不同下游模型和任务下，始终能够有效限制不公平性。

Abstract: Representation learning is increasingly applied to generate representations
that generalize well across multiple downstream tasks. Ensuring fairness
guarantees in representation learning is crucial to prevent unfairness toward
specific demographic groups in downstream tasks. In this work, we formally
introduce the task of learning representations that achieve high-confidence
fairness. We aim to guarantee that demographic disparity in every downstream
prediction remains bounded by a *user-defined* error threshold $\epsilon$, with
*controllable* high probability. To this end, we propose the ***F**air
**R**epresentation learning with high-confidence **G**uarantees (FRG)*
framework, which provides these high-confidence fairness guarantees by
leveraging an optimized adversarial model. We empirically evaluate FRG on three
real-world datasets, comparing its performance to six state-of-the-art fair
representation learning methods. Our results demonstrate that FRG consistently
bounds unfairness across a range of downstream models and tasks.

</details>


### [111] [More Than Memory Savings: Zeroth-Order Optimization Mitigates Forgetting in Continual Learning](https://arxiv.org/abs/2510.21019)
*Wanhao Yu,Zheng Wang,Shuteng Niu,Sen Lin,Li Yang*

Main category: cs.LG

TL;DR: 本文探讨了ZO优化在持续学习中的应用，发现其在提高稳定性的同时降低了塑性，提出了ZO-FC方法以平衡二者，并展示了其在设备端的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究ZO优化在持续学习中的潜力，以应对塑性、稳定性和效率之间的权衡。

Method: 通过理论分析和实证评估，比较ZO优化与FO优化在持续学习中的表现，提出并测试了ZO-FC方法。

Result: 该论文研究了零阶（ZO）优化在持续学习（CL）中的应用，作为一种内存高效的替代方案，尤其在梯度计算昂贵或不切实际的环境中。通过理论分析和实证证据，发现ZO优化可以自然产生更平坦的损失曲面，从而减少CL中的遗忘。然而，这种稳定性伴随着塑性损失，ZO优化在获取新的任务知识时不如一阶（FO）优化有效, 尤其是在受限的训练预算下。为深入理解这种权衡，本文对ZO优化在多种现存CL方法中的应用进行了全面评估。结果表明，ZO优化提高了稳定性，但在使用可学习分类器时往往削弱了塑性。基于此发现，本文提出了ZO-FC，一种将ZO优化应用于单一适配器基础的PEFT模块与FO优化分类器的简单有效方法。该设计利用ZO的稳定性优势，同时保持FO更新的适应性，几乎没有内存开销。实验表明，ZO-FC在稳定性和塑性之间实现了有效平衡，提供了一个实用且内存高效的设备端CL解决方案。

Conclusion: ZO-FC方法在稳定性与塑性之间达到了有效平衡，适用于内存受限的持续学习场景。

Abstract: Zeroth-order (ZO) optimization has gained attention as a memory-efficient
alternative to first-order (FO) methods, particularly in settings where
gradient computation is expensive or even impractical. Beyond its memory
efficiency, in this work, we investigate ZO optimization for continual learning
(CL) as a novel approach to address the plasticity-stability-efficiency
trilemma. Through theoretical analysis and empirical evidence, we show that ZO
optimization naturally leads to flatter loss landscapes, which in turn reduce
forgetting in CL. However, this stability comes at a cost of plasticity: due to
its imprecise gradient estimates and slower convergence, ZO optimization tends
to be less effective than FO in acquiring new task-specific knowledge,
particularly under constrained training budgets. To better understand this
trade-off, we conduct a holistic evaluation of ZO optimization applied to
various existing CL methods. Our findings reveal that ZO optimization enhances
stability but often undermines plasticity, particularly when used with
learnable classifiers. Motivated by this insight, we propose ZO-FC, a simple
but effective approach that applies ZO optimization to a single adapter-based
PEFT module with FO optimized classifier. This design leverages the stability
benefits of ZO while preserving the adaptability of FO updates with negligible
memory overhead. Experiments demonstrate that ZO-FC achieves an effective
balance between stability and plasticity, offering a practical and
memory-efficient solution for on-device CL.

</details>


### [112] [CIPHER: Scalable Time Series Analysis for Physical Sciences with Application to Solar Wind Phenomena](https://arxiv.org/abs/2510.21022)
*Jasmine R. Kobayashi,Daniela Martin,Valmir P Moraes Filho,Connor O'Brien,Jinsu Hong,Sudeshna Boro Saikia,Hala Lamdouar,Nathan D. Miles,Marcella Scoczynski,Mavis Stone,Sairam Sundaresan,Anna Jungbluth,Andrés Muñoz-Jaramillo,Evangelia Samara,Joseph Gallego*

Main category: cs.LG

TL;DR: CIPHER是一个加速物理学复杂时间序列标注的大规模框架，结合了符号化表示、无监督学习和专家知识，应对标注稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 物理科学中的时间序列标注挑战，专家标注稀缺且成本高，通过机器学习模型进行理解和预测需要稳健的标注。

Method: 提出了CIPHER框架，通过结合iSAX和HDBSCAN实现复杂时间序列的标注和分类。

Result: CIPHER框架在分类太阳风现象中有效恢复了重要现象，如日冕物质抛射和流交互区域。

Conclusion: CIPHER框架提供了一种通用策略，促进了物理科学中时间序列标注和分类的研究。

Abstract: Labeling or classifying time series is a persistent challenge in the physical
sciences, where expert annotations are scarce, costly, and often inconsistent.
Yet robust labeling is essential to enable machine learning models for
understanding, prediction, and forecasting. We present the \textit{Clustering
and Indexation Pipeline with Human Evaluation for Recognition} (CIPHER), a
framework designed to accelerate large-scale labeling of complex time series in
physics. CIPHER integrates \textit{indexable Symbolic Aggregate approXimation}
(iSAX) for interpretable compression and indexing, density-based clustering
(HDBSCAN) to group recurring phenomena, and a human-in-the-loop step for
efficient expert validation. Representative samples are labeled by domain
scientists, and these annotations are propagated across clusters to yield
systematic, scalable classifications. We evaluate CIPHER on the task of
classifying solar wind phenomena in OMNI data, a central challenge in space
weather research, showing that the framework recovers meaningful phenomena such
as coronal mass ejections and stream interaction regions. Beyond this case
study, CIPHER highlights a general strategy for combining symbolic
representations, unsupervised learning, and expert knowledge to address label
scarcity in time series across the physical sciences. The code and
configuration files used in this study are publicly available to support
reproducibility.

</details>


### [113] [Elementary, My Dear Watson: Non-Invasive Neural Keyword Spotting in the LibriBrain Dataset](https://arxiv.org/abs/2510.21038)
*Gereon Elvers,Gilad Landau,Oiwi Parker Jones*

Main category: cs.LG

TL;DR: 提出关键字识别（KWS）作为非侵入性BCIs的中间任务，并提供标准化的基准测试与数据集，初步模型展现出良好的可行性。


<details>
  <summary>Details</summary>
Motivation: 推动非侵入性脑机接口的实用性以及提升对隐私的保护，填补现有任务和应用之间的空白。

Method: 使用深度学习模型进行关键字识别的训练，采用标准化的数据集和评估指标。

Result: 本文提出了关键字识别（KWS）作为非侵入性脑机接口（BCIs）中一个可实际应用且注重隐私的中间任务，利用52小时的LibriBrain数据集进行标准化的训练/验证/测试分割以实现可重复的基准测试。作者采用了针对极端类别不平衡的评估协议，使用精确率-召回曲线下面积（AUPRC）作为评估指标，并通过固定召回率下的每小时假警报（FA/h）来捕捉用户面临的权衡。同时，作者更新了pnpl库，方便研究者进一步实验。初始参考模型为紧凑的1-D Conv/ResNet基线，训练时在单个消费级GPU上进行，且在持出会话上取得约13倍的基准AUPRC，证明了任务的可行性。

Conclusion: 关键字识别在非侵入性脑机接口中的应用前景良好，且相关模型和方法可供深入研究与实验。

Abstract: Non-invasive brain-computer interfaces (BCIs) are beginning to benefit from
large, public benchmarks. However, current benchmarks target relatively simple,
foundational tasks like Speech Detection and Phoneme Classification, while
application-ready results on tasks like Brain-to-Text remain elusive. We
propose Keyword Spotting (KWS) as a practically applicable, privacy-aware
intermediate task. Using the deep 52-hour, within-subject LibriBrain corpus, we
provide standardized train/validation/test splits for reproducible
benchmarking, and adopt an evaluation protocol tailored to extreme class
imbalance. Concretely, we use area under the precision-recall curve (AUPRC) as
a robust evaluation metric, complemented by false alarms per hour (FA/h) at
fixed recall to capture user-facing trade-offs. To simplify deployment and
further experimentation within the research community, we are releasing an
updated version of the pnpl library with word-level dataloaders and Colab-ready
tutorials. As an initial reference model, we present a compact 1-D Conv/ResNet
baseline with focal loss and top-k pooling that is trainable on a single
consumer-class GPU. The reference model achieves approximately 13x the
permutation baseline AUPRC on held-out sessions, demonstrating the viability of
the task. Exploratory analyses reveal: (i) predictable within-subject scaling -
performance improves log-linearly with more training hours - and (ii) the
existence of word-level factors (frequency and duration) that systematically
modulate detectability.

</details>


### [114] [Amortized Active Generation of Pareto Sets](https://arxiv.org/abs/2510.21052)
*Daniel M. Steinberg,Asiri Wijesinghe,Rafael Oliveira,Piotr Koniusz,Cheng Soon Ong,Edwin V. Bonilla*

Main category: cs.LG

TL;DR: 提出了一种新的在线黑箱多目标优化框架A-GPS，通过生成模型和用户偏好有效地生成Pareto集合。


<details>
  <summary>Details</summary>
Motivation: 该方法旨在学习Pareto集合的生成模型，支持基于用户偏好的后验条件。

Method: 引入主动生成Pareto集合（A-GPS）框架用于在线离散黑箱多目标优化（MOO）。

Result: A-GPS实现了高质量的Pareto集合近似，避免了显式的超体积计算，并灵活捕捉用户偏好。

Conclusion: A-GPS展示了在合成基准和蛋白质设计任务上的强大样本效率和有效的偏好整合。

Abstract: We introduce active generation of Pareto sets (A-GPS), a new framework for
online discrete black-box multi-objective optimization (MOO). A-GPS learns a
generative model of the Pareto set that supports a-posteriori conditioning on
user preferences. The method employs a class probability estimator (CPE) to
predict non-dominance relations and to condition the generative model toward
high-performing regions of the search space. We also show that this
non-dominance CPE implicitly estimates the probability of hypervolume
improvement (PHVI). To incorporate subjective trade-offs, A-GPS introduces
preference direction vectors that encode user-specified preferences in
objective space. At each iteration, the model is updated using both Pareto
membership and alignment with these preference directions, producing an
amortized generative model capable of sampling across the Pareto front without
retraining. The result is a simple yet powerful approach that achieves
high-quality Pareto set approximations, avoids explicit hypervolume
computation, and flexibly captures user preferences. Empirical results on
synthetic benchmarks and protein design tasks demonstrate strong sample
efficiency and effective preference incorporation.

</details>


### [115] [On the Sample Complexity of Differentially Private Policy Optimization](https://arxiv.org/abs/2510.21060)
*Yi He,Xingyu Zhou*

Main category: cs.LG

TL;DR: 本文探讨了差分隐私政策优化的样本复杂性，提供了对隐私保护政策优化重要的理论和实践见解。


<details>
  <summary>Details</summary>
Motivation: 随着政策优化在敏感领域的广泛应用，确保其隐私性成为了重要问题。

Method: 通过建立一个统一框架，系统分析了在不同隐私保护约束下，多种政策优化算法的样本复杂性。

Result: 本理论研究首次提出了适合政策优化的差分隐私定义，并分析了常用算法在差分隐私条件下的样本复杂性。

Conclusion: 本研究表明，在隐私保护的政策优化中，隐私成本通常以低阶项的形式出现在样本复杂性中，同时提供了对隐私保护政策优化算法的重要观察。

Abstract: Policy optimization (PO) is a cornerstone of modern reinforcement learning
(RL), with diverse applications spanning robotics, healthcare, and large
language model training. The increasing deployment of PO in sensitive domains,
however, raises significant privacy concerns. In this paper, we initiate a
theoretical study of differentially private policy optimization, focusing
explicitly on its sample complexity. We first formalize an appropriate
definition of differential privacy (DP) tailored to PO, addressing the inherent
challenges arising from on-policy learning dynamics and the subtlety involved
in defining the unit of privacy. We then systematically analyze the sample
complexity of widely-used PO algorithms, including policy gradient (PG),
natural policy gradient (NPG) and more, under DP constraints and various
settings, via a unified framework. Our theoretical results demonstrate that
privacy costs can often manifest as lower-order terms in the sample complexity,
while also highlighting subtle yet important observations in private PO
settings. These offer valuable practical insights for privacy-preserving PO
algorithms.

</details>


### [116] [Scalable Machine Learning Analysis of Parker Solar Probe Solar Wind Data](https://arxiv.org/abs/2510.21066)
*Daniela Martin,Connor O'Brien,Valmir P Moraes Filho,Jinsu Hong,Jasmine R. Kobayashi,Evangelia Samara,Joseph Gallego*

Main category: cs.LG

TL;DR: 本研究提出了一个新颖的机器学习框架，用于分析Parker Solar Probe的太阳风数据，并提供关键参数之间的关系与趋势，促进了空间天气研究。


<details>
  <summary>Details</summary>
Motivation: 解决传统分析方法在处理超过150GB的PSP数据集时的挑战，并探索复杂物理数据集。

Method: 利用Dask进行大规模统计计算，并采用量子启发的核密度矩阵方法（KDM）来估计太阳风各主要参数的单变量和双变量分布。

Result: 揭示了内日球的特征趋势，包括太阳风速度随距离增大而增加、质子密度降低及速度与密度之间的反向关系，为极端空间天气现象提供了定量见解。

Conclusion: 提出了一种可扩展的机器学习框架，用于分析Parker Solar Probe的太阳风数据，并提供了对太阳风动态和空间天气预测的深入理解。

Abstract: We present a scalable machine learning framework for analyzing Parker Solar
Probe (PSP) solar wind data using distributed processing and the
quantum-inspired Kernel Density Matrices (KDM) method. The PSP dataset
(2018--2024) exceeds 150 GB, challenging conventional analysis approaches. Our
framework leverages Dask for large-scale statistical computations and KDM to
estimate univariate and bivariate distributions of key solar wind parameters,
including solar wind speed, proton density, and proton thermal speed, as well
as anomaly thresholds for each parameter. We reveal characteristic trends in
the inner heliosphere, including increasing solar wind speed with distance from
the Sun, decreasing proton density, and the inverse relationship between speed
and density. Solar wind structures play a critical role in enhancing and
mediating extreme space weather phenomena and can trigger geomagnetic storms;
our analyses provide quantitative insights into these processes. This approach
offers a tractable, interpretable, and distributed methodology for exploring
complex physical datasets and facilitates reproducible analysis of large-scale
in situ measurements. Processed data products and analysis tools are made
publicly available to advance future studies of solar wind dynamics and space
weather forecasting. The code and configuration files used in this study are
publicly available to support reproducibility.

</details>


### [117] [The Virtues of Brevity: Avoid Overthinking in Parallel Test-Time Reasoning](https://arxiv.org/abs/2510.21067)
*Raul Cavalcante Dinardi,Bruno Yamamoto,Anna Helena Reali Costa,Artur Jordao*

Main category: cs.LG

TL;DR: 通过选择最短解的简单启发式方法，可以提高大型语言模型在复杂推理任务中的表现，并降低计算复杂性。


<details>
  <summary>Details</summary>
Motivation: 提高大型语言模型在复杂推理任务中的预测性能，降低计算成本和复杂性。

Method: 选择最短解的启发式方法

Result: 所提出的方法在两个具有挑战性的基准测试中，与自一致性等复杂方法竞争，同时显著减少了计算开销。

Conclusion: 最短解启发式方法在自一致性等复杂方法的基础上实现了帕累托改进，并适用于输出不易定义的任务。

Abstract: Reasoning models represent a significant advance in LLM capabilities,
particularly for complex reasoning tasks such as mathematics and coding.
Previous studies confirm that parallel test-time compute-sampling multiple
solutions and selecting the best one-can further enhance the predictive
performance of LLMs. However, strategies in this area often require complex
scoring, thus increasing computational cost and complexity. In this work, we
demonstrate that the simple and counterintuitive heuristic of selecting the
shortest solution is highly effective. We posit that the observed effectiveness
stems from models operating in two distinct regimes: a concise, confident
conventional regime and a verbose overthinking regime characterized by
uncertainty, and we show evidence of a critical point where the overthinking
regime begins to be significant. By selecting the shortest answer, the
heuristic preferentially samples from the conventional regime. We confirm that
this approach is competitive with more complex methods such as self-consistency
across two challenging benchmarks while significantly reducing computational
overhead. The shortest-answer heuristic provides a Pareto improvement over
self-consistency and applies even to tasks where output equality is not well
defined.

</details>


### [118] [DictPFL: Efficient and Private Federated Learning on Encrypted Gradients](https://arxiv.org/abs/2510.21086)
*Jiaqi Xue,Mayank Kumar,Yuzhang Shang,Shangqian Gao,Rui Ning,Mengxin Zheng,Xiaoqian Jiang,Qian Lou*

Main category: cs.LG

TL;DR: DictPFL是一种实用的联邦学习框架，通过加密梯度和优化参数处理，实现强隐私保护和高效计算。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，尽管避免了原始数据共享，但梯度共享仍面临隐私泄露的风险，因此需要一种有效且低开销的私人联邦学习方法。

Method: DictPFL通过加密每个传输的梯度且保留非传输参数为本地，解决了梯度共享的隐私泄露问题。

Result: DictPFL在通信成本和训练速度上显著优于现有的方法，具体表现为节省通信成本402-748倍，加速训练28-65倍。

Conclusion: DictPFL框架实现了全梯度保护且计算开销极小，适用于真实世界的联邦学习部署。

Abstract: Federated Learning (FL) enables collaborative model training across
institutions without sharing raw data. However, gradient sharing still risks
privacy leakage, such as gradient inversion attacks. Homomorphic Encryption
(HE) can secure aggregation but often incurs prohibitive computational and
communication overhead. Existing HE-based FL methods sit at two extremes:
encrypting all gradients for full privacy at high cost, or partially encrypting
gradients to save resources while exposing vulnerabilities. We present DictPFL,
a practical framework that achieves full gradient protection with minimal
overhead. DictPFL encrypts every transmitted gradient while keeping
non-transmitted parameters local, preserving privacy without heavy computation.
It introduces two key modules: Decompose-for-Partial-Encrypt (DePE), which
decomposes model weights into a static dictionary and an updatable lookup
table, only the latter is encrypted and aggregated, while the static dictionary
remains local and requires neither sharing nor encryption; and
Prune-for-Minimum-Encrypt (PrME), which applies encryption-aware pruning to
minimize encrypted parameters via consistent, history-guided masks. Experiments
show that DictPFL reduces communication cost by 402-748$\times$ and accelerates
training by 28-65$\times$ compared to fully encrypted FL, while outperforming
state-of-the-art selective encryption methods by 51-155$\times$ in overhead and
4-19$\times$ in speed. Remarkably, DictPFL's runtime is within 2$\times$ of
plaintext FL, demonstrating for the first time, that HE-based private federated
learning is practical for real-world deployment. The code is publicly available
at https://github.com/UCF-ML-Research/DictPFL.

</details>


### [119] [ESCORT: Efficient Stein-variational and Sliced Consistency-Optimized Temporal Belief Representation for POMDPs](https://arxiv.org/abs/2510.21107)
*Yunuo Zhang,Baiting Luo,Ayan Mukhopadhyay,Gabor Karsai,Abhishek Dubey*

Main category: cs.LG

TL;DR: ESCORT是一种新方法，专注于在高维信念空间中捕捉复杂多模态分布，解决了现有POMDP信念近似方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着环境的复杂性增加，标准数学模型难以准确捕捉高维、多模态信念分布，导致估计误差和次优行为。

Method: 提出了一种基于粒子的框架，结合相关性感知投影和时间一致性约束，改进了SVGD算法，以适应复杂信念结构。

Result: ESCORT在POMDP领域和合成多模态分布的广泛评估中表现优于现有方法。

Conclusion: ESCORT方法在捕捉复杂的多模态分布和高维信念空间中表现优越，成功提升了信念近似准确性和后续决策质量。

Abstract: In Partially Observable Markov Decision Processes (POMDPs), maintaining and
updating belief distributions over possible underlying states provides a
principled way to summarize action-observation history for effective
decision-making under uncertainty. As environments grow more realistic, belief
distributions develop complexity that standard mathematical models cannot
accurately capture, creating a fundamental challenge in maintaining
representational accuracy. Despite advances in deep learning and probabilistic
modeling, existing POMDP belief approximation methods fail to accurately
represent complex uncertainty structures such as high-dimensional, multi-modal
belief distributions, resulting in estimation errors that lead to suboptimal
agent behaviors. To address this challenge, we present ESCORT (Efficient
Stein-variational and sliced Consistency-Optimized Representation for Temporal
beliefs), a particle-based framework for capturing complex, multi-modal
distributions in high-dimensional belief spaces. ESCORT extends SVGD with two
key innovations: correlation-aware projections that model dependencies between
state dimensions, and temporal consistency constraints that stabilize updates
while preserving correlation structures. This approach retains SVGD's
attractive-repulsive particle dynamics while enabling accurate modeling of
intricate correlation patterns. Unlike particle filters prone to degeneracy or
parametric methods with fixed representational capacity, ESCORT dynamically
adapts to belief landscape complexity without resampling or restrictive
distributional assumptions. We demonstrate ESCORT's effectiveness through
extensive evaluations on both POMDP domains and synthetic multi-modal
distributions of varying dimensionality, where it consistently outperforms
state-of-the-art methods in terms of belief approximation accuracy and
downstream decision quality.

</details>


### [120] [Distributionally Robust Feature Selection](https://arxiv.org/abs/2510.21113)
*Maitreyi Swaroop,Tamar Krishnamurti,Bryan Wilder*

Main category: cs.LG

TL;DR: 本研究探讨了在高成本特征收集场景下，如何选择有限特征以提高多个子群体的模型表现，提出了一种无需反向传播的框架，并进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 在特征收集成本较高的情况下，选择有限特征以保证在多个子群体上训练的模型同时表现良好。

Method: 将传统变量选择的问题作为一种连续松弛，并使用噪声机制来解决，避免了对模型训练过程的反向传播要求。

Result: 开发了一个模型无关的框架，可以在子群体中平衡下游预测的整体性能，并通过在合成数据集和真实世界数据上的实验验证了该方法。

Conclusion: 该方法通过优化Bayes最优预测器的方差，提供了一种有效的特征选择机制，对不同群体的预测性能具有良好的平衡作用。

Abstract: We study the problem of selecting limited features to observe such that
models trained on them can perform well simultaneously across multiple
subpopulations. This problem has applications in settings where collecting each
feature is costly, e.g. requiring adding survey questions or physical sensors,
and we must be able to use the selected features to create high-quality
downstream models for different populations. Our method frames the problem as a
continuous relaxation of traditional variable selection using a noising
mechanism, without requiring backpropagation through model training processes.
By optimizing over the variance of a Bayes-optimal predictor, we develop a
model-agnostic framework that balances overall performance of downstream
prediction across populations. We validate our approach through experiments on
both synthetic datasets and real-world data.

</details>


### [121] [SolarBoost: Distributed Photovoltaic Power Forecasting Amid Time-varying Grid Capacity](https://arxiv.org/abs/2510.21129)
*Linyuan Geng,Linxiao Yang,Xinyue Gu,Liang Sun*

Main category: cs.LG

TL;DR: SolarBoost 是一种新方法，用于预测分布式光伏系统的发电输出，能有效克服传统方法在DPV系统中的局限性，通过小型电网组合建模实现准确预测，并在多个城市得到验证。


<details>
  <summary>Details</summary>
Motivation: 解决现有集中式光伏方法在面对分布式光伏系统时的局限性，针对DPV系统的特点进行更加精准的发电预测。

Method: 通过将集成的发电输出建模为小电网的组合，使用单位输出函数和动态容量的解耦关系，并引入高效算法改进计算性能。

Result: 本论文提出了SolarBoost，这是一种用于预测分布式光伏（DPV）系统发电输出的新方法。现有的集中式光伏（CPV）方法虽然能够精确建模由于均匀性所产生的输出依赖性，但很难将这些技术应用于DPV系统，因为DPV面临着缺乏电网级数据、已安装容量的时间变化、地理差异和面板多样性等挑战。SolarBoost通过将聚合的发电输出建模为小型电网的输出组合来克服这些挑战，其中每个电网的输出使用单位输出函数乘以其容量进行建模。这种方法将均匀的单位输出函数与动态容量解耦，从而实现准确预测。文中提出了高效的算法来克服损失函数中的计算瓶颈。通过理论分析和实验，证明了电网级建模的优越性。SolarBoost已经在中国多个城市进行部署验证，显著减少了潜在损失，并为电网的运行提供了有价值的见解。代码可在https://github.com/DAMO-DI-ML/SolarBoost获取。

Conclusion: SolarBoost在分布式光伏系统中有效提高了发电预测的准确性，提供了对电网运行重要的指导。

Abstract: This paper presents SolarBoost, a novel approach for forecasting power output
in distributed photovoltaic (DPV) systems. While existing centralized
photovoltaic (CPV) methods are able to precisely model output dependencies due
to uniformity, it is difficult to apply such techniques to DPV systems, as DPVs
face challenges such as missing grid-level data, temporal shifts in installed
capacity, geographic variability, and panel diversity. SolarBoost overcomes
these challenges by modeling aggregated power output as a composite of output
from small grids, where each grid output is modeled using a unit output
function multiplied by its capacity. This approach decouples the homogeneous
unit output function from dynamic capacity for accurate prediction. Efficient
algorithms over an upper-bound approximation are proposed to overcome
computational bottlenecks in loss functions. We demonstrate the superiority of
grid-level modeling via theoretical analysis and experiments. SolarBoost has
been validated through deployment across various cities in China, significantly
reducing potential losses and provides valuable insights for the operation of
power grids. The code for this work is available at
https://github.com/DAMO-DI-ML/SolarBoost.

</details>


### [122] [Cloud-Fog-Edge Collaborative Computing for Sequential MIoT Workflow: A Two-Tier DDPG-Based Scheduling Framework](https://arxiv.org/abs/2510.21135)
*Yuhao Fu,Yinghao Zhang,Yalin Liu,Bishenghui Tao,Junhong Ruan*

Main category: cs.LG

TL;DR: 本文提出了一种双层DDPG调度框架，旨在通过分层控制器提高医疗物联网工作的调度效率，特别是在复杂性增加时，其表现优于基准。


<details>
  <summary>Details</summary>
Motivation: 针对医疗物联网（MIoT）中的顺序医疗工作流程，确保严格的端到端延迟保证是重要的，而在异构云-雾-边缘基础设施上调度这些工作流程以最小化完成时间是一个NP难题。

Method: 提出了一种双层DDPG调度框架，包含全局控制器进行层选择和局部控制器处理选定层内的节点分配。

Result: 提出了一种基于双层DDPG的调度框架，通过分层过程来处理调度决策，从而实现工作流的高效调度。

Conclusion: 实验结果表明，该框架在处理复杂、大规模的MIoT调度场景时，能够学习有效的长期策略，从而显著提升性能。

Abstract: The Medical Internet of Things (MIoT) demands stringent end-to-end latency
guarantees for sequential healthcare workflows deployed over heterogeneous
cloud-fog-edge infrastructures. Scheduling these sequential workflows to
minimize makespan is an NP-hard problem. To tackle this challenge, we propose a
Two-tier DDPG-based scheduling framework that decomposes the scheduling
decision into a hierarchical process: a global controller performs layer
selection (edge, fog, or cloud), while specialized local controllers handle
node assignment within the chosen layer. The primary optimization objective is
the minimization of the workflow makespan. Experiments results validate our
approach, demonstrating increasingly superior performance over baselines as
workflow complexity rises. This trend highlights the frameworks ability to
learn effective long-term strategies, which is critical for complex,
large-scale MIoT scheduling scenarios.

</details>


### [123] [Uncertainty-Aware Multi-Objective Reinforcement Learning-Guided Diffusion Models for 3D De Novo Molecular Design](https://arxiv.org/abs/2510.21153)
*Lianghong Chen,Dongkyu Eugene Kim,Mike Domaratzki,Pingzhao Hu*

Main category: cs.LG

TL;DR: 本文提出了一种新的RL框架来优化3D分子扩散模型，能够同时满足多个特性目标，提高生成分子的整体质量。


<details>
  <summary>Details</summary>
Motivation: 传统的扩散模型在处理复杂的多目标约束时表现不佳，而药物发现和分子工程急需设计具有理想特性的3D分子。

Method: 提出一种不确定性感知的强化学习框架，优化3D分子扩散模型。

Result: 该框架在三种基准数据集和多种扩散模型架构中进行评估，始终优于基线，分子质量和特性优化表现出色。

Conclusion: RL引导的生成扩散模型在自动化分子设计中显示出良好的发展潜力，生成的候选分子具有良好的药物特性和结合稳定性。

Abstract: Designing de novo 3D molecules with desirable properties remains a
fundamental challenge in drug discovery and molecular engineering. While
diffusion models have demonstrated remarkable capabilities in generating
high-quality 3D molecular structures, they often struggle to effectively
control complex multi-objective constraints critical for real-world
applications. In this study, we propose an uncertainty-aware Reinforcement
Learning (RL) framework to guide the optimization of 3D molecular diffusion
models toward multiple property objectives while enhancing the overall quality
of the generated molecules. Our method leverages surrogate models with
predictive uncertainty estimation to dynamically shape reward functions,
facilitating balance across multiple optimization objectives. We
comprehensively evaluate our framework across three benchmark datasets and
multiple diffusion model architectures, consistently outperforming baselines
for molecular quality and property optimization. Additionally, Molecular
Dynamics (MD) simulations and ADMET profiling of top generated candidates
indicate promising drug-like behavior and binding stability, comparable to
known Epidermal Growth Factor Receptor (EGFR) inhibitors. Our results
demonstrate the strong potential of RL-guided generative diffusion models for
advancing automated molecular design.

</details>


### [124] [A Unified Matrix Factorization Framework for Classical and Robust Clustering](https://arxiv.org/abs/2510.21172)
*Angshul Majumdar*

Main category: cs.LG

TL;DR: 本文提出了一种统一的矩阵分解框架，用于经典和稳健聚类，重新推导了k均值聚类与矩阵分解的等价性，并提出了模糊c均值聚类的矩阵分解解释，进而扩展到稳健变体。


<details>
  <summary>Details</summary>
Motivation: 探讨经典聚类方法与矩阵分解之间的联系，推动稳健聚类的发展，解决对离群值敏感的问题。

Method: 首先重述了k均值聚类与矩阵分解之间的等价性，并对模糊c均值聚类的矩阵分解解释进行了推导，最后提出了基于交替最小化和IRLS的稳健聚类算法。

Result: 提出的算法在理论上证明能够收敛到局部最小值，拓展了传统与稳健聚类的应用。

Conclusion: 通过稳健和模糊聚类的矩阵分解框架的提出，本文为聚类问题的优化提供了新思路，且算法具有理论收敛性。

Abstract: This paper presents a unified matrix factorization framework for classical
and robust clustering. We begin by revisiting the well-known equivalence
between crisp k-means clustering and matrix factorization, following and
rigorously rederiving an unpublished formulation by Bauckhage. Extending this
framework, we derive an analogous matrix factorization interpretation for fuzzy
c-means clustering, which to the best of our knowledge has not been previously
formalized. These reformulations allow both clustering paradigms to be
expressed as optimization problems over factor matrices, thereby enabling
principled extensions to robust variants. To address sensitivity to outliers,
we propose robust formulations for both crisp and fuzzy clustering by replacing
the Frobenius norm with the l1,2-norm, which penalizes the sum of Euclidean
norms across residual columns. We develop alternating minimization algorithms
for the standard formulations and IRLS-based algorithms for the robust
counterparts. All algorithms are theoretically proven to converge to a local
minimum.

</details>


### [125] [Reducing the Probability of Undesirable Outputs in Language Models Using Probabilistic Inference](https://arxiv.org/abs/2510.21184)
*Stephen Zhao,Aidan Li,Rob Brekelmans,Roger Grosse*

Main category: cs.LG

TL;DR: 提出了一种名为 RePULSe 的新训练方法，通过添加额外的损失来改进 RL 的输出，以实现更好的奖励与不良输出概率的权衡。


<details>
  <summary>Details</summary>
Motivation: 提高强化学习（RL）在语言模型（LM）中的应用效果，特别是在优化人类偏好和减少 undesirable outputs 之间的平衡。

Method: 通过增强标准 RL 损失并利用学习的提议指导低奖励输出的抽样，减少这些输出的概率。

Result: RePULSe 方法展示了在期望奖励与不良输出概率之间提供了更好的权衡，并且在对抗性攻击下表现出更强的鲁棒性。

Conclusion: RePULSe 在期望奖励和不良输出概率的权衡方面优于传统 RL 对齐方法，并且在对抗环境中更具鲁棒性。

Abstract: Reinforcement learning (RL) has become a predominant technique to align
language models (LMs) with human preferences or promote outputs which are
deemed to be desirable by a given reward function. Standard RL approaches
optimize average reward, while methods explicitly focused on reducing the
probability of undesired outputs typically come at a cost to average-case
performance. To improve this tradeoff, we introduce RePULSe, a new training
method that augments the standard RL loss with an additional loss that uses
learned proposals to guide sampling low-reward outputs, and then reduces those
outputs' probability. We run experiments demonstrating that RePULSe produces a
better tradeoff of expected reward versus the probability of undesired outputs
and is more adversarially robust, compared to standard RL alignment approaches
and alternatives.

</details>


### [126] [A visual big data system for the prediction of weather-related variables: Jordan-Spain case study](https://arxiv.org/abs/2510.21176)
*Shadi Aljawarneh,Juan A. Lara,Muneer Bani Yassein*

Main category: cs.LG

TL;DR: 设计了一个用于分析气象数据的可视化大数据系统，具备预测功能，并进行了有效性评估。


<details>
  <summary>Details</summary>
Motivation: 气象领域产生大量数据，需要有效的技术处理和提取知识以预测天气现象。

Method: 采用NoSQL数据库，利用单变量和多变量方法进行预测分析，并处理缺失值。

Result: 提出了一个可视化大数据系统，能够处理大量天气数据，实现预测任务。

Conclusion: 系统经过专家评估，表现出良好的可用性和预测性能，结果鼓励进一步研究。

Abstract: The Meteorology is a field where huge amounts of data are generated, mainly
collected by sensors at weather stations, where different variables can be
measured. Those data have some particularities such as high volume and
dimensionality, the frequent existence of missing values in some stations, and
the high correlation between collected variables. In this regard, it is crucial
to make use of Big Data and Data Mining techniques to deal with those data and
extract useful knowledge from them that can be used, for instance, to predict
weather phenomena. In this paper, we propose a visual big data system that is
designed to deal with high amounts of weather-related data and lets the user
analyze those data to perform predictive tasks over the considered variables
(temperature and rainfall). The proposed system collects open data and loads
them onto a local NoSQL database fusing them at different levels of temporal
and spatial aggregation in order to perform a predictive analysis using
univariate and multivariate approaches as well as forecasting based on training
data from neighbor stations in cases with high rates of missing values. The
system has been assessed in terms of usability and predictive performance,
obtaining an overall normalized mean squared error value of 0.00013, and an
overall directional symmetry value of nearly 0.84. Our system has been rated
positively by a group of experts in the area (all aspects of the system except
graphic desing were rated 3 or above in a 1-5 scale). The promising preliminary
results obtained demonstrate the validity of our system and invite us to keep
working on this area.

</details>


### [127] [Leverage Unlearning to Sanitize LLMs](https://arxiv.org/abs/2510.21322)
*Antoine Boutet,Lucas Magnana*

Main category: cs.LG

TL;DR: 提出了一种名为SANI的去记忆方法，通过重置模型神经元和再训练，安全地去除模型对敏感信息的记忆。


<details>
  <summary>Details</summary>
Motivation: 随着预训练的大型语言模型（LLMs）在各类任务中的广泛应用，确保这些模型在特定任务上的表现和隐私安全变得至关重要。

Method: SANI方法包括擦除和修复两个阶段，首先重置模型最后几层的某些神经元以打断细颗粒信息的记忆，再进行模型的再训练以防止新记忆敏感信息。

Result: 通过SANI方法进行去记忆处理后，模型的敏感信息被有效清除，且信息的再现率显著降低。

Conclusion: SANI可以有效清理已训练模型中的敏感数据，特别适用于医疗等需要保障隐私的行业。

Abstract: Pre-trained large language models (LLMs) are becoming useful for various
tasks. To improve their performance on certain tasks, it is necessary to
fine-tune them on specific data corpora (e.g., medical reports, business data).
These specialized data corpora may contain sensitive data (e.g., personal or
confidential data) that will be memorized by the model and likely to be
regurgitated during its subsequent use. This memorization of sensitive
information by the model poses a significant privacy or confidentiality issue.
To remove this memorization and sanitize the model without requiring costly
additional fine-tuning on a secured data corpus, we propose SANI. SANI is an
unlearning approach to sanitize language models. It relies on both an erasure
and repair phases that 1) reset certain neurons in the last layers of the model
to disrupt the memorization of fine-grained information, and then 2) fine-tune
the model while avoiding memorizing sensitive information. We comprehensively
evaluate SANI to sanitize both a model fine-tuned and specialized with medical
data by removing directly and indirectly identifiers from the memorization of
the model, and a standard pre-trained model by removing specific terms defined
as confidential information from the model. Results show that with only few
additional epochs of unlearning, the model is sanitized and the number of
regurgitations is drastically reduced. This approach can be particularly useful
for hospitals or other industries that have already spent significant resources
training models on large datasets and wish to sanitize them before sharing.

</details>


### [128] [PLAN: Proactive Low-Rank Allocation for Continual Learning](https://arxiv.org/abs/2510.21188)
*Xiequn Wang,Zhan Zhuang,Yu Zhang*

Main category: cs.LG

TL;DR: PLAN是一种新的持续学习框架，能够高效地管理任务特定子空间的分配，显著提高了在新任务适应的同时不会丢失旧知识的能力。


<details>
  <summary>Details</summary>
Motivation: 持续学习要求模型能够在不遗忘过去知识的情况下不断适应新任务。

Method: 提出了一种名为PLAN的框架，扩展了LoRA，允许在持续学习场景中高效且干扰感知地微调大型预训练模型。

Result: PLAN在标准持续学习基准测试中的表现优于现有方法，确立了基于基础模型的持续学习的新标杆。

Conclusion: 通过优化正交基向量和选择机制，PLAN有效地减少了干扰的敏感性，从而在持续学习中取得了更好的性能。

Abstract: Continual learning (CL) requires models to continuously adapt to new tasks
without forgetting past knowledge. In this work, we propose
\underline{P}roactive \underline{L}ow-rank \underline{A}llocatio\underline{N}
(PLAN), a framework that extends Low-Rank Adaptation (LoRA) to enable efficient
and interference-aware fine-tuning of large pre-trained models in CL settings.
PLAN proactively manages the allocation of task-specific subspaces by
introducing orthogonal basis vectors for each task and optimizing them through
a perturbation-based strategy that minimizes conflicts with previously learned
parameters. Furthermore, PLAN incorporates a novel selection mechanism that
identifies and assigns basis vectors with minimal sensitivity to interference,
reducing the risk of degrading past knowledge while maintaining efficient
adaptation to new tasks. Empirical results on standard CL benchmarks
demonstrate that PLAN consistently outperforms existing methods, establishing a
new state-of-the-art for continual learning with foundation models.

</details>


### [129] [FairImagen: Post-Processing for Bias Mitigation in Text-to-Image Models](https://arxiv.org/abs/2510.21363)
*Zihao Fu,Ryan Brown,Shun Shao,Kai Rawal,Eoin Delaney,Chris Russell*

Main category: cs.LG

TL;DR: 本研究提出FairImagen框架，针对文本到图像扩散模型的社会偏见问题，通过提示嵌入后处理方法，实现去偏见，提升了生成公平性。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型在高质量和多样性图像生成方面表现出色，但却存在重复和放大社会偏见的问题，尤其是在性别和种族方面。

Method: 提出了一种后处理去偏见框架FairImagen，利用提示嵌入函数进行去偏见，而无需重新训练或修改基础的扩散模型。

Result: 实验结果表明，FairImagen在性别、种族和交叉设定中显著提升了公平性，同时在图像质量和提示保真度上有适度的权衡。

Conclusion: FairImagen是一个简单、可扩展且与模型无关的解决方案，有效改善了文本到图像生成的公平性。

Abstract: Text-to-image diffusion models, such as Stable Diffusion, have demonstrated
remarkable capabilities in generating high-quality and diverse images from
natural language prompts. However, recent studies reveal that these models
often replicate and amplify societal biases, particularly along demographic
attributes like gender and race. In this paper, we introduce FairImagen
(https://github.com/fuzihaofzh/FairImagen), a post-hoc debiasing framework that
operates on prompt embeddings to mitigate such biases without retraining or
modifying the underlying diffusion model. Our method integrates Fair Principal
Component Analysis to project CLIP-based input embeddings into a subspace that
minimizes group-specific information while preserving semantic content. We
further enhance debiasing effectiveness through empirical noise injection and
propose a unified cross-demographic projection method that enables simultaneous
debiasing across multiple demographic attributes. Extensive experiments across
gender, race, and intersectional settings demonstrate that FairImagen
significantly improves fairness with a moderate trade-off in image quality and
prompt fidelity. Our framework outperforms existing post-hoc methods and offers
a simple, scalable, and model-agnostic solution for equitable text-to-image
generation.

</details>


### [130] [Gen-Review: A Large-scale Dataset of AI-Generated (and Human-written) Peer Reviews](https://arxiv.org/abs/2510.21192)
*Luca Demetrio,Giovanni Apruzzese,Kathrin Grosse,Pavel Laskov,Emil Lupu,Vera Rimmer,Philine Widmer*

Main category: cs.LG

TL;DR: 本研究介绍GenReview数据集，分析LLM在科学评审中的作用和表现，发现偏见及检测可能性，提供未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 填补关于大型语言模型在科学评审中使用效果的数据空白，探讨其对科学评审过程的影响。

Method: 通过LLM生成的81K条评论来分析其在评审中的表现，分类为负面、积极和中立三种类型，并与真实论文及原始评审联系。

Result: 研究发现LLM评审存在偏见，可检测其生成的评论，但在遵循评论指令的能力和与接受或拒绝决定的一致性方面表现不一。

Conclusion: GenReview提供了一个世界上最大的数据集，展示了LLM在同行评审中的应用及其潜在偏见，揭示了当前LLM写作评论的有效性和局限性。

Abstract: How does the progressive embracement of Large Language Models (LLMs) affect
scientific peer reviewing? This multifaceted question is fundamental to the
effectiveness -- as well as to the integrity -- of the scientific process.
Recent evidence suggests that LLMs may have already been tacitly used in peer
reviewing, e.g., at the 2024 International Conference of Learning
Representations (ICLR). Furthermore, some efforts have been undertaken in an
attempt to explicitly integrate LLMs in peer reviewing by various editorial
boards (including that of ICLR'25). To fully understand the utility and the
implications of LLMs' deployment for scientific reviewing, a comprehensive
relevant dataset is strongly desirable. Despite some previous research on this
topic, such dataset has been lacking so far. We fill in this gap by presenting
GenReview, the hitherto largest dataset containing LLM-written reviews. Our
dataset includes 81K reviews generated for all submissions to the 2018--2025
editions of the ICLR by providing the LLM with three independent prompts: a
negative, a positive, and a neutral one. GenReview is also linked to the
respective papers and their original reviews, thereby enabling a broad range of
investigations. To illustrate the value of GenReview, we explore a sample of
intriguing research questions, namely: if LLMs exhibit bias in reviewing (they
do); if LLM-written reviews can be automatically detected (so far, they can);
if LLMs can rigorously follow reviewing instructions (not always) and whether
LLM-provided ratings align with decisions on paper acceptance or rejection
(holds true only for accepted papers). GenReview can be accessed at the
following link: https://anonymous.4open.science/r/gen_review.

</details>


### [131] [Online AUC Optimization Based on Second-order Surrogate Loss](https://arxiv.org/abs/2510.21202)
*JunRu Luo,Difei Cheng,Bo Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种新的二阶替代损失和在线算法来有效优化AUC，特别是在类别不平衡和大规模应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 探索在类别不平衡情况下AUC的优化问题，解决现有方法在大规模应用中遇到的优化和存储瓶颈。

Method: 基于成对铰链损失构建二阶替代损失，开发了一种高效的在线算法，并扩展到非线性设置。

Result: 提出了一种基于成对铰链损失的新型二阶替代损失及高效的在线算法，优化AUC性能。

Conclusion: 通过理论证明和大量实验，所提方法在优化在线AUC性能方面显示出优越的效率和效果。

Abstract: The Area Under the Curve (AUC) is an important performance metric for
classification tasks, particularly in class-imbalanced scenarios. However,
minimizing the AUC presents significant challenges due to the non-convex and
discontinuous nature of pairwise 0/1 losses, which are difficult to optimize,
as well as the substantial memory cost of instance-wise storage, which creates
bottlenecks in large-scale applications. To overcome these challenges, we
propose a novel second-order surrogate loss based on the pairwise hinge loss,
and develop an efficient online algorithm. Unlike conventional approaches that
approximate each individual pairwise 0/1 loss term with an instance-wise
surrogate function, our approach introduces a new paradigm that directly
substitutes the entire aggregated pairwise loss with a surrogate loss function
constructed from the first- and second-order statistics of the training data.
Theoretically, while existing online AUC optimization algorithms typically
achieve an $\mathcal{O}(\sqrt{T})$ regret bound, our method attains a tighter
$\mathcal{O}(\ln T)$ bound. Furthermore, we extend the proposed framework to
nonlinear settings through a kernel-based formulation. Extensive experiments on
multiple benchmark datasets demonstrate the superior efficiency and
effectiveness of the proposed second-order surrogate loss in optimizing online
AUC performance.

</details>


### [132] [Mitra: Mixed Synthetic Priors for Enhancing Tabular Foundation Models](https://arxiv.org/abs/2510.21204)
*Xiyuan Zhang,Danielle C. Maddix,Junming Yin,Nick Erickson,Abdul Fatir Ansari,Boran Han,Shuai Zhang,Leman Akoglu,Christos Faloutsos,Michael W. Mahoney,Cuixiong Hu,Huzefa Rangwala,George Karypis,Bernie Wang*

Main category: cs.LG

TL;DR: 本文首次系统性研究合成先验对预训练表格基础模型（TFMs）泛化能力的影响，并提出Mitra模型，在多项基准测试中表现优于现有TFMs。


<details>
  <summary>Details</summary>
Motivation: 探索合成数据集及其先验分布对于表格基础模型泛化能力的重要性，以填补这一研究领域的空白。

Method: 系统性地研究和识别合成先验的关键属性，并基于此设计Mitra模型。

Result: 本研究探讨了基于上下文学习的表格基础模型（TFMs）的发展，提出了合成数据集设计的重要性，以及合成先验分布的关键特性，这些特性帮助预训练的TFMs在无真实数据的情况下实现良好的泛化。通过引入Mitra，研究显示其在分类和回归基准测试中超越了现有的最先进TFMs，如TabPFNv2和TabICL，且样本效率更优。

Conclusion: Mitra模型通过优化合成先验设计，提升了表格学习任务的性能，改变了传统机器学习的范式。

Abstract: Since the seminal work of TabPFN, research on tabular foundation models
(TFMs) based on in-context learning (ICL) has challenged long-standing
paradigms in machine learning. Without seeing any real-world data, models
pretrained on purely synthetic datasets generalize remarkably well across
diverse datasets, often using only a moderate number of in-context examples.
This shifts the focus in tabular machine learning from model architecture
design to the design of synthetic datasets, or, more precisely, to the prior
distributions that generate them. Yet the guiding principles for prior design
remain poorly understood. This work marks the first attempt to address the gap.
We systematically investigate and identify key properties of synthetic priors
that allow pretrained TFMs to generalize well. Based on these insights, we
introduce Mitra, a TFM trained on a curated mixture of synthetic priors
selected for their diversity, distinctiveness, and performance on real-world
tabular data. Mitra consistently outperforms state-of-the-art TFMs, such as
TabPFNv2 and TabICL, across both classification and regression benchmarks, with
better sample efficiency.

</details>


### [133] [Few-Shot Knowledge Distillation of LLMs With Counterfactual Explanations](https://arxiv.org/abs/2510.21631)
*Faisal Hamman,Pasan Dissanayake,Yanjun Fu,Sanghamitra Dutta*

Main category: cs.LG

TL;DR: 提出了一种新的针对少量任务感知知识蒸馏的策略CoD，通过对抗解释来减少所需数据量，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有任务感知蒸馏对数据量要求高的挑战，优选使用对抗解释来增强知识转移。

Method: 通过对抗解释来缩减样本数据，并改进模型决策边界的映射。

Result: CoD显著减少使用样本数量，同时提升了模型性能，验证了对抗解释的应用效果。

Conclusion: 实验结果表明，CoD在较少的样本情况下优于传统蒸馏方法，证明了对抗解释的有效性。

Abstract: Knowledge distillation is a promising approach to transfer capabilities from
complex teacher models to smaller, resource-efficient student models that can
be deployed easily, particularly in task-aware scenarios. However, existing
methods of task-aware distillation typically require substantial quantities of
data which may be unavailable or expensive to obtain in many practical
scenarios. In this paper, we address this challenge by introducing a novel
strategy called Counterfactual-explanation-infused Distillation CoD for
few-shot task-aware knowledge distillation by systematically infusing
counterfactual explanations. Counterfactual explanations (CFEs) refer to inputs
that can flip the output prediction of the teacher model with minimum
perturbation. Our strategy CoD leverages these CFEs to precisely map the
teacher's decision boundary with significantly fewer samples. We provide
theoretical guarantees for motivating the role of CFEs in distillation, from
both statistical and geometric perspectives. We mathematically show that CFEs
can improve parameter estimation by providing more informative examples near
the teacher's decision boundary. We also derive geometric insights on how CFEs
effectively act as knowledge probes, helping the students mimic the teacher's
decision boundaries more effectively than standard data. We perform experiments
across various datasets and LLMs to show that CoD outperforms standard
distillation approaches in few-shot regimes (as low as 8-512 samples). Notably,
CoD only uses half of the original samples used by the baselines, paired with
their corresponding CFEs and still improves performance.

</details>


### [134] [Model Merging with Functional Dual Anchors](https://arxiv.org/abs/2510.21223)
*Kexuan Shi,Yandong Wen,Weiyang Liu*

Main category: cs.LG

TL;DR: 提出了一种新的模型合并方法FDAs，通过建模输入表示空间而非参数空间，提高了多任务合并的鲁棒性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有的模型合并方法受限于参数不一致性，缺乏灵活性和鲁棒性，因此需要一种新的方法来解决这一问题。

Method: 提出了一种功能双锚（FDAs）框架，通过合成输入和相应梯度对齐任务向量，捕捉预训练模型相对于特定任务的功能变化。

Result: 全面的实验表明FDAs在模型合并中的有效性。

Conclusion: FDAs在模型合并中表现出良好的效果，证明了其与参数空间合并的互补性。

Abstract: Model merging is an efficient post-training strategy for integrating
knowledge from multiple finetuned checkpoints of a shared foundation model.
Existing methods operate in the parameter space, combining task vectors to
mitigate conflicts, but remain constrained by parameter inconsistencies. We
propose Functional Dual Anchors (FDAs), a framework that instead models the
input-representation space. FDAs are synthetic inputs whose induced gradients
align with task vectors, capturing task-specific functional shifts relative to
the pretrained model. This perspective bridges joint multi-task training and
post-hoc merging, offering both robustness and flexibility. We further
introduce a principled initialization scheme and show that FDAs are
complementary to parameter-space model merging. Comprehensive experiments
demonstrate the effectiveness of FDAs in model merging.

</details>


### [135] [Convergence of Stochastic Gradient Langevin Dynamics in the Lazy Training Regime](https://arxiv.org/abs/2510.21245)
*Noah Oberweis,Semih Cayci*

Main category: cs.LG

TL;DR: 本研究分析了随机梯度Langevin动力学在懒训练条件下的收敛性，表明其具有非退化内核且期望上实现指数收敛。


<details>
  <summary>Details</summary>
Motivation: 分析连续时间优化算法在深度学习中的训练动态，特别是随机梯度Langevin动力学的表现。

Method: 通过对随机梯度Langevin动力学的非渐近收敛分析，探讨其在懒训练阶段的表现。

Result: SGLD在损失函数Hessian的正则性条件下，具有高概率非退化性能，并在期望中以指数速度收敛。

Conclusion: SGLD在懒训练状态下展现出高概率的非退化核，且在期望上以指数速度收敛到经验风险最小化器，并建立了关于最优性间隙的有限时间和有限宽度界限。

Abstract: Continuous-time models provide important insights into the training dynamics
of optimization algorithms in deep learning. In this work, we establish a
non-asymptotic convergence analysis of stochastic gradient Langevin dynamics
(SGLD), which is an It\^o stochastic differential equation (SDE) approximation
of stochastic gradient descent in continuous time, in the lazy training regime.
We show that, under regularity conditions on the Hessian of the loss function,
SGLD with multiplicative and state-dependent noise (i) yields a non-degenerate
kernel throughout the training process with high probability, and (ii) achieves
exponential convergence to the empirical risk minimizer in expectation, and we
establish finite-time and finite-width bounds on the optimality gap. We
corroborate our theoretical findings with numerical examples in the regression
setting.

</details>


### [136] [Relieving the Over-Aggregating Effect in Graph Transformers](https://arxiv.org/abs/2510.21267)
*Junshu Sun,Wanxing Chang,Chenxue Yang,Qingming Huang,Shuhui Wang*

Main category: cs.LG

TL;DR: Graph attention在图学习任务中表现优异，但存在过度聚合现象导致信息丢失。为此，提出了Wideformer方法，通过并行处理和重点关注特定子集来缓解此问题。


<details>
  <summary>Details</summary>
Motivation: 为了克服在图学习任务中由于节点数量庞大而导致的全局交互学习难题，尤其是过度聚合现象。

Method: Wideformer通过将节点的聚合分为多个并行过程，指导模型聚焦于特定子集，限制每次聚合的输入量，避免信息稀释。

Result: Wideformer有效缓解了过度聚合现象，使得模型能够侧重于有用信息，从而在图学习任务中表现优于基线方法。

Conclusion: Wideformer显著减少了信息损失，提高了图学习任务的性能。

Abstract: Graph attention has demonstrated superior performance in graph learning
tasks. However, learning from global interactions can be challenging due to the
large number of nodes. In this paper, we discover a new phenomenon termed
over-aggregating. Over-aggregating arises when a large volume of messages is
aggregated into a single node with less discrimination, leading to the dilution
of the key messages and potential information loss. To address this, we propose
Wideformer, a plug-and-play method for graph attention. Wideformer divides the
aggregation of all nodes into parallel processes and guides the model to focus
on specific subsets of these processes. The division can limit the input volume
per aggregation, avoiding message dilution and reducing information loss. The
guiding step sorts and weights the aggregation outputs, prioritizing the
informative messages. Evaluations show that Wideformer can effectively mitigate
over-aggregating. As a result, the backbone methods can focus on the
informative messages, achieving superior performance compared to baseline
methods.

</details>


### [137] [Buffer layers for Test-Time Adaptation](https://arxiv.org/abs/2510.21271)
*Hyeongyu Kim,Geonhui Han,Dosik Hwang*

Main category: cs.LG

TL;DR: 本论文提出了基于Buffer层的新范式，改善现有的归一化层适应方法，提升模型在域偏移中的表现和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 改善测试时适应（TTA）的方法，克服归一化层对小批量和预训练模型结构的敏感性

Method: 引入Buffer层作为新范式，解决归一化层更新的局限性

Result: 提出的方法在缓解域偏移和增强模型鲁棒性方面优于传统方法，且对遗忘表现出较强的韧性

Conclusion: 提出的Buffer层在实际域适应场景中验证了其有效性和通用性，适用于几乎所有现有TTA框架。

Abstract: In recent advancements in Test Time Adaptation (TTA), most existing
methodologies focus on updating normalization layers to adapt to the test
domain. However, the reliance on normalization-based adaptation presents key
challenges. First, normalization layers such as Batch Normalization (BN) are
highly sensitive to small batch sizes, leading to unstable and inaccurate
statistics. Moreover, normalization-based adaptation is inherently constrained
by the structure of the pre-trained model, as it relies on training-time
statistics that may not generalize well to unseen domains. These issues limit
the effectiveness of normalization-based TTA approaches, especially under
significant domain shift. In this paper, we introduce a novel paradigm based on
the concept of a Buffer layer, which addresses the fundamental limitations of
normalization layer updates. Unlike existing methods that modify the core
parameters of the model, our approach preserves the integrity of the
pre-trained backbone, inherently mitigating the risk of catastrophic forgetting
during online adaptation. Through comprehensive experimentation, we demonstrate
that our approach not only outperforms traditional methods in mitigating domain
shift and enhancing model robustness, but also exhibits strong resilience to
forgetting. Furthermore, our Buffer layer is modular and can be seamlessly
integrated into nearly all existing TTA frameworks, resulting in consistent
performance improvements across various architectures. These findings validate
the effectiveness and versatility of the proposed solution in real-world domain
adaptation scenarios. The code is available at
https://github.com/hyeongyu-kim/Buffer_TTA.

</details>


### [138] [Additive Models Explained: A Computational Complexity Approach](https://arxiv.org/abs/2510.21292)
*Shahaf Bassan,Michal Moshkovitz,Guy Katz*

Main category: cs.LG

TL;DR: 本文分析了广义加性模型（GAMs）生成解释的计算复杂性，挑战了其解释能力的有效性假设，揭示了不同上下文下的复杂性多样性。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在验证GAMs生成有意义解释的效率与可行性，并分析其计算复杂性。

Method: 通过对多种GAMs形式的分析，考察了在多个上下文中生成解释的计算复杂性。

Result: 发现生成GAMs的解释复杂性受输入空间结构和模型类型显著影响，并在回归任务与分类任务之间存在显著差异；复杂模型的加性表达可以在特定方法和输入条件下简化解释。

Conclusion: 生成GAMs的解释的计算复杂性受到输入空间结构、组件模型类型及任务类型的显著影响，而表达复杂模型为加性形式可在特定情况下简化解释过程。

Abstract: Generalized Additive Models (GAMs) are commonly considered *interpretable*
within the ML community, as their structure makes the relationship between
inputs and outputs relatively understandable. Therefore, it may seem natural to
hypothesize that obtaining meaningful explanations for GAMs could be performed
efficiently and would not be computationally infeasible. In this work, we
challenge this hypothesis by analyzing the *computational complexity* of
generating different explanations for various forms of GAMs across multiple
contexts. Our analysis reveals a surprisingly diverse landscape of both
positive and negative complexity outcomes. Particularly, under standard
complexity assumptions such as P!=NP, we establish several key findings: (1) in
stark contrast to many other common ML models, the complexity of generating
explanations for GAMs is heavily influenced by the structure of the input
space; (2) the complexity of explaining GAMs varies significantly with the
types of component models used - but interestingly, these differences only
emerge under specific input domain settings; (3) significant complexity
distinctions appear for obtaining explanations in regression tasks versus
classification tasks in GAMs; and (4) expressing complex models like neural
networks additively (e.g., as neural additive models) can make them easier to
explain, though interestingly, this benefit appears only for certain
explanation methods and input domains. Collectively, these results shed light
on the feasibility of computing diverse explanations for GAMs, offering a
rigorous theoretical picture of the conditions under which such computations
are possible or provably hard.

</details>


### [139] [An Evidence-Based Post-Hoc Adjustment Framework for Anomaly Detection Under Data Contamination](https://arxiv.org/abs/2510.21296)
*Sukanya Patra,Souhaib Ben Taieb*

Main category: cs.LG

TL;DR: EPHAD是一个简单有效的测试时适应框架，针对训练数据中的标记错误和未检测异常的问题，旨在提高无监督异常检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现实世界的数据集常常含有未检测或错误标记的异常，导致现有无监督异常检测方法性能下降，因此有必要发展新方法以提高模型的鲁棒性和适用性。

Method: EPHAD通过结合已污染数据集上训练的异常检测模型的先验知识与多模态基础模型（如CLIP）和传统异常检测方法的证据，在测试阶段更新模型输出。

Result: 通过对八个视觉异常检测数据集、二十六个表格异常检测数据集和一个真实工业异常检测数据集的全面实验，验证了EPHAD的有效性。

Conclusion: EPHAD在多种异常检测场景中表现出色，展示了其在不同模型和证据组合下的多样性和稳健性。

Abstract: Unsupervised anomaly detection (AD) methods typically assume clean training
data, yet real-world datasets often contain undetected or mislabeled anomalies,
leading to significant performance degradation. Existing solutions require
access to the training pipelines, data or prior knowledge of the proportions of
anomalies in the data, limiting their real-world applicability. To address this
challenge, we propose EPHAD, a simple yet effective test-time adaptation
framework that updates the outputs of AD models trained on contaminated
datasets using evidence gathered at test time. Our approach integrates the
prior knowledge captured by the AD model trained on contaminated datasets with
evidence derived from multimodal foundation models like Contrastive
Language-Image Pre-training (CLIP), classical AD methods like the Latent
Outlier Factor or domain-specific knowledge. We illustrate the intuition behind
EPHAD using a synthetic toy example and validate its effectiveness through
comprehensive experiments across eight visual AD datasets, twenty-six tabular
AD datasets, and a real-world industrial AD dataset. Additionally, we conduct
an ablation study to analyse hyperparameter influence and robustness to varying
contamination levels, demonstrating the versatility and robustness of EPHAD
across diverse AD models and evidence pairs. To ensure reproducibility, our
code is publicly available at https://github.com/sukanyapatra1997/EPHAD.

</details>


### [140] [Data as a Lever: A Neighbouring Datasets Perspective on Predictive Multiplicity](https://arxiv.org/abs/2510.21303)
*Prakhar Ganesh,Hsiang Hsu,Golnoosh Farnadi*

Main category: cs.LG

TL;DR: 研究探讨了数据对模型多重性的影响，发现邻近数据集重叠度高时，多重性反而降低，并在主动学习和数据插补领域提出了新方法。


<details>
  <summary>Details</summary>
Motivation: 探讨数据对模型多重性的影响，以弥补以往研究对模型选择的关注，提出数据驱动的多重性理解。

Method: 引入邻近数据集框架，分析数据点差异对模型多重性的影响，并在实践中扩展至主动学习和数据插补。

Result: 本文探讨了模型多重性，着重于数据在形成多重性中的关键作用。研究引入了邻近数据集框架，分析了单数据点差异对多重性的影响，发现相较于传统预期，类别间分布重叠更大的邻近数据集表现出更低的多重性。基于这一发现，研究进一步扩展到主动学习和数据插补等实际领域，建立了自然扩展，进行系统性研究，并提出了新的多重性意识方法。

Conclusion: 数据在模型多重性中的作用被重新审视，提出的邻近数据集方法在实践中具有潜在应用价值。

Abstract: Multiplicity -- the existence of distinct models with comparable performance
-- has received growing attention in recent years. While prior work has largely
emphasized modelling choices, the critical role of data in shaping multiplicity
has been comparatively overlooked. In this work, we introduce a neighbouring
datasets framework to examine the most granular case: the impact of a
single-data-point difference on multiplicity. Our analysis yields a seemingly
counterintuitive finding: neighbouring datasets with greater inter-class
distribution overlap exhibit lower multiplicity. This reversal of conventional
expectations arises from a shared Rashomon parameter, and we substantiate it
with rigorous proofs.
  Building on this foundation, we extend our framework to two practical
domains: active learning and data imputation. For each, we establish natural
extensions of the neighbouring datasets perspective, conduct the first
systematic study of multiplicity in existing algorithms, and finally, propose
novel multiplicity-aware methods, namely, multiplicity-aware data acquisition
strategies for active learning and multiplicity-aware data imputation
techniques.

</details>


### [141] [A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization](https://arxiv.org/abs/2510.21314)
*Xuan Tang,Jichu Li,Difan Zou*

Main category: cs.LG

TL;DR: 本文提出了一个理论框架来分析自适应优化器在低精度训练下的收敛性，发现Adam和Muon在量化方面的敏感性及其在低精度训练中的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的快速发展，低精度训练变得至关重要，以减少内存、提高效率并支持更大的模型和数据集。然而，现有的适应性优化器收敛理论假设所有组件都是精确的，忽略了硬件感知的量化，这引出了低精度训练有效性的疑问。

Method: 我们建立了一个理论框架来分析在浮点量化下自适应优化器（如Adam和Muon）的收敛性，并推导了在标准随机梯度假设下的光滑非凸目标的收敛速率。

Result: 我们的分析进一步揭示了两种算法在满足标准随机梯度假设下接近全精度相应的收敛率，前提是尾数长度与迭代次数仅以对数比例缩放。数值实验验证了我们的理论。

Conclusion: Adam对权重和二阶矩量化高度敏感，而Muon在误差控制方面要求较弱，因此更加稳健。这些结果缩小了低精度训练方法的经验成功与理论理解之间的差距。

Abstract: The rapid scaling of large language models (LLMs) has made low-precision
training essential for reducing memory, improving efficiency, and enabling
larger models and datasets. Existing convergence theories for adaptive
optimizers, however, assume all components are exact and neglect hardware-aware
quantization, leaving open the question of why low-precision training remains
effective. We introduce the first theoretical framework for analyzing the
convergence of adaptive optimizers, including Adam and Muon, under
floating-point quantization of gradients, weights, and optimizer states (e.g.,
moment estimates). Within this framework, we derive convergence rates on smooth
non-convex objectives under standard stochastic gradient assumptions,
explicitly characterizing how quantization errors from different components
affect convergence. We show that both algorithms retain rates close to their
full-precision counterparts provided mantissa length scales only
logarithmically with the number of iterations. Our analysis further reveals
that Adam is highly sensitive to weights and second-moment quantization due to
its reliance on $\beta_2 \to 1$, while Muon requires weaker error control and
is thus potentially more robust. These results narrow the gap between empirical
success and theoretical understanding of low-precision training methods.
Numerical experiments on synthetic and real-world data corroborate our theory.

</details>


### [142] [SCORENF: Score-based Normalizing Flows for Sampling Unnormalized distributions](https://arxiv.org/abs/2510.21330)
*Vikas Kanaujia,Vipul Arora*

Main category: cs.LG

TL;DR: 提出了一种新的采样框架ScoreNF，它结合了标准化流架构和独立Metropolis-Hastings模块，旨在从未规范化的目标分布中高效、无偏地进行采样。


<details>
  <summary>Details</summary>
Motivation: 解决传统采样方法的慢收敛、模式混合差和高自相关等问题，提供替代方案以减少对大数据集的依赖。

Method: 提出了ScoreNF框架，结合标准化流架构与独立Metropolis-Hastings模块，以实现高效、无偏的采样。

Result: 在合成2D分布（如MOG-4和MOG-8）及高维$
abla^4$格点场理论分布上验证了ScoreNF的有效性和性能。

Conclusion: ScoreNF在小型训练集上表现良好，有效减少了对传统MCMC数据的依赖，并在多种分布上验证了其有效性。

Abstract: Unnormalized probability distributions are central to modeling complex
physical systems across various scientific domains. Traditional sampling
methods, such as Markov Chain Monte Carlo (MCMC), often suffer from slow
convergence, critical slowing down, poor mode mixing, and high autocorrelation.
In contrast, likelihood-based and adversarial machine learning models, though
effective, are heavily data-driven, requiring large datasets and often
encountering mode covering and mode collapse. In this work, we propose ScoreNF,
a score-based learning framework built on the Normalizing Flow (NF)
architecture, integrated with an Independent Metropolis-Hastings (IMH) module,
enabling efficient and unbiased sampling from unnormalized target
distributions. We show that ScoreNF maintains high performance even with small
training ensembles, thereby reducing reliance on computationally expensive
MCMC-generated training data. We also present a method for assessing
mode-covering and mode-collapse behaviours. We validate our method on synthetic
2D distributions (MOG-4 and MOG-8) and the high-dimensional $\phi^4$ lattice
field theory distribution, demonstrating its effectiveness for sampling tasks.

</details>


### [143] [Weak-to-Strong Generalization under Distribution Shifts](https://arxiv.org/abs/2510.21332)
*Myeongho Jeon,Jan Sobotka,Suhwan Choi,Maria Brbić*

Main category: cs.LG

TL;DR: RAVEN是一种新框架，通过动态组合弱模型来提升强模型的监督效能，克服了传统弱到强泛化在分布转移中的失败。


<details>
  <summary>Details</summary>
Motivation: 探讨在未来复杂的超人类模型中，弱模型如何有效地监督强模型，尤其是在分布转移情况下的挑战。

Method: 提出了一种名为RAVEN的框架，通过动态学习最优的弱模型组合来增强强模型的监督能力。

Result: RAVEN在图像分类、文本分类和偏好对齐任务中表现出色，在分布外任务上比其他基线方法提高超过30%，同时在分布内任务上与现有方法持平或超越。

Conclusion: RAVEN有效地识别可信的监督，通过给予更准确的弱模型更高的权重，实现了对强模型的更好监督。

Abstract: As future superhuman models become increasingly complex, accurately
supervising their behavior may exceed human capabilities. Recent works have
demonstrated that in such scenarios, weak models can effectively supervise
strong models, a phenomenon known as weak-to-strong generalization. However, we
find that naive weak-to-strong generalization fails under distribution shifts,
often leading to worse performance of the strong model than its weak
supervisors. To address this, we propose RAVEN, a robust weak-to-strong
generalization framework that dynamically learns the optimal combinations of
weak models in addition to parameters of the strong model. We demonstrate the
effectiveness of RAVEN on image classification, text classification, and
preference alignment tasks. RAVEN outperforms alternative baselines by over 30%
on out-of-distribution tasks while matching or surpassing existing methods on
in-distribution tasks. Moreover, our results show that RAVEN assigns higher
weights to more accurate weak models, demonstrating its ability to
automatically identify trustworthy supervision.

</details>


### [144] [$α$-LoRA: Effective Fine-Tuning via Base Model Rescaling](https://arxiv.org/abs/2510.21345)
*Aymane El Firdoussi,El Mahdi Chayti,Mohamed El Amine Seddik,Martin Jaggi*

Main category: cs.LG

TL;DR: 本文介绍了一类新的重参数化方法，旨在提高微调模型的泛化能力，并通过随机矩阵理论和实验进行了验证。


<details>
  <summary>Details</summary>
Motivation: 研究预训练模型在新的任务上表现良好的能力及其在最小数据样本下的适应性。

Method: 采用随机矩阵理论工具建立理论基础，并通过微调大型语言模型（LLMs）等更现实的实验进行验证。

Result: 提出了一种新类的重参数化方法，旨在增强微调模型的泛化能力，并在高维二分类设置中验证了其有效性。

Conclusion: 我们的重参数化方法在理论和实际应用中均显示出了增强泛化能力的潜力。

Abstract: Fine-tuning has proven to be highly effective in adapting pre-trained models
to perform better on new desired tasks with minimal data samples. Among the
most widely used approaches are reparameterization methods, which update a
target module by augmenting its frozen weight matrix with an additional
trainable weight matrix. The most prominent example is Low Rank Adaption
(LoRA), which gained significant attention in recent years. In this paper, we
introduce a new class of reparameterization methods for transfer learning,
designed to enhance the generalization ability of fine-tuned models. We
establish the effectiveness of our approach in a high-dimensional binary
classification setting using tools from Random Matrix Theory, and further
validate our theoretical findings through more realistic experiments, such as
fine-tuning LLMs.

</details>


### [145] [Compositional Monte Carlo Tree Diffusion for Extendable Planning](https://arxiv.org/abs/2510.21361)
*Jaesik Yoon,Hyeonseo Cho,Sungjin Ahn*

Main category: cs.LG

TL;DR: C-MCTD 是一种新框架，通过引入三个组件提高了 Monte Carlo Tree Diffusion 的规划能力，解决了局部搜索的局限性，实现全局计划组合推理。


<details>
  <summary>Details</summary>
Motivation: MCTD 的局限性在于其训练轨迹长度和局部搜索，无法有效利用全局上下文进行轨迹生成。

Method: 提出了三种互补的组件：在线作曲器、分布式作曲器和预规划作曲器，以增强规划能力。

Result: C-MCTD 提供了一种新的将计划优化提升到完整计划组合的推理框架，显著提高了轨迹探索的有效性。

Conclusion: C-MCTD 通过引入全局感知规划、并行探索和缓存计划图的方式，提升了轨迹生成的效率和效果。

Abstract: Monte Carlo Tree Diffusion (MCTD) integrates diffusion models with structured
tree search to enable effective trajectory exploration through stepwise
reasoning. However, MCTD remains fundamentally limited by training trajectory
lengths. While periodic replanning allows plan concatenation for longer plan
generation, the planning process remains locally confined, as MCTD searches
within individual trajectories without access to global context. We propose
Compositional Monte Carlo Tree Diffusion (C-MCTD), a framework that elevates
planning from individual trajectory optimization to reasoning over complete
plan compositions. C-MCTD introduces three complementary components: (1) Online
Composer, which performs globally-aware planning by searching across entire
plan compositions; (2) Distributed Composer, which reduces search complexity
through parallel exploration from multiple starting points; and (3) Preplan
Composer, which accelerates inference by leveraging cached plan graphs.

</details>


### [146] [Disentangled Representation Learning via Modular Compositional Bias](https://arxiv.org/abs/2510.21402)
*Whie Jung,Dong Hoon Lee,Seunghoon Hong*

Main category: cs.LG

TL;DR: 提出了一种新的组合偏置，用于解开属性和对象的表示，而无需修改目标或模型架构。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有解耦表示学习方法在面对新变化因素时的重大开销问题。

Method: 通过随机混合潜在变量并使用两种互补目标（解码损失和组合一致性损失）来学习不同因素在数据分布中的重组规则。

Result: 实验表明，该方法在属性和对象的解耦上均表现出色，独特地实现了全局样式和对象的联合解耦。

Conclusion: 本文提出的组合偏置方法在属性和对象解耦方面表现出竞争力，并成功实现了全局风格和对象的联合解耦。

Abstract: Recent disentangled representation learning (DRL) methods heavily rely on
factor specific strategies-either learning objectives for attributes or model
architectures for objects-to embed inductive biases. Such divergent approaches
result in significant overhead when novel factors of variation do not align
with prior assumptions, such as statistical independence or spatial
exclusivity, or when multiple factors coexist, as practitioners must redesign
architectures or objectives. To address this, we propose a compositional bias,
a modular inductive bias decoupled from both objectives and architectures. Our
key insight is that different factors obey distinct recombination rules in the
data distribution: global attributes are mutually exclusive, e.g., a face has
one nose, while objects share a common support (any subset of objects can
co-exist). We therefore randomly remix latents according to factor-specific
rules, i.e., a mixing strategy, and force the encoder to discover whichever
factor structure the mixing strategy reflects through two complementary
objectives: (i) a prior loss that ensures every remix decodes into a realistic
image, and (ii) the compositional consistency loss introduced by Wiedemer et
al. (arXiv:2310.05327), which aligns each composite image with its
corresponding composite latent. Under this general framework, simply adjusting
the mixing strategy enables disentanglement of attributes, objects, and even
both, without modifying the objectives or architectures. Extensive experiments
demonstrate that our method shows competitive performance in both attribute and
object disentanglement, and uniquely achieves joint disentanglement of global
style and objects. Code is available at
https://github.com/whieya/Compositional-DRL.

</details>


### [147] [Cost-Sensitive Freeze-thaw Bayesian Optimization for Efficient Hyperparameter Tuning](https://arxiv.org/abs/2510.21379)
*Dong Bok Lee,Aoxuan Silvia Zhang,Byungjoo Kim,Junhyeon Park,Steven Adriaensen,Juho Lee,Sung Ju Hwang,Hae Beom Lee*

Main category: cs.LG

TL;DR: 本文提出了一种基于用户偏好的实用性函数来优化超参数的冷却-重启贝叶斯优化方法，以提高成本与性能之间的平衡。


<details>
  <summary>Details</summary>
Motivation: 解决在成本敏感超参数优化过程中用户对性能改进和计算成本之间的权衡问题。

Method: 结合实用性函数，提出了一种新的采集函数和停止标准，同时采用迁移学习提升现有方法的样本效率。

Result: 提出了一种新的实用性函数结合收缩-重启贝叶斯优化的方法，能够根据用户的偏好动态调整超参数优化过程。

Conclusion: 实验结果表明，该算法在传统的多保真超参数优化基准上表现优异，且在成本与性能的权衡上更为显著。

Abstract: In this paper, we address the problem of \emph{cost-sensitive} hyperparameter
optimization (HPO) built upon freeze-thaw Bayesian optimization (BO).
Specifically, we assume a scenario where users want to early-stop the HPO
process when the expected performance improvement is not satisfactory with
respect to the additional computational cost. Motivated by this scenario, we
introduce \emph{utility} in the freeze-thaw framework, a function describing
the trade-off between the cost and performance that can be estimated from the
user's preference data. This utility function, combined with our novel
acquisition function and stopping criterion, allows us to dynamically continue
training the configuration that we expect to maximally improve the utility in
the future, and also automatically stop the HPO process around the maximum
utility. Further, we improve the sample efficiency of existing freeze-thaw
methods with transfer learning to develop a specialized surrogate model for the
cost-sensitive HPO problem. We validate our algorithm on established
multi-fidelity HPO benchmarks and show that it outperforms all the previous
freeze-thaw BO and transfer-BO baselines we consider, while achieving a
significantly better trade-off between the cost and performance. Our code is
publicly available at https://github.com/db-Lee/CFBO.

</details>


### [148] [Large Language Models as Model Organisms for Human Associative Learning](https://arxiv.org/abs/2510.21408)
*Camila Kolling,Vy Ai Vo,Mariya Toneva*

Main category: cs.LG

TL;DR: 本文利用大型语言模型研究关联学习，发现相似项在学习中的表现差异与词汇干扰有关，对表示变化的影响显著。


<details>
  <summary>Details</summary>
Motivation: 探究生物系统中表征变化的机制，以及LLMs如何提供可扩展的研究方法

Method: 使用大型语言模型（LLMs）来研究关联学习中表征的演变

Result: 发现与非单调可塑性假说一致的非单调模式；相似性适中的项目在学习后表现出差异化

Conclusion: LLMs可作为研究人类学习系统表征动态的强大工具，并为脑内记忆重组原理生成新假设提供便利。

Abstract: Associative learning--forming links between co-occurring items--is
fundamental to human cognition, reshaping internal representations in complex
ways. Testing hypotheses on how representational changes occur in biological
systems is challenging, but large language models (LLMs) offer a scalable
alternative. Building on LLMs' in-context learning, we adapt a cognitive
neuroscience associative learning paradigm and investigate how representations
evolve across six models. Our initial findings reveal a non-monotonic pattern
consistent with the Non-Monotonic Plasticity Hypothesis, with moderately
similar items differentiating after learning. Leveraging the controllability of
LLMs, we further show that this differentiation is modulated by the overlap of
associated items with the broader vocabulary--a factor we term vocabulary
interference, capturing how new associations compete with prior knowledge. We
find that higher vocabulary interference amplifies differentiation, suggesting
that representational change is influenced by both item similarity and global
competition. Our findings position LLMs not only as powerful tools for studying
representational dynamics in human-like learning systems, but also as
accessible and general computational models for generating new hypotheses about
the principles underlying memory reorganization in the brain.

</details>


### [149] [DreamerV3-XP: Optimizing exploration through uncertainty estimation](https://arxiv.org/abs/2510.21418)
*Lukas Bierling,Davide Pasero,Jan-Henrik Bertrand,Kiki Van Gerwen*

Main category: cs.LG

TL;DR: DreamerV3-XP扩展了DreamerV3，提高了探索和学习效率，尤其在稀疏奖励设置下表现更佳。


<details>
  <summary>Details</summary>
Motivation: 为了解决探索和稀疏奖励问题，提高强化学习中的学习效率。

Method: 使用优先重放缓冲区和基于模型集合的内在奖励来提高学习效率。

Result: DreamerV3-XP是DreamerV3的扩展，旨在提高探索和学习效率。它包括一种优先重放缓冲区，通过回报、重建损失和价值误差对轨迹进行评分，以及一种基于环境奖励预测不一致性的内在奖励。DreamerV3-XP在Atari100k和DeepMind Control Visual Benchmark任务的子集上进行了评估，证实了原始DreamerV3的结果，并显示出我们的扩展在稀疏奖励的情况下能够更快学习和降低动态模型损失。

Conclusion: DreamerV3-XP的扩展使得模型在学习效率和动态模型损失方面性能更好，特别是在稀疏奖励的环境中。

Abstract: We introduce DreamerV3-XP, an extension of DreamerV3 that improves
exploration and learning efficiency. This includes (i) a prioritized replay
buffer, scoring trajectories by return, reconstruction loss, and value error
and (ii) an intrinsic reward based on disagreement over predicted environment
rewards from an ensemble of world models. DreamerV3-XP is evaluated on a subset
of Atari100k and DeepMind Control Visual Benchmark tasks, confirming the
original DreamerV3 results and showing that our extensions lead to faster
learning and lower dynamics model loss, particularly in sparse-reward settings.

</details>


### [150] [Unified token representations for sequential decision models](https://arxiv.org/abs/2510.21448)
*Zhuojing Tian,Yushu Chen*

Main category: cs.LG

TL;DR: 提出统一的令牌表示（UTR），通过合并返回状态和行为，降低模型复杂性，提升离线强化学习的效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在实时或资源受限环境下的可扩展性问题，优化离线强化学习中的模型复杂性和计算量。

Method: 通过将返回值、状态和动作合并为单个令牌，减少序列长度，并进行理论分析以验证更好的泛化能力。开发UDT和UDC两种基于不同架构的变体，并进行性能比较。

Result: 提出了一种统一的令牌表示（UTR），显著减少序列长度和模型复杂性，并开发了两个变体（UDT 和 UDC），在性能和计算上优于现有的最先进方法。

Conclusion: UTR在不同架构中表现出良好的泛化能力，为未来大规模决策模型的可扩展控制提供了高效基础。

Abstract: Transformers have demonstrated strong potential in offline reinforcement
learning (RL) by modeling trajectories as sequences of return-to-go, states,
and actions. However, existing approaches such as the Decision Transformer(DT)
and its variants suffer from redundant tokenization and quadratic attention
complexity, limiting their scalability in real-time or resource-constrained
settings. To address this, we propose a Unified Token Representation (UTR) that
merges return-to-go, state, and action into a single token, substantially
reducing sequence length and model complexity. Theoretical analysis shows that
UTR leads to a tighter Rademacher complexity bound, suggesting improved
generalization. We further develop two variants: UDT and UDC, built upon
transformer and gated CNN backbones, respectively. Both achieve comparable or
superior performance to state-of-the-art methods with markedly lower
computation. These findings demonstrate that UTR generalizes well across
architectures and may provide an efficient foundation for scalable control in
future large decision models.

</details>


### [151] [Towards Explainable Personalized Recommendations by Learning from Users' Photos](https://arxiv.org/abs/2510.21455)
*Jorge Díez,Pablo Pérez-Núñez,Oscar Luaces,Beatriz Remeseiro,Antonio Bahamonde*

Main category: cs.LG

TL;DR: 本研究探讨了如何通过用户上传的照片为推荐系统提供个性化解释，以增强系统的可靠性和公司对产品特性的理解。


<details>
  <summary>Details</summary>
Motivation: 在复杂系统（如推荐系统）中，为用户和公司提供透明的解释变得至关重要，以增强信任并改善服务品质。

Method: 建立一个正式框架来估算给定用户和照片对的著作概率，以进行用户个性化的照片推荐。

Result: 基于TripAdvisor从六个不同规模城市的餐厅评论（含照片）收集的数据，成功展示了个性化照片推荐的有效性和实用性。

Conclusion: 通过构建预测用户拍照内容的模型，可以为推荐系统提供更可信的解释，同时帮助公司了解客户关注的产品特点。

Abstract: Explaining the output of a complex system, such as a Recommender System (RS),
is becoming of utmost importance for both users and companies. In this paper we
explore the idea that personalized explanations can be learned as
recommendation themselves. There are plenty of online services where users can
upload some photos, in addition to rating items. We assume that users take
these photos to reinforce or justify their opinions about the items. For this
reason we try to predict what photo a user would take of an item, because that
image is the argument that can best convince her of the qualities of the item.
In this sense, an RS can explain its results and, therefore, increase its
reliability. Furthermore, once we have a model to predict attractive images for
users, we can estimate their distribution. Thus, the companies acquire a vivid
knowledge about the aspects that the clients highlight of their products. The
paper includes a formal framework that estimates the authorship probability for
a given pair (user, photo). To illustrate the proposal, we use data gathered
from TripAdvisor containing the reviews (with photos) of restaurants in six
cities of different sizes.

</details>


### [152] [Benchmarking Catastrophic Forgetting Mitigation Methods in Federated Time Series Forecasting](https://arxiv.org/abs/2510.21491)
*Khaled Hallak,Oudom Kem*

Main category: cs.LG

TL;DR: 本文介绍了一个新基准框架，用于研究联邦学习中的时间序列预测中的灾难性遗忘，并评估了多种缓解策略。


<details>
  <summary>Details</summary>
Motivation: 研究连续学习中的灾难性遗忘问题，特别是在联邦学习环境下处理非独立同分布的时间序列数据。

Method: 使用北京多站点空气质量数据集，在12个去中心化客户端上系统评估了Replay、弹性权重巩固、忘记无关学习和突触智能等多种灾难性遗忘缓解策略。

Result: 提出了针对联邦连续时间序列预测的首个基准框架并系统评估了多种灾难性遗忘缓解策略。

Conclusion: 这项工作为推进联邦时间序列预测系统中的连续学习提供了必要的工具和见解。

Abstract: Catastrophic forgetting (CF) poses a persistent challenge in continual
learning (CL), especially within federated learning (FL) environments
characterized by non-i.i.d. time series data. While existing research has
largely focused on classification tasks in vision domains, the regression-based
forecasting setting prevalent in IoT and edge applications remains
underexplored. In this paper, we present the first benchmarking framework
tailored to investigate CF in federated continual time series forecasting.
Using the Beijing Multi-site Air Quality dataset across 12 decentralized
clients, we systematically evaluate several CF mitigation strategies, including
Replay, Elastic Weight Consolidation, Learning without Forgetting, and Synaptic
Intelligence. Key contributions include: (i) introducing a new benchmark for CF
in time series FL, (ii) conducting a comprehensive comparative analysis of
state-of-the-art methods, and (iii) releasing a reproducible open-source
framework. This work provides essential tools and insights for advancing
continual learning in federated time-series forecasting systems.

</details>


### [153] [Uniform Convergence Beyond Glivenko-Cantelli](https://arxiv.org/abs/2510.21506)
*Tanmay Devale,Pramith Devulapalli,Steve Hanneke*

Main category: cs.LG

TL;DR: 研究均值估计的统一可学习性，通过建立充分条件与构造反例，拓展均值估计的理论框架。


<details>
  <summary>Details</summary>
Motivation: 在先前的Vapnik和Chervonenkis的工作基础上，提升了对均值估计的一般化理解。

Method: 引入Uniform Mean Estimability (UME-) 可学习性，通过对任意估计器的均值估计进行统一分析。

Result: 揭示了均值向量的可分性是UME可学习的充分条件，但不是必要条件。构建了非可分均值向量但仍然是UME可学习的分布集合。并证明可数个UME可学习集合并集也是UME可学习的。

Conclusion: 该研究不仅深化了对UME可学习性的理解，还解决了Cohen等人提出的一个相关猜想。

Abstract: We characterize conditions under which collections of distributions on
$\{0,1\}^\mathbb{N}$ admit uniform estimation of their mean. Prior work from
Vapnik and Chervonenkis (1971) has focused on uniform convergence using the
empirical mean estimator, leading to the principle known as $P-$
Glivenko-Cantelli. We extend this framework by moving beyond the empirical mean
estimator and introducing Uniform Mean Estimability, also called $UME-$
learnability, which captures when a collection permits uniform mean estimation
by any arbitrary estimator. We work on the space created by the mean vectors of
the collection of distributions. For each distribution, the mean vector records
the expected value in each coordinate. We show that separability of the mean
vectors is a sufficient condition for $UME-$ learnability. However, we show
that separability of the mean vectors is not necessary for $UME-$ learnability
by constructing a collection of distributions whose mean vectors are
non-separable yet $UME-$ learnable using techniques fundamentally different
from those used in our separability-based analysis. Finally, we establish that
countable unions of $UME-$ learnable collections are also $UME-$ learnable,
solving a conjecture posed in Cohen et al. (2025).

</details>


### [154] [Generative Correlation Manifolds: Generating Synthetic Data with Preserved Higher-Order Correlations](https://arxiv.org/abs/2510.21610)
*Jens E. d'Hondt,Wieger R. Punter,Odysseas Papapetrou*

Main category: cs.LG

TL;DR: 提出了一种新的合成数据生成方法GCM，保留完整的相关结构，适用于数据隐私与模型训练。


<details>
  <summary>Details</summary>
Motivation: 应对数据隐私需求和强大的机器学习模型的开发，解决现有方法在复杂多变量交互中的不足。

Method: 使用目标相关矩阵的Cholesky分解生成合成数据集。

Result: 生成的数据保持了源数据集的完整相关结构，适用于隐私保护的数据共享与模型训练。

Conclusion: GCM方法通过保留整个相关结构，提供了一种新的合成数据生成方法，具有很大的应用潜力。

Abstract: The increasing need for data privacy and the demand for robust machine
learning models have fueled the development of synthetic data generation
techniques. However, current methods often succeed in replicating simple
summary statistics but fail to preserve both the pairwise and higher-order
correlation structure of the data that define the complex, multi-variable
interactions inherent in real-world systems. This limitation can lead to
synthetic data that is superficially realistic but fails when used for
sophisticated modeling tasks. In this white paper, we introduce Generative
Correlation Manifolds (GCM), a computationally efficient method for generating
synthetic data. The technique uses Cholesky decomposition of a target
correlation matrix to produce datasets that, by mathematical proof, preserve
the entire correlation structure -- from simple pairwise relationships to
higher-order interactions -- of the source dataset. We argue that this method
provides a new approach to synthetic data generation with potential
applications in privacy-preserving data sharing, robust model training, and
simulation.

</details>


### [155] [Probe-based Fine-tuning for Reducing Toxicity](https://arxiv.org/abs/2510.21531)
*Jan Wehner,Mario Fritz*

Main category: cs.LG

TL;DR: 本论文探讨利用探针监测模型内部行为的可行性，提出两种训练方法以降低模型的有害行为，同时评估探针准确性在训练过程中的变化，并提出保持探针准确性的策略。


<details>
  <summary>Details</summary>
Motivation: 通过训练模型使其内部过程更可解释，以便更好地识别不当行为并提升模型输出的质量。

Method: 提出两种基于监督微调和直接偏好优化的训练方法，并在一个减少毒性的测试平台中进行初步探索。

Result: 探针基础的偏好优化在保持探测能力方面表现优于分类器方法，而探针的多样性带来的实际好处较小，再训练探针可以恢复高度的检测准确性。

Conclusion: 探针基础的训练方法在某些对齐方法中是可行的，但探针的多样性在再训练可行时并不是必需的。

Abstract: Probes trained on model activations can detect undesirable behaviors like
deception or biases that are difficult to identify from outputs alone. This
makes them useful detectors to identify misbehavior. Furthermore, they are also
valuable training signals, since they not only reward outputs, but also good
internal processes for arriving at that output. However, training against
interpretability tools raises a fundamental concern: when a monitor becomes a
training target, it may cease to be reliable (Goodhart's Law). We propose two
methods for training against probes based on Supervised Fine-tuning and Direct
Preference Optimization. We conduct an initial exploration of these methods in
a testbed for reducing toxicity and evaluate the amount by which probe accuracy
drops when training against them. To retain the accuracy of probe-detectors
after training, we attempt (1) to train against an ensemble of probes, (2)
retain held-out probes that aren't used for training, and (3) retrain new
probes after training.
  First, probe-based preference optimization unexpectedly preserves probe
detectability better than classifier-based methods, suggesting the preference
learning objective incentivizes maintaining rather than obfuscating relevant
representations. Second, probe diversity provides minimal practical benefit -
simply retraining probes after optimization recovers high detection accuracy.
Our findings suggest probe-based training can be viable for certain alignment
methods, though probe ensembles are largely unnecessary when retraining is
feasible.

</details>


### [156] [FrameShield: Adversarially Robust Video Anomaly Detection](https://arxiv.org/abs/2510.21532)
*Mojtaba Nafez,Mobina Poulaei,Nikan Vasei,Bardia Soltani Moakhar,Mohammad Sabokrou,MohammadHossein Rohban*

Main category: cs.LG

TL;DR: 提出了一种新颖的伪异常生成方法SRD，旨在增强弱监督视频异常检测模型对抗攻击的鲁棒性，显著提高性能。


<details>
  <summary>Details</summary>
Motivation: 针对现有模型在对抗攻击下的脆弱性，以及传统对抗防御机制在弱监督条件下的局限性，提出改进方案。

Method: 使用SRD方法生成合成异常，通过对正常视频中的局部区域应用严重增广来实现，从而降低标签噪音，促进有效的对抗训练。

Result: 经实验验证，该方法在多个基准测试中的AUROC性能平均提升71.0%，显著优于现有最先进的方法。

Conclusion: 该研究通过引入SRD方法，显著提升了弱监督视频异常检测模型对抗攻击的防御能力，在多个基准测试中表现优越。

Abstract: Weakly Supervised Video Anomaly Detection (WSVAD) has achieved notable
advancements, yet existing models remain vulnerable to adversarial attacks,
limiting their reliability. Due to the inherent constraints of weak
supervision, where only video-level labels are provided despite the need for
frame-level predictions, traditional adversarial defense mechanisms, such as
adversarial training, are not effective since video-level adversarial
perturbations are typically weak and inadequate. To address this limitation,
pseudo-labels generated directly from the model can enable frame-level
adversarial training; however, these pseudo-labels are inherently noisy,
significantly degrading performance. We therefore introduce a novel
Pseudo-Anomaly Generation method called Spatiotemporal Region Distortion (SRD),
which creates synthetic anomalies by applying severe augmentations to localized
regions in normal videos while preserving temporal consistency. Integrating
these precisely annotated synthetic anomalies with the noisy pseudo-labels
substantially reduces label noise, enabling effective adversarial training.
Extensive experiments demonstrate that our method significantly enhances the
robustness of WSVAD models against adversarial attacks, outperforming
state-of-the-art methods by an average of 71.0\% in overall AUROC performance
across multiple benchmarks. The implementation and code are publicly available
at https://github.com/rohban-lab/FrameShield.

</details>


### [157] [DEEDEE: Fast and Scalable Out-of-Distribution Dynamics Detection](https://arxiv.org/abs/2510.21638)
*Tala Aljaafari,Varun Kanade,Philip Torr,Christian Schroeder de Witt*

Main category: cs.LG

TL;DR: DEEDEE是一种用于强化学习的OOD检测工具，凭借其简单的统计方法在复杂环境中实现了有效的异常检测。


<details>
  <summary>Details</summary>
Motivation: 研究强化学习在安全关键设置中因分布转移导致的脆弱性，并寻找有效的OOD检测方法。

Method: DEEDEE通过使用每个回合的均值和基于RBF核的相似性进行OOD检测，减少了计算需求。

Result: DEEDEE在标准RL OOD测试中表现优越，实现了600倍的计算资源节约和5%的准确率提升。

Conclusion: DEEDEE展示了低阶统计数据在检测复杂环境中异常的能力，证实了其在计算效率和准确性方面优于现有方法。

Abstract: Deploying reinforcement learning (RL) in safety-critical settings is
constrained by brittleness under distribution shift. We study
out-of-distribution (OOD) detection for RL time series and introduce DEEDEE, a
two-statistic detector that revisits representation-heavy pipelines with a
minimal alternative. DEEDEE uses only an episodewise mean and an RBF kernel
similarity to a training summary, capturing complementary global and local
deviations. Despite its simplicity, DEEDEE matches or surpasses contemporary
detectors across standard RL OOD suites, delivering a 600-fold reduction in
compute (FLOPs / wall-time) and an average 5% absolute accuracy gain over
strong baselines. Conceptually, our results indicate that diverse anomaly types
often imprint on RL trajectories through a small set of low-order statistics,
suggesting a compact foundation for OOD detection in complex environments.

</details>


### [158] [Excision Score: Evaluating Edits with Surgical Precision](https://arxiv.org/abs/2510.21537)
*Nikolai Gruzinov,Ksenia Sycheva,Earl T. Barr,Alex Bezzubov*

Main category: cs.LG

TL;DR: 修订相似性问题新方法ES通过消除共享内容，提供更准确的相似性评估，优于传统指标。


<details>
  <summary>Details</summary>
Motivation: 提出修订相似性问题，以统一评估现有文档修订的多种机器学习任务。

Method: 提出一个新的静态度量Excision Score (ES)，通过计算最长公共子序列（LCS）来移除与现有文档共享的内容，然后仅比较剩余的不同区域，提升相似性评估的精准性。

Result: 新提出的Excision Score (ES) 在代码编辑评估中表现超越现有指标，如SARI和BLEU。

Conclusion: ES在处理共享上下文和其他边角病例方面表现优越，证明其在修订评估中的有效性和可靠性。

Abstract: Many tasks revolve around editing a document, whether code or text. We
formulate the revision similarity problem to unify a wide range of machine
learning evaluation problems whose goal is to assess a revision to an existing
document. We observe that revisions usually change only a small portion of an
existing document, so the existing document and its immediate revisions share a
majority of their content. We formulate five adequacy criteria for revision
similarity measures, designed to align them with human judgement. We show that
popular pairwise measures, like BLEU, fail to meet these criteria, because
their scores are dominated by the shared content. They report high similarity
between two revisions when humans would assess them as quite different. This is
a fundamental flaw we address. We propose a novel static measure, Excision
Score (ES), which computes longest common subsequence (LCS) to remove content
shared by an existing document with the ground truth and predicted revisions,
before comparing only the remaining divergent regions. This is analogous to a
surgeon creating a sterile field to focus on the work area. We use
approximation to speed the standard cubic LCS computation to quadratic. In
code-editing evaluation, where static measures are often used as a cheap proxy
for passing tests, we demonstrate that ES surpasses existing measures. When
aligned with test execution on HumanEvalFix, ES improves over its nearest
competitor, SARI, by 12% Pearson correlation and by >21% over standard measures
like BLEU. The key criterion is invariance to shared context; when we perturb
HumanEvalFix with increased shared context, ES' improvement over SARI increases
to 20% and >30% over standard measures. ES also handles other corner cases that
other measures do not, such as correctly aligning moved code blocks, and
appropriately rewarding matching insertions or deletions.

</details>


### [159] [Cost Minimization for Space-Air-Ground Integrated Multi-Access Edge Computing Systems](https://arxiv.org/abs/2510.21541)
*Weihong Qin,Aimin Wang,Geng Sun,Zemin Sun,Jiacheng Wang,Dusit Niyato,Dong In Kim,Zhu Han*

Main category: cs.LG

TL;DR: SAGIN-MEC为低空经济提供了灵活的计算服务，面临协调异构节点、建模复杂因素和实时决策的挑战。提出了一种层级SAGIN-MEC架构和UD成本最小化优化问题，并开发了MADDPG-COCG算法以提升用户性能。


<details>
  <summary>Details</summary>
Motivation: 旨在满足低空经济中对灵活和广域计算服务的需求，解决SAGIN-MEC在部分可观察环境中的决策挑战。

Method: 提出了一种层级SAGIN-MEC架构和UD成本最小化优化问题，使用MADDPG算法和凸优化与合力博弈方法解决问题。

Result: 通过MADDPG-COCG算法，显著提升了用户性能，且相较基准算法，UAV能耗略有增加。

Conclusion: MADDPG-COCG算法在聚合UD成本、任务完成延迟和UD能耗方面显著提升了用户性能，并展现出优越的收敛稳定性和可扩展性。

Abstract: Space-air-ground integrated multi-access edge computing (SAGIN-MEC) provides
a promising solution for the rapidly developing low-altitude economy (LAE) to
deliver flexible and wide-area computing services. However, fully realizing the
potential of SAGIN-MEC in the LAE presents significant challenges, including
coordinating decisions across heterogeneous nodes with different roles,
modeling complex factors such as mobility and network variability, and handling
real-time decision-making under partially observable environment with hybrid
variables. To address these challenges, we first present a hierarchical
SAGIN-MEC architecture that enables the coordination between user devices
(UDs), uncrewed aerial vehicles (UAVs), and satellites. Then, we formulate a UD
cost minimization optimization problem (UCMOP) to minimize the UD cost by
jointly optimizing the task offloading ratio, UAV trajectory planning,
computing resource allocation, and UD association. We show that the UCMOP is an
NP-hard problem. To overcome this challenge, we propose a multi-agent deep
deterministic policy gradient (MADDPG)-convex optimization and coalitional game
(MADDPG-COCG) algorithm. Specifically, we employ the MADDPG algorithm to
optimize the continuous temporal decisions for heterogeneous nodes in the
partially observable SAGIN-MEC system. Moreover, we propose a convex
optimization and coalitional game (COCG) method to enhance the conventional
MADDPG by deterministically handling the hybrid and varying-dimensional
decisions. Simulation results demonstrate that the proposed MADDPG-COCG
algorithm significantly enhances the user-centric performances in terms of the
aggregated UD cost, task completion delay, and UD energy consumption, with a
slight increase in UAV energy consumption, compared to the benchmark
algorithms. Moreover, the MADDPG-COCG algorithm shows superior convergence
stability and scalability.

</details>


### [160] [Interpretable Multimodal Zero-Shot ECG Diagnosis via Structured Clinical Knowledge Alignment](https://arxiv.org/abs/2510.21551)
*Jialu Tang,Hung Manh Pham,Ignace De Lathauwer,Henk S. Schipper,Yuan Lu,Dong Ma,Aaqib Saeed*

Main category: cs.LG

TL;DR: ZETA是一个零样本多模态框架，旨在提高心电图(ECG)解读的可解释性和广泛适用性，通过将ECG信号与结构化的临床观察进行比较，以支持心血管疾病的诊断。


<details>
  <summary>Details</summary>
Motivation: 旨在解决当前自动化系统在透明性和对未见条件的泛化能力方面的挑战，从而促进心血管疾病的诊断。

Method: ZETA通过与LLM辅助的专家验证的正负临床观察进行比较，利用预训练的多模态模型对ECG和文本嵌入进行对齐，无需疾病特定的微调。

Result: 实证评估表明ZETA在零样本分类性能上具备竞争力，并提供了定性和定量证据，显示其在特定临床相关的正负诊断特征上的可解释性增强。

Conclusion: ZETA展示了通过将ECG分析与结构化临床知识对齐，可以构建更透明、广泛适用且可信赖的AI诊断系统的潜力。

Abstract: Electrocardiogram (ECG) interpretation is essential for cardiovascular
disease diagnosis, but current automated systems often struggle with
transparency and generalization to unseen conditions. To address this, we
introduce ZETA, a zero-shot multimodal framework designed for interpretable ECG
diagnosis aligned with clinical workflows. ZETA uniquely compares ECG signals
against structured positive and negative clinical observations, which are
curated through an LLM-assisted, expert-validated process, thereby mimicking
differential diagnosis. Our approach leverages a pre-trained multimodal model
to align ECG and text embeddings without disease-specific fine-tuning.
Empirical evaluations demonstrate ZETA's competitive zero-shot classification
performance and, importantly, provide qualitative and quantitative evidence of
enhanced interpretability, grounding predictions in specific, clinically
relevant positive and negative diagnostic features. ZETA underscores the
potential of aligning ECG analysis with structured clinical knowledge for
building more transparent, generalizable, and trustworthy AI diagnostic
systems. We will release the curated observation dataset and code to facilitate
future research.

</details>


### [161] [REVE: A Foundation Model for EEG -- Adapting to Any Setup with Large-Scale Pretraining on 25,000 Subjects](https://arxiv.org/abs/2510.21585)
*Yassine El Ouahidi,Jonathan Lys,Philipp Thölke,Nicolas Farrugia,Bastien Pasdeloup,Vincent Gripon,Karim Jerbi,Giulia Lioi*

Main category: cs.LG

TL;DR: REVE是一种针对EEG信号的预训练模型，能够处理不同配置的EEG数据，实现了多项任务的最佳效果，促进了临床神经科学的研究。


<details>
  <summary>Details</summary>
Motivation: 解决现有EEG基础模型在不同协议和设备上的泛化能力不足问题，推动EEG研究的发展与应用。

Method: 通过在92个数据集上对60,000小时EEG数据进行掩蔽自编码预训练，结合新型4D位置编码策略以处理不同信号长度和电极布局。

Result: 本研究提出了REVE（Representation for EEG with Versatile Embeddings）模型，旨在提高脑电图（EEG）数据的可用性和有效性。通过对超过60,000小时EEG数据的预训练，REVE采用了一种新颖的4D位置编码方案，使其能够处理任意长度和电极排列的信号。在多项EEG任务中，该模型展示了了卓越的表现和广泛的通用性，标志着EEG预训练的最大进展。

Conclusion: REVE模型显著提高了EEG信号处理的效果，并且具备良好的泛化能力，适合应用于多种EEG相关任务。

Abstract: Foundation models have transformed AI by reducing reliance on task-specific
data through large-scale pretraining. While successful in language and vision,
their adoption in EEG has lagged due to the heterogeneity of public datasets,
which are collected under varying protocols, devices, and electrode
configurations. Existing EEG foundation models struggle to generalize across
these variations, often restricting pretraining to a single setup, resulting in
suboptimal performance, in particular under linear probing. We present REVE
(Representation for EEG with Versatile Embeddings), a pretrained model
explicitly designed to generalize across diverse EEG signals. REVE introduces a
novel 4D positional encoding scheme that enables it to process signals of
arbitrary length and electrode arrangement. Using a masked autoencoding
objective, we pretrain REVE on over 60,000 hours of EEG data from 92 datasets
spanning 25,000 subjects, representing the largest EEG pretraining effort to
date. REVE achieves state-of-the-art results on 10 downstream EEG tasks,
including motor imagery classification, seizure detection, sleep staging,
cognitive load estimation, and emotion recognition. With little to no
fine-tuning, it demonstrates strong generalization, and nuanced spatio-temporal
modeling. We release code, pretrained weights, and tutorials to support
standardized EEG research and accelerate progress in clinical neuroscience.

</details>


### [162] [Accelerating Data Generation for Nonlinear temporal PDEs via homologous perturbation in solution space](https://arxiv.org/abs/2510.21592)
*Lei Liu,Zhenxin Huang,Hong Wang,huanshuo dong,Haiyang Xin,Hongwei Zhao,Bin Li*

Main category: cs.LG

TL;DR: HOPSS算法提出了一种新颖的数据生成方法，通过减少时间步长加速PDE数据生成，同时保持模型训练精度。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法生成解对所需的时间步长过多，造成计算和时间负担。

Method: HOPSS算法通过同源扰动方法直接生成高精度的PDE数据点，并计算原方程右侧的变化以形成新的解对。

Result: HOPSS算法在Navier-Stokes方程上的实验显示，它在大约传统方法10%的时间内生成10,000个样本，且训练性能相当。

Conclusion: HOPSS算法在减少数据生成时间方面表现优异，同时保持模型训练所需的精确度。

Abstract: Data-driven deep learning methods like neural operators have advanced in
solving nonlinear temporal partial differential equations (PDEs). However,
these methods require large quantities of solution pairs\u2014the solution
functions and right-hand sides (RHS) of the equations. These pairs are
typically generated via traditional numerical methods, which need thousands of
time steps iterations far more than the dozens required for training, creating
heavy computational and temporal overheads. To address these challenges, we
propose a novel data generation algorithm, called HOmologous Perturbation in
Solution Space (HOPSS), which directly generates training datasets with fewer
time steps rather than following the traditional approach of generating large
time steps datasets. This algorithm simultaneously accelerates dataset
generation and preserves the approximate precision required for model training.
Specifically, we first obtain a set of base solution functions from a reliable
solver, usually with thousands of time steps, and then align them in time steps
with training datasets by downsampling. Subsequently, we propose a "homologous
perturbation" approach: by combining two solution functions (one as the primary
function, the other as a homologous perturbation term scaled by a small scalar)
with random noise, we efficiently generate comparable-precision PDE data
points. Finally, using these data points, we compute the variation in the
original equation's RHS to form new solution pairs. Theoretical and
experimental results show HOPSS lowers time complexity. For example, on the
Navier-Stokes equation, it generates 10,000 samples in approximately 10% of
traditional methods' time, with comparable model training performance.

</details>


### [163] [Generalised Flow Maps for Few-Step Generative Modelling on Riemannian Manifolds](https://arxiv.org/abs/2510.21608)
*Oscar Davis,Michael S. Albergo,Nicholas M. Boffi,Michael M. Bronstein,Avishek Joey Bose*

Main category: cs.LG

TL;DR: 本研究提出了广义流图（GFM），一种高效的几何生成模型，能够在各种几何数据集上实现最佳性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有几何生成模型在推断时计算成本高的问题，优化其在任意黎曼流形上的应用。

Method: 提出了一种新的生成模型类别，名为广义流图（GFM），旨在改进现有基于流图的几何生成模型。

Result: GFMs在多种几何数据集上表现出色，达到了单步和少步评估的最先进样本质量，并在隐式概率流中展示了竞争性的对数似然性。

Conclusion: GFMs通过特定的设计决策，将现有的欧几里德少步生成模型提升至黎曼设置，展示了其在许多应用中的潜力和优势。

Abstract: Geometric data and purpose-built generative models on them have become
ubiquitous in high-impact deep learning application domains, ranging from
protein backbone generation and computational chemistry to geospatial data.
Current geometric generative models remain computationally expensive at
inference -- requiring many steps of complex numerical simulation -- as they
are derived from dynamical measure transport frameworks such as diffusion and
flow-matching on Riemannian manifolds. In this paper, we propose Generalised
Flow Maps (GFM), a new class of few-step generative models that generalises the
Flow Map framework in Euclidean spaces to arbitrary Riemannian manifolds. We
instantiate GFMs with three self-distillation-based training methods:
Generalised Lagrangian Flow Maps, Generalised Eulerian Flow Maps, and
Generalised Progressive Flow Maps. We theoretically show that GFMs, under
specific design decisions, unify and elevate existing Euclidean few-step
generative models, such as consistency models, shortcut models, and meanflows,
to the Riemannian setting. We benchmark GFMs against other geometric generative
models on a suite of geometric datasets, including geospatial data, RNA torsion
angles, and hyperbolic manifolds, and achieve state-of-the-art sample quality
for single- and few-step evaluations, and superior or competitive
log-likelihoods using the implicit probability flow.

</details>


### [164] [Optimal Graph Clustering without Edge Density Signals](https://arxiv.org/abs/2510.21669)
*Maximilien Dreveton,Elaine Siyu Liu,Matthias Grossglauser,Patrick Thiran*

Main category: cs.LG

TL;DR: 提出了流行度调整块模型（PABM），解决了现有图聚类模型的局限性，展示了其在聚类恢复方面的优势。


<details>
  <summary>Details</summary>
Motivation: 研究现有图聚类模型的局限性，并在PABM框架下建立更有效的聚类理论限制。

Method: 理论分析与数值实验

Result: 在PABM下，提出了聚类的最佳错误率特征，并展示了在传统边密度信号消失的情况下仍能进行聚类恢复的可能性，前提是聚类内外的流行度系数不同。

Conclusion: PABM提供了比DCBM更丰富的结构，传统的谱嵌入方法可能忽略重要的结构信息，建议使用基于前$k^2$特征向量的谱聚类算法。

Abstract: This paper establishes the theoretical limits of graph clustering under the
Popularity-Adjusted Block Model (PABM), addressing limitations of existing
models. In contrast to the Stochastic Block Model (SBM), which assumes uniform
vertex degrees, and to the Degree-Corrected Block Model (DCBM), which applies
uniform degree corrections across clusters, PABM introduces separate popularity
parameters for intra- and inter-cluster connections. Our main contribution is
the characterization of the optimal error rate for clustering under PABM, which
provides novel insights on clustering hardness: we demonstrate that unlike SBM
and DCBM, cluster recovery remains possible in PABM even when traditional
edge-density signals vanish, provided intra- and inter-cluster popularity
coefficients differ. This highlights a dimension of degree heterogeneity
captured by PABM but overlooked by DCBM: local differences in connectivity
patterns can enhance cluster separability independently of global edge
densities. Finally, because PABM exhibits a richer structure, its expected
adjacency matrix has rank between $k$ and $k^2$, where $k$ is the number of
clusters. As a result, spectral embeddings based on the top $k$ eigenvectors
may fail to capture important structural information. Our numerical experiments
on both synthetic and real datasets confirm that spectral clustering algorithms
incorporating $k^2$ eigenvectors outperform traditional spectral approaches.

</details>


### [165] [Equivariance by Contrast: Identifiable Equivariant Embeddings from Unlabeled Finite Group Actions](https://arxiv.org/abs/2510.21706)
*Tobias Schmidt,Steffen Schneider,Matthias Bethge*

Main category: cs.LG

TL;DR: 本研究提出了Equivariance by Contrast (EbC)方法，成功学习了等变嵌入，强调了在没有群特定诱导偏见的情况下进行学习的效果。


<details>
  <summary>Details</summary>
Motivation: 提出一种新方法以学习从观测对中获得的等变嵌入，这涉及到群作用而不依赖于特定的诱导偏见。

Method: 结合对数据的群作用，使用无偏见的学习方式从观测对中提取潜在空间和群表示。

Result: 成功展示了一种普适的编码器仅基于群动作观测进行的等变学习，包括非平凡的非阿贝尔群和用于建模计算机视觉中仿射等变性的直积群。

Conclusion: 我们的研究首次展示了仅通过群动作观测实现的一般性编码器等变学习，为未来的研究奠定了基础。

Abstract: We propose Equivariance by Contrast (EbC) to learn equivariant embeddings
from observation pairs $(\mathbf{y}, g \cdot \mathbf{y})$, where $g$ is drawn
from a finite group acting on the data. Our method jointly learns a latent
space and a group representation in which group actions correspond to
invertible linear maps -- without relying on group-specific inductive biases.
We validate our approach on the infinite dSprites dataset with structured
transformations defined by the finite group $G:= (R_m \times \mathbb{Z}_n
\times \mathbb{Z}_n)$, combining discrete rotations and periodic translations.
The resulting embeddings exhibit high-fidelity equivariance, with group
operations faithfully reproduced in latent space. On synthetic data, we further
validate the approach on the non-abelian orthogonal group $O(n)$ and the
general linear group $GL(n)$. We also provide a theoretical proof for
identifiability. While broad evaluation across diverse group types on
real-world data remains future work, our results constitute the first
successful demonstration of general-purpose encoder-only equivariant learning
from group action observations alone, including non-trivial non-abelian groups
and a product group motivated by modeling affine equivariances in computer
vision.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [166] [NeuroPilot: A Realtime Brain-Computer Interface system to enhance concentration of students in online learning](https://arxiv.org/abs/2510.20958)
*Asif Islam,Farhan Ishtiaque,Md. Muhyminul Haque,Kaled Masukur Rahman,Ravi Vaidyanathan,Khondaker A. Mamun*

Main category: cs.HC

TL;DR: 本文开发了一种基于脑机接口的系统，用于在线学习中实时监测学生的专注度，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统方法在监测学生专注度上的局限性，开发基于脑机接口的技术以实现更有效的专注度评估。

Method: 使用非侵入性脑电图头带记录脑电活动，通过支持向量机分类分析，进行实时监测与反馈。

Result: 本文探讨了在线学习中实时监测学生专注度的挑战，现有方法如问卷评估和基于摄像头的监测存在不足。为了解决这些问题，研究开发了一种基于非侵入性脑电图（EEG）头带的脑机接口（BCI）系统FocusCalm。该系统记录参与者观看教育视频时的脑电活动，收集了20名参与者的20分钟数据，并通过新颖的问卷评估进行数据验证。使用支持向量机（SVM）对注意与非注意状态进行分类，交叉验证准确率达88.77%。该系统在检测到非注意状态时提供反馈警报，并记录专注档案。试点研究显示在反馈干预下，参与者专注度显著提高。

Conclusion: 研究显示，使用脑机接口技术可以有效提升学生的专注度，实时反馈具有显著的积极影响。

Abstract: Prevalence of online learning poses a vital challenge in real-time monitoring
of students' concentration. Traditional methods such as questionnaire
assessments require manual interventions and webcam-based monitoring fails to
provide accurate insights into learners' mental focus as they are deceived by
mere screen fixation without cognitive engagement. Existing BCI-based
approaches lack real-time validation and evaluation procedures. To address
these limitations, a Brain-Computer Interface (BCI) system is developed using a
non-invasive Electroencephalogram (EEG) headband, FocusCalm, to record
brainwave activity under attentive and non-attentive states. 20 minutes of data
were collected from each of 20 participants watching a pre-recorded educational
video. The data validation employed a novel intra-video questionnaire
assessment. Subsequently, collected signals were segmented (sliding window),
filtered (butterworth bandpass), and cleaned (removal of high-amplitude and EOG
artifacts such as eye blinks). Time, frequency, wavelet and statistical
features have been extracted, followed by recursive feature elimination (RFE)
with Support vector machines (SVMs) to classify attention and non-attention
states. The leave-one-subject-out (LOSO) cross-validation accuracy has been
tested to be 88.77%. The system provides feedback alerts upon non-attention
state detection and keeps focus profile logs. A pilot study was conducted to
evaluate the effectiveness of real-time feedback. Five participants completed a
10-minute session consisting of a 5-minute baseline phase without feedback
followed by a 5-minute feedback phase, during which alerts were issued if
participants remained non-attentive for approximately 8 consecutive seconds. A
paired t-test (t = 5.73, p = 0.007) indicated a statistically significant
improvement in concentration during the feedback phase.

</details>


### [167] [Race and Gender in LLM-Generated Personas: A Large-Scale Audit of 41 Occupations](https://arxiv.org/abs/2510.21011)
*Ilona van der Linden,Sahana Kumar,Arnav Dixit,Aadi Sudan,Smruthi Danda,David C. Anastasiu,Kai Lukoff*

Main category: cs.HC

TL;DR: 对生成式AI工具生成的职业角色进行了大规模审计，发现种族表现存在显著偏差。


<details>
  <summary>Details</summary>
Motivation: 评估生成式AI工具在职业角色中对种族和性别的表现影响，以了解其潜在的偏见和扭曲。

Method: 大型审计分析

Result: 发现系统性偏差和刻板印象的增强，特别是在对不同种族群体的代表性方面。

Conclusion: 研究表明，提供者选择会显著影响哪些群体被可见，建议进行模型特定的审计和负责任的设计实践。

Abstract: Generative AI tools are increasingly used to create portrayals of people in
occupations, raising concerns about how race and gender are represented. We
conducted a large-scale audit of over 1.5 million occupational personas across
41 U.S. occupations, generated by four large language models with different AI
safety commitments and countries of origin (U.S., China, France). Compared with
Bureau of Labor Statistics data, we find two recurring patterns: systematic
shifts, where some groups are consistently under- or overrepresented, and
stereotype exaggeration, where existing demographic skews are amplified. On
average, White (--31pp) and Black (--9pp) workers are underrepresented, while
Hispanic (+17pp) and Asian (+12pp) workers are overrepresented. These
distortions can be extreme: for example, across all four models, Housekeepers
are portrayed as nearly 100\% Hispanic, while Black workers are erased from
many occupations. For HCI, these findings show provider choice materially
changes who is visible, motivating model-specific audits and accountable design
practices.

</details>


### [168] [Designing and Evaluating Hint Generation Systems for Science Education](https://arxiv.org/abs/2510.21087)
*Anubhav Jangra,Smaranda Muresan*

Main category: cs.HC

TL;DR: 研究自动生成提示在促进学生主动学习中的作用，探索两种提示策略对学习者的影响。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型可能导致的学生对答案的依赖，促进概念理解和批判性思维。

Method: 进行了一项定量研究，比较静态提示和动态提示的效果，收集41名参与者的数据。

Result: 发现学习者在提示策略上的偏好不同，同时认识到自动评估指标捕捉这些偏好的局限性。

Conclusion: 自动生成提示可以有效支持学习者，但需根据学习者的进展进行调整。

Abstract: Large language models are influencing the education landscape, with students
relying on them in their learning process. Often implemented using
general-purpose models, these systems are likely to give away the answers,
which could hinder conceptual understanding and critical thinking. We study the
role of automatic hint generation as a pedagogical strategy to promote active
engagement with the learning content, while guiding learners toward the
answers. Focusing on scientific topics at the secondary education level, we
explore the potential of large language models to generate chains of hints that
scaffold learners without revealing answers. We compare two distinct hinting
strategies: static hints, pre-generated for each problem, and dynamic hints,
adapted to learners' progress. Through a quantitative study with 41
participants, we uncover different preferences among learners with respect to
hinting strategies, and identify the limitations of automatic evaluation
metrics to capture them. Our findings highlight key design considerations for
future research on hint generation and intelligent tutoring systems that seek
to develop learner-centered educational technologies.

</details>


### [169] [Co-Designing with Multiple Stakeholders and Datasets: A Community-Centered Process to Understand Youth Deviance in the Italian City of Turin](https://arxiv.org/abs/2510.21467)
*Ravinithesh Annapureddy,Alessandro Fornaroli,Massimo Fattori,Valeria Lacovara,Eleonora Fiori,Sarah Vollmer,Moritz Konradi,Britta Elena Hecking,Gianfranco Todesco,Daniel Gatica-Perez*

Main category: cs.HC

TL;DR: 本研究展示了通过共同设计和合作分析来开发公民工具，应对社会问题的过程和挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨如何通过多方合作和数据分析解决意大利都灵青少年偏差问题。

Method: 采用参与式设计和研究设计方法，通过利益相关者工作坊进行设计验证和评估。

Result: 开发了一款名为Sbocciamo Torino的公民工具，促进了利益相关者之间的信任与合作。

Conclusion: 公民工具通过参与设计有效应对复杂社会问题，但政治支持和数据素养是成功的关键因素。

Abstract: This paper presents the co-design and design evaluation of Sbocciamo Torino
civic tool, which helps understand and act upon the issues of youth deviance in
the Italian city of Turin through multi-stakeholder collaboration and
collaborative data analysis. Rooted in research through design and
participatory design methodologies, the civic tool integrates a data dashboard,
stakeholder committee, and structured co-design sessions to facilitate
collaborative analysis and intervention planning. The civic tool was developed
in partnership with municipal authorities, law enforcement, NGOs, and social
services, and reflects their institutional priorities while centering community
knowledge. We describe the iterative co-design process, including stakeholder
workshops for design, validation, training, and evaluation. The civic tool's
impact on stakeholder trust, collaboration, and decision-making was assessed
through surveys and open-ended questionnaires. Our findings show that
stakeholders valued the inclusive design approach and data-driven collaboration
while revealing barriers in communication, data literacy, and operational
coordination. Furthermore, political and institutional support was identified
as critical to the civic tool's success. This paper contributes to research on
community technologies by demonstrating how civic tools can be collaboratively
developed to navigate wicked social problems through participatory design.

</details>


### [170] [Human and AI Trust: Trust Attitude Measurement Instrument](https://arxiv.org/abs/2510.21535)
*Retno Larasati*

Main category: cs.HC

TL;DR: 本研究开发了一种16项信任量表，用于评估非专家对AI医疗支持系统的信任，并证明其可靠性和有效性。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能技术的发展，信任成为使用和接纳AI的必要条件，因此需要合适的测量工具来评估AI系统的信任。

Method: 研究通过六个阶段进行信任测量工具的开发和验证，包括项目研发、项目评估、调查管理、维度测试、可靠性测试和效度测试。

Result: 该论文开发并验证了一种信任测量工具，专为人-AI交互研究而设计，以非专家的视角评估对AI系统的信任态度。工具采用心理测量学原理，包含16项信任量表，特别针对AI医疗支持系统（如癌症/健康预测）进行了应用。经过六个研究阶段的评估，结果表明该信任测量工具在系统比较非专家对AI医疗支持系统的信任方面是可靠和有效的。

Conclusion: 提出的信任测量工具能够系统地测量和比较非专家对AI医疗支持系统的信任，具有良好的测量效度和信度。

Abstract: With the current progress of Artificial Intelligence (AI) technology and its
increasingly broader applications, trust is seen as a required criterion for AI
usage, acceptance, and deployment. A robust measurement instrument is essential
to correctly evaluate trust from a human-centered perspective. This paper
describes the development and validation process of a trust measure instrument,
which follows psychometric principles, and consists of a 16-items trust scale.
The instrument was built explicitly for research in human-AI interaction to
measure trust attitudes towards AI systems from layperson (non-expert)
perspective. The use-case we used to develop the scale was in the context of AI
medical support systems (specifically cancer/health prediction). The scale
development (Measurement Item Development) and validation (Measurement Item
Evaluation) involved six research stages: item development, item evaluation,
survey administration, test of dimensionality, test of reliability, and test of
validity. The results of the six-stages evaluation show that the proposed trust
measurement instrument is empirically reliable and valid for systematically
measuring and comparing non-experts' trust in AI Medical Support Systems.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [171] [Fuzzy numbers revisited: operations on extensional fuzzy numbers](https://arxiv.org/abs/2510.20861)
*Krzysztof Siminski*

Main category: cs.AI

TL;DR: 本文提出了扩展模糊数，解决了传统模糊数运算中的复杂性和结果模糊性问题，并提供了相应的实现和应用示例。


<details>
  <summary>Details</summary>
Motivation: 解决传统模糊数在操作中遇到的高计算复杂性和结果不符合预期的问题，尤其是在多次运算后增加的模糊性。

Method: 定义扩展模糊数的运算及其关系操作符，并提供了C++实现。

Result: 提出了一种新型扩展模糊数，并通过多个应用示例展示了其操作的有效性。

Conclusion: 通过提出扩展模糊数及其运算，改善了传统模糊数操作的复杂性并解决了模糊结果的问题。

Abstract: Fuzzy numbers are commonly represented with fuzzy sets. Their objective is to
better represent imprecise data. However, operations on fuzzy numbers are not
as straightforward as maths on crisp numbers. Commonly, the Zadeh's extension
rule is applied to elaborate a result. This can produce two problems: (1) high
computational complexity and (2) for some fuzzy sets and some operations the
results is not a fuzzy set with the same features (eg. multiplication of two
triangular fuzzy sets does not produce a triangular fuzzy set). One more
problem is the fuzzy spread -- fuzziness of the result increases with the
number of operations. These facts can severely limit the application field of
fuzzy numbers. In this paper we would like to revisite this problem with a
different kind of fuzzy numbers -- extensional fuzzy numbers. The paper defines
operations on extensional fuzzy numbers and relational operators (=, >, >=, <,
<=) for them. The proposed approach is illustrated with several applicational
examples. The C++ implementation is available from a public GitHub repository.

</details>


### [172] [MedAlign: A Synergistic Framework of Multimodal Preference Optimization and Federated Meta-Cognitive Reasoning](https://arxiv.org/abs/2510.21093)
*Siyong Chen,Jinbo Wen,Jiawen Kang,Tenghui Huang,Xumin Huang,Yuanjia Su,Hudan Pan,Zishao Zhong,Dusit Niyato,Shengli Xie,Dong In Kim*

Main category: cs.AI

TL;DR: MedAlign框架通过视觉上下文对齐和多专家协作，显著提升医用视觉问答模型的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 面对大模型在临床服务应用中的三大挑战：虚幻回答、固定深度推理低效、和多机构合作困难，提出解决方案。

Method: 开发MedAlign框架，结合多模态直接偏好优化(mDPO)目标，和检索感知专家混合架构(RA-MoE)，以确保医用视觉问答中的视觉精确性。

Result: MedAlign在三个Med-VQA数据集上的实验结果表明，其性能优于强大的检索增强基线，在F1分数上提升了多达11.85%，并且有效减少平均推理长度51.60%。

Conclusion: MedAlign实现了在医疗视觉问答中较高的性能，同时在推理效率方面也有显著改善，为未来的多机构合作提供了可能性。

Abstract: Recently, large models have shown significant potential for smart healthcare.
However, the deployment of Large Vision-Language Models (LVLMs) for clinical
services is currently hindered by three critical challenges: a tendency to
hallucinate answers not grounded in visual evidence, the inefficiency of
fixed-depth reasoning, and the difficulty of multi-institutional collaboration.
To address these challenges, in this paper, we develop MedAlign, a novel
framework to ensure visually accurate LVLM responses for Medical Visual
Question Answering (Med-VQA). Specifically, we first propose a multimodal
Direct Preference Optimization (mDPO) objective to explicitly align preference
learning with visual context. We then design a Retrieval-Aware
Mixture-of-Experts (RA-MoE) architecture that utilizes image and text
similarity to route queries to a specialized and context-augmented LVLM (i.e.,
an expert), thereby mitigating hallucinations in LVLMs. To achieve adaptive
reasoning and facilitate multi-institutional collaboration, we propose a
federated governance mechanism, where the selected expert, fine-tuned on
clinical datasets based on mDPO, locally performs iterative Chain-of-Thought
(CoT) reasoning via the local meta-cognitive uncertainty estimator. Extensive
experiments on three representative Med-VQA datasets demonstrate that MedAlign
achieves state-of-the-art performance, outperforming strong retrieval-augmented
baselines by up to $11.85\%$ in F1-score, and simultaneously reducing the
average reasoning length by $51.60\%$ compared with fixed-depth CoT approaches.

</details>


### [173] [Understanding AI Trustworthiness: A Scoping Review of AIES & FAccT Articles](https://arxiv.org/abs/2510.21293)
*Siddharth Mehrotra,Jin Huang,Xuelong Fu,Roel Dobbe,Clara I. Sánchez,Maarten de Rijke*

Main category: cs.AI

TL;DR: 研究表明当前可信AI的研究过于集中于技术属性，缺乏对社会技术维度的关注，建议采用更综合的跨学科方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在填补当前可信AI研究中技术与社会维度之间的空白，以促进更全面的理解和应用。

Method: 通过系统分析AIES和FAccT的会议论文，审视AI可信度的定义、应用及其测量、验证等多个方面。

Result: 这项研究审视了AIES和FAccT会议中对可信人工智能的定义、测量和验证，发现研究存在技术与社会之间的脱节，亟需更全面的理解和方法。

Conclusion: 为了推动可信人工智能的发展，需要将技术严谨性与社会、文化和制度考虑相结合，提出切实可行的措施以构建全面框架。

Abstract: Background: Trustworthy AI serves as a foundational pillar for two major AI
ethics conferences: AIES and FAccT. However, current research often adopts
techno-centric approaches, focusing primarily on technical attributes such as
reliability, robustness, and fairness, while overlooking the sociotechnical
dimensions critical to understanding AI trustworthiness in real-world contexts.
  Objectives: This scoping review aims to examine how the AIES and FAccT
communities conceptualize, measure, and validate AI trustworthiness,
identifying major gaps and opportunities for advancing a holistic understanding
of trustworthy AI systems.
  Methods: We conduct a scoping review of AIES and FAccT conference proceedings
to date, systematically analyzing how trustworthiness is defined,
operationalized, and applied across different research domains. Our analysis
focuses on conceptualization approaches, measurement methods, verification and
validation techniques, application areas, and underlying values.
  Results: While significant progress has been made in defining technical
attributes such as transparency, accountability, and robustness, our findings
reveal critical gaps. Current research often predominantly emphasizes technical
precision at the expense of social and ethical considerations. The
sociotechnical nature of AI systems remains less explored and trustworthiness
emerges as a contested concept shaped by those with the power to define it.
  Conclusions: An interdisciplinary approach combining technical rigor with
social, cultural, and institutional considerations is essential for advancing
trustworthy AI. We propose actionable measures for the AI ethics community to
adopt holistic frameworks that genuinely address the complex interplay between
AI systems and society, ultimately promoting responsible technological
development that benefits all stakeholders.

</details>


### [174] [NeuroGenPoisoning: Neuron-Guided Attacks on Retrieval-Augmented Generation of LLM via Genetic Optimization of External Knowledge](https://arxiv.org/abs/2510.21144)
*Hanyu Zhu,Lance Fiondella,Jiawei Yuan,Kai Zeng,Long Jiao*

Main category: cs.AI

TL;DR: 该研究提出了NeuroGenPoisoning框架，有效生成对抗性外部知识，增强RAG模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 提高RAG模型对外部知识的抵抗能力，防止敌手注入有毒知识以覆盖模型的内部记忆。

Method: 提出了一种新的攻击框架NeuroGenPoisoning，利用LLM内部神经元归因和遗传优化生成对抗性的外部知识。

Result: 在不同模型和数据集上实现了超过90%的高人口覆盖成功率，同时保持流畅性，并有效解决了知识冲突问题。

Conclusion: NeuroGenPoisoning能够有效利用毒性响应神经元，提高模型对知识冲突的处理能力，并在实验中取得显著成功。

Abstract: Retrieval-Augmented Generation (RAG) empowers Large Language Models (LLMs) to
dynamically integrate external knowledge during inference, improving their
factual accuracy and adaptability. However, adversaries can inject poisoned
external knowledge to override the model's internal memory. While existing
attacks iteratively manipulate retrieval content or prompt structure of RAG,
they largely ignore the model's internal representation dynamics and
neuron-level sensitivities. The underlying mechanism of RAG poisoning has not
been fully studied and the effect of knowledge conflict with strong parametric
knowledge in RAG is not considered. In this work, we propose NeuroGenPoisoning,
a novel attack framework that generates adversarial external knowledge in RAG
guided by LLM internal neuron attribution and genetic optimization. Our method
first identifies a set of Poison-Responsive Neurons whose activation strongly
correlates with contextual poisoning knowledge. We then employ a genetic
algorithm to evolve adversarial passages that maximally activate these neurons.
Crucially, our framework enables massive-scale generation of effective poisoned
RAG knowledge by identifying and reusing promising but initially unsuccessful
external knowledge variants via observed attribution signals. At the same time,
Poison-Responsive Neurons guided poisoning can effectively resolves knowledge
conflict. Experimental results across models and datasets demonstrate
consistently achieving high Population Overwrite Success Rate (POSR) of over
90% while preserving fluency. Empirical evidence shows that our method
effectively resolves knowledge conflict.

</details>


### [175] [How to Auto-optimize Prompts for Domain Tasks? Adaptive Prompting and Reasoning through Evolutionary Domain Knowledge Adaptation](https://arxiv.org/abs/2510.21148)
*Yang Zhao,Pu Wang,Hao Frank Yang*

Main category: cs.AI

TL;DR: 本研究提出 EGO-Prompt 框架，通过优化提示和推理流程，提高了小模型的效率和可解释性，并在多个领域任务中取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 为大语言模型设计最佳提示和推理过程，以提升在特定领域任务中的应用效果。

Method: 通过进化图优化框架，融合领域知识并改进推理效率，提出了一种新的因果引导文本梯度处理方法。

Result: 在公共卫生、交通和人类行为任务中，EGO-Prompt 的 F1 得分比最先进的方法高出 7.32%-12.61%，同时小模型在成本低于 20% 的情况下达到大模型的性能。

Conclusion: EGO-Prompt 在多个领域任务中表现出色，优化了推理过程并提高了模型的可解释性。

Abstract: Designing optimal prompts and reasoning processes for large language models
(LLMs) on domain-specific tasks is both necessary and challenging in real-world
applications. Determining how to integrate domain knowledge, enhance reasoning
efficiency, and even provide domain experts with refined knowledge integration
hints are particularly crucial yet unresolved tasks. In this research, we
propose Evolutionary Graph Optimization for Prompting (EGO-Prompt), an
automated framework to designing better prompts, efficient reasoning processes
and providing enhanced causal-informed process. EGO-Prompt begins with a
general prompt and fault-tolerant initial Semantic Causal Graph (SCG)
descriptions, constructed by human experts, which is then automatically refined
and optimized to guide LLM reasoning. Recognizing that expert-defined SCGs may
be partial or imperfect and that their optimal integration varies across LLMs,
EGO-Prompt integrates a novel causal-guided textual gradient process in two
steps: first, generating nearly deterministic reasoning guidance from the SCG
for each instance, and second, adapting the LLM to effectively utilize the
guidance alongside the original input. The iterative optimization algorithm
further refines both the SCG and the reasoning mechanism using textual
gradients with ground-truth. We tested the framework on real-world public
health, transportation and human behavior tasks. EGO-Prompt achieves
7.32%-12.61% higher F1 than cutting-edge methods, and allows small models to
reach the performence of larger models at under 20% of the original cost. It
also outputs a refined, domain-specific SCG that improves interpretability.

</details>


### [176] [String Seed of Thought: Prompting LLMs for Distribution-Faithful and Diverse Generation](https://arxiv.org/abs/2510.21150)
*Kou Misaki,Takuya Akiba*

Main category: cs.AI

TL;DR: 提出SSoT方法以提高LLM的概率性指令跟随性能，增强回答的多样性。


<details>
  <summary>Details</summary>
Motivation: 改善大语言模型（LLM）在概率性指令跟随（PIF）任务中的表现。

Method: 提出了一种新的提示方法String Seed of Thought (SSoT)

Result: SSoT显著提高了LLM的PIF表现，接近伪随机数生成器的理想性能，同时增进了响应的多样性。

Conclusion: 实验结果表明，SSoT能够改善LLM在封闭集和开放任务中的响应多样性。

Abstract: We introduce String Seed of Thought (SSoT), a novel prompting method for LLMs
that improves Probabilistic Instruction Following (PIF). We define PIF as a
task requiring an LLM to select its answer from a predefined set of options,
each associated with a specific probability, such that the empirical
distribution of the generated answers aligns with the target distribution when
prompted multiple times. While LLMs excel at tasks with single, deterministic
answers, they often fail at PIF, exhibiting biases problematic for applications
requiring non-deterministic behaviors, such as human-behavior simulation,
content diversification, and multiplayer games. It also harms the diversity of
generated responses, a crucial factor in test-time scaling, by causing the
outputs to collapse into a limited set of answers. To address this, we propose
SSoT, a simple prompting method that instructs an LLM to first output a random
string to generate sufficient entropy. SSoT also instructs the LLM to extract
randomness by manipulating this string to derive a final answer, thereby
preserving diversity while adhering to specific constraints. We demonstrate
that SSoT significantly improves the PIF performance of LLMs, approaching the
ideal performance of a pseudo-random number generator. Furthermore, our
experiments on NoveltyBench show SSoT's benefits extend beyond closed-set tasks
to open-ended tasks by enhancing response diversity.

</details>


### [177] [Memory-Free Continual Learning with Null Space Adaptation for Zero-Shot Vision-Language Models](https://arxiv.org/abs/2510.21175)
*Yujin Jo,Taesup Kim*

Main category: cs.AI

TL;DR: NuSA-CL是一种轻量级的无记忆持续学习框架，旨在帮助视觉语言模型在不断变化的环境中保持零-shot能力，避免灾难性遗忘，适合资源限制的实际应用。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型在现实应用中的广泛使用，确保其在不断变化的环境中的适应能力和性能是一个重要的研究方向。

Method: 本研究提出了一种低秩适应的方法，通过约束任务特定的权重更新在模型参数的近似零空间内，从而避免对已有知识的干扰。

Result: 本研究提出的NuSA-CL框架能够有效应对视觉语言模型面对的不断变化的环境，从而实现持续学习。该框架通过低秩适应，并将任务特定权重更新限制在当前模型参数的近似零空间内，极大地减少了对已有知识的干扰。同时，NuSA-CL没有引入重放缓冲区或复杂的蒸馏过程，因而降低了计算和内存开销，使其适合资源限制的实际应用场景。实验结果表明，NuSA-CL不仅能够保持零-shot迁移能力，而且在持续学习基准上表现出色，显示出其在实际应用中可行且可扩展。

Conclusion: NuSA-CL提供了一种有效的持续学习解决方案，能够在实际应用中实现视觉语言模型的持续适应和性能保持。

Abstract: Pre-trained vision-language models (VLMs), such as CLIP, have demonstrated
remarkable zero-shot generalization, enabling deployment in a wide range of
real-world tasks without additional task-specific training. However, in real
deployment scenarios with evolving environments or emerging classes, these
models inevitably face distributional shifts and novel tasks. In such contexts,
static zero-shot capabilities are insufficient, and there is a growing need for
continual learning methods that allow models to adapt over time while avoiding
catastrophic forgetting. We introduce NuSA-CL (Null Space Adaptation for
Continual Learning), a lightweight memory-free continual learning framework
designed to address this challenge. NuSA-CL employs low-rank adaptation and
constrains task-specific weight updates to lie within an approximate null space
of the model's current parameters. This strategy minimizes interference with
previously acquired knowledge, effectively preserving the zero-shot
capabilities of the original model. Unlike methods relying on replay buffers or
costly distillation, NuSA-CL imposes minimal computational and memory overhead,
making it practical for deployment in resource-constrained, real-world
continual learning environments. Experiments show that our framework not only
effectively preserves zero-shot transfer capabilities but also achieves highly
competitive performance on continual learning benchmarks. These results
position NuSA-CL as a practical and scalable solution for continually evolving
zero-shot VLMs in real-world applications.

</details>


### [178] [Shylock: Causal Discovery in Multivariate Time Series based on Hybrid Constraints](https://arxiv.org/abs/2510.21181)
*Shuo Li,Keqin Xu,Jie Liu,Dan Ye*

Main category: cs.AI

TL;DR: 论文提出了Shylock，一种新方法，用于在少量样本和常规多变量时间序列中发现因果关系，显示出优越的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖人为经验和大量数据的问题，目标是提高因果关系发现的准确性，尤其是在少量样本和常规MTS中。

Method: 提出了一种新方法Shylock，用于发现多变量时间序列（MTS）中的因果关系。

Result: Shylock在少量样本和常规MTS上 outperform了两个现有的最先进的方法，并且通过生成MTS数据的方法进行性能评估。

Conclusion: Shylock通过减少参数数量和共享内核，结合全局和局部约束，成功提高了因果关系发现的准确性，并为用户提供了Tcausal库以简化使用。

Abstract: Causal relationship discovery has been drawing increasing attention due to
its prevalent application. Existing methods rely on human experience,
statistical methods, or graphical criteria methods which are error-prone, stuck
at the idealized assumption, and rely on a huge amount of data. And there is
also a serious data gap in accessing Multivariate time series(MTS) in many
areas, adding difficulty in finding their causal relationship. Existing methods
are easy to be over-fitting on them. To fill the gap we mentioned above, in
this paper, we propose Shylock, a novel method that can work well in both
few-shot and normal MTS to find the causal relationship. Shylock can reduce the
number of parameters exponentially by using group dilated convolution and a
sharing kernel, but still learn a better representation of variables with time
delay. By combing the global constraint and the local constraint, Shylock
achieves information sharing among networks to help improve the accuracy. To
evaluate the performance of Shylock, we also design a data generation method to
generate MTS with time delay. We evaluate it on commonly used benchmarks and
generated datasets. Extensive experiments show that Shylock outperforms two
existing state-of-art methods on both few-shot and normal MTS. We also
developed Tcausal, a library for easy use and deployed it on the EarthDataMiner
platform

</details>


### [179] [OutboundEval: A Dual-Dimensional Benchmark for Expert-Level Intelligent Outbound Evaluation of Xbench's Professional-Aligned Series](https://arxiv.org/abs/2510.21244)
*Pengyu Xu,Shijia Li,Ao Sun,Feng Zhang,Yahan Li,Bo Wu,Zhanyu Ma,Jiguo Li,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He,Rui Wang,Yang Liu,Xiaobo Hu,Fan Yang,Jia Zheng,Guanghua Yao*

Main category: cs.AI

TL;DR: OutboundEval是一种用于评估大型语言模型在外呼场景中表现的基准，通过特别设计的数据集和动态评估方法克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在数据集多样性、用户模拟和评估指标方面的不足。

Method: 提出OutboundEval基准，评估大型语言模型在专家级智能外呼场景中的表现。

Result: 在30个代表性子场景的12个最先进的LLM上进行实验，揭示在任务完成和互动流畅性之间的不同权衡。

Conclusion: OutboundEval为专业应用中的LLM基准测试建立了一个实用、可扩展的标准。

Abstract: We propose OutboundEval, a comprehensive benchmark for evaluating large
language models (LLMs) in expert-level intelligent outbound calling scenarios.
Unlike existing methods that suffer from three key limitations - insufficient
dataset diversity and category coverage, unrealistic user simulation, and
inaccurate evaluation metrics - OutboundEval addresses these issues through a
structured framework. First, we design a benchmark spanning six major business
domains and 30 representative sub-scenarios, each with scenario-specific
process decomposition, weighted scoring, and domain-adaptive metrics. Second,
we develop a large-model-driven User Simulator that generates diverse,
persona-rich virtual users with realistic behaviors, emotional variability, and
communication styles, providing a controlled yet authentic testing environment.
Third, we introduce a dynamic evaluation method that adapts to task variations,
integrating automated and human-in-the-loop assessment to measure task
execution accuracy, professional knowledge application, adaptability, and user
experience quality. Experiments on 12 state-of-the-art LLMs reveal distinct
trade-offs between expert-level task completion and interaction fluency,
offering practical insights for building reliable, human-like outbound AI
systems. OutboundEval establishes a practical, extensible, and domain-oriented
standard for benchmarking LLMs in professional applications.

</details>


### [180] [Out-of-Distribution Detection for Safety Assurance of AI and Autonomous Systems](https://arxiv.org/abs/2510.21254)
*Victoria J. Hodge,Colin Paterson,Ibrahim Habli*

Main category: cs.AI

TL;DR: 随着机器人和机器学习的发展，AI自主系统的应用能力显著提升，然而其安全性验证面临挑战，本文综述了异构数据检测在自主系统安全中的重要性和应用。


<details>
  <summary>Details</summary>
Motivation: 为确保自主系统的负责任采用，准确检测并处理OoD数据是必要的，因此亟需针对这方面进行深入研究和探索。

Method: 通过综合文献分析，对OoD检测技术进行分类，讨论在机器学习开发生命周期中的应用及其安全保障的相关问题。

Result: 本文综述了在自主系统安全保障背景下的异构数据（OoD）检测技术，特别是在安全关键领域。重点分析了自主系统安全性的重要性以及OoD数据的检测挑战，提出了可在机器学习开发生命周期中使用的一系列技术，并讨论了系统和安全工程师在生命周期整合OoD检测时需要注意的事项。

Conclusion: 自主系统的发展和运作安全性亟需解决OoD检测相关的挑战，并强调未来研究的方向。

Abstract: The operational capabilities and application domains of AI-enabled autonomous
systems have expanded significantly in recent years due to advances in robotics
and machine learning (ML). Demonstrating the safety of autonomous systems
rigorously is critical for their responsible adoption but it is challenging as
it requires robust methodologies that can handle novel and uncertain situations
throughout the system lifecycle, including detecting out-of-distribution (OoD)
data. Thus, OOD detection is receiving increased attention from the research,
development and safety engineering communities. This comprehensive review
analyses OOD detection techniques within the context of safety assurance for
autonomous systems, in particular in safety-critical domains. We begin by
defining the relevant concepts, investigating what causes OOD and exploring the
factors which make the safety assurance of autonomous systems and OOD detection
challenging. Our review identifies a range of techniques which can be used
throughout the ML development lifecycle and we suggest areas within the
lifecycle in which they may be used to support safety assurance arguments. We
discuss a number of caveats that system and safety engineers must be aware of
when integrating OOD detection into system lifecycles. We conclude by outlining
the challenges and future work necessary for the safe development and operation
of autonomous systems across a range of domains and applications.

</details>


### [181] [Investigating Scale Independent UCT Exploration Factor Strategies](https://arxiv.org/abs/2510.21275)
*Robin Schmöcker,Christoph Schnell,Alexander Dockhorn*

Main category: cs.AI

TL;DR: 本文探讨了UCT算法在不同奖励规模下的适应性调整方法，提出的新$	ext{λ}$策略表现优异。


<details>
  <summary>Details</summary>
Motivation: 研究UCT算法在不同奖励规模下的表现，特别是在稀疏和密集奖励的零和游戏中。

Method: 评估多种适应性选择UCT探索常数$	ext{λ}$的策略，对比分析其中包括文献中提到的策略和五种新策略。

Result: 通过实验结果显示，新的$	ext{λ}$策略在多个任务中优于现有策略，且在参数优化方面表现良好。

Conclusion: 建议使用新提出的$	ext{λ}$策略，即选择$	ext{λ}$为$2 	imes 	ext{σ}$，此方法在多种任务中均表现优于现有的$	ext{λ}$策略。

Abstract: The Upper Confidence Bounds For Trees (UCT) algorithm is not agnostic to the
reward scale of the game it is applied to. For zero-sum games with the sparse
rewards of $\{-1,0,1\}$ at the end of the game, this is not a problem, but many
games often feature dense rewards with hand-picked reward scales, causing a
node's Q-value to span different magnitudes across different games. In this
paper, we evaluate various strategies for adaptively choosing the UCT
exploration constant $\lambda$, called $\lambda$-strategies, that are agnostic
to the game's reward scale. These $\lambda$-strategies include those proposed
in the literature as well as five new strategies. Given our experimental
results, we recommend using one of our newly suggested $\lambda$-strategies,
which is to choose $\lambda$ as $2 \cdot \sigma$ where $\sigma$ is the
empirical standard deviation of all state-action pairs' Q-values of the search
tree. This method outperforms existing $\lambda$-strategies across a wide range
of tasks both in terms of a single parameter value and the peak performances
obtained by optimizing all available parameters.

</details>


### [182] [When Models Outthink Their Safety: Mitigating Self-Jailbreak in Large Reasoning Models with Chain-of-Guardrails](https://arxiv.org/abs/2510.21285)
*Yingzhi Mao,Chunkang Zhang,Junxiang Wang,Xinyan Guan,Boxi Cao,Yaojie Lu,Hongyu Lin,Xianpei Han,Le Sun*

Main category: cs.AI

TL;DR: 本研究揭示了大型推理模型在面对安全风险时自我破解现象，并提出一种新训练框架CoG，有效提升模型安全性。


<details>
  <summary>Details</summary>
Motivation: 探讨大型推理模型在复杂任务中面临的自我破解现象，以改善其安全性和推理能力的平衡。

Method: 提出护栏链（CoG）训练框架，重新组合或回溯不安全的推理步骤，确保安全的推理轨迹。

Result: 本研究探讨了大型推理模型（LRMs）在复杂推理任务中的优越性能与其面临的安全风险之间的矛盾，包括有害内容生成和破解攻击。现有的缓解策略主要通过在训练过程中注入启发式安全信号来解决这些问题，但往往抑制了推理能力，难以在安全性与推理能力之间取得平衡。通过分析LRMs的推理轨迹，我们发现了一种称为“自我破解”（Self-Jailbreak）的现象，这意味着模型会忽视自身的风险评估，选择响应不安全的提示。尽管LRMs具备拒绝不安全查询的能力，但这一能力却遭到削弱，导致生成有害输出。基于以上发现，我们提出了“护栏链”（Chain-of-Guardrail，CoG）训练框架，该框架通过重新组合或回溯不安全的推理步骤，引导模型回归到安全的推理轨迹，同时保持有效的推理链。在多个推理和安全基准测试中的广泛实验表明，CoG显著提升了当前LRMs的安全性，同时保持了相近的推理能力，显著优于存在严重安全与推理能力权衡的先前方法。

Conclusion: 通过引入护栏链（CoG）训练框架，可以在不牺牲推理能力的前提下，显著提高大型推理模型的安全性。

Abstract: Large Reasoning Models (LRMs) demonstrate remarkable capabilities on complex
reasoning tasks but remain vulnerable to severe safety risks, including harmful
content generation and jailbreak attacks. Existing mitigation strategies rely
on injecting heuristic safety signals during training, which often suppress
reasoning ability and fail to resolve the safety-reasoning trade-off. To
systematically investigate this issue, we analyze the reasoning trajectories of
diverse LRMs and uncover a phenomenon we term Self-Jailbreak, where models
override their own risk assessments and justify responding to unsafe prompts.
This finding reveals that LRMs inherently possess the ability to reject unsafe
queries, but this ability is compromised, resulting in harmful outputs.
Building on these insights, we propose the Chain-of-Guardrail (CoG), a training
framework that recomposes or backtracks unsafe reasoning steps, steering the
model back onto safe trajectories while preserving valid reasoning chains.
Extensive experiments across multiple reasoning and safety benchmarks
demonstrate that CoG substantially improves the safety of current LRMs while
preserving comparable reasoning ability, significantly outperforming prior
methods that suffer from severe safety-reasoning trade-offs.

</details>


### [183] [Towards Reliable Code-as-Policies: A Neuro-Symbolic Framework for Embodied Task Planning](https://arxiv.org/abs/2510.21302)
*Sanghyun Ahn,Wonje Choi,Junyong Lee,Jinwoo Park,Honguk Woo*

Main category: cs.AI

TL;DR: 提出了一种神经符号的体态任务规划框架，通过符号验证和互动验证增强LLM生成代码的环境基础，显著提高任务成功率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 针对LLM生成代码存在的环境基础有限和任务成功率低的问题，提出改善方案。

Method: 采用神经符号方法，结合符号验证和互动验证，在代码生成过程中增强环境交互。

Result: 实验结果显示，该框架在任务成功率上提升了46.2%，并在相关任务动作的可执行性上达到了86.8%。

Conclusion: 提出的框架在动态、部分可观察场景中显著改善了任务成功率和可执行性，验证了其在复杂环境下的有效性。

Abstract: Recent advances in large language models (LLMs) have enabled the automatic
generation of executable code for task planning and control in embodied agents
such as robots, demonstrating the potential of LLM-based embodied intelligence.
However, these LLM-based code-as-policies approaches often suffer from limited
environmental grounding, particularly in dynamic or partially observable
settings, leading to suboptimal task success rates due to incorrect or
incomplete code generation. In this work, we propose a neuro-symbolic embodied
task planning framework that incorporates explicit symbolic verification and
interactive validation processes during code generation. In the validation
phase, the framework generates exploratory code that actively interacts with
the environment to acquire missing observations while preserving task-relevant
states. This integrated process enhances the grounding of generated code,
resulting in improved task reliability and success rates in complex
environments. We evaluate our framework on RLBench and in real-world settings
across dynamic, partially observable scenarios. Experimental results
demonstrate that our framework improves task success rates by 46.2% over
Code-as-Policies baselines and attains over 86.8% executability of
task-relevant actions, thereby enhancing the reliability of task planning in
dynamic environments.

</details>


### [184] [Magellan: Guided MCTS for Latent Space Exploration and Novelty Generation](https://arxiv.org/abs/2510.21341)
*Lufan Chang*

Main category: cs.AI

TL;DR: Magellan框架利用MCTS和层次引导系统，提升LLMs的创新生成能力。


<details>
  <summary>Details</summary>
Motivation: LLMs在生成创新想法时的局限性，以及现有方法的不足

Method: 使用蒙特卡洛树搜索(MCTS)和层次引导系统，结合语义向量和价值函数优化生成过程。

Result: Magellan框架在生成科学想法上优于多个基线，表现出更高的可信性和创新性

Conclusion: 采用有原则的引导搜索方法，能有效提高LLMs在创造性发现中的性能。

Abstract: Large Language Models (LLMs) often struggle with generating truly innovative
ideas, typically defaulting to high-probability, familiar concepts within their
training data's "gravity wells." While advanced search-based methods like Tree
of Thoughts (ToT) attempt to mitigate this, they are fundamentally limited by
their reliance on unprincipled, inconsistent self-evaluation heuristics to
guide exploration. To address this gap, we introduce \textbf{Magellan}, a novel
framework that reframes creative generation as a principled, guided exploration
of an LLM's latent conceptual space. At its core, Magellan employs Monte Carlo
Tree Search (MCTS) governed by a hierarchical guidance system. For long-range
direction, a "semantic compass" vector, formulated via orthogonal projection,
steers the search towards relevant novelty. For local, step-by-step decisions,
a landscape-aware value function replaces flawed self-evaluation with an
explicit reward structure that balances intrinsic coherence, extrinsic novelty,
and narrative progress. Extensive experiments demonstrate that Magellan
significantly outperforms strong baselines, including ReAct and ToT, in
generating scientific ideas with superior plausibility and innovation. Our work
shows that for creative discovery, a principled, guided search is more
effective than unconstrained agency, paving the way for LLMs to become more
capable partners in innovation.

</details>


### [185] [Advancing Symbolic Integration in Large Language Models: Beyond Conventional Neurosymbolic AI](https://arxiv.org/abs/2510.21425)
*Maneeha Rani,Bhupesh Kumar Mishra,Dhavalkumar Thakker*

Main category: cs.AI

TL;DR: 本文回顾了Neurosymbolic AI方法，提出在LLMs中集成符号技术的新框架与研究方向，以提升系统透明度。


<details>
  <summary>Details</summary>
Motivation: LLMs虽然展现出出色的学习与决策能力，但在响应透明度方面仍然存在不足亟需解决。

Method: 对现有Neurosymbolic AI方法进行回顾并提出符号集成的新分类框架和研究路线图。

Result: 提出了一种新的符号集成分类框架，并识别出当前研究中的benchmark、技术进展和关键空白，为未来研究提供了路线图。

Conclusion: 通过识别文献中的新发展和空白，本文为LLMs的符号集成提供了实用见解，以增强其透明度。

Abstract: LLMs have demonstrated highly effective learning, human-like response
generation,and decision-making capabilities in high-risk sectors. However,
these models remain black boxes because they struggle to ensure transparency in
responses. The literature has explored numerous approaches to address
transparency challenges in LLMs, including Neurosymbolic AI (NeSy AI). NeSy AI
approaches were primarily developed for conventional neural networks and are
not well-suited to the unique features of LLMs. Consequently, there is a
limited systematic understanding of how symbolic AI can be effectively
integrated into LLMs. This paper aims to address this gap by first reviewing
established NeSy AI methods and then proposing a novel taxonomy of symbolic
integration in LLMs, along with a roadmap to merge symbolic techniques with
LLMs. The roadmap introduces a new categorisation framework across four
dimensions by organising existing literature within these categories. These
include symbolic integration across various stages of LLM, coupling mechanisms,
architectural paradigms, as well as algorithmic and application-level
perspectives. The paper thoroughly identifies current benchmarks, cutting-edge
advancements, and critical gaps within the field to propose a roadmap for
future research. By highlighting the latest developments and notable gaps in
the literature, it offers practical insights for implementing frameworks for
symbolic integration into LLMs to enhance transparency.

</details>


### [186] [AutoOpt: A Dataset and a Unified Framework for Automating Optimization Problem Solving](https://arxiv.org/abs/2510.21436)
*Ankur Sinha,Shobhit Arora,Dhaval Pujara*

Main category: cs.AI

TL;DR: 本研究提出了AutoOpt-11k，包含超过11,000个手写和打印的数学优化模型图像的数据集，涵盖单目标、多目标、多级和随机优化问题，涉及多种复杂性类型。并开发了AutoOpt框架，实现自动化优化问题求解。


<details>
  <summary>Details</summary>
Motivation: 创建一个包含丰富类别和复杂性的图像数据集，以支持自动化优化求解的研究。

Method: 自动化框架包含三个模块：图像到文本转换的深度学习模型、基于小规模微调的LLM生成优化建模语言、以及使用双层优化分解方法求解问题。

Result: MER任务的深度学习模型在BLEU分数上超越了现有的模型，而BOBD方法在处理复杂测试问题时表现优于传统算法。

Conclusion: AutoOpt框架通过深度学习和双层优化方法，为不同复杂性的问题提供了高效的自动求解方案，显示出与现有方法的显著性能提升。

Abstract: This study presents AutoOpt-11k, a unique image dataset of over 11,000
handwritten and printed mathematical optimization models corresponding to
single-objective, multi-objective, multi-level, and stochastic optimization
problems exhibiting various types of complexities such as non-linearity,
non-convexity, non-differentiability, discontinuity, and high-dimensionality.
The labels consist of the LaTeX representation for all the images and modeling
language representation for a subset of images. The dataset is created by 25
experts following ethical data creation guidelines and verified in two-phases
to avoid errors. Further, we develop AutoOpt framework, a machine learning
based automated approach for solving optimization problems, where the user just
needs to provide an image of the formulation and AutoOpt solves it efficiently
without any further human intervention. AutoOpt framework consists of three
Modules: (i) M1 (Image_to_Text)- a deep learning model performs the
Mathematical Expression Recognition (MER) task to generate the LaTeX code
corresponding to the optimization formulation in image; (ii) M2 (Text_to_Text)-
a small-scale fine-tuned LLM generates the PYOMO script (optimization modeling
language) from LaTeX code; (iii) M3 (Optimization)- a Bilevel Optimization
based Decomposition (BOBD) method solves the optimization formulation described
in the PYOMO script. We use AutoOpt-11k dataset for training and testing of
deep learning models employed in AutoOpt. The deep learning model for MER task
(M1) outperforms ChatGPT, Gemini and Nougat on BLEU score metric. BOBD method
(M3), which is a hybrid approach, yields better results on complex test
problems compared to common approaches, like interior-point algorithm and
genetic algorithm.

</details>


### [187] [Multi-Task Vehicle Routing Solver via Mixture of Specialized Experts under State-Decomposable MDP](https://arxiv.org/abs/2510.21453)
*Yuxin Pan,Zhiguang Cao,Chengyang Gu,Liu Liu,Peilin Zhao,Yize Chen,Fangzhen Lin*

Main category: cs.AI

TL;DR: 本文提出了MoSES框架，通过状态可分解的MDP和潜在空间扩展，提升多任务车辆路径规划的求解效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 旨在克服现有统一求解器未能充分利用车辆路径规划变体的组合结构，以提高多任务请求的求解效率和质量。

Method: 采用状态可分解马尔科夫决策过程（SDMDP）重新构建多任务车辆路径规划问题，并引入潜在空间的扩展，利用门控机制实现基础政策的协同优化。

Result: 本文提出了一种新的框架MoSES，用于解决多任务车辆路径规划问题，克服了现有的统一求解器未充分利用车辆路径规划变体的组合结构的局限性。该方法通过状态可分解的马尔科夫决策过程（SDMDP）重新构建VRP，使得各个基础VRP变体的最佳基础策略可以被有效利用。同时，本文还引入了一种基于潜在空间的SDMDP扩展，进一步提升了政策复用的能力，并通过适应性门控机制实现了策略的混合功能，最终在大规模实验中显示了其优越性。

Conclusion: MoSES框架在多个VRP变体中展示了其相较于之前方法的优势，表明了基础政策复用的重要性和有效性。

Abstract: Existing neural methods for multi-task vehicle routing problems (VRPs)
typically learn unified solvers to handle multiple constraints simultaneously.
However, they often underutilize the compositional structure of VRP variants,
each derivable from a common set of basis VRP variants. This critical oversight
causes unified solvers to miss out the potential benefits of basis solvers,
each specialized for a basis VRP variant. To overcome this limitation, we
propose a framework that enables unified solvers to perceive the
shared-component nature across VRP variants by proactively reusing basis
solvers, while mitigating the exponential growth of trained neural solvers.
Specifically, we introduce a State-Decomposable MDP (SDMDP) that reformulates
VRPs by expressing the state space as the Cartesian product of basis state
spaces associated with basis VRP variants. More crucially, this formulation
inherently yields the optimal basis policy for each basis VRP variant.
Furthermore, a Latent Space-based SDMDP extension is developed by incorporating
both the optimal basis policies and a learnable mixture function to enable the
policy reuse in the latent space. Under mild assumptions, this extension
provably recovers the optimal unified policy of SDMDP through the mixture
function that computes the state embedding as a mapping from the basis state
embeddings generated by optimal basis policies. For practical implementation,
we introduce the Mixture-of-Specialized-Experts Solver (MoSES), which realizes
basis policies through specialized Low-Rank Adaptation (LoRA) experts, and
implements the mixture function via an adaptive gating mechanism. Extensive
experiments conducted across VRP variants showcase the superiority of MoSES
over prior methods.

</details>


### [188] [EU-Agent-Bench: Measuring Illegal Behavior of LLM Agents Under EU Law](https://arxiv.org/abs/2510.21524)
*Ilija Lichkovski,Alexander Müller,Mariam Ibrahim,Tiwai Mhundwa*

Main category: cs.AI

TL;DR: EU-Agent-Bench是一个评估大型语言模型遵循欧盟法律的基准，旨在通过比较模型的行为与法律规范来确保安全性。


<details>
  <summary>Details</summary>
Motivation: 为了衡量大型语言模型（LLMs）在欧盟法律背景下采取非法行动的潜在倾向，提出了EU-Agent-Bench基准测试。

Method: 建立一个涵盖多个类别（数据保护、偏见/歧视、科学诚信）的标准，可通过用户请求评估合规与否，并对模型的法律合规性进行系统评估。

Result: 通过对模型的功能调用与详细法律文献的对比，评估前沿LLMs的法律合规性，并研究在系统提示中提供相关法律摘录的效果。

Conclusion: 发布公共预览集供研究界使用，鼓励未来的工作扩展到不同法律管辖区以及多轮和多语言交互。

Abstract: Large language models (LLMs) are increasingly deployed as agents in various
contexts by providing tools at their disposal. However, LLM agents can exhibit
unpredictable behaviors, including taking undesirable and/or unsafe actions. In
order to measure the latent propensity of LLM agents for taking illegal actions
under an EU legislative context, we introduce EU-Agent-Bench, a verifiable
human-curated benchmark that evaluates an agent's alignment with EU legal norms
in situations where benign user inputs could lead to unlawful actions. Our
benchmark spans scenarios across several categories, including data protection,
bias/discrimination, and scientific integrity, with each user request allowing
for both compliant and non-compliant execution of the requested actions.
Comparing the model's function calls against a rubric exhaustively supported by
citations of the relevant legislature, we evaluate the legal compliance of
frontier LLMs, and furthermore investigate the compliance effect of providing
the relevant legislative excerpts in the agent's system prompt along with
explicit instructions to comply. We release a public preview set for the
research community, while holding out a private test set to prevent data
contamination in evaluating upcoming models. We encourage future work extending
agentic safety benchmarks to different legal jurisdictions and to multi-turn
and multilingual interactions. We release our code on
\href{https://github.com/ilijalichkovski/eu-agent-bench}{this URL}.

</details>


### [189] [Learning Neural Control Barrier Functions from Expert Demonstrations using Inverse Constraint Learning](https://arxiv.org/abs/2510.21560)
*Yuxuan Yang,Hussein Sibai*

Main category: cs.AI

TL;DR: 本文提出了一种基于专家演示的学习神经控制障碍函数，通过约束函数来分类安全与不安全状态，以提高自主系统的安全性能，并通过四个不同环境的实证评估显示优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 在自主系统的关键领域，安全性至关重要，传统优化方法计算开销大，而通过专家演示生成数据驱动的解决方案更加高效。

Method: 使用专家演示生成的约束函数，分类系统状态为安全和不安全，并通过模拟轨迹锻炼神经控制障碍函数。

Result: 将该方法应用于四个不同环境中，相较于现有方法显示出更好的性能，并与使用真实安全标签训练的神经控制障碍函数的性能相当。

Conclusion: 该方法有效提高了自主系统在关键领域的安全性，并能够处理非显式失效状态的分类问题。

Abstract: Safety is a fundamental requirement for autonomous systems operating in
critical domains. Control barrier functions (CBFs) have been used to design
safety filters that minimally alter nominal controls for such systems to
maintain their safety. Learning neural CBFs has been proposed as a data-driven
alternative for their computationally expensive optimization-based synthesis.
However, it is often the case that the failure set of states that should be
avoided is non-obvious or hard to specify formally, e.g., tailgating in
autonomous driving, while a set of expert demonstrations that achieve the task
and avoid the failure set is easier to generate. We use ICL to train a
constraint function that classifies the states of the system under
consideration to safe, i.e., belong to a controlled forward invariant set that
is disjoint from the unspecified failure set, and unsafe ones, i.e., belong to
the complement of that set. We then use that function to label a new set of
simulated trajectories to train our neural CBF. We empirically evaluate our
approach in four different environments, demonstrating that it outperforms
existing baselines and achieves comparable performance to a neural CBF trained
with the same data but annotated with ground-truth safety labels.

</details>


### [190] [CMOMgen: Complex Multi-Ontology Alignment via Pattern-Guided In-Context Learning](https://arxiv.org/abs/2510.21656)
*Marta Contreiras Silva,Daniel Faria,Catia Pesquita*

Main category: cs.AI

TL;DR: 提出了一种新的复杂多本体匹配策略CMOMgen，能够生成完整且语义正确的映射，且不受目标本体或实体数量的限制。


<details>
  <summary>Details</summary>
Motivation: 构建全面的知识图谱需要多本体，以便在特定领域中全面上下文化数据，传统的配对匹配无法实现充分的语义整合。

Method: 通过检索增强生成的方法选择相关类构建映射，并过滤匹配参考映射作为例子，提升上下文学习效果。

Result: CMOMgen在类选择上表现突出，并且在两个任务中实现了63%以上的F1-score，手动评估显示46%的映射达到了最高分。

Conclusion: CMOMgen在三个生物医学任务中的评估显示其在类选择上优于基线实现，且在构建语义正确的映射方面表现出色。

Abstract: Constructing comprehensive knowledge graphs requires the use of multiple
ontologies in order to fully contextualize data into a domain. Ontology
matching finds equivalences between concepts interconnecting ontologies and
creating a cohesive semantic layer. While the simple pairwise state of the art
is well established, simple equivalence mappings cannot provide full semantic
integration of related but disjoint ontologies. Complex multi-ontology matching
(CMOM) aligns one source entity to composite logical expressions of multiple
target entities, establishing more nuanced equivalences and provenance along
the ontological hierarchy.
  We present CMOMgen, the first end-to-end CMOM strategy that generates
complete and semantically sound mappings, without establishing any restrictions
on the number of target ontologies or entities. Retrieval-Augmented Generation
selects relevant classes to compose the mapping and filters matching reference
mappings to serve as examples, enhancing In-Context Learning. The strategy was
evaluated in three biomedical tasks with partial reference alignments. CMOMgen
outperforms baselines in class selection, demonstrating the impact of having a
dedicated strategy. Our strategy also achieves a minimum of 63% in F1-score,
outperforming all baselines and ablated versions in two out of three tasks and
placing second in the third. Furthermore, a manual evaluation of non-reference
mappings showed that 46% of the mappings achieve the maximum score, further
substantiating its ability to construct semantically sound mappings.

</details>


### [191] [A Multimodal Benchmark for Framing of Oil & Gas Advertising and Potential Greenwashing Detection](https://arxiv.org/abs/2510.21679)
*Gaku Morio,Harri Rowlands,Dominik Stammbach,Christopher D. Manning,Peter Henderson*

Main category: cs.AI

TL;DR: 本研究推出了一个包含专家标注的视频广告数据集，旨在评估公共关系活动的框架，与现有文本数据集不同，主要用于视觉-语言模型的研究。


<details>
  <summary>Details</summary>
Motivation: 理解公共关系活动中的信息框架和变化，以揭示公司传达的信息与实际行动之间的差距。

Method: 构建了一个专家标注的视频广告数据集，进行了基线实验以评估模型性能。

Result: 本研究介绍了一个基准数据集，该数据集包含了来自Facebook和YouTube的专家标注视频广告，旨在帮助理解公共关系活动中信息的框架和变化。数据集涵盖了20个国家的50多家公司的13种框架类型，并专门设计用于评估视觉-语言模型(VLMs)。实验结果显示，尽管现有模型在识别环境信息方面取得了一定的成绩，但在绿色创新的框架识别上仍有待提高。此外，研究还指出了VLMs面临的多种挑战，如隐性框架、多样长度视频的处理及文化背景的隐性影响。这一数据集为能源领域的战略传播多模态分析研究做出了贡献。

Conclusion: 该数据集为研究公共关系活动提供了重要数据，指出了VLMs在处理隐性框架和视频处理中的挑战，并为今后在能源领域的多模态分析研究奠定基础。

Abstract: Companies spend large amounts of money on public relations campaigns to
project a positive brand image. However, sometimes there is a mismatch between
what they say and what they do. Oil & gas companies, for example, are accused
of "greenwashing" with imagery of climate-friendly initiatives. Understanding
the framing, and changes in framing, at scale can help better understand the
goals and nature of public relations campaigns. To address this, we introduce a
benchmark dataset of expert-annotated video ads obtained from Facebook and
YouTube. The dataset provides annotations for 13 framing types for more than 50
companies or advocacy groups across 20 countries. Our dataset is especially
designed for the evaluation of vision-language models (VLMs), distinguishing it
from past text-only framing datasets. Baseline experiments show some promising
results, while leaving room for improvement for future work: GPT-4.1 can detect
environmental messages with 79% F1 score, while our best model only achieves
46% F1 score on identifying framing around green innovation. We also identify
challenges that VLMs must address, such as implicit framing, handling videos of
various lengths, or implicit cultural backgrounds. Our dataset contributes to
research in multimodal analysis of strategic communication in the energy
sector.

</details>


### [192] [A Knowledge-Graph Translation Layer for Mission-Aware Multi-Agent Path Planning in Spatiotemporal Dynamics](https://arxiv.org/abs/2510.21695)
*Edward Holmberg,Elias Ioup,Mahdi Abdelguerfi*

Main category: cs.AI

TL;DR: 本研究提出了一个基于知识图谱的框架，解决了自主智能体在动态环境中的协调问题，展示了KG作为协调者的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了解决自主智能体在动态环境中任务协调时的语义差距问题，提高其路径协调的灵活性和效率。

Method: 使用知识图谱的双层架构，将高层目标转化为智能体的具体世界观和行动规则，进行案例分析验证。

Result: 本研究提出了一个以知识图谱（KG）为核心框架，旨在解决动态环境中自主智能体协调时高层任务目标与低层规划输入之间的语义差距。该框架方法具有双层结构，可以将声明性事实转化为每个智能体的任务感知“世界观”及物理感知的遍历规则，从而将任务语义与领域无关的规划器解耦。通过改变KG中的事实，可以简单地修改复杂的协调路径。研究案例涉及墨西哥湾的自主水下航行器（AUV），通过视觉化展示了整个过程，并量化证明了不同的声明性策略能够产生不同的高效结果。研究表明，KG不仅是数据存储库，更是创建自适应和可解释的自主系统的强大、有状态的协调器。

Conclusion: 知识图谱不仅作为数据存储，更是创建适应性与可解释性自主系统的重要工具。

Abstract: The coordination of autonomous agents in dynamic environments is hampered by
the semantic gap between high-level mission objectives and low-level planner
inputs. To address this, we introduce a framework centered on a Knowledge Graph
(KG) that functions as an intelligent translation layer. The KG's two-plane
architecture compiles declarative facts into per-agent, mission-aware
``worldviews" and physics-aware traversal rules, decoupling mission semantics
from a domain-agnostic planner. This allows complex, coordinated paths to be
modified simply by changing facts in the KG. A case study involving Autonomous
Underwater Vehicles (AUVs) in the Gulf of Mexico visually demonstrates the
end-to-end process and quantitatively proves that different declarative
policies produce distinct, high-performing outcomes. This work establishes the
KG not merely as a data repository, but as a powerful, stateful orchestrator
for creating adaptive and explainable autonomous systems.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [193] [HIKMA: Human-Inspired Knowledge by Machine Agents through a Multi-Agent Framework for Semi-Autonomous Scientific Conferences](https://arxiv.org/abs/2510.21370)
*Zain Ul Abideen Tariq,Mahmood Al-Zubaidi,Uzair Shah,Marco Agus,Mowafa Househ*

Main category: cs.MA

TL;DR: HIKMA会议通过AI技术重新构想学术交流，展示了AI在学术出版、审稿及展示中的应用，强调其对传统实践的支持性角色。


<details>
  <summary>Details</summary>
Motivation: 探讨AI技术在学术交流中的应用潜力，并确保学术实践的诚信与透明。

Method: 设计并实施了一个集成AI的学术交流框架，包括稿件生成、同行评审及会议展示等环节。

Result: HIKMA半自主会议是重新构想学术交流的首次实验，通过人工智能的端到端集成来改进学术出版和展示流程。本文介绍了HIKMA框架的设计、实施和评估，包括AI数据集策划、基于AI的稿件生成、AI辅助同行评审、AI驱动的修订、AI会议展示和AI归档传播。HIKMA通过结合语言模型、结构化研究工作流程和领域保护措施，展示了AI如何支持而非取代传统学术实践，同时维护知识产权保护、透明度和完整性。该会议作为一个试验平台和概念验证，提供了关于AI推动的学术机会与挑战的见解，同时探讨了关于AI作者身份、责任和人机合作在研究中的作用的问题。

Conclusion: HIKMA为AI赋能的学术研究提供了评估框架，揭示了其在保持学术诚信和知识产权方面的潜力与挑战。

Abstract: HIKMA Semi-Autonomous Conference is the first experiment in reimagining
scholarly communication through an end-to-end integration of artificial
intelligence into the academic publishing and presentation pipeline. This paper
presents the design, implementation, and evaluation of the HIKMA framework,
which includes AI dataset curation, AI-based manuscript generation, AI-assisted
peer review, AI-driven revision, AI conference presentation, and AI archival
dissemination. By combining language models, structured research workflows, and
domain safeguards, HIKMA shows how AI can support - not replace traditional
scholarly practices while maintaining intellectual property protection,
transparency, and integrity. The conference functions as a testbed and proof of
concept, providing insights into the opportunities and challenges of AI-enabled
scholarship. It also examines questions about AI authorship, accountability,
and the role of human-AI collaboration in research.

</details>

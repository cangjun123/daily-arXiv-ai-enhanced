<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 49]
- [cs.CL](#cs.CL) [Total: 38]
- [cs.HC](#cs.HC) [Total: 9]
- [cs.AI](#cs.AI) [Total: 5]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.LG](#cs.LG) [Total: 55]
- [cs.MM](#cs.MM) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [GSE: Evaluating Sticker Visual Semantic Similarity via a General Sticker Encoder](https://arxiv.org/abs/2511.04977)
*Heng Er Metilda Chee,Jiayin Wang,Zhiqiang Guo,Weizhi Ma,Min Zhang*

Main category: cs.CV

TL;DR: 研究提出Triple-S基准和GSE模型，以促进对贴纸语义理解的研究，展示了贴纸的语义相似性和下游应用潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管贴纸作为一种视觉交流形式越来越流行，但由于其多样化和象征性的内容，理解其语义关系依然具有挑战性。

Method: 本研究定义了贴纸语义相似性任务，并推出了包括905个人工标注的正负贴纸对的Triple-S基准。提出的通用贴纸编码器(GSE)使用Triple-S及其他数据集学习强大的贴纸嵌入表示。

Result: GSE在未见贴纸上表现优越，同时在情感分类和贴纸间检索等下游任务中也展现了强大的结果。

Conclusion: 通过引入Triple-S和GSE模型，研究为贴纸理解和检索提供了标准化的评估工具和强大的嵌入表示，促进了后续研究的发展。

Abstract: Stickers have become a popular form of visual communication, yet
understanding their semantic relationships remains challenging due to their
highly diverse and symbolic content. In this work, we formally {define the
Sticker Semantic Similarity task} and introduce {Triple-S}, the first benchmark
for this task, consisting of 905 human-annotated positive and negative sticker
pairs. Through extensive evaluation, we show that existing pretrained vision
and multimodal models struggle to capture nuanced sticker semantics. To address
this, we propose the {General Sticker Encoder (GSE)}, a lightweight and
versatile model that learns robust sticker embeddings using both Triple-S and
additional datasets. GSE achieves superior performance on unseen stickers, and
demonstrates strong results on downstream tasks such as emotion classification
and sticker-to-sticker retrieval. By releasing both Triple-S and GSE, we
provide standardized evaluation tools and robust embeddings, enabling future
research in sticker understanding, retrieval, and multimodal content
generation. The Triple-S benchmark and GSE have been publicly released and are
available here.

</details>


### [2] [Splatography: Sparse multi-view dynamic Gaussian Splatting for filmmaking challenges](https://arxiv.org/abs/2511.05152)
*Adrian Azzarelli,Nantheera Anantrasirichai,David R Bull*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的动态3D重建方法，能在稀疏相机配置下实现优异性能，显著提高了重建质量和效率。


<details>
  <summary>Details</summary>
Motivation: 在电影制作中，由于预算限制，稀疏的相机配置可能导致捕捉复杂动态特征的能力下降，因此需要一个更有效的动态3D重建方法。

Method: 该方法使用稀疏的帧掩码分别对前景和背景组件进行训练，采用不同的损失函数，并在动态训练中为每个变形字段建模不同的参数。

Result: 实验表明，该方法在3D和2.5D娱乐数据集上实现了超越现有技术的定性和定量结果，在3D场景中达到更高的PSNR，并且模型大小减半。

Conclusion: 本研究提出了一种新的方法，通过将经典高斯表示与变形字段拆分为前景和背景组件，解决了稀疏相机配置下动态3D重建的困难。

Abstract: Deformable Gaussian Splatting (GS) accomplishes photorealistic dynamic 3-D
reconstruction from dense multi-view video (MVV) by learning to deform a
canonical GS representation. However, in filmmaking, tight budgets can result
in sparse camera configurations, which limits state-of-the-art (SotA) methods
when capturing complex dynamic features. To address this issue, we introduce an
approach that splits the canonical Gaussians and deformation field into
foreground and background components using a sparse set of masks for frames at
t=0. Each representation is separately trained on different loss functions
during canonical pre-training. Then, during dynamic training, different
parameters are modeled for each deformation field following common filmmaking
practices. The foreground stage contains diverse dynamic features so changes in
color, position and rotation are learned. While, the background containing
film-crew and equipment, is typically dimmer and less dynamic so only changes
in point position are learned. Experiments on 3-D and 2.5-D entertainment
datasets show that our method produces SotA qualitative and quantitative
results; up to 3 PSNR higher with half the model size on 3-D scenes. Unlike the
SotA and without the need for dense mask supervision, our method also produces
segmented dynamic reconstructions including transparent and dynamic textures.
Code and video comparisons are available online:
https://interims-git.github.io/

</details>


### [3] [IndicVisionBench: Benchmarking Cultural and Multilingual Understanding in VLMs](https://arxiv.org/abs/2511.04727)
*Ali Faraz,Akash,Shaharukh Khan,Raja Kolla,Akshat Patidar,Suranjan Goswami,Abhinav Ravi,Chandra Khatri,Shubham Agarwal*

Main category: cs.CV

TL;DR: 介绍IndicVisionBench，为评估VLM在印度及多语言环境下的表现提供基准，发现当前模型存在文化和语言偏置的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的评估基准主要集中在西方，忽视了文化多样性和多语言背景下的表现差异。

Method: 通过构建涵盖英语言和10种印度语言的基准，涉及OCR、MMT和VQA等多模态任务，进行模型评估。

Result: 对8种模型的评估表明，在多元文化背景下，现有VLMs表现存在显著差距。

Conclusion: IndicVisionBench建立了一个可复制的评估框架，强调了文化多样性和多语言性对多模态研究的重要性。

Abstract: Vision-language models (VLMs) have demonstrated impressive generalization
across multimodal tasks, yet most evaluation benchmarks remain Western-centric,
leaving open questions about their performance in culturally diverse and
multilingual settings. To address this gap, we introduce IndicVisionBench, the
first large-scale benchmark centered on the Indian subcontinent. Covering
English and 10 Indian languages, our benchmark spans 3 multimodal tasks,
including Optical Character Recognition (OCR), Multimodal Machine Translation
(MMT), and Visual Question Answering (VQA), covering 6 kinds of question types.
Our final benchmark consists of a total of ~5K images and 37K+ QA pairs across
13 culturally grounded topics. In addition, we release a paired parallel corpus
of annotations across 10 Indic languages, creating a unique resource for
analyzing cultural and linguistic biases in VLMs. We evaluate a broad spectrum
of 8 models, from proprietary closed-source systems to open-weights medium and
large-scale models. Our experiments reveal substantial performance gaps,
underscoring the limitations of current VLMs in culturally diverse contexts. By
centering cultural diversity and multilinguality, IndicVisionBench establishes
a reproducible evaluation framework that paves the way for more inclusive
multimodal research.

</details>


### [4] [CPO: Condition Preference Optimization for Controllable Image Generation](https://arxiv.org/abs/2511.04753)
*Zonglin Lyu,Ming Li,Xinxin Liu,Chen Chen*

Main category: cs.CV

TL;DR: 提出条件偏好优化 (CPO) 方法，通过控制信号的偏好训练模型，显著提高了文本到图像生成中的可控性。


<details>
  <summary>Details</summary>
Motivation: 为了解决DPO方法在生成图像不一致性中的挑战，提出了一种新的优化方法，以确保控件的可控性。

Method: 通过构建胜负控制信号并训练模型偏好胜信号，实施条件偏好优化 (CPO)。

Result: CPO在多个控制类型上实现了超过10%的错误率减少，在人体姿态上减少了70-80%，并在边缘和深度图上实现了一致的2-5%减少。

Conclusion: CPO显著提高了控制能力，相较于ControlNet++在多个控制类型上展现出优越的性能。

Abstract: To enhance controllability in text-to-image generation, ControlNet introduces
image-based control signals, while ControlNet++ improves pixel-level cycle
consistency between generated images and the input control signal. To avoid the
prohibitive cost of back-propagating through the sampling process, ControlNet++
optimizes only low-noise timesteps (e.g., $t < 200$) using a single-step
approximation, which not only ignores the contribution of high-noise timesteps
but also introduces additional approximation errors. A straightforward
alternative for optimizing controllability across all timesteps is Direct
Preference Optimization (DPO), a fine-tuning method that increases model
preference for more controllable images ($I^{w}$) over less controllable ones
($I^{l}$). However, due to uncertainty in generative models, it is difficult to
ensure that win--lose image pairs differ only in controllability while keeping
other factors, such as image quality, fixed. To address this, we propose
performing preference learning over control conditions rather than generated
images. Specifically, we construct winning and losing control signals,
$\mathbf{c}^{w}$ and $\mathbf{c}^{l}$, and train the model to prefer
$\mathbf{c}^{w}$. This method, which we term \textit{Condition Preference
Optimization} (CPO), eliminates confounding factors and yields a low-variance
training objective. Our approach theoretically exhibits lower contrastive loss
variance than DPO and empirically achieves superior results. Moreover, CPO
requires less computation and storage for dataset curation. Extensive
experiments show that CPO significantly improves controllability over the
state-of-the-art ControlNet++ across multiple control types: over $10\%$ error
rate reduction in segmentation, $70$--$80\%$ in human pose, and consistent
$2$--$5\%$ reductions in edge and depth maps.

</details>


### [5] [Global 3D Reconstruction of Clouds & Tropical Cyclones](https://arxiv.org/abs/2511.04773)
*Shirin Ermis,Cesar Aybar,Lilli Freischem,Stella Girtsou,Kyriaki-Margarita Bintsi,Emiliano Diaz Salas-Porras,Michael Eisinger,William Jones,Anna Jungbluth,Benoit Tremblay*

Main category: cs.CV

TL;DR: 本文介绍了一种新框架，通过多卫星数据生成三维云图，成功重建强烈热带气旋的云结构，从而推动对热带气旋增强的理解和预测能力的提升。


<details>
  <summary>Details</summary>
Motivation: 由于热带气旋结构的卫星观测有限，以及云特性解析的难度，使得准确预测热带气旋的挑战依然存在。

Method: 提出了一种基于预训练-微调的框架，从多个覆盖全球的卫星学习，将二维卫星图像转换为三维云图，涵盖重要的云特性。

Result: 通过应用模型于定制的热带气旋数据集，我们首次能够生成全球瞬时的三维云图并准确重建强风暴的三维结构。

Conclusion: 该模型不仅扩展了现有的卫星观测能力，还能在观测缺失时提供估算，这对于深入理解热带气旋的增强机制和改进预测至关重要。

Abstract: Accurate forecasting of tropical cyclones (TCs) remains challenging due to
limited satellite observations probing TC structure and difficulties in
resolving cloud properties involved in TC intensification. Recent research has
demonstrated the capabilities of machine learning methods for 3D cloud
reconstruction from satellite observations. However, existing approaches have
been restricted to regions where TCs are uncommon, and are poorly validated for
intense storms. We introduce a new framework, based on a
pre-training--fine-tuning pipeline, that learns from multiple satellites with
global coverage to translate 2D satellite imagery into 3D cloud maps of
relevant cloud properties. We apply our model to a custom-built TC dataset to
evaluate performance in the most challenging and relevant conditions. We show
that we can - for the first time - create global instantaneous 3D cloud maps
and accurately reconstruct the 3D structure of intense storms. Our model not
only extends available satellite observations but also provides estimates when
observations are missing entirely. This is crucial for advancing our
understanding of TC intensification and improving forecasts.

</details>


### [6] [3D Gaussian Point Encoders](https://arxiv.org/abs/2511.04797)
*Jim James,Ben Wilson,Simon Lucey,James Hays*

Main category: cs.CV

TL;DR: 本文介绍了3D高斯点编码器，显示出在3D识别任务中优于传统模型的性能，优化技术使其计算更高效。


<details>
  <summary>Details</summary>
Motivation: 采用显式几何表示来解决3D识别任务，以克服现有隐式表示的局限性。

Method: 通过自然梯度优化和PointNets的蒸馏技术，构建3D高斯编码器，进一步结合计算几何启发式加速。

Result: 构建的3D高斯点编码器比传统PointNet速度快2.7倍，内存使用减少46%，FLOPs减少88%。在Mamba3D中的应用表现出更高的效率。

Conclusion: 3D Gaussian Point Encoders在性能和参数效率上优于传统的PointNet，能够在CPU设备上实现高帧率。

Abstract: In this work, we introduce the 3D Gaussian Point Encoder, an explicit
per-point embedding built on mixtures of learned 3D Gaussians. This explicit
geometric representation for 3D recognition tasks is a departure from widely
used implicit representations such as PointNet. However, it is difficult to
learn 3D Gaussian encoders in end-to-end fashion with standard optimizers. We
develop optimization techniques based on natural gradients and distillation
from PointNets to find a Gaussian Basis that can reconstruct PointNet
activations. The resulting 3D Gaussian Point Encoders are faster and more
parameter efficient than traditional PointNets. As in the 3D reconstruction
literature where there has been considerable interest in the move from implicit
(e.g., NeRF) to explicit (e.g., Gaussian Splatting) representations, we can
take advantage of computational geometry heuristics to accelerate 3D Gaussian
Point Encoders further. We extend filtering techniques from 3D Gaussian
Splatting to construct encoders that run 2.7 times faster as a comparable
accuracy PointNet while using 46% less memory and 88% fewer FLOPs. Furthermore,
we demonstrate the effectiveness of 3D Gaussian Point Encoders as a component
in Mamba3D, running 1.27 times faster and achieving a reduction in memory and
FLOPs by 42% and 54% respectively. 3D Gaussian Point Encoders are lightweight
enough to achieve high framerates on CPU-only devices.

</details>


### [7] [Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose](https://arxiv.org/abs/2511.04803)
*Shuo Zhao,Jianxu Chen*

Main category: cs.CV

TL;DR: 本研究分析了Cellpose模型在生物医学图像分割中的数据冗余和跨领域迁移影响，提出了紧凑的数据集选择策略和保留学习策略。


<details>
  <summary>Details</summary>
Motivation: 尽管通用生物医学图像分割模型如Cellpose被广泛应用，但训练数据冗余和跨领域迁移的影响尚未得到充分探讨。

Method: 通过对Cellpose模型进行系统的实证分析，探索训练数据冗余和跨领域迁移对模型保留的影响。

Result: 实验表明，数据冗余很高，只有10%的数据即可达到饱和的分割性能，且选择性回放可以有效恢复源领域性能，而合理的训练域序列能够提高泛化能力并减少遗忘。

Conclusion: 本研究强调了数据集中设计在生物医学图像分割中的重要性，建议有效的训练不仅需要紧凑的子集，还需要关注保留的学习策略和合理的领域排序。

Abstract: Generalist biomedical image segmentation models such as Cellpose are
increasingly applied across diverse imaging modalities and cell types. However,
two critical challenges remain underexplored: (1) the extent of training data
redundancy and (2) the impact of cross domain transfer on model retention. In
this study, we conduct a systematic empirical analysis of these challenges
using Cellpose as a case study. First, to assess data redundancy, we propose a
simple dataset quantization (DQ) strategy for constructing compact yet diverse
training subsets. Experiments on the Cyto dataset show that image segmentation
performance saturates with only 10% of the data, revealing substantial
redundancy and potential for training with minimal annotations. Latent space
analysis using MAE embeddings and t-SNE confirms that DQ selected patches
capture greater feature diversity than random sampling. Second, to examine
catastrophic forgetting, we perform cross domain finetuning experiments and
observe significant degradation in source domain performance, particularly when
adapting from generalist to specialist domains. We demonstrate that selective
DQ based replay reintroducing just 5-10% of the source data effectively
restores source performance, while full replay can hinder target adaptation.
Additionally, we find that training domain sequencing improves generalization
and reduces forgetting in multi stage transfer. Our findings highlight the
importance of data centric design in biomedical image segmentation and suggest
that efficient training requires not only compact subsets but also retention
aware learning strategies and informed domain ordering. The code is available
at https://github.com/MMV-Lab/biomedseg-efficiency.

</details>


### [8] [Geometry Denoising with Preferred Normal Vectors](https://arxiv.org/abs/2511.04848)
*Manuel Weiß,Lukas Baumgärtner,Roland Herzog,Stephan Schmidt*

Main category: cs.CV

TL;DR: 本文提出了一种利用法向量先验知识的几何去噪新方法，通过分割与正则化技术，采用分裂Bregman方法进行优化。


<details>
  <summary>Details</summary>
Motivation: 利用表面法向量的先验知识，提高几何去噪的效果。

Method: 采用分裂Bregman（ADMM）方法解决优化问题，更新步骤基于二阶形状微积分。

Result: 通过优先法向量进行分割，同时引入全变差项实现正则化，实现了更加精细的去噪效果。

Conclusion: 提出了一种新的几何去噪范式，通过对表面法向量的先验知识进行利用，实现高效的去噪处理。

Abstract: We introduce a new paradigm for geometry denoising using prior knowledge
about the surface normal vector. This prior knowledge comes in the form of a
set of preferred normal vectors, which we refer to as label vectors. A
segmentation problem is naturally embedded in the denoising process. The
segmentation is based on the similarity of the normal vector to the elements of
the set of label vectors. Regularization is achieved by a total variation term.
We formulate a split Bregman (ADMM) approach to solve the resulting
optimization problem. The vertex update step is based on second-order shape
calculus.

</details>


### [9] [Self-Supervised Implicit Attention Priors for Point Cloud Reconstruction](https://arxiv.org/abs/2511.04864)
*Kyle Fogarty,Chenyue Cai,Jing Yang,Zhilin Guo,Cengiz Öztireli*

Main category: cs.CV

TL;DR: 提出了一种隐式自先验方法，通过学习嵌入和隐式距离场，能够有效恢复高质量表面，优于传统和学习方法，保持细节与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 从输入点云直接提取形状特定的先验信息，以恢复高质量的表面，并解决常规方法面临的稀疏区域问题。

Method: 通过同时训练可学习嵌入的小字典和隐式距离场，采用隐式自先验方法，利用交叉注意力捕捉重复结构和长程关联。

Result: 展示了该混合策略能够在保留输入数据的微小几何细节的同时，利用学习到的先验来规范稀疏区域。

Conclusion: 该方法在生成高保真表面和保留细节方面优于经典和基于学习的方法，并且对常见数据失真具有更强的鲁棒性。

Abstract: Recovering high-quality surfaces from irregular point cloud is ill-posed
unless strong geometric priors are available. We introduce an implicit
self-prior approach that distills a shape-specific prior directly from the
input point cloud itself and embeds it within an implicit neural
representation. This is achieved by jointly training a small dictionary of
learnable embeddings with an implicit distance field; at every query location,
the field attends to the dictionary via cross-attention, enabling the network
to capture and reuse repeating structures and long-range correlations inherent
to the shape. Optimized solely with self-supervised point cloud reconstruction
losses, our approach requires no external training data. To effectively
integrate this learned prior while preserving input fidelity, the trained field
is then sampled to extract densely distributed points and analytic normals via
automatic differentiation. We integrate the resulting dense point cloud and
corresponding normals into a robust implicit moving least squares (RIMLS)
formulation. We show this hybrid strategy preserves fine geometric details in
the input data, while leveraging the learned prior to regularize sparse
regions. Experiments show that our method outperforms both classical and
learning-based approaches in generating high-fidelity surfaces with superior
detail preservation and robustness to common data degradations.

</details>


### [10] [Clinical-ComBAT: a diffusion-weighted MRI harmonization method for clinical applications](https://arxiv.org/abs/2511.04871)
*Gabriel Girard,Manon Edde,Félix Dumais,Yoan David,Matthieu Dumont,Guillaume Theaud,Jean-Christophe Houde,Arnaud Boré,Maxime Descoteaux,Pierre-Marc Jodoin*

Main category: cs.CV

TL;DR: 本文提出Clinical-ComBAT方法，以提高DW-MRI数据在临床中的协调性和适用性。


<details>
  <summary>Details</summary>
Motivation: DW-MRI衍生的标量图在评估神经退行性疾病和白质微结构属性方面有效，但传统方法在临床中使用受到限制。

Method: 提出了一种针对临床实际场景的新方法Clinical-ComBAT，独立协调每个数据获取站点，并采用非线性多项式数据模型和小数据集可调的方差先验。

Result: Clinical-ComBAT在模拟和真实数据上表现出更好的扩散指标对齐效果，提升了规范建模的适用性。

Conclusion: Clinical-ComBAT方法有效克服了传统DW-MRI数据合成中的限制，增强了其在临床应用中的适用性。

Abstract: Diffusion-weighted magnetic resonance imaging (DW-MRI) derived scalar maps
are effective for assessing neurodegenerative diseases and microstructural
properties of white matter in large number of brain conditions. However, DW-MRI
inherently limits the combination of data from multiple acquisition sites
without harmonization to mitigate scanner-specific biases. While the widely
used ComBAT method reduces site effects in research, its reliance on linear
covariate relationships, homogeneous populations, fixed site numbers, and well
populated sites constrains its clinical use. To overcome these limitations, we
propose Clinical-ComBAT, a method designed for real-world clinical scenarios.
Clinical-ComBAT harmonizes each site independently, enabling flexibility as new
data and clinics are introduced. It incorporates a non-linear polynomial data
model, site-specific harmonization referenced to a normative site, and variance
priors adaptable to small cohorts. It further includes hyperparameter tuning
and a goodness-of-fit metric for harmonization assessment. We demonstrate its
effectiveness on simulated and real data, showing improved alignment of
diffusion metrics and enhanced applicability for normative modeling.

</details>


### [11] [AI Assisted AR Assembly: Object Recognition and Computer Vision for Augmented Reality Assisted Assembly](https://arxiv.org/abs/2511.05394)
*Alexander Htet Kyaw,Haotian Ma,Sasa Zivkovic,Jenny Sabin*

Main category: cs.CV

TL;DR: 提出了一种基于AI的增强现实装配工作流程，通过深度学习对象识别简化组装步骤，提高了组装效率。


<details>
  <summary>Details</summary>
Motivation: 旨在简化物品组装过程，减少人工搜索和分类时间，提高组装精度和效率。

Method: 使用深度学习技术进行对象识别和增强现实工作流程的设计和实施。

Result: 展示了利用对象识别技术进行增强现实辅助组装的可行性，案例为LEGO雕塑的组装。

Conclusion: 该系统通过深度学习对象识别技术优化了增强现实装配流程，显著提高了组装效率。

Abstract: We present an AI-assisted Augmented Reality assembly workflow that uses deep
learning-based object recognition to identify different assembly components and
display step-by-step instructions. For each assembly step, the system displays
a bounding box around the corresponding components in the physical space, and
where the component should be placed. By connecting assembly instructions with
the real-time location of relevant components, the system eliminates the need
for manual searching, sorting, or labeling of different components before each
assembly. To demonstrate the feasibility of using object recognition for
AR-assisted assembly, we highlight a case study involving the assembly of LEGO
sculptures.

</details>


### [12] [A benchmark multimodal oro-dental dataset for large vision-language models](https://arxiv.org/abs/2511.04948)
*Haoxin Lv,Ijazul Haq,Jin Du,Jiaxin Ma,Binnian Zhu,Xiaobing Dang,Chaoan Liang,Ruxu Du,Yingjie Zhang,Muhammad Saqib*

Main category: cs.CV

TL;DR: 本研究构建了一个包含8775次牙科检查的大规模多模态数据集，验证了其在AI驱动的口腔健康护理中的应用有效性，并提供了公共资源供未来研究使用。


<details>
  <summary>Details</summary>
Motivation: 口腔健康护理中人工智能的进步依赖于大规模的多模态数据集，而现有的数据集无法充分捕捉临床实践的复杂性，因此创建这样一个数据集是必要的。

Method: 通过细化最先进的视觉-语言模型，并在两个任务上进行评估：口腔异常的分类和从多模态输入生成完整诊断报告。

Result: 细化后的模型在任务上取得了显著改进，超过了基准模型和GPT-4o，验证了数据集的有效性。

Conclusion: 该研究通过构建和使用一个大规模的多模态数据集，验证了其在口腔健康护理中应用人工智能的有效性，同时提供了一个可公开获取的资源，推动了该领域的进一步研究。

Abstract: The advancement of artificial intelligence in oral healthcare relies on the
availability of large-scale multimodal datasets that capture the complexity of
clinical practice. In this paper, we present a comprehensive multimodal
dataset, comprising 8775 dental checkups from 4800 patients collected over
eight years (2018-2025), with patients ranging from 10 to 90 years of age. The
dataset includes 50000 intraoral images, 8056 radiographs, and detailed textual
records, including diagnoses, treatment plans, and follow-up notes. The data
were collected under standard ethical guidelines and annotated for
benchmarking. To demonstrate its utility, we fine-tuned state-of-the-art large
vision-language models, Qwen-VL 3B and 7B, and evaluated them on two tasks:
classification of six oro-dental anomalies and generation of complete
diagnostic reports from multimodal inputs. We compared the fine-tuned models
with their base counterparts and GPT-4o. The fine-tuned models achieved
substantial gains over these baselines, validating the dataset and underscoring
its effectiveness in advancing AI-driven oro-dental healthcare solutions. The
dataset is publicly available, providing an essential resource for future
research in AI dentistry.

</details>


### [13] [DeepForgeSeal: Latent Space-Driven Semi-Fragile Watermarking for Deepfake Detection Using Multi-Agent Adversarial Reinforcement Learning](https://arxiv.org/abs/2511.04949)
*Tharindu Fernando,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

TL;DR: 本文提出了一种创新的水印嵌入方法，利用MAARL框架显著提高深度伪造检测的鲁棒性和灵敏度，超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度伪造检测方法面临的挑战，包括对新深度伪造类型的泛化能力不足。

Method: 采用高维潜在空间表示和多智能体对抗强化学习（MAARL）框架进行水印检测。

Result: 在CelebA和CelebA-HQ基准测试上，该方法表现优异，相较于最先进方法分别提升了4.5%和5.3%的性能。

Conclusion: 该论文提出了一种基于深度学习的新型水印嵌入框架，在对抗性策略下有效平衡了鲁棒性和敏感性，显著优于现有技术。

Abstract: Rapid advances in generative AI have led to increasingly realistic deepfakes,
posing growing challenges for law enforcement and public trust. Existing
passive deepfake detectors struggle to keep pace, largely due to their
dependence on specific forgery artifacts, which limits their ability to
generalize to new deepfake types. Proactive deepfake detection using watermarks
has emerged to address the challenge of identifying high-quality synthetic
media. However, these methods often struggle to balance robustness against
benign distortions with sensitivity to malicious tampering. This paper
introduces a novel deep learning framework that harnesses high-dimensional
latent space representations and the Multi-Agent Adversarial Reinforcement
Learning (MAARL) paradigm to develop a robust and adaptive watermarking
approach. Specifically, we develop a learnable watermark embedder that operates
in the latent space, capturing high-level image semantics, while offering
precise control over message encoding and extraction. The MAARL paradigm
empowers the learnable watermarking agent to pursue an optimal balance between
robustness and fragility by interacting with a dynamic curriculum of benign and
malicious image manipulations simulated by an adversarial attacker agent.
Comprehensive evaluations on the CelebA and CelebA-HQ benchmarks reveal that
our method consistently outperforms state-of-the-art approaches, achieving
improvements of over 4.5% on CelebA and more than 5.3% on CelebA-HQ under
challenging manipulation scenarios.

</details>


### [14] [CLM: Removing the GPU Memory Barrier for 3D Gaussian Splatting](https://arxiv.org/abs/2511.04951)
*Hexu Zhao,Xiwen Min,Xiaoteng Liu,Moonjun Gong,Yiming Li,Ang Li,Saining Xie,Jinyang Li,Aurojit Panda*

Main category: cs.CV

TL;DR: 本文提出CLM系统，旨在提升3D Gaussian Splatting在大场景中的渲染能力，优化内存管理与资源利用，以达到高质量输出。


<details>
  <summary>Details</summary>
Motivation: 提升3D Gaussian Splatting方法在大场景渲染中的可扩展性，克服现有方法在内存需求上的局限性。

Method: 通过将高斯点转移到CPU内存，仅在必要时加载到GPU内存，同时利用新颖的卸载策略优化内存访问模式，实现GPU与CPU之间的计算和通信重叠。

Result: 实现能够在单个RTX4090上渲染需要1亿个高斯的庞大场景，并获得业界领先的重建质量。

Conclusion: CLM系统能够在单个消费级GPU上高效地渲染大场景，达到顶尖的重建质量。

Abstract: 3D Gaussian Splatting (3DGS) is an increasingly popular novel view synthesis
approach due to its fast rendering time, and high-quality output. However,
scaling 3DGS to large (or intricate) scenes is challenging due to its large
memory requirement, which exceed most GPU's memory capacity. In this paper, we
describe CLM, a system that allows 3DGS to render large scenes using a single
consumer-grade GPU, e.g., RTX4090. It does so by offloading Gaussians to CPU
memory, and loading them into GPU memory only when necessary. To reduce
performance and communication overheads, CLM uses a novel offloading strategy
that exploits observations about 3DGS's memory access pattern for pipelining,
and thus overlap GPU-to-CPU communication, GPU computation and CPU computation.
Furthermore, we also exploit observation about the access pattern to reduce
communication volume. Our evaluation shows that the resulting implementation
can render a large scene that requires 100 million Gaussians on a single
RTX4090 and achieve state-of-the-art reconstruction quality.

</details>


### [15] [Towards Mitigating Hallucinations in Large Vision-Language Models by Refining Textual Embeddings](https://arxiv.org/abs/2511.05017)
*Aakriti Agrawal,Gouthaman KV,Rohith Aralikatti,Gauri Jagatap,Jiaxin Yuan,Vijay Kamarshi,Andrea Fanelli,Furong Huang*

Main category: cs.CV

TL;DR: 本文识别了LVLM架构的模态偏差，提出利用视觉特征精炼文本嵌入的方法，改善了视觉定位并减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 识别现有LVLM架构中语言模态的固有偏差，并探讨其导致的幻觉问题。

Method: 提出了一种简单有效的方法，使用平均池化的视觉特征来精炼文本嵌入。

Result: 在已有基准测试上，显著改善了视觉定位，减少了幻觉现象。

Conclusion: 本研究通过整合视觉信息来改善文本嵌入，从而减轻了模态不平衡及其对幻觉的影响。

Abstract: In this work, we identify an inherent bias in prevailing LVLM architectures
toward the language modality, largely resulting from the common practice of
simply appending visual embeddings to the input text sequence. To address this,
we propose a simple yet effective method that refines textual embeddings by
integrating average-pooled visual features. Our approach demonstrably improves
visual grounding and significantly reduces hallucinations on established
benchmarks. While average pooling offers a straightforward, robust, and
efficient means of incorporating visual information, we believe that more
sophisticated fusion methods could further enhance visual grounding and
cross-modal alignment. Given that the primary focus of this work is to
highlight the modality imbalance and its impact on hallucinations -- and to
show that refining textual embeddings with visual information mitigates this
issue -- we leave exploration of advanced fusion strategies for future work.

</details>


### [16] [Dynamic Residual Encoding with Slide-Level Contrastive Learning for End-to-End Whole Slide Image Representation](https://arxiv.org/abs/2511.05034)
*Jing Jin,Xu Liu,Te Gao,Zhihong Shi,Yixiong Liang,Ruiqing Zheng,Hulin Kuang,Min Zeng,Shichao Kan*

Main category: cs.CV

TL;DR: 提出一种动态残差编码和滑动级对比学习的方法，解决WSI表示模型训练中的挑战，验证在癌症相关任务中的效果。


<details>
  <summary>Details</summary>
Motivation: 在传统的方法中，由于GPU的限制，处理包含成千上万的图像切片的WSI时面临计算梯度的挑战。

Method: 提出了一种动态残差编码的方法，结合幻灯片级对比学习，以实现端到端的WSI表示。

Result: 通过使用存储特征的内存库，动态选择图像切片，改进了WSI的表示学习过程。

Conclusion: DRE-SLCL方法证明了在癌症亚型分类、癌症识别和突变预测任务中的有效性。

Abstract: Whole Slide Image (WSI) representation is critical for cancer subtyping,
cancer recognition and mutation prediction.Training an end-to-end WSI
representation model poses significant challenges, as a standard gigapixel
slide can contain tens of thousands of image tiles, making it difficult to
compute gradients of all tiles in a single mini-batch due to current GPU
limitations. To address this challenge, we propose a method of dynamic residual
encoding with slide-level contrastive learning (DRE-SLCL) for end-to-end WSI
representation. Our approach utilizes a memory bank to store the features of
tiles across all WSIs in the dataset. During training, a mini-batch usually
contains multiple WSIs. For each WSI in the batch, a subset of tiles is
randomly sampled and their features are computed using a tile encoder. Then,
additional tile features from the same WSI are selected from the memory bank.
The representation of each individual WSI is generated using a residual
encoding technique that incorporates both the sampled features and those
retrieved from the memory bank. Finally, the slide-level contrastive loss is
computed based on the representations and histopathology reports ofthe WSIs
within the mini-batch. Experiments conducted over cancer subtyping, cancer
recognition, and mutation prediction tasks proved the effectiveness of the
proposed DRE-SLCL method.

</details>


### [17] [Pressure2Motion: Hierarchical Motion Synthesis from Ground Pressure with Text Guidance](https://arxiv.org/abs/2511.05038)
*Zhengxuan Li,Qinhui Yang,Yiyu Zhuang,Chuan Guo,Xinxin Zuo,Xiaoxiao Long,Yao Yao,Xun Cao,Qiu Shen,Hao Zhu*

Main category: cs.CV

TL;DR: Pressure2Motion是一种新颖的动作捕捉算法，通过地面压力序列和文本提示合成动作，能够在各种限制条件下工作，成果显示出高保真和物理合理性。


<details>
  <summary>Details</summary>
Motivation: 旨在解决传统动作捕捉方法的局限性，特别是在隐私保护、低光和低成本的场景下。

Method: 提出了一个双层特征提取器，准确解释压力数据，随后使用分层扩散模型来识别宽范围运动轨迹和微妙的姿势调整。

Result: 实验表明，该方法生成的动作在保真度和物理合理性上表现优异，设立了该领域的新标准。

Conclusion: Pressure2Motion是首个结合压力数据和语言先验进行动作生成的模型，能够生成高保真、物理可行的动作，建立了该任务的新状态标准。

Abstract: We present Pressure2Motion, a novel motion capture algorithm that synthesizes
human motion from a ground pressure sequence and text prompt. It eliminates the
need for specialized lighting setups, cameras, or wearable devices, making it
suitable for privacy-preserving, low-light, and low-cost motion capture
scenarios. Such a task is severely ill-posed due to the indeterminate nature of
the pressure signals to full-body motion. To address this issue, we introduce
Pressure2Motion, a generative model that leverages pressure features as input
and utilizes a text prompt as a high-level guiding constraint. Specifically,
our model utilizes a dual-level feature extractor that accurately interprets
pressure data, followed by a hierarchical diffusion model that discerns
broad-scale movement trajectories and subtle posture adjustments. Both the
physical cues gained from the pressure sequence and the semantic guidance
derived from descriptive texts are leveraged to guide the motion generation
with precision. To the best of our knowledge, Pressure2Motion is a pioneering
work in leveraging both pressure data and linguistic priors for motion
generation, and the established MPL benchmark is the first benchmark for this
task. Experiments show our method generates high-fidelity, physically plausible
motions, establishing a new state-of-the-art for this task. The codes and
benchmarks will be publicly released upon publication.

</details>


### [18] [Medical Referring Image Segmentation via Next-Token Mask Prediction](https://arxiv.org/abs/2511.05044)
*Xinyu Chen,Yiran Wang,Gaoyang Pang,Jiafu Hao,Chentao Yue,Luping Zhou,Yonghui Li*

Main category: cs.CV

TL;DR: NTP-MRISeg是一种新框架，通过将MRIS重构为自回归预测任务，简化了设计，并在多个数据集上取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 为了简化模型设计，解决现有方法中存在的复杂性，包括多模态融合和多阶段解码器。

Method: 将MRIS重新定义为自回归下一个令牌预测任务，采用统一的多模态序列，包含图像、文本和掩膜表示。

Result: NTP-MRISeg通过三个新策略提高模型表现，并在QaTa-COV19和MosMedData+数据集上进行的广泛实验中展现出卓越的性能。

Conclusion: NTP-MRISeg在MRIS任务上达到了新的最先进表现，提供了一种简化且有效的替代传统MRIS流程的方法。

Abstract: Medical Referring Image Segmentation (MRIS) involves segmenting target
regions in medical images based on natural language descriptions. While
achieving promising results, recent approaches usually involve complex design
of multimodal fusion or multi-stage decoders. In this work, we propose
NTP-MRISeg, a novel framework that reformulates MRIS as an autoregressive
next-token prediction task over a unified multimodal sequence of tokenized
image, text, and mask representations. This formulation streamlines model
design by eliminating the need for modality-specific fusion and external
segmentation models, supports a unified architecture for end-to-end training.
It also enables the use of pretrained tokenizers from emerging large-scale
multimodal models, enhancing generalization and adaptability. More importantly,
to address challenges under this formulation-such as exposure bias, long-tail
token distributions, and fine-grained lesion edges-we propose three novel
strategies: (1) a Next-k Token Prediction (NkTP) scheme to reduce cumulative
prediction errors, (2) Token-level Contrastive Learning (TCL) to enhance
boundary sensitivity and mitigate long-tail distribution effects, and (3) a
memory-based Hard Error Token (HET) optimization strategy that emphasizes
difficult tokens during training. Extensive experiments on the QaTa-COV19 and
MosMedData+ datasets demonstrate that NTP-MRISeg achieves new state-of-the-art
performance, offering a streamlined and effective alternative to traditional
MRIS pipelines.

</details>


### [19] [No Pose Estimation? No Problem: Pose-Agnostic and Instance-Aware Test-Time Adaptation for Monocular Depth Estimation](https://arxiv.org/abs/2511.05055)
*Mingyu Sung,Hyeonmin Choe,Il-Min Kim,Sangseok Yun,Jae Mo Kang*

Main category: cs.CV

TL;DR: 提出了一种新框架PITTA，用于在多变环境下进行单目深度估计（MDE），显著提升了性能，尤其在动态场景处理方面。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有MDE方法在多样化和动态环境下应用时的低效和问题，提出了一种新的TTA框架。

Method: 提出了一种新颖的高性能测试时间适应（TTA）框架PITTA，综合了无视角TTA范式和基于实例的图像遮罩两种关键创新策略。

Result: PITTA框架通过实例遮罩策略和边缘提取方法，提升了在驾驶立体和Waymo数据集上的MDE性能，克服了静态背景对动态对象识别的干扰。

Conclusion: PITTA框架在多种环境条件下的单目深度估计（MDE）任务中，显著超越了现有的最先进技术，展现出优异的性能提升。

Abstract: Monocular depth estimation (MDE), inferring pixel-level depths in single RGB
images from a monocular camera, plays a crucial and pivotal role in a variety
of AI applications demanding a three-dimensional (3D) topographical scene. In
the real-world scenarios, MDE models often need to be deployed in environments
with different conditions from those for training. Test-time (domain)
adaptation (TTA) is one of the compelling and practical approaches to address
the issue. Although there have been notable advancements in TTA for MDE,
particularly in a self-supervised manner, existing methods are still
ineffective and problematic when applied to diverse and dynamic environments.
To break through this challenge, we propose a novel and high-performing TTA
framework for MDE, named PITTA. Our approach incorporates two key innovative
strategies: (i) pose-agnostic TTA paradigm for MDE and (ii) instance-aware
image masking. Specifically, PITTA enables highly effective TTA on a pretrained
MDE network in a pose-agnostic manner without resorting to any camera pose
information. Besides, our instance-aware masking strategy extracts
instance-wise masks for dynamic objects (e.g., vehicles, pedestrians, etc.)
from a segmentation mask produced by a pretrained panoptic segmentation
network, by removing static objects including background components. To further
boost performance, we also present a simple yet effective edge extraction
methodology for the input image (i.e., a single monocular image) and depth map.
Extensive experimental evaluations on DrivingStereo and Waymo datasets with
varying environmental conditions demonstrate that our proposed framework,
PITTA, surpasses the existing state-of-the-art techniques with remarkable
performance improvements in MDE during TTA.

</details>


### [20] [Role-SynthCLIP: A Role Play Driven Diverse Synthetic Data Approach](https://arxiv.org/abs/2511.05057)
*Yuanxiang Huangfu,Chaochao Wang,Weilei Wang*

Main category: cs.CV

TL;DR: 该研究提出Role-SynthCLIP框架，通过多视角提示提升合成图像-文本对的多样性与准确性，显著提高CLIP模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有合成数据生成方法侧重于数据量的增加，但往往导致语义多样性不足和描述冗余。

Method: 利用多模态大语言模型（MLLMs）生成不同视角的图像描述，采用角色扮演的方法引导生成过程。

Result: 通过Role-SynthCLIP生成的合成对能显著提高CLIP模型的性能，表现优于现有最佳合成数据基线。

Conclusion: Role-SynthCLIP框架通过多视角角色扮演提示生成语义多样的图像-文本对，从而提高了合成数据的表达力和准确性。

Abstract: The effectiveness of Contrastive Language-Image Pre-training (CLIP) models
critically depends on the semantic diversity and quality of their training
data. However, while existing synthetic data generation methods primarily focus
on increasing data volume, such emphasis often leads to limited semantic
diversity and redundant or shallow captions. To address this limitation, we
propose Role-SynthCLIP, a novel data synthesis framework that leverages
multi-perspective role-playing prompts (e.g., a compositional analyst, an
interpreter of image context) to guide Multimodal Large Language Models (MLLMs)
in generating semantically diverse captions from distinct viewpoints. This
mechanism enhances the semantic diversity and fine-grained image-text alignment
of synthetic pairs, thereby improving caption expressiveness and accuracy while
keeping the total number of image-text pairs unchanged. Experimental results
demonstrate the effectiveness and efficiency of our method. A CLIP-B/16 model
trained on only 1 million Role-SynthCLIP pairs achieves a Recall@1 of 64.1% on
the MS COCO validation set, surpassing the best existing synthetic data
baseline (trained on 5M pairs) by 2.8 percentage points. The code and trained
models are released at https://github.com/huangfu170/Role-SynthCLIP.

</details>


### [21] [A Dual-stage Prompt-driven Privacy-preserving Paradigm for Person Re-Identification](https://arxiv.org/abs/2511.05092)
*Ruolin Li,Min Liu,Yuan Bian,Zhaoyang Li,Yuzhen Li,Xueping Wang,Yaonan Wang*

Main category: cs.CV

TL;DR: 本论文提出了DPPP方法，通过构建GenePerson虚拟数据集并利用PDM，显著提升了行人重识别模型在多样性和域不变性方面的表现。


<details>
  <summary>Details</summary>
Motivation: 随着数据隐私的日益受到关注，研究者们需要寻找能够替代真实敏感图像的虚拟数据用于训练行人重识别模型。

Method: 提出了一个双阶段的提示驱动隐私保护范式DPPP，第一阶段生成多维属性的丰富提示以合成数据，第二阶段利用对比学习和提示驱动的解耦机制学习域不变特征。

Result: 模型在GenePerson数据集和PDM的训练中达到了业内领先的泛化性能，超过了在常用的真实和虚拟Re-ID数据集上的表现。

Conclusion: 通过DPPP方法，所提出的GenePerson数据集和Prompt-driven Disentanglement Mechanism（PDM）能够有效提高行人重识别模型的域不变性泛化性能。

Abstract: With growing concerns over data privacy, researchers have started using
virtual data as an alternative to sensitive real-world images for training
person re-identification (Re-ID) models. However, existing virtual datasets
produced by game engines still face challenges such as complex construction and
poor domain generalization, making them difficult to apply in real scenarios.
To address these challenges, we propose a Dual-stage Prompt-driven
Privacy-preserving Paradigm (DPPP). In the first stage, we generate rich
prompts incorporating multi-dimensional attributes such as pedestrian
appearance, illumination, and viewpoint that drive the diffusion model to
synthesize diverse data end-to-end, building a large-scale virtual dataset
named GenePerson with 130,519 images of 6,641 identities. In the second stage,
we propose a Prompt-driven Disentanglement Mechanism (PDM) to learn
domain-invariant generalization features. With the aid of contrastive learning,
we employ two textual inversion networks to map images into pseudo-words
representing style and content, respectively, thereby constructing
style-disentangled content prompts to guide the model in learning
domain-invariant content features at the image level. Experiments demonstrate
that models trained on GenePerson with PDM achieve state-of-the-art
generalization performance, surpassing those on popular real and virtual Re-ID
datasets.

</details>


### [22] [Real-World Adverse Weather Image Restoration via Dual-Level Reinforcement Learning with High-Quality Cold Start](https://arxiv.org/abs/2511.05095)
*Fuyang Liu,Jiaqi Xu,Xiaowei Hu*

Main category: cs.CV

TL;DR: 提出了一种新型双层强化学习框架，结合HFLS-Weather数据集，实现恶劣天气下的视觉恢复。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉模型在合成数据上训练，难以泛化到复杂的降级情况。

Method: 设计了一个基于HFLS-Weather的双层强化学习框架，进行冷启动训练。

Result: 构建了HFLS-Weather数据集，并在本框架中实现了奖励驱动学习和动态模型选择。

Conclusion: 该框架能够在各种恶劣天气场景下实现最高水平的表现，并且能持续适应现实世界的条件。

Abstract: Adverse weather severely impairs real-world visual perception, while existing
vision models trained on synthetic data with fixed parameters struggle to
generalize to complex degradations. To address this, we first construct
HFLS-Weather, a physics-driven, high-fidelity dataset that simulates diverse
weather phenomena, and then design a dual-level reinforcement learning
framework initialized with HFLS-Weather for cold-start training. Within this
framework, at the local level, weather-specific restoration models are refined
through perturbation-driven image quality optimization, enabling reward-based
learning without paired supervision; at the global level, a meta-controller
dynamically orchestrates model selection and execution order according to scene
degradation. This framework enables continuous adaptation to real-world
conditions and achieves state-of-the-art performance across a wide range of
adverse weather scenarios. Code is available at
https://github.com/xxclfy/AgentRL-Real-Weather

</details>


### [23] [Early Alzheimer's Disease Detection from Retinal OCT Images: A UK Biobank Study](https://arxiv.org/abs/2511.05106)
*Yasemin Turkan,F. Boray Tek,M. Serdar Nazlı,Öykü Eren*

Main category: cs.CV

TL;DR: 本研究首次应用深度学习对OCT原始B扫描图像进行阿尔茨海默病预测，结果虽不符合临床应用，但为未来研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 研究视网膜层厚度的变化与阿尔茨海默病的早期检测之间的关系，并探索直接分类OCT B扫描图像的可能性。

Method: 采用深度学习对原始OCT B扫描图像进行分类，利用从UK Biobank cohort中匹配的年龄、性别和成像实例的主题级交叉验证数据集进行微调和评估多种预训练模型。

Result: ResNet-34在4年队列中取得了0.62的AUC，尽管低于临床应用的阈值，但解释性分析确认了阿尔茨海默病和对照组之间中央黄斑亚区的局部结构差异。

Conclusion: 该研究为基于OCT的阿尔茨海默病预测提供了基线，强调了在临床诊断前几年检测微妙视网膜生物标志物的挑战，并指出需要更大的数据集和多模态方法。

Abstract: Alterations in retinal layer thickness, measurable using Optical Coherence
Tomography (OCT), have been associated with neurodegenerative diseases such as
Alzheimer's disease (AD). While previous studies have mainly focused on
segmented layer thickness measurements, this study explored the direct
classification of OCT B-scan images for the early detection of AD. To our
knowledge, this is the first application of deep learning to raw OCT B-scans
for AD prediction in the literature. Unlike conventional medical image
classification tasks, early detection is more challenging than diagnosis
because imaging precedes clinical diagnosis by several years. We fine-tuned and
evaluated multiple pretrained models, including ImageNet-based networks and the
OCT-specific RETFound transformer, using subject-level cross-validation
datasets matched for age, sex, and imaging instances from the UK Biobank
cohort. To reduce overfitting in this small, high-dimensional dataset, both
standard and OCT-specific augmentation techniques were applied, along with a
year-weighted loss function that prioritized cases diagnosed within four years
of imaging. ResNet-34 produced the most stable results, achieving an AUC of
0.62 in the 4-year cohort. Although below the threshold for clinical
application, our explainability analyses confirmed localized structural
differences in the central macular subfield between the AD and control groups.
These findings provide a baseline for OCT-based AD prediction, highlight the
challenges of detecting subtle retinal biomarkers years before AD diagnosis,
and point to the need for larger datasets and multimodal approaches.

</details>


### [24] [SnowyLane: Robust Lane Detection on Snow-covered Rural Roads Using Infrastructural Elements](https://arxiv.org/abs/2511.05108)
*Jörg Gamerdinger,Benedict Wetzel,Patrick Schulz,Sven Teufel,Oliver Bringmann*

Main category: cs.CV

TL;DR: 本文提出了一种新的车道检测方法，利用路边分界标作为间接车道指示，针对冬季雪天情况进行了改进，同时发布了包含80,000帧的合成数据集SnowyLane，能够提升车道检测在恶劣天气中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术的发展，雪覆盖环境下的车道检测面临诸多挑战，现有的方法在这种情况下常常效率低下，因此需要一种新的检测方式。

Method: 我们的方案首先识别垂直的路边标志（称为分界标），然后使用参数化的Bezier曲线模型拟合平滑的车道轨迹，利用空间一致性和道路几何特征。

Result: 与现有的先进车道检测系统相比，我们的方法在恶劣天气下表现出显著的鲁棒性，尤其是重雪遮挡的情况下。

Conclusion: 本研究提供了一种新颖且鲁棒的车道检测方法，特别是在冬季雪覆盖的环境中，通过检测路边的特征而非传统的车道标记，实现了更好的检测性能。

Abstract: Lane detection for autonomous driving in snow-covered environments remains a
major challenge due to the frequent absence or occlusion of lane markings. In
this paper, we present a novel, robust and realtime capable approach that
bypasses the reliance on traditional lane markings by detecting roadside
features,specifically vertical roadside posts called delineators, as indirect
lane indicators. Our method first perceives these posts, then fits a smooth
lane trajectory using a parameterized Bezier curve model, leveraging spatial
consistency and road geometry. To support training and evaluation in these
challenging scenarios, we introduce SnowyLane, a new synthetic dataset
containing 80,000 annotated frames capture winter driving conditions, with
varying snow coverage, and lighting conditions. Compared to state-of-the-art
lane detection systems, our approach demonstrates significantly improved
robustness in adverse weather, particularly in cases with heavy snow occlusion.
This work establishes a strong foundation for reliable lane detection in winter
scenarios and contributes a valuable resource for future research in
all-weather autonomous driving. The dataset is available at
https://ekut-es.github.io/snowy-lane

</details>


### [25] [From Linear Probing to Joint-Weighted Token Hierarchy: A Foundation Model Bridging Global and Cellular Representations in Biomarker Detection](https://arxiv.org/abs/2511.05150)
*Jingsong Liu,Han Li,Nassir Navab,Peter J. Schüffler*

Main category: cs.CV

TL;DR: JWTH模型通过细胞中心的调整和注意力聚合提高了数字病理学中AI生物标志物的检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有的病理基础模型通常依赖全球的补丁级嵌入，忽视细胞级形态特征，因此需要一种新的方法来提升生物标志物的检测能力。

Method: 采用大规模自监督预训练结合以细胞为中心的后调优和注意力池化，融合了局部和全局的特征。

Result: JWTH模型在四个生物标志物和八个队列的四项任务中，平衡准确率提高了最高8.3%，平均改善1.2%。

Conclusion: JWTH模型在数字病理学中实现了更高的可解释性和稳健性，显著提升了AI基础生物标志物的检测能力。

Abstract: AI-based biomarkers can infer molecular features directly from hematoxylin &
eosin (H&E) slides, yet most pathology foundation models (PFMs) rely on global
patch-level embeddings and overlook cell-level morphology. We present a PFM
model, JWTH (Joint-Weighted Token Hierarchy), which integrates large-scale
self-supervised pretraining with cell-centric post-tuning and attention pooling
to fuse local and global tokens. Across four tasks involving four biomarkers
and eight cohorts, JWTH achieves up to 8.3% higher balanced accuracy and 1.2%
average improvement over prior PFMs, advancing interpretable and robust
AI-based biomarker detection in digital pathology.

</details>


### [26] [MUSE: Multi-Scale Dense Self-Distillation for Nucleus Detection and Classification](https://arxiv.org/abs/2511.05170)
*Zijiang Yang,Hanqing Chao,Bokai Zhao,Yelin Yang,Yunshuo Zhang,Dongmei Fu,Junping Zhang,Le Lu,Ke Yan,Dakai Jin,Minfeng Xu,Yun Bian,Hui Jiang*

Main category: cs.CV

TL;DR: MUSE是一种新兴的自监督学习方法，通过NuLo机制，灵活处理未标注数据，显著提升组织病理核检测与分类的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法过于依赖劳动密集型的核级注释，难以充分利用大规模未标注数据进行表征学习。

Method: MUSE为一新颖的自监督学习方法，核心为NuLo机制，支持基于预测核位置的灵活本地自蒸馏，并通过设计简单有效的编码解码架构及半监督微调策略来最大化未标注病理图像的价值。

Result: MUSE在三个广泛使用的基准上进行了广泛实验，证明了其有效性，模型性能超越了现有的监督基线和通用病理基础模型。

Conclusion: MUSE方法有效解决了组织病理学中核检测与分类的关键挑战，其模型性能超过了现有的监督基线及通用病理基础模型。

Abstract: Nucleus detection and classification (NDC) in histopathology analysis is a
fundamental task that underpins a wide range of high-level pathology
applications. However, existing methods heavily rely on labor-intensive
nucleus-level annotations and struggle to fully exploit large-scale unlabeled
data for learning discriminative nucleus representations. In this work, we
propose MUSE (MUlti-scale denSE self-distillation), a novel self-supervised
learning method tailored for NDC. At its core is NuLo (Nucleus-based Local
self-distillation), a coordinate-guided mechanism that enables flexible local
self-distillation based on predicted nucleus positions. By removing the need
for strict spatial alignment between augmented views, NuLo allows critical
cross-scale alignment, thus unlocking the capacity of models for fine-grained
nucleus-level representation. To support MUSE, we design a simple yet effective
encoder-decoder architecture and a large field-of-view semi-supervised
fine-tuning strategy that together maximize the value of unlabeled pathology
images. Extensive experiments on three widely used benchmarks demonstrate that
MUSE effectively addresses the core challenges of histopathological NDC. The
resulting models not only surpass state-of-the-art supervised baselines but
also outperform generic pathology foundation models.

</details>


### [27] [Walk the Lines 2: Contour Tracking for Detailed Segmentation](https://arxiv.org/abs/2511.05210)
*André Peter Kelm,Max Braeschke,Emre Gülsoylu,Simone Frintrop*

Main category: cs.CV

TL;DR: WtL2是一种新型的轮廓跟踪算法，适用于红外和RGB图像中的详细分割，性能优于现有方法，能加速特定领域的图像分割进展。


<details>
  <summary>Details</summary>
Motivation: 扩展原有的Walk the Lines（WtL）算法，以适应红外图像的船舶分割和其他RGB对象的细节分割需求。

Method: 采用轮廓跟踪代替标准的非最大抑制（NMS）来细化对象轮廓，形成可二值化的闭合区域。

Result: 在实现闭合对象轮廓方面，WtL2的性能超越了最新一代的基于轮廓的方法，并展现出高峰值交并比（IoU）和卓越的细节表现。

Conclusion: WtL2是一种具有较高细节分割能力的新型轮廓跟踪算法，适用于红外和RGB图像中的对象，并且在多种应用中表现出色。

Abstract: This paper presents Walk the Lines 2 (WtL2), a unique contour tracking
algorithm specifically adapted for detailed segmentation of infrared (IR) ships
and various objects in RGB.1 This extends the original Walk the Lines (WtL)
[12], which focused solely on detailed ship segmentation in color. These
innovative WtLs can replace the standard non-maximum suppression (NMS) by using
contour tracking to refine the object contour until a 1-pixel-wide closed shape
can be binarized, forming a segmentable area in foreground-background
scenarios. WtL2 broadens the application range of WtL beyond its original
scope, adapting to IR and expanding to diverse objects within the RGB context.
To achieve IR segmentation, we adapt its input, the object contour detector, to
IR ships. In addition, the algorithm is enhanced to process a wide range of RGB
objects, outperforming the latest generation of contour-based methods when
achieving a closed object contour, offering high peak Intersection over Union
(IoU) with impressive details. This positions WtL2 as a compelling method for
specialized applications that require detailed segmentation or high-quality
samples, potentially accelerating progress in several niche areas of image
segmentation.

</details>


### [28] [FreeControl: Efficient, Training-Free Structural Control via One-Step Attention Extraction](https://arxiv.org/abs/2511.05219)
*Jiang Lin,Xinyu Chen,Song Wu,Zhiqiu Zhang,Jizhi Zhang,Ye Wang,Qiang Tang,Qian Wang,Jian Yang,Zili Yi*

Main category: cs.CV

TL;DR: FreeControl 是一种无训练的框架，通过优化的注意力提取和结构解耦技术，提高了扩散模型的生成质量和操作灵活性。


<details>
  <summary>Details</summary>
Motivation: 控制扩散生成图像的空间和语义结构是一项挑战，现有方法受限于手工设计条件图和重新训练，缺乏灵活性和普适性。

Method: FreeControl 通过一次注意力提取，避免了重复训练和反演，同时引入了潜在条件解耦（LCD）以增强注意力质量。

Result: FreeControl 显示了优秀的生成效果，能在约 5% 的额外成本下实现语义和结构上的一致生成，并支持多来源的参考图像进行组合控制。

Conclusion: FreeControl 是一种创新的无训练框架，能够有效地实现扩散模型中的语义结构控制，具有更高的灵活性和更低的成本。

Abstract: Controlling the spatial and semantic structure of diffusion-generated images
remains a challenge. Existing methods like ControlNet rely on handcrafted
condition maps and retraining, limiting flexibility and generalization.
Inversion-based approaches offer stronger alignment but incur high inference
cost due to dual-path denoising. We present FreeControl, a training-free
framework for semantic structural control in diffusion models. Unlike prior
methods that extract attention across multiple timesteps, FreeControl performs
one-step attention extraction from a single, optimally chosen key timestep and
reuses it throughout denoising. This enables efficient structural guidance
without inversion or retraining. To further improve quality and stability, we
introduce Latent-Condition Decoupling (LCD): a principled separation of the key
timestep and the noised latent used in attention extraction. LCD provides finer
control over attention quality and eliminates structural artifacts. FreeControl
also supports compositional control via reference images assembled from
multiple sources - enabling intuitive scene layout design and stronger prompt
alignment. FreeControl introduces a new paradigm for test-time control,
enabling structurally and semantically aligned, visually coherent generation
directly from raw images, with the flexibility for intuitive compositional
design and compatibility with modern diffusion models at approximately 5
percent additional cost.

</details>


### [29] [4D3R: Motion-Aware Neural Reconstruction and Rendering of Dynamic Scenes from Monocular Videos](https://arxiv.org/abs/2511.05229)
*Mengqi Guo,Bo Xu,Yanyan Li,Gim Hee Lee*

Main category: cs.CV

TL;DR: 本研究提出4D3R，一个无须姿态的动态神经渲染框架，通过两阶段方法有效合成动态场景新视图，提升了重构质量并减少了计算成本。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决现有方法对动态场景重建的局限性，尤其是在相机姿态未知的情况下。

Method: 该方法分为两阶段：首先通过3D基础模型进行初步姿态和几何估计，随后进行运动感知的细化。

Result: 在真实的动态数据集上，4D3R方法在PSNR指标上比现有最先进的方法提高了1.8dB，同时将计算需求减少了5倍。

Conclusion: 4D3R方法在动态场景的单目视频新视图合成中表现优异，尤其是在处理大动态物体时，显著提升了重构质量并减少了计算成本。

Abstract: Novel view synthesis from monocular videos of dynamic scenes with unknown
camera poses remains a fundamental challenge in computer vision and graphics.
While recent advances in 3D representations such as Neural Radiance Fields
(NeRF) and 3D Gaussian Splatting (3DGS) have shown promising results for static
scenes, they struggle with dynamic content and typically rely on pre-computed
camera poses. We present 4D3R, a pose-free dynamic neural rendering framework
that decouples static and dynamic components through a two-stage approach. Our
method first leverages 3D foundational models for initial pose and geometry
estimation, followed by motion-aware refinement. 4D3R introduces two key
technical innovations: (1) a motion-aware bundle adjustment (MA-BA) module that
combines transformer-based learned priors with SAM2 for robust dynamic object
segmentation, enabling more accurate camera pose refinement; and (2) an
efficient Motion-Aware Gaussian Splatting (MA-GS) representation that uses
control points with a deformation field MLP and linear blend skinning to model
dynamic motion, significantly reducing computational cost while maintaining
high-quality reconstruction. Extensive experiments on real-world dynamic
datasets demonstrate that our approach achieves up to 1.8dB PSNR improvement
over state-of-the-art methods, particularly in challenging scenarios with large
dynamic objects, while reducing computational requirements by 5x compared to
previous dynamic scene representations.

</details>


### [30] [Automatic segmentation of colorectal liver metastases for ultrasound-based navigated resection](https://arxiv.org/abs/2511.05253)
*Tiziano Natali,Karin A. Olthof,Niels F. M. Kok,Koert F. D. Kuhlmann,Theo J. M. Ruers,Matteo Fusaglia*

Main category: cs.CV

TL;DR: 研究表明，使用裁剪3D U-Net实现肝肠道转移瘤的术中超声自动分割可大幅提高准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 提升术中超声成像对肝肠道转移瘤的分割精度，克服当前方法的不足。

Method: 使用nnU-Net框架训练的3D U-Net进行自动化分割，比较全体积和裁剪体积模型的表现。

Result: 裁剪体积模型在所有评价指标上表现显著优于全体积模型，且具有较快的执行速度和临床可接受的准确性。

Conclusion: 自动化3D分割技术在肝肠道转移瘤的术中超声成像中提供了可靠且接近实时的结果，显著降低了操作难度和手术时间。

Abstract: Introduction: Accurate intraoperative delineation of colorectal liver
metastases (CRLM) is crucial for achieving negative resection margins but
remains challenging using intraoperative ultrasound (iUS) due to low contrast,
noise, and operator dependency. Automated segmentation could enhance precision
and efficiency in ultrasound-based navigation workflows.
  Methods: Eighty-five tracked 3D iUS volumes from 85 CRLM patients were used
to train and evaluate a 3D U-Net implemented via the nnU-Net framework. Two
variants were compared: one trained on full iUS volumes and another on cropped
regions around tumors. Segmentation accuracy was assessed using Dice Similarity
Coefficient (DSC), Hausdorff Distance (HDist.), and Relative Volume Difference
(RVD) on retrospective and prospective datasets. The workflow was integrated
into 3D Slicer for real-time intraoperative use.
  Results: The cropped-volume model significantly outperformed the full-volume
model across all metrics (AUC-ROC = 0.898 vs 0.718). It achieved median DSC =
0.74, recall = 0.79, and HDist. = 17.1 mm comparable to semi-automatic
segmentation but with ~4x faster execution (~ 1 min). Prospective
intraoperative testing confirmed robust and consistent performance, with
clinically acceptable accuracy for real-time surgical guidance.
  Conclusion: Automatic 3D segmentation of CRLM in iUS using a cropped 3D U-Net
provides reliable, near real-time results with minimal operator input. The
method enables efficient, registration-free ultrasound-based navigation for
hepatic surgery, approaching expert-level accuracy while substantially reducing
manual workload and procedure time.

</details>


### [31] [OregairuChar: A Benchmark Dataset for Character Appearance Frequency Analysis in My Teen Romantic Comedy SNAFU](https://arxiv.org/abs/2511.05263)
*Qi Sun,Dingju Zhou,Lina Zhang*

Main category: cs.CV

TL;DR: 本研究构建了 OregairuChar 数据集，有助于分析和理解动漫中角色出现频率及其叙事动态。


<details>
  <summary>Details</summary>
Motivation: 为了理解动漫中的叙事结构、角色重要性和故事进展，需要分析角色出现频率。

Method: 通过手动选择帧和标注边界框，构建 OregairuChar 数据集，并基准多个物体检测模型以进行量化研究。

Result: 通过对数据集的分析，发现角色突出性模式及其在叙事中的演变。

Conclusion: OregairuChar 数据集为分析动漫角色出现频率提供了重要资源，揭示了角色在叙事中的重要性和演变。

Abstract: The analysis of character appearance frequency is essential for understanding
narrative structure, character prominence, and story progression in anime. In
this work, we introduce OregairuChar, a benchmark dataset designed for
appearance frequency analysis in the anime series My Teen Romantic Comedy
SNAFU. The dataset comprises 1600 manually selected frames from the third
season, annotated with 2860 bounding boxes across 11 main characters.
OregairuChar captures diverse visual challenges, including occlusion, pose
variation, and inter-character similarity, providing a realistic basis for
appearance-based studies. To enable quantitative research, we benchmark several
object detection models on the dataset and leverage their predictions for
fine-grained, episode-level analysis of character presence over time. This
approach reveals patterns of character prominence and their evolution within
the narrative. By emphasizing appearance frequency, OregairuChar serves as a
valuable resource for exploring computational narrative dynamics and
character-centric storytelling in stylized media.

</details>


### [32] [DeepEyesV2: Toward Agentic Multimodal Model](https://arxiv.org/abs/2511.05271)
*Jack Hong,Chenxiao Zhao,ChengLin Zhu,Weiheng Lu,Guohai Xu,Xing Yu*

Main category: cs.CV

TL;DR: 本研究提出DeepEyesV2模型，通过两阶段训练改进工具使用行为，实现在真实世界中的广泛应用和有效性。


<details>
  <summary>Details</summary>
Motivation: 直接的强化学习无法有效地引导工具使用行为，因此需要探索建立有效的工具使用模式。

Method: 采用两阶段训练管道，包括冷启动阶段和强化学习阶段，以建立和精炼工具使用模式。

Result: 在RealX-Bench和其他基准测试中评估DeepEyesV2，证实其在多模态推理中的有效性，尤其是在感知任务和推理任务中能根据上下文选择性调用工具。

Conclusion: DeepEyesV2在真实世界理解、数学推理和搜索密集型任务中表现出色，展示了任务适应性工具调用的能力。

Abstract: Agentic multimodal models should not only comprehend text and images, but
also actively invoke external tools, such as code execution environments and
web search, and integrate these operations into reasoning. In this work, we
introduce DeepEyesV2 and explore how to build an agentic multimodal model from
the perspectives of data construction, training methods, and model evaluation.
We observe that direct reinforcement learning alone fails to induce robust
tool-use behavior. This phenomenon motivates a two-stage training pipeline: a
cold-start stage to establish tool-use patterns, and reinforcement learning
stage to further refine tool invocation. We curate a diverse, moderately
challenging training dataset, specifically including examples where tool use is
beneficial. We further introduce RealX-Bench, a comprehensive benchmark
designed to evaluate real-world multimodal reasoning, which inherently requires
the integration of multiple capabilities, including perception, search, and
reasoning. We evaluate DeepEyesV2 on RealX-Bench and other representative
benchmarks, demonstrating its effectiveness across real-world understanding,
mathematical reasoning, and search-intensive tasks. Moreover, DeepEyesV2
exhibits task-adaptive tool invocation, tending to use image operations for
perception tasks and numerical computations for reasoning tasks. Reinforcement
learning further enables complex tool combinations and allows model to
selectively invoke tools based on context. We hope our study can provide
guidance for community in developing agentic multimodal models.

</details>


### [33] [What's on Your Plate? Inferring Chinese Cuisine Intake from Wearable IMUs](https://arxiv.org/abs/2511.05292)
*Jiaxi Yin,Pengcheng Wang,Han Ding,Fei Wang*

Main category: cs.CV

TL;DR: CuisineSense 是一种新颖的饮食监测系统，结合了手势和头部动态，能高效识别多种中国食品类型，适用于日常饮食监测。


<details>
  <summary>Details</summary>
Motivation: 传统饮食监测方法存在偏倚且隐私问题，现有的可穿戴设备方法缺乏对多样化中国菜品的支持，因此需要开发一种新的解决方案。

Method: 通过整合智能手表的手部动作和智能眼镜的头部动态，设计了一个双阶段检测管道来识别饮食状态和细粒度的食品类型。

Result: CuisineSense 在进食状态检测和食品分类中均实现了高准确度，充分满足了便携式饮食监测的需求。

Conclusion: CuisineSense 提供了一种高精度的穿戴式饮食监测解决方案，能够准确检测进食状态和食品分类，尤其适用于多样化的中国菜。

Abstract: Accurate food intake detection is vital for dietary monitoring and chronic
disease prevention. Traditional self-report methods are prone to recall bias,
while camera-based approaches raise concerns about privacy. Furthermore,
existing wearable-based methods primarily focus on a limited number of food
types, such as hamburgers and pizza, failing to address the vast diversity of
Chinese cuisine. To bridge this gap, we propose CuisineSense, a system that
classifies Chinese food types by integrating hand motion cues from a smartwatch
with head dynamics from smart glasses. To filter out irrelevant daily
activities, we design a two-stage detection pipeline. The first stage
identifies eating states by distinguishing characteristic temporal patterns
from non-eating behaviors. The second stage then conducts fine-grained food
type recognition based on the motions captured during food intake. To evaluate
CuisineSense, we construct a dataset comprising 27.5 hours of IMU recordings
across 11 food categories and 10 participants. Experiments demonstrate that
CuisineSense achieves high accuracy in both eating state detection and food
classification, offering a practical solution for unobtrusive, wearable-based
dietary monitoring.The system code is publicly available at
https://github.com/joeeeeyin/CuisineSense.git.

</details>


### [34] [Cross-domain EEG-based Emotion Recognition with Contrastive Learning](https://arxiv.org/abs/2511.05293)
*Rui Yan,Yibo Li,Han Ding,Fei Wang*

Main category: cs.CV

TL;DR: This study presents EmotionCLIP, an innovative method for EEG-based emotion recognition that utilizes multimodal contrastive learning, achieving significant performance improvements.


<details>
  <summary>Details</summary>
Motivation: To address challenges in feature utilization and cross-domain generalization in EEG-based emotion recognition.

Method: The paper formulates emotion recognition as an EEG-text matching task using the CLIP framework, with a custom backbone (SST-LegoViT) for feature extraction.

Result: The model demonstrates high cross-subject and cross-time accuracies on SEED and SEED-IV datasets, outperforming existing methods.

Conclusion: EmotionCLIP achieves superior performance in EEG-based emotion recognition through multimodal contrastive learning.

Abstract: Electroencephalogram (EEG)-based emotion recognition is vital for affective
computing but faces challenges in feature utilization and cross-domain
generalization. This work introduces EmotionCLIP, which reformulates
recognition as an EEG-text matching task within the CLIP framework. A tailored
backbone, SST-LegoViT, captures spatial, spectral, and temporal features using
multi-scale convolution and Transformer modules. Experiments on SEED and
SEED-IV datasets show superior cross-subject accuracies of 88.69% and 73.50%,
and cross-time accuracies of 88.46% and 77.54%, outperforming existing models.
Results demonstrate the effectiveness of multimodal contrastive learning for
robust EEG emotion recognition.

</details>


### [35] [LiveStar: Live Streaming Assistant for Real-World Online Video Understanding](https://arxiv.org/abs/2511.05299)
*Zhenyu Yang,Kairui Zhang,Yuhang Hu,Bing Wang,Shengsheng Qian,Bin Wen,Fan Yang,Tingting Gao,Weiming Dong,Changsheng Xu*

Main category: cs.CV

TL;DR: 本文提出LiveStar，一个针对实时视频理解的助理，利用新的训练策略和解码框架，实现了更高的准确性和响应效率。


<details>
  <summary>Details</summary>
Motivation: 现有在线视频大语言模型在处理连续帧输入和响应时机的优化上存在困难，需要改善实时性和叙述连贯性。

Method: 提出了一种增量视频语言对齐的训练策略、基于响应沉默解码框架和记忆感知加速技术，来实现实时响应。

Result: 通过在三个基准上的广泛实验，验证了LiveStar在语义正确性和推理速度上的显著提升。

Conclusion: LiveStar在在线视频理解任务中表现出色，显示出比现有模型更高的语义正确性和更低的时间延迟，同时提高了帧率。

Abstract: Despite significant progress in Video Large Language Models (Video-LLMs) for
offline video understanding, existing online Video-LLMs typically struggle to
simultaneously process continuous frame-by-frame inputs and determine optimal
response timing, often compromising real-time responsiveness and narrative
coherence. To address these limitations, we introduce LiveStar, a pioneering
live streaming assistant that achieves always-on proactive responses through
adaptive streaming decoding. Specifically, LiveStar incorporates: (1) a
training strategy enabling incremental video-language alignment for
variable-length video streams, preserving temporal consistency across
dynamically evolving frame sequences; (2) a response-silence decoding framework
that determines optimal proactive response timing via a single forward pass
verification; (3) memory-aware acceleration via peak-end memory compression for
online inference on 10+ minute videos, combined with streaming key-value cache
to achieve 1.53x faster inference. We also construct an OmniStar dataset, a
comprehensive dataset for training and benchmarking that encompasses 15 diverse
real-world scenarios and 5 evaluation tasks for online video understanding.
Extensive experiments across three benchmarks demonstrate LiveStar's
state-of-the-art performance, achieving an average 19.5% improvement in
semantic correctness with 18.1% reduced timing difference compared to existing
online Video-LLMs, while improving FPS by 12.0% across all five OmniStar tasks.
Our model and dataset can be accessed at https://github.com/yzy-bupt/LiveStar.

</details>


### [36] [Rethinking Metrics and Diffusion Architecture for 3D Point Cloud Generation](https://arxiv.org/abs/2511.05308)
*Matteo Bastico,David Ryckelynck,Laurent Corté,Yannick Tillier,Etienne Decencière*

Main category: cs.CV

TL;DR: 本研究提出了一种新型架构Diffusion Point Transformer及改进的评估指标，以提高3D点云生成的质量和稳定性。


<details>
  <summary>Details</summary>
Motivation: 随着3D点云在现代技术中的广泛应用，对先进生成模型和可靠评估指标的需求日益增长，但现有的评估指标存在缺陷。

Method: 通过引入样本对齐和密度感知Chamfer距离（DCD）解决评估指标的稳定性和一致性问题，并提出了一种新的表面法向一致性(SNC)指标来评估生成样本的质量。

Result: 提出新的SNC评估指标与传统指标结合使用，改善了生成点云样本的质量评估；开发的Diffusion Point Transformer架构在ShapeNet数据集上的实验显示出其卓越的表现。

Conclusion: 提出的一种新型架构Diffusion Point Transformer在生成高保真3D结构方面优于现有解决方案，尤其是在生成点云的质量上，达到了新的最优性能。

Abstract: As 3D point clouds become a cornerstone of modern technology, the need for
sophisticated generative models and reliable evaluation metrics has grown
exponentially. In this work, we first expose that some commonly used metrics
for evaluating generated point clouds, particularly those based on Chamfer
Distance (CD), lack robustness against defects and fail to capture geometric
fidelity and local shape consistency when used as quality indicators. We
further show that introducing samples alignment prior to distance calculation
and replacing CD with Density-Aware Chamfer Distance (DCD) are simple yet
essential steps to ensure the consistency and robustness of point cloud
generative model evaluation metrics. While existing metrics primarily focus on
directly comparing 3D Euclidean coordinates, we present a novel metric, named
Surface Normal Concordance (SNC), which approximates surface similarity by
comparing estimated point normals. This new metric, when combined with
traditional ones, provides a more comprehensive evaluation of the quality of
generated samples. Finally, leveraging recent advancements in transformer-based
models for point cloud analysis, such as serialized patch attention , we
propose a new architecture for generating high-fidelity 3D structures, the
Diffusion Point Transformer. We perform extensive experiments and comparisons
on the ShapeNet dataset, showing that our model outperforms previous solutions,
particularly in terms of quality of generated point clouds, achieving new
state-of-the-art. Code available at
https://github.com/matteo-bastico/DiffusionPointTransformer.

</details>


### [37] [$\mathbf{S^2LM}$: Towards Semantic Steganography via Large Language Models](https://arxiv.org/abs/2511.05319)
*Huanqi Wu,Huangbiao Xu,Runfeng Xie,Jiaxin Cai,Kaixin Zhang,Xiao Ke*

Main category: cs.CV

TL;DR: 本研究提出了一种新的语义隐写方法$	extbf{S^2LM}$，通过大语言模型将句子级信息嵌入到图像中，并建立了评估基准Invisible Text。


<details>
  <summary>Details</summary>
Motivation: 随着AIGC时代的到来，隐写术在嵌入丰富语义信息中的重要性日益增加。

Method: 通过设计一个新的流程，使得大语言模型（LLM）全程参与，将句子或段落层次的文本信息嵌入到图像中。

Result: 通过建立Invisible Text基准和进行定量与定性实验，验证了该方法的有效性。

Conclusion: 提出的$	extbf{S^2LM}$方法有效地扩展了LLMs在语义隐写中的能力。

Abstract: Although steganography has made significant advancements in recent years, it
still struggles to embed semantically rich, sentence-level information into
carriers. However, in the era of AIGC, the capacity of steganography is more
critical than ever. In this work, we present Sentence-to-Image Steganography,
an instance of Semantic Steganography, a novel task that enables the hiding of
arbitrary sentence-level messages within a cover image. Furthermore, we
establish a benchmark named Invisible Text (IVT), comprising a diverse set of
sentence-level texts as secret messages for evaluation. Finally, we present
$\mathbf{S^2LM}$: Semantic Steganographic Language Model, which utilizes large
language models (LLMs) to embed high-level textual information, such as
sentences or even paragraphs, into images. Unlike traditional bit-level
counterparts, $\mathrm{S^2LM}$ enables the integration of semantically rich
content through a newly designed pipeline in which the LLM is involved
throughout the entire process. Both quantitative and qualitative experiments
demonstrate that our method effectively unlocks new semantic steganographic
capabilities for LLMs. The source code will be released soon.

</details>


### [38] [Canonical Space Representation for 4D Panoptic Segmentation of Articulated Objects](https://arxiv.org/abs/2511.05356)
*Manuel Gomes,Bogdan Raducanu,Miguel Oliveira*

Main category: cs.CV

TL;DR: 本文提出了 Artic4D 数据集和 CanonSeg4D 框架，在动态物体感知中通过时间建模和规范对齐技术实现了全景分割精度的提高。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了物体的动态特性，缺乏基准数据集，影响了关节物体的感知研究。

Method: 提出了一种新的 4D 全景分割框架 CanonSeg4D，显式估计每帧偏移，将观察到的物体部分映射到学习的规范空间。

Result: 推出了 Artic4D 数据集，并通过 CanonSeg4D 框架在复杂场景中实现了全景分割精度的提升。

Conclusion: 通过 CanonSeg4D 方法，相较于现有技术在复杂场景中的全景分割精度显著提高，展示了时间建模和规范对齐在动态物体理解中的有效性。

Abstract: Articulated object perception presents significant challenges in computer
vision, particularly because most existing methods ignore temporal dynamics
despite the inherently dynamic nature of such objects. The use of 4D temporal
data has not been thoroughly explored in articulated object perception and
remains unexamined for panoptic segmentation. The lack of a benchmark dataset
further hurt this field. To this end, we introduce Artic4D as a new dataset
derived from PartNet Mobility and augmented with synthetic sensor data,
featuring 4D panoptic annotations and articulation parameters. Building on this
dataset, we propose CanonSeg4D, a novel 4D panoptic segmentation framework.
This approach explicitly estimates per-frame offsets mapping observed object
parts to a learned canonical space, thereby enhancing part-level segmentation.
The framework employs this canonical representation to achieve consistent
alignment of object parts across sequential frames. Comprehensive experiments
on Artic4D demonstrate that the proposed CanonSeg4D outperforms state of the
art approaches in panoptic segmentation accuracy in more complex scenarios.
These findings highlight the effectiveness of temporal modeling and canonical
alignment in dynamic object understanding, and pave the way for future advances
in 4D articulated object perception.

</details>


### [39] [Dense Motion Captioning](https://arxiv.org/abs/2511.05369)
*Shiyao Xu,Benedetta Liberatori,Gül Varol,Paolo Rota*

Main category: cs.CV

TL;DR: 本文提出了一种新的Dense Motion Captioning任务，介绍了包含丰富标注的复杂运动数据集（CompMo），并展示了DEMO模型在运动理解和字幕生成领域的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前3D人类运动理解相对较少，而现有数据集在时间标注方面存在不足，本研究旨在填补这一空白。

Method: 提出了DEMO模型，通过大型语言模型与简单运动适配器相结合，进行密集、时间基础的字幕生成。

Result: 推出了复杂运动数据集（CompMo），包含60000个运动序列，带有精确的时间边界标注，同时DEMO模型在新数据集上表现优越。

Conclusion: DEMO模型在复杂运动理解和字幕生成任务中表现优越，为未来的研究奠定了坚实基础。

Abstract: Recent advances in 3D human motion and language integration have primarily
focused on text-to-motion generation, leaving the task of motion understanding
relatively unexplored. We introduce Dense Motion Captioning, a novel task that
aims to temporally localize and caption actions within 3D human motion
sequences. Current datasets fall short in providing detailed temporal
annotations and predominantly consist of short sequences featuring few actions.
To overcome these limitations, we present the Complex Motion Dataset (CompMo),
the first large-scale dataset featuring richly annotated, complex motion
sequences with precise temporal boundaries. Built through a carefully designed
data generation pipeline, CompMo includes 60,000 motion sequences, each
composed of multiple actions ranging from at least two to ten, accurately
annotated with their temporal extents. We further present DEMO, a model that
integrates a large language model with a simple motion adapter, trained to
generate dense, temporally grounded captions. Our experiments show that DEMO
substantially outperforms existing methods on CompMo as well as on adapted
benchmarks, establishing a robust baseline for future research in 3D motion
understanding and captioning.

</details>


### [40] [PreResQ-R1: Towards Fine-Grained Rank-and-Score Reinforcement Learning for Visual Quality Assessment via Preference-Response Disentangled Policy Optimization](https://arxiv.org/abs/2511.05393)
*Zehui Feng,Tian Qiu,Tong Wu,Junxuan Li,Huayuan Xu,Ting Han*

Main category: cs.CV

TL;DR: PreResQ-R1是一种新型的视觉质量评估框架，通过强化学习优化技巧，超越了传统方法，达到了最先进的评估结果。


<details>
  <summary>Details</summary>
Motivation: 针对现有视觉质量评估方法的局限性，尤其是在推理深度、评分校准以及跨领域泛化能力上的不足，旨在提升视觉质量评估的准确性与解释性。

Method: 提出了一种偏好-响应解耦的强化学习框架，通过群体相对策划优化实现绝对评分回归和相对排名一致性的统一优化。

Result: 在仅使用6000张图像和28000个视频进行强化微调的情况下，PreResQ-R1在10个图像质量评估和5个视频质量评估基准上实现了5.30%和2.15%的显著提升。

Conclusion: PreResQ-R1在多项图像和视频质量评估基准测试中取得了最先进的结果，并提供了符合人类认知的推理路径。

Abstract: Visual Quality Assessment (QA) seeks to predict human perceptual judgments of
visual fidelity. While recent multimodal large language models (MLLMs) show
promise in reasoning about image and video quality, existing approaches mainly
rely on supervised fine-tuning or rank-only objectives, resulting in shallow
reasoning, poor score calibration, and limited cross-domain generalization. We
propose PreResQ-R1, a Preference-Response Disentangled Reinforcement Learning
framework that unifies absolute score regression and relative ranking
consistency within a single reasoning-driven optimization scheme. Unlike prior
QA methods, PreResQ-R1 introduces a dual-branch reward formulation that
separately models intra-sample response coherence and inter-sample preference
alignment, optimized via Group Relative Policy Optimization (GRPO). This design
encourages fine-grained, stable, and interpretable chain-of-thought reasoning
about perceptual quality. To extend beyond static imagery, we further design a
global-temporal and local-spatial data flow strategy for Video Quality
Assessment. Remarkably, with reinforcement fine-tuning on only 6K images and
28K videos, PreResQ-R1 achieves state-of-the-art results across 10 IQA and 5
VQA benchmarks under both SRCC and PLCC metrics, surpassing by margins of 5.30%
and textbf2.15% in IQA task, respectively. Beyond quantitative gains, it
produces human-aligned reasoning traces that reveal the perceptual cues
underlying quality judgments. Code and model are available.

</details>


### [41] [Multi-modal Loop Closure Detection with Foundation Models in Severely Unstructured Environments](https://arxiv.org/abs/2511.05404)
*Laura Alejandra Encinar Gonzalez,John Folkesson,Rudolph Triebel,Riccardo Giubilato*

Main category: cs.CV

TL;DR: MPRF是一个多模态管道，利用基础模型实现环闭合检测，展示了在低纹理环境下优于现有方法的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在GNSS受限环境中，可靠的环闭合检测对于SLAM算法至关重要，现有方法在可视化和LiDAR方法上存在显著局限。

Method: MPRF采用了多模态管道，结合视觉检索和六自由度姿态估计策略，集成了DINOv2特征和SONATA基础的LiDAR描述符。

Result: MPRF在S3LI数据集和S3LI Vulcano数据集上的实验表明，其在精度上优于最先进的检索方法，并在低纹理区域增强了姿态估计的鲁棒性。

Conclusion: MPRF展示了将基础模型应用于视觉和LiDAR模态在极端非结构化环境下进行环闭合检测的潜力，提供了精确和可靠的pose估计。

Abstract: Robust loop closure detection is a critical component of Simultaneous
Localization and Mapping (SLAM) algorithms in GNSS-denied environments, such as
in the context of planetary exploration. In these settings, visual place
recognition often fails due to aliasing and weak textures, while LiDAR-based
methods suffer from sparsity and ambiguity. This paper presents MPRF, a
multimodal pipeline that leverages transformer-based foundation models for both
vision and LiDAR modalities to achieve robust loop closure in severely
unstructured environments. Unlike prior work limited to retrieval, MPRF
integrates a two-stage visual retrieval strategy with explicit 6-DoF pose
estimation, combining DINOv2 features with SALAD aggregation for efficient
candidate screening and SONATA-based LiDAR descriptors for geometric
verification. Experiments on the S3LI dataset and S3LI Vulcano dataset show
that MPRF outperforms state-of-the-art retrieval methods in precision while
enhancing pose estimation robustness in low-texture regions. By providing
interpretable correspondences suitable for SLAM back-ends, MPRF achieves a
favorable trade-off between accuracy, efficiency, and reliability,
demonstrating the potential of foundation models to unify place recognition and
pose estimation. Code and models will be released at github.com/DLR-RM/MPRF.

</details>


### [42] [Shared Latent Representation for Joint Text-to-Audio-Visual Synthesis](https://arxiv.org/abs/2511.05432)
*Dogucan Yaman,Seymanur Akti,Fevziye Irem Eyiokur,Alexander Waibel*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的文本到谈话面合成框架，显著提高了合成语音与面部动作的同步性和真实感。


<details>
  <summary>Details</summary>
Motivation: 解决传统文本到语音合成在语音与面部表现生成之间的配合问题，提供更自然和富有表现力的合成结果。

Method: 使用文本到向量模块生成Wav2Vec2嵌入，并采用两阶段训练来处理干净特征与TTS预测特征之间的分布差异。

Result: 通过采用TTS预测的潜在特征进行条件生成，相比传统级联管道，在唇同步和视觉真实感方面表现更佳。

Conclusion: 引入了基于潜在语音表示的文本到谈话面部合成框架，该框架在保持说话者身份的同时，改善了唇同步和视觉真实感。

Abstract: We propose a text-to-talking-face synthesis framework leveraging latent
speech representations from HierSpeech++. A Text-to-Vec module generates
Wav2Vec2 embeddings from text, which jointly condition speech and face
generation. To handle distribution shifts between clean and TTS-predicted
features, we adopt a two-stage training: pretraining on Wav2Vec2 embeddings and
finetuning on TTS outputs. This enables tight audio-visual alignment, preserves
speaker identity, and produces natural, expressive speech and synchronized
facial motion without ground-truth audio at inference. Experiments show that
conditioning on TTS-predicted latent features outperforms cascaded pipelines,
improving both lip-sync and visual realism.

</details>


### [43] [How Many Tokens Do 3D Point Cloud Transformer Architectures Really Need?](https://arxiv.org/abs/2511.05449)
*Tuan Anh Tran,Duy M. H. Nguyen,Hoai-Chau Tran,Michael Barz,Khoa D. Doan,Roger Wattenhofer,Ngo Anh Vien,Mathias Niepert,Daniel Sonntag,Paul Swoboda*

Main category: cs.CV

TL;DR: 本研究提出gitmerge3D方法，通过合并冗余令牌减少计算负担，从而提升3D点云转换器的效率。


<details>
  <summary>Details</summary>
Motivation: 现有的3D点云转换器模型通常依赖于密集的令牌表示，导致训练和推理时的计算及内存成本高昂。通过观察到令牌的冗余性，我们希望挑战现有模型对令牌数量的依赖。

Method: 提出了一种全球信息驱动的图形令牌合并方法，称为gitmerge3D，能够将令牌数量减少90-95%。

Result: 我们的方法在多个3D视觉任务中进行了验证，显示出计算效率的一致性提升。

Conclusion: 我们的方法通过减少令牌数量显著提高了计算效率，同时保持了竞争力的性能。

Abstract: Recent advances in 3D point cloud transformers have led to state-of-the-art
results in tasks such as semantic segmentation and reconstruction. However,
these models typically rely on dense token representations, incurring high
computational and memory costs during training and inference. In this work, we
present the finding that tokens are remarkably redundant, leading to
substantial inefficiency. We introduce gitmerge3D, a globally informed graph
token merging method that can reduce the token count by up to 90-95% while
maintaining competitive performance. This finding challenges the prevailing
assumption that more tokens inherently yield better performance and highlights
that many current models are over-tokenized and under-optimized for
scalability. We validate our method across multiple 3D vision tasks and show
consistent improvements in computational efficiency. This work is the first to
assess redundancy in large-scale 3D transformer models, providing insights into
the development of more efficient 3D foundation architectures. Our code and
checkpoints are publicly available at https://gitmerge3d.github.io

</details>


### [44] [The Potential of Copernicus Satellites for Disaster Response: Retrieving Building Damage from Sentinel-1 and Sentinel-2](https://arxiv.org/abs/2511.05461)
*Olivier Dietrich,Merlin Alfredsson,Emilia Arens,Nando Metzger,Torben Peters,Linus Scheibenreif,Jan Dirk Wegner,Konrad Schindler*

Main category: cs.CV

TL;DR: 本研究表明，Copernicus中等分辨率卫星影像能够有效支持建筑损伤评估，推出了xBD-S12数据集以促进相关研究。


<details>
  <summary>Details</summary>
Motivation: 在自然灾害发生时，快速评估损害以指导人道主义响应至关重要。

Method: 通过引入xBD-S12数据集，进行一系列实验来评估自然灾害后的建筑损伤检测与映射。

Result: 在多种灾害场景下，尽管分辨率为10米，建筑损伤的检测和映射表现良好，但复杂的模型架构对未见灾害的泛化能力较差。

Conclusion: Copernicus中等分辨率影像是快速大范围损伤评估的可行数据源，与高分辨率影像可以互为补充。

Abstract: Natural disasters demand rapid damage assessment to guide humanitarian
response. Here, we investigate whether medium-resolution Earth observation
images from the Copernicus program can support building damage assessment,
complementing very-high resolution imagery with often limited availability. We
introduce xBD-S12, a dataset of 10,315 pre- and post-disaster image pairs from
both Sentinel-1 and Sentinel-2, spatially and temporally aligned with the
established xBD benchmark. In a series of experiments, we demonstrate that
building damage can be detected and mapped rather well in many disaster
scenarios, despite the moderate 10$\,$m ground sampling distance. We also find
that, for damage mapping at that resolution, architectural sophistication does
not seem to bring much advantage: more complex model architectures tend to
struggle with generalization to unseen disasters, and geospatial foundation
models bring little practical benefit. Our results suggest that Copernicus
images are a viable data source for rapid, wide-area damage assessment and
could play an important role alongside VHR imagery. We release the xBD-S12
dataset, code, and trained models to support further research.

</details>


### [45] [Photo Dating by Facial Age Aggregation](https://arxiv.org/abs/2511.05464)
*Jakub Paplham,Vojtech Franc*

Main category: cs.CV

TL;DR: 我们提出了一种新的照片年份估计方法，利用了一个包含160万标注面孔的数据集，并显著改善了多面孔图像的年份预测准确性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在通过分析照片中人物的面孔信息来估计照片拍摄的年份，填补现有技术的空白。

Method: 本研究提出了一种概率框架，结合现代人脸识别和年龄估计模型的视觉证据，以及基于职业的时间先验，以推断照片的拍摄年份。

Result: 研究结果表明，通过聚合多个面孔的证据，性能得到了持续提升，我们的方法显著优于一些强大的基于场景的方法。

Conclusion: 我们的方法通过整合多个面孔的信息，显著提高了照片拍摄年份估计的准确性，尤其在包含多个可识别个体的图像中表现出色。

Abstract: We introduce a novel method for Photo Dating which estimates the year a
photograph was taken by leveraging information from the faces of people present
in the image. To facilitate this research, we publicly release CSFD-1.6M, a new
dataset containing over 1.6 million annotated faces, primarily from movie
stills, with identity and birth year annotations. Uniquely, our dataset
provides annotations for multiple individuals within a single image, enabling
the study of multi-face information aggregation. We propose a probabilistic
framework that formally combines visual evidence from modern face recognition
and age estimation models, and career-based temporal priors to infer the photo
capture year. Our experiments demonstrate that aggregating evidence from
multiple faces consistently improves the performance and the approach
significantly outperforms strong, scene-based baselines, particularly for
images containing several identifiable individuals.

</details>


### [46] [EventFlow: Real-Time Neuromorphic Event-Driven Classification of Two-Phase Boiling Flow Regimes](https://arxiv.org/abs/2511.05467)
*Sanghyeon Chang,Srikar Arani,Nishant Sai Nuthalapati,Youngjoon Suh,Nicholas Choi,Siavash Khodakarami,Md Rakibul Hasan Roni,Nenad Miljkovic,Aparna Chandramowlishwaran,Yoonjin Won*

Main category: cs.CV

TL;DR: 本研究提出了一种利用神经形态传感器信号的实时流动状态分类框架，显著提升了流动状态监测的准确性与响应速度。


<details>
  <summary>Details</summary>
Motivation: 动机在于现有光学成像方法在捕捉瞬态流动行为时面临高计算要求和时间分辨率不足的问题。

Method: 开发了五种分类模型，结合传统图像数据与事件数据进行流动状态分类。

Result: 事件驱动的长短期记忆模型在准确性（97.6%）和处理速度（0.28毫秒）之间提供了最佳平衡，显著优于基于帧的方法。

Conclusion: 提出的基于神经形态传感器的实时框架显著提升了流动状态分类的准确性和速度，适用于智能热管理。

Abstract: Flow boiling is an efficient heat transfer mechanism capable of dissipating
high heat loads with minimal temperature variation, making it an ideal thermal
management method. However, sudden shifts between flow regimes can disrupt
thermal performance and system reliability, highlighting the need for accurate
and low-latency real-time monitoring. Conventional optical imaging methods are
limited by high computational demands and insufficient temporal resolution,
making them inadequate for capturing transient flow behavior. To address this,
we propose a real-time framework based on signals from neuromorphic sensors for
flow regime classification. Neuromorphic sensors detect changes in brightness
at individual pixels, which typically correspond to motion at edges, enabling
fast and efficient detection without full-frame reconstruction, providing
event-based information. We develop five classification models using both
traditional image data and event-based data, demonstrating that models
leveraging event data outperform frame-based approaches due to their
sensitivity to dynamic flow features. Among these models, the event-based long
short-term memory model provides the best balance between accuracy and speed,
achieving 97.6% classification accuracy with a processing time of 0.28 ms. Our
asynchronous processing pipeline supports continuous, low-latency predictions
and delivers stable output through a majority voting mechanisms, enabling
reliable real-time feedback for experimental control and intelligent thermal
management.

</details>


### [47] [Semantic-Guided Natural Language and Visual Fusion for Cross-Modal Interaction Based on Tiny Object Detection](https://arxiv.org/abs/2511.05474)
*Xian-Hong Huang,Hui-Kai Su,Chi-Chia Sun,Jun-Wei Hsieh*

Main category: cs.CV

TL;DR: 本研究提出了一种结合自然语言处理和先进视觉模型的新方法，显著提高了小型物体检测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 提出一种前沿的跨模态交互方法，通过语义引导的自然语言处理和先进的视觉识别反向，提升小型物体检测精度。

Method: 结合BERT语言模型与基于CNN的PRB-FPN-Net模型，并引入ELAN、MSP和CSP等创新骨干架构以优化特征提取与融合。

Result: 在COCO2017验证集中，模型获得52.6%的平均精度（AP），显著优于YOLO-World，并且参数消耗仅为GLIP等基于Transformer模型的一半。

Conclusion: 本研究表明，通过将自然语言理解与先进的骨干架构相结合，显著提高了小型物体检测的准确性和效率，并在现实世界挑战中展现了适应性。

Abstract: This paper introduces a cutting-edge approach to cross-modal interaction for
tiny object detection by combining semantic-guided natural language processing
with advanced visual recognition backbones. The proposed method integrates the
BERT language model with the CNN-based Parallel Residual Bi-Fusion Feature
Pyramid Network (PRB-FPN-Net), incorporating innovative backbone architectures
such as ELAN, MSP, and CSP to optimize feature extraction and fusion. By
employing lemmatization and fine-tuning techniques, the system aligns semantic
cues from textual inputs with visual features, enhancing detection precision
for small and complex objects. Experimental validation using the COCO and
Objects365 datasets demonstrates that the model achieves superior performance.
On the COCO2017 validation set, it attains a 52.6% average precision (AP),
outperforming YOLO-World significantly while maintaining half the parameter
consumption of Transformer-based models like GLIP. Several test on different of
backbones such ELAN, MSP, and CSP further enable efficient handling of
multi-scale objects, ensuring scalability and robustness in
resource-constrained environments. This study underscores the potential of
integrating natural language understanding with advanced backbone
architectures, setting new benchmarks in object detection accuracy, efficiency,
and adaptability to real-world challenges.

</details>


### [48] [TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning](https://arxiv.org/abs/2511.05489)
*Junwen Pan,Qizhe Zhang,Rui Zhang,Ming Lu,Xin Wan,Yuan Zhang,Chang Liu,Qi She*

Main category: cs.CV

TL;DR: 本文提出了TimeSearch-R，通过强化学习改进时间搜索策略，显著提升长视频理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的时间搜索方法依赖手工设计的搜索流程，缺乏端到端优化，导致探索不足与逻辑推理不一致。

Method: 通过强化学习将时间搜索重新定义为交错的文本-视频思考，结合GRPO-CSV方法改进视频推理的完整性。

Result: TimeSearch-R在多个基准上取得显著进展，并在LongVideoBench上实现了新的最先进水平，超越了多个竞争模型。

Conclusion: TimeSearch-R在时间搜索基准上显著提升，并在长视频理解基准上设立了新的最先进成果。

Abstract: Temporal search aims to identify a minimal set of relevant frames from tens
of thousands based on a given query, serving as a foundation for accurate
long-form video understanding. Existing works attempt to progressively narrow
the search space. However, these approaches typically rely on a hand-crafted
search process, lacking end-to-end optimization for learning optimal search
strategies. In this paper, we propose TimeSearch-R, which reformulates temporal
search as interleaved text-video thinking, seamlessly integrating searching
video clips into the reasoning process through reinforcement learning (RL).
However, applying RL training methods, such as Group Relative Policy
Optimization (GRPO), to video reasoning can result in unsupervised intermediate
search decisions. This leads to insufficient exploration of the video content
and inconsistent logical reasoning. To address these issues, we introduce GRPO
with Completeness Self-Verification (GRPO-CSV), which gathers searched video
frames from the interleaved reasoning process and utilizes the same policy
model to verify the adequacy of searched frames, thereby improving the
completeness of video reasoning. Additionally, we construct datasets
specifically designed for the SFT cold-start and RL training of GRPO-CSV,
filtering out samples with weak temporal dependencies to enhance task
difficulty and improve temporal search capabilities. Extensive experiments
demonstrate that TimeSearch-R achieves significant improvements on temporal
search benchmarks such as Haystack-LVBench and Haystack-Ego4D, as well as
long-form video understanding benchmarks like VideoMME and MLVU. Notably,
TimeSearch-R establishes a new state-of-the-art on LongVideoBench with 4.1%
improvement over the base model Qwen2.5-VL and 2.0% over the advanced video
reasoning model Video-R1. Our code is available at
https://github.com/Time-Search/TimeSearch-R.

</details>


### [49] [Visual Spatial Tuning](https://arxiv.org/abs/2511.05491)
*Rui Yang,Ziyu Zhu,Yanwei Li,Jingjia Huang,Shen Yan,Siyuan Zhou,Zhe Liu,Xiangtai Li,Shuangye Li,Wenqian Wang,Yi Lin,Hengshuang Zhao*

Main category: cs.CV

TL;DR: 通过引入视觉空间调优框架，研究者有效提升了视觉语言模型的空间感知和推理能力，且未对通用性能产生负面影响。


<details>
  <summary>Details</summary>
Motivation: 旨在增强视觉语言模型的空间意识，克服现有方法对模型通用能力的负面影响。

Method: 通过构建两个数据集（VST-P和VST-R），采用逐步训练的方式，包括监督微调和强化学习，来提升模型的空间知识和推理能力。

Result: VST成功地提升了视觉语言模型在空间基准测试上的表现，分别取得了$34.8\%$和$61.2\%$的成绩。此外，模型的整体性能未受影响，表明该方法的有效性。

Conclusion: 本研究提出的视觉空间调优框架能够有效提升视觉语言模型的空间感知和推理能力，并在多个基准测试中取得了先进的结果。

Abstract: Capturing spatial relationships from visual inputs is a cornerstone of
human-like general intelligence. Several previous studies have tried to enhance
the spatial awareness of Vision-Language Models (VLMs) by adding extra expert
encoders, which brings extra overhead and usually harms general capabilities.
To enhance the spatial ability in general architectures, we introduce Visual
Spatial Tuning (VST), a comprehensive framework to cultivate VLMs with
human-like visuospatial abilities, from spatial perception to reasoning. We
first attempt to enhance spatial perception in VLMs by constructing a
large-scale dataset termed VST-P, which comprises 4.1 million samples spanning
19 skills across single views, multiple images, and videos. Then, we present
VST-R, a curated dataset with 135K samples that instruct models to reason in
space. In particular, we adopt a progressive training pipeline: supervised
fine-tuning to build foundational spatial knowledge, followed by reinforcement
learning to further improve spatial reasoning abilities. Without the
side-effect to general capabilities, the proposed VST consistently achieves
state-of-the-art results on several spatial benchmarks, including $34.8\%$ on
MMSI-Bench and $61.2\%$ on VSIBench. It turns out that the
Vision-Language-Action models can be significantly enhanced with the proposed
spatial tuning paradigm, paving the way for more physically grounded AI.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [50] [Evaluating LLMs' Reasoning Over Ordered Procedural Steps](https://arxiv.org/abs/2511.04688)
*Adrita Anika,Md Messal Monem Miah*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型在重构程序序列顺序时的能力，发现随着序列长度增大和步骤打乱，模型性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 解决程序步骤的顺序重构问题，因为步骤顺序直接影响结果，且在某些任务如食谱中至关重要。

Method: 通过对食谱这一领域的程序步骤进行零-shot和少量训练的实验，使用了Kendall's Tau、标准化最长公共子序列（NLCS）和标准化编辑距离（NED）等评估指标进行全面评估。

Result: 评估表明，随着序列长度的增加，模型表现下降，且输入的步变位越大，性能进一步恶化。

Conclusion: 当前的大型语言模型在处理更长和更无序的程序序列时存在局限性，表现随着序列长度的增加和输入的严重打乱而下降。

Abstract: Reasoning over procedural sequences, where the order of steps directly
impacts outcomes, is a critical capability for large language models (LLMs). In
this work, we study the task of reconstructing globally ordered sequences from
shuffled procedural steps, using a curated dataset of food recipes, a domain
where correct sequencing is essential for task success. We evaluate several
LLMs under zero-shot and few-shot settings and present a comprehensive
evaluation framework that adapts established metrics from ranking and sequence
alignment. These include Kendall's Tau, Normalized Longest Common Subsequence
(NLCS), and Normalized Edit Distance (NED), which capture complementary aspects
of ordering quality. Our analysis shows that model performance declines with
increasing sequence length, reflecting the added complexity of longer
procedures. We also find that greater step displacement in the input,
corresponding to more severe shuffling, leads to further degradation. These
findings highlight the limitations of current LLMs in procedural reasoning,
especially with longer and more disordered inputs.

</details>


### [51] [Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks](https://arxiv.org/abs/2511.04689)
*Peiyu Li,Xiuxiu Tang,Si Chen,Ying Cheng,Ronald Metoyer,Ting Hua,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: ATLAS是一个新的自适应测试框架，利用IRT显著降低了大语言模型评估的项目数量，同时保持评估准确性，发现固定评估中的错误项目。


<details>
  <summary>Details</summary>
Motivation: 传统的评估方法依赖于固定的项目集，效率低且结果受项目质量影响，ATLAS旨在优化评估过程，降低评估成本。

Method: 采用Item Response Theory (IRT) 结合Fisher信息引导的项目选择，进行模型能力的估计。

Result: 通过使用ATLAS，仅需42个项目就能在HellaSwag基准上达到与完整基准相似的估计精度，并降低了项目的暴露率和测试重叠率。

Conclusion: ATLAS框架通过动态选择测试项目有效提高了语言模型评估的效率和准确性，显著减少了所需测试项目数量，同时保持了测量精准度。

Abstract: Large language model evaluation requires thousands of benchmark items, making
evaluations expensive and slow. Existing methods compute average accuracy
across fixed item sets, treating all items equally despite varying quality and
informativeness. We present ATLAS an adaptive testing framework using Item
Response Theory (IRT) to estimate model ability through Fisher
information-guided item selection. Our analysis of five major benchmarks
reveals that 3-6% of items exhibit negative discrimination, indicating
annotation errors that corrupt static evaluation. ATLAS achieves 90% item
reduction while maintaining measurement precision: on HellaSwag (5,608 items),
we match full-benchmark estimates using only 42 items with 0.154 MAE. Our
framework maintains item exposure rates below 10% and test overlap at 16-27%,
compared to static benchmarks where every model sees all items (100% exposure).
Among 4,000+ tested models, IRT ranks differ from accuracy ranks: models with
the same accuracy get different IRT scores, and 23-31% of all models shift by
more than 10 rank positions. Code and calibrated item banks are available at
https://github.com/Peiyu-Georgia-Li/ATLAS.git.

</details>


### [52] [SARC: Sentiment-Augmented Deep Role Clustering for Fake News Detection](https://arxiv.org/abs/2511.04692)
*Jingqing Wang,Jiaxing Shang,Rong Xu,Fei Hao,Tianjin Huang,Geyong Min*

Main category: cs.CL

TL;DR: SARC是一种通过情感增强角色聚类提高假新闻检测性能的框架，实验结果表明其效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了用户角色的差异性，限制了假新闻检测的效果。因此提出了SARC框架。

Method: 采用情感增强的深度聚类，生成用户特征，通过联合优化假新闻检测和角色聚类。

Result: 在RumourEval-19和Weibo-comp数据集上的实验结果显示，SARC在所有指标上均优于基线模型。

Conclusion: SARC框架通过角色聚类增强假新闻检测的性能，实验结果表明其在各项指标上均优于基线模型。

Abstract: Fake news detection has been a long-standing research focus in social
networks. Recent studies suggest that incorporating sentiment information from
both news content and user comments can enhance detection performance. However,
existing approaches typically treat sentiment features as auxiliary signals,
overlooking role differentiation, that is, the same sentiment polarity may
originate from users with distinct roles, thereby limiting their ability to
capture nuanced patterns for effective detection. To address this issue, we
propose SARC, a Sentiment-Augmented Role Clustering framework which utilizes
sentiment-enhanced deep clustering to identify user roles for improved fake
news detection. The framework first generates user features through joint
comment text representation (with BiGRU and Attention mechanism) and sentiment
encoding. It then constructs a differentiable deep clustering module to
automatically categorize user roles. Finally, unlike existing approaches which
take fake news label as the unique supervision signal, we propose a joint
optimization objective integrating role clustering and fake news detection to
further improve the model performance. Experimental results on two benchmark
datasets, RumourEval-19 and Weibo-comp, demonstrate that SARC achieves superior
performance across all metrics compared to baseline models. The code is
available at: https://github.com/jxshang/SARC.

</details>


### [53] [Reasoning Up the Instruction Ladder for Controllable Language Models](https://arxiv.org/abs/2511.04694)
*Zishuo Zheng,Vidhisha Balachandran,Chan Young Park,Faeze Brahman,Sachin Kumar*

Main category: cs.CL

TL;DR: 本研究提出了一种将指令层级解决视为推理任务的方法，通过构建VerIH数据集并应用强化学习，显著提升了大型语言模型在指令遵循和安全性方面的表现。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在现实世界决策中的应用日益增加，迫切需要确保其能够有效处理来自不同来源的竞争指令。

Method: 构建VerIH数据集，使用轻量级强化学习训练模型，以实现指令层级的推理。

Result: 微调后的模型在指令遵循和指令层级基准测试中表现一致改进，并且该推理能力在安全关键环境中也能够推广。

Conclusion: 本研究表明，对指令层级的推理可以为可靠的大型语言模型提供切实可行的路径，使系统提示的更新能有效控制和增强模型行为的鲁棒性。

Abstract: As large language model (LLM) based systems take on high-stakes roles in
real-world decision-making, they must reconcile competing instructions from
multiple sources (e.g., model developers, users, and tools) within a single
prompt context. Thus, enforcing an instruction hierarchy (IH) in LLMs, where
higher-level directives override lower-priority requests, is critical for the
reliability and controllability of LLMs. In this work, we reframe instruction
hierarchy resolution as a reasoning task. Specifically, the model must first
"think" about the relationship between a given user prompt and higher-priority
(system) instructions before generating a response. To enable this capability
via training, we construct VerIH, an instruction hierarchy dataset of
constraint-following tasks with verifiable answers. This dataset comprises both
aligned and conflicting system-user instructions. We show that lightweight
reinforcement learning with VerIH effectively transfers general reasoning
capabilities of models to instruction prioritization. Our finetuned models
achieve consistent improvements on instruction following and instruction
hierarchy benchmarks. This reasoning ability also generalizes to
safety-critical settings beyond the training distribution. By treating safety
issues as resolving conflicts between adversarial user inputs and predefined
higher-priority policies, our trained model enhances robustness against
jailbreak and prompt injection attacks. These results demonstrate that
reasoning over instruction hierarchies provides a practical path to reliable
LLMs, where updates to system prompts yield controllable and robust changes in
model behavior.

</details>


### [54] [EncouRAGe: Evaluating RAG Local, Fast, and Reliable](https://arxiv.org/abs/2511.04696)
*Jan Strich,Adeline Scharfenberg,Chris Biemann,Martin Semmann*

Main category: cs.CL

TL;DR: 本文介绍了EncouRAGe框架，旨在提升RAG系统的开发与评估，评估表明RAG的表现仍逊色于Oracle Context，而Hybrid BM25表现最佳。


<details>
  <summary>Details</summary>
Motivation: 旨在简化使用大语言模型和嵌入模型的RAG系统的开发和评估过程，强调科学可重复性和多样化的评估指标。

Method: 开发了EncouRAGe，一个模块化的框架，通过实验和评估促进RAG系统的研发，并提供了详细的实现和评估。

Result: 在多个基准数据集（包括25k QA对和超过51k文档）的广泛评估中，展示了EncouRAGe的效果。

Conclusion: RAG系统在与Oracle Context的比较中表现仍然较差，但Hybrid BM25在所有数据集上都取得了最佳结果，重排效果带来了仅限的性能改善，同时增加了响应延迟。

Abstract: We introduce EncouRAGe, a comprehensive Python framework designed to
streamline the development and evaluation of Retrieval-Augmented Generation
(RAG) systems using Large Language Models (LLMs) and Embedding Models.
EncouRAGe comprises five modular and extensible components: Type Manifest, RAG
Factory, Inference, Vector Store, and Metrics, facilitating flexible
experimentation and extensible development. The framework emphasizes scientific
reproducibility, diverse evaluation metrics, and local deployment, enabling
researchers to efficiently assess datasets within RAG workflows. This paper
presents implementation details and an extensive evaluation across multiple
benchmark datasets, including 25k QA pairs and over 51k documents. Our results
show that RAG still underperforms compared to the Oracle Context, while Hybrid
BM25 consistently achieves the best results across all four datasets. We
further examine the effects of reranking, observing only marginal performance
improvements accompanied by higher response latency.

</details>


### [55] [multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder](https://arxiv.org/abs/2511.04698)
*K M Sajjadul Islam,John Fields,Praveen Madiraju*

Main category: cs.CL

TL;DR: 本研究提出了multiMentalRoBERTa模型，用于社交媒体文本中多类别心理健康状况的检测，展现了优越的分类性能和可解释性，强化了心理健康支持。


<details>
  <summary>Details</summary>
Motivation: 社交媒体文本中对心理健康障碍的早期检测对及时支持、风险评估以及转介至适当资源至关重要。

Method: 使用多类别分类的微调RoBERTa模型进行心理健康状况的检测。

Result: 在六类设置中，macro F1分数达到0.839，在五类设置中（排除压力）达到0.870，优于其他基线分类器。

Conclusion: multiMentalRoBERTa是一个轻量级、稳健且可部署的解决方案，用于改善心理健康平台的支持。

Abstract: The early detection of mental health disorders from social media text is
critical for enabling timely support, risk assessment, and referral to
appropriate resources. This work introduces multiMentalRoBERTa, a fine-tuned
RoBERTa model designed for multiclass classification of common mental health
conditions, including stress, anxiety, depression, post-traumatic stress
disorder (PTSD), suicidal ideation, and neutral discourse. Drawing on multiple
curated datasets, data exploration is conducted to analyze class overlaps,
revealing strong correlations between depression and suicidal ideation as well
as anxiety and PTSD, while stress emerges as a broad, overlapping category.
Comparative experiments with traditional machine learning methods,
domain-specific transformers, and prompting-based large language models
demonstrate that multiMentalRoBERTa achieves superior performance, with macro
F1-scores of 0.839 in the six-class setup and 0.870 in the five-class setup
(excluding stress), outperforming both fine-tuned MentalBERT and baseline
classifiers. Beyond predictive accuracy, explainability methods, including
Layer Integrated Gradients and KeyBERT, are applied to identify lexical cues
that drive classification, with a particular focus on distinguishing depression
from suicidal ideation. The findings emphasize the effectiveness of fine-tuned
transformers for reliable and interpretable detection in sensitive contexts,
while also underscoring the importance of fairness, bias mitigation, and
human-in-the-loop safety protocols. Overall, multiMentalRoBERTa is presented as
a lightweight, robust, and deployable solution for enhancing support in mental
health platforms.

</details>


### [56] [Cross-Lingual SynthDocs: A Large-Scale Synthetic Corpus for Any to Arabic OCR and Document Understanding](https://arxiv.org/abs/2511.04699)
*Haneen Al-Homoud,Asma Ibrahim,Murtadha Al-Jubran,Fahad Al-Otaibi,Yazeed Al-Harbi,Daulet Toibazar,Kesen Wang,Pedro J. Moreno*

Main category: cs.CL

TL;DR: Cross-Lingual SynthDocs是一个针对阿拉伯语OCR和文档理解的合成数据集，包含超过250万样本，微调模型后在多个基准测试中显著提高了错误率和提取精度。


<details>
  <summary>Details</summary>
Motivation: 针对阿拉伯语在光学字符识别和文档理解方面资源稀缺的问题。

Method: 通过利用真实扫描背景、双语布局和考虑到分音符的字体来创建合成语料库。

Result: 在多个阿拉伯公开基准上，通过对Qwen-2.5-VL的微调，Word Error Rate和Character Error Rate都有显著改善，同时Tree-Edit Distance Similarity和Chart Extraction Score也有所提高。

Conclusion: SynthDocs为多语言文档分析研究提供了一个可扩展且视觉真实的资源。

Abstract: Cross-Lingual SynthDocs is a large-scale synthetic corpus designed to address
the scarcity of Arabic resources for Optical Character Recognition (OCR) and
Document Understanding (DU). The dataset comprises over 2.5 million of samples,
including 1.5 million textual data, 270K fully annotated tables, and hundred
thousands of real data based charts. Our pipeline leverages authentic scanned
backgrounds, bilingual layouts, and diacritic aware fonts to capture the
typographic and structural complexity of Arabic documents. In addition to text,
the corpus includes variety of rendered styles for charts and tables.
Finetuning Qwen-2.5-VL on SynthDocs yields consistent improvements in Word
Error Rate (WER) and Character Error Rate (CER) in terms of OCR across multiple
public Arabic benchmarks, Tree-Edit Distance Similarity (TEDS) and Chart
Extraction Score (CharTeX) improved as well in other modalities. SynthDocs
provides a scalable, visually realistic resource for advancing research in
multilingual document analysis.

</details>


### [57] [Measuring what Matters: Construct Validity in Large Language Model Benchmarks](https://arxiv.org/abs/2511.04703)
*Andrew M. Bean,Ryan Othniel Kearns,Angelika Romanou,Franziska Sofia Hafner,Harry Mayne,Jan Batzner,Negar Foroutan,Chris Schmitz,Karolina Korgul,Hunar Batra,Oishi Deb,Emma Beharry,Cornelius Emde,Thomas Foster,Anna Gausen,María Grandury,Simeng Han,Valentin Hofmann,Lujain Ibrahim,Hazel Kim,Hannah Rose Kirk,Fangru Lin,Gabrielle Kaili-May Liu,Lennart Luettgau,Jabez Magomere,Jonathan Rystrøm,Anna Sotnikova,Yushi Yang,Yilun Zhao,Adel Bibi,Antoine Bosselut,Ronald Clark,Arman Cohan,Jakob Foerster,Yarin Gal,Scott A. Hale,Inioluwa Deborah Raji,Christopher Summerfield,Philip H. S. Torr,Cozmin Ududec,Luc Rocher,Adam Mahdi*

Main category: cs.CL

TL;DR: 本研究系统评审了445个LLM基准，发现效度问题并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型对其能力、安全性和稳健性进行可靠测量的必要性。

Method: 通过系统评审445个LLM基准，与29名专家评审团队合作，分析数据并识别模式。

Result: 识别了影响效度问题的现象、任务和评分标准，并提出了八项关键建议和操作指导。

Conclusion: 研究发现当前大型语言模型基准的有效性受到多种因素的影响，并提出了改进建议。

Abstract: Evaluating large language models (LLMs) is crucial for both assessing their
capabilities and identifying safety or robustness issues prior to deployment.
Reliably measuring abstract and complex phenomena such as 'safety' and
'robustness' requires strong construct validity, that is, having measures that
represent what matters to the phenomenon. With a team of 29 expert reviewers,
we conduct a systematic review of 445 LLM benchmarks from leading conferences
in natural language processing and machine learning. Across the reviewed
articles, we find patterns related to the measured phenomena, tasks, and
scoring metrics which undermine the validity of the resulting claims. To
address these shortcomings, we provide eight key recommendations and detailed
actionable guidance to researchers and practitioners in developing LLM
benchmarks.

</details>


### [58] [GEMMA-SQL: A Novel Text-to-SQL Model Based on Large Language Models](https://arxiv.org/abs/2511.04710)
*Hari Mohan Pandey,Anshul Gupta,Subham Sarkar,Minakshi Tomer,Schneider Johannes,Yan Gong*

Main category: cs.CL

TL;DR: GEMMA-SQL是一个高效的文本到SQL模型，通过先进的提示设计和指令调整，实现了与较大模型相比的高准确率，适合低成本硬件部署。


<details>
  <summary>Details</summary>
Motivation: 为了使用户能够使用自然语言与结构化数据库互动，降低对专业编程知识的需求。

Method: 采用轻量级的GEMMA 2B架构，并基于SPIDER基准进行训练和评估，结合多种提示策略和少量学习。

Result: GEMMA-SQL Instruct在测试套件上达到了66.8%的准确率，并在Exact Set Match准确率上达到了63.3%，超越多个先进的基线模型。

Conclusion: GEMMA-SQL被确立为一种实用的开源文本到SQL系统，展现出强劲的准确性和灵活性。

Abstract: Text-to-SQL systems enable users to interact with structured databases using
natural language, eliminating the need for specialized programming knowledge.
In this work, we introduce GEMMA-SQL, a lightweight and efficient text-to-SQL
model built upon the open-source Gemma 2B architecture. Unlike many large
language models (LLMs), GEMMA-SQL is fine-tuned in a resource-efficient,
iterative manner and can be deployed on low-cost hardware. Leveraging the
SPIDER benchmark for training and evaluation, GEMMA-SQL combines multiple
prompting strategies, including few-shot learning, to enhance SQL query
generation accuracy. The instruction-tuned variant, GEMMA-SQL Instruct,
achieves 66.8% Test-Suite accuracy and 63.3% Exact Set Match accuracy,
outperforming several state-of-the-art baselines such as IRNet, RYANSQL, and
CodeXDavinci. The proposed approach demonstrates that effective prompt design
and targeted instruction tuning can significantly boost performance while
maintaining high scalability and adaptability. These results position GEMMA-SQL
as a practical, open-source alternative for robust and accessible text-to-SQL
systems.

</details>


### [59] [First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation](https://arxiv.org/abs/2511.04715)
*Dmytro Vitel,Anshuman Chhabra*

Main category: cs.CL

TL;DR: 本研究提出中间注意力层在大语言模型的影响力估计中更为可靠，并探讨了影响力得分的聚合和评估新方法。


<details>
  <summary>Details</summary>
Motivation: 理解训练样本如何影响大语言模型的决策，对有效解释模型的决策及审计大规模数据集至关重要。

Method: 提出理论和实证证据，挑战先前的取消效应假设，并探讨不同层的影响力得分聚合方法。

Result: 通过实验证明中间层在影响力估计中的重要性，并引入了一种新的评价指标NDR，显示出强预测能力。

Conclusion: 中间注意力层是评估大语言模型影响力的更佳估计者，而不必依赖于传统的嵌入层。

Abstract: Identifying how training samples influence/impact Large Language Model (LLM)
decision-making is essential for effectively interpreting model decisions and
auditing large-scale datasets. Current training sample influence estimation
methods (also known as influence functions) undertake this goal by utilizing
information flow through the model via its first-order and higher-order
gradient terms. However, owing to the large model sizes of today consisting of
billions of parameters, these influence computations are often restricted to
some subset of model layers to ensure computational feasibility. Prior seminal
work by Yeh et al. (2022) in assessing which layers are best suited for
computing language data influence concluded that the first (embedding) layers
are the most informative for this purpose, using a hypothesis based on
influence scores canceling out (i.e., the cancellation effect). In this work,
we propose theoretical and empirical evidence demonstrating how the
cancellation effect is unreliable, and that middle attention layers are better
estimators for influence. Furthermore, we address the broader challenge of
aggregating influence scores across layers, and showcase how alternatives to
standard averaging (such as ranking and vote-based methods) can lead to
significantly improved performance. Finally, we propose better methods for
evaluating influence score efficacy in LLMs without undertaking model
retraining, and propose a new metric known as the Noise Detection Rate (NDR)
that exhibits strong predictive capability compared to the cancellation effect.
Through extensive experiments across LLMs of varying types and scales, we
concretely determine that the first (layers) are not necessarily better than
the last (layers) for LLM influence estimation, contrasting with prior
knowledge in the field.

</details>


### [60] [Learning to reason about rare diseases through retrieval-augmented agents](https://arxiv.org/abs/2511.04720)
*Ha Young Kim,Jun Li,Ana Beatriz Solana,Carolin M. Pirkl,Benedikt Wiestler,Julia A. Schnabel,Cosmin I. Bercea*

Main category: cs.CL

TL;DR: RADAR通过检索临床相关证据，在脑部MRI中的稀有疾病检测上显著提高了模型的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 稀有疾病在医学影像中数据稀缺，传统AI模型难以有效识别，因此需要通过辅助资源来提高诊断能力。

Method: 通过使用句子变换器和FAISS对病例报告和文献进行嵌入和索引，实现在稀有疾病检测中的相似性搜索。

Result: 在NOVA数据集上，RADAR系统对包含280种稀有疾病的识别性能提升达10.2%，特别是开源模型的表现显著改善。

Conclusion: RADAR系统在脑部MRI中对稀有疾病检测表现出色，提升了模型的认知能力与可解释性。

Abstract: Rare diseases represent the long tail of medical imaging, where AI models
often fail due to the scarcity of representative training data. In clinical
workflows, radiologists frequently consult case reports and literature when
confronted with unfamiliar findings. Following this line of reasoning, we
introduce RADAR, Retrieval Augmented Diagnostic Reasoning Agents, an agentic
system for rare disease detection in brain MRI. Our approach uses AI agents
with access to external medical knowledge by embedding both case reports and
literature using sentence transformers and indexing them with FAISS to enable
efficient similarity search. The agent retrieves clinically relevant evidence
to guide diagnostic decision making on unseen diseases, without the need of
additional training. Designed as a model-agnostic reasoning module, RADAR can
be seamlessly integrated with diverse large language models, consistently
improving their rare pathology recognition and interpretability. On the NOVA
dataset comprising 280 distinct rare diseases, RADAR achieves up to a 10.2%
performance gain, with the strongest improvements observed for open source
models such as DeepSeek. Beyond accuracy, the retrieved examples provide
interpretable, literature grounded explanations, highlighting
retrieval-augmented reasoning as a powerful paradigm for low-prevalence
conditions in medical imaging.

</details>


### [61] [Surprisal reveals diversity gaps in image captioning and different scorers change the story](https://arxiv.org/abs/2511.04754)
*Nikolai Ilinykh,Simon Dobnik*

Main category: cs.CL

TL;DR: 通过惊讶度方差量化图像字幕的语言多样性，发现人类和模型在表现上的显著差异，并强调多评分器下的稳健评估重要性。


<details>
  <summary>Details</summary>
Motivation: 旨在量化图像字幕中的语言多样性，以促进对决策过程的理解并提高模型的表现。

Method: 使用惊讶度方差量化图像字幕的语言多样性，通过比较人类字幕与五种最先进的视觉-语言模型在MSCOCO测试集的表现。

Result: 人类的惊讶度方差大约是模型的两倍，但使用通用语言模型重新评分同一字幕会逆转这一模式。

Conclusion: 依赖单一评分器可能完全颠倒结论，因此稳健的多样性评估必须在多个评分器下报告惊讶度。

Abstract: We quantify linguistic diversity in image captioning with surprisal variance
- the spread of token-level negative log-probabilities within a caption set. On
the MSCOCO test set, we compare five state-of-the-art vision-and-language LLMs,
decoded with greedy and nucleus sampling, to human captions. Measured with a
caption-trained n-gram LM, humans display roughly twice the surprisal variance
of models, but rescoring the same captions with a general-language model
reverses the pattern. Our analysis introduces the surprisal-based diversity
metric for image captioning. We show that relying on a single scorer can
completely invert conclusions, thus, robust diversity evaluation must report
surprisal under several scorers.

</details>


### [62] [Explore Data Left Behind in Reinforcement Learning for Reasoning Language Models](https://arxiv.org/abs/2511.04800)
*Chenxi Liu,Junjie Liang,Yuqi Jia,Bochuan Cao,Yang Bai,Heng Huang,Xun Chen*

Main category: cs.CL

TL;DR: ERPO框架有效利用残余提示，增强了大语言模型的推理能力，表现优于多项基线。


<details>
  <summary>Details</summary>
Motivation: 面对随着训练时间延长和模型规模增大而增加的残余提示现象，ERPO旨在重新激活这些提示的训练信号，从而提高模型的推理能力。

Method: 提出ERPO框架，维护提示历史追踪器，并适应性地增加残余提示的采样温度，以促进多样化推理轨迹生成。

Result: 在Qwen2.5系列上的实证结果表明，ERPO在多个数学推理基准上 consistently 超越了强基线。

Conclusion: ERPO框架通过鼓励探索残余提示，有效提升了大语言模型的训练效果，增强了推理能力。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an
effective approach for improving the reasoning abilities of large language
models (LLMs). The Group Relative Policy Optimization (GRPO) family has
demonstrated strong performance in training LLMs with RLVR. However, as models
train longer and scale larger, more training prompts become residual prompts,
those with zero variance rewards that provide no training signal. Consequently,
fewer prompts contribute to training, reducing diversity and hindering
effectiveness. To fully exploit these residual prompts, we propose the Explore
Residual Prompts in Policy Optimization (ERPO) framework, which encourages
exploration on residual prompts and reactivates their training signals. ERPO
maintains a history tracker for each prompt and adaptively increases the
sampling temperature for residual prompts that previously produced all correct
responses. This encourages the model to generate more diverse reasoning traces,
introducing incorrect responses that revive training signals. Empirical results
on the Qwen2.5 series demonstrate that ERPO consistently surpasses strong
baselines across multiple mathematical reasoning benchmarks.

</details>


### [63] [Trained on Tokens, Calibrated on Concepts: The Emergence of Semantic Calibration in LLMs](https://arxiv.org/abs/2511.04869)
*Preetum Nakkiran,Arwen Bradley,Adam Goliński,Eugene Ndiaye,Michael Kirchhof,Sinead Williamson*

Main category: cs.CL

TL;DR: 研究表明基础大语言模型能够在问答任务中有效评估语义置信度，并揭示了语义校准的理论机制。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型的输出置信度估计能力以及语义校准的机制。

Method: 基于采样的语义校准方法，以及通过实验验证三个主要预测。

Result: 发现基础大语言模型在开放领域问答任务中能够有效地进行语义校准。

Conclusion: 本研究首次系统性解释了为何和何时大语言模型中的语义校准会出现。

Abstract: Large Language Models (LLMs) often lack meaningful confidence estimates for
their outputs. While base LLMs are known to exhibit next-token calibration, it
remains unclear whether they can assess confidence in the actual meaning of
their responses beyond the token level. We find that, when using a certain
sampling-based notion of semantic calibration, base LLMs are remarkably
well-calibrated: they can meaningfully assess confidence in open-domain
question-answering tasks, despite not being explicitly trained to do so. Our
main theoretical contribution establishes a mechanism for why semantic
calibration emerges as a byproduct of next-token prediction, leveraging a
recent connection between calibration and local loss optimality. The theory
relies on a general definition of "B-calibration," which is a notion of
calibration parameterized by a choice of equivalence classes (semantic or
otherwise). This theoretical mechanism leads to a testable prediction: base
LLMs will be semantically calibrated when they can easily predict their own
distribution over semantic answer classes before generating a response. We
state three implications of this prediction, which we validate through
experiments: (1) Base LLMs are semantically calibrated across
question-answering tasks, (2) RL instruction-tuning systematically breaks this
calibration, and (3) chain-of-thought reasoning breaks calibration. To our
knowledge, our work provides the first principled explanation of when and why
semantic calibration emerges in LLMs.

</details>


### [64] [Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs](https://arxiv.org/abs/2511.04875)
*Matthew Bozoukov,Matthew Nguyen,Shubkarman Singh,Bart Bussmann,Patrick Leask*

Main category: cs.CL

TL;DR: 通过低秩适配器对LLMs进行微调实验，发现行为自我意识是一种特定领域的线性特征，能够通过简单的手段诱发。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解和表征LLMs的行为自我意识以及其出现的最小条件和机制。

Method: 通过对低秩适配器（LoRA）进行控制的微调实验，分析LLMs的行为自我意识。

Result: 发现自我意识可以通过单个秩为1的LoRA适配器可靠诱导，并且该自我意识行为几乎可以通过单个激活空间中的引导向量完全捕获。

Conclusion: 行为自我意识是一种特定领域的线性特征，可以通过简单的调整轻松诱导和调节。

Abstract: Recent studies have revealed that LLMs can exhibit behavioral self-awareness:
the ability to accurately describe or predict their own learned behaviors
without explicit supervision. This capability raises safety concerns as it may,
for example, allow models to better conceal their true abilities during
evaluation. We attempt to characterize the minimal conditions under which such
self-awareness emerges, and the mechanistic processes through which it
manifests. Through controlled finetuning experiments on instruction-tuned LLMs
with low-rank adapters (LoRA), we find: (1) that self-awareness can be reliably
induced using a single rank-1 LoRA adapter; (2) that the learned self-aware
behavior can be largely captured by a single steering vector in activation
space, recovering nearly all of the fine-tune's behavioral effect; and (3) that
self-awareness is non-universal and domain-localized, with independent
representations across tasks. Together, these findings suggest that behavioral
self-awareness emerges as a domain-specific, linear feature that can be easily
induced and modulated.

</details>


### [65] [SDS KoPub VDR: A Benchmark Dataset for Visual Document Retrieval in Korean Public Documents](https://arxiv.org/abs/2511.04910)
*Jaehoon Lee,Sohyun Kim,Wanggeun Park,Geon Lee,Seungkyung Kim,Minyoung Lee*

Main category: cs.CL

TL;DR: 本文介绍了SDS KoPub VDR，一个针对韩国公共文档的全新基准，揭示了多模态检索中存在的性能差距，为复杂文档智能的研究提供了基础。


<details>
  <summary>Details</summary>
Motivation: 当前的文档检索基准缺乏对非英语语言和正式出版物结构复杂性的关注，因此需要建立一个专门针对韩国公共文档的基准。

Method: 构建了一个包含361份真实文档的大型评测基准，利用人类验证的600个查询-页面-答案三元组进行评估。

Result: 通过评估文本和多模态检索任务，发现最新模型在跨模态推理方面存在显著的性能差距，尤其在处理复杂视觉元素时。

Conclusion: SDS KoPub VDR为多模态文档检索提供了一个基础性资源，并揭示了当前模型在复杂情境下的性能差距。

Abstract: Existing benchmarks for visual document retrieval (VDR) largely overlook
non-English languages and the structural complexity of official publications.
To address this critical gap, we introduce SDS KoPub VDR, the first
large-scale, publicly available benchmark for retrieving and understanding
Korean public documents. The benchmark is built upon a corpus of 361 real-world
documents (40,781 pages), including 256 files under the KOGL Type 1 license and
105 from official legal portals, capturing complex visual elements like tables,
charts, and multi-column layouts. To establish a challenging and reliable
evaluation set, we constructed 600 query-page-answer triples. These were
initially generated using multimodal models (e.g., GPT-4o) and subsequently
underwent a rigorous human verification and refinement process to ensure
factual accuracy and contextual relevance. The queries span six major public
domains and are systematically categorized by the reasoning modality required:
text-based, visual-based (e.g., chart interpretation), and cross-modal. We
evaluate SDS KoPub VDR on two complementary tasks that reflect distinct
retrieval paradigms: (1) text-only retrieval, which measures a model's ability
to locate relevant document pages based solely on textual signals, and (2)
multimodal retrieval, which assesses retrieval performance when visual features
(e.g., tables, charts, and layouts) are jointly leveraged alongside text. This
dual-task evaluation reveals substantial performance gaps, particularly in
multimodal scenarios requiring cross-modal reasoning, even for state-of-the-art
models. As a foundational resource, SDS KoPub VDR not only enables rigorous and
fine-grained evaluation across textual and multimodal retrieval tasks but also
provides a clear roadmap for advancing multimodal AI in complex, real-world
document intelligence.

</details>


### [66] [BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing in Language Models](https://arxiv.org/abs/2511.04919)
*Chandra Vamsi Krishna Alla,Harish Naidu Gaddam,Manohar Kommi*

Main category: cs.CL

TL;DR: BudgetMem是一种新型内存增强架构，能够有效处理长文档，显著减少内存消耗，适用于资源有限的环境。


<details>
  <summary>Details</summary>
Motivation: 解决当前长文本处理中的计算和内存限制，以满足对推理能力的日益增长的需求。

Method: 提出了一种新颖的内存增强架构，通过选择性记忆策略和特征基于显著性评分来决定保存哪些信息。

Result: BudgetMem在长文档处理中仅有1.0%的F1得分降级，同时节省了72.4%的内存，相较于基线RAG系统表现出色。

Conclusion: BudgetMem能够在较长文档处理上显著提高性能，并减少内存使用，为长文本处理提供了节省成本的有效方案。

Abstract: Large Language Models (LLMs) face significant computational and memory
constraints when processing long contexts, despite growing demand for
applications requiring reasoning over extensive documents, multi-session
dialogues, and book length texts. While recent advances have extended context
windows to 100K-1M tokens, such approaches incur prohibitive costs for resource
constrained deployments. We propose BudgetMem, a novel memory augmented
architecture that learns what to remember rather than remembering everything.
Our system combines selective memory policies with feature based salience
scoring (entity density, TF-IDF, discourse markers, position bias) to decide
which information merits storage under strict budget constraints. Unlike
existing retrieval augmented generation (RAG) systems that store all chunks,
BudgetMem employs learned gating mechanisms coupled with BM25 sparse retrieval
for efficient information access. Through comprehensive experiments on 700
question answer pairs across short (237 tokens) and long (5K-10K tokens)
documents with Llama-3.2-3B-Instruct, we demonstrate that BudgetMem achieves
remarkable results on long documents: only 1.0% F1 score degradation while
saving 72.4% memory compared to baseline RAG. We validate our approach through
budget sensitivity analysis (testing 7 budget ratios), naive baseline
comparisons, and document length analysis, showing that BudgetMem's benefits
increase with document length. Our work provides a practical pathway for
deploying capable long context systems on modest hardware, democratizing access
to advanced language understanding capabilities.

</details>


### [67] [Diagnosing and Mitigating Semantic Inconsistencies in Wikidata's Classification Hierarchy](https://arxiv.org/abs/2511.04926)
*Shixiong Zhao,Hideaki Takeda*

Main category: cs.CL

TL;DR: 本文提出了一种新的方法，旨在识别和纠正Wikidata中的分类错误，提升知识图谱的一致性和准确性。


<details>
  <summary>Details</summary>
Motivation: Wikidata作为一个开放的知识图谱，虽提供了便利的知识获取方式，但其编辑政策相对宽松，导致了分类的一致性问题，因此需要改进。

Method: 通过应用新开发的验证方法和评估标准，分析Wikidata中的具体领域，以确认分类错误、过于宽泛的子类链接和冗余连接。

Result: 研究证明了所提出的方法能够有效识别Wikidata中的分类问题，并实现用户对任意实体的分类关系的检查。

Conclusion: 本文提出了一种新的验证方法，旨在识别和纠正Wikidata中的分类错误和冗余连接，进而提升知识图谱的准确性和一致性。

Abstract: Wikidata is currently the largest open knowledge graph on the web,
encompassing over 120 million entities. It integrates data from various
domain-specific databases and imports a substantial amount of content from
Wikipedia, while also allowing users to freely edit its content. This openness
has positioned Wikidata as a central resource in knowledge graph research and
has enabled convenient knowledge access for users worldwide. However, its
relatively loose editorial policy has also led to a degree of taxonomic
inconsistency. Building on prior work, this study proposes and applies a novel
validation method to confirm the presence of classification errors,
over-generalized subclass links, and redundant connections in specific domains
of Wikidata. We further introduce a new evaluation criterion for determining
whether such issues warrant correction and develop a system that allows users
to inspect the taxonomic relationships of arbitrary Wikidata
entities-leveraging the platform's crowdsourced nature to its full potential.

</details>


### [68] [LoPT: Lossless Parallel Tokenization Acceleration for Long Context Inference of Large Language Model](https://arxiv.org/abs/2511.04952)
*Wei Shao,Lingchao Zheng,Pengyu Wang,Peizhen Zheng,Jun Li,Yuwei Fan*

Main category: cs.CL

TL;DR: 提出了一种新的无损并行标记化框架LoPT，能够加速长文本标记化并确保结果的一致性。


<details>
  <summary>Details</summary>
Motivation: 长文本推理场景的重要性日益增加，但当前的标记化方法存在边界伪影导致的结果不一致性。

Method: 通过基于字符位置的匹配和动态块长度调整来实现标记化段的准确对齐和合并。

Result: 在各种长文本数据集上的广泛实验表明，LoPT框架能够显著提升速度，并保证无损标记化。

Conclusion: LoPT框架在保证无损的情况下显著加速了长文本的标记化过程。

Abstract: Long context inference scenarios have become increasingly important for large
language models, yet they introduce significant computational latency. While
prior research has optimized long-sequence inference through operators, model
architectures, and system frameworks, tokenization remains an overlooked
bottleneck. Existing parallel tokenization methods accelerate processing
through text segmentation and multi-process tokenization, but they suffer from
inconsistent results due to boundary artifacts that occur after merging. To
address this, we propose LoPT, a novel Lossless Parallel Tokenization framework
that ensures output identical to standard sequential tokenization. Our approach
employs character-position-based matching and dynamic chunk length adjustment
to align and merge tokenized segments accurately. Extensive experiments across
diverse long-text datasets demonstrate that LoPT achieves significant speedup
while guaranteeing lossless tokenization. We also provide theoretical proof of
consistency and comprehensive analytical studies to validate the robustness of
our method.

</details>


### [69] [Too Good to be Bad: On the Failure of LLMs to Role-Play Villains](https://arxiv.org/abs/2511.04962)
*Zihao Yi,Qingxuan Jiang,Ruotian Ma,Xingyu Chen,Qu Yang,Mengru Wang,Fanghua Ye,Ying Shen,Zhaopeng Tu,Xiaolong Li,Linus*

Main category: cs.CL

TL;DR: 本研究引入Moral RolePlay基准，系统性评估大型语言模型在角色扮演非利他角色方面的限制，揭示模型安全性与创意忠实性之间的紧张关系。


<details>
  <summary>Details</summary>
Motivation: 探讨当前大型语言模型在模拟非利他、对立角色方面的能力，尤其是道德模糊或恶棍角色的表现。

Method: 引入了Moral RolePlay基准，这是一种新的数据集，提供四级道德对齐尺度，并通过严格评估测试集进行评估。

Result: 发现一般聊天机器人的熟练程度对恶棍角色扮演能力的预测效果差，同时高度安全对齐的模型表现尤为糟糕。

Conclusion: 大规模评估表明，角色扮演的忠实度随着角色道德水平的降低而一致下降，特别部分与安全原则直接对立的特质表现不佳。

Abstract: Large Language Models (LLMs) are increasingly tasked with creative
generation, including the simulation of fictional characters. However, their
ability to portray non-prosocial, antagonistic personas remains largely
unexamined. We hypothesize that the safety alignment of modern LLMs creates a
fundamental conflict with the task of authentically role-playing morally
ambiguous or villainous characters. To investigate this, we introduce the Moral
RolePlay benchmark, a new dataset featuring a four-level moral alignment scale
and a balanced test set for rigorous evaluation. We task state-of-the-art LLMs
with role-playing characters from moral paragons to pure villains. Our
large-scale evaluation reveals a consistent, monotonic decline in role-playing
fidelity as character morality decreases. We find that models struggle most
with traits directly antithetical to safety principles, such as ``Deceitful''
and ``Manipulative'', often substituting nuanced malevolence with superficial
aggression. Furthermore, we demonstrate that general chatbot proficiency is a
poor predictor of villain role-playing ability, with highly safety-aligned
models performing particularly poorly. Our work provides the first systematic
evidence of this critical limitation, highlighting a key tension between model
safety and creative fidelity. Our benchmark and findings pave the way for
developing more nuanced, context-aware alignment methods.

</details>


### [70] [Acquiring Common Chinese Emotional Events Using Large Language Model](https://arxiv.org/abs/2511.04989)
*Ya Wang,Guangzheng Zhu,Cungen Cao,Jingjing Li,He Li,Xin Huang*

Main category: cs.CL

TL;DR: 本研究获取并整理了中文的常见情感事件，创建了一个高质量的知识库，展示了其在情感分析中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 情感事件知识在多个应用中提升效果，但获取普遍情感事件尤其困难。

Method: 通过收集中文情感事件指示符，在大型语言模型的提示下生成情感事件，并通过训练滤波器确保结果的有效性。

Result: 获得102,218个高质量的常见情感事件，并进行了分类和情感极性标注，创建了中文情感事件的大规模常识知识库。

Conclusion: 提出的方法能够有效获取中文的常见情感事件，并展示了其在情感原因提取领域的强大潜力。

Abstract: Knowledge about emotional events is an important kind of knowledge which has
been applied to improve the effectiveness of different applications. However,
emotional events cannot be easily acquired, especially common or generalized
emotional events that are context-independent. The goal of this paper is to
obtain common emotional events in Chinese language such as "win a prize" and
"be criticized". Our approach begins by collecting a comprehensive list of
Chinese emotional event indicators. Then, we generate emotional events by
prompting a Chinese large language model (LLM) using these indicators. To
ensure the quality of these emotional events, we train a filter to discard
invalid generated results. We also classify these emotional events as being
positive events and negative events using different techniques. Finally, we
harvest a total of 102,218 high-quality common emotional events with sentiment
polarity labels, which is the only large-scale commonsense knowledge base of
emotional events in Chinese language. Intrinsic evaluation results show that
the proposed method in this paper can be effectively used to acquire common
Chinese emotional events. An extrinsic use case also demonstrates the strong
potential of common emotional events in the field of emotion cause extraction
(ECE). Related resources including emotional event indicators and emotional
events will be released after the publication of this paper.

</details>


### [71] [Pluralistic Behavior Suite: Stress-Testing Multi-Turn Adherence to Custom Behavioral Policies](https://arxiv.org/abs/2511.05018)
*Prasoon Varshney,Makesh Narsimhan Sreedhar,Liwei Jiang,Traian Rebedea,Christopher Parisien*

Main category: cs.CL

TL;DR: 本研究提出PLURALISTIC BEHAVIOR SUITE评估LLM在多轮对话中的多元对齐能力，发现现有模型方法在此场景下存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 鉴于LLM在实际应用中受到不同企业政策、监管要求和用户价值观的影响，迫切需要一种能够评估其多元对齐能力的方法。

Method: 使用PLURALISTIC BEHAVIOR SUITE (PBSUITE)评估LLM在多轮交互中的合规性与适应性。

Result: 研究表明，领先的LLM在单轮对话中对行为政策有良好的遵守率，但在多轮对抗性互动中合规性显著下降，失败率高达84%。

Conclusion: 现有的模型对齐和安全管理方法无法在现实世界的LLM交互中一致地执行多元化的行为政策，因此需要更加全面的评估与研究来支持多元对齐技术的有效性。

Abstract: Large language models (LLMs) are typically aligned to a universal set of
safety and usage principles intended for broad public acceptability. Yet,
real-world applications of LLMs often take place within organizational
ecosystems shaped by distinctive corporate policies, regulatory requirements,
use cases, brand guidelines, and ethical commitments. This reality highlights
the need for rigorous and comprehensive evaluation of LLMs with pluralistic
alignment goals, an alignment paradigm that emphasizes adaptability to diverse
user values and needs. In this work, we present PLURALISTIC BEHAVIOR SUITE
(PBSUITE), a dynamic evaluation suite designed to systematically assess LLMs'
capacity to adhere to pluralistic alignment specifications in multi-turn,
interactive conversations. PBSUITE consists of (1) a diverse dataset of 300
realistic LLM behavioral policies, grounded in 30 industries; and (2) a dynamic
evaluation framework for stress-testing model compliance with custom behavioral
specifications under adversarial conditions. Using PBSUITE, We find that
leading open- and closed-source LLMs maintain robust adherence to behavioral
policies in single-turn settings (less than 4% failure rates), but their
compliance weakens substantially in multi-turn adversarial interactions (up to
84% failure rates). These findings highlight that existing model alignment and
safety moderation methods fall short in coherently enforcing pluralistic
behavioral policies in real-world LLM interactions. Our work contributes both
the dataset and analytical framework to support future research toward robust
and context-aware pluralistic alignment techniques.

</details>


### [72] [UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM Code Generation in Ukrainian](https://arxiv.org/abs/2511.05040)
*Mykyta Syromiatnikov,Victoria Ruvinskaya*

Main category: cs.CL

TL;DR: 本研究引入了UA-Code-Bench基准，以评估大型语言模型在乌克兰语中的代码生成能力，结果表明现有模型在解决编程问题方面存在显著挑战。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在低资源语言中的真实能力仍然是一项挑战，因为现有基准主要集中在从英文翻译而来的广泛任务或仅评估简单的语言理解。

Method: 本研究评估了13个主要的专有和开源模型在Eolymp平台上生成Python解决方案的能力，使用了一次性提示，并通过专门的Eolymp环境进行评估，以隐藏测试确保代码正确性。

Result: 即使是表现最好的模型，如OpenAI o3和GPT-5，只解决了大约一半的问题，突显出在低资源自然语言中的代码生成挑战。同时还进行了不同难度水平下的性能分析及解决方案的独特性和计算效率的评估。

Conclusion: 本研究展示了竞争性编程基准在评估大型语言模型，特别是在资源不足语言中的价值，并为未来多语言代码生成和推理增强模型的研究铺平了道路。

Abstract: Evaluating the real capabilities of large language models in low-resource
languages still represents a challenge, as many existing benchmarks focus on
widespread tasks translated from English or evaluate only simple language
understanding. This paper introduces UA-Code-Bench, a new open-source benchmark
established for a thorough evaluation of language models' code generation and
competitive programming problem-solving abilities in Ukrainian. The benchmark
comprises 500 problems from the Eolymp platform, evenly distributed across five
complexity levels from very easy to very hard. A diverse set of 13 leading
proprietary and open-source models, generating Python solutions based on a
one-shot prompt, was evaluated via the dedicated Eolymp environment against
hidden tests, ensuring code correctness. The obtained results reveal that even
top-performing models, such as OpenAI o3 and GPT-5, solve only half of the
problems, highlighting the challenge of code generation in low-resource natural
language. Furthermore, this research presents a comprehensive analysis of
performance across various difficulty levels, as well as an assessment of
solution uniqueness and computational efficiency, measured by both elapsed time
and memory consumption of the generated solutions. In conclusion, this work
demonstrates the value of competitive programming benchmarks in evaluating
large language models, especially in underrepresented languages. It also paves
the way for future research on multilingual code generation and
reasoning-enhanced models. The benchmark, data parsing, preparation, code
generation, and evaluation scripts are available at
https://huggingface.co/datasets/NLPForUA/ua-code-bench.

</details>


### [73] [Order-Level Attention Similarity Across Language Models: A Latent Commonality](https://arxiv.org/abs/2511.05064)
*Jinglin Liang,Jin Zhong,Shuangping Huang,Yunqing Hu,Huiyuan Zhang,Huifang Li,Lixin Fan,Hanlin Gu*

Main category: cs.CL

TL;DR: 本论文研究了不同语言模型之间的上下文聚合模式的共同点，提出了基于Order-Level Attention的跨模型适配器TOA，有效提高了未见语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 探讨不同语言模型之间的上下文聚合模式的相似性，填补了先前研究的空白。

Method: 引入了一种无训练的跨语言模型适配器传输方法，基于Order-Level Attention（OLA）的统一句法特征表示。

Result: 发现不同语言模型在同一顺序的OLA显示出显著的相似性，并提出了TOA适配器作为一种跨模型知识转移的方法。

Conclusion: 提出的TOA方法通过利用不同语言模型间的相似性，能够有效提升未见语言模型的性能。

Abstract: In this paper, we explore an important yet previously neglected question: Do
context aggregation patterns across Language Models (LMs) share commonalities?
While some works have investigated context aggregation or attention weights in
LMs, they typically focus on individual models or attention heads, lacking a
systematic analysis across multiple LMs to explore their commonalities. In
contrast, we focus on the commonalities among LMs, which can deepen our
understanding of LMs and even facilitate cross-model knowledge transfer. In
this work, we introduce the Order-Level Attention (OLA) derived from the
order-wise decomposition of Attention Rollout and reveal that the OLA at the
same order across LMs exhibits significant similarities. Furthermore, we
discover an implicit mapping between OLA and syntactic knowledge. Based on
these two findings, we propose the Transferable OLA Adapter (TOA), a
training-free cross-LM adapter transfer method. Specifically, we treat the OLA
as a unified syntactic feature representation and train an adapter that takes
OLA as input. Due to the similarities in OLA across LMs, the adapter
generalizes to unseen LMs without requiring any parameter updates. Extensive
experiments demonstrate that TOA's cross-LM generalization effectively enhances
the performance of unseen LMs. Code is available at
https://github.com/jinglin-liang/OLAS.

</details>


### [74] [Reasoning-Guided Claim Normalization for Noisy Multilingual Social Media Posts](https://arxiv.org/abs/2511.05078)
*Manan Sharma,Arya Suneesh,Manish Jain,Pawan Kumar Rajpoot,Prasanna Devadiga,Bharatdeep Hazarika,Ashish Shrivastava,Kishan Gurumurthy,Anshuman B Suresh,Aditya U Baliga*

Main category: cs.CL

TL;DR: 本研究提出一种多语言虚假信息检测的声明规范化方法，通过系统分解和微调技术，显著提高了不同语言间的语义一致性和检测效果。


<details>
  <summary>Details</summary>
Motivation: 鉴于社交媒体中存在的虚假信息的复杂性，本研究旨在将嘈杂的社交媒体帖子转换为清晰且可验证的声明。

Method: 通过使用 LoRA 对 Qwen3-14B 进行微调，并结合去重、标记级召回过滤和检索增强的少量学习，进行多语言的声明规范化。

Result: 该系统在 METEOR 评分上展示了显著的性能提升，英语言得分为41.16，马拉地语为15.21，整体显示出对基线配置的41.3%的相对提升。

Conclusion: 该方法在跨语言一般化方面表现出色，尤其是在罗曼语和日耳曼语言中，能够保持语义一致性。

Abstract: We address claim normalization for multilingual misinformation detection -
transforming noisy social media posts into clear, verifiable statements across
20 languages. The key contribution demonstrates how systematic decomposition of
posts using Who, What, Where, When, Why and How questions enables robust
cross-lingual transfer despite training exclusively on English data. Our
methodology incorporates finetuning Qwen3-14B using LoRA with the provided
dataset after intra-post deduplication, token-level recall filtering for
semantic alignment and retrieval-augmented few-shot learning with contextual
examples during inference. Our system achieves METEOR scores ranging from 41.16
(English) to 15.21 (Marathi), securing third rank on the English leaderboard
and fourth rank for Dutch and Punjabi. The approach shows 41.3% relative
improvement in METEOR over baseline configurations and substantial gains over
existing methods. Results demonstrate effective cross-lingual generalization
for Romance and Germanic languages while maintaining semantic coherence across
diverse linguistic structures.

</details>


### [75] [On Text Simplification Metrics and General-Purpose LLMs for Accessible Health Information, and A Potential Architectural Advantage of The Instruction-Tuned LLM class](https://arxiv.org/abs/2511.05080)
*P. Bilha Githinji,Aikaterini Meilliou,Peiwu Qin*

Main category: cs.CL

TL;DR: 本文评估了两种LLMs在文本简化任务上的表现，发现Mistral 24B在提高可读性和保持语篇忠实度方面优于QWen2.5 32B。


<details>
  <summary>Details</summary>
Motivation: 公众对生物医学信息的健康寻求行为和数字消费不断增加，需要可扩展的解决方案来自动将复杂科学技术文档转化为通俗易懂的语言。

Method: 比较分析两种主要类型的通用大型语言模型（LLMs），分别是指令调优的Mistral 24B和推理增强的QWen2.5 32B。

Result: Mistral表现出较强的词汇简化策略，SARI均值为42.46，BERTScore为0.91，而QWen的BERTScore为0.89，显著低于Mistral。

Conclusion: 指令调优的Mistral 24B在文本简化任务中表现出色，既提高了可读性，又保持了人类水平的语篇忠实度。

Abstract: The increasing health-seeking behavior and digital consumption of biomedical
information by the general public necessitate scalable solutions for
automatically adapting complex scientific and technical documents into plain
language. Automatic text simplification solutions, including advanced large
language models, however, continue to face challenges in reliably arbitrating
the tension between optimizing readability performance and ensuring
preservation of discourse fidelity. This report empirically assesses the
performance of two major classes of general-purpose LLMs, demonstrating their
linguistic capabilities and foundational readiness for the task compared to a
human benchmark. Using a comparative analysis of the instruction-tuned Mistral
24B and the reasoning-augmented QWen2.5 32B, we identify a potential
architectural advantage in the instruction-tuned LLM. Mistral exhibits a
tempered lexical simplification strategy that enhances readability across a
suite of metrics and the simplification-specific formula SARI (mean 42.46),
while preserving human-level discourse with a BERTScore of 0.91. QWen also
attains enhanced readability performance, but its operational strategy shows a
disconnect in balancing between readability and accuracy, reaching a
statistically significantly lower BERTScore of 0.89. Additionally, a
comprehensive correlation analysis of 21 metrics spanning readability,
discourse fidelity, content safety, and underlying distributional measures for
mechanistic insights, confirms strong functional redundancies among five
readability indices. This empirical evidence tracks baseline performance of the
evolving LLMs for the task of text simplification, identifies the
instruction-tuned Mistral 24B for simplification, provides necessary heuristics
for metric selection, and points to lexical support as a primary
domain-adaptation issue for simplification.

</details>


### [76] [Iterative Layer-wise Distillation for Efficient Compression of Large Language Models](https://arxiv.org/abs/2511.05085)
*Grigory Kovalev,Mikhail Tikhomirov*

Main category: cs.CL

TL;DR: 本研究提出了一种改进的蒸馏方法，通过迭代评估层重要性，显著减少大语言模型的层数而保持性能，适合在资源有限的环境中应用。


<details>
  <summary>Details</summary>
Motivation: 旨在开发紧凑型模型，同时保持高性能，解决大语言模型在资源使用上的挑战。

Method: 基于短期GPT的方法，结合逐层重要性评估和使用联合损失函数进行进一步训练。

Result: 在Qwen2.5-3B模型上的实验显示，可以将层数从36层减少到28层（参数为24.7亿），质量损失仅为9.7%；减少到24层时，质量损失为18%。

Conclusion: 通过迭代蒸馏和微调的方法，可以有效减少大语言模型的层数，同时保持相对高的性能，使其适用于资源有限的环境下的部署。

Abstract: This work investigates distillation methods for large language models (LLMs)
with the goal of developing compact models that preserve high performance.
Several existing approaches are reviewed, with a discussion of their respective
strengths and limitations. An improved method based on the ShortGPT approach
has been developed, building upon the idea of incorporating iterative
evaluation of layer importance. At each step, importance is assessed by
measuring performance degradation when individual layers are removed, using a
set of representative datasets. This process is combined with further training
using a joint loss function based on KL divergence and mean squared error.
Experiments on the Qwen2.5-3B model show that the number of layers can be
reduced from 36 to 28 (resulting in a 2.47 billion parameter model) with only a
9.7% quality loss, and to 24 layers with an 18% loss. The findings suggest that
the middle transformer layers contribute less to inference, underscoring the
potential of the proposed method for creating efficient models. The results
demonstrate the effectiveness of iterative distillation and fine-tuning, making
the approach suitable for deployment in resource-limited settings.

</details>


### [77] [A Toolbox for Improving Evolutionary Prompt Search](https://arxiv.org/abs/2511.05120)
*Daniel Grießhaber,Maximilian Kimmich,Johannes Maucher,Ngoc Thang Vu*

Main category: cs.CL

TL;DR: 本文提出了一种新的演化提示优化方法，通过分步骤演化、人工智能评估、人类反馈和高效评估策略来增强优化效果，提升了性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的演化提示优化方法在操作强度和评估机制上存在不足，因此需要进行改进。

Method: 提出了分步骤的演化解构、基于LLM的评估者、整合人类反馈以及开发高效评估策略。

Result: 我们的改进措施在提高提示优化的质量和效率方面取得了成效。

Conclusion: 我们提出的改进方法在优化质量和效率上都有所提升，并且通过发布代码支持新任务的提示优化和该领域的进一步研究。

Abstract: Evolutionary prompt optimization has demonstrated effectiveness in refining
prompts for LLMs. However, existing approaches lack robust operators and
efficient evaluation mechanisms. In this work, we propose several key
improvements to evolutionary prompt optimization that can partially generalize
to prompt optimization in general: 1) decomposing evolution into distinct steps
to enhance the evolution and its control, 2) introducing an LLM-based judge to
verify the evolutions, 3) integrating human feedback to refine the evolutionary
operator, and 4) developing more efficient evaluation strategies that maintain
performance while reducing computational overhead. Our approach improves both
optimization quality and efficiency. We release our code, enabling prompt
optimization on new tasks and facilitating further research in this area.

</details>


### [78] [ManufactuBERT: Efficient Continual Pretraining for Manufacturing](https://arxiv.org/abs/2511.05135)
*Robin Armingaud,Romaric Besançon*

Main category: cs.CL

TL;DR: 本研究提出了制造BERT模型，通过精心构建的专用语料库大幅提高了制造领域NLP任务的表现和训练效率。


<details>
  <summary>Details</summary>
Motivation: 为了克服大型通用Transformer模型在专业领域（如制造业）中由于缺乏领域特定术语和语义的暴露所导致的性能下降。

Method: 引入了一种数据处理管道，首先进行领域特定的过滤，然后进行多阶段的去重处理，生成用于制造领域的大规模语料库。

Result: 制造BERT在多个制造相关的NLP任务上超越了强大的专业基准，尤其是在使用经过去重的语料库训练时，加速了收敛。

Conclusion: ManufactuBERT在制造领域的NLP任务中表现优异，创造了新的最佳记录，并且使用经过仔细去重的语料库进行训练显著加速了收敛，减少了训练时间和计算成本。

Abstract: While large general-purpose Transformer-based encoders excel at general
language understanding, their performance diminishes in specialized domains
like manufacturing due to a lack of exposure to domain-specific terminology and
semantics. In this paper, we address this gap by introducing ManufactuBERT, a
RoBERTa model continually pretrained on a large-scale corpus curated for the
manufacturing domain. We present a comprehensive data processing pipeline to
create this corpus from web data, involving an initial domain-specific
filtering step followed by a multi-stage deduplication process that removes
redundancies. Our experiments show that ManufactuBERT establishes a new
state-of-the-art on a range of manufacturing-related NLP tasks, outperforming
strong specialized baselines. More importantly, we demonstrate that training on
our carefully deduplicated corpus significantly accelerates convergence,
leading to a 33\% reduction in training time and computational cost compared to
training on the non-deduplicated dataset. The proposed pipeline offers a
reproducible example for developing high-performing encoders in other
specialized domains. We will release our model and curated corpus at
https://huggingface.co/cea-list-ia.

</details>


### [79] [Effectiveness of Chain-of-Thought in Distilling Reasoning Capability from Large Language Models](https://arxiv.org/abs/2511.05184)
*Cong-Thanh Do,Rama Doddipatla,Kate Knill*

Main category: cs.CL

TL;DR: 本研究探讨了Chain-of-Thought在知识蒸馏中的应用，发现其能有效提升小型LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过CoT增强从大型LLM到小型LLM的推理能力的蒸馏过程。

Method: 使用来自Qwen和Llama2系列的LLM进行白盒知识蒸馏实验，结合CoT-Collection数据集中的CoT数据。

Result: 实验结果展示了CoT在提升白盒知识蒸馏效果方面的作用，蒸馏模型在BBH基准测试中的平均性能得到了改善。

Conclusion: CoT显著提升了白盒知识蒸馏的效果，使得蒸馏模型在自然语言推理和理解任务中表现更佳。

Abstract: Chain-of-Thought (CoT) prompting is a widely used method to improve the
reasoning capability of Large Language Models (LLMs). More recently, CoT has
been leveraged in Knowledge Distillation (KD) to transfer reasoning capability
from a larger LLM to a smaller one. This paper examines the role of CoT in
distilling the reasoning capability from larger LLMs to smaller LLMs using
white-box KD, analysing its effectiveness in improving the performance of the
distilled models for various natural language reasoning and understanding
tasks. We conduct white-box KD experiments using LLMs from the Qwen and Llama2
families, employing CoT data from the CoT-Collection dataset. The distilled
models are then evaluated on natural language reasoning and understanding tasks
from the BIG-Bench-Hard (BBH) benchmark, which presents complex challenges for
smaller LLMs. Experimental results demonstrate the role of CoT in improving
white-box KD effectiveness, enabling the distilled models to achieve better
average performance in natural language reasoning and understanding tasks from
BBH.

</details>


### [80] [Translation via Annotation: A Computational Study of Translating Classical Chinese into Japanese](https://arxiv.org/abs/2511.05239)
*Zilong Li,Jie Cao*

Main category: cs.CL

TL;DR: 研究古代汉语翻译日语的注释过程，通过建立LLM的注释管道和新数据集，在低资源环境中提升序列标记任务的训练效果。


<details>
  <summary>Details</summary>
Motivation: 解决古代汉语到日语的翻译中遇到的低资源问题，并提高注释及翻译的效果。

Method: 利用大型语言模型和构建的新数据集，研究古代翻译中的注释过程，并将其抽象为序列标记任务。

Result: 引入辅助的中文NLP任务能够提升序列标记任务的训练效果，大型语言模型在直接翻译中表现良好，但在标注字符时表现不佳。

Conclusion: 本文提出的基于LLM的注释管道在低资源环境中有效地促进了序列标记任务的训练，并展示了与大型语言模型的配合使用策略。

Abstract: Ancient people translated classical Chinese into Japanese by annotating
around each character. We abstract this process as sequence tagging tasks and
fit them into modern language technologies. The research of this annotation and
translation system is a facing low-resource problem. We release this problem by
introducing a LLM-based annotation pipeline and construct a new dataset from
digitalized open-source translation data. We show that under the low-resource
setting, introducing auxiliary Chinese NLP tasks has a promoting effect on the
training of sequence tagging tasks. We also evaluate the performance of large
language models. They achieve high scores in direct machine translation, but
they are confused when being asked to annotate characters. Our method could
work as a supplement of LLMs.

</details>


### [81] [Reflective Personalization Optimization: A Post-hoc Rewriting Framework for Black-Box Large Language Models](https://arxiv.org/abs/2511.05286)
*Teqi Hao,Xioayu Tan,Shaojie Shi,Yinghui Xu,Xihe Qiu*

Main category: cs.CL

TL;DR: RPO通过将内容生成与用户个性化解耦，显著提高了输出质量，提出了一种可以与多种基模型兼容的创新个性化框架。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化方法往往通过上下文注入来引导生成过程，但这会增加模型的负担，导致输出质量的折衷，因此需要重新定义个性化的范式。

Method: RPO框架分为两个阶段：首先是基模型生成高质量的一般响应，其次是由外部反思模块显式重写该输出以满足用户偏好。反思模块通过两阶段过程进行训练，首先是监督微调，然后使用强化学习进一步优化输出质量。

Result: 在LaMP基准上的综合实验表明，RPO显著优于最新的基准方法，强调了显式响应塑造的优势，同时介绍了可与任何基础模型无缝集成的高效个性化层。

Conclusion: RPO（反思个性化优化）通过解耦内容生成与个性化，显著优于现有的基准，证明了显式响应塑造的优越性，并提供了一种高效的与模型无关的个性化层。

Abstract: The personalization of black-box large language models (LLMs) is a critical
yet challenging task. Existing approaches predominantly rely on context
injection, where user history is embedded into the prompt to directly guide the
generation process. However, this single-step paradigm imposes a dual burden on
the model: generating accurate content while simultaneously aligning with
user-specific styles. This often results in a trade-off that compromises output
quality and limits precise control. To address this fundamental tension, we
propose Reflective Personalization Optimization (RPO), a novel framework that
redefines the personalization paradigm by decoupling content generation from
alignment. RPO operates in two distinct stages: first, a base model generates a
high-quality, generic response; then, an external reflection module explicitly
rewrites this output to align with the user's preferences. This reflection
module is trained using a two-stage process. Initially, supervised fine-tuning
is employed on structured rewriting trajectories to establish a core
personalized reasoning policy that models the transformation from generic to
user-aligned responses. Subsequently, reinforcement learning is applied to
further refine and enhance the quality of the personalized outputs.
Comprehensive experiments on the LaMP benchmark demonstrate that RPO, by
decoupling content generation from personalization, significantly outperforms
state-of-the-art baselines. These findings underscore the superiority of
explicit response shaping over implicit context injection. Moreover, RPO
introduces an efficient, model-agnostic personalization layer that can be
seamlessly integrated with any underlying base model, paving the way for a new
and effective direction in user-centric generation scenarios.

</details>


### [82] [Listening Between the Lines: Decoding Podcast Narratives with Language Modeling](https://arxiv.org/abs/2511.05310)
*Shreya Gupta,Ojasva Saxena,Arghodeep Nandi,Sarah Masud,Kiran Garimella,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文分析了播客的叙事结构，提出了一种新的分析方法，以便更好地理解播客如何影响公众舆论。


<details>
  <summary>Details</summary>
Motivation: 随着播客在塑造公众舆论中的重要性提升，理解其叙事结构有助于把握当代话语。

Method: 通过开发并评估一个微调的BERT模型，将叙事框架与对话中提到的具体实体连接起来，从而实现对播客叙事的分析。

Result: 提出了一种新的帧标注方法，能更准确地与人类判断相匹配，同时揭示了讨论内容和呈现方式之间的关系。

Conclusion: 本文提出了一种新的帧标注方法，并揭示了主题与叙事框架之间的系统性关系，为数字媒体中的影响力研究提供了更强大的框架。

Abstract: Podcasts have become a central arena for shaping public opinion, making them
a vital source for understanding contemporary discourse. Their typically
unscripted, multi-themed, and conversational style offers a rich but complex
form of data. To analyze how podcasts persuade and inform, we must examine
their narrative structures -- specifically, the narrative frames they employ.
  The fluid and conversational nature of podcasts presents a significant
challenge for automated analysis. We show that existing large language models,
typically trained on more structured text such as news articles, struggle to
capture the subtle cues that human listeners rely on to identify narrative
frames. As a result, current approaches fall short of accurately analyzing
podcast narratives at scale.
  To solve this, we develop and evaluate a fine-tuned BERT model that
explicitly links narrative frames to specific entities mentioned in the
conversation, effectively grounding the abstract frame in concrete details. Our
approach then uses these granular frame labels and correlates them with
high-level topics to reveal broader discourse trends. The primary contributions
of this paper are: (i) a novel frame-labeling methodology that more closely
aligns with human judgment for messy, conversational data, and (ii) a new
analysis that uncovers the systematic relationship between what is being
discussed (the topic) and how it is being presented (the frame), offering a
more robust framework for studying influence in digital media.

</details>


### [83] [What Are the Facts? Automated Extraction of Court-Established Facts from Criminal-Court Opinions](https://arxiv.org/abs/2511.05320)
*Klára Bendová,Tomáš Knap,Jan Černý,Vojtěch Pour,Jaromir Savelka,Ivana Kvapilíková,Jakub Drápal*

Main category: cs.CL

TL;DR: 本研究探讨了提取斯洛伐克法院判决中犯罪行为描述的可行性，证明高级正则表达式和大型语言模型能有效提高提取准确率。


<details>
  <summary>Details</summary>
Motivation: 探索利用大陆欧洲法院判决书中丰富的犯罪行为描述信息来增强刑事司法数据分析的有效性。

Method: 使用两种方法提取犯罪行为描述：高级正则表达式和大型语言模型（LLMs）。

Result: 通过先进的正则表达式和LLMs，描述提取准确率显著提高，分别达97%和98.75%。

Conclusion: 本研究表明通过高级正则表达式和大型语言模型，可以有效提取斯洛伐克法院判决中的犯罪行为描述，超过传统方法的性能，并与人类标注结果高度一致。

Abstract: Criminal justice administrative data contain only a limited amount of
information about the committed offense. However, there is an unused source of
extensive information in continental European courts' decisions: descriptions
of criminal behaviors in verdicts by which offenders are found guilty. In this
paper, we study the feasibility of extracting these descriptions from publicly
available court decisions from Slovakia. We use two different approaches for
retrieval: regular expressions and large language models (LLMs). Our baseline
was a simple method employing regular expressions to identify typical words
occurring before and after the description. The advanced regular expression
approach further focused on "sparing" and its normalization (insertion of
spaces between individual letters), typical for delineating the description.
The LLM approach involved prompting the Gemini Flash 2.0 model to extract the
descriptions using predefined instructions. Although the baseline identified
descriptions in only 40.5% of verdicts, both methods significantly outperformed
it, achieving 97% with advanced regular expressions and 98.75% with LLMs, and
99.5% when combined. Evaluation by law students showed that both advanced
methods matched human annotations in about 90% of cases, compared to just 34.5%
for the baseline. LLMs fully matched human-labeled descriptions in 91.75% of
instances, and a combination of advanced regular expressions with LLMs reached
92%.

</details>


### [84] [Evaluating Subword Tokenization Techniques for Bengali: A Benchmark Study with BengaliBPE](https://arxiv.org/abs/2511.05324)
*Firoj Ahmmed Patwary,Abdullah Al Noman*

Main category: cs.CL

TL;DR: 提出了一种针对孟加拉语的分词器BengaliBPE，通过形态学感知的合并规则提高了分词效果，为未来的孟加拉语NLP系统提供了良好基础。


<details>
  <summary>Details</summary>
Motivation: 现有的子词分词器在处理形态丰富的语言（如孟加拉语）时表现不佳，因此迫切需要一种专为孟加拉语设计的分词器。

Method: 开发了针对孟加拉语脚本的专用Byte Pair Encoding（BPE）分词器，采用Unicode规范化、图素级初始化和形态学感知的合并规则。

Result: BengaliBPE在分词的细粒度、编码速度和下游分类准确性方面与三个基线进行比较，结果显示BengaliBPE在细节分割和形态解释方面优于其他方法，但计算成本略高。

Conclusion: BengaliBPE在分词细节和形态学可解释性方面表现最佳，为未来的孟加拉语NLP系统奠定了基础。

Abstract: Tokenization is an important first step in Natural Language Processing (NLP)
pipelines because it decides how models learn and represent linguistic
information. However, current subword tokenizers like SentencePiece or
HuggingFace BPE are mostly designed for Latin or multilingual corpora and do
not perform well on languages with rich morphology such as Bengali. To address
this limitation, we present BengaliBPE, a Byte Pair Encoding (BPE) tokenizer
specifically developed for the Bengali script. BengaliBPE applies Unicode
normalization, grapheme-level initialization, and morphology-aware merge rules
to maintain linguistic consistency and preserve subword integrity. We use a
large-scale Bengali news classification dataset to compare BengaliBPE with
three baselines: Whitespace, SentencePiece BPE, and HuggingFace BPE. The
evaluation considers tokenization granularity, encoding speed, and downstream
classification accuracy. While all methods perform reasonably well, BengaliBPE
provides the most detailed segmentation and the best morphological
interpretability, albeit with slightly higher computational cost. These
findings highlight the importance of language-aware tokenization for
morphologically rich scripts and establish BengaliBPE as a strong foundation
for future Bengali NLP systems, including large-scale pretraining of contextual
language models.

</details>


### [85] [Minority-Aware Satisfaction Estimation in Dialogue Systems via Preference-Adaptive Reinforcement Learning](https://arxiv.org/abs/2511.05407)
*Yahui Fu,Zi Haur Pang,Tatsuya Kawahara*

Main category: cs.CL

TL;DR: 本文提出了一种新的对话系统用户满意度评估框架，通过个体与群体偏好的建模改善少数用户的满意度估计。


<details>
  <summary>Details</summary>
Motivation: 由于对用户满意度的主观性以及少数群体意见的忽视，现有对齐方法未能充分考虑不同用户的个体化需求。

Method: 利用Chain-of-Personalized-Reasoning捕捉个体偏好，并采用M2PC算法识别用户群体，再通过PAda-PPO框架整合优化个体与群体偏好。

Result: 在情感支持对话数据集上的实验证明了提出的方法在用户满意度估计方面的有效性，尤其是针对代表性不足的用户群体。

Conclusion: 提出的PAda-PPO框架有效提高了用户满意度的估计，特别是对少数用户群体的支持。

Abstract: User satisfaction in dialogue systems is inherently subjective. When the same
response strategy is applied across users, minority users may assign different
satisfaction ratings than majority users due to variations in individual
intents and preferences. However, existing alignment methods typically train
one-size-fits-all models that aim for broad consensus, often overlooking
minority perspectives and user-specific adaptation. We propose a unified
framework that models both individual- and group-level preferences for user
satisfaction estimation. First, we introduce Chain-of-Personalized-Reasoning
(CoPeR) to capture individual preferences through interpretable reasoning
chains. Second, we propose an expectation-maximization-based Majority-Minority
Preference-Aware Clustering (M2PC) algorithm that discovers distinct user
groups in an unsupervised manner to learn group-level preferences. Finally, we
integrate these components into a preference-adaptive reinforcement learning
framework (PAda-PPO) that jointly optimizes alignment with both individual and
group preferences. Experiments on the Emotional Support Conversation dataset
demonstrate consistent improvements in user satisfaction estimation,
particularly for underrepresented user groups.

</details>


### [86] [Steering Language Models with Weight Arithmetic](https://arxiv.org/abs/2511.05408)
*Constanza Fierro,Fabien Roger*

Main category: cs.CL

TL;DR: 提出了一种对比权重引导的方法，以调整大型语言模型的权重，减少不良行为并保持任务性能，同时监测潜在的行为失调。


<details>
  <summary>Details</summary>
Motivation: 审视高质量反馈的挑战，尤其是在狭窄的训练分布下，以避免意外的泛化问题。

Method: 使用对比权重引导，通过加减模型参数中的重量方向来调整模型，以减少阿谀奉承和引入错误拒绝。

Result: 我们发现该方法在减少不良行为方面优于激活引导，并且能够在一定程度上减轻微调过程中的行为漂移。

Conclusion: 对大型语言模型的对比权重引导能够有效减少不良行为，并在特定任务微调过程中保持任务表现，同时能够监测潜在的行为失调。

Abstract: Providing high-quality feedback to Large Language Models (LLMs) on a diverse
training distribution can be difficult and expensive, and providing feedback
only on a narrow distribution can result in unintended generalizations. To
better leverage narrow training data, we propose contrastive weight steering, a
simple post-training method that edits the model parameters using weight
arithmetic. We isolate a behavior direction in weight-space by subtracting the
weight deltas from two small fine-tunes -- one that induces the desired
behavior and another that induces its opposite -- and then add or remove this
direction to modify the model's weights. We apply this technique to mitigate
sycophancy and induce misalignment, and find that weight steering often
generalizes further than activation steering, achieving stronger
out-of-distribution behavioral control before degrading general capabilities.
We also show that, in the context of task-specific fine-tuning, weight steering
can partially mitigate undesired behavioral drift: it can reduce sycophancy and
under-refusals introduced during fine-tuning while preserving task performance
gains. Finally, we provide preliminary evidence that emergent misalignment can
be detected by measuring the similarity between fine-tuning updates and an
"evil" weight direction, suggesting that it may be possible to monitor the
evolution of weights during training and detect rare misaligned behaviors that
never manifest during training or evaluations.

</details>


### [87] [MIMIC-SR-ICD11: A Dataset for Narrative-Based Diagnosis](https://arxiv.org/abs/2511.05485)
*Yuexin Wu,Shiqi Wang,Vasile Rus*

Main category: cs.CL

TL;DR: 本文提出了MIMIC-SR-ICD11数据集和LL-Rank框架，以提升疾病诊断的准确性，LL-Rank显示出优于GenMap的效果，主要由于其基于PMI的评分机制。


<details>
  <summary>Details</summary>
Motivation: 为了提高疾病诊断的准确性，尤其是在处理电子健康记录中隐含但重要的自我报告信号。

Method: 提出LL-Rank框架，通过计算条件临床报告上下文下每个标签的联合似然性并减去相应的无报告先验似然性来进行标记重新排序。

Result: MIMIC-SR-ICD11是一个基于电子健康记录出院记录构建的大型诊断数据集，采用WHO ICD-11术语，并且LL-Rank在性能上优于前述基线。

Conclusion: LL-Rank在多个模型架构上始终优于强基线GenMap，证明了其在疾病诊断中有效性。

Abstract: Disease diagnosis is a central pillar of modern healthcare, enabling early
detection and timely intervention for acute conditions while guiding lifestyle
adjustments and medication regimens to prevent or slow chronic disease.
Self-reports preserve clinically salient signals that templated electronic
health record (EHR) documentation often attenuates or omits, especially subtle
but consequential details. To operationalize this shift, we introduce
MIMIC-SR-ICD11, a large English diagnostic dataset built from EHR discharge
notes and natively aligned to WHO ICD-11 terminology. We further present
LL-Rank, a likelihood-based re-ranking framework that computes a
length-normalized joint likelihood of each label given the clinical report
context and subtracts the corresponding report-free prior likelihood for that
label. Across seven model backbones, LL-Rank consistently outperforms a strong
generation-plus-mapping baseline (GenMap). Ablation experiments show that
LL-Rank's gains primarily stem from its PMI-based scoring, which isolates
semantic compatibility from label frequency bias.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [88] [Scientific judgment drifts over time in AI ideation](https://arxiv.org/abs/2511.04964)
*Lingyu Zhang,Mitchell Wang,Boyuan Chen*

Main category: cs.HC

TL;DR: 科学家对研究想法的评估不是静态的，而是随着时间的推移而变化，建立动态的评估协议至关重要。


<details>
  <summary>Details</summary>
Motivation: 评估早期研究概念的主观性，以及现有系统假设科学家的评估是固定标准的问题。

Method: 通过对57名活跃研究人员在两轮研究中进行7182次评分，评估AI生成的想法与控制想法之间的相对质量。

Result: 科学家的评分随着时间推移而系统性漂移，总体质量评分在0-10的尺度上增加了0.61分，且核心科学价值维度的测试-重测可靠性为中等水平。

Conclusion: 人类对科学想法的评估是动态的，稳定的优先级需要不断调整，以追踪专家标准的变化。

Abstract: Scientific discovery begins with ideas, yet evaluating early-stage research
concepts is a subtle and subjective human judgment. As large language models
(LLMs) are increasingly tasked with generating scientific hypotheses, most
systems assume that scientists' evaluations form a fixed gold standard, and
that scientists' judgments do not change. Here we challenge this assumption. In
a two-wave study with 7,182 ratings from 57 active researchers across six
scientific departments, each participant repeatedly evaluated a constant
"control" research idea alongside AI-generated ideas. We show that scientists'
ratings of the very same idea systematically drift over time: overall quality
scores increased by 0.61 points on a 0-10 scale (P = 0.005), and test-retest
reliability was only moderate across core dimensions of scientific value,
revealing systematic temporal drift in perceived idea quality. Yet the internal
structure of judgment remained stable, such as the relative importance placed
on originality, feasibility, clarity. We then aligned an LLM-based ideation
system to first-wave human ratings and used it to select new ideas. Although
alignment improved agreement with Wave-1 evaluations, its apparent gains
disappeared once drift in human standards was accounted for. Thus, tuning to a
fixed human snapshot produced improvements that were transient rather than
persistent. These findings reveal that human evaluation of scientific ideas is
not static but a dynamic process with stable priorities and requires shifting
calibration. Treating one-time human ratings as immutable ground truth risks
overstating progress in AI-assisted ideation and obscuring the challenge of
co-evolving with changing expert standards. Drift-aware evaluation protocols
and longitudinal benchmarks may therefore be essential for building AI systems
that reliably augment, rather than overfit to, human scientific judgment.

</details>


### [89] [Enhancing Public Speaking Skills in Engineering Students Through AI](https://arxiv.org/abs/2511.04995)
*Amol Harsh,Brainerd Prince,Siddharth Siddharth,Deepan Raj Prabakar Muthirayan,Kabir S Bhalla,Esraaj Sarkar Gupta,Siddharth Sahu*

Main category: cs.HC

TL;DR: 本研究构建了一个AI驱动的公共演讲评估模型，通过多模态技术对演讲进行评估和反馈，帮助工程学生改善沟通能力。


<details>
  <summary>Details</summary>
Motivation: 由于工程学生在有效沟通中面临挑战，本研究旨在通过AI技术提供持续、个性化的公共演讲培训，填补现有教育体系的空白。

Method: 该研究结合了语音分析、计算机视觉和情感检测，形成一个多模态的AI系统，通过评估语言与非语言的沟通方式来提供反馈和评估。

Result: 初步测试显示，AI生成的反馈与专家评估有中等一致性，其中Gemini Pro表现最佳，与人类评审者的意见一致性最高。

Conclusion: 本研究开发的AI驱动评估模型能够提供个性化的公共演讲反馈，帮助工程学生提升沟通能力，尤其在演讲与肢体语言的一致性方面表现良好。

Abstract: This research-to-practice full paper was inspired by the persistent challenge
in effective communication among engineering students. Public speaking is a
necessary skill for future engineers as they have to communicate technical
knowledge with diverse stakeholders. While universities offer courses or
workshops, they are unable to offer sustained and personalized training to
students. Providing comprehensive feedback on both verbal and non-verbal
aspects of public speaking is time-intensive, making consistent and
individualized assessment impractical. This study integrates research on verbal
and non-verbal cues in public speaking to develop an AI-driven assessment model
for engineering students. Our approach combines speech analysis, computer
vision, and sentiment detection into a multi-modal AI system that provides
assessment and feedback. The model evaluates (1) verbal communication (pitch,
loudness, pacing, intonation), (2) non-verbal communication (facial
expressions, gestures, posture), and (3) expressive coherence, a novel
integration ensuring alignment between speech and body language. Unlike
previous systems that assess these aspects separately, our model fuses multiple
modalities to deliver personalized, scalable feedback. Preliminary testing
demonstrated that our AI-generated feedback was moderately aligned with expert
evaluations. Among the state-of-the-art AI models evaluated, all of which were
Large Language Models (LLMs), including Gemini and OpenAI models, Gemini Pro
emerged as the best-performing, showing the strongest agreement with human
annotators. By eliminating reliance on human evaluators, this AI-driven public
speaking trainer enables repeated practice, helping students naturally align
their speech with body language and emotion, crucial for impactful and
professional communication.

</details>


### [90] [Do intelligent tutoring systems benefit K-12 students? A meta-analysis and evaluation of heterogeneity of treatment effects in the U.S](https://arxiv.org/abs/2511.04997)
*Walter L. Leite,Huibin Zhang,Shibani Rana,Yide Hao,Amber D. Hatch,Lingchen Kong,Huan Kuang*

Main category: cs.HC

TL;DR: 本研究通过元分析评估了智能辅导系统对K-12学生学习效果的影响，结果显示整体上存在显著积极效应，但在不同学校环境下效果有所差异。


<details>
  <summary>Details</summary>
Motivation: 为了推广智能辅导系统在K-12学校的应用，有必要了解其最有效的使用条件。

Method: 进行了一项元分析，涵盖18项研究和77个效应大小，分析智能辅导系统在不同学段的效果。

Result: 研究发现，智能辅导系统对美国K-12学生的学习成果总体上有显著的积极效应，但在农村学校的研究中，效应较低。

Conclusion: 智能辅导系统在K-12教育中对学生学习成果有显著的积极影响。

Abstract: To expand the use of intelligent tutoring systems (ITS) in K-12 schools, it
is essential to understand the conditions under which their use is most
beneficial. This meta-analysis evaluated the heterogeneity of ITS effects
across studies focusing on elementary, middle, and high schools in the U.S. It
included 18 studies with 77 effect sizes across 11 ITS. Overall, there was a
significant positive effect size of ITS on U.S. K-12 students' learning
outcomes (g=0.271, SE=0.011, p=0.001). Furthermore, effect sizes were similar
across elementary and middle schools, and for low-achieving students, but were
lower in studies including rural schools. A MetaForest analysis showed that
providing worked-out examples, intervention duration, intervention condition,
type of learning outcome, and immediate measurement were the most important
moderators of treatment effects.

</details>


### [91] [8bit-GPT: Exploring Human-AI Interaction on Obsolete Macintosh Operating Systems](https://arxiv.org/abs/2511.05025)
*Hala Sheta*

Main category: cs.HC

TL;DR: 本研究引入8bit-GPT模型，反思人机交互及其影响，强调对聊天机器人的依赖问题。


<details>
  <summary>Details</summary>
Motivation: 随着聊天机器人的普及，人们在决策和日常任务中对它们的依赖性增加，导致信息保留不足和情感附着表面化，因此有必要反思人机互动的后果。

Method: 通过模拟旧款Macintosh操作系统设计语言模型8bit-GPT，运用缓慢科技和反功能性等反思设计原则，创建一种疏离界面，促成低效互动。

Result: 该研究探讨了助理聊天机器人依赖带来的负面影响，并通过8bit-GPT模型的设计提出了一种促使人们重新反思这种依赖的新方式。

Conclusion: 该研究通过引入8bit-GPT模型，旨在促使人们反思人机交互的本质及其影响，特别是在过度依赖聊天机器人方面。

Abstract: The proliferation of assistive chatbots offering efficient, personalized
communication has driven widespread over-reliance on them for decision-making,
information-seeking and everyday tasks. This dependence was found to have
adverse consequences on information retention as well as lead to superficial
emotional attachment. As such, this work introduces 8bit-GPT; a language model
simulated on a legacy Macintosh Operating System, to evoke reflection on the
nature of Human-AI interaction and the consequences of anthropomorphic
rhetoric. Drawing on reflective design principles such as slow-technology and
counterfunctionality, this work aims to foreground the presence of chatbots as
a tool by defamiliarizing the interface and prioritizing inefficient
interaction, creating a friction between the familiar and not.

</details>


### [92] [VEIL: Reading Control Flow Graphs Like Code](https://arxiv.org/abs/2511.05066)
*Philipp Schaad,Tal Ben-Nun,Torsten Hoefler*

Main category: cs.HC

TL;DR: 这篇论文介绍了专为控制流图可视化设计的标准和VEIL算法，该算法通过支配者分析提高了控制流图的可读性和布局性能。


<details>
  <summary>Details</summary>
Motivation: 控制流图是理解程序行为的重要工具，但实际应用中的控制流图规模庞大，难以解读，因此需要新的可视化方法来提升对程序结构的理解。

Method: 我们提出了一套专门针对控制流图可视化的标准，重点在于保持执行顺序，并使复杂结构更易于理解。基于这些标准，我们开发了VEIL算法，并使用支配者分析生成更清晰、直观的控制流图布局。

Result: 经过对实际应用中控制流图的研究，我们展示了我们的方法如何改善可读性，并提供比最先进的图形绘制技术更好的布局性能。

Conclusion: 我们的研究表明，VEIL算法在提高控制流图的可读性和布局性能方面优于现有的图形绘制技术。

Abstract: Control flow graphs (CFGs) are essential tools for understanding program
behavior, yet the size of real-world CFGs makes them difficult to interpret.
With thousands of nodes and edges, sophisticated graph drawing algorithms are
required to present them on screens in ways that make them readable and
understandable. However, being designed for general graphs, these algorithms
frequently break the natural flow of execution, placing later instructions
before earlier ones and obscuring critical program structures. In this paper,
we introduce a set of criteria specifically tailored for CFG visualization,
focusing on preserving execution order and making complex structures easier to
follow. Building on these criteria, we present VEIL, a new layout algorithm
that uses dominator analysis to produce clearer, more intuitive CFG layouts.
Through a study of CFGs from real-world applications, we show how our method
improves readability and provides improved layout performance compared to state
of the art graph drawing techniques.

</details>


### [93] [Interface Homme-Machine pour l'Identification des Liaisons de Coins](https://arxiv.org/abs/2511.05136)
*Patrice Labedan,Nicolas Drougard*

Main category: cs.HC

TL;DR: ACCADIL项目开发了用于识别钱币铸造链接的软件，结合计算机视觉算法和用户交互界面，为钱币学提供了强大支持。


<details>
  <summary>Details</summary>
Motivation: 旨在发展识别钱币铸造链接的软件工具，提升钱币研究的效率和准确性。

Method: 基于计算机视觉和分类技术的计算算法，结合在线界面进行结果的交互验证。

Result: 开发了一个功能齐全的软件工具，支持数据集添加、可视化模式和结果导出等功能。

Conclusion: ACCADIL为钱币学家提供了一种全面的工具，用于分析钱币藏品中的铸造链接。

Abstract: ACCADIL is a project that led to the development of software tools for the
identification of coin die links from coin photographs. It provides a
computational algorithm based on computer vision and classification techniques,
along with an online interface for the interactive verification of results.
This guide briefly describes the algorithmic principles, the preparation of
data prior to analysis, and the features offered by the interface: dataset
addition, visualization modes (overlay, side-by-side, magnifier, transparency),
result export, and distance visualization. ACCADIL thus provides numismatists
with a comprehensive tool for the analysis of die links within a coin
collection.

</details>


### [94] [psiUnity: A Platform for Multimodal Data-Driven XR](https://arxiv.org/abs/2511.05304)
*Akhil Ajikumar,Sahil Mayenkar,Steven Yoo,Sakib Reza,Mohsen Moghaddam*

Main category: cs.HC

TL;DR: 本论文介绍了psiUnity，这一开源整合解决了HoloLens 2与psi平台的接入问题，实现了多模态数据的实时流传输，促进了XR技术的发展。


<details>
  <summary>Details</summary>
Motivation: 开发者在HoloLens开发中面临psi平台的可接入性问题，因此需要一个解决方案来实现多模态数据的共享和同步。

Method: 通过整合psi的.NET库与Unity的架构，psiUnity实现了双向实时流数据传输，具有微秒级时间精度。

Result: psiUnity使HoloLens 2能够处理头部姿态、手部追踪、视线、IMU、音频和深度传感器数据，推动了HRI、HCI和具身AI社区的发展。

Conclusion: psiUnity为Unity 2022.3和MRTK3提供了一个开源的C#整合，促进了HoloLens 2的多模态数据流和同步，推动了XR交互和实验的发展。

Abstract: Extended reality (XR) research increasingly relies on the ability to stream
and synchronize multimodal data between headsets and immersive applications for
data-driven interaction and experimentation. However, developers face a
critical gap: the Platform for Situated Intelligence (psi), which excels at
deterministic temporal alignment and multimodal data management, has been
largely inaccessible to the dominant Unity/MRTK ecosystem used for HoloLens
development. We introduce psiUnity, an open-source C# integration that bridges
psi's .NET libraries with Unity 2022.3 and MRTK3 for HoloLens 2. psiUnity
enables bidirectional, real-time streaming of head pose, hand tracking, gaze,
IMU, audio, and depth sensor data (AHAT and long-throw) with microsecond-level
temporal precision, allowing Unity applications to both consume and produce
synchronized multimodal data streams. By embedding psi's native serialization,
logging, and temporal coordination directly within Unity's architecture,
psiUnity extends psi beyond its previous StereoKit limitations and empowers the
HRI, HCI, and embodied-AI communities to develop reproducible, data-driven XR
interactions and experiments within the familiar Unity environment. The
integration is available at https://github.com/sailgt/psiUnity.

</details>


### [95] [Semantic Interactivity: leveraging NLP to enable a shared interaction approach for joint activities](https://arxiv.org/abs/2511.05346)
*Olaf V. Adan,Dimitra Dritsa,Steven Houben*

Main category: cs.HC

TL;DR: 本研究提出了一种NLP驱动的语义交互机制，通过互动桌面系统CollEagle支持协作讨论，促进小组互动并为新型协作界面的设计提供了见解。


<details>
  <summary>Details</summary>
Motivation: 现有协作系统主要支持个体任务而非共同活动，缺乏激发共享体验的互动性。

Method: 通过开发CollEagle这一互动桌面系统，提供一个共享的交互机制来支持协作讨论中的信息创建、策划、组织和结构化。

Result: 初步研究显示语义交互在调解小组互动方面具有潜力，提醒未来研究可以在支持共同活动的系统中融入该机制。

Conclusion: 本研究表明，语义交互机制能够促进小组互动，并为设计新型协作界面开辟了道路。

Abstract: Collocated collaboration, where individuals work together in the same
physical space and time, remains a cornerstone of effective teamwork. However,
most collaborative systems are designed to support individual tasks rather than
joint activities; they enable interactions for users to complete tasks rather
than interactivity to engage in shared experiences. In this work, we introduce
an NLP-driven mechanism that enables semantic interactivity through a shared
interaction mechanism. This mechanism was developed as part of CollEagle, an
interactive tabletop system that supports shared externalisation practices by
offering a low-effort way for users to create, curate, organise, and structure
information to capture the essence of collaborative discussions. Our
preliminary study highlights the potential for semantic interactivity to
mediate group interactions, suggesting that the interaction approach paves the
way for designing novel collaborative interfaces. We contribute our
implementation and offer insights for future research to enable semantic
interactivity in systems that support joint activities.

</details>


### [96] [Designing Hierarchical Exploratory Experiences for Ethnic Costumes: A Cultural Gene-Based Perspective](https://arxiv.org/abs/2511.05400)
*Ma Xiaofan,Yan Lirong,Zhao Weijia,Zeng Weiping,Wu Huiyue*

Main category: cs.HC

TL;DR: 本论文提出了一个三层文化基因框架，旨在提升民族服装的数字体验，通过互动平台鼓励用户构建个性化的文化叙事，增强文化认同。


<details>
  <summary>Details</summary>
Motivation: ethnic clothing在文化身份中的重要性，以及现有数字保存方式无法有效传达其深层文化内涵的现状。

Method: 开发并实施了一个互动数字平台，采用‘基因优先’的探索路径和AI共同创作体验。

Result: 平台有效增强了用户的文化认知，加深了情感联系，并显著促进了文化认同感。

Conclusion: 本研究提供了一个验证的框架和实际示例，用于设计生成性、构建身份的数字体验，从而为文化遗产的数字化保存和复兴提供了新路径。

Abstract: Ethnic clothing is a vital carrier of cultural identity, yet its digital
preservation often results in static displays that fail to convey deep cultural
meaning or foster user engagement. Existing practices lack a systematic design
framework for translating the hierarchical cultural connotations of these
garments into dynamic, personalized, and identity-promoting digital
experiences. To address this gap, this paper proposes a Three-Layer Cultural
Gene Framework that systematically decodes ethnic costumes from their
surface-level visual symbols, through their mid-level socio-cultural contexts,
to their inner-layer spiritual core. Based on this framework, we designed and
implemented an interactive digital platform featuring two key innovations: a
"gene-first" exploratory path that encourages curiosity-driven discovery, and
an AI-powered co-creation experience. This generative feature allows users to
co-create personalized narratives and images based on their understanding of
the "inner-layer" genes, transforming them from passive observers into active
co-creators. A mixed-methods user study (N=24) was conducted to evaluate the
platform. The findings demonstrate that our approach effectively enhances
users' cultural cognition, deepens their affective connection, and
significantly promotes their sense of cultural identity. This research
contributes a validated framework and a practical exemplar for designing
generative, identity-building digital experiences for cultural heritage,
offering a new pathway for its preservation and revitalization in the digital
age.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [97] [A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024](https://arxiv.org/abs/2511.04685)
*Daniela Guericke,Rolf van der Hulst,Asal Karimpour,Ieke Schrader,Matthias Walter*

Main category: cs.AI

TL;DR: 本文介绍了团队Twente在2024年综合医疗时间表竞赛中的算法、实现及结果，提出了一种新方法，并分享了见解和未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 动机是为了解决医疗时间安排中的复杂问题并提高竞赛中的表现。

Method: 本研究采用了混合整数规划、约束规划和模拟退火相结合的三阶段解决方案方法，通过将问题分解为子问题进行求解。

Result: 该方法在竞赛中获得了第三名，并首次提供了基准实例的最优解值的下界。

Conclusion: 该研究报告了团队Twente在2024年综合医疗时间表竞赛中取得的第三名成绩，并提出了改进的方向。

Abstract: We report about the algorithm, implementation and results submitted to the
Integrated Healthcare Timetabling Competition 2024 by Team Twente, which scored
third in the competition. Our approach combines mixed-integer programming,
constraint programming and simulated annealing in a 3-phase solution approach
based on decomposition into subproblems. Next to describing our approach and
describing our design decisions, we share our insights and, for the first time,
lower bounds on the optimal solution values for the benchmark instances. We
finally highlight open problems for which we think that addressing them could
improve our approach even further.

</details>


### [98] [Epistemic Reject Option Prediction](https://arxiv.org/abs/2511.04855)
*Vojtech Franc,Jakub Paplham*

Main category: cs.AI

TL;DR: 本文提出了一种新型的认知拒绝选项预测器，能够在数据不足时识别高不确定性的输入，从而优化预测决策。


<details>
  <summary>Details</summary>
Motivation: 在高风险应用中，预测模型不仅需要做出准确的预测，还需要量化和传达其不确定性，现有的方法在数据不足的情况下未能有效处理这种情况。

Method: 基于贝叶斯学习，重新定义了最优预测器为最小化期望遗憾，即学习模型与完全知识下的贝叶斯最优预测器之间的性能差距。

Result: 引入了认知拒绝选项预测器，该模型在预测不确定性高的区域选择放弃，从而提高了模型的可靠性。

Conclusion: 提出了一种新的框架，使得预测模型能够识别数据不足以作出可靠决策的输入，从而能够在高不确定性区域选择放弃预测。

Abstract: In high-stakes applications, predictive models must not only produce accurate
predictions but also quantify and communicate their uncertainty. Reject-option
prediction addresses this by allowing the model to abstain when prediction
uncertainty is high. Traditional reject-option approaches focus solely on
aleatoric uncertainty, an assumption valid only when large training data makes
the epistemic uncertainty negligible. However, in many practical scenarios,
limited data makes this assumption unrealistic. This paper introduces the
epistemic reject-option predictor, which abstains in regions of high epistemic
uncertainty caused by insufficient data. Building on Bayesian learning, we
redefine the optimal predictor as the one that minimizes expected regret -- the
performance gap between the learned model and the Bayes-optimal predictor with
full knowledge of the data distribution. The model abstains when the regret for
a given input exceeds a specified rejection cost. To our knowledge, this is the
first principled framework that enables learning predictors capable of
identifying inputs for which the training data is insufficient to make reliable
decisions.

</details>


### [99] [DMA: Online RAG Alignment with Human Feedback](https://arxiv.org/abs/2511.04880)
*Yu Bai,Yukai Miao,Dawei Wang,Li Chen,Fei Long,Rundi Zhai,Dan Li,Yanyu Ren,Tianfeng Liu,Hongtao Xie,Ce Yang,Xuhui Cai*

Main category: cs.AI

TL;DR: DMA是一种新的在线学习框架，通过整合多层次的人类反馈，显著提升了RAG系统在动态环境中的适应性和人机交互效果。


<details>
  <summary>Details</summary>
Motivation: 传统的静态检索限制了RAG系统对意图和内容变化的适应能力，迫切需要一种新的方法来改善这一点。

Method: 通过引入动态记忆对齐(DMA)框架，系统整合多层次的人类反馈，采用监督训练、政策优化和知识蒸馏等方法。

Result: DMA在大型在线A/B测试和知识密集型基准的少量样本离线测试中均展现出显著的性能提升，尤其在对话问答任务中表现优异。

Conclusion: DMA提供了一种反馈驱动的实时适应方法，使RAG系统能够在不降低基准能力的情况下进行有效调整。

Abstract: Retrieval-augmented generation (RAG) systems often rely on static retrieval,
limiting adaptation to evolving intent and content drift. We introduce Dynamic
Memory Alignment (DMA), an online learning framework that systematically
incorporates multi-granularity human feedback to align ranking in interactive
settings. DMA organizes document-, list-, and response-level signals into a
coherent learning pipeline: supervised training for pointwise and listwise
rankers, policy optimization driven by response-level preferences, and
knowledge distillation into a lightweight scorer for low-latency serving.
Throughout this paper, memory refers to the model's working memory, which is
the entire context visible to the LLM for In-Context Learning.
  We adopt a dual-track evaluation protocol mirroring deployment: (i)
large-scale online A/B ablations to isolate the utility of each feedback
source, and (ii) few-shot offline tests on knowledge-intensive benchmarks.
Online, a multi-month industrial deployment further shows substantial
improvements in human engagement. Offline, DMA preserves competitive
foundational retrieval while yielding notable gains on conversational QA
(TriviaQA, HotpotQA). Taken together, these results position DMA as a
principled approach to feedback-driven, real-time adaptation in RAG without
sacrificing baseline capability.

</details>


### [100] [Real-Time Reasoning Agents in Evolving Environments](https://arxiv.org/abs/2511.04898)
*Yule Wen,Yixin Ye,Yanzhe Zhang,Diyi Yang,Hao Zhu*

Main category: cs.AI

TL;DR: 本研究提出实时推理的新问题表述及训练平台，并通过AgileThinker实现了在动态环境中及时逻辑判断的能力，推动了时间受限AI系统的研究。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的智能体不仅需要逻辑判断，还必须及时做出决策，因此需要不断意识到动态环境中的变化，现有语言模型推理方法未能考虑这一动态特性。

Method: 引入实时推理作为新的问题表述，构建了实时推理训练平台（Real-Time Reasoning Gym），并研究了两种智能体部署语言模型的范式：反应型智能体和规划型智能体。

Result: 尽管采用了最先进的模型，在这两种范式中智能体在逻辑与及时判断上仍然面临挑战。我们的研究提出了AgileThinker，它同时利用两种推理范式，能在任务难度与时间压力增加时保持优越表现。

Conclusion: 本研究建立了实时推理作为开发实用智能体的重要测试平台，并为研究时间受限的人工智能系统提供了基础，指出了实现实时能力智能体的路径。

Abstract: Agents in the real world must make not only logical but also timely
judgments. This requires continuous awareness of the dynamic environment:
hazards emerge, opportunities arise, and other agents act, while the agent's
reasoning is still unfolding. Despite advances in language model reasoning,
existing approaches fail to account for this dynamic nature. We introduce
real-time reasoning as a new problem formulation for agents in evolving
environments and build Real-Time Reasoning Gym to demonstrate it. We study two
paradigms for deploying language models in agents: (1) reactive agents, which
employ language models with bounded reasoning computation for rapid responses,
and (2) planning agents, which allow extended reasoning computation for complex
problems. Our experiments show that even state-of-the-art models struggle with
making logical and timely judgments in either paradigm. To address this
limitation, we propose AgileThinker, which simultaneously engages both
reasoning paradigms. AgileThinker consistently outperforms agents engaging only
one reasoning paradigm as the task difficulty and time pressure rise,
effectively balancing reasoning depth and response latency. Our work
establishes real-time reasoning as a critical testbed for developing practical
agents and provides a foundation for research in temporally constrained AI
systems, highlighting a path toward real-time capable agents.

</details>


### [101] [Autonomous generation of different courses of action in mechanized combat operations](https://arxiv.org/abs/2511.05182)
*Johan Schubert,Patrik Hansen,Pontus Hörling,Ronnie Johansson*

Main category: cs.AI

TL;DR: 本文提出了一种结构化的方法，旨在增强军事地面战斗中的决策支持，通过生成和评估多种行动方案来优化实施效果。


<details>
  <summary>Details</summary>
Motivation: 旨在改善军队在战斗执行阶段的决策过程，特别是在动态战场环境中的应对能力。

Method: 提出了一种生成和评估各种行动方案的体系，针对机械化营的决策支持。

Result: 生成数千个行动替代方案并进行评估，识别出具有较高预期结果的行动路径。

Conclusion: 本方法提供了一种系统化的决策支持，有助于在军事地面作战中优化行动方案。

Abstract: In this paper, we propose a methodology designed to support decision-making
during the execution phase of military ground combat operations, with a focus
on one's actions. This methodology generates and evaluates recommendations for
various courses of action for a mechanized battalion, commencing with an
initial set assessed by their anticipated outcomes. It systematically produces
thousands of individual action alternatives, followed by evaluations aimed at
identifying alternative courses of action with superior outcomes. These
alternatives are appraised in light of the opponent's status and actions,
considering unit composition, force ratios, types of offense and defense, and
anticipated advance rates. Field manuals evaluate battle outcomes and
advancement rates. The processes of generation and evaluation work
concurrently, yielding a variety of alternative courses of action. This
approach facilitates the management of new course generation based on
previously evaluated actions. As the combat unfolds and conditions evolve,
revised courses of action are formulated for the decision-maker within a
sequential decision-making framework.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [102] [TAMAS: Benchmarking Adversarial Risks in Multi-Agent LLM Systems](https://arxiv.org/abs/2511.05269)
*Ishan Kavathekar,Hemang Jain,Ameya Rathod,Ponnurangam Kumaraguru,Tanuja Ganu*

Main category: cs.MA

TL;DR: 本文提出了TAMAS基准，旨在评估多智能体LLM系统的鲁棒性和安全性，指出其在面对敌对攻击时的脆弱性，并强调改进防御措施的必要性。


<details>
  <summary>Details</summary>
Motivation: 随着任务复杂性的增加，多智能体LLM系统的使用逐渐增多，但其安全性和防护问题尚未得到充分研究。

Method: 引入TAMAS基准，通过五种不同的场景和多个对抗实例来评估多智能体LLM系统的鲁棒性和安全性。

Result: TAMAS展示了当前多智能体部署中的关键挑战和失败模式，并引入了有效鲁棒性评分（ERS）来评估安全性与任务有效性之间的权衡。

Conclusion: 多智能体系统对敌对攻击高度脆弱，迫切需要更强的防御措施。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities as
autonomous agents through tool use, planning, and decision-making abilities,
leading to their widespread adoption across diverse tasks. As task complexity
grows, multi-agent LLM systems are increasingly used to solve problems
collaboratively. However, safety and security of these systems remains largely
under-explored. Existing benchmarks and datasets predominantly focus on
single-agent settings, failing to capture the unique vulnerabilities of
multi-agent dynamics and co-ordination. To address this gap, we introduce
$\textbf{T}$hreats and $\textbf{A}$ttacks in $\textbf{M}$ulti-$\textbf{A}$gent
$\textbf{S}$ystems ($\textbf{TAMAS}$), a benchmark designed to evaluate the
robustness and safety of multi-agent LLM systems. TAMAS includes five distinct
scenarios comprising 300 adversarial instances across six attack types and 211
tools, along with 100 harmless tasks. We assess system performance across ten
backbone LLMs and three agent interaction configurations from Autogen and
CrewAI frameworks, highlighting critical challenges and failure modes in
current multi-agent deployments. Furthermore, we introduce Effective Robustness
Score (ERS) to assess the tradeoff between safety and task effectiveness of
these frameworks. Our findings show that multi-agent systems are highly
vulnerable to adversarial attacks, underscoring the urgent need for stronger
defenses. TAMAS provides a foundation for systematically studying and improving
the safety of multi-agent LLM systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [103] [Stateful KV Cache Management for LLMs: Balancing Space, Time, Accuracy, and Positional Fidelity](https://arxiv.org/abs/2511.04686)
*Pratik Poudel*

Main category: cs.LG

TL;DR: 本文调查KV缓存管理对大型语言模型生成质量的影响，提出优化驱逐策略以维护位置编码的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在多轮对话中的应用，KV缓存的无界增长带来了性能挑战。

Method: 通过状态基准测试框架的实证分析，探讨KV缓存管理策略与模型上下文限制及位置编码之间的关系。

Result: 当累积的KV缓存接近或超过模型训练的上下文窗口时，LLM生成质量急剧下降，而常见的驱逐策略可能会进一步恶化性能。

Conclusion: 优化KV缓存管理策略和保持位置编码的完整性对LLM的生成质量至关重要。

Abstract: The Key-Value (KV) cache is integral to efficient autoregressive inference in
large language models (LLMs), yet its unbounded growth in stateful multi-turn
scenarios presents major challenges. This paper examines the interplay between
KV cache management strategies, the architectural context limits of models like
meta-llama/Meta-Llama-3-8b-instruct, and the often-overlooked integrity of
positional encodings. Through empirical analysis using a stateful benchmarking
framework, we show that LLM generation quality degrades sharply when the
accumulated KV cache approaches or exceeds the model's trained context window
(e.g., 8192 tokens for Llama 3), a failure mode distinct from GPU memory
exhaustion. Common eviction strategies, even high-retention ones (e.g., 99% via
AttentionTop), can worsen performance if they disrupt positional coherence.
Because LLMs rely on consistent positional signals (e.g., RoPE), compacting a
cache by removing non-contiguous tokens can scramble these signals and lead to
degenerative outputs. We further show that simple strategies preserving
contiguous context blocks (e.g., keeping an initial "gist") can yield more
coherent generations than complex or positionally disruptive ones. We advocate
for eviction techniques that respect architectural limits, preserve positional
structure, and view "cache health" holistically beyond mere size.

</details>


### [104] [Multi-Agent Craftax: Benchmarking Open-Ended Multi-Agent Reinforcement Learning at the Hyperscale](https://arxiv.org/abs/2511.04904)
*Bassel Al Omari,Michael Matthews,Alexander Rutherford,Jakob Nicolaus Foerster*

Main category: cs.LG

TL;DR: 本文提出了Craftax-MA和Craftax-Coop两个新基准，以评估多智能体强化学习的能力，解决现有基准在长期依赖性和合作方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习基准无法充分评估多智能体系统在长期依赖性和泛化能力方面的表现，因此需要新的基准来推动研究。

Method: 介绍并实现了Craftax-MA和Craftax-Coop两个基准，包括多个智能体、异质智能体以及需要复杂合作的机制。

Result: 分析表明，现有算法在关键挑战（如长时间信用分配、探索和合作）上表现不佳，强调了新基准的必要性和潜力。

Conclusion: Craftax-MA和Craftax-Coop作为新基准，能够有效评估多智能体强化学习算法的能力，推动该领域的长期研究。

Abstract: Progress in multi-agent reinforcement learning (MARL) requires challenging
benchmarks that assess the limits of current methods. However, existing
benchmarks often target narrow short-horizon challenges that do not adequately
stress the long-term dependencies and generalization capabilities inherent in
many multi-agent systems. To address this, we first present
\textit{Craftax-MA}: an extension of the popular open-ended RL environment,
Craftax, that supports multiple agents and evaluates a wide range of general
abilities within a single environment. Written in JAX, \textit{Craftax-MA} is
exceptionally fast with a training run using 250 million environment
interactions completing in under an hour. To provide a more compelling
challenge for MARL, we also present \textit{Craftax-Coop}, an extension
introducing heterogeneous agents, trading and more mechanics that require
complex cooperation among agents for success. We provide analysis demonstrating
that existing algorithms struggle with key challenges in this benchmark,
including long-horizon credit assignment, exploration and cooperation, and
argue for its potential to drive long-term research in MARL.

</details>


### [105] [Regularized GLISp for sensor-guided human-in-the-loop optimization](https://arxiv.org/abs/2511.04751)
*Matteo Cercola,Michele Lomuscio,Dario Piga,Simone Formentin*

Main category: cs.LG

TL;DR: 本研究介绍了一种改进的GLISp方法，将传感器信息纳入偏好学习，显著提升了算法性能。


<details>
  <summary>Details</summary>
Motivation: 在偏好优化中，传统方法忽略了传感器测量信息，限制了算法的有效性。

Method: 通过物理信息假设函数和最小二乘正则化，将可测量的描述符融入偏好学习循环，实现灰箱结构。

Result: 在分析基准和人机协作的车辆悬挂调谐任务中，新方法展示出比基线GLISp更快的收敛速度和更优的最终解。

Conclusion: 提出的传感器引导的GLISp扩展能够更快收敛并取得更优解。

Abstract: Human-in-the-loop calibration is often addressed via preference-based
optimization, where algorithms learn from pairwise comparisons rather than
explicit cost evaluations. While effective, methods such as Preferential
Bayesian Optimization or Global optimization based on active preference
learning with radial basis functions (GLISp) treat the system as a black box
and ignore informative sensor measurements. In this work, we introduce a
sensor-guided regularized extension of GLISp that integrates measurable
descriptors into the preference-learning loop through a physics-informed
hypothesis function and a least-squares regularization term. This injects
grey-box structure, combining subjective feedback with quantitative sensor
information while preserving the flexibility of preference-based search.
Numerical evaluations on an analytical benchmark and on a human-in-the-loop
vehicle suspension tuning task show faster convergence and superior final
solutions compared to baseline GLISp.

</details>


### [106] [When Data Falls Short: Grokking Below the Critical Threshold](https://arxiv.org/abs/2511.04760)
*Vaibhav Singh,Eugene Belilovsky,Rahaf Aljundi*

Main category: cs.LG

TL;DR: 本文研究了grokking现象及其在数据稀缺和分布变化情境下的知识蒸馏应用，表明知识蒸馏能提高模型的泛化能力并减轻灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 探讨在数据稀缺和分布变化的实际场景中，如何解决模型过拟合后延迟泛化的问题。

Method: 研究了在知识蒸馏背景下模型在不同数据分布上实现的延迟泛化现象，即grokking，特别是在数据匮乏时的表现。

Result: 知识蒸馏能加速模型在不同分布之间的grokking过程，即使在数据量不足的情况下，仍能实现有效的模型泛化。

Conclusion: 知识蒸馏作为一种技术，对于在数据稀缺和分布变化场景中，提升模型的泛化能力具有重要意义。

Abstract: In this paper, we investigate the phenomenon of grokking, where models
exhibit delayed generalization following overfitting on training data. We focus
on data-scarce regimes where the number of training samples falls below the
critical threshold, making grokking unobservable, and on practical scenarios
involving distribution shift. We first show that Knowledge Distillation (KD)
from a model that has already grokked on a distribution (p1) can induce and
accelerate grokking on a different distribution (p2), even when the available
data lies below the critical threshold. This highlights the value of KD for
deployed models that must adapt to new distributions under limited data. We
then study training on the joint distribution (p1, p2) and demonstrate that
while standard supervised training fails when either distribution has
insufficient data, distilling from models grokked on the individual
distributions enables generalization. Finally, we examine a continual
pretraining setup, where a grokked model transitions from p1 to p2, and find
that KD both accelerates generalization and mitigates catastrophic forgetting,
achieving strong performance even with only 10% of the data. Together, our
results provide new insights into the mechanics of grokking under knowledge
transfer and underscore the central role of KD in enabling generalization in
low-data and evolving distribution settings.

</details>


### [107] [FuseFlow: A Fusion-Centric Compilation Framework for Sparse Deep Learning on Streaming Dataflow](https://arxiv.org/abs/2511.04768)
*Rubens Lacouture,Nathan Zhang,Ritvik Sharma,Marco Siracusa,Fredrik Kjolstad,Kunle Olukotun,Olivia Hsu*

Main category: cs.LG

TL;DR: FuseFlow是一种针对稀疏机器学习模型的编译器，通过跨表达式融合和多种优化技术在设计空间探索中实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型的规模扩大，效率问题亟需解决，因此开发更加高效的数据流硬件和稀疏计算模型显得尤为重要。

Method: 提出了一种新的编译器FuseFlow，将稀疏的机器学习模型转换为融合的稀疏数据流图，并进行了微架构分析和设计空间探索。

Result: 在四个真实世界的稀疏机器学习应用中，通过FuseFlow实现了约2.7倍的速度提升，表明全融合并非总是最佳选择。

Conclusion: FuseFlow在稀疏机器学习模型的优化中表现出色，通过跨表达式的融合技术实现了显著的性能提升，尤其在处理不同模型时，融合粒度的选择非常关键。

Abstract: As deep learning models scale, sparse computation and specialized dataflow
hardware have emerged as powerful solutions to address efficiency. We propose
FuseFlow, a compiler that converts sparse machine learning models written in
PyTorch to fused sparse dataflow graphs for reconfigurable dataflow
architectures (RDAs). FuseFlow is the first compiler to support general
cross-expression fusion of sparse operations. In addition to fusion across
kernels (expressions), FuseFlow also supports optimizations like
parallelization, dataflow ordering, and sparsity blocking. It targets a
cycle-accurate dataflow simulator for microarchitectural analysis of fusion
strategies. We use FuseFlow for design-space exploration across four real-world
machine learning applications with sparsity, showing that full fusion (entire
cross-expression fusion across all computation in an end-to-end model) is not
always optimal for sparse models-fusion granularity depends on the model
itself. FuseFlow also provides a heuristic to identify and prune suboptimal
configurations. Using Fuseflow, we achieve performance improvements, including
a ~2.7x speedup over an unfused baseline for GPT-3 with BigBird block-sparse
attention.

</details>


### [108] [Conditional Neural ODE for Longitudinal Parkinson's Disease Progression Forecasting](https://arxiv.org/abs/2511.04789)
*Xiaoda Wang,Yuji Zhao,Kaiqiao Han,Xiao Luo,Sanne van Rooij,Jennifer Stevens,Lifang He,Liang Zhan,Yizhou Sun,Wei Wang,Carl Yang*

Main category: cs.LG

TL;DR: 提出一种新的连续建模方法CNODE，用于提高帕金森病的个性化进展预测准确性，实验显示其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 针对帕金森病（PD）患者数据的不规则性和个体差异，通过连续建模来提高预后预测的准确性和个性化。

Method: 使用条件神经常微分方程（CNODE）框架，建模脑部形态变化为连续时间过程，并学习患者特定的初始时间和进展速度。

Result: 在帕金森病进展预测的实验中，CNODE相比于现有最先进的基准方法表现更佳。

Conclusion: CNODE方法在预测帕金森病（PD）进展方面优于现有的基准方法。

Abstract: Parkinson's disease (PD) shows heterogeneous, evolving brain-morphometry
patterns. Modeling these longitudinal trajectories enables mechanistic insight,
treatment development, and individualized 'digital-twin' forecasting. However,
existing methods usually adopt recurrent neural networks and transformer
architectures, which rely on discrete, regularly sampled data while struggling
to handle irregular and sparse magnetic resonance imaging (MRI) in PD cohorts.
Moreover, these methods have difficulty capturing individual heterogeneity
including variations in disease onset, progression rate, and symptom severity,
which is a hallmark of PD. To address these challenges, we propose CNODE
(Conditional Neural ODE), a novel framework for continuous, individualized PD
progression forecasting. The core of CNODE is to model morphological brain
changes as continuous temporal processes using a neural ODE model. In addition,
we jointly learn patient-specific initial time and progress speed to align
individual trajectories into a shared progression trajectory. We validate CNODE
on the Parkinson's Progression Markers Initiative (PPMI) dataset. Experimental
results show that our method outperforms state-of-the-art baselines in
forecasting longitudinal PD progression.

</details>


### [109] [Causal Structure and Representation Learning with Biomedical Applications](https://arxiv.org/abs/2511.04790)
*Caroline Uhler,Jiaqi Zhang*

Main category: cs.LG

TL;DR: 这篇论文提出了一个新的框架，将表示学习与因果推断结合，以利用多模态数据进行因果分析。


<details>
  <summary>Details</summary>
Motivation: 解决表示学习在因果任务中失败的问题，以及利用多模态数据的机会。

Method: 框架结合了多模态数据和因果推断的方法。

Result: 通过该框架，可以更有效地进行因果发现、学习因果变量和设计优化的干预。

Conclusion: 提出了一个统计和计算框架，以促进因果结构和表示学习，为生物医学问题提供解决方案。

Abstract: Massive data collection holds the promise of a better understanding of
complex phenomena and, ultimately, better decisions. Representation learning
has become a key driver of deep learning applications, as it allows learning
latent spaces that capture important properties of the data without requiring
any supervised annotations. Although representation learning has been hugely
successful in predictive tasks, it can fail miserably in causal tasks including
predicting the effect of a perturbation/intervention. This calls for a marriage
between representation learning and causal inference. An exciting opportunity
in this regard stems from the growing availability of multi-modal data
(observational and perturbational, imaging-based and sequencing-based, at the
single-cell level, tissue-level, and organism-level). We outline a statistical
and computational framework for causal structure and representation learning
motivated by fundamental biomedical questions: how to effectively use
observational and perturbational data to perform causal discovery on observed
causal variables; how to use multi-modal views of the system to learn causal
variables; and how to design optimal perturbations.

</details>


### [110] [PuzzleMoE: Efficient Compression of Large Mixture-of-Experts Models via Sparse Expert Merging and Bit-packed inference](https://arxiv.org/abs/2511.04805)
*Yushu Zhao,Zheng Wang,Minjia Zhang*

Main category: cs.LG

TL;DR: PuzzleMoE是一种无训练的MoE压缩方法，通过稀疏专家合并和位打包编码实现高效推理和高准确性，能够在50%压缩比下保持模型表现。


<details>
  <summary>Details</summary>
Motivation: 解决MoE模型在高压缩比下存储和性能瓶颈问题。

Method: 引入双重掩码捕获共享和专家特定参数，使用位打包编码方案实现高效推理。

Result: 在各项任务上，PuzzleMoE在50%压缩比下，准确性提高16.7%，并且推理速度提高1.28倍。

Conclusion: PuzzleMoE有效地压缩了MoE模型，保持了准确性，同时提高了推理速度。

Abstract: Mixture-of-Experts (MoE) models have shown strong potential in scaling
language models efficiently by activating only a small subset of experts per
input. However, their widespread deployment remains limited due to the high
memory overhead associated with storing all expert parameters, particularly as
the number of experts increases. To address this challenge, prior works have
explored expert dropping and merging strategies, yet they often suffer from
performance drop at high compression ratios. In this paper, we introduce
PuzzleMoE, a training-free MoE compression method that achieves both high
accuracy and efficient inference through two key innovations: First, PuzzleMoE
performs sparse expert merging by identifying element-wise weight redundancy
and specialization. It uses a dual-mask to capture both shared and
expert-specific parameters. Second, to avoid the overhead of storing binary
masks and signs, PuzzleMoE introduces a bit-packed encoding scheme that reuses
underutilized exponent bits, enabling efficient MoE inference on GPUs.
Extensive experiments demonstrate that PuzzleMoE can compress MoE models by up
to 50% while maintaining accuracy across various tasks. Specifically, it
outperforms prior MoE compression methods by up to 16.7% on MMLU at 50%
compression ratio, and achieves up to 1.28\times inference speedup.

</details>


### [111] [Autoencoding Dynamics: Topological Limitations and Capabilities](https://arxiv.org/abs/2511.04807)
*Matthew D. Kvalheim,Eduardo D. Sontag*

Main category: cs.LG

TL;DR: 本论文探讨了自编码器在特定数据流形和动态系统中的拓扑特性及映射能力。


<details>
  <summary>Details</summary>
Motivation: 研究数据流形及其在动态系统中的自编码应用，以理解自编码器的拓扑限制与能力。

Method: 通过分析自编码器的构造，重点关注编码器和解码器之间的映射特性。

Result: 阐明了自编码器在数据流形上的映射性能及其对动态系统的适应能力。

Conclusion: 本研究探讨了在数据流形和潜在空间下自编码器的构造及其拓扑限制与能力，特别是在动态系统中的应用。

Abstract: Given a "data manifold" $M\subset \mathbb{R}^n$ and "latent space"
$\mathbb{R}^\ell$, an autoencoder is a pair of continuous maps consisting of an
"encoder" $E\colon \mathbb{R}^n\to \mathbb{R}^\ell$ and "decoder" $D\colon
\mathbb{R}^\ell\to \mathbb{R}^n$ such that the "round trip" map $D\circ E$ is
as close as possible to the identity map $\mbox{id}_M$ on $M$. We present
various topological limitations and capabilites inherent to the search for an
autoencoder, and describe capabilities for autoencoding dynamical systems
having $M$ as an invariant manifold.

</details>


### [112] [Sharp Minima Can Generalize: A Loss Landscape Perspective On Data](https://arxiv.org/abs/2511.04808)
*Raymond Fan,Bryce Sandlund,Lin Myat Ko*

Main category: cs.LG

TL;DR: 本研究探讨了在不同训练数据量下极小值的体积，发现增加数据量可使原本小的良好泛化极小值变得相对较大。


<details>
  <summary>Details</summary>
Motivation: 探讨大数据集在深度学习泛化能力中的作用，尤其是与极小值体积的关系。

Method: 测量在不同训练数据量下的极小值体积。

Result: 发现虽然存在良好泛化的尖锐极小值，但由于其小体积，不容易被找到。

Conclusion: 增加训练数据可以改变损失景观，使得之前较小的具有良好泛化能力的极小值变得相对较大。

Abstract: The volume hypothesis suggests deep learning is effective because it is
likely to find flat minima due to their large volumes, and flat minima
generalize well. This picture does not explain the role of large datasets in
generalization. Measuring minima volumes under varying amounts of training data
reveals sharp minima which generalize well exist, but are unlikely to be found
due to their small volumes. Increasing data changes the loss landscape, such
that previously small generalizing minima become (relatively) large.

</details>


### [113] [A Standardized Benchmark for Multilabel Antimicrobial Peptide Classification](https://arxiv.org/abs/2511.04814)
*Sebastian Ojeda,Rafael Velasquez,Nicolás Aparicio,Juanita Puentes,Paula Cárdenas,Nicolás Andrade,Gabriel González,Sergio Rincón,Carolina Muñoz-Camargo,Pablo Arbeláez*

Main category: cs.LG

TL;DR: 本研究构建了ESCAPE，一个整合80000多肽的数据集，并提出了一种新模型，用于提升抗菌肽的多功能活性预测。


<details>
  <summary>Details</summary>
Motivation: 抗菌肽有潜力对抗抗菌耐药，但存在数据集碎片化、注释不一致和缺乏标准基准等挑战。

Method: 提出了一种基于变换器的模型，利用序列和结构信息来预测肽的多种功能活性。

Result: 在ESCAPE的基础上，我们的方法实现了相对于第二优方法平均精度提高2.56%，建立了最新的多标签肽分类技术。

Conclusion: ESCAPE提供了一个全面和可重复的评估框架，推动了基于AI的抗菌肽研究。

Abstract: Antimicrobial peptides have emerged as promising molecules to combat
antimicrobial resistance. However, fragmented datasets, inconsistent
annotations, and the lack of standardized benchmarks hinder computational
approaches and slow down the discovery of new candidates. To address these
challenges, we present the Expanded Standardized Collection for Antimicrobial
Peptide Evaluation (ESCAPE), an experimental framework integrating over 80.000
peptides from 27 validated repositories. Our dataset separates antimicrobial
peptides from negative sequences and incorporates their functional annotations
into a biologically coherent multilabel hierarchy, capturing activities across
antibacterial, antifungal, antiviral, and antiparasitic classes. Building on
ESCAPE, we propose a transformer-based model that leverages sequence and
structural information to predict multiple functional activities of peptides.
Our method achieves up to a 2.56% relative average improvement in mean Average
Precision over the second-best method adapted for this task, establishing a new
state-of-the-art multilabel peptide classification. ESCAPE provides a
comprehensive and reproducible evaluation framework to advance AI-driven
antimicrobial peptide research.

</details>


### [114] [Prompt-Based Safety Guidance Is Ineffective for Unlearned Text-to-Image Diffusion Models](https://arxiv.org/abs/2511.04834)
*Jiwoo Shin,Byeonghu Na,Mina Kang,Wonhyeok Choi,Il-chul Moon*

Main category: cs.LG

TL;DR: 本文提出了一种新方法，通过概念逆转提高文本生成模型对恶意输入的防御能力，实验结果表明效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决文本生成模型在处理恶意输入时产生有害内容的风险，并改善现有防御方法的兼容性和有效性。

Method: 将负面提示替换为通过概念逆转获得的隐式负嵌入，且无需修改现有的防御方法。

Result: 在裸体和暴力基准测试中验证了方法的有效性，展示了防御成功率的持续改善，同时保持输入提示的核心语义。

Conclusion: 提出了一种新方法，通过使用概念逆转获得的隐式负嵌入替代训练无关方法中使用的负面提示，从而有效提升了防御成功率。

Abstract: Recent advances in text-to-image generative models have raised concerns about
their potential to produce harmful content when provided with malicious input
text prompts. To address this issue, two main approaches have emerged: (1)
fine-tuning the model to unlearn harmful concepts and (2) training-free
guidance methods that leverage negative prompts. However, we observe that
combining these two orthogonal approaches often leads to marginal or even
degraded defense performance. This observation indicates a critical
incompatibility between two paradigms, which hinders their combined
effectiveness. In this work, we address this issue by proposing a conceptually
simple yet experimentally robust method: replacing the negative prompts used in
training-free methods with implicit negative embeddings obtained through
concept inversion. Our method requires no modification to either approach and
can be easily integrated into existing pipelines. We experimentally validate
its effectiveness on nudity and violence benchmarks, demonstrating consistent
improvements in defense success rate while preserving the core semantics of
input prompts.

</details>


### [115] [Sublinear iterations can suffice even for DDPMs](https://arxiv.org/abs/2511.04844)
*Matthew S. Zhang,Stephen Huan,Jerry Huang,Nicholas M. Boffi,Sitan Chen,Sinho Chewi*

Main category: cs.LG

TL;DR: 创新的去噪扩散随机中点方法（DDRaM）在SDE近似中显示出亚线性复杂度，提供实验支持，提升了生成模型的实用性。


<details>
  <summary>Details</summary>
Motivation: 以往的DDPM分析主要集中在指数欧拉离散化，限制了其在维度或初始费舍尔信息上的线性依赖，激发了对更高效采样方法的需求。

Method: 采用去噪扩散随机中点方法（DDRaM）结合新的解析框架“移位组合规则”分析方法的离散化性质。

Result: 通过DDRaM算法的分析，证明该算法在适当的平滑性假设下具有优越的离散化特性，且收敛所需的评分评估为亚线性复杂度。

Conclusion: 该研究提出的去噪扩散随机中点方法在优化SDE近似方面优于现有方法，并提供了实验验证其有效性。

Abstract: SDE-based methods such as denoising diffusion probabilistic models (DDPMs)
have shown remarkable success in real-world sample generation tasks. Prior
analyses of DDPMs have been focused on the exponential Euler discretization,
showing guarantees that generally depend at least linearly on the dimension or
initial Fisher information. Inspired by works in log-concave sampling (Shen and
Lee, 2019), we analyze an integrator -- the denoising diffusion randomized
midpoint method (DDRaM) -- that leverages an additional randomized midpoint to
better approximate the SDE. Using a recently-developed analytic framework
called the "shifted composition rule", we show that this algorithm enjoys
favorable discretization properties under appropriate smoothness assumptions,
with sublinear $\widetilde{O}(\sqrt{d})$ score evaluations needed to ensure
convergence. This is the first sublinear complexity bound for pure DDPM
sampling -- prior works which obtained such bounds worked instead with
ODE-based sampling and had to make modifications to the sampler which deviate
from how they are used in practice. We also provide experimental validation of
the advantages of our method, showing that it performs well in practice with
pre-trained image synthesis models.

</details>


### [116] [Investigating U.S. Consumer Demand for Food Products with Innovative Transportation Certificates Based on Stated Preferences and Machine Learning Approaches](https://arxiv.org/abs/2511.04845)
*Jingchen Bi,Rodrigo Mesa-Arango*

Main category: cs.LG

TL;DR: 本研究利用机器学习模型分析消费者对食品运输相关证书的偏好，发现安全和能源证书受到重视，并提供相关的改进建议。


<details>
  <summary>Details</summary>
Motivation: 基于以往研究，为了深入了解运输因素在消费者食品购买选择中的重要性，开展了本研究。

Method: 利用机器学习模型评估消费者对带有创新运输证书的食品产品的行为，进行两项实验以识别运输因素和消费者偏好。

Result: 发现安全和能源证书在美国食品供应链的运输领域受到消费者的青睐，同时也考察了价格、产品类型、证书和决策者因素对购买选择的影响。

Conclusion: 消费者对食品运输领域中安全和能源证书表现出显著偏好，本研究提供了改善食品供应链系统的数据驱动建议。

Abstract: This paper utilizes a machine learning model to estimate the consumer's
behavior for food products with innovative transportation certificates in the
U.S. Building on previous research that examined demand for food products with
supply chain traceability using stated preference analysis, transportation
factors were identified as significant in consumer food purchasing choices.
Consequently, a second experiment was conducted to pinpoint the specific
transportation attributes valued by consumers. A machine learning model was
applied, and five innovative certificates related to transportation were
proposed: Transportation Mode, Internet of Things (IoT), Safety measures,
Energy Source, and Must Arrive By Dates (MABDs). The preference experiment also
incorporated product-specific and decision-maker factors for control purposes.
The findings reveal a notable inclination toward safety and energy certificates
within the transportation domain of the U.S. food supply chain. Additionally,
the study examined the influence of price, product type, certificates, and
decision-maker factors on purchasing choices. Ultimately, the study offers
data-driven recommendations for improving food supply chain systems.

</details>


### [117] [SigmaDock: Untwisting Molecular Docking With Fragment-Based SE(3) Diffusion](https://arxiv.org/abs/2511.04854)
*Alvaro Prat,Leo Zhang,Charlotte M. Deane,Yee Whye Teh,Garrett M. Morris*

Main category: cs.LG

TL;DR: SigmaDock 是一种新型分子对接方法，通过将配体分解为刚体片段并在 SE(3) 中生成构象，克服了传统方法的多种挑战，显著超越了经典物理基础对接的表现。


<details>
  <summary>Details</summary>
Motivation: 分子对接是药物发现中的基本任务，生成性方法比基于物理的方法在速度、改进和多样性采样方面有优势，但常常受到化学不可能输出、泛化能力差和高计算成本的困扰。

Method: 介绍了一种新颖的分解方案，通过将配体分解为刚体片段，利用结构化学的归纳偏见，提出了 SigmaDock，一个 SE(3) Riemannian 扩散模型，该模型通过学习在结合口内重新组装这些刚体来生成构象。

Result: 实验表明，SigmaDock 在 PoseBusters 数据集上达到超过 79.9% 的 Top-1 成功率（RMSD<2 和 PB-valid），相比近期的深度学习方法（12.7-30.8%），展现出对未见蛋白质的可靠泛化能力。

Conclusion: SigmaDock 是首个在 PB 训练测试拆分中超越经典物理基础对接的深度学习方法，为分子建模的可靠性和可行性带来了重大进展。

Abstract: Determining the binding pose of a ligand to a protein, known as molecular
docking, is a fundamental task in drug discovery. Generative approaches promise
faster, improved, and more diverse pose sampling than physics-based methods,
but are often hindered by chemically implausible outputs, poor
generalisability, and high computational cost. To address these challenges, we
introduce a novel fragmentation scheme, leveraging inductive biases from
structural chemistry, to decompose ligands into rigid-body fragments. Building
on this decomposition, we present SigmaDock, an SE(3) Riemannian diffusion
model that generates poses by learning to reassemble these rigid bodies within
the binding pocket. By operating at the level of fragments in SE(3), SigmaDock
exploits well-established geometric priors while avoiding overly complex
diffusion processes and unstable training dynamics. Experimentally, we show
SigmaDock achieves state-of-the-art performance, reaching Top-1 success rates
(RMSD<2 & PB-valid) above 79.9% on the PoseBusters set, compared to 12.7-30.8%
reported by recent deep learning approaches, whilst demonstrating consistent
generalisation to unseen proteins. SigmaDock is the first deep learning
approach to surpass classical physics-based docking under the PB train-test
split, marking a significant leap forward in the reliability and feasibility of
deep learning for molecular modelling.

</details>


### [118] [Quantum Boltzmann Machines for Sample-Efficient Reinforcement Learning](https://arxiv.org/abs/2511.04856)
*Thore Gerlach,Michael Schenk,Verena Kain*

Main category: cs.LG

TL;DR: 介绍了一种支持连续动作强化学习的CSQBM模型，通过混合量子-经典的方法提高模型稳定性和表达能力。


<details>
  <summary>Details</summary>
Motivation: 为连续动作强化学习提供更强的模型表达力，并减少对量子比特的需求。

Method: 通过结合可见单元的指数族先验和隐藏单元的量子Boltzmann分布，提出了一种混合量子-经典模型。

Result: 提出连续Q学习框架，通过从CSQBM分布进行有效采样来克服连续控制中的不稳定性问题。

Conclusion: CSQBMs facilitate efficient continuous-action reinforcement learning by addressing instability issues through improved sampling methods.

Abstract: We introduce theoretically grounded Continuous Semi-Quantum Boltzmann
Machines (CSQBMs) that supports continuous-action reinforcement learning. By
combining exponential-family priors over visible units with quantum Boltzmann
distributions over hidden units, CSQBMs yield a hybrid quantum-classical model
that reduces qubit requirements while retaining strong expressiveness.
Crucially, gradients with respect to continuous variables can be computed
analytically, enabling direct integration into Actor-Critic algorithms.
Building on this, we propose a continuous Q-learning framework that replaces
global maximization by efficient sampling from the CSQBM distribution, thereby
overcoming instability issues in continuous control.

</details>


### [119] [FoodRL: A Reinforcement Learning Ensembling Framework For In-Kind Food Donation Forecasting](https://arxiv.org/abs/2511.04865)
*Esha Sharma,Lauren Davis,Julie Ivy,Min Chi*

Main category: cs.LG

TL;DR: FoodRL利用强化学习提升食物银行的预测准确性，能在不稳定环境中有效分配资源，并每年额外提供170万餐的食物。


<details>
  <summary>Details</summary>
Motivation: 解决传统预测模型在面对季节性变化和自然灾害等不可预测波动时的准确性不足问题。

Method: 提出了一种基于强化学习的元学习框架，能够动态地对不同预测模型进行聚类和加权。

Result: FoodRL在面对自然灾害等干扰期间，能够比基线方法提供更可靠的预测，预计可实现每年额外分发170万餐的粮食。

Conclusion: FoodRL展示了在复杂、动态环境中进行有效预测的重大潜力，能够显著提高食物银行的资源分配效率，进而对社会产生积极影响。

Abstract: Food banks are crucial for alleviating food insecurity, but their
effectiveness hinges on accurately forecasting highly volatile in-kind
donations to ensure equitable and efficient resource distribution. Traditional
forecasting models often fail to maintain consistent accuracy due to
unpredictable fluctuations and concept drift driven by seasonal variations and
natural disasters such as hurricanes in the Southeastern U.S. and wildfires in
the West Coast. To address these challenges, we propose FoodRL, a novel
reinforcement learning (RL) based metalearning framework that clusters and
dynamically weights diverse forecasting models based on recent performance and
contextual information. Evaluated on multi-year data from two structurally
distinct U.S. food banks-one large regional West Coast food bank affected by
wildfires and another state-level East Coast food bank consistently impacted by
hurricanes, FoodRL consistently outperforms baseline methods, particularly
during periods of disruption or decline. By delivering more reliable and
adaptive forecasts, FoodRL can facilitate the redistribution of food equivalent
to 1.7 million additional meals annually, demonstrating its significant
potential for social impact as well as adaptive ensemble learning for
humanitarian supply chains.

</details>


### [120] [You Need Reasoning to Learn Reasoning: The Limitations of Label-Free RL in Weak Base Models](https://arxiv.org/abs/2511.04902)
*Shuvendu Roy,Hossein Hajimirsadeghi,Mengyao Zhai,Golnoosh Samei*

Main category: cs.LG

TL;DR: 本文系统研究了无标签强化学习在不同模型中的表现，并提出基于课程学习的方法，有效提升推理能力。


<details>
  <summary>Details</summary>
Motivation: 探索无标签强化学习方法在不同规模和推理能力的基础模型上的适用性，解决小模型推理能力不足的问题。

Method: 通过课程学习逐步引入更难的问题进行训练，以及在训练中掩蔽非主流的回合。

Result: 提出的方法在所有模型规模和推理能力上均表现出持续的改进。

Conclusion: 提出了一种基于课程学习的无标签强化学习方法，可以有效提高不同规模模型的推理能力，尤其是资源有限的模型。

Abstract: Recent advances in large language models have demonstrated the promise of
unsupervised reinforcement learning (RL) methods for enhancing reasoning
capabilities without external supervision. However, the generalizability of
these label-free RL approaches to smaller base models with limited reasoning
capabilities remains unexplored. In this work, we systematically investigate
the performance of label-free RL methods across different model sizes and
reasoning strengths, from 0.5B to 7B parameters. Our empirical analysis reveals
critical limitations: label-free RL is highly dependent on the base model's
pre-existing reasoning capability, with performance often degrading below
baseline levels for weaker models. We find that smaller models fail to generate
sufficiently long or diverse chain-of-thought reasoning to enable effective
self-reflection, and that training data difficulty plays a crucial role in
determining success. To address these challenges, we propose a simple yet
effective method for label-free RL that utilizes curriculum learning to
progressively introduce harder problems during training and mask no-majority
rollouts during training. Additionally, we introduce a data curation pipeline
to generate samples with predefined difficulty. Our approach demonstrates
consistent improvements across all model sizes and reasoning capabilities,
providing a path toward more robust unsupervised RL that can bootstrap
reasoning abilities in resource-constrained models. We make our code available
at https://github.com/BorealisAI/CuMa

</details>


### [121] [Efficient Swap Multicalibration of Elicitable Properties](https://arxiv.org/abs/2511.04907)
*Lunjia Hu,Haipeng Luo,Spandan Senapati,Vatsal Sharan*

Main category: cs.LG

TL;DR: 本文推广了多重校准的概念并提出了一种高效算法，显著降低了多重校准误差，实现了对开放问题的积极回答。


<details>
  <summary>Details</summary>
Motivation: 提出更高效的算法以实现更低的多重校准误差，同时解决广泛关注的开放性问题。

Method: 将多重校准从群组成员函数推广到任意有界假设类，并引入swap多重校准的概念，基于具有界限序列Rademacher复杂度的假设类，提出了新的算法。

Result: 展示了给定在线不可知学习算法的情况下，算法能够以高概率实现$T^{1/(r+1)}$的$	ext{l}_r$-swap多重校准误差，特别在$r=2$的情况下，误差为$T^{1/3}$，超越了已有边界。

Conclusion: 本研究提出了一种新的oracle高效算法，实现了对可引发属性的swap多重校准错误的显著改进，尤其在Mean多重校准的情况下，从之前的界限提升到$T^{1/3}$，并积极回应了一个开放性问题。

Abstract: Multicalibration [HJKRR18] is an algorithmic fairness perspective that
demands that the predictions of a predictor are correct conditional on
themselves and membership in a collection of potentially overlapping subgroups
of a population. The work of [NR23] established a surprising connection between
multicalibration for an arbitrary property $\Gamma$ (e.g., mean or median) and
property elicitation: a property $\Gamma$ can be multicalibrated if and only if
it is elicitable, where elicitability is the notion that the true property
value of a distribution can be obtained by solving a regression problem over
the distribution. In the online setting, [NR23] proposed an inefficient
algorithm that achieves $\sqrt T$ $\ell_2$-multicalibration error for a
hypothesis class of group membership functions and an elicitable property
$\Gamma$, after $T$ rounds of interaction between a forecaster and adversary.
  In this paper, we generalize multicalibration for an elicitable property
$\Gamma$ from group membership functions to arbitrary bounded hypothesis
classes and introduce a stronger notion -- swap multicalibration, following
[GKR23]. Subsequently, we propose an oracle-efficient algorithm which, when
given access to an online agnostic learner, achieves $T^{1/(r+1)}$
$\ell_r$-swap multicalibration error with high probability (for $r\ge2$) for a
hypothesis class with bounded sequential Rademacher complexity and an
elicitable property $\Gamma$. For the special case of $r=2$, this implies an
oracle-efficient algorithm that achieves $T^{1/3}$ $\ell_2$-swap
multicalibration error, which significantly improves on the previously
established bounds for the problem [NR23, GMS25, LSS25a], and completely
resolves an open question raised in [GJRR24] on the possibility of an
oracle-efficient algorithm that achieves $\sqrt{T}$ $\ell_2$-mean
multicalibration error by answering it in a strongly affirmative sense.

</details>


### [122] [A Dual Perspective on Decision-Focused Learning: Scalable Training via Dual-Guided Surrogates](https://arxiv.org/abs/2511.04909)
*Paula Rodriguez-Diaz,Kirk Bansak Elisabeth Paulson*

Main category: cs.LG

TL;DR: 本文提出了Dual-Guided Loss (DGL)作为一种新方法，旨在在保持决策对齐的同时，减少对求解器的依赖，提高训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 在不确定性下进行决策时，通过优化问题解决方案来提高下游决策的性能，面对现有方法在规模化中的挑战。

Method: 提出了一个新的目标Dual-Guided Loss (DGL)，适用于组合选择问题，并通过周期性求解下游问题来解耦优化和梯度更新。

Result: DGL在两个问题类上表现出超过或匹配最新的决策聚焦学习（DFL）方法，同时调用求解器的次数更少，训练时间显著更短。

Conclusion: DGL在决策对齐方面保持强大性能，同时显著减少了求解器调用和训练时间。

Abstract: Many real-world decisions are made under uncertainty by solving optimization
problems using predicted quantities. This predict-then-optimize paradigm has
motivated decision-focused learning, which trains models with awareness of how
the optimizer uses predictions, improving the performance of downstream
decisions. Despite its promise, scaling is challenging: state-of-the-art
methods either differentiate through a solver or rely on task-specific
surrogates, both of which require frequent and expensive calls to an optimizer,
often a combinatorial one. In this paper, we leverage dual variables from the
downstream problem to shape learning and introduce Dual-Guided Loss (DGL), a
simple, scalable objective that preserves decision alignment while reducing
solver dependence. We construct DGL specifically for combinatorial selection
problems with natural one-of-many constraints, such as matching, knapsack, and
shortest path. Our approach (a) decouples optimization from gradient updates by
solving the downstream problem only periodically; (b) between refreshes, trains
on dual-adjusted targets using simple differentiable surrogate losses; and (c)
as refreshes become less frequent, drives training cost toward standard
supervised learning while retaining strong decision alignment. We prove that
DGL has asymptotically diminishing decision regret, analyze runtime complexity,
and show on two problem classes that DGL matches or exceeds state-of-the-art
DFL methods while using far fewer solver calls and substantially less training
time. Code is available at https://github.com/paularodr/Dual-Guided-Learning.

</details>


### [123] [Machine Learning Algorithms in Statistical Modelling Bridging Theory and Application](https://arxiv.org/abs/2511.04918)
*A. Ganapathi Rao,Sathish Krishna Anumula,Aditya Kumar Singh,Renukhadevi M,Y. Jeevan Nagendra Kumar,Tammineni Rama Tulasi*

Main category: cs.LG

TL;DR: 本文探讨了机器学习算法与传统统计模型的结合，展示了混合模型在多个方面的提升。


<details>
  <summary>Details</summary>
Motivation: 探索机器学习算法如何增强传统模型，并提高数据分析和预测的能力。

Method: 研究现代机器学习算法与传统统计模型的结合方式。

Result: 新算法改善了传统模型的性能、规模、灵活性和鲁棒性。

Conclusion: 混合模型在预测准确性、鲁棒性和可解释性方面有显著提升。

Abstract: It involves the completely novel ways of integrating ML algorithms with
traditional statistical modelling that has changed the way we analyze data, do
predictive analytics or make decisions in the fields of the data. In this
paper, we study some ML and statistical model connections to understand ways in
which some modern ML algorithms help 'enrich' conventional models; we
demonstrate how new algorithms improve performance, scale, flexibility and
robustness of the traditional models. It shows that the hybrid models are of
great improvement in predictive accuracy, robustness, and interpretability

</details>


### [124] [Leak@$k$: Unlearning Does Not Make LLMs Forget Under Probabilistic Decoding](https://arxiv.org/abs/2511.04934)
*Hadi Reisizadeh,Jiajun Ruan,Yiwei Chen,Soumyadeep Pal,Sijia Liu,Mingyi Hong*

Main category: cs.LG

TL;DR: 本研究表明，现有的反学习方法在实践中未能实现真正的遗忘，知识泄漏现象普遍存在，亟需改进。


<details>
  <summary>Details</summary>
Motivation: 为了确保合规性和构建道德的生成性人工智能系统，反学习在大语言模型中至关重要。

Method: 引入新的元评估指标leak@$k$，通过生成模型的标准概率解码样本来量化遗忘知识重新出现的可能性。

Result: 通过广泛采用的基准测试TOFU、MUSE和WMDP进行的系统研究，发现知识泄漏在不同的方法和任务中持续存在。

Conclusion: 当前的最先进的反学习技术仅提供有限的遗忘，迫切需要更强健的方法来处理大语言模型的反学习问题。

Abstract: Unlearning in large language models (LLMs) is critical for regulatory
compliance and for building ethical generative AI systems that avoid producing
private, toxic, illegal, or copyrighted content. Despite rapid progress, in
this work we show that \textit{almost all} existing unlearning methods fail to
achieve true forgetting in practice. Specifically, while evaluations of these
`unlearned' models under deterministic (greedy) decoding often suggest
successful knowledge removal using standard benchmarks (as has been done in the
literature), we show that sensitive information reliably resurfaces when models
are sampled with standard probabilistic decoding. To rigorously capture this
vulnerability, we introduce \texttt{leak@$k$}, a new meta-evaluation metric
that quantifies the likelihood of forgotten knowledge reappearing when
generating $k$ samples from the model under realistic decoding strategies.
Using three widely adopted benchmarks, TOFU, MUSE, and WMDP, we conduct the
first large-scale, systematic study of unlearning reliability using our newly
defined \texttt{leak@$k$} metric. Our findings demonstrate that knowledge
leakage persists across methods and tasks, underscoring that current
state-of-the-art unlearning techniques provide only limited forgetting and
highlighting the urgent need for more robust approaches to LLM unlearning.

</details>


### [125] [Structural Properties, Cycloid Trajectories and Non-Asymptotic Guarantees of EM Algorithm for Mixed Linear Regression](https://arxiv.org/abs/2511.04937)
*Zhankun Luo,Abolfazl Hashemi*

Main category: cs.LG

TL;DR: 本工作探讨期望最大化算法在两组分混合线性回归中的结构特性及其收敛性，提供了全新轨迹基础的分析框架。


<details>
  <summary>Details</summary>
Motivation: 目前EM算法在完全未知情况下的理论行为尚不清晰，细致研究其收敛性及轨迹能为实际应用提供理论支持。

Method: 通过推导EM更新表达式，并分析其结构特性和周期轨迹。

Result: 在无噪声情况下，证明EM迭代中的回归参数轨迹呈周期轨迹；在高信噪比条件下量化其与周期轨迹的差异，并确立了收敛阶。

Conclusion: 本研究为具有未知混合权重和回归参数的两组分混合线性回归中的期望最大化算法提供了新的基于轨迹的分析框架。

Abstract: This work investigates the structural properties, cycloid trajectories, and
non-asymptotic convergence guarantees of the Expectation-Maximization (EM)
algorithm for two-component Mixed Linear Regression (2MLR) with unknown mixing
weights and regression parameters. Recent studies have established global
convergence for 2MLR with known balanced weights and super-linear convergence
in noiseless and high signal-to-noise ratio (SNR) regimes. However, the
theoretical behavior of EM in the fully unknown setting remains unclear, with
its trajectory and convergence order not yet fully characterized. We derive
explicit EM update expressions for 2MLR with unknown mixing weights and
regression parameters across all SNR regimes and analyze their structural
properties and cycloid trajectories. In the noiseless case, we prove that the
trajectory of the regression parameters in EM iterations traces a cycloid by
establishing a recurrence relation for the sub-optimality angle, while in high
SNR regimes we quantify its discrepancy from the cycloid trajectory. The
trajectory-based analysis reveals the order of convergence: linear when the EM
estimate is nearly orthogonal to the ground truth, and quadratic when the angle
between the estimate and ground truth is small at the population level. Our
analysis establishes non-asymptotic guarantees by sharpening bounds on
statistical errors between finite-sample and population EM updates, relating
EM's statistical accuracy to the sub-optimality angle, and proving convergence
with arbitrary initialization at the finite-sample level. This work provides a
novel trajectory-based framework for analyzing EM in Mixed Linear Regression.

</details>


### [126] [Risk Prediction of Cardiovascular Disease for Diabetic Patients with Machine Learning and Deep Learning Techniques](https://arxiv.org/abs/2511.04971)
*Esha Chowdhury*

Main category: cs.LG

TL;DR: 本研究提出了一种创新的心血管疾病风险预测模型，并验证了机器学习和深度学习在糖尿病患者中的应用效果。


<details>
  <summary>Details</summary>
Motivation: 应对糖尿病日益普遍与其与心脏疾病密切相关的问题，开发一个高效的心血管疾病风险预测模型。

Method: 使用机器学习和混合深度学习方法，分析和处理BRFSS数据集，实施多种模型并比较其准确性和表现。

Result: XGBoost和LSTM模型均达到0.9050的最高准确率，一些深度学习模型实现了完美的召回率，表明模型在CVD风险预测中的潜力。

Conclusion: 该研究表明机器学习和深度学习模型在预测糖尿病患者心血管疾病风险方面的有效性，能够自动化并增强临床决策，提升个性化风险管理和预防策略。

Abstract: Accurate prediction of cardiovascular disease (CVD) risk is crucial for
healthcare institutions. This study addresses the growing prevalence of
diabetes and its strong link to heart disease by proposing an efficient CVD
risk prediction model for diabetic patients using machine learning (ML) and
hybrid deep learning (DL) approaches. The BRFSS dataset was preprocessed by
removing duplicates, handling missing values, identifying categorical and
numerical features, and applying Principal Component Analysis (PCA) for feature
extraction. Several ML models, including Decision Trees (DT), Random Forest
(RF), k-Nearest Neighbors (KNN), Support Vector Machine (SVM), AdaBoost, and
XGBoost, were implemented, with XGBoost achieving the highest accuracy of
0.9050. Various DL models, such as Artificial Neural Networks (ANN), Deep
Neural Networks (DNN), Recurrent Neural Networks (RNN), Convolutional Neural
Networks (CNN), Long Short-Term Memory (LSTM), Bidirectional LSTM (BiLSTM), and
Gated Recurrent Unit (GRU), as well as hybrid models combining CNN with LSTM,
BiLSTM, and GRU, were also explored. Some of these models achieved perfect
recall (1.00), with the LSTM model achieving the highest accuracy of 0.9050.
Our research highlights the effectiveness of ML and DL models in predicting CVD
risk among diabetic patients, automating and enhancing clinical
decision-making. High accuracy and F1 scores demonstrate these models'
potential to improve personalized risk management and preventive strategies.

</details>


### [127] [Less Is More: Generating Time Series with LLaMA-Style Autoregression in Simple Factorized Latent Spaces](https://arxiv.org/abs/2511.04973)
*Siyuan Li,Yifan Sun,Lei Cheng,Lewen Wang,Yang Liu,Weiqing Liu,Jianlong Li,Jiang Bian,Shikai Fang*

Main category: cs.LG

TL;DR: FAR-TS是一个高效的框架，可快速生成高质量的多变量时间序列，克服了现有方法的速度和灵活性限制。


<details>
  <summary>Details</summary>
Motivation: 当前主流的扩散基础方法速度慢且局限于固定长度窗口，因此需要一种快速且灵活的生成框架。

Method: 将解耦因子化与自回归Transformer结合，利用离散量化的潜在空间生成时间序列。

Result: FAR-TS的生成速度比Diffusion-TS快几个数量级，同时保持了交叉通道相关性和可解释的潜在空间。

Conclusion: FAR-TS提供了一种高效、灵活的多变量时间序列生成方法，能够快速生成高质量序列并保持交叉通道相关性。

Abstract: Generative models for multivariate time series are essential for data
augmentation, simulation, and privacy preservation, yet current
state-of-the-art diffusion-based approaches are slow and limited to
fixed-length windows. We propose FAR-TS, a simple yet effective framework that
combines disentangled factorization with an autoregressive Transformer over a
discrete, quantized latent space to generate time series. Each time series is
decomposed into a data-adaptive basis that captures static cross-channel
correlations and temporal coefficients that are vector-quantized into discrete
tokens. A LLaMA-style autoregressive Transformer then models these token
sequences, enabling fast and controllable generation of sequences with
arbitrary length. Owing to its streamlined design, FAR-TS achieves
orders-of-magnitude faster generation than Diffusion-TS while preserving
cross-channel correlations and an interpretable latent space, enabling
high-quality and flexible time series synthesis.

</details>


### [128] [Scaling Up ROC-Optimizing Support Vector Machines](https://arxiv.org/abs/2511.04979)
*Gimun Bae,Seung Jun Shin*

Main category: cs.LG

TL;DR: 本研究提出了一种可扩展的ROC-SVM变体，通过不完全U统计量降低计算复杂度，并在非线性分类中应用低秩核近似，显著提高训练效率。


<details>
  <summary>Details</summary>
Motivation: ROC-SVM作为一种处理类别不平衡的二分类方法，受限于高计算成本，急需改进。

Method: 通过利用不完全U统计量，提出一款可扩展的ROC-SVM变体，并利用低秩核近似扩展至非线性分类。

Result: 在合成和真实数据集上，验证结果表明，所提方法在AUC性能上与原ROC-SVM相当，但训练时间显著减少。

Conclusion: 所提出的方法在保持ROC-SVM性能的同时，大幅降低了训练时间，适合处理不平衡数据的二分类问题。

Abstract: The ROC-SVM, originally proposed by Rakotomamonjy, directly maximizes the
area under the ROC curve (AUC) and has become an attractive alternative of the
conventional binary classification under the presence of class imbalance.
However, its practical use is limited by high computational cost, as training
involves evaluating all $O(n^2)$. To overcome this limitation, we develop a
scalable variant of the ROC-SVM that leverages incomplete U-statistics, thereby
substantially reducing computational complexity. We further extend the
framework to nonlinear classification through a low-rank kernel approximation,
enabling efficient training in reproducing kernel Hilbert spaces. Theoretical
analysis establishes an error bound that justifies the proposed approximation,
and empirical results on both synthetic and real datasets demonstrate that the
proposed method achieves comparable AUC performance to the original ROC-SVM
with drastically reduced training time.

</details>


### [129] [Unlocking the Black Box: A Five-Dimensional Framework for Evaluating Explainable AI in Credit Risk](https://arxiv.org/abs/2511.04980)
*Rongbin Ye,Jiaqi Chen*

Main category: cs.LG

TL;DR: 本文探讨了如何在金融行业中平衡机器学习模型的性能与可解释性，提出了一个评价模型可解释性的五维框架，展示了高性能模型能够在监管环境中有效应用的可能性。


<details>
  <summary>Details</summary>
Motivation: 金融行业面临的挑战是如何在先进机器学习模型的可预测性与监管机构所需的可解释性之间找到平衡。

Method: 提出了一个五维框架，评估内在可解释性、全局解释、本地解释、一致性和复杂性，以比较和评估模型的可解释性。

Result: 研究表明，更复杂的模型可以达到与简单模型相同的可解释性水平，阐明了使用SHAP和LIME等技术的效果。

Conclusion: 该研究展示了在受监管的金融环境中应用先进的机器学习模型的可行性，利用现代可解释性技术，提供了评估模型性能与可解释性之间关键权衡的系统化方法。

Abstract: The financial industry faces a significant challenge modeling and risk
portfolios: balancing the predictability of advanced machine learning models,
neural network models, and explainability required by regulatory entities (such
as Office of the Comptroller of the Currency, Consumer Financial Protection
Bureau). This paper intends to fill the gap in the application between these
"black box" models and explainability frameworks, such as LIME and SHAP.
Authors elaborate on the application of these frameworks on different models
and demonstrates the more complex models with better prediction powers could be
applied and reach the same level of the explainability, using SHAP and LIME.
Beyond the comparison and discussion of performances, this paper proposes a
novel five dimensional framework evaluating Inherent Interpretability, Global
Explanations, Local Explanations, Consistency, and Complexity to offer a
nuanced method for assessing and comparing model explainability beyond simple
accuracy metrics. This research demonstrates the feasibility of employing
sophisticated, high performing ML models in regulated financial environments by
utilizing modern explainability techniques and provides a structured approach
to evaluate the crucial trade offs between model performance and
interpretability.

</details>


### [130] [Deep Progressive Training: scaling up depth capacity of zero/one-layer models](https://arxiv.org/abs/2511.04981)
*Zhiqi Bu*

Main category: cs.LG

TL;DR: 本文提出零/一层渐进训练方法，通过优化模型深度与计算成本之间的平衡，显著提高训练效率。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型的加深，其准确性虽提高但计算成本也随之增加，寻找有效的训练策略成为亟需解决的问题。

Method: 研究大型模型的深度扩展，通过优化理论和特征学习的视角，提出了新的层初始化、超参数转移、学习率调度及模型扩展时机的方法。

Result: 零/一层渐进训练在GPT2模型上节省约80%的计算能力，或等效于以约5倍的速度加快训练，同时几乎保证相同的损失。

Conclusion: 提出的零/一层渐进训练方法在计算和损失之间实现了最佳平衡，能够显著提高训练效率。

Abstract: Model depth is a double-edged sword in deep learning: deeper models achieve
higher accuracy but require higher computational cost. To efficiently train
models at scale, an effective strategy is the progressive training, which
scales up model capacity during training, hence significantly reducing
computation with little to none performance degradation. In this work, we study
the depth expansion of large models through the lens of optimization theory and
feature learning, offering insights on the initialization of new layers,
hyperparameter transfer, learning rate schedule, and timing of model expansion.
Specifically, we propose zero/one-layer progressive training for the optimal
tradeoff between computation and loss. For example, zero/one-layer progressive
training on GPT2 can save $\approx 80\%$ compute, or equivalently accelerate
$\approx 5\times$ while achieving almost the same loss, compared to to a fully
trained 60-layer model with 7B parameters.

</details>


### [131] [Carbon Price Forecasting with Structural Breaks: A Comparative Study of Deep Learning Models](https://arxiv.org/abs/2511.04988)
*Runsheng Ren,Jing Li,Yanxiu Li,Shixun Huang,Jun Shen,Wanqing Li,John Le,Sheng Wang*

Main category: cs.LG

TL;DR: 本研究提出了一种新的框架，通过结合结构断点检测和深度学习模型，显著提高了碳价格预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 准确预测碳价格对于能源市场决策、可持续能源规划和有效的脱碳策略至关重要，但由于政策干预和市场冲击造成的结构性断裂和高频噪声，使得这一过程面临挑战。

Method: 本研究采用混合框架，结合结构断点检测（包括Bai-Perron、ICSS和PELT算法）、小波信号去噪和三种先进的深度学习模型（LSTM、GRU和TCN）进行碳价格预测。

Result: 实验结果表明，提出的PELT-WT-TCN模型在预测精度方面优于现有的基准模型，RMSE和MAE分别减少22.35%和18.63%。

Conclusion: 这项研究提出的PELT-WT-TCN框架在碳价格预测中显示出显著提高的精度，强调了将结构意识和多尺度分解融入深度学习架构的重要性。

Abstract: Accurately forecasting carbon prices is essential for informed energy market
decision-making, guiding sustainable energy planning, and supporting effective
decarbonization strategies. However, it remains challenging due to structural
breaks and high-frequency noise caused by frequent policy interventions and
market shocks. Existing studies, including the most recent baseline approaches,
have attempted to incorporate breakpoints but often treat denoising and
modeling as separate processes and lack systematic evaluation across advanced
deep learning architectures, limiting the robustness and the generalization
capability. To address these gaps, this paper proposes a comprehensive hybrid
framework that integrates structural break detection (Bai-Perron, ICSS, and
PELT algorithms), wavelet signal denoising, and three state-of-the-art deep
learning models (LSTM, GRU, and TCN). Using European Union Allowance (EUA) spot
prices from 2007 to 2024 and exogenous features such as energy prices and
policy indicators, the framework constructs univariate and multivariate
datasets for comparative evaluation. Experimental results demonstrate that our
proposed PELT-WT-TCN achieves the highest prediction accuracy, reducing
forecasting errors by 22.35% in RMSE and 18.63% in MAE compared to the
state-of-the-art baseline model (Breakpoints with Wavelet and LSTM), and by
70.55% in RMSE and 74.42% in MAE compared to the original LSTM without
decomposition from the same baseline study. These findings underscore the value
of integrating structural awareness and multiscale decomposition into deep
learning architectures to enhance accuracy and interpretability in carbon price
forecasting and other nonstationary financial time series.

</details>


### [132] [BiPETE: A Bi-Positional Embedding Transformer Encoder for Risk Assessment of Alcohol and Substance Use Disorder with Electronic Health Records](https://arxiv.org/abs/2511.04998)
*Daniel S. Lee,Mayra S. Haedo-Cruz,Chen Jiang,Oshin Miranda,LiRong Wang*

Main category: cs.LG

TL;DR: 本研究提出BiPETE模型，通过结合新型位置嵌入方式，有效提高了精神健康领域的疾病风险预测性能。


<details>
  <summary>Details</summary>
Motivation: 应对电子健康记录中因不规则就诊间隔和缺乏统一结构带来的时间建模挑战。

Method: 提出Bi-Positional Embedding Transformer Encoder (BiPETE)，结合旋转位置嵌入和正弦嵌入来建模时间依赖性。

Result: 在抑郁症和创伤后压力障碍（PTSD）人群中，BiPETE分别提高了34%和50%的精准召回曲线下面积（AUPRC），并通过消融研究确认了双重位置编码策略的有效性。

Conclusion: 本研究提出了一种实用且可解释的疾病风险预测框架，通过电子健康记录数据实现强性能。

Abstract: Transformer-based deep learning models have shown promise for disease risk
prediction using electronic health records(EHRs), but modeling temporal
dependencies remains a key challenge due to irregular visit intervals and lack
of uniform structure. We propose a Bi-Positional Embedding Transformer Encoder
or BiPETE for single-disease prediction, which integrates rotary positional
embeddings to encode relative visit timing and sinusoidal embeddings to
preserve visit order. Without relying on large-scale pretraining, BiPETE is
trained on EHR data from two mental health cohorts-depressive disorder and
post-traumatic stress disorder (PTSD)-to predict the risk of alcohol and
substance use disorders (ASUD). BiPETE outperforms baseline models, improving
the area under the precision-recall curve (AUPRC) by 34% and 50% in the
depression and PTSD cohorts, respectively. An ablation study further confirms
the effectiveness of the dual positional encoding strategy. We apply the
Integrated Gradients method to interpret model predictions, identifying key
clinical features associated with ASUD risk and protection, such as abnormal
inflammatory, hematologic, and metabolic markers, as well as specific
medications and comorbidities. Overall, these key clinical features identified
by the attribution methods contribute to a deeper understanding of the risk
assessment process and offer valuable clues for mitigating potential risks. In
summary, our study presents a practical and interpretable framework for disease
risk prediction using EHR data, which can achieve strong performance.

</details>


### [133] [Multi-agent Coordination via Flow Matching](https://arxiv.org/abs/2511.05005)
*Dongsu Lee,Daehee Lee,Amy Zhang*

Main category: cs.LG

TL;DR: MAC-Flow是一种新的框架，用于多智能体协调，兼顾了性能和实时执行效率，显著提升了推理速度。


<details>
  <summary>Details</summary>
Motivation: 传统方法在复杂协调与计算效率之间存在矛盾，MAC-Flow旨在解决这一问题。

Method: 通过学习基于流的联合行为表示，并将其提炼为去中心化的一步策略，MAC-Flow提高了实时执行效率。

Result: 在四个基准测试中，MAC-Flow的推理速度比扩散基础的MARL方法快约14.5倍，同时保持良好的性能，推理速度类似于之前的高斯策略基础的离线MARL方法。

Conclusion: MAC-Flow在多智能体协调中有效地平衡了性能与计算成本，实现了快速推理和良好表现。

Abstract: This work presents MAC-Flow, a simple yet expressive framework for
multi-agent coordination. We argue that requirements of effective coordination
are twofold: (i) a rich representation of the diverse joint behaviors present
in offline data and (ii) the ability to act efficiently in real time. However,
prior approaches often sacrifice one for the other, i.e., denoising
diffusion-based solutions capture complex coordination but are computationally
slow, while Gaussian policy-based solutions are fast but brittle in handling
multi-agent interaction. MAC-Flow addresses this trade-off by first learning a
flow-based representation of joint behaviors, and then distilling it into
decentralized one-step policies that preserve coordination while enabling fast
execution. Across four different benchmarks, including $12$ environments and
$34$ datasets, MAC-Flow alleviates the trade-off between performance and
computational cost, specifically achieving about $\boldsymbol{\times14.5}$
faster inference compared to diffusion-based MARL methods, while maintaining
good performance. At the same time, its inference speed is similar to that of
prior Gaussian policy-based offline multi-agent reinforcement learning (MARL)
methods.

</details>


### [134] [OvA-LP: A Simple and Efficient Framework for Federated Learning on Non-IID Data](https://arxiv.org/abs/2511.05028)
*Dongjin Park,Hasung Yeo,Joon-Woo Lee*

Main category: cs.LG

TL;DR: OvA-LP是一个新框架，通过抑制局部漂移，提升了联邦微调在异构数据上的性能。


<details>
  <summary>Details</summary>
Motivation: 针对现有方法在极端非独立同分布条件下的脆弱性，旨在从源头抑制漂移。

Method: 引入一种最小化框架OvA-LP，结合冻结编码器上的线性探测和一对多的头部，以及简单的两阶段程序。

Result: 在CIFAR-100上，OvA-LP保持了95.9%的 IID 准确率，相比之下，其他最先进的FFT基线仅保留了10.1%和34.5%。此外，在标签噪音条件下，OvA-LP也表现出良好的鲁棒性。

Conclusion: OvA-LP在异构数据情况下提供了一种原则性和高效的框架，有效抑制了局部漂移。

Abstract: Federated fine-tuning (FFT) adapts foundation models to decentralized data
but remains fragile under heterogeneous client distributions due to local
drift, i.e., client-level update divergences that induce systematic bias and
amplified variance in the global model. Existing aggregation and
personalization methods largely correct drift post hoc, which proves brittle
under extreme non-IID conditions. We introduce OvA-LP, a minimalist framework
that is, to our knowledge, the first explicitly designed to suppress drift at
its source within the PEFT-based FFT paradigm. OvA-LP combines linear probing
on a frozen encoder with a one-vs-all head and a simple two-stage procedure,
preserving pretrained feature geometry and decoupling logits to prevent the
mechanisms that amplify drift. On CIFAR-100 with 100 clients, averaged over
shard-1, shard-2, and Bernoulli-Dirichlet partitions, OvA-LP retains 95.9% of
its IID accuracy, whereas state-of-the-art FFT baselines retain only 10.1%
(PFPT) and 34.5% (FFT-MoE) under the same conditions. OvA-LP further maintains
resilience under both symmetric and asymmetric label noise. In addition,
precomputing encoder features makes per-round cost nearly independent of
encoder size. Together, these results demonstrate that OvA-LP provides a
principled and efficient basis for robust FFT under heterogeneity.

</details>


### [135] [Usando LLMs para Programar Jogos de Tabuleiro e Variações](https://arxiv.org/abs/2511.05114)
*Álvaro Guglielmin Becker,Lana Bertoldo Rossato,Anderson Rocha Tavares*

Main category: cs.LG

TL;DR: 本研究探讨了大型语言模型在生成棋盘游戏代码方面的能力，旨在减少开发时间。


<details>
  <summary>Details</summary>
Motivation: 由于传统棋盘游戏程序的开发耗时较长，因此探索大型语言模型在这一领域的应用潜力具有重要意义。

Method: 通过对比测试三种大型语言模型（Claude、DeepSeek和ChatGPT）在棋盘游戏代码生成任务上的表现，评估它们的能力。

Result: 测试结果表明，三种模型在生成新游戏变体和现有游戏代码方面表现出色，显示出LLM在游戏开发中的可行性。

Conclusion: 三种大型语言模型在生成棋盘游戏代码方面展现出一定的能力，未来可以进一步优化以提高效率和准确性。

Abstract: Creating programs to represent board games can be a time-consuming task.
Large Language Models (LLMs) arise as appealing tools to expedite this process,
given their capacity to efficiently generate code from simple contextual
information. In this work, we propose a method to test how capable three LLMs
(Claude, DeepSeek and ChatGPT) are at creating code for board games, as well as
new variants of existing games.

</details>


### [136] [QuAnTS: Question Answering on Time Series](https://arxiv.org/abs/2511.05124)
*Felix Divo,Maurice Kraus,Anh Q. Nguyen,Hao Xue,Imran Razzak,Flora D. Salim,Kristian Kersting,Devendra Singh Dhami*

Main category: cs.LG

TL;DR: 本研究创建了QuAnTS数据集以支持时间序列问答，旨在推动相关领域的研究和应用。


<details>
  <summary>Details</summary>
Motivation: 针对当前时间序列问答研究不足的现状，提出QuAnTS数据集，以促进与时间序列模型的交互和改进决策。

Method: 通过丰富的实验验证QuAnTS数据集的有效性，并评估现有和新提出的基线模型。

Result: QuAnTS数据集经过全面评估，功能完整并适合于人类动作的问答研究，提供了人类表现作为基准。

Conclusion: 本研究提出的QuAnTS数据集为时间序列问答提供了新的挑战，促进了时间序列模型的研究和决策过程的透明度。

Abstract: Text offers intuitive access to information. This can, in particular,
complement the density of numerical time series, thereby allowing improved
interactions with time series models to enhance accessibility and
decision-making. While the creation of question-answering datasets and models
has recently seen remarkable growth, most research focuses on question
answering (QA) on vision and text, with time series receiving minute attention.
To bridge this gap, we propose a challenging novel time series QA (TSQA)
dataset, QuAnTS, for Question Answering on Time Series data. Specifically, we
pose a wide variety of questions and answers about human motion in the form of
tracked skeleton trajectories. We verify that the large-scale QuAnTS dataset is
well-formed and comprehensive through extensive experiments. Thoroughly
evaluating existing and newly proposed baselines then lays the groundwork for a
deeper exploration of TSQA using QuAnTS. Additionally, we provide human
performances as a key reference for gauging the practical usability of such
models. We hope to encourage future research on interacting with time series
models through text, enabling better decision-making and more transparent
systems.

</details>


### [137] [Consecutive Preferential Bayesian Optimization](https://arxiv.org/abs/2511.05163)
*Aras Erarslan,Carlos Sevilla Salcedo,Ville Tanskanen,Anni Nisov,Eero Päiväkumpu,Heikki Aisala,Kaisu Honkapää,Arto Klami,Petrus Mikkola*

Main category: cs.LG

TL;DR: 本研究提出了一种新的优先贝叶斯优化方法，考虑了生产和评估成本，显著提高了在高生产成本和模糊反馈环境中的优化准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的优先优化方法忽视了生成候选解的成本，因此需要一种新的方法来更好地处理生产和评估成本。

Method: 引入了连续优先贝叶斯优化，结合了生产成本约束和感知模糊的概率偏好模型。

Result: 我们通过实证实验展示了在高生产成本或反馈模糊情况下，优化准确性的显著提高。

Conclusion: 通过将生产和评估成本纳入考虑，我们的研究显著提高了在高生产成本或模糊反馈情况下的优化准确性。

Abstract: Preferential Bayesian optimization allows optimization of objectives that are
either expensive or difficult to measure directly, by relying on a minimal
number of comparative evaluations done by a human expert. Generating candidate
solutions for evaluation is also often expensive, but this cost is ignored by
existing methods. We generalize preference-based optimization to explicitly
account for production and evaluation costs with Consecutive Preferential
Bayesian Optimization, reducing production cost by constraining comparisons to
involve previously generated candidates. We also account for the perceptual
ambiguity of the oracle providing the feedback by incorporating a
Just-Noticeable Difference threshold into a probabilistic preference model to
capture indifference to small utility differences. We adapt an
information-theoretic acquisition strategy to this setting, selecting new
configurations that are most informative about the unknown optimum under a
preference model accounting for the perceptual ambiguity. We empirically
demonstrate a notable increase in accuracy in setups with high production costs
or with indifference feedback.

</details>


### [138] [Multimodal Deep Learning for Prediction of Progression-Free Survival in Patients with Neuroendocrine Tumors Undergoing 177Lu-based Peptide Receptor Radionuclide Therapy](https://arxiv.org/abs/2511.05169)
*Simon Baur,Tristan Ruhwedel,Ekin Böke,Zuzanna Kobus,Gergana Lishkova,Christoph Wetz,Holger Amthauer,Christoph Roderburg,Frank Tacke,Julian M. Rogasch,Wojciech Samek,Henning Jann,Jackie Ma,Johannes Eschrich*

Main category: cs.LG

TL;DR: 本研究探讨了多模态深度学习在预测转移性神经内分泌肿瘤患者接受PRRT后无进展生存期的有效性，结果显示多模态模型优于单一模型，为个体化治疗提供支持。


<details>
  <summary>Details</summary>
Motivation: 由于PRRT只在部分患者中实现长期疾病控制，预测无进展生存期（PFS）有助于个体化治疗规划。

Method: 回顾性单中心研究，分析116名接受177Lu-DOTATOC治疗的转移性神经内分泌肿瘤患者，训练七种模型（包括单模态和多模态融合方法）来分类低PFS和高PFS组。

Result: 短期PFS（< 1年）患者占36%，与长期PFS患者相比，短期PFS患者的基线肿瘤标记物较高以及PRRT周期较少。多模态融合模型达到了最佳预测效果（AUROC 0.72）。

Conclusion: 多模态深度学习模型在预测PRRT治疗后的无进展生存期（PFS）中优于单模态方法，并可能支持风险适应性随访策略。

Abstract: Peptide receptor radionuclide therapy (PRRT) is an established treatment for
metastatic neuroendocrine tumors (NETs), yet long-term disease control occurs
only in a subset of patients. Predicting progression-free survival (PFS) could
support individualized treatment planning. This study evaluates laboratory,
imaging, and multimodal deep learning models for PFS prediction in PRRT-treated
patients. In this retrospective, single-center study 116 patients with
metastatic NETs undergoing 177Lu-DOTATOC were included. Clinical
characteristics, laboratory values, and pretherapeutic somatostatin receptor
positron emission tomography/computed tomographies (SR-PET/CT) were collected.
Seven models were trained to classify low- vs. high-PFS groups, including
unimodal (laboratory, SR-PET, or CT) and multimodal fusion approaches.
Explainability was evaluated by feature importance analysis and gradient maps.
Forty-two patients (36%) had short PFS (< 1 year), 74 patients long PFS (>1
year). Groups were similar in most characteristics, except for higher baseline
chromogranin A (p = 0.003), elevated gamma-GT (p = 0.002), and fewer PRRT
cycles (p < 0.001) in short-PFS patients. The Random Forest model trained only
on laboratory biomarkers reached an AUROC of 0.59 +- 0.02. Unimodal
three-dimensional convolutional neural networks using SR-PET or CT performed
worse (AUROC 0.42 +- 0.03 and 0.54 +- 0.01, respectively). A multimodal fusion
model laboratory values, SR-PET, and CT -augmented with a pretrained CT branch
- achieved the best results (AUROC 0.72 +- 0.01, AUPRC 0.80 +- 0.01).
Multimodal deep learning combining SR-PET, CT, and laboratory biomarkers
outperformed unimodal approaches for PFS prediction after PRRT. Upon external
validation, such models may support risk-adapted follow-up strategies.

</details>


### [139] [Model Merging Improves Zero-Shot Generalization in Bioacoustic Foundation Models](https://arxiv.org/abs/2511.05171)
*Davide Marincione,Donato Crisostomi,Roberto Dessi,Emanuele Rodolà,Emanuele Rossi*

Main category: cs.LG

TL;DR: 这篇论文研究了NatureLM模型在生物声学中的应用，提出通过模型合并策略来提升其指令遵循能力，并显著改善了未见物种的分类性能。


<details>
  <summary>Details</summary>
Motivation: 探讨在细化的领域模型（NatureLM）与指令遵循灵活性之间的权衡，寻找更好的解决方案。

Method: 应用简单的模型合并策略，将NatureLM与其基础语言模型进行插值。

Result: 合并模型恢复了指令遵循能力，且在未见物种的分类精度上显著提升。

Conclusion: 合并模型在未见物种的封闭集零-shot分类中设置了新的最先进水平，并大幅提高了零-shot泛化能力。

Abstract: Foundation models capable of generalizing across species and tasks represent
a promising new frontier in bioacoustics, with NatureLM being one of the most
prominent examples. While its domain-specific fine-tuning yields strong
performance on bioacoustic benchmarks, we observe that it also introduces
trade-offs in instruction-following flexibility. For instance, NatureLM
achieves high accuracy when prompted for either the common or scientific name
individually, but its accuracy drops significantly when both are requested in a
single prompt. We address this by applying a simple model merging strategy that
interpolates NatureLM with its base language model, recovering
instruction-following capabilities with minimal loss of domain expertise.
Finally, we show that the merged model exhibits markedly stronger zero-shot
generalization, achieving over a 200% relative improvement and setting a new
state-of-the-art in closed-set zero-shot classification of unseen species.

</details>


### [140] [APP: Accelerated Path Patching with Task-Specific Pruning](https://arxiv.org/abs/2511.05442)
*Frauke Andersen,William Rudman,Ruochen Zhang,Carsten Eickhoff*

Main category: cs.LG

TL;DR: 本研究提出了加速路径拼接（APP）方法，通过对比注意力头修剪减少电路发现方法的搜索空间，从而提高效率。


<details>
  <summary>Details</summary>
Motivation: 电路发现是机械可解释性管道中的关键步骤，但现有方法计算开销大且分析能力有限。

Method: 提出了加速路径拼接（APP）方法，通过对比注意力头修剪和传统路径拼接相结合来优化电路发现。

Result: APP方法平均减少了56%的搜索空间，速度提升了59.63%-93.27%。

Conclusion: APP显著减少了电路发现方法的搜索空间，并提高了计算效率，尽管得到的电路与现有方法有较大重叠。

Abstract: Circuit discovery is a key step in many mechanistic interpretability
pipelines. Current methods, such as Path Patching, are computationally
expensive and have limited in-depth circuit analysis for smaller models. In
this study, we propose Accelerated Path Patching (APP), a hybrid approach
leveraging our novel contrastive attention head pruning method to drastically
reduce the search space of circuit discovery methods. Our Contrastive-FLAP
pruning algorithm uses techniques from causal mediation analysis to assign
higher pruning scores to task-specific attention heads, leading to higher
performing sparse models compared to traditional pruning techniques. Although
Contrastive-FLAP is successful at preserving task-specific heads that existing
pruning algorithms remove at low sparsity ratios, the circuits found by
Contrastive-FLAP alone are too large to satisfy the minimality constraint
required in circuit analysis. APP first applies Contrastive-FLAP to reduce the
search space on required for circuit discovery algorithms by, on average, 56\%.
Next, APP, applies traditional Path Patching on the remaining attention heads,
leading to a speed up of 59.63\%-93.27\% compared to Path Patching applied to
the dense model. Despite the substantial computational saving that APP
provides, circuits obtained from APP exhibit substantial overlap and similar
performance to previously established Path Patching circuits

</details>


### [141] [Associative Poisoning to Generative Machine Learning](https://arxiv.org/abs/2511.05177)
*Mathias Lundteigen Mohus,Jingyue Li,Zhirong Yang*

Main category: cs.LG

TL;DR: 本研究提出了一种新型数据投毒方法，能在不控制训练过程的情况下，微妙地操控生成模型的输出特征，论证其理论可行性并提供反制策略。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型（如Stable Diffusion和ChatGPT）的广泛采用，其成为恶意利用的目标，尤其是在数据投毒方面。

Method: 提出了一种名为关联性投毒的新型数据投毒技术，能够在不控制训练过程的情况下，操控生成数据的细粒度特征。

Result: 通过对两种最先进的生成模型的实证评估，证明关联性投毒有效诱导或抑制特征关联，同时保持目标特征的边际分布和高质量输出，逃避视觉检测。

Conclusion: 生成系统在图像合成、合成数据集生成和自然语言处理等领域容易受到微妙且隐蔽的操控，损害其统计完整性。

Abstract: The widespread adoption of generative models such as Stable Diffusion and
ChatGPT has made them increasingly attractive targets for malicious
exploitation, particularly through data poisoning. Existing poisoning attacks
compromising synthesised data typically either cause broad degradation of
generated data or require control over the training process, limiting their
applicability in real-world scenarios. In this paper, we introduce a novel data
poisoning technique called associative poisoning, which compromises
fine-grained features of the generated data without requiring control of the
training process. This attack perturbs only the training data to manipulate
statistical associations between specific feature pairs in the generated
outputs. We provide a formal mathematical formulation of the attack and prove
its theoretical feasibility and stealthiness. Empirical evaluations using two
state-of-the-art generative models demonstrate that associative poisoning
effectively induces or suppresses feature associations while preserving the
marginal distributions of the targeted features and maintaining high-quality
outputs, thereby evading visual detection. These results suggest that
generative systems used in image synthesis, synthetic dataset generation, and
natural language processing are susceptible to subtle, stealthy manipulations
that compromise their statistical integrity. To address this risk, we examine
the limitations of existing defensive strategies and propose a novel
countermeasure strategy.

</details>


### [142] [ActiTect: A Generalizable Machine Learning Pipeline for REM Sleep Behavior Disorder Screening through Standardized Actigraphy](https://arxiv.org/abs/2511.05221)
*David Bertram,Anja Ophey,Sinah Röttgen,Konstantin Kuffer,Gereon R. Fink,Elke Kalbe,Clint Hansen,Walter Maetzler,Maximilian Kapsecker,Lara M. Reimer,Stephan Jonas,Andreas T. Damgaard,Natasha B. Bertelsen,Casper Skjaerbaek,Per Borghammer,Karolien Groenewald,Pietro-Luca Ratti,Michele T. Hu,No émie Moreau,Michael Sommerauer,Katarzyna Bozek*

Main category: cs.LG

TL;DR: 本研究开发了ActiTect，一个开源的机器学习工具，能够自动识别iRBD，展现出高效的性能和广泛的应用潜力，支持跨数据集的一致性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 由于iRBD是α-突触核蛋白病的主要前驱标志，构建一个可靠的自动化分析工具对于大规模筛查和早期检测至关重要。

Method: 本研究通过对78名个体进行模型开发，使用嵌套交叉验证来提高模型的准确性，并进行了不同数据集的验证以确认模型的泛化能力。

Result: 在嵌套交叉验证中，模型的AUROC为0.95；在盲测试集（n = 31）和两个独立外部队列中，AUROC分别为0.86、0.84和0.94，证明了模型的有效性和稳定性。

Conclusion: ActiTect是一个开源的机器学习工具，能够有效识别iRBD，具有良好的通用性和实用性，促进了RBD检测模型的推广和验证。

Abstract: Isolated rapid eye movement sleep behavior disorder (iRBD) is a major
prodromal marker of $\alpha$-synucleinopathies, often preceding the clinical
onset of Parkinson's disease, dementia with Lewy bodies, or multiple system
atrophy. While wrist-worn actimeters hold significant potential for detecting
RBD in large-scale screening efforts by capturing abnormal nocturnal movements,
they become inoperable without a reliable and efficient analysis pipeline. This
study presents ActiTect, a fully automated, open-source machine learning tool
to identify RBD from actigraphy recordings. To ensure generalizability across
heterogeneous acquisition settings, our pipeline includes robust preprocessing
and automated sleep-wake detection to harmonize multi-device data and extract
physiologically interpretable motion features characterizing activity patterns.
Model development was conducted on a cohort of 78 individuals, yielding strong
discrimination under nested cross-validation (AUROC = 0.95). Generalization was
confirmed on a blinded local test set (n = 31, AUROC = 0.86) and on two
independent external cohorts (n = 113, AUROC = 0.84; n = 57, AUROC = 0.94). To
assess real-world robustness, leave-one-dataset-out cross-validation across the
internal and external cohorts demonstrated consistent performance (AUROC range
= 0.84-0.89). A complementary stability analysis showed that key predictive
features remained reproducible across datasets, supporting the final pooled
multi-center model as a robust pre-trained resource for broader deployment. By
being open-source and easy to use, our tool promotes widespread adoption and
facilitates independent validation and collaborative improvements, thereby
advancing the field toward a unified and generalizable RBD detection model
using wearable devices.

</details>


### [143] [The Causal Round Trip: Generating Authentic Counterfactuals by Eliminating Information Loss](https://arxiv.org/abs/2511.05236)
*Rui Wu,Lizheng Wang,Yongjun Li*

Main category: cs.LG

TL;DR: 本研究提出了一种新框架，解决了因果推理中因果信息保留的挑战，结合了现代生成模型与经典因果理论的优势。


<details>
  <summary>Details</summary>
Motivation: 解决复杂非线性机制的潜在外生噪声的精准推断所面临的计算挑战。

Method: 引入BELM-MDCM框架，消除结构重构误差（SRE），并通过目标建模策略和混合训练目标实现强因果归纳偏见。

Result: 开发了零SRE框架，达到了最先进的准确性，并能够提供高保真、个体级的反事实推断。

Conclusion: 本研究提供了一种基础蓝图，将现代生成模型的强大能力与经典因果理论的严谨性相结合，为新兴领域建立了一个更严格的标准。

Abstract: Judea Pearl's vision of Structural Causal Models (SCMs) as engines for
counterfactual reasoning hinges on faithful abduction: the precise inference of
latent exogenous noise. For decades, operationalizing this step for complex,
non-linear mechanisms has remained a significant computational challenge. The
advent of diffusion models, powerful universal function approximators, offers a
promising solution. However, we argue that their standard design, optimized for
perceptual generation over logical inference, introduces a fundamental flaw for
this classical problem: an inherent information loss we term the Structural
Reconstruction Error (SRE). To address this challenge, we formalize the
principle of Causal Information Conservation (CIC) as the necessary condition
for faithful abduction. We then introduce BELM-MDCM, the first diffusion-based
framework engineered to be causally sound by eliminating SRE by construction
through an analytically invertible mechanism. To operationalize this framework,
a Targeted Modeling strategy provides structural regularization, while a Hybrid
Training Objective instills a strong causal inductive bias. Rigorous
experiments demonstrate that our Zero-SRE framework not only achieves
state-of-the-art accuracy but, more importantly, enables the high-fidelity,
individual-level counterfactuals required for deep causal inquiries. Our work
provides a foundational blueprint that reconciles the power of modern
generative models with the rigor of classical causal theory, establishing a new
and more rigorous standard for this emerging field.

</details>


### [144] [An End-to-End Deep Reinforcement Learning Approach for Solving the Traveling Salesman Problem with Drones](https://arxiv.org/abs/2511.05265)
*Taihelong Zeng,Yun Lin,Yuhe Shi,Yan Li,Zhiqing Wei,Xuanru Ji*

Main category: cs.LG

TL;DR: 本研究提出了一种高效的深度强化学习框架，用于解决复杂的旅行商问题，表现出较好的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 针对TSP-D问题的复杂性，探索深度强化学习在优化最后一公里物流中的应用。

Method: 采用分层Actor-Critic框架，结合Transformer编码器和高效的Minimal Gated Unit解码器。

Result: 在不同规模的基准TSP-D实例上，提出的模型能够在较短的计算时间内获得竞争性或更优的解决方案。

Conclusion: 该研究提出的分层Actor-Critic深度强化学习框架在解决TSP-D问题上表现出色，具有较高的训练效率和竞争力的解决方案。

Abstract: The emergence of truck-drone collaborative systems in last-mile logistics has
positioned the Traveling Salesman Problem with Drones (TSP-D) as a pivotal
extension of classical routing optimization, where synchronized vehicle
coordination promises substantial operational efficiency and reduced
environmental impact, yet introduces NP-hard combinatorial complexity beyond
the reach of conventional optimization paradigms. Deep reinforcement learning
offers a theoretically grounded framework to address TSP-D's inherent
challenges through self-supervised policy learning and adaptive
decision-making. This study proposes a hierarchical Actor-Critic deep
reinforcement learning framework for solving the TSP-D problem. The
architecture consists of two primary components: a Transformer-inspired encoder
and an efficient Minimal Gated Unit decoder. The encoder incorporates a novel,
optimized k-nearest neighbors sparse attention mechanism specifically for
focusing on relevant spatial relationships, further enhanced by the integration
of global node features. The Minimal Gated Unit decoder processes these encoded
representations to efficiently generate solution sequences. The entire
framework operates within an asynchronous advantage actor-critic paradigm.
Experimental results show that, on benchmark TSP-D instances of various scales
(N=10 to 100), the proposed model can obtain competitive or even superior
solutions in shorter average computation times compared to high-performance
heuristic algorithms and existing reinforcement learning methods. Moreover,
compared to advanced reinforcement learning algorithm benchmarks, the proposed
framework significantly reduces the total training time required while
achieving superior final performance, highlighting its notable advantage in
training efficiency.

</details>


### [145] [Embedding-Space Data Augmentation to Prevent Membership Inference Attacks in Clinical Time Series Forecasting](https://arxiv.org/abs/2511.05289)
*Marius Fracarolli,Michael Staniek,Stefan Riezler*

Main category: cs.LG

TL;DR: 本研究探讨了数据增强如何减轻时间序列预测模型的会员推断攻击，发现ZOO-PCA方法在不影响测试性能的情况下，最佳地降低了攻击的TPR/FPR比率。


<details>
  <summary>Details</summary>
Motivation: 在涉及电子健康记录的时间序列预测任务中，平衡隐私保障与预测性能至关重要。

Method: 使用数据增强技术，包括Zeroth-Order Optimization（ZOO）、ZOO-PCA、MixUp等，对时间序列预测模型进行重新训练。

Result: 通过使用合成数据进行重新训练，显著减少了基于损失的会员推断攻击的有效性，提高了模型的泛化能力。

Conclusion: ZOO-PCA策略在提高模型对会员推断攻击的抵抗力的同时，保持了测试数据的表现。

Abstract: Balancing strong privacy guarantees with high predictive performance is
critical for time series forecasting (TSF) tasks involving Electronic Health
Records (EHR). In this study, we explore how data augmentation can mitigate
Membership Inference Attacks (MIA) on TSF models. We show that retraining with
synthetic data can substantially reduce the effectiveness of loss-based MIAs by
reducing the attacker's true-positive to false-positive ratio. The key
challenge is generating synthetic samples that closely resemble the original
training data to confuse the attacker, while also introducing enough novelty to
enhance the model's ability to generalize to unseen data. We examine multiple
augmentation strategies - Zeroth-Order Optimization (ZOO), a variant of ZOO
constrained by Principal Component Analysis (ZOO-PCA), and MixUp - to
strengthen model resilience without sacrificing accuracy. Our experimental
results show that ZOO-PCA yields the best reductions in TPR/FPR ratio for MIA
attacks without sacrificing performance on test data.

</details>


### [146] [Attention and Compression is all you need for Controllably Efficient Language Models](https://arxiv.org/abs/2511.05313)
*Jatin Prakash,Aahlad Puli,Rajesh Ranganath*

Main category: cs.LG

TL;DR: CAT是一种新型Transformer架构，通过稠密注意力和压缩机制提升性能和效率，在语言建模中超越现有基准。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有稀疏注意力机制在计算和内存方面的不足，同时提高上下文回忆性能。

Method: 提出了Compress & Attend Transformer (CAT)架构，结合稠密注意力与压缩机制。

Result: CAT模型在多个语言建模任务中评估，表现优于其他高效架构，在模型速度和内存占用方面具有显著优势。

Conclusion: CAT模型在语言建模任务中表现优于现有高效基准，同时在速度和内存使用方面显著优化。

Abstract: The quadratic cost of attention in transformers motivated the development of
efficient approaches: namely sparse and sliding window attention, convolutions
and linear attention. Although these approaches result in impressive reductions
in compute and memory, they often trade-off with quality, specifically
in-context recall performance. Moreover, apriori fixing this quality-compute
tradeoff means being suboptimal from the get-go: some downstream applications
require more memory for in-context recall, while others require lower latency
and memory. Further, these approaches rely on heuristic choices that
artificially restrict attention, or require handcrafted and complex recurrent
state update rules, or they must be carefully composed with attention at
specific layers to form a hybrid architecture that complicates the design
process, especially at scale. To address above issues, we propose Compress &
Attend Transformer (CAT), a conceptually simple architecture employing two
simple ingredients only: dense attention and compression. CAT decodes chunks of
tokens by attending to compressed chunks of the sequence so far. Compression
results in decoding from a reduced sequence length that yields compute and
memory savings, while choosing a particular chunk size trades-off quality for
efficiency. Moreover, CAT can be trained with multiple chunk sizes at once,
unlocking control of quality-compute trade-offs directly at test-time without
any retraining, all in a single adaptive architecture. In exhaustive
evaluations on common language modeling tasks, in-context recall, and
long-context understanding, a single adaptive CAT model outperforms existing
efficient baselines, including hybrid architectures, across different
compute-memory budgets. Further, a single CAT matches dense transformer in
language modeling across model scales while being 1.4-3x faster and requiring
2-9x lower total memory usage.

</details>


### [147] [Turning Adversaries into Allies: Reversing Typographic Attacks for Multimodal E-Commerce Product Retrieval](https://arxiv.org/abs/2511.05325)
*Janet Jenq,Hongda Shen*

Main category: cs.LG

TL;DR: 本研究提出通过视觉渲染产品文本来提升电商多模态检索系统的表现。


<details>
  <summary>Details</summary>
Motivation: 由于现有的视觉语言模型在应对排版攻击方面面临挑战，我们希望通过增强图像与文本的结合来提高搜索的相关性和用户体验。

Method: 采用视觉文本压缩的方法，将相关文本内容直接嵌入产品图像中，以加强图像与文本之间的对齐。

Result: 在三个特定电商数据集上进行评估后，我们的实验表明该方法在单模态和多模态检索准确性上均有持续改进。

Conclusion: 通过将产品元数据可视化渲染到产品图像上，我们提出了一种有效的方法来增强多模态产品检索的性能。

Abstract: Multimodal product retrieval systems in e-commerce platforms rely on
effectively combining visual and textual signals to improve search relevance
and user experience. However, vision-language models such as CLIP are
vulnerable to typographic attacks, where misleading or irrelevant text embedded
in images skews model predictions. In this work, we propose a novel method that
reverses the logic of typographic attacks by rendering relevant textual content
(e.g., titles, descriptions) directly onto product images to perform
vision-text compression, thereby strengthening image-text alignment and
boosting multimodal product retrieval performance. We evaluate our method on
three vertical-specific e-commerce datasets (sneakers, handbags, and trading
cards) using six state-of-the-art vision foundation models. Our experiments
demonstrate consistent improvements in unimodal and multimodal retrieval
accuracy across categories and model families. Our findings suggest that
visually rendering product metadata is a simple yet effective enhancement for
zero-shot multimodal retrieval in e-commerce applications.

</details>


### [148] [Learning Dynamics from Input-Output Data with Hamiltonian Gaussian Processes](https://arxiv.org/abs/2511.05330)
*Jan-Hendrik Ewering,Robin E. Herrmann,Niklas Wahlström,Thomas B. Schön,Thomas Seel*

Main category: cs.LG

TL;DR: 本文提出了一种从输入-输出数据学习非保守哈密尔顿动态的方法，利用全贝叶斯框架和降维GP近似，实现在非线性模拟中的有效预测。


<details>
  <summary>Details</summary>
Motivation: 通过学习基础数据中的非保守哈密尔顿动态，来构建符合物理原则的模型，尤其是在缺乏速度或动量数据的实际应用场景中。

Method: 使用全贝叶斯方案来估计未知隐藏状态、GP超参数和结构超参数，并采用降维GP近似来实现高效的预测和训练。

Result: 在非保守哈密尔顿GP的框架下，从输入-输出数据中学习动力学，并实现了高效的概率密度估计。

Conclusion: 提出的方法在非线性模拟案例研究中表现良好，优于依赖动量测量的现有方法。

Abstract: Embedding non-restrictive prior knowledge, such as energy conservation laws,
in learning-based approaches is a key motive to construct physically consistent
models from limited data, relevant for, e.g., model-based control. Recent work
incorporates Hamiltonian dynamics into Gaussian Process (GP) regression to
obtain uncertainty-quantifying models that adhere to the underlying physical
principles. However, these works rely on velocity or momentum data, which is
rarely available in practice. In this paper, we consider dynamics learning with
non-conservative Hamiltonian GPs, and address the more realistic problem
setting of learning from input-output data. We provide a fully Bayesian scheme
for estimating probability densities of unknown hidden states, of GP
hyperparameters, as well as of structural hyperparameters, such as damping
coefficients. Considering the computational complexity of GPs, we take
advantage of a reduced-rank GP approximation and leverage its properties for
computationally efficient prediction and training. The proposed method is
evaluated in a nonlinear simulation case study and compared to a
state-of-the-art approach that relies on momentum measurements.

</details>


### [149] [SAD-Flower: Flow Matching for Safe, Admissible, and Dynamically Consistent Planning](https://arxiv.org/abs/2511.05355)
*Tzu-Yuan Huang,Armin Lederer,Dai-Jie Wu,Xiaobing Dai,Sihua Zhang,Stefan Sosnowski,Shao-Hua Sun,Sandra Hirche*

Main category: cs.LG

TL;DR: SAD-Flower 是一种新颖的轨迹生成框架，旨在解决流匹配方法的安全性和动态一致性问题，并在多任务实验中 outperform 现有基线。


<details>
  <summary>Details</summary>
Motivation: 解决现有流匹配规划器在状态和动作约束满足以及动态一致性方面的不足，以确保安全和可接受的轨迹生成。

Method: 通过在流匹配方法中增加虚拟控制输入，采用非线性控制理论的技术来指导轨迹生成。

Result: SAD-Flower 在多项任务的广泛实验中展示了其优越性，能够确保约束条件的满足，并且无需重新训练。

Conclusion: SAD-Flower 比现有生成模型基线在满足约束条件方面表现更优，提供了安全、可接受且动态一致的轨迹生成保证。

Abstract: Flow matching (FM) has shown promising results in data-driven planning.
However, it inherently lacks formal guarantees for ensuring state and action
constraints, whose satisfaction is a fundamental and crucial requirement for
the safety and admissibility of planned trajectories on various systems.
Moreover, existing FM planners do not ensure the dynamical consistency, which
potentially renders trajectories inexecutable. We address these shortcomings by
proposing SAD-Flower, a novel framework for generating Safe, Admissible, and
Dynamically consistent trajectories. Our approach relies on an augmentation of
the flow with a virtual control input. Thereby, principled guidance can be
derived using techniques from nonlinear control theory, providing formal
guarantees for state constraints, action constraints, and dynamic consistency.
Crucially, SAD-Flower operates without retraining, enabling test-time
satisfaction of unseen constraints. Through extensive experiments across
several tasks, we demonstrate that SAD-Flower outperforms various
generative-model-based baselines in ensuring constraint satisfaction.

</details>


### [150] [Diffusion-Based Electromagnetic Inverse Design of Scattering Structured Media](https://arxiv.org/abs/2511.05357)
*Mikhail Tsukerman,Konstantin Grotov,Pavel Ginzburg*

Main category: cs.LG

TL;DR: 提出了一种条件扩散模型，用于电磁逆向设计，显著降低设计时间且提高了设计精度，展示了未来在光子和无线通信系统开发中的潜力。


<details>
  <summary>Details</summary>
Motivation: 旨在通过绕过昂贵的迭代优化过程，快速生成复杂的电磁结构以满足特定的散射要求。

Method: 使用1D U-Net架构和特征线性调制，模型从目标差分散射截面直接生成媒体几何结构，处理逆问题的非唯一性。

Result: 在11,000个模拟超材料的训练下，模型在未见目标上的中位数绝对误差(MPE)低于19%，设计时间从小时缩短到秒。

Conclusion: 该研究展示了条件扩散模型在电磁逆向设计中的有效性，显著提高了设计效率并降低了时间成本。

Abstract: We present a conditional diffusion model for electromagnetic inverse design
that generates structured media geometries directly from target differential
scattering cross-section profiles, bypassing expensive iterative optimization.
Our 1D U-Net architecture with Feature-wise Linear Modulation learns to map
desired angular scattering patterns to 2x2 dielectric sphere structure,
naturally handling the non-uniqueness of inverse problems by sampling diverse
valid designs. Trained on 11,000 simulated metasurfaces, the model achieves
median MPE below 19% on unseen targets (best: 1.39%), outperforming CMA-ES
evolutionary optimization while reducing design time from hours to seconds.
These results demonstrate that employing diffusion models is promising for
advancing electromagnetic inverse design research, potentially enabling rapid
exploration of complex metasurface architectures and accelerating the
development of next-generation photonic and wireless communication systems. The
code is publicly available at
https://github.com/mikzuker/inverse_design_metasurface_generation.

</details>


### [151] [Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction](https://arxiv.org/abs/2511.05396)
*Yiting He,Zhishuai Liu,Weixin Wang,Pan Xu*

Main category: cs.LG

TL;DR: 研究在线强化学习的探索难度，提出了一种新算法实现有效学习，并验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 研究在线交互受限的训练环境下的强化学习，以解决训练动态与部署动态不匹配的问题。

Method: 通过引入超极大访问比率来捕捉在线RMDP中的探索难度，并提出了一种基于$f$-散度的过渡不确定性的算法。

Result: 提出的算法在在线RMDP中能够实现次线性遗憾并验证了理论边界。

Conclusion: 提出了一种有效的算法，能够在在线RMDP中实现次线性遗憾，并且通过数值实验验证了理论结果。

Abstract: Off-dynamics reinforcement learning (RL), where training and deployment
transition dynamics are different, can be formulated as learning in a robust
Markov decision process (RMDP) where uncertainties in transition dynamics are
imposed. Existing literature mostly assumes access to generative models
allowing arbitrary state-action queries or pre-collected datasets with a good
state coverage of the deployment environment, bypassing the challenge of
exploration. In this work, we study a more realistic and challenging setting
where the agent is limited to online interaction with the training environment.
To capture the intrinsic difficulty of exploration in online RMDPs, we
introduce the supremal visitation ratio, a novel quantity that measures the
mismatch between the training dynamics and the deployment dynamics. We show
that if this ratio is unbounded, online learning becomes exponentially hard. We
propose the first computationally efficient algorithm that achieves sublinear
regret in online RMDPs with $f$-divergence based transition uncertainties. We
also establish matching regret lower bounds, demonstrating that our algorithm
achieves optimal dependence on both the supremal visitation ratio and the
number of interaction episodes. Finally, we validate our theoretical results
through comprehensive numerical experiments.

</details>


### [152] [ProDER: A Continual Learning Approach for Fault Prediction in Evolving Smart Grids](https://arxiv.org/abs/2511.05420)
*Emad Efatinasab,Nahal Azadi,Davide Dalle Pezze,Gian Antonio Susto,Chuadhry Mujeeb Ahmed,Mirco Rampazzo*

Main category: cs.LG

TL;DR: 本研究提出了一种持续学习框架ProDER，可有效应对智能电网的故障预测挑战，展示了其在实际应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着智能电网的发展，准确预测故障变得愈发重要，但现有的AI模型在适应新故障类型和工作区域时面临挑战。

Method: 采用Prototype-based Dark Experience Replay (ProDER)方法，结合原型特征正则化、logit蒸馏及原型引导的重放记忆，以实现故障类型及故障区域的预测。

Result: 实验结果表明，ProDER在故障类型预测中仅下降0.045的准确率，而故障区域预测中下降0.015，最佳表现于测试的持续学习技术。

Conclusion: 提出的Prototype-based Dark Experience Replay (ProDER)方法在智能电网故障预测中表现优越，显示出持续学习的实用性与可扩展性。

Abstract: As smart grids evolve to meet growing energy demands and modern operational
challenges, the ability to accurately predict faults becomes increasingly
critical. However, existing AI-based fault prediction models struggle to ensure
reliability in evolving environments where they are required to adapt to new
fault types and operational zones. In this paper, we propose a continual
learning (CL) framework in the smart grid context to evolve the model together
with the environment. We design four realistic evaluation scenarios grounded in
class-incremental and domain-incremental learning to emulate evolving grid
conditions. We further introduce Prototype-based Dark Experience Replay
(ProDER), a unified replay-based approach that integrates prototype-based
feature regularization, logit distillation, and a prototype-guided replay
memory. ProDER achieves the best performance among tested CL techniques, with
only a 0.045 accuracy drop for fault type prediction and 0.015 for fault zone
prediction. These results demonstrate the practicality of CL for scalable,
real-world fault prediction in smart grids.

</details>


### [153] [Adversarially Robust Multitask Adaptive Control](https://arxiv.org/abs/2511.05444)
*Kasra Fallah,Leonardo F. Toso,James Anderson*

Main category: cs.LG

TL;DR: 研究了在对抗干扰与模型不确定性条件下的多任务控制策略，提出了一种聚类方法，以减少对抗影响下的后悔期望。


<details>
  <summary>Details</summary>
Motivation: 研究在模型不确定性和对抗性干扰下的多任务自适应线性二次控制问题。

Method: 采用聚类和系统识别相结合的方法，并通过抗干扰的聚合机制来应对模型更新的损坏。

Result: 通过非渐近界限，证明了在每个群集中的诚实系统数量与后悔的逆相关性，并且这一减少在有对抗系统存在的情况下得以保存。

Conclusion: 提出的聚类多任务方法有效地减少了在存在对抗性系统的情况下的控制策略的后悔期望。

Abstract: We study adversarially robust multitask adaptive linear quadratic control; a
setting where multiple systems collaboratively learn control policies under
model uncertainty and adversarial corruption. We propose a clustered multitask
approach that integrates clustering and system identification with resilient
aggregation to mitigate corrupted model updates. Our analysis characterizes how
clustering accuracy, intra-cluster heterogeneity, and adversarial behavior
affect the expected regret of certainty-equivalent (CE) control across LQR
tasks. We establish non-asymptotic bounds demonstrating that the regret
decreases inversely with the number of honest systems per cluster and that this
reduction is preserved under a bounded fraction of adversarial systems within
each cluster.

</details>


### [154] [Synapse: Adaptive Arbitration of Complementary Expertise in Time Series Foundational Models](https://arxiv.org/abs/2511.05460)
*Sarkar Snigdha Sarathi Das,Palash Goyal,Mihir Parmar,Yiwen Song,Long T. Le,Lesly Miculicich,Jinsung Yoon,Rui Zhang,Hamid Palangi,Tomas Pfister*

Main category: cs.LG

TL;DR: 本文提出了Synapse框架，它通过动态利用不同TSFM的输出，优化时间序列预测的性能，实验结果表明该框架表现优于其他技术。


<details>
  <summary>Details</summary>
Motivation: 虽然预训练时间序列基础模型（TSFMs）在各种预测任务中表现出色，但其有效性因数据源和训练协议的不同而存在很大差异，因此探索模型间的互补能力和仲裁策略具有重要意义。

Method: 分析不同时间序列基础模型(TSFMs)在不同预测设置下的表现，研究模型选择和预测范围的影响，提出并实现了Synapse框架。

Result: 实验结果显示，Synapse框架在时间序列预测上持续优于其他常见集成技术和单独TSFMs，验证了其有效性。

Conclusion: Synapse框架在时间序列预测中表现优越，能够有效利用不同TSFM的互补优势。

Abstract: Pre-trained Time Series Foundational Models (TSFMs) represent a significant
advance, capable of forecasting diverse time series with complex
characteristics, including varied seasonalities, trends, and long-range
dependencies. Despite their primary goal of universal time series forecasting,
their efficacy is far from uniform; divergent training protocols and data
sources cause individual TSFMs to exhibit highly variable performance across
different forecasting tasks, domains, and horizons. Leveraging this
complementary expertise by arbitrating existing TSFM outputs presents a
compelling strategy, yet this remains a largely unexplored area of research. In
this paper, we conduct a thorough examination of how different TSFMs exhibit
specialized performance profiles across various forecasting settings, and how
we can effectively leverage this behavior in arbitration between different time
series models. We specifically analyze how factors such as model selection and
forecast horizon distribution can influence the efficacy of arbitration
strategies. Based on this analysis, we propose Synapse, a novel arbitration
framework for TSFMs. Synapse is designed to dynamically leverage a pool of
TSFMs, assign and adjust predictive weights based on their relative,
context-dependent performance, and construct a robust forecast distribution by
adaptively sampling from the output quantiles of constituent models.
Experimental results demonstrate that Synapse consistently outperforms other
popular ensembling techniques as well as individual TSFMs, demonstrating
Synapse's efficacy in time series forecasting.

</details>


### [155] [SiamMM: A Mixture Model Perspective on Deep Unsupervised Learning](https://arxiv.org/abs/2511.05462)
*Xiaodong Wang,Jing Huang,Kevin J Liang*

Main category: cs.LG

TL;DR: 本研究提出了SiamMM模型，通过与经典混合模型的关联显著提高了无监督聚类的效果，并在自监督学习任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索聚类方法的最佳实践，以提高自监督和无监督学习的效果。

Method: 通过将无监督聚类方法与经典统计混合模型建立联系，提出改进的聚类方法。

Result: 提出了一种名为SiamMM的新模型，在多个自监督学习基准中达到了最先进的性能，并发现了聚类与未见真实标签的强相似性。

Conclusion: 本研究的SiamMM模型在各种自监督学习基准中表现出色，揭示了聚类与真实标签之间的关联，指向可能的错误标记实例。

Abstract: Recent studies have demonstrated the effectiveness of clustering-based
approaches for self-supervised and unsupervised learning. However, the
application of clustering is often heuristic, and the optimal methodology
remains unclear. In this work, we establish connections between these
unsupervised clustering methods and classical mixture models from statistics.
Through this framework, we demonstrate significant enhancements to these
clustering methods, leading to the development of a novel model named SiamMM.
Our method attains state-of-the-art performance across various self-supervised
learning benchmarks. Inspection of the learned clusters reveals a strong
resemblance to unseen ground truth labels, uncovering potential instances of
mislabeling.

</details>


### [156] [On Flow Matching KL Divergence](https://arxiv.org/abs/2511.05480)
*Maojiang Su,Jerry Yao-Chieh Hu,Sophia Pi,Han Liu*

Main category: cs.LG

TL;DR: 论文提出了流匹配分布近似的KL散度的非渐近上界，展示了流匹配在估计光滑分布时的高效性。


<details>
  <summary>Details</summary>
Motivation: 希望在流匹配分布近似中提供一个确定性的界限，进而分析其统计效率，对比现有模型。

Method: 通过推导流匹配分布近似的Kullback-Leibler散度的确定性非渐近上界，分析了流匹配损失与KL散度之间的关系。

Result: 如果$L_2$流匹配损失受限于$	ext{ε}^2 > 0$，则真实数据分布与估计分布之间的KL散度受到了相应的界限。

Conclusion: 流匹配在估计光滑分布时实现了近乎最优的效率，其统计效率与扩散模型在总变差距离下具有可比性。

Abstract: We derive a deterministic, non-asymptotic upper bound on the Kullback-Leibler
(KL) divergence of the flow-matching distribution approximation. In particular,
if the $L_2$ flow-matching loss is bounded by $\epsilon^2 > 0$, then the KL
divergence between the true data distribution and the estimated distribution is
bounded by $A_1 \epsilon + A_2 \epsilon^2$. Here, the constants $A_1$ and $A_2$
depend only on the regularities of the data and velocity fields. Consequently,
this bound implies statistical convergence rates of Flow Matching Transformers
under the Total Variation (TV) distance. We show that, flow matching achieves
nearly minimax-optimal efficiency in estimating smooth distributions. Our
results make the statistical efficiency of flow matching comparable to that of
diffusion models under the TV distance. Numerical studies on synthetic and
learned velocities corroborate our theory.

</details>


### [157] [SoilX: Calibration-Free Comprehensive Soil Sensing Through Contrastive Cross-Component Learning](https://arxiv.org/abs/2511.05482)
*Kang Yang,Yuanlin Yang,Yuning Chen,Sikai Yang,Xinyu Zhang,Wan Du*

Main category: cs.LG

TL;DR: 本文提出了一种名为SoilX的土壤传感系统，能在不需要重新校准的情况下准确测量土壤湿度及关键营养素，显著降低估计误差。


<details>
  <summary>Details</summary>
Motivation: 应对目前无线土壤传感器在土壤纹理变化下需要重新校准的问题，以提高精准农业的效率。

Method: 引入了一种校准自由的土壤传感系统，通过建模有机碳和铝硅酸盐消除了对土壤纹理的依赖。采用对比交叉组分学习（3CL）和独特的天线阵列设计。

Result: SoilX系统在土壤电介质常数检测中表现优异，估计错误减少23.8%至31.5%。

Conclusion: SoilX系统在减少土壤湿度和关键营养素估计误差方面表现出色，并能有效推广到未知领域。

Abstract: Precision agriculture demands continuous and accurate monitoring of soil
moisture (M) and key macronutrients, including nitrogen (N), phosphorus (P),
and potassium (K), to optimize yields and conserve resources. Wireless soil
sensing has been explored to measure these four components; however, current
solutions require recalibration (i.e., retraining the data processing model) to
handle variations in soil texture, characterized by aluminosilicates (Al) and
organic carbon (C), limiting their practicality. To address this, we introduce
SoilX, a calibration-free soil sensing system that jointly measures six key
components: {M, N, P, K, C, Al}. By explicitly modeling C and Al, SoilX
eliminates texture- and carbon-dependent recalibration. SoilX incorporates
Contrastive Cross-Component Learning (3CL), with two customized terms: the
Orthogonality Regularizer and the Separation Loss, to effectively disentangle
cross-component interference. Additionally, we design a novel tetrahedral
antenna array with an antenna-switching mechanism, which can robustly measure
soil dielectric permittivity independent of device placement. Extensive
experiments demonstrate that SoilX reduces estimation errors by 23.8% to 31.5%
over baselines and generalizes well to unseen fields.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [158] [Automatización de Informes Geotécnicos para Macizos Rocosos con IA](https://arxiv.org/abs/2511.04690)
*Christofer Valencia,Alexis Llumigusín,Silvia Alvarez,Abrahan Arias,Christian Mejia-Escobar*

Main category: cs.MM

TL;DR: 研究提出了一种基于AI的系统，能够自动生成地质报告，效率高且数据可信，适用于地质学领域的多个使用者。


<details>
  <summary>Details</summary>
Motivation: 传统地质报告的手动编制方式效率低下，容易出错，因此需要引入自动化技术来提高准确性和效率。

Method: 利用人工智能技术处理图像和现场数据，自动生成地质报告。

Result: 通过对多模态大语言模型进行迭代优化，最终报告的质量指标与专家报告相仿，具有实际应用价值。

Conclusion: 该工具为地质学专业人员和学生提供了一种创新的解决方案，促进了地质报告的自动生成，提高了效率。

Abstract: Geotechnical reports are crucial for assessing the stability of rock
formations and ensuring safety in modern engineering. Traditionally, these
reports are prepared manually based on field observations using compasses,
magnifying glasses, and notebooks. This method is slow, prone to errors, and
subjective in its interpretations. To overcome these limitations, the use of
artificial intelligence techniques is proposed for the automatic generation of
reports through the processing of images and field data. The methodology was
based on the collection of photographs of rock outcrops and manual samples with
their respective descriptions, as well as on the reports prepared during the
Geotechnical Studies course. These resources were used to define the report
outline, prompt engineering, and validate the responses of a multimodal large
language model (MLLM). The iterative refinement of prompts until structured and
specific instructions were obtained for each section of the report proved to be
an effective alternative to the costly process of fine-tuning the MLLM. The
system evaluation establishes values of 0.455 and 0.653 for the BLEU and
ROUGE-L metrics, respectively, suggesting that automatic descriptions are
comparable to those made by experts. This tool, accessible via the web, with an
intuitive interface and the ability to export to standardized formats,
represents an innovation and an important contribution for professionals and
students of field geology.

</details>
